[
  {
    "brand": "intel",
    "generation": "battlemage",
    "tier": "580",
    "matched_keywords": [
      "a580",
      "b580",
      "arc b580"
    ],
    "title": "Intel Arc B580 Battlemage GPU OpenCL/Vulkan performance leaks out, 9% to 30% faster than A580",
    "selftext": "",
    "comments": [
      "Just saw a GamersNexus video on this yesterday.\n\nFrom what I understand, the A-series Arc cards had to basically emulate many functions for gaming that were natively supported by other cards. \n\nThat led to driver support being reaaaallly shaky at the beginning.  It has improved a lot since then, and even though I only play a couple of games, my A series cards have performed really well. \n\nThe B-series cards have that capability baked in natively, which *should* give the cards a big performance boost over the previous generation and make driver support much easier.",
      "Which is a great combination at this price range tbh. The 2080 is a DECENT 1080p - 2k card, pair that with a healthy 12gb vram and you got a nice package. Something that AMD and Nvidia fails to deliver.",
      "So this is basically a rtx 2080 but with 12gb vram?",
      "Go to NGREEDIA",
      "Great",
      "Yeah, I got nothing to say to this level of performance as long as pricing is good. If they can figure out the drivers B580 should be the better 4060 for less money.",
      "it's nowhere near as bad as people say, in my experience",
      "\"rendering 3D scenes\" lol... as opposed to what? smell-ovision?",
      "Had No issues yet....there are regular Updates , especially when new popular Games release",
      "3060 ti is probably still faster. Maybe wait for the B770",
      "I am very confused can you guys help me i am planning to buy this card, the only thing worrying me is driver support, is it that bad ? i dont consider myself as a first day gamer when the game release but i have heard even the previous titles struggles with intel driver supports is that true ?",
      "Why are you comparing a productivity benchmark for a gaming card. It's like comparing a productivity benchmark to the 9800x3d. It loses to a 13600k.",
      "Just search for b580 on NewEgg to see all the cards for pre-order that have sold out",
      "https://opendata.blender.org/benchmarks/query/?device_name=NVIDIA%20GeForce%20RTX%203060%20Ti&device_name=Intel%20Arc%20A770%20Graphics&device_name=NVIDIA%20GeForce%20RTX%204060&device_name=NVIDIA%20GeForce%20RTX%202080&compute_type=OPTIX&compute_type=CUDA&compute_type=HIP&compute_type=METAL&compute_type=ONEAPI&blender_version=4.2.0&group_by=device_name\n\nAh look! The blender score shows the a770 with about the same score as a 2080!",
      "Driver support is really good.",
      "Has it been officially confirmed from Intel that they won’t be making the B750 & B770? Wasn’t there supposed to be a B980?",
      "When can I order one of these cards? None listed on Amazon or NewEgg",
      "For now, we don't know what AMD's cooking",
      "An intel insider some weeks ago said the inner working on intel is wishy washy on a ton rn, cutting costs left and right just to return what had gotten cut days or weeks later, so maybe not even intel themselves know for certain which is why the messaging is mixed.",
      "Yeah but like who cares? We know what they meant."
    ]
  },
  {
    "brand": "intel",
    "generation": "battlemage",
    "tier": "580",
    "matched_keywords": [
      "a580",
      "b580",
      "arc b580"
    ],
    "title": "Retailers accidentally ship Arc B580 early, mistaking It for A580",
    "selftext": "",
    "comments": [
      "congrats,\n\nhappy for you,\n\nnice,",
      "I can see the pic of the wee lad, in my mind",
      "I thought they had the cards but the drivers aren’t released until embargo day",
      "They aren't talking about reviewers, they shipped some cards to regular consumers that had pre-ordered a B580",
      "Reviewers have had the LE cards for over a week, embargo lifts tomorrow, on the 12th. I believe AIB models are embargoed until the 13th (launch day).",
      "When do the reviews drop?",
      "Lmao good luck selling 4060 once B770 come out and when 5060 are right after.",
      "I'm giddy. Can't wait for the reviews",
      "A lot of times reviewers will be given an early or beta version of an upcoming driver.",
      "It's just retailers sending out cards early. They're paperweights without the drivers so there's not much harm or leaking done here. We all knew what the cards looked like anyway",
      "I read this with patrick bateman voice",
      "On an unrelated note: Retailers seeing a sudden boom in A580 orders. One retailer which remained anonymous states \"We can't keep A580 on the shelves. They're suddenly moving out fast\"",
      "To bad they didn’t price them as the A580.",
      "Unfortunate, it costs 400 EUROS in my country. It's just not worth it. Im gonna buy an rtx 4060, and keep an eye out for that potential b770.",
      "the B770 is very likely to be announced at CompuTex alongside AMD and Nvidia, with similarly a launch date to follow too far away.  Anyway - whatever you are in the mood for, right now is the worst time to buy a card - any remaining 4000 series stock not called 4090 is going to have its price drop soon.",
      "With the world recorder vat, and the usual price upping during Christmas time in Hungary it's unlikely it'll drop much. It cost me 295 in euros and it was 20euros cheaper literally a day before pay day... I just want to game during my 3 weeks off. Hell knows how many ot I'll have to do January..\n\n\nOr maybe I'm just coping",
      "how the hell it works in the US? I see people are getting completely wrong SKUs or entire box of drives instead of just one. in countries where I lived you as a seller just cannot sell it without scanning barcode, only after this you will be allowed to print invoice and ship stuff. and ofc you cannot just put 6 drives instead of one, company will just deduct it from your salary",
      "Lol that’s funny",
      "It's a strange naming scheme",
      "Why are there so many leaks? I started to think they just let some pass to hype us."
    ]
  },
  {
    "brand": "intel",
    "generation": "battlemage",
    "tier": "580",
    "matched_keywords": [
      "a580",
      "b580",
      "arc b580"
    ],
    "title": "ARC B580 and Steam VR - VIVE 2 Pro",
    "selftext": "  \nBad luck, we must pressure Intel. Things will NOT work out on itself.\n\nSteam  \n\n\nHello,\n\n\n\nThank you for reaching out to Steam Support about the issues you appear to be encountering with SteamVR.\n\n\n\nThe GPU you are currently using, an Intel ARC B580, is currently not compatible with SteamVR.\n\n\n\nSome users may have been able to get this GPU to function under certain circumstances but Steam Support is unable to troubleshoot issues that occur with this GPU.\n\n\n\nFrom what we can understand GPU driver updates will need to be released for the Intel GPUs. Until then, this GPU will remain incompatible with SteamVR.\n\n\n\nYou can view the system requirements for SteamVR here: [https://store.steampowered.com/app/250820/SteamVR/](https://store.steampowered.com/app/250820/SteamVR/)\n\n\n\nWe apologize for this inconvenience.\n\n\n\nIf you have any further questions, please let us know - we will do our best to assist you.\n\n\n\nSteam Support\n\nMichael\n\n\n\nMessage from you on May 11 @ 10:08pm | 14 hours ago\n\nCard is far more advanced then minimal requirements.\n\nI am sure both Steam and Intel can cooperate in making it to the list.\n\nIts a shame such well priced and popular card from major vendor is left behind.\n\n\n\nPlease let me know as soon as this is corrected.  \nHTC Vive\n\n||\n||\n||Dear Customer, Thanks for contacting VIVE support.   We appreciate your keen interest in the VIVE Pro 2 Full Kit and your proactive inquiry regarding its compatibility with your ASRock Steel Legend B580 Intel Arc A580 12GB OC graphics card.    Given the relatively recent introduction of the Intel Arc series to the discrete graphics card market, and the nuanced nature of VR support with evolving architectures, we wish to provide you with the most accurate information currently available.   Comprehensive and dedicated testing specifically involving the B580 chipset and the Intel Arc A580 12GB OC in conjunction with the VIVE Pro 2 Full Kit appears to be limited. This is due to the ongoing development and assessment of VR support for the Intel Arc series.   While Intel has been diligently releasing drivers aimed at enhancing compatibility with virtual reality headsets and platforms such as SteamVR, the [VIVE Pro 2's officially recommended specifications](https://www.vive.com/eu/vive-ready/) include NVIDIA GeForce RTX 20 Series or AMD Radeon RX 5700 or superior. Although these represent the optimal configurations, graphics cards below these recommendations may function, potentially with a reduction in visual fidelity or performance, particularly in graphically intensive applications.   It is challenging to provide an absolute guarantee of \"100 percent working\" across all possible system configurations, especially with newer graphics processing units. The overall performance can also be significantly influenced by the specific virtual reality application or game being utilized, as well as other integral system components, such as your central processing unit and random-access memory.   Regarding your expressed preference for a high-quality VR kit over a more expensive graphics card paired with a potentially less immersive VR system, we understand your rationale. The VIVE Pro 2 offers impressive resolution and exceptional visual fidelity. However, the overall quality of your experience will ultimately depend on the capability of your graphics card to adequately drive the VR content you intend to utilize.   In conclusion, while the Intel Arc A580 *may* function with the VIVE Pro 2 on SteamVR, we cannot offer a definitive guarantee of complete and flawless operation without specific testing data for this precise hardware combination. The necessity to adjust graphical settings for optimal performance remains a possibility. **Nina** (VIVE) May 12, 2025, 18:34 GMT+8 |",
    "comments": [
      "Intel cards don't support VR. At least not yet. Honestly tho VR is a niche market so I would rather them ignor it and get everything else great before diving into it. It wasn't till recently that AMD's VR performance was good enough to consider as well. Nvidia has had a strangle hold on the VR market sense VR started hitting the market. \n\nI love my Intel card but if I was using VR I would have bought nivida hands down simply because they offer the best reliable performance in VR.",
      "Uh… that’s not news to us tho? Intel never said it supports VR",
      "Intel has been pretty straightforward on not supporting VR: https://www.intel.com/content/www/us/en/support/articles/000093024/graphics.html",
      "I'm not interested in VR but I really want Intel to at least go all hands on it some day.",
      "It is a growing market, but it definitely is niche. It's a very common part of simracing as well. I own a vr head set and most of the people I game with also own one as alot of what I do is simracing and simdrifting and VR in those communities is extremely common (i personally use triple screens in sted of vr). My B580 is a far superior card to my old GTX1660 that I ran VR with, but the b580 doesn't run the VR. \n\nWhen the b580 has some driver issues and needs tweaking in games as common as CS2, Marvel rivals, and COD, which are by far the some of the most common and most played games, VR can wait. \n\nVR is a niche market that isn't for everyone. Not only is it a pricy perifial but there are alot of people that simply can't use it because it makes them physically ill. (Litterly the only thing I can do in VR is simdriving, anything else I sick with in 20 minutes.)",
      "Well, in general products list what they do support, instead of what they don’t. Of products listed what they don’t support, every product would have a huge list of “specs”…\n\nSo, at least for electronics, I always assume they if something is not explicitly listed as supported, then it’s not supported.",
      "Created a ticket with Intel as HTC and Steam responses were handwashing - simply not supported\n\n||\n||\n|Hello Vojin Vidanović,  Thank you for contacting Intel Customer Support. Please be advised we are currently experiencing higher than normal case volume, which may cause delays. Thank you for your patience. Below is a summary of the information you submitted, as well as the number assigned to your case.  Please reference this case number whenever you contact Intel Customer Support about this case.  Best regards, Intel Customer Support Case Number 06579504 Case Subject Steam VR is not working, please work on this! Hello, Thank you for reaching out to Steam Support about the issues you appear to be encountering with SteamVR. The GPU you are currently using, an Intel ARC B580, is currently not compatible with SteamVR.|",
      "Its growing market, check SteamVR to see how fast its library and user share is growing.  \nI do get now they dont (I through it was more unified standard like OpenGL or DirectX).  \nBut that makes my next gfx card surely nVIDIA. Changing card and buying VR set is too expensive.  \nAs I explained in mail to HTC, having budget card that supports VR would be great, as it enables users to buy better sets for price diff, and on paper B580 is not inferior to VR supported cards.",
      "I believe so, but that is the support page \nNowhere in card specs on the box (what I call straightforward) does ot say \"this card does not (and never will) support steamvr or any vr device",
      "No it did not, but is kind of expected for that gen card.\n\nIt would be honest to have no support vr and never will on the box and in card info.\nI found out recently",
      "Thanks, I shall wait for tech to be more mature and standardized",
      "In short vr is still expensive unsupported toy",
      "Created a ticket with Intel as HTC and Steam responses were handwashing - simply not supported\n\n||\n||\n||",
      "Created a ticket with Intel as HTC and Steam responses were handwashing - simply not supported",
      "Created a ticket with Intel as HTC and Steam responses were handwashing - simply not supported\n\n||\n||\n|Hello Vojin Vidanović,  Thank you for contacting Intel Customer Support. Please be advised we are currently experiencing higher than normal case volume, which may cause delays. Thank you for your patience. Below is a summary of the information you submitted, as well as the number assigned to your case.  Please reference this case number whenever you contact Intel Customer Support about this case.  Best regards, Intel Customer Support Case Number 06579504|",
      "Created a ticket with Intel as HTC and Steam responses were handwashing - simply not supported\n\n||\n||\n|Hello Vojin Vidanović,  Thank you for contacting Intel Customer Support. Please be advised we are currently experiencing higher than normal case volume, which may cause delays. Thank you for your patience. Below is a summary of the information you submitted, as well as the number assigned to your case.  Please reference this case number whenever you contact Intel Customer Support about this case.  Best regards, Intel Customer Support Case Number 06579504|"
    ]
  },
  {
    "brand": "intel",
    "generation": "battlemage",
    "tier": "580",
    "matched_keywords": [
      "b580",
      "arc b580"
    ],
    "title": "Is the B580 a sensible modern upgrade from a GTX 1660 Ti?",
    "selftext": "I recently upgraded my wife's midrange PC and was left this PC as a personal rig from some older parts.\n\nHere is the prospective build: https://pcpartpicker.com/list/jCQgb2\nRight now I have everything but the new case and the Arc B580, but the B580 was purchased and is on track to arrive before Christmas.\n\nAt this time, I play mostly on a 1080p monitor today, but curious to see if I can get playable frame rates on my 50\" 4k TV. My dream is to own a 32\" OLED 1440p monitor someday, but not this holiday season lol. Do you think the B580 is worth upgrading the 1660 Ti I currently have in this system? Is the 5600x going to bottleneck this GPU, or do you think it should be a good match given the B580 is still a lower end card?\n\nGiven that I already pulled the trigger on buying a B580 while it was still on stock, I'm really just trying to figure out if I should also be upgrading to AM5 now or in the near future. It's negligibly the same cost to me to meaningfully upgrade my CPU on AM4 as it is to invest in a low tier mobo and R5 7600x w/ RAM. I'm not certain whether either CPU upgrade would even be meaningfully necessary with this card or if the 5600x I've adopted is good enough.\n\nThanks for your help!",
    "comments": [
      "My A750 was a good upgrade from a 1660ti, so yes. It performs just fine with two 1440p monitors and the B580 is benching much better.",
      "It's a good 1080p card, and some games you can run at 1440p as well. 4k is way out of its league though.",
      "Upgraded from a 1660 ti to A750 and have been happy. 1660 has no hardware upscaling so started having issues with 1440p. A750 eats my 1440p games for breakfast. Looking for a B750 next.",
      "if you already have an AM4 mobo i would argue 5700X3D as cpu will be more cost effective\n\nB580 is a good match for your current cpu, should be even better with 5700\n\nB580 should be capable of 4K60 with upscaling on most games so if that works for you thats good, however for 1440p its more than capable",
      "Some TVs will allow you set the resolution (in Windows) to 1440 for example, and also can set 1440 in games as well for better performance vs 4k. The 5600x should be 'good enough' at 1440. Just recommend to update the board BIOS, and enable SAM Smart Access Memory/or Resize Bar, and Above 4G Decoding Memory, and XMP, in the BIOS settings after the update.\n\n\nAlso, may double check Windows is in UEFI mode(if Windows 11 already set). Can check on this in the System Information app in Windows. Under BIOS mode, should list UEFI(non legacy).\n\n\nAnother item, recommend to DDU(display driver uninstaller) the previous GPU, so no software conflicts for performance. There's an option in DDU to 'clean and shut down', just before going with the hardware swap.\n\n\nQuick DDU overview(also lots of video how to's online)\n\n\nhttps://www.intel.com/content/www/us/en/support/articles/000091878/graphics.html",
      "I did the same upgrade and yeah super happy",
      "You don't need a new mobo or CPU. Your 5600X will be just fine for the B580 (and probably even the B770 if it comes out). And yes, it's going to be a solid upgrade from your 1660ti.",
      "GTX1660 -> A750 LE - real upgrade. Also in VR for Quest 2 PCVR via VD.",
      "With upscaling it’s fine tho. The internal resolution doesn’t need to change much at all. 1080p -> 4K is a fine upscaling resolution. The ps5 even runs a lot of games at 720p lol. It does break down a lot more below 1080p tho",
      ">4K should be a breeze as long as you're liberal with XeSS and FSR usage.\n\nWith games starting to list it in their minimum requirements you might have to be very liberal with it.",
      "Yep but u need resizable bar",
      "Why would you not use upscaling for this? It would look 10x better than letting your display handle the upscaling.",
      "Yeah I play 1440p with 1660ti and A750 which both can handle reasonably with some tweaks, so B580 should be more than ok there",
      "Yep I built a second pc with A750 so I can compare 1660ti and that on a daily basis - confirm A750 is a good upgrade over it",
      "I do console emulation up through PS3, and then most of what I play on Steam are turn-based JRPGs. The most graphically intensive games I play would be Nier Automata and Nier Replicant. I want to play Baulders Gate 3 at some point when it gets cheap. I don't always have as much time as my partner to play games due to work, which is why I give her the better parts usually.\n\nThere's like two locations in Persona 3 Reload specifically which have ray tracing enhanced reflections and they look beautiful. My FPS and overall experience in this game was overall great at 1080p Ultra using the 1660 Ti except in these two areas of the game. If this card helps to address issues in more modern games like that in games like that one, and if it allows me to continue streaming over steam link at 60fps over my nice router, or from away on a 1Gb Internet connection, I will be ecstatic.\n\nMy son likes Pajama Sam and Putt-Putt, hoping to get some good performance in those lol.",
      "4K should be a breeze as long as you're liberal with XeSS and FSR usage. Don't shy away from upscaling because even with a high-end GPU, you'll STILL need it to get the framerates you'd ideally want.",
      "Yes",
      "Yes.",
      "How dare you. That graphics card belongs in a museum to be enjoyed by all!",
      "I have the same dilemma right now, I own the same gpu as you and I'm wondering if B580 would fit for my 1440p monitor.\n\nBy the benchmarks I've seen, it looks like a promising upgrade, I might finally take the bite.\n\nBut I am still waiting for the B750/B770 to see the price/performance.\n\nOtherwise, we both can't go wrong with the B580."
    ]
  },
  {
    "brand": "intel",
    "generation": "battlemage",
    "tier": "580",
    "matched_keywords": [
      "a580",
      "b580",
      "arc b580"
    ],
    "title": "Intel Arc B580",
    "selftext": "I’ve owned an Arc A580 and was somewhat disappointed by the performance and drivers. After more and more updates the card was finally a bit more useable. I decided to buy the Arc B580 on release date and replace my A580. I have this rig set up as my living room console. So far I’ve been impressed, it beats the performance of my 4060 and my 7600. Shockingly it’s more stable than my 7600 (maybe another story for that card) when playing Fortnite and The Finals. Yes, there’s some issues still looming around. I play OW2 from time to time and I’m still getting that issue of micro stutters where the fps will dip to 100fps and back to 200fps. Not perfect but I love seeing intel bring some affordable GPUs to the game. ",
    "comments": [
      "This is my favorite b580 edition, very beautiful 😍. I am also going to buy it 🤭",
      "Yeah, I’ve been eyeing the white version of this card since it was announced. Thank god I was able to order it online the day of release from my local Micro Center. Even the guy that was ringing me up said that he already saw 5 get picked up and only had 2 left over. That morning they had 18-20 cards in stock from different brands, sold out",
      "Really excited about getting this when they restock. I was gifted a prebuilt that has an AMD RX 6500xt and its not the best lol. Hopefully this card will be a huge upgrade",
      "cant wait to get my hands on the asrock b580 lol. too bad its out of stock everywhere and newegg doesnt even have it listed on their site anymore.",
      "I made the same decision and i appreciate this fine GPU. I own a Ryzen 7500F and my Acer Nitro B580 runs more stable in RDR 2 than my old RX 7600.",
      "Performance might improve little by little on certain games to fully optimize them. We’ll probably not see crazy types of uplift performance compared to the Alchemist cards but just have more stable performance. \n\nI haven’t done many benchmark tests as I had a short weekend. So far the games I tested are\n\nFortnite\nOverwatch 2\nThe Finals \nMarvel Rivals\n\nOnly game I had issues was Overwatch 2 as it uses DX11. \n\nThe CPU cooler I used is the Cooler Master 622 Halo White.",
      "Looking good system there. Do you see the performance to get better in the future on b 580 or it has peaked (or closed to it) therefore we're not expecting the same improvement we've witnessed they've broke through with the first Arc genb\n\n Btw, what cpu cooler would that be? Might be a good alternative to Deepcool AK62 I'm eye ing for my next build.",
      "Bro is complaining about 100 fps on an intro grade graphics card I prob read it wrong and it's the studdering that's the issue.",
      "What brands are those fans?",
      "How many fps on Fortnite low 1080p dx12 ?",
      "Cooler master halo for the cpu fans and cooler master sickle flow for the case.",
      "about 150-180fps",
      "what do u suggest with overwatch? cant figure out how to fix it and i get eyecancer playing it right now.\nlooks like 640x480.....",
      "Ok b580 or 4060 for competitive gaming ?",
      "I set mine to low but at 1440p without using FSR. It does okay but I do get a few micro stutters. When I put it at High or Ultra frame rate goes from 100 to my screen cap of 165 and then back to 100.",
      "RTX 4060 will not give you any compatibility issues with what you are playing compared to the B580. So far my B580 plays most DX12 esports games flawlessly but going to DX11 i tend to have some minor issues/hiccups with the frame times. If you can wait, try to see what the RTX 5060 has to offer (i know it may lack VRAM) but if you can't wait get the B580. Also depending what CPU you're pairing it with."
    ]
  },
  {
    "brand": "intel",
    "generation": "battlemage",
    "tier": "580",
    "matched_keywords": [
      "b580",
      "arc b580"
    ],
    "title": "Graphical glitches with B580",
    "selftext": "My friend just got a new Intel Arc B580 for his gaming computer and he noticed some weird graphical glitches happening very randomly, and only when things are in full screen. He says the problem happens while playing something, and when alt-tabbing it goes back to normal, only to then happen again when the game goes back to full screen. And then after a few seconds it completely stops. Here's what it looks like:\n\nhttps://preview.redd.it/ezann1fl9oze1.jpg?width=3051&format=pjpg&auto=webp&s=2f801691658819e613ba2d4e4dfb9b9461ef31aa\n\nNormally I would just say that's a dead card but I've learned that with Intel a lot of the times that is not the case. Here are his motherboard and cpu (before you look, he knows there is a huge overhead issue with the new intel cards, he plans on getting a newer cpu in the near future):\n\nMotherboard: Gigabyte H410M H V3  \nCPU: I5 10400\n\nAny suggestions would be appreciated!",
    "comments": [
      "Oof from my history with computer, i think it's related with the GPU memory health. Try to trade for a replacement and see if its any different\n\nbut it could be just a driver error. Idk",
      "Active resizable bar in bios, That fixed my problem.",
      "The same thing happens to me with the A580 exclusively when I go to stream opening obs",
      "this was my first guess as well. Im also wondering if they used DDU on the old drivers. it could be the gpu vram like suggested but until rebar and DDU'd drivers are confirmed I would hesitate to return it until doing those two things",
      "You know now that you mention it did happen for the first time after he started streaming something to me on discord.",
      "I think someone mentioned RAM issues in an older thread.",
      "Damn, this is even mentioned in the Tech Linus Tips video. I'm fed up. I'm a content creator and haven't been able to work on Kick. Objectively, I'm switching to an Nvidia graphics card 😭"
    ]
  },
  {
    "brand": "intel",
    "generation": "battlemage",
    "tier": "580",
    "matched_keywords": [
      "a580",
      "b580"
    ],
    "title": "B580 results in blender benchmarks",
    "selftext": "The results have surfaced in the Blender benchmark database. The results are just below the 7700 XT level and at the 4060 level in CUDA. It's important to consider that the 4060 has 8GB of VRAM and OptiX cannot take memory outside of VRAM.. The video card is also slightly faster than the A580. Perhaps in a future build of Blender the results for the B-series will be better, as was the case with the A-series.\n\nhttps://preview.redd.it/ro23ch1z606e1.png?width=1428&format=png&auto=webp&s=299898992f8b13ac31e17c3c2dc8650c20d6047f\n\nhttps://preview.redd.it/ex8y5ncz606e1.png?width=1433&format=png&auto=webp&s=e04573cdb5dd25f36b0ca60707e03fbdcc4122d8",
    "comments": [
      "What does this imply for real world performance? Like what does Blender test?",
      "How are y'all benchmarking since the official drivers will not release until the 13th?",
      "Work tasks related to 3D rendering. I wouldn't compare it to games. Moreover, Blender uses the Intel OneAPI, meaning everything here is quite optimized",
      "From what I understand, benchmarks like this come from reviewers who received advance cards and drivers, but didn't shut off their internet connections before benchmarking. \n\n Hopefully they don't get in trouble for violating the embargo date.",
      "Games have little to do with professional rendering, that's the freaking point.",
      "I saw a leaked vulkan score, looks to be very close to 3060ti/6700XT which would make it an excellent card.",
      "My thoughts as well. What drivers are they using?",
      "Not really. 3D scenes used for Blender benchmark are Monster, Junkshop and Classroom, none of the scenes require more than 4gb of Vram at most. The benefit to 4060’d be a gddr6x vram, which is faster than regular gddr6. But still, the difference wouldn’t be that big, since 4060’s chip is very slow anyway, especially for its price",
      "How does this compare to the A770 I see that has more benchmarks done here 4 Vs 8",
      "Relatively, depending on what your requirements are. We are unlikely to see Intel in Redshift/Octane. But the B770 with 16-18 GB in the same Blender for its price may be a good solution. Also in AE compositing, transcoding, etc. I would still wait for real tests. Even Blender does not behave exactly the same as in benchmarks, if you tried to compare video cards in rendering and benchmarking.",
      "Appreciated.\n\nI don't know anything about Blender, but I'm surprised how the 4060 is smoking everyone else (at least using Optix... why not in CUDA ? Isn't it the implementation of choice for an nVidia card ?).",
      "Unbiased non real time ray tracing speed if using Cycles, biased if using Eevee.",
      "Linux drivers ?",
      "Roughly speaking, these are the same thing, the only difference is that OptiX uses RT cores and is limited by VRAM memory. These are both computing platforms from Nvidia. CUDA as a computing platform is most often used when there is not enough VRAM during rendering. Previously, OptiX was less common, but as RT cores appeared, its rendering speed increased significantly and it became more widespread. And if for gamers ray tracing is a dubious matter, then for content creators it is meta.",
      "How do",
      "That's good to know",
      "I see ! Thank you for this clear explanation.\n\nThus I gather that if the 4060 had 12Gb memory like the B580, it'd score even higher.",
      "The problem with Blender benchmark is that its not that accurate. For example, even on a 4080 card the viewport is quite noisy and laggish, on 4060 its just slideshow. Radeon gpus are not better much, but the gap is nowhere near what those benchmarks and tech blogers trying to imply. In the end, radeon, and intel arc cards will render slower than rtx one, but not so much slower. And the viewport performance is roughly the same between them. And talking about nvidia optix denoiser, its bad literally for anything except static renders. Intel’s OpenImage denoiser saves a lot more details than Optix.",
      "Are they going to release a b770? I'm looking for 4070 ti super speeds.",
      "As more and more of these come out, I can’t help but feel a bit disappointed. \n\nI’m still really excited to see official benchmarks and reviews from YouTubers and reviewers"
    ]
  },
  {
    "brand": "intel",
    "generation": "battlemage",
    "tier": "580",
    "matched_keywords": [
      "a580",
      "b580",
      "arc b580"
    ],
    "title": "Extremely Unscientific Arc B580 Production Volume / Sales Figures Estimate",
    "selftext": "Hey everyone! \n\nEveryone in this subreddit is familiar with the poor availability of the B580. I've been wondering if this was due to low supply or high demand. Since we won't know the exact sales figures for Arc, we'll have to turn to some extremely unscientific methodology. We know for a fact that the RTX 4060 far outsells the B580 (it's the number 1 GPU on the Steam Hardware Survey), so a far more interesting comparison is against the **AMD Radeon RX 7600 XT.**\n\n**Extremely Unscientific Methodology**: Counting number of Newegg reviews per AIB model. I'm basically treating the number of reviews as a rough proxy for the number of GPUs sold, assuming a similar rate of review writing between AIB models. I'm also using the \"Verified Owners\" filter to limit the number of reviews to those who have actually purchased the card. \n\nThis analysis also focuses on the American GPU market. \n\n# Intel Arc B580\n\nAccording to [TechPowerUp](https://www.techpowerup.com/gpu-specs/arc-b580.c4244), these are the AIB models of the B580:\n\n1. [Acer Nitro Arc B580](https://www.newegg.com/acer-nitro-an-b580-oca-intel-12gb-gddr6/p/N82E16814553012) \\- 4/5, 3 reviews\n2. [ASRock Arc B580 Challenger OC](https://www.newegg.com/asrock-challenger-a580-cl-8go-intel-arc-a580-8gb-gddr6/p/N82E16814930131) \\- 4.7/5, 4 Reviews\n3. [ASRock Arc B580 Steel Legend OC](https://www.newegg.com/asrock-challenger-b580-cl-12go-intel-arc-b580-12gb-gddr6/p/N82E16814930132) \\- 4.8/5, 12 Reviews\n4. [GUNNIR Arc B580 Index](https://www.newegg.com/gunnir-b580-index-12g-intel-b580-12gb-gddr6/p/3GM-0001-00007) \\- seems to be a mostly Chinese AIB, I've only seem scalper prices on Newegg. 5/5, 1 Review. \n5. GUNNIR Arc B580 Photon OC - ditto.\n6. GUNNIR Arc B580 Photon OC W - also seems to be a scalper listing.\n7. [MAXSUN Arc B580 iCraft](https://www.newegg.com/maxsun-icraft-intel-arc-b580-12gb-gddr6/p/3GM-0003-00001) \\- 0 reviews, only 3rd party sellers, ships from China.\n8. MAXSUN Arc B580 Milestone - ditto. \n9. [ONIX Lumi Arc B580 OC](https://www.newegg.com/onix-odyssey-8346-00178-intel-arc-b580-12gb-gddr6/p/N82E16814987002) \\- 4.7/5, 28 Reviews\n10. [ONIX Odyssey Arc B580 OC](https://www.newegg.com/odyssey-arc-b580-12gb-gddr6/p/N82E16814987001) \\- 4.9/5, 14 Reviews\n11. SPARKLE Arc B580 GUARDIAN - release is scheduled for \"[Mid-March](https://www.fudzilla.com/news/graphics/60557-sparkle-launches-new-arc-b580-guardian-graphics-card)\" apparently, no Newegg page.\n12. [SPARKLE Arc B580 TITAN OC](https://www.newegg.com/sparkle-intel-arc-b580-titan-oc-12gb-gddr6/p/N82E16814993013) \\- 4.8/5, 28 Reviews\n13. SPARKLE Arc B580 TITAN Luna OC - seems to be a white version of the Titan OC, doesn't seem to be sold in the US, no Newegg page. \n14. [Intel Arc B580 Limited Edition](https://www.newegg.com/p/N82E16814883006) \\- 4.7/5, 41 Reviews\n\nTotal review count: 131\n\n# AMD Radeon RX 7600 XT\n\nAccording to [TechPowerUp](https://www.techpowerup.com/gpu-specs/arc-b580.c4244), these are the AIB models of the RX 7600 XT: - \n\n1. [ASRock RX 7600 XT Steel Legend OC](https://www.newegg.com/asrock-steel-legend-rx7600xt-sl-16go-amd-radeon-rx-7600-xt-16gb-gddr6/p/N82E16814930120) and Challenger OC - 4.8/5, 33 Reviews, these two cards seem to have a combined Newegg page. \n2. [ASUS DUAL RX 7600 XT OC](https://www.newegg.com/asus-radeon-rx-7600-xt-dual-rx7600xt-o16g/p/N82E16814126700) \\- 5/5, 5 Reviews\n3. [ASUS TUF RX 7600 XT GAMING OC](https://www.newegg.com/asus-tuf-gaming-video-card-tuf-rx7600xt-o16g-gaming-amd-radeon-rx-7600-xt-16gb-gddr6/p/N82E16814126699R) \\- seems to have no reviews? \n4. [GIGABYTE RX 7600 XT GAMING OC](https://www.newegg.com/gigabyte-gv-r76xtgaming-oc-16gd-amd-radeon-rx-7600-xt-16gb-gddr6/p/N82E16814932687) \\- 4.2/5, 26 Reviews\n5. [PowerColor Fighter RX 7600 XT](https://www.newegg.com/powercolor-radeon-rx-7600-xt-rx7600xt-16g-f/p/N82E16814131862?Item=N82E16814131862) \\- 5/5, 3 Reviews\n6. [PowerColor Hellhound RX 7600 XT](https://www.newegg.com/powercolor-radeon-rx-7600-xt-rx7600xt-16g-l-oc/p/N82E16814131861) \\- 5/5, 3 Reviews\n7. [Sapphire PULSE RX 7600 XT](https://www.newegg.com/sapphire-pulse-11339-04-20g-amd-radeon-rx-7600-xt-16gb-gddr6/p/N82E16814202440) \\- 4.7/5, 7 Reviews\n8. [XFX Speedster QICK309 RX 7600 XT](https://www.newegg.com/global/ae-en/product/14-150-888?item=14-150-888) \\- 4.4/5, 6 Reviews\n9. [XFX Speedster SWFT210 RX 7600 XT](https://www.newegg.com/xfx-speedster-rx-76tswftfp-amd-radeon-rx-7600-xt-16gb-gddr6/p/N82E16814150889) \\- 4.4/5, 7 Reviews\n\nTotal review count: 90\n\n# Anecdotal Datapoints\n\n1. Central Computers, a small chain with only 5 locations in the San Francisco Bay Area, [received over 100 B570 cards](https://www.reddit.com/r/IntelArc/comments/1itjpp9/psa_central_computers_bay_area_ca_has_tons_and/) during a just a single restock. It's worth noting that it's certainly possible Intel allocated disproportionately more supply to them, as Intel is headquartered in Santa Clara and CC has been a pillar of Silicon Valley for decades. \n\n2. Hardware Unboxed said that the initial supply was \"[quite substantial. They were \"blown away\" by demand for the Arc B580 – even the pre-orders were exceptionally high](https://youtu.be/fJVHUOCPT60?t=1199).\"\n\n# Important Caveats\n\nObviously this methodology is not very scientific at all LOL\n\n1. It doesn't take into account all retailers (maybe the RX 7600 XT sells more on Amazon vs Newegg, or through brick and mortar)\n\n2. It assumes that users of both GPUs leave reviews at the same rate, which is probably not true as it's quite possible Arc users are more likely to leave reviews since they're more likely to want to support an end to the AMD/Nvidia duopoly. \n\n3. However, it is worth noting that it's not like the B580's reviews are inflated by people review bombing due to driver issues, the LE's review average is sitting at 4.7/5, compared with 4.2/5 for the highest volume RX 7600 XT model, the Gigabyte Windforce Gaming OC.\n\n4. But it's also worth noting that the B580 has been on the market for a much, much shorter period of time, as the 7600 XT was released all the way back in January 2024 compared to December 2024 for the B580. This extra year of sales will tilt the numbers in favor of the RX 7600 XT. \n\nI don't think the data points towards the B580 being a \"paper launch,\" but I also don't think Intel is pumping out millions upon millions of B580s. They're definitely in third place in volume compared to the RX 7600 XT and the RTX 4060, but they're not as far as you might think; demand just seems to be super high. \n\nIf I have time, I might look at some other retailers (B&H maybe) or another card like the RX 7600 or the B570.\n\n**Once again, please don't take this too seriously LOL**",
    "comments": [
      "Yeah for some reason it's just super super bad in the US",
      "People who screamed paper launch should take a look at Nvidia 50 series, especially 5090. A halo product is already expected to have low supply but somehow it's even worse, even with way more AIB partners than Intel did.",
      "Pretty much the US gpu market is cooked because I’ve read numerous posts where people living abroad don’t have trouble finding the B580 close to msrp with lots of inventory. Im pretty sure no one is touching the 4060 because it has 8gb of vram, if it had 10gb like the B570, it too would be struggling to stay on the shelf because the 7600 (non xt) is also an 8gb card and is readily available",
      "I can easily find b580s MSRP plus tax on Turkey. Maybe they focused on countries where they have more chance but still b580 sparkle titan was cheaper than normal version.",
      "Just got a \" used \" b580 for 260€ ( open Box ) from Caseking in Germany with 24 months warranty im pretty Happy",
      "I checked Shopee Taiwan and searched for the RTX 4060. Looking at different sellers' sales numbers, the highest was 379 units, followed by 209, and the third was around 79. Roughly estimating the total sales from all sellers with visible numbers, it adds up to around 1,500 units.\n\nThen, I searched for the B580. There were four sellers with visible sales numbers: the highest sold 95 units, followed by 52, then 25, and 18. In total, that's 193 units.\n\nConsidering that the RTX 4060 has been on the market for almost two years, I think the B580's sales numbers are quite impressive. If we extend the timeline to two years, it could potentially surpass 700 units or even more. Especially if future driver updates bring a 5-10% performance improvement, this price-to-performance ratio could make the B580 a big seller.\n\nThe RTX 4060 is the best-selling model from NVIDIA and the entire GPU market, making this comparison even more interesting.\n\nI also searched for the A770 and only found a few listings from different sellers, but the sales numbers were all zero. Then, I searched for the A580, but the results mostly showed listings for the B580 instead.",
      "I can get B580 for 300€ (250€ MSRP +22%VAT) today if i want to. Also other models are also in stock in several eu countries.",
      "Well the prices for NGREDIA and AMD  in most of the european countries are bad as hell, saphire pure 9070xt is 850€ and saphire pulse wich is supposed to be a MSRP model is even worse and is around 950€, also cheapest 5070ti is 1300 in stock and cheapest 5070 is 1100 and in stock.\n\nEdit: it could also be that people are unwilling to try intel because its new in GPU market. Even thoug i myself am considering it for my build, since i am building a highend pc but can wait a year or two on GPU, because i am not upgrading to a 4k monitor for next two years.",
      "i checked rn and there's tons of prebuilds (1 retailer has 13 different prebuild with b580 other one has 19 and this is just 2 retailers ) and retailers still have many b580 i dont know why there's none at us market.\nFor proof (there is so many more i put just 2 retailers)\nPreebuilds\n\nhttps://www.incehesap.com/gaming-hazir-sistemler-fiyatlari/ozellik-95818/\n\nhttps://www.itopya.com/HazirSistemler?gpumodel=intel-arc-b580-q7598\n\nOnly gpu \n\nhttps://www.incehesap.com/intel-arc-b580-12gb-gddr6-192bit-ekran-karti-fiyati-76606/\n\nhttps://www.itopya.com/intel-arc-b580-12gb-gddr6-192bit-limited-edition-ekran-karti_u27591\n\nhttps://www.incehesap.com/sparkle-intel-arc-b580-titan-12gb-gddr6-192bit-ekran-karti-fiyati-76874/?srsltid=AfmBOoomMi_5NMORH1gY9jio3hvXt2Jg1cX6j-9IpeqTXA-c7mErX1_Z\n\nhttps://www.sinerji.gen.tr/asrock-intel-arc-b580-challenger-oc-12gb-gddr6-192-bit-ekran-karti-p-54280",
      "That's the fascinating part too, like you read all these posts from Europeans etc. saying how there's plenty of supply... meanwhile in the US there's literally not a single listing that has stock that's not from scalpers or resellers.",
      "Yeah, I'm really not sure whether that's due to higher supply outside the US or lower demand.",
      "Link?",
      "Interesting, thanks for the research! Looks about right. How were the RX 7600 and 7600 XT sales? Intel obviously has no chance to overtake Nvidia in the GPU market, but they could get closer to AMD."
    ]
  },
  {
    "brand": "intel",
    "generation": "battlemage",
    "tier": "580",
    "matched_keywords": [
      "b580",
      "arc b580"
    ],
    "title": "Intel Arc B580 Xe2 HPG (Battlemage) launch imminent?",
    "selftext": "",
    "comments": [
      "As mentioned on the Tom's Hardware comments section, the winner of more competition is the consumer.",
      "Shhhh baby, it'll happen when it happens.",
      "Pretty much the main reason intel needs to get their shit together, unless we want AMD to also start jacking prices up eventually for both their GPUs and CPUs.",
      "On the CPU side they're kind of already there. For some reason they refuse to launch the 7500f in the US so the cheapest AM5 option for a while was the 7600, now it's the awful 8400f. It doesn't take a lot for these companies to get complacent.",
      "This is the same screenshot that was linked to a Twitter post by [Tomasz Gawroński](https://x.com/GawroskiT) \\- I have not heard of him until now.  I'm engaging with him on X.  I'm finding more and more people that are outside the US, who are supporting Arc.  The numbers are growing every day, we will see...\n\nIt is not easy as X has become a paywall nightmare with more and more features not being free.",
      "I really wish they had a trade in program for the folks who invested in their first gen.",
      "From what they told us before, Battlemage shouldn't get murdered by nanite and Unreal 5 as a whole, lets wait how that pans out",
      "I’m very much looking forward to what they have to offer in this next gen. I’m building a budget living room pc so my fiancé and I can play pc games together (aiming for MHWilds) and really considering getting an arc to replace my 3070. The living room pc will have the 3070 if the battlemage performance is good enough.",
      "Looking into technical write ups on it, nanite relies on indirect draws and of course Execute Indirect. More and more it's clear that emulating the function was a bad call. They've addressed this in battlemage but no driver update seems like it will fix the alchemist.\n\nhttps://www.trickybits.blog/2024/04/20/nanite.html",
      "> It is not easy as X has become a paywall nightmare with more and more features not being free.\n\nPeople are switching to BlueSky en masse!",
      "My 3070 will be passthrough and prime for Nv only games. Going dual GPU.",
      "I hope so",
      "Performance at RTX 4060 (with 4GB extra VRAM) at a580 price?",
      "[Every GPU is getting murdered by nanite. ](https://youtu.be/M00DGjAP-mU?si=aHh_UuZRSV5y4Dn7)\n\n[Silent Hill 2](https://youtu.be/07UFu-OX1yI?t=129) (some people are seeing massive gains, like 4080 owners)",
      "Really high geometry count (tessellation)",
      "Intel is only doing discrete to create a brand and to get experience on drivers that actually run games. Until they have money again they aren't going to make anything above a x060, maybe x060ti."
    ]
  },
  {
    "brand": "intel",
    "generation": "battlemage",
    "tier": "580",
    "matched_keywords": [
      "a580",
      "b580",
      "arc b580"
    ],
    "title": "Retailers accidentally ship Arc B580 early, mistaking It for A580",
    "selftext": "",
    "comments": [
      "Well there you go, congrats to those who got their B580 GPUs early.",
      "Source: Reddit, VideoCardz\n\n👍",
      "C.  Following the English alphabet.",
      "First gen was Arc (Axxx), now Battlemage (Bxxx), then Celestial (Cxxx). I've seen \"Druid\" thrown around for the 4th gen name but who knows.",
      "celestial is coming out next year around dec too?",
      "I see. I only saw Druid mentioned in the article, and they skipped Celestial so why I was asking. Make sense.\n\nThanks for sharing that!",
      "IDK. 12 months seems quite quick to me, 18ish is more normal.",
      "So what's the naming scheme for the first letter in the model?\n\nWhat's the next one after 'B'?"
    ]
  },
  {
    "brand": "intel",
    "generation": "battlemage",
    "tier": "580",
    "matched_keywords": [
      "a580",
      "b580"
    ],
    "title": "B580 as a replacement for a 1070 ti for 1440p gaming and video editing - worth upgrading?",
    "selftext": "So, my PC has a old 1070 ti in there. At least since I upgraded my monitors to 1440p ones, the card struggles to deliver stable 60 FPS in some games on medium or low settings - on one game even with FSR 3.0 (but that game is not really optimized).  \nI don't play the most demanding games out there and I don't need the highest graphic settings and prefer a smooth frame rate over the highest graphic settings.\n\nI have a i7-8700k plus DDR4-RAM of 16 GB, all of that runs with a 550 W power supply. Would the upgrade fry my PSU (honestly, I've been planning to upgrade that grandma of a PC for a while now for various reasons)  \nWould a B580 be an upgrade in terms of FPS? One more thing that is important for me is Video. I know it can encode and decode AV1 which is awesome, but how good were the Intel Arc video encoders on the A series? Like AMD in earlier days (way behind Nvidia) or is it roughly on par? I know, even upgrading to A580 would probably be a big upgrade, as the 1070 ti does produce a really blocky video on lower bitrates.  \nWere the A series compatible with DaVinci Resolve editing? With my 1070 ti, I tend to have some stuttering when playing back video (hardware accelerated decoding is turned on).  \nOr would it be a better idea to just scrap the entire PC, upgrade to DDR5, a somewhat current CPU and a PSU that has headroom for upgrades in the future?\n\nAlso, one or two more of off-topic questions to the Arc card owners: Does YouTube display AV1 videos automatically (for me, it doesn't, I checked some videos with yt-dlp, it makes sense, as my old GPU can't decode AV1)? YT tends to save a bit on bitrate on 1080p and as we all know, AV1 performs really well, even at relatively low bitrates. I saw someone testing the Arc A series cards with 500 kbit/s von 1440p60 and it did look really watchable (sure, there were a lot of artefacts, but holy lord, for that low bitrate at high resolution it looked amazing and AVC, VP9 and HEVC would've probably failed miserably).",
    "comments": [
      "Probably not. 8x is a lot more than you might realize. Only when you go as low as 3.0 x4 that you'll start seeing noticeable performance hit due to bandwidth limitation. For example, my motherboard's 3.0 x16 slot started malfunctioning a few weeks ago, and now I have to use the x4 slot. Certain games like Honkai Impact 3 seem to be very sensitive to that as frame time spikes increase tenfold, while others like Star Rail are just very slightly affected, with hardly noticeable spikes.",
      "First, check if you can enable ReBAR on your motherboard, since it's a must for all Intel dGPUs. Pre-Alder Lake motherboards may not work very well with ReBAR so take that in mind (for example my B460 Aorus Pro AC keeps resetting its CSM setting every once in a while and disables ReBAR during the process because ReBAR cannot work with CSM on).",
      "If the motherboard is only PCIE 3.0 will the 8x lanes on the B580 be affected in a large way?",
      "550W is well enough for A770 and B580, unless havin some i9 to pair it.",
      "From what I can find the B580 is about 5% better than the 1070Ti. I'm sceptical about my own findings though and I hope I'm wrong, because I'm also looking for an upgrade for my 7 year old card without spending a fortune",
      "If you can enable ReBAR on your motherboard then it's worth a try using your 8700k with the B580. The CPU will likely bottleneck but it's worth a try if you're on a budget.\n\nThe Arc cards do work with Resolve and the B580 seems to be an excellent budget choice. However i think your CPU will limit you. It sounds like you should do a new build! A lot depends on your budget though.",
      "I did a little more research and you're correct, impact is negligible :)"
    ]
  },
  {
    "brand": "intel",
    "generation": "battlemage",
    "tier": "580",
    "matched_keywords": [
      "b580",
      "arc b580"
    ],
    "title": "i5 12400F & ARC B580 - A Decent Budget Gaming Combo? - 1080p and 1440p Tested",
    "selftext": "",
    "comments": [
      "Many people will probably be running this combo so it is good to know. Very underwhelming performance with the 12400f. I have an arc a580 with that cpu and the improvement I saw from those benchmarks does not seem too big of a jump so far."
    ]
  },
  {
    "brand": "intel",
    "generation": "battlemage",
    "tier": "580",
    "matched_keywords": [
      "b580",
      "arc b580"
    ],
    "title": "Hey did anyone benchmark the intel arc b580 for rendering in blender maybe? Because I cant find any data on it.",
    "selftext": "",
    "comments": [
      "https://opendata.blender.org/benchmarks/query/?blender_version=4.3.0&group_by=device_name \n\nB580 scores - 1805.36\n\nA770 scores - 2145.39\n\nA750 scores - 2175.69\n\nA580 scores - 1695.75\n\nFor reference a nvidia 3060 scores - 2132.1",
      "Thx!"
    ]
  },
  {
    "brand": "intel",
    "generation": "battlemage",
    "tier": "580",
    "matched_keywords": [
      "b580"
    ],
    "title": "Is b580 a good choice for Editing and Blender?",
    "selftext": "I might buy this for my editing and blender work!",
    "comments": [
      "Battle mage currently has issues in blende so can't tell yet as the scores are terribly low even compared to a series. But it's likely the 4060 will be better in blender since generally optix crushes everything else, though I hope I'm proven wrong."
    ]
  },
  {
    "brand": "intel",
    "generation": "battlemage",
    "tier": "580",
    "matched_keywords": [
      "a580",
      "b580"
    ],
    "title": "Are people being too optimistic about the B770?",
    "selftext": "This is going to be a controversial topic but I am seeing alot of people saying they are going to wait for the B770. \n\nThe B580 is phenomenal for its price, and they are expecting or hoping for the same with the B770. \n\nHowever there are a few things that all tie together which I think everyone should be taking into consideration, with the first being the performance difference between the A580 and the A770.\n\nTechnical City has the A770 at an average of 11.4% faster than the A580. \nhttps://technical.city/en/video/Arc-A770-vs-Arc-A580\nAssuming a +/- 2.5% similar difference in performance between the B580 and B770 would put the B770 at 19-24% faster than the 4060.\n\nThe next thing is the MSRP price increase of the B580 over the A580.\n\nThe A580 debuted with an MSRP of $189 while the B580 has debuted at $249. This is an increase of ~32%\n\nThe A770 retailed with an MSRP of $349, applying the same percentage of price increase for the B770 would put it at ~$459 for an estimated MSRP.\n\nAlso Tom Peterson who is from Intel and heavily involved in their GPUs, has stated in an interview that Intel is losing money pricing the B580 as aggressively as they are, which I think means we can't expect the B770 to be priced any more aggressively in comparison when it's launched.\n\nThen there is timing. Nvidia and AMD will be releasing their next gen cards soon, and the generational uplift for Nvidia's 60 class of cards over the last 3 generations ranges from 15-40% and averages out at 25%, this means is very reasonable to expect the 5060 to be 15-20% faster than the 4060, with AMD's entry level card somewhere in the vicinity and likely with more VRAM.\n\nKeep in mind this is just speculation but all in all I think by the time the B770 is released it won't be nearly as competitive with AMD and Nvidia's similarly priced cards in the way the B580 is.",
    "comments": [
      "I mean, until we actually get to see the b770 in specs and price, we dont really know if its going to be good or not.\n\nAnd considering that the b580 is already out of stock in many places (fuck scalpers), waiting is pretty much the only option left, especially for those of us not in the US.",
      "If the 5060 has 8gb of vram like we saw on some leaks then its pretty much dead on arrival from anyone who actually has any braincells.\n\nAnd you can almost guarantee that its going to be more expensive than the 4060 at launch, simply due to the fact that Nvidia really has no reason to give a fuck anymore, considering how much money they make from datacenters already.\n\nIntels biggest competitor is going to be AMD, depending on their entry level new Radeon cards, which could be very competitive.\n\nI still have high hopes for intel, not the company itself, just their GPU department.",
      "If you are waiting for a B700 series card I would also argue you should be waiting to see what Nvidia does with the 5070 as well as AMD alternatives.\n\nI am quietly optimistic that the reason Intel didn't announce the 700 cards is because they have confidence they may be competitive.\n\nIn all honesty though I don't think we should be naive in that the reason Intel announced and released the 500 cards prior to Nvidia and AMD is probably because they only have a short period to be relevant.\n\nAs much as I hate to say it if the Nvidia 5060 releases and is just as good as the B580, then consumers will go with the stronger support of Nvidia. The main hope Intel has is that Nvidia remain arrogant on their brand power and keep or even try to increase prices.\n\nWith all that said I believe people where expecting Nvidia to release the 5060 mid way through next year, so Intel may have some time to make this work for the B500 and hopefully B700 cards.",
      "I think architectural deficiencies in alchemist resulted in the card not scaling as anticipated with additional core count. It is hard to imagine that would not have been an area of focus for improving the architecture in this generation. Perhaps the performance delta between the B580 and B570 may give some clues as to that, although there are probably diminishing returns at the higher core counts. If a b770 is released (assuming Intel doesn't try to rush out Celestial), I can't imagine it scaling as badly as alchemist, but whether it reaches targets remains to be seen.",
      "It will probably be priced out of being a good deal outside the us. between higher sales taxes and companies charging higher prices. If it's more than 300€ you will just get an amd card or a 4060",
      "Intel promised and the B580 delivered. \n\nNow that's a good start.\n\nThere is nothing wrong with being optimistic.",
      "Atm with initial drivers the B580 is almost on par with 4060ti 16gb, if the B770 is another 20-25% over that im gucci for sure.",
      "I bet the 5060 will have 8gb ram and cost $350 and people will still lap it up",
      "\\>If the 5060 has 8gb of vram like we saw on some leaks then its pretty much dead on arrival from anyone who actually has any braincells.\n\nExactly my sentiment. It was originally the card that I planned to upgrade to from my 1060, but I've lost hope ever since Nvidia did the 4060 dirty (by making it a 4050 in disguise). Now the 5060 with 128bit and 8GB VRAM further ensured that I won't be buying any low end Nvidia card. 2025 is around the corner and 8GB has no place for $250-300 price range.",
      "No, if you compare the chip sizes you'll understand why. B580 is outclassing A770 with a smaller chip.",
      "Honestly, my guesses are evenly split between \"B770 in 3Q 2025\" and \"they won't release the B770 and will just move straight to Celestial 1st or 2nd Q 2026.\"",
      "if peeps will buy 4060 over rx6700xt then they will buy 5060 over b770 even if its better lol, peeps just follow brands even in the pc market",
      "For sure, like I said this is just speculation based off the data currently available and assuming similar trends. One thing I forgot to mention was they also cut down the B580 compared to the A580. If they decide not to do that with the B770 there might be a larger performance difference between the B770 and B580 then there was with the A770 and A580.",
      "Considering we should be expecting a jump from 20 Xe cores to 32 cores, this is quite the leap. The card should solidly be a 1440p card that I assume would have 16GB of GDDR6. Since we saw a pattern of higher res equals more performance deltas on the B580, I’d be optimistic about it doing well in a 1440p/4K shootout. \n\nOn the otherhand, Tom Petterson straight up said Xe 3 was finalized on the hardware level at this point, so they may just skip to that.",
      "https://www.techpowerup.com/gpu-specs/arc-a580.c3928\n\na770 is 23% faster than A580. It is a 1/3 bigger card, and the scale seems about right.\n\nA B770 would be a slightly slower 7700XT with 16GB VRAM and better RT. I am willing to pay 400 for it over the 7700XT. But of course, AMD and Nvidia is launching next gen, so my decision is withheld until then. I'd have to compare price of that generation. See my math below.",
      "I don't think that there will be a B770, regardless I will wait for Celestial. I am impressed by the generational uplifts and Celestial should be a cracker series!",
      "Theres hardly a point for it to be faster because of the 8gb vram was holding back the 4060 so imagine what it will do to the 5060 if its 15% faster",
      "Made a mistake. It's not 15 -40% over the last 3 generations, actually is 15-20% with an average of 18%\n\nIt is still reasonable to expect the 5060 to be 15-20% faster than the 4060.",
      "I genuinely like intel GPUs,  unlike CPUs, for its relatively fine specs for a good price. I bought my a770 (16 gb version) for around $300 and i like it. For the same price i could take 4060, but 8 gb vram, meh, not enough these days even for 1080p, especially doing some llm stuff.\n\nI think Intel's main goal is to fight for low end/ mid range gpu market and they are doing pretty well, considering it's only 2nd gen being released.",
      "The 5070 will not be in the same price bracket as the B770. The B770 will probably be $399 to $450. The 5070 will probably be priced like the 4070 at best. ($599)"
    ]
  },
  {
    "brand": "intel",
    "generation": "battlemage",
    "tier": "580",
    "matched_keywords": [
      "b580"
    ],
    "title": "How is life without DLSS?",
    "selftext": "I have a fairly old 2060 and I've been looking to upgrade for probably over a year now. I skipped the 40 series cus it was $$$ and the 50 series isn't looking much better. \n\nThe AMD 9070 looks good, but it's still double the price of a B580 and quite power hungry. \n\nThe thing I like about my 2060 is DLSS. The new transformer mode is insanely sharp. I can run CP2077 at high, with balanced dlss, 1440p at 50-60fps (no RT). Looks great, runs smooth.\n\nI know Intel has XeSS, and it looks pretty nifty. But how many games actually support it? How are you finding life with your Intel Arc? Do you miss DLSS? Or is it barely an issue?",
    "comments": [
      "FSR works well and is pretty widely supported. I've never used DLSS so I can't say I miss it, but the alternatives seem just as good from what I've seen. XESS is great when it is implemented. It remains fairly rare though.",
      "DLSS is great but I refuse to pay the Nvidia tax for it. XeSS is not in a ton of games, though it is in MH Wilds which is pretty cool. But thankfully you can use FSR on any GPU.\n\nGetting a great graphics card for $250 is more magical than DLSS will ever be.",
      "I have a b580 and a 4090 (in different machines in my home, b580 is in my kids machine) - the b580 at 1080p and 1440p is pretty brilliant.  But I also can say that DLSS is unmatched and if you like it, you should probably go for a 4-series Nvidia card.",
      "I guess it depends on the older game. As for examples…I’ve played Heroes III (1999), Skyrim, and Witcher 2 (2011) with no issues on the battlemage architecture. \n\nXeSS also looks as good as DLSS IMO, it’s just not in as many games as DLSS of course.\n\nEdit: Since you mentioned DLSS in Cyber….XeSS looks reallly good in Witcher 3 and Cyberpunk. I have the Claw 8 handheld with battlemage graphics and a 4090 desktop PC. I wouldn’t be afraid of buying a B580 after using the Claw 8.",
      "If you do get one, be sure to utilize the sharpening feature in the main intel graphics settings if there’s no slider for that specific game. You can set specific profiles for each game too. \n\nIt can help make XeSS pop and clean up a lot of blur if you have to use FSR. Made Witcher 3 look amazing with XeSS and helped RDR2 look much better when FSR Quality is on.",
      "90-95% of new AAA games are released with XeSS support I believe (either out of the box, or added later). Steam's XeSS enabled game list is relatively long\n\n\nhttps://steamdb.info/tech/SDK/Intel_XeSS/",
      "A 3070 or 3080 are still quite good ya know. If you look the right place they aren't scalped as hard",
      "Only 4060/4060Ti 8GB cards available here in NZ. Kinda lame.",
      "50 series dropping support for 32 bit Physx means you can't even play all your old games anymore on current Nvidia hardware. 50 series is a disgrace. Nvidia is dropping the ball for gamers, but they really don't care about that market anymore.\n\nFSR4 is sadly now AMD only. Hopefully the community can continue to build on FSR3.",
      "Certainly an option. I just wish they had more than 8GB.",
      "At some point gamers need to hold game companies feet to the fire and refuse to buy poorly-optimized games. Upscaling shouldn't be required on a new GPU to play a new game at a pleasant framerate and resolution, it should be sometime to fall back on 3-4 years down the road to extend the life of the GPU. FSR 3.1 is fine for that.\n\nUnfortunately looking at how well MH Wilds sold despite having months of evidence that it was diabolical levels of poorly-optimized, that point isn't coming any time soon. Gamers will buy anything and pay any price for it.",
      "I have the B580 and haven't had any issues. I've only gone as far back as 2010~ but haven't had any issues specific to older titles. There's a YouTube video where someone tested their whole library on an alchemist card and something like 95% worked near flawlessly.",
      "Thanks, that gives me a bit more confidence.",
      "Yeah. I've experimented a bit, and XeSS looks really good.  About the same as DLSS.  I wish it was in more games.",
      "https://steamdb.info/tech/SDK/NVIDIA_DLSS/\n\nhttps://steamdb.info/tech/SDK/Intel_XeSS/\n\nhttps://steamdb.info/tech/SDK/AMD_FidelityFX/\n\nXess little more than fsr but dlss is far ahead  for availability",
      "Intel all the way.. I’m rocking with a770 but can’t find a580",
      "If your game only has DLSS or FSR, just use optiscaler to enable XeSS.\n\nhttps://github.com/cdozdil/OptiScaler",
      "XeSS is implemented in more games than FSR",
      "Dang.  That’s a shame.  How is the AMD card availability?  Can you get a 7800xt or something like that?",
      "What games can you not play without physx?"
    ]
  },
  {
    "brand": "intel",
    "generation": "battlemage",
    "tier": "580",
    "matched_keywords": [
      "a580",
      "b580"
    ],
    "title": "My sparkle A580 does this every damn time. Often even refuses to post in my system ",
    "selftext": "I already replaced the motherboard (now an ASRock X870 Pro RS) because I was experiencing similar issues with my A770 on the old B650 Tomahawk. That issue is completely fixed now, but my A580 is still having the same problem, crashing the system after a few seconds in windows, after restarting no video but pc posts. Strangely, it worked once right after I installed the new motherboard, so I thought the issue was resolved. However, I wanted to create an A580 vs. B580 comparison video, but that’s clearly not happening anytime soon.\n\nFor context, I used to run everything on a B450 Strix, and the A580 worked fine there. A full Windows reinstall didn’t help, running DDU didn’t fix anything, and resetting the CMOS didn’t resolve it either. What makes this even more frustrating is that this is my second Sparkle A580. The first one caused similar system crashes, but only while running games. To make things more confusing, all other Arc cards and even Nvidia cards work perfectly fine in this system.",
    "comments": [
      "You swapped motherboards, but what about video and power cables or even the PSU? Are you using any PCIe risers? Is everything properly plugged in and grounded (I know, I know, but got to confirm the basics when weird things like this happens)?",
      "Ahhh the annoying bothering problem I had with like 3 or 4 of my setups ... I never figured it out until recently ... I found out the solution that worked for me and maybe it could help you too. \n\nThis usually happens when there is shorted circuit or faulty ground connection which causes electrical noises to directly impact the visual output .\n\n First look for any shorted circuits in the case itself and then the setup like connections devices sometimes even a usb hub can cause such problems.\n if all were good then Try removing or at least separating any connection of your setup to the floor or ground .that was what caused my PC to go funny and play hide and seek with me .\n\n If that didn't work for you , try checking if the cable is faulty or if it is properly plugged by like pushing it in more or applying a very very light force on the cable to see if it affects the problem like if it makes it worse or just stops that from happening . \nThis happened on my PS4 with the non original hdmi cable it had . Maybe replacing the HDMI cable could help if that is the case with yours as it was with mine . \nHope this helps.",
      "I tried without extension cables and the psu from my old system where the card did work. No risers",
      "Yea, looks like a power supply problem. These posts seems can't wait to associate Intel Arc with keywords like \"issues\" before properly describing what they are experiencing...what is going on...",
      "There is not short circuit anywhere. Tried a dozen different cables all same issues. I did manage to to get into windows long enough to launch some games but as soon as games start it crashes the pc. My A750, A770, A380 and B580 work without any issues in the pc so short circuit is very very unlikely.",
      "If it does this on a more inferior monitor than yours (like a 1080p display /tv) then its not your cable bandwidth (my current bet is here is on old sh!tty cables, as its your common denominator between what you've mentioned; No need for an $80 HDMI cable, but, the cable *does* need to be new enough to cover the spec needed by the newer bandwidth demands).\n\nIs HDR disabled?",
      "Happens on both DisplayPort and HDMI but I’ll try different cables and hope for the best\n\nEdit:\n5 cables or so all same issue.",
      "A. Already disabled\n\nB. Rebar is turned on and CSM off\n\nC. Windows install is already GPT \n\nD. Can’t even get far enough to open settings app in windows.",
      "Would a cable force the pc to restart though? It happens on both hdmi and DisplayPort, also just tried a different monitor with different hdmi cables and same exact issue. I’m pretty sure it’s the card itself.",
      "Some modern boards allow you to pass the video processing even if you are connected to the motherboards inbuild graphics. Have you tried the display port of the motherboard?",
      "Guess I’m going to have to RMA again. Every time I want to use this card it’s hours of troubleshooting and I don’t want to waste my time with that",
      "I tried like 5 different cables all experience the same issue so it highly doubt cables are to halen. Started the RMA process",
      "If something else would be faulty all my cards would have the same issues but none do. A750, A770, A380, B580, RTX 3080 all works with 0 issues.",
      "My A770 does something similar in the bios with only one of my monitors. It drops the video signal constantly. I've heard it could be due to certain cables. I know I had an HDMI cable that just would not play nice with my A770 and any of my monitors that did work with my old 980TI",
      "I had a lot of issues with my 380.\n\nSome things I remember I did: \n\nRemove all video drivers including Nvidia and amd, there is a special tool for this \n\nWhen installing the Intel driver select custom and only install the driver itself. \n\nCheck with driver easy if all drivers are up to date",
      "When this happens, if you try ctrl+shift+windows+b does it help?",
      "Can you enter Windows safe mode or try with live Linux image?",
      "Disable ASPM in BIOS, if it isnt already.",
      "My A750 was having the same issue although momentarily, I gave it to a friend until his 4070 came back from warranty, he didn't have this issue somehow.",
      "I had similiar problems with my A770. No boot, intermittent black screens, reboots, artifacts. After RMAing the card and turning off ASPM the card finally works fine.\nIt really was defective. Turning off ASPM fixed a few monitor standby issues."
    ]
  },
  {
    "brand": "intel",
    "generation": "battlemage",
    "tier": "580",
    "matched_keywords": [
      "a580",
      "b580"
    ],
    "title": "Hypothetical discussion of Battlemage performance levels",
    "selftext": "Hi all, as with most of you I am excited for battlemage as well, so after the rumors of battlemage arriving before the end of this year and yesterdays post of B580 getting listed on amazon, I wanted to check what the new lineup would look like based on some fairly realistic assumptions of how intel could improve its gpus gen on gen\n\nEasiest way to do this would be using TPUs gpu database chart and I want to show 3 levels of each (25% - 35% - 50%)\n\nAccording to TPU current alchemist lineup looks like this, \n\nA380 (~RX6400/GTX1650)\n\nA580 (~RX5700/RX6600)\n\nA750 (~RTX3060/RX6600XT)\n\nA770 (~RTX2070S/RX6650XT)\n\nI'm not gonna argue about if gpus are performing to this level, if you used arc you know it depends on the game but generally their ranking seems fair\n\nSo lets look at where the new lineup would land if we get an improvement around 25%\n\nB380 (~RX480)\n\nB580 (~A770)\n\nB750 (~RTX3060Ti)\n\nB770 (~RX6750XT)\n\n\n\nAnd if we get an improvement around 35%\n\nB380 (~RX5500XT/RX580)\n\nB580 (~RX7600XT)\n\nB750 (~RX6750XT)\n\nB770 (~RTX3070)\n\n\n\nAnd if we get an improvement around 50%\n\nB380 (~RX590/GTX1660)\n\nB580 (~RX6700XT)\n\nB750 (~RTX3070/70Ti)\n\nB770 (~RX7700XT/RX6800)\n\n\n\nThis is of course based on the assumption that gpus will keep the same core count, however as you know there are also many other things that affect performance like bus width, bandwidth, core clocks",
    "comments": [
      "Based on Lunar Lake, I would expect somewhere between 33% to 50% performance uplift.",
      "If they make a bigger gpu with higher core count than a770, why not? It could happen with battlemage\n\nHowever i think 4080 is still a bit too far for intel imo, matching 4070 is more likely",
      "Dang I have a 3070 and I was hoping for some RTX 4070-4080 performance with the battlemage series to finally upgrade without taking out a loan. Maybe celestial (if/whenever that comes out) would be the move but that probably won’t be until late 2025 right?",
      "Lunar lake igpu I think maxes at 1.95-2.05ghz; a770 2300-2500 (2400-2500 is an overclock, run mine around 2500) and I’ve read Battlemage will be closer to 3ghz\n\nCould be very strong",
      "I'm not so sure about your performance comparisons. They said 50% I thought I read.",
      "The leak showed the b770 being between a 4070 and 4070ti but it's a leak so who knows what actual performance will be since they're often fake.",
      "I’d def settle for a 4070-level performance if it was sub-$500. I’m upgrading my pc right now and I was surprised (not really) at how high the 4070 variations still are",
      "I can see that A770 performing better or performing like how it should in DX12, however not every game is DX12\n\nA770 = 6650XT isnt my claim but considering all of the games in tpus game benchmarks its where the card sits according to them, its not a comparison between fsr and xess or comparison between rt performance, \n\nI'm aware from a580 to a770 theyre actually 256bit cards with decent memory bandwidth, a750 performs almost like a 4070 in topaz video ai, which ive found out happily\n\nBut all in all, you cant basically ignore arcs shortcomings, hopefully battlemage will fix them like you said",
      "B580 listing showed 2800mhz for it",
      "Been definitely considering AMD for my upgrade but I’m feeling weirdly drawn to Intel hahaha",
      "I hope the top end B770 has 16 GB of VRAM, performs the same or better as the 4070 and sells for $350 max. That would make it appealing.",
      "Intel's Xe2 has 50% IPC on previous gen.\n\nDue to a better node, approx 30% better clocks then approx another 20-25% due to other architectural improvements.\n\nB770 will be around RTX 4070 level.",
      "Nothing is certain until we see the benchmarks from reviewers\n\nThis is just guesstimating",
      "Recently I have found leaks to be pretty accurate.",
      "Yup, hopefully Intel does what i said above. That's the only way they're going to gain market share and have a shot at the next gen making decent margins.",
      "7700XT performs bit slower than 4070 in raster games however its significantly cheaper",
      "My focus is PCVR. I'm getting an Omni One (VR omni-directional treadmill) delivered soon. The current rumor is specs on par with 4070 super only with 16g VRAM instead of 12g (\"ti\" is necessary to get up to 16g) for one of the models. If they can put that out at the same price as a 4070S I'll likely snatch it.\n\nI'm just as excited as I was for the 285k (for the love of intelligence fix the name and call it 15th gen) because I expect all the issues to be worked out on launch. the chipset has so much potential. I am really hoping some amazing numbers in some areas for gamers.\n\nSpecifically so I really hope the efficiency & display interface they hyped on in the video they put out a few months ago shines through    https://www.youtube.com/watch?v=1LSF-II0l-4...  Quest 3 (which is what i use) caps at 120hz. If it can render VR at that refresh rate for most games for me it'll be a roaring success.",
      "The leak showed the b770 being between a 4070 and 4070ti but it's a leak so who knows what actual performance will be since they're often fake.",
      "I can see the B770 having at least 16gb since the B580 amazon posting showed 12gb",
      "PCI-e only cards are definitely not where the market sits, however theyre usually efficient and cheap enough for what they are\n\nFor htpc market and like entry level 1080p gaming they still matter imo, how profitable they are is intels question"
    ]
  },
  {
    "brand": "intel",
    "generation": "battlemage",
    "tier": "580",
    "matched_keywords": [
      "b580"
    ],
    "title": "New graphics card arrived!",
    "selftext": "I'm gonna be swapping over my RX 6600 for this (Arc A770 16gb), mostly because this was at a decent price during the holidays and I couldn't find a B580 since they were out of stock at the time.",
    "comments": [
      "Idrk if this is a substantial upgrade over the RX 6600- will the card atleast be played in 1440p? Or utilize lots of programs that need that 16GBs of Vram?",
      "Congrats on the new Arc A770! It's quite a good price for the GPU performance, but from the RX 6600 to the Arc A770, it's not a significant improvement but it's still good.",
      "I would say yeah, but just know that some games still aren't optimized by Intel's drivers as they are relatively new to the GPU market. I hope you enjoy your new GPU though",
      "I mostly got it since I've heard it was decent at 1440p, and I wanted to be able to use my monitor at its native resolution for the games I play. That and the 16gb of vram I feel like will be useful in the future.",
      "How much did you spend? I got an open box A580 in microcenter for $110 yesterday. Upgraded from 1060 3gb for $185 back in 2016 🤣",
      "I need to upgrade my CPU and motherboard before I can use my sparkle titan 😭😭😭(I got it early because I was afraid of it selling out and scalpers)",
      "Oh, well for now, just enjoy the 6600 and have the last moments before you replace it.",
      "$240 for A580? It usually goes for $180 on Amazon before taxes.",
      "Ah ok. A770 is around $270 on Amazon so $240 is a great price.",
      "Nice! he can utilize your old hardware so it's not e-waste",
      "Nice!! I bought the same card for my son's rig. Went from a 1080ti with a 5600x. To this card and a 7600x also made the jump to 1440 as well. It's been a good upgrade so far.",
      "Its a good card just not for gaming. If u ever need to head down the content creation route the media encoders on that gpu is unrivaled with.",
      "Good looking card.",
      "I think it would've been worth the wait. Unless you really wanted 16gbs of vram instead of 12 gbs",
      "It's totally an upgrade over that 8gb card. \n8gb cards suffer nowadays. \n\nI upgraded from a 6650xt... never looked back.",
      "I am planning on getting a new PC case eventually down the line, thinking on swapping I've to the Jonsbo TK-1 as I think it's an aesthetically gorgeous case, it fits my board (im using an matx board), it'll probably look good with the new graphics card, and it's small and compact so it'll give more room on my desk.",
      "How much are they usually? I was able to get one on Neweggs eBay page for $240 and free shipping.",
      "I was thinking on going for a B580, but that was a little bit after we made the purchase on eBay, and they were all sold out where I lived. (Edit\" fixed some spelling errors)",
      "Yeah I've heard about that, hopefully the games that I play will be fine.",
      "It'll be in good hands, I plan on giving this to a buddy of mine someday, he want to build his nephew a PC."
    ]
  },
  {
    "brand": "intel",
    "generation": "battlemage",
    "tier": "580",
    "matched_keywords": [
      "a580",
      "b580"
    ],
    "title": "Which Arc card should i get?",
    "selftext": "Before anyone says \"don't, just wait for Battlemage\"\n\nWell my budget is at max currently £200.\n\nIt would seem most people here believe that the B770 is going to be $400+ which is around £320+ but we'd have to add tax onto that so probably closer to £400 ($500).\n\nThe B770 is going to be out of my price range.\n\nThe B580 may be in my price range, but if the B770 is going to come in $70+ higher than the A770 ($329 before tax) then that would be the B580 would probably be around say $229 (before tax) ($70 higher than the A580 launch of $179). I could potentially run to this, but when the A580 never released in the UK it feels like theres a good chance the B580 won't either.  \nStock is starting to dry up fast here of Alchemist GPU's, and i'm not convinced their going to restock if the next line is about to launch, but that also doesn't mean their going to release in the UK any time soon either.\n\nThere is one official retailer currently still selling Arc GPU's.\n\nI wanted to get the Asrock a750 challanger, but its just listed as preorder and i'm not sold that they'll actually get it back into stock. Tried to check with them and they just gave some gas about not being able to confirm an estimate.\n\nThe options are:\n\nSparkle A750 ROC Luna £179\n\nIntel Arc A750 limited edition - £169\n\nThese both come with a game (Assasins creed Shadows)\n\nI've heard that both cards aren't as good as the Asrock. Thats a shame, is that true?\n\nShould i just go for the cheapest? I'm feeling that might be best.",
    "comments": [
      "A770 16GB when the price drops after the new cards come out.",
      "Arc a770 3 fan 16gb OC all the way",
      "A770 16GB or battlemage top of the line.  since your gaming the video card is your most important part along with your screen (240hz).",
      "Yes that's basically the deal I'm looking at to\n\n\nI'm thinking I might just get the limited edition a750 for 169 plus AC shadows, then I've got a nice upgrade from my a380, a free game to look forward to and I can save for battlemage. \n\n\nMaybe I should spend 10 more and go with the a750 roc Luna though.",
      "THe A750 is a beast.",
      "The arc a750 LE is a great card. \n\nThat's a good price as well. \n\nGet it and enjoy",
      "Try to find A770 but A750 is still great choice",
      "I can get one for £239 atm, which is on a discount. Do you think they'll drop the price much more than that?  \nIts also tempting because part of the deal is Assasin's creed Shadows which the offer might be pulled before the next line are out.",
      "A770 Luna has been around that price lately, I got mine a month ago for $240 (around £190)",
      "ah luna a770 is out of stock, would the non luna variant of the sparkle ROC be the same but basically in white?\n\nHow have you found fan noise?",
      "At this point, if it’s not urgent, I would wait to see how battlemage pans out. In hindsight, I could’ve waited too, but I also got AC:Shadows+ Ubisoft Classics (for 6 months), which sweetened the deal; also, the card is white and matches my build.\n\nBtw, since they may pull out the offer as you said, I have already redeemed the game and it shows up as a preorder on the ubisoft launcher, ready to download when it comes out on Feb. 14th.",
      "I owned the a780, it was awesome but yes - it was hotter than the competing Nvidia card - however, ran games very well and the heat wasn't a deterrent",
      "Just got the ASRock Challenger A750, very quiet card and the cooler works quite well, keeps the temps at 60C at load. Very good considering it's one of the cheaper Arc A750 cards.\n\nIt may or may not come back in stock, Arc card stock doesn't seem to be amazing, likely Intel is prepping to focus on Battlemage.",
      "If your Budget is somewhat Tight, then I would go for the A580.\n\nIt is a 1080p Starter Card for Gamers so you shouldn't have much issues. I'm entirely sure if it can run 1440p unless you don't plan to go play at Higher Resolution.\n\n\nI have an A770 but I believe an A580 will be Consistent on Workflow for you.",
      "Retail pricing is back to circa two years, ago. A750 ~170-185, a770 ~ 230-245. So, it's really not on sale, and the current limitations isn't fairing to well in modern games--particularly UE5 engine games with any kind of lumen or nanite. As a first gen card, best to wait for the b580 reviews at least, or buy pre-owned for 100-150 range, IMO.",
      "If your budget is tight I would also look at the used market. Last gen AMD cards are getting pretty cheap.",
      "I love my ASRock 770. I can vouch that it's an extremely capable card. I stream and game simultaneously from it. A little game tweaking here and there and I can actually do well in a lot of games in terms of stability and framerate. I've been streaming SH2 at a solid 60 fps with XESS enabled. My main game is dead by daylight, and again XESS enabled give me a solid 120 at all times on the game's ultra settings. I'll say that call of duty is very weird to play though.",
      "I'm stunned with SPARKLE's A750 8GB OC.\n\nDoing great in new games and also in multimedia(rendering photo/video)\n\nCurrently, no regrets at all.",
      "Price in the UK is 330 for a770  and 239 for a750 when not on sale, so at £169 with a game its definitely on sale",
      "I've just ordered that exact card, great price really for what you're getting"
    ]
  },
  {
    "brand": "intel",
    "generation": "battlemage",
    "tier": "580",
    "matched_keywords": [
      "a580"
    ],
    "title": "My first Intel Arc build.",
    "selftext": "So this is the card that got me interested in Intel GPUs. I bought the Arc A580 for $170 from Amazon during one of the Prime deals. \n\nPC Specs Pairing\nRyzen 5 5600 \n32GBs of Ram clocked at 3600mt/s\nMSI B550-A Pro\n750w PSU\n1TB nvme SSD \n\nI typically like working with low end or budget hardware compared to high end. Yes I can set everything to max and play at 4K without any trouble but I prefer troubleshooting budget hardware to make games playable on them. Spent endless hours trying to play games at 1080p at low, worst headaches I got and I loved it 🤣.  But I learned something along the way, card runs more consistent in 1440p. Fortnite on competitive settings (everything low with view distance far on DX12) averaged 90-100fps at 1080p. At 1440P with with some upscaling with some setting set to med-high with lumen on I managed to get a locked 60fps on my 4K TV. So in the end this was my gaming rig for my living room (until I upgraded to the B550)",
    "comments": [
      "I actually got the B580 recently as well. 😄",
      "Too bad its an A580 not a B580. \n\nNice choice.",
      "i saw that above and then made maybe the biggest typo possible lmao, sorry",
      "I see alot of people saying the blue B580 is ugly but I really like the color. I wanna convince one of my friends to do a B580 7600X build with a blue theme haha",
      "Holy fuck ur cpu cooler fan is hot asf!",
      "Did a bios update, enabled Rebar, DDU old AMD drivers, updated Intel drivers, used different CPUs (5500, 5600, 5600x, 5800x) Always averaged 100fps, even did a comparison of the RX 6600 and got better results there in regular Battle Royale. My old 2060 even had better results. I’ll do a retest to see if drivers fixed this issue.",
      "Those typos screw up the Google searchers. C580. See? Hello Celestial people from the future.",
      "Fornite tests! Woo!\n\nOk, so, wait, my baked in graphics (Radeon 780M) on DX12, everything low, view distance epic) I can get 165hz locked on my 1080p monitor (via USBC out).\n\nSurely something is amiss if you're unable to get above 100fps at 1080p. Rebar enabled in BIOS?",
      "Life is too short to play games on Low.",
      "is the b580 better than an a750?",
      "It’s doable but very limited. There’s some motherboards that have blue accents which go with the card. Color scheme is pretty much blue and black.",
      "check again - this is an A580 btw",
      "A580, not B580.",
      "yes",
      "Way better. More VRAM and more powerful cores.",
      "The card used is the A580.",
      "Aw nuts."
    ]
  },
  {
    "brand": "intel",
    "generation": "battlemage",
    "tier": "580",
    "matched_keywords": [
      "a580"
    ],
    "title": "Should i get rtx 2060 or arc a580",
    "selftext": "I have ryzen 5 5600, b450, 16 bg ram now should i get rtx 2060 or a580 now which should be best upgrade for me now ",
    "comments": [
      "people be saying get the b580 but theres none on stock lol",
      "A580 or b580?",
      "That's kind of a big jump for someone asking about what sub $180 GPU to get",
      "B580",
      "None. Both are a bad choice 'cuz-\n•2060 might be a better option than the A580, though it is a really old and inefficient card (You know what I'm trying to say here)\n•The A580 is a big No-No as the Alchemist series of Arc GPUs has been a disaster in the terms of driver maturity+you're here talking about the low end variation of a first-generation product.\n \nHere, buying an AMD GPU or a B580 should be considered.",
      "Force one into existence",
      "Not to mention that the b580 is at least 50% more expensive than the A580",
      "Neither: get a B580. And a Ryzen 5700X3D.",
      "a580, the rtx 2060 is very underwhelming.",
      "I ran a 2060 super until I changed over to the b580\nI used it to play on 1440p and it ran well! Depends on what OS op is using I guess",
      "I am not comparing the two. I am saying that it is strange that so many people default to saying that OP should buy the B580 instead, when they are in two different price categories and have two different levels of performance",
      "Yep, that's right. I guess they just misread the post and in the current hype around B580, they automatically reacted with B580.",
      "A580 unless you can get an A750 for a similar price.",
      "b570 or the a750 nothing else is worth from intel . b580 isn't available but if you can get one do sure get it",
      "Rx 6600 since it's more performance, and slightly more expensive. (I wouldn't 1st Gen arc cards)",
      "the 6600 is prob best $200 card right now. I have seen a few B580 or 6600 xt  for not much more. I would get those instead if possible and still in budget. they're about 25% better than the 6600 but $30-50 cheaper last time i looked",
      "You can get a A580 new now for $169 and is a very good value if you can't swing a B580:\nhttps://www.techpowerup.com/review/intel-arc-b580/33.html\n\nIt looks like a used 2060 is $140 and being ~30% slower is not a great value.",
      "I have an Intel A770 16GB card. My son has the Nvidia 3060. His card crashes all the time and mine is stable as can be. Mine outperforms his as well so id definitely get the B580. My only complaint about my A770 is that last I knew it wasn't VR compatible with my Meta Quest so I bought Virtual Desktop and it runs fine that way. It's been awhile and maybe it supports VR now.",
      "The A580 is actually kind of ok for 1080p. The 2060 is weaker",
      "A580 is not the lowest end of Alchemist, and drivers have come a long way. I would still steer OP toward a used radeon card either way though."
    ]
  },
  {
    "brand": "intel",
    "generation": "battlemage",
    "tier": "580",
    "matched_keywords": [
      "a580",
      "b580",
      "arc b580"
    ],
    "title": "rare case where B is better than A",
    "selftext": "https://preview.redd.it/a1qus2j0a42f1.png?width=1758&format=png&auto=webp&s=1e1f65251aad1ade18d9668dab2e3453bf703d72\n\ni decided to buy the asrock b580 oc after...um...missing the chance to pre-order the nintendo switch 2 in japan...the a580 card i'm using was bought new last september from a chinese brand i can't spell for around $150 on amazon japan.\n\nCurrently, thanks to the rising value of the yankee, the price of imported electronic components is decreasing, including graphics cards, the price of the intel arc b580 has dropped from \\~52000yen to \\~44000yen and may drop further if the yankee continues to appreciate.  \n",
    "comments": [
      "[Amazon.co.jp: GDDR6 8GB Graphic Board with Intel Ark A580 (Genuine) AR-A580D6-E8GB/DF : Computers ](https://www.amazon.co.jp/-/en/dp/B0CMXGG77T?ref=ppx_yo2ov_dt_b_fed_asin_title)",
      "store link? I can absorb the import cost if I could get it around $150 too. \n\n\ncurrently one retailer in my area are scalping B580 to $400 level, particularly Steel Legend variant. Any B580 priced at $300 and below will instantly vanish. currently no one buys from that retailer when the price crossed $350 mark",
      "You mean 'decreasing value of yankee'",
      "[https://www.amazon.co.jp/-/en/dp/B0DNV4NWF7?ref=ppx\\_yo2ov\\_dt\\_b\\_fed\\_asin\\_title](https://www.amazon.co.jp/-/en/dp/B0DNV4NWF7?ref=ppx_yo2ov_dt_b_fed_asin_title)"
    ]
  },
  {
    "brand": "intel",
    "generation": "battlemage",
    "tier": "580",
    "matched_keywords": [
      "a580",
      "b580"
    ],
    "title": "A310, A380, A580.",
    "selftext": "Did these three cards ever get sold by Intel? And not third party? Reason I ask is because I’m trying my hand at building an Intel Arc LE collection.\nI have an A770 and a B580 but I wonder if I can even get the rest of these cards. I’ve only ever seen Sparkle, Asrock, Gunnar, and other companies.",
    "comments": [
      "A7670 is the best card honestly the next best card probably",
      "No LE cards of these.",
      "No. They only sold 770 and 750.",
      "dont forget DG1!",
      "i have an arc a580 with no markings from a third party because it was made by a Japanese company. it's the sparkle version without any of the sparkle branding on it so it looks like stock",
      "There are also a crap-ton of DG1 and DG2 dev boards that would make great collection pieces. Many have the wavy silver prototype shrouds.\n\n\nE.g.: https://forums.anandtech.com/threads/intel-xe-dg1-sg1-dg2-prototype.2610568/\n\n\nLot harder to find, though. :)",
      "No, only B580.",
      "ofc im joking bro, get the a770 or the b570 if you find it around 240$",
      "LE look alikes are tbh difficult to find",
      "Do they have a B570 Le?",
      "Hold onto that",
      "That’s my fault I didn’t realize the typo.",
      "i guess thats what makes them collectible... although not necesarily valuable, unless intel cards do really take off and displace second, or even first place in the GPU world",
      "Where would I ever find one of these?!",
      "That’s what I’m looking for next, gonna get an Arc A750 and then start looking at trashed prebuilts to see I can’t find any LE look alikes"
    ]
  },
  {
    "brand": "intel",
    "generation": "battlemage",
    "tier": "580",
    "matched_keywords": [
      "a580"
    ],
    "title": "Taking out the Arc A580",
    "selftext": "Took out the Arc A580 to see if there’s any performance improvements after some driver updates that were released. Surprisingly yes! I saw improvements on some of the esports titles that I play the most. The Finals I saw go from low-50-60fps to med 80-90fps. OW2 since its DX12 beta release game went from 120 with stutters to 200-220fps with no stutters. Fortnite seems to be the same 130fps on performance. Marvel Rivals, 80-90fps on low. \n\nThinking of using this for a week and see how it works with more games. ",
    "comments": [
      "Nice! Still think it's a card worth buying for anyone on a stricter budget and only cares about 1080p gaming.",
      "First line up of the Intel cards. They were so bad at launch that they weren’t really worth buying, even under the msrp and discounts they were hard to sell. I got mine for $150. It’s worth getting one today if your able to find one even the A750 or A770",
      "Is it worth an A770 if I have a 6900xt?",
      "Yup. It’s slowly becoming more usable but still not user friendly when installing drivers. But I’m slowly starting to recommend it more.",
      "It's also capable of image generation, and even video, albeit it's not so good for the latter",
      "i don't game but I really like the idea of using a B580 for blender or compute stuff on a budget!",
      "Not worth it, the 6900xt is compatible with more games and you’ll take a performance hit.",
      "Thanks",
      "Didn't know there were an a580"
    ]
  },
  {
    "brand": "intel",
    "generation": "battlemage",
    "tier": "580",
    "matched_keywords": [
      "a580",
      "b580"
    ],
    "title": "i5 11500 or 5700x to pair with intel arc a380 gpu",
    "selftext": "i can't afford latest n high end stuff rn, I'll try to Keep the cost as low as possible with optimal performance gain\n\nTo give u an mrp idea in my region,\ni5 11500(6c,12t)-125$\nRyzen 5700x(8c,16t)-125$\nIntel arc a380-138$\nG. aorus elite b450m-95$\nG. b550m k/Biostar b550mxc pro-110$\n\nRx 6600-240$\nA750-260$\nA770-300$,350$\nB580-350$\nA580 isn't available\n\nI want to learn video editing,may do some programming/info/loom video occasionally, maybe with basic colour grading/motion gfx/animation on davinci/AE\n\nI've heard of Intel's Quick Sync/Deeplink on video editing,do I lose something if I go with Ryzen 5700x since it has 2 more core,isn't all the necessary video editing stuff included in the arc a380(like av1) if I go with this combo?\n\nI've got a MBA M1 8gb/256gb,can i edit 720p/1080p videos on it?\n\nOptional -\nPlay valorant/PS2/PS3 emu games,gran turismo 3-4 sometimes(really loved GT5 when I had an i5 12500H Rtx 3050 laptop)\ni5 11500 has avx512 encoding but dk how great that would be in rpcs3 compared to 5700x/my previous 12th gen laptop exp.\n\n27\" 1440p 180hz display(275$,grabbing it ig, it's crisp n big)\n\nIs GPU even needed in my usecase?\n\nCurrent pc specs-\n i3 10th gen\nAsus 510m mobo(supports 11th gen,capped at 144hz 1440p,hdmi 2.0)\n2x8gb ram \n256gb gen3 nvme SSD \n1tb HDD \n450w generic psu\n21\" 1080p 60hz",
    "comments": [
      "get a lower end B760M and an i5 12400 imo, so you at least have some semblance of future proofing, 11500 is alright, but it's gonna become obsolete real fast, and you can't upgrade it to next gen on that mobo, but if you think your financial situations are gonna improve and you will replace the board and cpu altogether, then it's fine. but if you had to choose between the 5700x and 11500, then it's a blind buy for the 5700x. I understand you're on a budget constraint, so I'm not gonna try and coerce you into buying  a better gpu, but any of the CPUs you mentioned are perfectly fine to drive an a380, ans if you pick up the 11th gen processor or the 12400 you can Leverage the deep link tech too. But why would you get a 1440p 180hz Monitor for this set up is baffling me, because this is an alright 1080p build. Unless youre trying to future proof to some extent and are gonna pick up the 12th gen cpu, I'd advice prioritizing a better gpu over a 300$ Monitor. And youve already got a 144hz 1440p Monitor.",
      "Buying an old LGA1200 motherboard seems silly when you already have an old LGA1200 motherboard. Either use the one you got or jump to the new generation AM5.",
      "My parents buying me these :),and I wanted to replace my 10yr old monitor,so 1440p 27\"  is decent upgrade,I didn't want a ultra high refresh rate,I just needed a big monitor and it came with 180hz,while others have 165hz,100hz same price haha, different brand n warranty period that it"
    ]
  },
  {
    "brand": "intel",
    "generation": "battlemage",
    "tier": "580",
    "matched_keywords": [
      "a580",
      "b580"
    ],
    "title": "Arc A-B series \"off-on\" fan behaviour",
    "selftext": "I am overall very enthusiastic about the new B-series and hope to pick one up soon. But there's something that stuck out I wanted to raise a discussion on.\n\nNew reviews of the B580 LE note that it has annoying fan ramping behaviour:\n\n>https://www.techpowerup.com/review/intel-arc-b580/41.html\n\n>\"While there was no idle fan-stop on the A-Series, Intel has made this capability standard with the B-Series—the fans will turn off in idle, desktop productivity, media playback and internet browsing. Unfortunately, the fans do spin up every few seconds, which can be quite distracting, because the human ear is much more sensitive to changes in noise. I'm not even sure why this is happening, it looks more like a bug than a feature, hopefully it's something that Intel can fix.\"\n\n>\"[thumbs down] Fan keeps switching on in idle\"\n\nYou can see this clearly in their graph of idle fan speeds:\n\n>https://tpucdn.com/review/intel-arc-b580/images/clocks-and-thermals.png\n\nEven the marketing for all the B580 cards seems to be proud of this!\n\n>https://www.asrock.com/Graphics-Card/Intel/Intel%20Arc%20B580%20Challenger%2012GB%20OC/\n\n> 0dB Silent Cooling\n\n> Spin For Cooling, Stop For Silence.\n\n> The fan spins when the temperature goes high for the optimal cooling, and stops when the temperature goes low for the complete silence.\n\n...\n\n>https://www.sparkle.com.tw/en/products/view/6893fe373180\n\n>0db Fan-Stop\n\n\n\nNow isn't this already a well-known dodgy issue for the A-series cards? The Sparkle cards in particular have had many complaints, and I thought it might have been a Sparkle-only issue. Or maybe Sparkle just has noiser fans that make it a lot more obvious.\n\nhttps://www.reddit.com/r/SparkleComputer/comments/1g0wqai/intel_arc_a_750_sparkle_fans_ramps_up_and_stops/\n\nhttps://www.reddit.com/r/IntelArc/comments/1gq6vyj/sparkle_intel_arc_a310_fan_issue/\n\nhttps://www.reddit.com/r/SparkleComputer/comments/1dngosy/sparkle_a310_eco_fan_revving_upd_and_down_issue/\n\nhttps://www.reddit.com/r/SparkleComputer/comments/1bohrb5/intel_arc_a310_eco_revving_fan_issue/\n\n**Old review from 2023**\n\nhttps://www.tomshardware.com/reviews/intel-arc-a580-review-a-new-budget-contender/7\n\n>Oh, Sparkle... what have you done? If you're in a quiet environment, the Sparkle A580 is absolutely audible. What's worse, the fan speeds aren't constant. Even at idle, the fans would often turn on for a few seconds and then shut off again, repeating that every 15 seconds or so.\n\nSo, can more people that have picked up any of the Battlemage cards comment on the issue? It sounds like Intel has built this \"feature\"/problem into all their cards *and are actually proud of it.*",
    "comments": [
      "If true and reproducible it would be a huge bummer as it is a major annoyance (I own a sparkle A750 and hoped that they would have fixed it with the new B-Series 😐)",
      "I think it will depend on whatever temperature is set as the cutoff (which can be influenced by the intel software fan curve).\n\nSo if your system goes above 50\\*C, the fans switch on, then it drops to 48\\*C, the fans switch off... repeat indefinitely.\n\nIf your system is naturally cool, then it might be able to stay with the fans off indefinitely at idle. \n\nI think a software solution could add some \"hysteresis\" to the fan behaviour. So the fans could switch on at 60C, then it cools down to 40C, then it takes a while to get back up to 60C. Which would be better than the 10 second intervals!",
      "It makes the issue only slightly less annoying. I want the issue to be gone completely. I mean it has to be doable right? I am pretty sure that it has to do with the high idle power draw which keeps the GPU at around 50-52 degrees Celsius.",
      "Might have to do with higher power usage at idle or bad case airflow at idle? 1080p 60 fps single monitor systems might not get it? While a 4k 144 hz multi monitor system might get it? Idle power draw seems dependent on monitor resolution and refresh rate. Aspm might help if it works well?\n\nAspm for the pcie slot in the bios might reduce power consumption/heat/fan triggering. 7w vs 38w at idle??????\n\nIncreasing idle case fan speeds might help? Side fan or bottom fan at low rpm help to keep gpu temperatures cool?\n\nMsi afterburner has a fan curve you can adjust. Can set it low enough to cool the card but not make much noise? Likely a minimum voltage/speed/power required to start the fans spinning. Not sure about the intel software.",
      "i can confirm this fan off / on bug on my B580",
      "Can always do a custom fan curve.... it's available even with the current software",
      "maybe the plugin works? [https://www.reddit.com/r/IntelArc/comments/1bvrvo6/plugin\\_for\\_fan\\_control\\_that\\_provides\\_support\\_for/](https://www.reddit.com/r/IntelArc/comments/1bvrvo6/plugin_for_fan_control_that_provides_support_for/) haven't tried it myself yet, but seems to at least exist heh",
      "For single monitor 60hz I know that the PCI-E power saving settings can bring A-series down a lot, but that's a vanishingly rare setup for people buying GPUs for custom built computers... \n\nHopefully it can indeed be resolved fully heh.",
      "Already tried that. Unfortunately for me it has literally zero impact :(",
      "seems People here dont get the problem. It is NOT possible to fix this bug with a fan curve. At least with no software i know of. I set Fan to ZERO till 70c. Card was on 40C and ist still turning off / on with a electric noise. Its a real issue because your fans are always running while on desktop",
      "What model do you have? LE?",
      "Make sure you have ASPM enabled in the BIOS (which can be tricky and need multiple lines to be ticked) and that your card is idling at 5-10W. That will help a lot in getting it to stay cool. With ASPM disabled it'll be making 18-30W during idle and will inevitably heat up until it needs fans on.",
      "no",
      "yes",
      "the card is cool and takes only 19W. Its a Software bug by Intels Graphic Software unable to stop fan",
      "19W is a bit high, that's what I got before I enabled ASPM properly, now it idles well below 10W.\n\nWhile idling, my fan is still going between 0 and 100rpm which is very gentle and I can't hear it, but I agree that seems like a bug. My Arc A310 on a different machine can stay at 0rpm.",
      "yes it should be 0 because i set it to 0 on intels software",
      "owww, dang : /"
    ]
  },
  {
    "brand": "intel",
    "generation": "battlemage",
    "tier": "580",
    "matched_keywords": [
      "a580"
    ],
    "title": "I think my arc a580 graphics card is doing its best.",
    "selftext": "Setting:\n\n\\- Lowest\n\n\\- 720p windows\n\n\\- XESS 1.3.1\n\nhttps://preview.redd.it/2gvsizqsk3me1.png?width=1275&format=png&auto=webp&s=e458123b3ca5d3445718f3cc93ec4f2f9f89242a\n\n",
    "comments": [
      "I just wanna see XeSS 2 asap. More games should have it.\n\nAnd if you take a look at the steam reviews, everybody is having performance issues with this game. Another unfinishes unoptimized game entered the market. So I wouldn’t count on this game for performance issues",
      "I dlas swapped xess 2...its the exact same. Its the xell and xefg that makes it xess2, which i hope they add",
      "man that sucks, b580 at least can run 45fps with high settings.",
      "well, Intel is not Asian, A not better than B :)))"
    ]
  },
  {
    "brand": "intel",
    "generation": "battlemage",
    "tier": "580",
    "matched_keywords": [
      "b580"
    ],
    "title": "My AM4 holdout build",
    "selftext": "Since everyone is sharing their build I'd thought I'd share mine. I swear the LEDs aren't as intense as they are in the video lol my camera sucks. I was previously using an rx 580 4gb blower(LOUD ASF) i shucked from a Dell Optiplex before I got my b580 so needless to say it was a massive upgrade for me in both noise and performance. I'm loving the AV1 encode on the b580 a lot, I stream to my SteamDeck all the time and it looks great.\n\n\nThe Specs are as follows:\nCPU: 5700x3D\nRAM: 48gb of DDR4 3200mhz(I got 32gb free when I purchased the 5700x3D), 16gbs are G.Skill Trident Z and the other 32gb are Crucial Ballistix\nStorage: 1x Gen 3 NVME, 2x SATA SSDs, and 1x HDD for bulk storage.\nCase: Zalman P30\nGPU: Asrock B580 Steel Legend\nMB: Asrock B450m Steel Legend\nPSU: SeaSonic 850w Gold MII\nCooler: Deepcool Captain 240ex\nFans: Thermalright M-12S\n\nMost of these components I've had for years, the only new parts are the 32gb of RAM, 5700x3D, Case, Fans, and of course the B580.\n ",
    "comments": [
      "Nice looking build, gives off Star Wars Sith Vvbes.  Do you run any benchmarks?  If you do or can you run the 3DMark tests and show how the 5700x3d pulls in both Time Spy and Steel Nomad (Dx12 Standard test)?  Time Spy will give you a GPU and CPU number, that latter is of interest.  I have an old AM4 system I was thinking of upgrading, which is my interest in the 5700x3d results.  Thanks!",
      "Yeah I can do that... tomorrow, I'm in bed now. I did run Steel Nomad DX12 a couple of days ago and I believe my score was 3300-3400~ish(EDIT: I was wrong look for my other comment below). If you look on the results for the b580 on 3dmark it is in the expected range. But I'll make sure to run it again along with Time Spy.",
      "Works fine for me, very few issues.",
      "Basically identical build minus running a b450 and 650w. Id like the 4.0pcie slot but I aint spending for a new mobo, if I did it would be am5.",
      "I wanted to ask if the intel arc do well on the AM4 Mobo. I also have an RX 580 and looking to upgrade to an A580",
      "Would a pci3 board bench be of benefit to you? Same setup just older mobo.",
      "Alright sorry this took so long, it's been a looong day, but here it is: [My Time Spy Result](https://www.3dmark.com/3dm/124349867) and my [Steel Nomad Result](https://www.3dmark.com/3dm/124350030) i made a mistake in saying i got 3300-3400\\~ish, i seem to have misremembered my test score... those are from the heavily OC'd cards, mine is just a stock Steel Legend one. (I also did a Port Royal, and FireStrike test if you wanna see that: [Port Royal Result](https://www.3dmark.com/3dm/124350478), [FireStrike Result](https://www.3dmark.com/fs/32812462))"
    ]
  },
  {
    "brand": "intel",
    "generation": "battlemage",
    "tier": "580",
    "matched_keywords": [
      "a580"
    ],
    "title": "Should get rtx 2060 or arc a580",
    "selftext": "My config is r 5600 and b450 ",
    "comments": [
      "2060, but I recommend saving for b580",
      "B580, it's still being optimized so it'll just keep getting better.",
      "i don't think the b580 would play nice with the ryzen 5 5600, regarding the overhead issue lately",
      "It's still worth it, it's greatly exaggerated on reddit, new benchmarks have come out.",
      "2060\n\nbased on your budget range, a 1080 or 5700 xt could also work",
      "The RTX 2060 6 GB card outperforms the Intel ARC Alchemist A580 by more than 10% with the only advantage for the Intel card as better video compression technology. The A580 along with all the other Alchemist series hardware has a manufacturing design flaw where the programming will randomly crash the system up to two hours upon initial loading of a program for full load usage of the memory capacity of the hardware. The developers determined that the scheduling section of the chip is broken and that the flaw is a design problem. This is why there is an upper limit to FPS. Video driver updates can reduce the problem but it will be by sacrificing FPS to a lower rate to reduce probability of crashing and lower 1% low system stuttering.\n\nAll Intel ARC discrete video cards were designed for use for DirectX 12 and newer application protocols, therefore, performance for usage of any programs that use DirectX 11 or older will have performance issues, because Intel will use emulation software inside of the GPU hardware to perform legacy programming. This technique always reduces overall maximum potential performance output.\n\nThe recommendation is to use an RTX 2060 Super 8 GB card rather than an RTX 2060 6 GB or ARC Alchemist A580 8 GB video card. In the used market, all of these cards are priced below 200 US dollars, while in the brand new video card market, the AMD RX 6600 8 GB card will outperform all the previous hardware mentioned with a performance level equal to the RTX 2060 Super 8 GB card.\n\nIf your budget is at or above 250 US dollars, then your options are much better than any of the hardware mentioned here. Since, that gives you possibilities such as the RTX 3060 12 GB, RX 6700XT 12 GB, and even the RX 6800 16 GB card at just over 300 dollars.",
      "cheap Nvidia cards are a scam, either get the cool one or get AMD"
    ]
  },
  {
    "brand": "intel",
    "generation": "battlemage",
    "tier": "580",
    "matched_keywords": [
      "a580",
      "b580",
      "arc b580"
    ],
    "title": "Should I buy Intel Arc A580 for my current setup?",
    "selftext": "Hey everyone,\n\nI'm considering upgrading my system with the Intel Arc B580 and would love your advice. Here’s my current setup:\n\n* **Processor:** Ryzen 5 5600G\n* **RAM:** 16 GB\n* **Motherboard:** MSI B450 Tomahawk MAX II\n\nI'll primarily be using the GPU for Unreal Engine, Blender, and some gaming. Do you think the Arc B580 would be a good fit for this configuration?",
    "comments": [
      "Intel have fumbled the bag with the overhead issues since even if they fix it, it'll take a year for people to stop talking about it whenever someone mentions the b580. They had this issue with 13/14th gen cpus. Lots of misinformation about affected processors and then the same usual larping even after hotfixes. So, I would suggest. Don't let the overhead issue completely put you off as intel do seem to have a track record of fixing their drivers. They should at least close the gap on nvidia and amds overhead issues. \n\nHowever, Intel did recommend buyers that they should use a 10th gen or newer, or amd 3000 series or newer CPU to pair with the b580. You'll notice a lot of these benchmarks pointing out the issues are using 9th gen or 2k series cpus. So in a way, if you take their recommended advice, you won't have an issue. you'll be fine with the 5600g. As you can see someone has said they have the same CPU and have no issues. \n\nJust remember people on reddit take a snippet of information from a youtube video with no knowledge, and run with it, and will continue to run with it even if it was fixed years ago. So yeah, take my advice but do your own research to confirm what I'm saying. Can't trust anyone with tech on reddit.",
      "Titles says \"A580\" but seems like you meant B580?",
      "I have the same processor. No issues so far, but limited testing. I think you might want more RAM, however.",
      "My suggestions:  Upgrade your CPU to the 5700X3D.  It's the best performing CPU for AM4 for the money.  No overhead issues for the GPU then.  Upgrade your RAM to 32GB(or more) which will be an inexpensive and easy upgrade.  Make sure you have a decent tower cooler for the CPU as well, but you don't need to spend more then $30.00 on that. \n\nKnow that the B450 chipset is limited to PCI Express 3.0 speeds so you may not get the full performance out of your new GPU regardless of any other upgrades.  Also ensure REBAR is turned on and you update your BIOS ahead of any other upgrades.\n\nYou could also consider an AM5/Intel upgrade for board/cpu/RAM.  You'll spend a bit more but you'll be on a much more modern chipset and current/recent gen CPU's that will eliminate any driver performance issues.",
      "No. With a different CPU yes, but not the current one.",
      "Probably wouldn't recommend it with that processor and some people have had issues with the B400 series motherboards not to say yours will."
    ]
  },
  {
    "brand": "intel",
    "generation": "battlemage",
    "tier": "580",
    "matched_keywords": [
      "b580"
    ],
    "title": "Finals performance increase?",
    "selftext": "Is it just me or has anyone else noticed the finals performs a ton better on arc, specially alchemist.\nBefore I'd be lucky to get 60+ avg on all low with many dips but now I'm averaging over 80 fps and hitting a 100 with more stable frame times. This could be a sign devs are taking arc more seriously, probably because of the b580. Either way I'm happy.\nI'm using a a750 with a 5600g btw.",
    "comments": [
      "Before it was barely running 60, now I can play it decently. 60-80+fps. and I'm like using  r5 2600 with 3.8 ghz \\[oc tuner in bios\\] and 32gb ram. and i'm using a750 8gb  with settings  like 228w in the core power limit  29 performance boost in intel graphic software.  the graphical preset is custom with some settings medium but majority is high with xess ultra or ultra quality. \n\nwhich is potato cpu by today's standard lol. but yes i'm satisfied knowing that I have an outdated cpu.",
      "I'm just happy I ain't stuck at sub 60 anymore. Though I guess it wasn't a performance increase but instead a cpu overhead decrease.",
      "same here.  I tried it out to report here. but I already have a game that I main which is valorant. but I'm happy that even with my old cpu, I can play it decently.",
      "I don’t notice much difference before and after the driver release. I only play esport games like CS and valorant",
      "I have A580 with 10700k. Amazing 1080P medium to high setting with 70fps+",
      "Is it any better or is my setup just to trash and only ĺess guys like me saw the improvement."
    ]
  },
  {
    "brand": "intel",
    "generation": "battlemage",
    "tier": "580",
    "matched_keywords": [
      "a580",
      "b580"
    ],
    "title": "DX12 Support? 😮",
    "selftext": "I recently saw that OW2 added a beta of DX12 and included support for XeSS. I had to try it out on my ARC cards. On my A580, I’m now averaging 180-220 on High. Before I would get 120-150 on the same settings. Those small frame stutters are gone and the game runs much smoother. On occasion there’s one pause or dip when so much is happening on screen (which is listed on the patch notes) but occurs once in game and it’s not happening every second. Gotta try it on my B580 now. ",
    "comments": [
      "This plus a BIOS update literally saved the game for me. Previously it was unplayable with the stutters."
    ]
  },
  {
    "brand": "intel",
    "generation": "battlemage",
    "tier": "580",
    "matched_keywords": [
      "a580",
      "b580"
    ],
    "title": "i3 12100f + ARC A580",
    "selftext": "Im doing my first build and also im on a budget so im not sure if using the MSI PRO B760M and the i3 12100f would be good enough for a build having in mind i want to upgrade in the future in like 3-4 years, maybe a better cpu or a gpu like the B580",
    "comments": [
      "Ideally, want 6 core or more. \n\n\nAlso, lots of options depending on the budget whether Intel CPU platform, or newer AM5 platform. With AM5, will at least have a better upgrade path if looking ahead. Really depends on budget, and what looking for in a PC. Also, the region for pricing may be a factor.",
      "great idea i see you get a b760 so you want to upgrade your system but if ou ave money you could get a 12400f or 14400f(they are the same)or you could get 14700f",
      "Right now getting an i5 12400f it's more cheaper than the 5600x so I probably gonna go with that",
      "ali express"
    ]
  },
  {
    "brand": "intel",
    "generation": "battlemage",
    "tier": "580",
    "matched_keywords": [
      "a580"
    ],
    "title": "asrock a320m/ac compatible with the intel arc a580",
    "selftext": "Hi I do not know much about computers but I want to update my graphics card from a 1050ti. My motherboard is an asrock a320m/ac, will the intel arc a580 be compatible. I’ve been trying to look it up but am struggling to understand pci and pcie and how to tell. ",
    "comments": [
      "By a quick look of it, it's unclear. \n\nhttps://www.asrock.com/mb/AMD/A320Mac/index.asp#BIOS\n\nhttps://www.reddit.com/r/ASRock/comments/pp9d86/i_cant_find_resizeable_bar_on_my_motherboard/\n\nhttps://www.reddit.com/r/AMDHelp/comments/15tr45x/is_there_a_way_i_can_enable_sam_in_this_system/\n\nYou could try updating the BIOS and seeing if you can enable resizable BAR (reBAR) which might be called SAM (smart access memory). A program like CPU-Z can tell you if it's successfully enabled.\n\nEven after that, with such an old CPU (what is your CPU?) you might run into bottlenecking.\n\nhttps://old.reddit.com/r/hardware/comments/1hsjqb2/intel_arc_b580_massive_overhead_issue/\n\nSo you might be encouraged to upgrade your mobo and CPU to run an intel card. If you must keep your old system then probably not an arc card.",
      "Assume you mean B (Battlemage) gen, as in B580, there's also A (Alchemist) gen and an A580 but the B580 is the one in the news atm- what follows works for both. See if you can do [this](https://www.youtube.com/watch?v=b9KTTLbn8Io&t=1s) in the BIOS. If yes you've got the ReBAR and 4G encoding to get full mileage out of a B580 (or A580) and are good to go. You've also got a PCIe 3.0 x16 slot on the mobo it'll need (it needs x8 IIRC but will fit in a x16, the A580 needs x16 so good for that too).\n\nThen you might want to post what CPU you've got here, so folks can comment on whether it's a good 'fit'.\n\nAlso I don't have a B580 (or A580) myself but check dimensions of your case to make sure it will fit.\n\nIf you really are talking A580 as opposed to B580 my advice is don't do it unless it's a really good deal and even then think x2 or x3 or still don't do it. Get the B580 or wait for next gen cards to appear this year before deciding. Or good 2nd hand deal on an A770 16GB (that;'s the ONLY A gen card I'd buy at this point)."
    ]
  },
  {
    "brand": "intel",
    "generation": "battlemage",
    "tier": "580",
    "matched_keywords": [
      "b580"
    ],
    "title": "Future B series cards? ",
    "selftext": "Sorry for the ignorance, i genuinely tried looking up to see if intel had announced other B series cards other than the B580 and B570. I really want to make the jump to Intel cards, but the 580 would be a side-grade at best. \nHow was the A series roll out? Did it take time for higher end cards to be introduced? \nIt just seems odd to me they only announced two cards. ",
    "comments": [
      "The A series started with the A380, with the A580 being one of the last cards. This time the B580 and A570 (no Alchemist equivalent) came out first. I think if there is going to be a more powerful gpu it will be released in March next year.",
      "During a recent interview the head of Intel Arc said Celestial (Arc gen 3) is ahead of schedule. I think i remember from like back in 2022 they wanted to do YEARLY gpu updates... maybe Q4 next year is C770?",
      "It’s strange to me, I can’t even find anyone online asking the same question. It seems like everyone is just hyped about the two they released, no one is asking, or even speculating about future battle mage cards.",
      "I really hope they come out with something in the spring. I don’t want to wait another year lol"
    ]
  },
  {
    "brand": "intel",
    "generation": "battlemage",
    "tier": "580",
    "matched_keywords": [
      "a580",
      "b580"
    ],
    "title": "Not getting a signal out of my ASRock A770 Challenger and Sparkle A580 in my MSI B650. ",
    "selftext": "Switched to my main pc because my B450 died and now I can’t get 2 out my 5 Arc card working in my MSI B650 Tomahawk WiFi. The A770 makes a weird electrical noise (not like coil whine) and fans ramping when powered on and sometimes shows the bios but quickly goes black and giving no signal. Same for my Sparkle A580 but no video at all not even bios, fans also ramp up randomly but not weird electrical noises. Have updated the BIOS of my motherboard, CMOS rest but no luck. Bottom slot also doesn’t work. Windows doesn’t even recognizes the cards when I use my iGPU. Both cards work on other older motherboard. \n\nAnyone experienced similar issues? I’m really thinking about just buying a ASRock motherboard and hope this fixes it. Just finished recording 16 games for side with A770 but now I can’t get it working 😭. My A750 Challenger and A380 do work. B580 also. \n",
    "comments": [
      "I got the A770 working again by pulling out my 3rd m.2 and sound card. Guess the A770 can’t run X16 with those installed while the A750 can. My A580 now also shows video but as soon as windows loads it just goes black even after safe mode ddu.",
      "It's likely just that B650 motherboard. I had a similar case when my A750 stopped running on the x16 slot of my B460 Aorus Pro AC. At first I thought it was the GPU, but extensive testing with a 2080 confirmed that the mobo was busted. Basically with the A750 the mobo would boot on first boot and fail on subsequent boots unless I turn off the PSU switches and turn it back again, while with the 2080 it could boot just fine but turn into no signal after 20 mins of running.",
      "Any update on this. I'm getting that same motherboard and b580 and I'm curious is you have found a solution tot his issue."
    ]
  },
  {
    "brand": "intel",
    "generation": "battlemage",
    "tier": "580",
    "matched_keywords": [
      "a580"
    ],
    "title": "Arc A580 is among the minimun GPUs for running Final Fantasy 7 Rebirth ",
    "selftext": "Final Fantasy 7 Rebirth PC technical specs revealed\n\n16GB is almost mandatory for 2160p@60FPS\n\n[https://www.eurogamer.net/final-fantasy-7-rebirth-pc-technical-specs-revealed-ps5-console-exclusive-being-optimised-for-steam-deck](https://www.eurogamer.net/final-fantasy-7-rebirth-pc-technical-specs-revealed-ps5-console-exclusive-being-optimised-for-steam-deck)",
    "comments": [
      "B580 probably falls somewhere in the recommended area. Maybe it'll get 1080p high 60."
    ]
  },
  {
    "brand": "intel",
    "generation": "battlemage",
    "tier": "580",
    "matched_keywords": [
      "b580"
    ],
    "title": "My B580 finally arrived ",
    "selftext": "",
    "comments": [
      "Welcome to the club",
      "Congrats, nice to see more people getting them in the post, just one suggestion before installing unless you already have is to make sure your BIOS is the latest version and turn on Resize Bar unless you have a fairly new motherboard (last 6 months).",
      "They can pry my 770 from my cold dead.... Well actually another 770\n\nThat way I can ray trace my memes twice as fast. Baked-in DX would be nice too. lol.",
      "Aesthetically, Intel did a great job with these gpus. They look great!",
      "Mine arrived Saturday. I know it's a small detail, but the packaging on a cheap GPU has no right to be this fancy.",
      "Did turn on resizable bar, not sure if my bios is fully updated it, probably not, haven't updated it ever, but only bought it 2 months ago, although it's a 2 year old product.",
      "Holy shit it pairs well with your cpu cooler, looks super clean to me",
      "BIOS after 09/28/22 supported Resize Bar (if your version is after BIOS 7B86vAH1)\n\n[https://www.msi.com/Motherboard/B450-A-PRO/support](https://www.msi.com/Motherboard/B450-A-PRO/support)  \nThe \"Re-Size BAR Support\" option located under \"Advanced/PCIe/PCI Subsystem Settings in BIOS",
      "Silent protest against them, the NZXT logo on the case is covered up by my intel arc sticker too.",
      "Resize BAR technology unlocks CPU access to video memory, enabling full access to video memory and multitasking, thus improving overall data processing and gaming performance\n\nResize BAR support requires the motherboard BIOS, graphics card and driver to be supported simultaneously",
      "You're one of the lucky few. When I wanted to buy one, they were already taken up by scalpers who are selling them on eBay for 500+and leaving only the 350+ \"custom\" options from the other manufacturers, and I don't have the time or money to go to the nearest micro center to buy one in person",
      "I have to admit, the design looks great and I appreciate every competition against Nvidia!",
      "They look sexy too. I know once you stick it in, you don't see it as well, but definitely a nice overall touch.",
      "The power this thing has no right to be $250",
      "Does microcenter always have them in store?",
      "Make sure your bios is up to date and then look  thoroughly for Rebar",
      "I  only mention it as some people have had issues, best way I can explain is that the BIOS might have been written before this was even thought about. It may work just fine out of the box like most have. My board is about 2 years old and I updated the BIOS a couple of weeks ago and had no issues with the card being recognised. Some with older boards have run into issues (may not of been a BIOS issue) . Less so with the 580 LE over third parties.",
      "Really good looking card",
      "These cards are so smooth",
      "Hey, total noob to the intel Arc series graphics cards here, are they good for gaming? I don’t know anything about them but a lot of people seem to be picking them up, is there a stand out feature that AMD or NVIDIA cards don’t have?"
    ]
  },
  {
    "brand": "intel",
    "generation": "battlemage",
    "tier": "580",
    "matched_keywords": [
      "a580"
    ],
    "title": "Any feedback on Intel arc cards regarding video encoding in VMIX?",
    "selftext": "I guys sorry if this was brought in the forum earlier, I searched and could found so I'm posting, for your help and feedback.  \n\n\nI'm on to buy a new GPU specifically for live streaming on vmix and some light media work on premiere or resolve, and read that the guys at vmix are making intel fully compatible, but cant find any good review on it. Also I am considering Intel over NVIDIA because of price and energy I'v built a micro atx pc for that, so want to keep system small and efficient to be portable. And also because Ive read that intel hardware encoders (HEVC, AV1, H264) are best quality and more efficient with more codecs.  \n\n\nSo to the point have you guys had some experience you care to share on vmix, premiere and resolve, with a380, a580, a750 cards?  \n\n\nThanks again  \n",
    "comments": [
      "Took a year for me to follow up, but just now settling down to testing a B580 and 265KF combo with vMIX 27.0.0.91. Very impressive, streaming to YouTube with an AV1 custom encode in vMIX, at 14000 Mbps. Very low CPU and GPU loads, and my card, the Gunnir B580 Phantom (3 fan), is at only 28 degrees C. Shockingly good. I tend to stay on the final run of an old build like 27 for 6 months, will switch to 28 next month. Likely even better."
    ]
  },
  {
    "brand": "intel",
    "generation": "battlemage",
    "tier": "580",
    "matched_keywords": [
      "b580",
      "arc b580"
    ],
    "title": "the graphics car has arrived (ignore Arc B580)",
    "selftext": "",
    "comments": [
      "how is purrrrrrrrrrrrrrrrformance ?",
      "+100 floofs purrrrrrrr second",
      "Nnnnnyyyyyyyooommmmm",
      "The Graphic \\*cat has arrived. Ignore the B580.",
      "The cat: 😏",
      "Cat tax is satisfactory :P",
      "The cat has pretty impressive graphics.",
      "This is such a great comment 🤣🤣",
      "It's a car",
      "That’s a lotta floofs!",
      "Wdym? I only see car",
      "good job!! - my B580 just arrived today as well!! :)",
      "Dad please stop posting online this is getting embarrassing now",
      "Cheers!! Here's hoping future drivers help our cards age even better",
      "No need to mention \"ignore Arc B580\", because couldn't see that in this pic.",
      "Nice car. What's the retail on one of those?",
      "Congratz on the upgrade. Nice car!. And nice dog!",
      "The cat is angry, because it know's that you will for the next 4 month's not play with her.",
      "Kittel Arc B580 Cattlemage Graphics Car",
      "Pleas go to r/roastmycat but i like the cat"
    ]
  },
  {
    "brand": "intel",
    "generation": "battlemage",
    "tier": "580",
    "matched_keywords": [
      "b580"
    ],
    "title": "Time to start testing B580 on lower-end CPUs",
    "selftext": "Let me know what games you want to see!",
    "comments": [
      "General reminder. When changing CPU and GPU at the same time, don’t forget the following.\n\n1. Clear CMOS/BIOS\n2. Run DDU prior to changing to Intel GPU.\n3. Plug in the 8-pin PCIe power connector to the GPU.\n\nThis will aid your efforts greatly… as I just learned",
      "Baldurs gate 3!",
      "People like you are why we have to deal with so much shitty DRM.\n\nPirate what you can't buy, for whatever reason you may have. Don't just pirate because you don't think single player games are worth paying for.",
      "Reinstalling the chipset driver is also recommended, as it can influence power plan behavior for each specific CPU.",
      "I can help you find it... ;)",
      "Don’t own it, and it’s currently to $60 on Steam. Sorry.",
      "if anyone knows how tf2 cs2, and overwatch run with a b580 on an i5 11400 I would love to know, 4k and 1440p.",
      "I also have a 3700x and 2600.",
      "I'm sorry, lower end? The 5800x3d is not low end",
      "Good call! Doing that now.",
      "It's a 7 year old CPU dude. You can buy one for under $50. It's low end\n\nEdit:\nI'd like to mention that it wasn't even high end in its own product stack when it released, the 2700x was. And that's what I had bad it was DEFINITELY bottlenecking me in new games",
      "Starfield, Stalker 2, Hogwarts legacy, Warframe 😁",
      "Please test with the 3700x, that's my cpu and I'm curious on how it performs.",
      "ark survival ascended if possible!",
      "I refuse to assume that my 2600 is low end (it heats up hotter than the sun in 2.045 seconds when I launch Starfield)",
      "That game should be avoided asap. You don't even get 60fps a 4090 with forced framegen.",
      "Lol @this attitude in regards to baldurs gate. One of the best made triple A's in quite a long time. If any company deserves to be paid for their work, it's them.",
      "I buy games that you know had heart put into them others I don't play. A lot of those are 60$ games and I unlike you seem to understand that piracy is a useful tool only when needed.",
      "I had a 2600x up until a month ago and boy did it get hot",
      "It should get more than 120 fps on high settings at 1440p on those games, as in that resolution games uses GPU more than CPU, still check for a benchmark video"
    ]
  },
  {
    "brand": "intel",
    "generation": "battlemage",
    "tier": "580",
    "matched_keywords": [
      "b580"
    ],
    "title": "Dual B580 go brrrrr!",
    "selftext": "",
    "comments": [
      "Not with a dedicated hardware bridge like SLI/Crossfire (which are dead as noone wants to implement a vendor-locked solution), but PCIe 4.0 x8 is plenty fast for multi-GPU data transfer, and cross-vendor compatible. My [FluidX3D software](https://github.com/ProjectPhysX/FluidX3D) can do that (with OpenCL!): [pool the VRAM of the GPUs together, even cross-vendor](https://youtu.be/PscbxGVs52o), here using 12+12+12 GB of 2x B580 + 1x Titan Xp, for one large fluid simulation in 36GB VRAM.",
      "Malcom in the middle there will indeed be going BRRRRRRRR\n\nat least the top of the GTX will always be clean.",
      "I need them for work, so my employer sent some over 🖖😉\n\n\n(I wrote big parts of the GPU kernels for XeSS Frame Generation and Super Resolution)",
      "So that’s where my B580 LE went.",
      "I'm actually curious what are the 3 gpus used for? Do the arc cards support an sli/crossfire like solution?",
      "I was wondering \"who the fuck needs two B580\"\n\nI guess \"person who wrote big parts of the GPU kernels for XeSS\" is the most valid answer I was ever going to get! :D",
      "This is actually super awesome, I had no idea you can pool different gpus together like this, I'll have to look into it more",
      "Yeah, I'm worried about that poor B580 in the middle haha. Poor guy starving for air",
      "Yes that's me!\nNot just that cow aerodynamics video, but I wrote the entire CFD simulation software for that myself ;)",
      "you're the one who made Aerodynamics of a cow, nice!",
      "\\>(I wrote big parts of the GPU kernels for XeSS Frame Generation and Super Resolution)\n\nDoing gods work here OP.\n\nDo you have a spare one left? 👉👈 /s",
      "Yes it's me Moritz, small world indeed! 🖖",
      "In OpenCL you can use any OpenCL compliant device, CPUs too in the pool......",
      "Oh Mortiz, is it you? Intel did hire you to write the XeSS kernel?! Oh man, what a little world we live in :|",
      "Yep, for games the return-on-investment unfortunately wasn't there, so Nvidia killed it after Ampere generation.\n\n\nThere is a good side though: in the meantime, PCIe 4.0 and 5.0 have become so fast that the SLI/NVLink bridge today is entirely obsolete. And while SLI only worked between identical Nvidia GPUs, PCIe works with literally every GPU out here. Developers only have to implement multi-GPU once with PCIe and it can work everywhere. For games this is still not done anymore because ROI is still not there, but for simulation / HPC software it very much makes sense. I've demonstrated this some time ago by [\"SLI\"-ing together an Intel A770 + Nvidia Titna Xp](https://youtu.be/PscbxGVs52o), pooling their VRAM over PCIe with OpenCL. PCIe is the future!",
      "Intel Core i7-13700K, in an Asus Z790 ProArt mainboard, which is really cool as it supports bifurcation of the CPU's PCIe 5.0 x16 lanes to the first two slots, as x8/x8, so both B580 cards are getting the max supported PCIe bandwidth. The third slot is a 3.0 x4 over the chipset, still good enough for the Titan Xp.",
      "Definitely gonna starve of air!\nI tried to pack 2x A770 LE together and that didn’t work so well!",
      "Yeah I saw your GitHub, It's super impressive and cool that you wrote it by yourself :)",
      "Bandwidth is very similar, but the 3060 Ti is only 8GB capacity. FluidX3D in that case can pair 8+8GB, or at some slowdown with several domains per GPU (4+4+4)+(4+4)GB. Not a perfect match but it will work.",
      "where did you find them???"
    ]
  },
  {
    "brand": "intel",
    "generation": "battlemage",
    "tier": "580",
    "matched_keywords": [
      "b580",
      "arc b580"
    ],
    "title": "Intel finally notches a GPU win, confirms Arc B580 is selling out after stellar reviews",
    "selftext": "",
    "comments": [
      "intel's being successful is what we absolutely need in this duopoly market. It'll benefit everyone. Great news!",
      "Quote from the article:\n\n>“Demand for Arc B580 graphics cards is high and many retailers have sold through their initial inventory. We expect weekly inventory replenishments of the Intel Arc B580 Limited Edition graphics card and are working with partners to ensure a steady availability of choices in the market,” Intel spokesperson Mark Anthony Ramirez tells *The Verge.*",
      "The duopoly is dead, long live the triopoly!",
      "So much for a PaPeR lAuNcH",
      "MLID said it's fakepaper lauch of fakepaper card. 🤡",
      "MLID can retire now 🤣",
      "lmao, still better tho.",
      "That guy is still around??\n\nI watched him years ago, not for long though. He has always been salty, and he was always wrong with his predictions/leaks... \n\nCan't believe people still watch that troll",
      "By the desperation we see here in the sub 100x daily in the last couple months one would think people are buying these to run their heart and lung machines rather than use it for rendering graphics or do GPGPU things lol...",
      "Well AMD has consoles & handhelds going for them. So still a duopoly, IMO.",
      "I managed to get one on launch day, so it definitely wasn't a paper launch, it's just in high demand, higher than expected.",
      "barely even a duopoly",
      "Great news",
      "Hopefully this encourages them to move forward with at least 1 higher end Battlemage card like a B770.  I really wish they would release a high VRAM card too for home AI like a 32 or 64 GB B580 as it does not have to be the fastest to be truly useful and they could keep the price down.  A 32/64GB B770 would be great too.",
      "Pat saved Intel",
      "Grandma guy must be happy",
      "He is still saying that the B580 for $250 is overpriced by $50 but never replies to comments proving it is a completely different situation in the EU.",
      "Reference to Moore Law Is Dead. Guy have a hate boner for intel.",
      "Fantastic news. I bought an A750 LE back in the day as I was sure Intel were done with their 'GPU experiment' and I wanted to own a piece of history on my shelf. I can wholeheartedly say I'm glad I was wrong.\n\nI cracked it open a day after they announced the B580 and it's being used in my brother's PC.",
      "MLiD is just the type person who feels it mandatory to he is always right so he just makes up things that can’t be proven or disproven. Don’t get me wrong he has some good source but he doesn’t like to wrong and do anything to “prove” he isn’t."
    ]
  },
  {
    "brand": "intel",
    "generation": "battlemage",
    "tier": "580",
    "matched_keywords": [
      "b580"
    ],
    "title": "Got a B580. now what?",
    "selftext": "Got FOMO and was able to snag a b580 at msrp from Newegg. Didn’t do any research, just pulled the trigger once stock came in. My current setup is a b450f, ryzen 5 3600x and Radeon RX 5600xt.\n\nMy concern is the bottleneck issues I’ve seen with low end CPU’s. My motherboard also lacks pci 4.0 support. Anyone out there running this combo that can give any advice?\n\nWhat would you do? Do I take my chances and install the card? Order a new motherboard and cpu? Sell the card and get something different? The box is still sealed.\n",
    "comments": [
      "I've read somewhere that the pcie is no issues since this card is 4.0x8, and backward compatible. You need to see if your mobo supports reBar, also make sure you're on latest bios. It should be fine !\n\n Use DDU uninstaller to remove all previous vga driver ( do it in safe mode : windows key + r  , msconfig +enter I think it's the second tab there's a section at the bottom for safe mode, tik the square , it'll ask to reboot but don't chose the save options. \n\nRun ddu in safe mode and redo msconfig but untik safemode and let it reboot. Install whql drivers from intel. Once it's all done, download superposition bench, download ARC OC tools ( see vids on how to use, very easy) Start with 190w power, 0.90v.core and set the clock at it's max rate. Enjoy 👍\n\n Edit: When you set the settings in arc tools for C.clock and v.core , you have to input all the settings you change and then press save. If you do it one by one it won't work",
      "download dlss swapper so you can upgrade games that support XESS 1.3 to XESS 2.0. I'm not promoting, just think it's a handy tool/app since only few games have XESS 2.0 support",
      "Add cooking oil to a pan and set to a medium heat for, place the gpu in the pan and season with salt, pepper, and paprika, add an egg for extra flavour if you like. \n\nKeep on the stove for about ten minutes turning over the gpu ever couple of minutes to make sure both sides are evenly cooked.",
      "Maybe you should put in your computer.",
      "It was a great upgrade on my 9900kf, just keep in mind it is a PITA to get it running correctly, for my Motherboard not only did I need above 4g decoding + Rebar enabled, but I also needed CSM disabled to get it to work(required changing my windows install). But once working, it was a big step up over my old Radeon R9 290. Not as plug and play as a nvidia or radeon upgrade would have been but still worth it.",
      "you have to build it into your rig and install the driver...thank me later",
      "brother, its not that serious.",
      "This",
      "This guy is a downer. You'll probably see some small fps loss with a 3600x but people really blow the issue out of proportion and should be a big improvement over your 5600xt. If you want to remove the bottleneck get a cheap used 5600. If you want to stretch out your build as long as you can get a 5800x3d and you should be good for at least a few years before upgrading is worth it.",
      "Now u play some of the most advanced games just like me im talkin about pso, m&m 1 to 9, everquest p99 and many more",
      "That CPU is officially shit now.  I had it and it can’t even handle a 5700XT.  Your motherboard is fine I wouldn’t worry about the PCIe 4x the bottleneck there is small.  \n\nI’d upgrade to a 5700X3D or 5800X3D.",
      "Nope wouldn't reccomend, xess 2 the upscaling itself is the same. Wait until it gets added to optiscaler so that it'll have xell and xefg",
      "I'm running a 3600x with a 6700xt with no problems and great performances on Arch. And all metrics show a well balanced system (where GPU util is a fixed 99% on taxing games and CPU stays around 70/80).  \nCPU issues starts to show at 150+ fps, a target that I don't need to get over.  \nOnce I'll upgrade my main monitor to an oled that will be the right moment to upgrade the CPU, but calling it officially shit is absurd, is still a fantastic value for a 2k gaming rig (so much that I've build a living room machine with the same chip, for basically nothing).",
      "because yolo. its a cheap card at msrp.",
      "Just did a windows reinstall to be able to turn on rebar. It’s night and day once you turn it on. It’s like it’s a different card.\nEvery thing runsruns amazing so far",
      "The only thing im expecting, is better than I currently have. If the card doesnt work out its an easy sell.",
      "Try the new card out (after a driver uninstall).   If it's faster, then it's faster. Enjoy it and schedule a CPU/MB upgrade when you can afford it.    A faster CPU will almost certainly give you a bump.    If it's heavily bottlenecked, then return it and go for an AMD RX 7600.   Less VRAM but not sensitive to CPUs and readily available.",
      "You'll see **some** CPU overhead, but IMO that may not be a dealbreaker because it'll still outperform your Radeon RX 5600XT in your current config.\n\nIf you have the money, consider upgrading to a more powerful AM4 CPU a few months down the line; prices have been trending down on the 5600, 5600X, and 5700X3D as they're *finally* approaching the sunset of AM4.",
      "Its a good card, might struggle with your CPU in some CPU intensive games.\n\nI mean, you have it already, might as well try it out and play some games you know? Unlike most redditors who don't even play games lmao.",
      "you put it into your pc."
    ]
  },
  {
    "brand": "intel",
    "generation": "battlemage",
    "tier": "580",
    "matched_keywords": [
      "b580",
      "arc b580"
    ],
    "title": "Intel finally notches a GPU win, confirms Arc B580 is selling out after stellar reviews / Intel says it expects to restock the GPU “weekly”.",
    "selftext": "",
    "comments": [
      "A bit surprised they will be restocking so quickly. Bodes well for the future of their gpu platform.",
      "Even if their gpu have quite low margin it helps their overall business in several ways:\n1. Consumer mindshare and brand recognition \n2. More TSMC volume which means they can negotiate better pricing which helps the margins for other products where they use TSMC \n3. Increased gpu users will enable better software as they will need to support more users across more platforms. Better software is a plus going forward",
      "They have a few months before the new gen arrives. They need to sell as many as possible in that time where they are the absolute best value in the market.",
      "It's in AMDs best interest to quash any would be competition before it takes off the ground.\n\nIf Intel gets a hold in the low end AMD will be squeezed from both sides.",
      "The value at the low end hasn’t changed in years, why do people think that it will now all of a sudden.",
      "AMD has shown to be incapable of being a real competitor to Nvidia for over a decade, they deserve to get squeezed out of the market at this point. Ideally it would be nice to have 3 companies competing, but I'd prefer Intel over AMD at this point.",
      "Between a 4060 and 4060ti",
      "Absolute love to see the intel arc W. Much needed in the community. Here is hoping they do what AMD never could, and in doing so light a fire as hot as the 14900k running modded minecraft right below Lisa Suu's seat.",
      "Weekly? Amazon US didn’t even have stock in the first week. 😛",
      "Somebody tell this guy that there are other things that matter than immediate term profit",
      "The progress made by Intel in DGPU's is astonishing\n\nNot only did intel write an excellent driver stack that rivals the Nvidia/AMD, they also implemented AI Upscaling and AI framegen, with RT performance that rivals Ada Lovelace. even in heavily ray traced titles (where RDNA2 and RDNA3 completely fall apart)\n\nIf Intel can do all of this as a new player in the DGPU space, then why can't AMD do it?",
      "It sometimes outperforms the 4060ti, especially if overclocked and running at a higher resolution.",
      "I doubt Intel have any mindshare when it comes to GPU’s. Intel’s iGPU have always been regarded as crap.",
      "🤡 for you. No one expected it to be better than 4070 at 250 dollars 🤡🤡🤡",
      "Actually this is a lesson for their CPU division also, for the most, except those performing absolutely in the useless category, there's no bad product, only bad pricing",
      "How do you know that they're losing silicon on every unit sold?",
      "AMD is constantly busy with fumbling almost every GPU release in the last 10 years, I don't expect that to change anytime soon. Apart from Polaris and RDNA2 every other generation ranges from mediocre to trash. RDNA3 could have been a hit, even with its flaws, if the pricing was right, but they chose to slightly undercut an untouchable Nvidia and call it a day. Meanwhile Intel somehow managed to get the ball rolling in less than half a decade and with their super aggressive pricing they are slowly stealing market share from AMD. RDNA4 needs to be a huge success in the budget segment if they don't want to eventually go out of business. They can't compete in the high end anyway.",
      "what competition. AMD isn't even trying at low end. 7600 was a complete no show and uncompetitive. I don't see why they would care suddenly because Intel is selling a card. The equation hasn't changed for them. There is no profit in this sector so they just put the bare minimum out. AMD is maybe more interested in mid range like $500-600 cards when Intel is not even getting close to that price point.\n\nif B770 somehow magically can compete with $500 cards at $350 then yeah they should be worried but it won't.",
      "Intel GPUs are becoming popular. 4% market share, up from 1%.",
      "Very few reviewer actually talked about overclocking, unlike most modern GPU, Intel B580 actually overclocks pretty well and actually see performance uplift, doesn't even require lifting power limit in most case, just voltage. \n\nMy guess is Intel played safe and tuned GPU boost behavior more conservatively, which is fair."
    ]
  },
  {
    "brand": "intel",
    "generation": "battlemage",
    "tier": "580",
    "matched_keywords": [
      "b580",
      "arc b580"
    ],
    "title": "The Intel Arc B580 is Better Than You Think",
    "selftext": "**TL;DR:** Intel's Arc B580 at $250 is killing it... near RTX 4060 performance, slick as hell, and the driver horror stories are ancient history.\n\nI'm writing this for all you folks who've been stuck in GPU purgatory like I was - endlessly scrolling reviews, watching conflicting YouTube hot takes, creating and deleting Best Buy carts. I get it. The Intel fear is real. But after a month with the B580, I needed to share this with fellow overthinking budget gamers.\n\nIn a market where everyone acts like you need a 4090 just to play Minecraft, I took a chance on the underdog - and damn, I'm impressed.\n\n**The Hunt:** We're living in weird GPU times, right? Even grabbing a brand new 4060 is a headache. The 5060 TI reviews are lukewarm at best, the 5060 rumors are a snooze fest, and prices still make zero sense. I was hunting for a used card, but most were either highway robbery or smelled like they'd been mining crypto in a chain-smoker's basement for three years (*seriously, that smell haunts me*).\n\n**The Score:** So I set my eye on an **Intel Arc B580 for $250 at Best Buy** and thought: screw it, why not? Set up a Raspberry Pi to ping Best Buy every 30s, and one day my phone blew up - MSRP alert! Got lucky and snagged one before the bots.\n\n**My Setup:** Nothing fancy - **Ryzen 9700X, 32GB DDR5, Gigabyte AM5 board** \\--- just a typical Micro Center bundle I impulse-bought during a Chicago trip. I'm not some hardcore FPS sweat lord... more of a weekend pilot. *Microsoft Flight Simulator*, Forza Horizon, *Cities: Skylines II*, or whatever shooter my friends are into that month.\n\n**The Unboxing:** Holy crap, this unboxing experience blindsided me. Got the official Intel model, and it's gorgeous. The GPU was wrapped in what I can only describe as a sacred cloth like some tech priest blessing. As you open the box, the GPU rises up on a platform like some holy artifact --- Intel just out-Apple'd Apple on the unboxing experience. The B580 feels SOLID in your hands. No cheap plastic vibes. Holding it felt like Intel engineers actually gave a damn.\n\n**Installation & Drivers (The Part Everyone Warned Me About):** Very easy. Had it in and powered up within minutes. First boot? Yeah, straight back to Windows 95 era in pixelated 640x480 glory, which I expected --- quick trip to Intel's driver site, one install, reboot, and boom --- all fixed, rock solid.\n\nRemember all those horror stories about Arc drivers? Appear to be ancient history. The software now looks clean as hell. Modern, zero bloat --- and it just works. It even shows you whether Resizable BAR is enabled right up front. No digging through BIOS menus wondering if you screwed something up.\n\n**Performance:** Flight Simulator runs smooth as butter on my ultra-wide monitor, which honestly shocked me. Same for Forza Horizon - crisp, fluid gameplay that I wasn't expecting from a $250 card. I did notice a small glitch where some random driver in Forza appeared to be missing... pants! I know because I played quite a bit on Xbox and he definitely had PANTS there! But hey, I'll take one pantsless AI character over stuttering gameplay any day.\n\n**The Verdict:** If you're still on the fence, hop off. Arc is better than you think. And honestly, it's kinda refreshing to root for the underdog for once. \n\n**If Pat Gelsinger were around, I'd give him a hug. Let's just hope Lip-Bu Tan doesn't mess it all up. Lip-Bu Tan, keep the Arc team alive!**",
    "comments": [
      "Only issue is it’s getting harder and harder to find one at MSRP.. I’ve seen some go for $300 - $400 which isn’t worth it in my opinion. \n\nIt’s a great value card if you can snag one for $250 tho. I was lucky enough to get the Limited Edition at MSRP so I can’t complain. \n\nIt definitely has its issues tho, some games just straight up don’t work for me. Just this weekend I came across two games in my library that wouldn’t work. Detroit: Become Human gives you a warning that it doesn’t support the GPU and crashes on start up, and Batman Arkham Knight crashed on me every start up too, which is weird because every other Arkham game worked completely fine.",
      "Nothing fancy - 9700x 💀\n\nI mean yeah B580 is great if you have the CPU power to drive it and only use Windows.",
      "You're absolutely right about holding out for MSRP. At $250, the B580 is genuinely great value, but at $300-400 you're better off looking at other options.",
      "where are you finding it for $250?",
      "I'm doing well on Ubuntu 25.04, proton works fine and for one month I had no troubles.",
      "LOL you caught me there! You're absolutely right - calling a 9700X \"nothing fancy\" is like saying my Ferrari is \"just a car.\" 😂\n\nFair point about the CPU dependency too. The B580 definitely benefits from having solid CPU horsepower behind it, and yeah, Linux users appear to be out of luck for now, but did not try.\n\nStill stands though - for Windows gamers with decent systems, this card punches way above its $250 price tag. Just don't expect miracles if you're pairing it with a 10-year-old CPU or trying to run it on Linux!​​​​​​​​​​​​​​​​",
      "I'd say $300 is top-dollar for one.  If I needed a GPU I'd pay that for one but with gritted teeth.  I picked up my LE in a package deal but it ended up being a little lower than MSRP thanks to the package deal (basically GPU plus PSU at retail with $5 off so not a significant discount).  \n  \nWhen I got mine there was no news about VR compatibility so I picked one up just to play around with it.  VR is a no-go, sadly, but the overall gaming performance is incredible for what you pay and the people whining about CPU overhead need to quit riding the shaft of that Australian YouTuber--if you're pairing it with a CPU that predates resizable BAR (despite becoming an option in later BIOS revisions) you're going to have a bad time.  If you've upgraded in the last \\~5 years you're fine.",
      "Best Buy. Had to setup a price watcher to ping their website every 30 seconds.",
      "It works fine on linux as well.",
      "Google tells me that a $130 CPU is more than adequate for the B580. Certainly, my 5700X is absolutely fine, and it’s a three year old mid-tier part.",
      "I would agree with this if I could find a B580 at $250.",
      "I have a 5 7600 with the b580\n \nNo issues. From Denmark so had to pay more for it. \n\nWhat i got was the steel legends b580 and was the exact price or a 4060. \n\nMostly great experience.\nDont wanna say everything is a gpu issues but had very few issues here they are\n\nTarkov.\nTarkov on everything high expect texture quality on medium i have around 160 fps.\n\nWhen texture quality high i have about 20.  But if that is a driver issue game issue or something else i dont know.\n\nStar Citizen. (I know very unreliable game).\n\nHigh settings with some stuff set Medium.\nHad around 55 lows maybe 30 fps in new babbage.\nEverywhere else including lorrewille i had 60+ fps at all times \n\nIndiana Jones.\nStopped playing at the snake lvl cause im a pussy.\n\nHad great fps with settings high+ with xess.\nOnly problem i had was pop ins here and there.\n\nGood card i love it.",
      "Driver stories are not ancient history. Of course modern games would have Arc GPUs in mind. But still some legendary games like Forza Horizon 3 cannot even be played.",
      "There is a workaround for the Arkham Knight device detection issue, via .dll swap. This worked with my A770.\n\n\nhttps://www.intel.com/content/www/us/en/support/articles/000094465/graphics.html\n\n\nI don't own Detroit:BH, but the game has always been a compatibility mess on Arc. There were driver revisions that did finally allow it to run (albeit not well), but I'm pretty sure those branches also predate Battlemage.",
      "Arkham Knight has a built-in killswitch of the sort: \"if detecting Intel GPU, kill process\". It's the game's fault, not the driver.\n\nUse DXVK to bypass it.",
      "As long as you don't have an ancient CPU you'll be fine, 5\\*\\*\\* AMD does perfectly fine and 10th generation Intel will be enough with 12th generation giving a boost particularly in percentile lows.",
      "Thanks “person who contributes nothing of value”",
      "It’s absolutely fine with my 5700X, a three year old mid-tier CPU that costs US$130. I know money is tight for most people these days, but that’s half the cost of the GPU.",
      "Every Game Pass PC title I've tried runs flawlessly on the B580. Most mainstream games perform great.",
      "VR is something a lot of people have complained about around Arc, but I just recently set up PCVR for my younger sibling with their Quest 2 and A750. \n\nall it required was installing ALVR, making sure the OpenXR runtime was set correctly (it is by default iirc) and then SteamVR will run fine.\n\nfrom what I understand, ALVR is what bridges the connection between your GPU and headset streaming platform. It handles all of the encoding and transformation work to get SteamVR or whatever the Oculus software is to have your GPU not blackscreen. \n\nOnce ALVR is running, it'll launch SteamVR automatically, and you can open up a game to play. It just runs. ALVR also gives you full control over encoding settings and framerate and a bunch of other nice little things to get your video stream looking correct.\n\nI swear i haven't been sponsored lmao ALVR is open source anyways\n\njust try it, VR on arc is thriving 🙏🙏"
    ]
  },
  {
    "brand": "intel",
    "generation": "battlemage",
    "tier": "580",
    "matched_keywords": [
      "b580"
    ],
    "title": "My GTX 1080 shorted itself after 8 years, so I upgraded to B580.",
    "selftext": "",
    "comments": [
      "Got the card for around $270. I was playing Dota 2 when my PC suddenly shut down. I initially thought it was the PSU or motherboard, but it turned out to be the GPU. The motherboard and PSU were preventing power draw as a safety measure. When I tested my GTX 1080 in another computer, it exploded—lol.\n\nI was considering getting a used 6700 XT (it was cheaper than the B580) and this card. But after some thought, I decided to go with the B580 because, even though my PSU is platinum-rated, its wattage is relatively low.\n\nAt first, I had an issue where my PC wouldn't boot and just showed three underscore symbols. I fixed it by converting my boot partition from MBR to GPT, disabling CSM in the BIOS, and enabling Resizable BAR.",
      "CPU: Ryzen 5700x  \nGPU: Asrock Challenger B580  \nMotherboard: Asrock b450 fatal1ty ITX  \nPSU: Corsair SFX SF450 Platinum  \nRAM: ADATA SPECTRIX D35G RGB DDR4 64GB (somehow very cheap)  \ncase: SGPC k49\n\nStorage: 1tb nvme ssd (Samsung 980 pro I think), 2tb SATA SSD.  \nMonitor: ViewSonic 1440p 170hz VX2780.",
      "Actually 47% faster (per TechPowerUp). Not to forget that GTX 1080 was a top tier card with $600 MSRP on release (probably around $1000 considering inflation).",
      "solid ass case, stickers included",
      "I’m gonna need you to tell me where you get those stickers",
      "Nice!! I like your build!! What are your specs and case??",
      "I'm glad it worked out for you. That looks like a nice small case that can actually fit a GPU.",
      "My 1080Ti also took a crap and is getting upgraded to a B580.",
      "I got mine for around $500 if I remember correctly. It was a Zotac 1080 Mini.",
      "I was rather thinking about AMD or NVIDIA cards from the 4000 series. I faced a similar choice and went with the RX 6700 XT, since I considered not only new games but also older ones.",
      "I have a 500w and it’s been fine for me. 3700X cpu",
      "Goated stickers my guy! Kessoku Bando ftw",
      "have you tried searching \"your game\" + b580 benchmark on youtube?",
      "You also get slightly more memory, plus RT and ML accelerated upscaling/frame generation.",
      "What is the name of that case",
      "Your case to gpu ratio is making me feel uneasy.",
      "Im new ITX lover cant wait to make my PC full intel with Arc celestial and nova lake S!",
      "SGPC K49",
      "Very nice, makes me want a sff pc",
      "No, you need an sfx psu. Couldn't find any <10L case that support an ATX PSU on the r/sffpc [master list](https://docs.google.com/spreadsheets/d/1AddRvGWJ_f4B6UC7_IftDiVudVc8CJ8sxLUqlxVsCz4/edit?gid=0#gid=0)."
    ]
  },
  {
    "brand": "intel",
    "generation": "battlemage",
    "tier": "580",
    "matched_keywords": [
      "b580"
    ],
    "title": "Returned 4060ti and got a B580 ",
    "selftext": "Recently built a new PC in December with a Ryzen 5 7500 on AM5 and 4060ti. Couldn’t find a decent deal used so I got a new 4060ti at Walmart around $455 after taxes. Way more than I wanted to spend. \n\nWas bummed B580 was sold out everywhere but set Newegg to notify on restock and snagged an ASRock B580 Steel Legend last week. Went with someone else’s “over clock” settings and performance is close enough to my 4060ti. Super happy with the $159 I saved after taxes - even if I might’ve left a little performance on the table. I’ll pass this card to my son if Nvidia or AMD come out with anything more compelling this year. \n\nStill working on cable management and the trinkets in the case will probably replaced. ",
    "comments": [
      "Get a GPU stand / bracket.\n\nIt's sagging already.\n\nMay cause further issues later",
      "From a 4060ti to a b580 its a bit of a sidegrade, but considering the amount of bucks saved there while getting more vram and the same performance, its absolutely worth it.",
      "Ordered lol. This GPU was much bigger than the 4060ti it replaced. I wasn’t expecting it.",
      "Also an option, you seem to enjoy figurines, find one the perfect size and use their head or shoulder!",
      "In 1080p*\n\nDont forget that monitor/display are least upgraded part, at leat least focused on upgrades so you might find people getting display in excess of current setup but ready for future. 1440p 4060 just dies",
      "you'll likely end up with better performance LOL",
      "Loving the aesthetic! :)",
      "I'm kinda surprised, the sparkle came with it's own sag stand didn't realize the steel legend and other 3 fans might not.",
      "That’s fine. I don’t really care to split hairs about the loss in performance when it’s mostly imperceptible without an FPS counter. I’d rather save the money and have more vram for the future. Money isn’t an issue - I made $150k last year as a hospital RN in California…but I just like a good deal. It’s the remnants of my childhood being broke getting second hand clothes all the time lol.",
      "I have a Sama case, Sama CPU cooler and the modular PSU from Newegg. No problems so far. PSU is almost inaudible even while gaming. I love the case I got with the wooden slats and it included  4 ARGB fans too.",
      "It's actually a downgrade unless you have a high end CPU to pair with it, b580 has less performance than 4060 if they both are paired with 7600",
      "congrats, ultimately dispute maybe raw performance what matter is longevity from a vram perspective and ability to use new gen features like ray tracing. In this case the rtx 4060 ti fails and the B 580 succeeds. (have both rtx 4060 ti is great for mining but terrible from a gaming stand point, the b580 has been nice in my system for daily use)",
      "I love the Lego McLaren F1 car. I have that exact set and might put it in my pc lol",
      "My man",
      "Great GPU choice, poor Team choice... Forza Ferrari.\n\nThis year is our year.",
      "Oooh nice, thats the same model that I’m waiting on",
      "Thank you 😌",
      "I have women trapped in my case 😆😆😝",
      "I had to buy two of them. When did you see a team with a single car 😅. Tiny enough to not be considered a man child, but big enough to satisfy that Lego itch",
      "The problem is you can't really know in a lot of cases. For me I identified it in retrospect, after unintentionally fixing it.\n\nHad a 3070ti for 2 years so far. Zotac Holo Amp. It's massive. It's been sagging from the start.\n\nI've been having more and more issues with sudden BSOD (like 2-3 times a fortnight) and screen randomly flashing black for a split second whilst i'm using it.\n\nI just happened to be buying a gpu bracket because i saw it on sale at a shopping website. Did not even realise these issues could be linked. I was actually thinking it was a PSU problem.\n\nSo when I installed it 2 months ago, the computer was left on. I mean, it's just pushing the gpu up in a non-conductive, non-moving area, what's the harm? But whoah, when I did that, the computer went into a BSOD. In other words, my just slightly touching / lifting the GPU actually triggered a BSOD.\n\nThat's one of the first clues leading to me realising that the sag had probably tugged the GPU out over time and pcie contact was getting iffy especially when the gpu fan was moving causing tiny vibrations.\n\nHaven't gotten a BSOD or black flash since the bracket was installed.\n\nThe massive weight and sideways strain probably wasn't doing the pcie socket any favours either.\n\nOne day when I muster enough energy I may reseat the GPU (since I never did that even after installing the GPU bracket), but that's the story of how I found out about GPU sag issues."
    ]
  },
  {
    "brand": "intel",
    "generation": "battlemage",
    "tier": "580",
    "matched_keywords": [
      "b580",
      "arc b580"
    ],
    "title": "PC World just gave ARC B580 «The Full Nerd award» for «Best GPU of 2024»",
    "selftext": "",
    "comments": [
      "I love that PC World shout out:\n\n>Worst trend: The enshittification of everything\n\nGoogle, Meta, Microsoft, Twitter/X - pretty much all of their software has become unusable garbage, where the only part that still works is the ads. As if they could pull off anything on their user's back. Their users will move to better alternatives, and soon they'll realize that they have no power at all.",
      "Although I don't fully agree with them, I do rejoice in the progress that the Battlemage has made.",
      "I said something similar to this to friends \n\n\"We haven’t seen a $250 graphics card this compelling this decade – you’d need to go all the way back to the halcyon days of the GTX 1060 and Radeon RX 480 to find a budget GPU with a value proposition this strong. In a weak year for graphics cards, Intel’s surprisingly great Arc B580 stands out.\"",
      "Battlemage is still not friendly to old systems and the majority of inexperienced PC users.\n\nTake a look at this subreddit. Since the B580 was launched two weeks ago, so many new adopters swarmed here asking for help mostly because they are using an older PC and take the B580 as an upgrade for their old GPU, but I really don't agree that Arc GPU is a good option as an upgrade for older systems.",
      "Just out of curiosity, what points do you disagree with them on? I'm getting my B580 on Saturday and I'm looking forward to it, I have seen a mix of opinions on here though.",
      "Man, this is how I feel about it. Like everything is just gargage. Windows 11, Android, Google search, Office 365, Youtube etc. They all had thier sweet spot before and pandemic but now two years after and it all feels a lot worse than fifteen years ago. How could they fall so hard?",
      "It is unfortunate because it’s probably scaring off a decent amount of people when they see others are having issues running it on older processors. Intel isn’t hiding anything though, it says the minimum CPU to run with it right on the box, it’s 10th gen Intel or newer, or ryzen 3rd gen or newer, with a MB that has rebar support.",
      "I consider the 4070 Super and the 7900 GRE both to be fairly incremental nothing special cards. They replace what came before them with at a slightly better performance and slightly higher price point. They might be decent cards, but there is absolutely nothing special about them. \n\nMeanwhile the B580 jumps into a budget category that has been unoccupied for years and makes a really good card. It is night and day better than its direct predecessor, especially comparing launch date to launch date. \n\nAnd it is made by the underdog 3rd party but still manages to threaten BOTH other brands. It threatens AMD's hold on the low-end, and it threatens Intel's hold on the not-just-gaming segment. \n\nIt isn't perfect in all ways, but it is absolutely the best in its weight class. It is absolutely the most improved. It is absolutely made the biggest mark on the industry as a whole. \n\nI don't think it is just the best card of 2024, I think it wins at least for the past 5 years, and might win card of the decade. (Although that last one has some tough contenders.) \n\nFor best card of the year? I think its Michael Phelps vs a high school swim team alternate. I don't see that there is any real competition, much less another card that takes the title.",
      "MLID can cry all he wants, but it doesn't change that this GPU is a great card and will see massive future gains when drivers are in a better state.",
      "Props to you for including office 365 in there.\n\nMicrosoft managing to turn a decade old software into a subscription based system without any major update to it, it’s baffling.",
      "Tom is busy organizing redacting plan atm, Can't really trust a guy who make living by profiting someone else breaking their NDA",
      "Which GPU do you think should have been given the award instead?",
      "Not really. It's just because there are still some disappointments with B580 for me as a 2-year Arc A770 user. I do agree that B580 has shown plausible improvement over the Alchemist (performance, efficiency, etc.,) but several issues that were much complained about the Alchemist remain unchanged on the B580.",
      "Now that clarified everything. Thanks for detailing. I also feel the same about point 3 and 4 of your list of disappointments.",
      "Awesome!",
      "i wouldn't, thats like a sidegrade, maybe wait out a little bit more and pray for b770, however ur money ur choice if u can find it well priced and you really want it then no one is gonna stop you",
      "Google has been steadily worse once they became a publicly traded company. It took a few years for it to start but that need for the line to keep going up ruined all their goodwill they developed over the years.",
      "yup, now they will gut the publisher. also used onedrive a lot but now it is more and more cluttered with nonsense.",
      ">I consider the 4070 Super and the 7900 GRE both to be fairly incremental nothing special cards. They replace what came before them with at a slightly better performance and slightly higher price point. They might be decent cards, but there is absolutely nothing special about them. \n\nAgreed, the 7900GRE had a little bit more headroom for overclocking than the rest of the 7000 series and the 4070S typically had a little bit of a better price to performance ratio than the rest of the 4000 series, but neither of those things are on the same level as what Intel did with the B580.",
      "YES! I Have one and am happy as can be. Definitely earned that title."
    ]
  },
  {
    "brand": "intel",
    "generation": "battlemage",
    "tier": "580",
    "matched_keywords": [
      "b580",
      "arc b580"
    ],
    "title": "SPARKLE Intel Arc B580 TITAN OC Unboxing",
    "selftext": "",
    "comments": [
      "BENCHMARKSSSSSSSS",
      "Congrats. You got featured on videocardz.  \n[https://videocardz.com/newz/first-intel-arc-b580-gpu-ships-to-gamers-before-launch](https://videocardz.com/newz/first-intel-arc-b580-gpu-ships-to-gamers-before-launch)",
      "I've always dreamed of a blue graphics card. Here you go, I picked up today.  At the same price, I could have bought an RTX 4060, but I decided to join the testers of new technologies. It's a 2.2 slot design so it will fit perfectly with the Lian Li DAN a3-Matx.",
      "They'd need to track down a copy of the .6239 or .6242 drivers, which isn't likely as the only folks who have those are bound by NDA. :c",
      "I ordered on Saturday, received today. I am also surprised.  I guess the drivers for the ARC B580 will be available from Friday, December 13?",
      "It's relatively cheap tho. And it has great cooling, so whatevs",
      "Guess they missed mine",
      "Can you benchmark it already? Dont get me wrong but we all want raw performance benchmarks",
      "why are they blueballing us?",
      "Drivers won't be released to the public until Friday",
      "How did you buy it before launch?",
      "Can you post benchmarks ?",
      "No he can’t because there is no driver available, also got mine from retail and can’t use it",
      "There's always Linux ... ;)",
      "What's idle power consumption?",
      "Yeah my sparkle A770 titan oc is a gorgeous card very well built",
      "Nothing wrong with overkill cooling. Just means the card will be cooler running, and longer lasting. Looks really cool too. Also, it makes me wonder about a hypothetical B770/B780. Perhaps AIBs are reusing coolers intended for those.",
      "Ok, hopefully someone else will.",
      "Could you send me the lottery numbers since you're already in the future?",
      "No drivers. It won't run well"
    ]
  },
  {
    "brand": "intel",
    "generation": "battlemage",
    "tier": "580",
    "matched_keywords": [
      "b580",
      "arc b580"
    ],
    "title": "Intel announces Arc B580 at $249 and Arc B570 GPUs at $219 - VideoCardz.com",
    "selftext": "",
    "comments": [
      "It will probably also be around $500",
      "Intel is claiming that the Arc B580 is 10% faster than the GeForce RTX 4060 at 1440p\n\nhttps://cdn.mos.cms.futurecdn.net/9C9zEHTPExVJYkeAFNbvg-1200-80.jpg.webp\n\nhttps://cdn.mos.cms.futurecdn.net/42zbBqpa3CtyBcgp7fjw9n-1200-80.jpg.webp",
      "B580 for $250 sounds reasonable if the rumored spec is true, B570 feels like only exist to upsell B580.",
      "i think it is just there for the part defectly B580 chips.\n\nSo u can still sell those chips.",
      "And the scariest thing it will probably only have 8GB of VRAM",
      "I think that the pricepoint and VRAM amounts are definitely interesting.\n\nThe A580 looks really promising whereas the A570 may be a deal once it hits a sub 200 dollars street price.\n\nLet's see how the perform, Xe2 has been working great on Lunar Lake.",
      "4060 was also barely any faster than the 3060 and straight up tanks if vram limited (which can happen even at 1080p whereas a higher vram card can allow maxed out texture)",
      "did you write A when you wanted to write B?",
      "This looks like a pretty good deal and a real 3rd option to budget PC builders/buyers out there.\n\n12g of vram on a $250 card is pretty good.\n\nWaiting to see real benchmarks. I hope one day Arc GPUs can match 70-80 series nvidia performance, I might really consider going a full intel build for fun.",
      "It is also rumored to have 8GB of VRAM which will most definitely kill performance in modern titles",
      "This would have been impressive 2 years ago.",
      "No, Intel is claiming that it is 24% faster than the Arc 750 and 10% faster than the GeForce RTX 4060 at 1440p\n\nhttps://cdn.mos.cms.futurecdn.net/JasQiFARCQoPfWhn25V2Sm-1200-80.jpg.webp\n\nhttps://cdn.mos.cms.futurecdn.net/42zbBqpa3CtyBcgp7fjw9n-1200-80.jpg.webp",
      "Intel is claiming 10%, not 32%\n\nhttps://cdn.mos.cms.futurecdn.net/42zbBqpa3CtyBcgp7fjw9n-1200-80.jpg.webp",
      "Yes, the B570 might look weird at first blush, but it's there because of binning. And I suspect, like others, it'll drop in price to make the segmentation make more sense on the street.\n\nI only wish the power was down more.",
      "The 7900XT to B580's 7900XTX",
      "Its like 15% faster than the 7600 tho",
      "\"rumours\" this early are usually a bunch of nonsense and guesses. RTX 5060 won't launch until much later into 2025, the xx60 card has historically been released quite a few months after the top end xx90 and xx80 cards. So it's not gonna be relevant until maybe Q3 '25. Until then, B580 is exciting for the lower end market. It's cheaper, faster on average, more VRAM, better than AMD on the software side.",
      "Not by that much though, cheapest I found was 249 for the RX 7600 which puts it in a similar spot but with 12GB VRAM.\nHonestly it mostly depends on driver / software support because at the end of the day there is no reason to go for the Intel card currently unless it's significantly more raw performance / price",
      "I like your funny words, magic man",
      "It fills a gap in the market, it’s fine now"
    ]
  },
  {
    "brand": "intel",
    "generation": "battlemage",
    "tier": "580",
    "matched_keywords": [
      "b580"
    ],
    "title": "A770 at 109fps, but this B580.... ",
    "selftext": "",
    "comments": [
      "I'll wait for a 770 to come out. I have the A770 and see no reason to jump yet",
      "I really hope we get to see the B580 being sold at 250 - 260 euros here in Europe. Last price tag I saw was around 332 euros. I don’t understand that pricing.",
      "That 40% increase almost makes it worth it to upgrade from my A770.\n\nThe charts I've seen make it look like they are neck and neck in some games, and the B580 stomps it in others.  I just want to see how it does in Helldivers 2.",
      "It's not going to be 250-260 due to tax being around ~20% in most EU countries. But it shouldn't be more than 290€ after currency conversion + tax so I don't know why they're so expensive currently.",
      "Looks good but should have linked the whole video I’m sure it’s drivers needing optimization but it’s a bit all over the place still. I want to know if there’s going to be a B770. Also AMD has new mid level cards coming too . Nvidia is in lala land with their pricing still but those leather jackets won’t pay for themselves 😂",
      "I am also a 1080p gamer. It's all my monitor does and I am happy. I am waiting because I have an A770. If I had something worse, I might rethink that",
      "Same. Wait until B770 comes out. It'll rock the GPU market.",
      "3060 12gb can perform better in certain titles because it has higher memory bus bandwidth than the 4060, and also 4 more GB of VRAM.",
      "Only for the one generation. If Intel goes down AMD and Nvidia will just return to where they are now. Intel needs the chance to establish themselves. I want to see Nvidia especially take this seriously too late to be able to truly crush them.",
      "AMD especially considering how badly they are struggling to sell their cards compare to Nvidia but still greedy enough to price their cards so high.",
      "Depends on what games you play, but most likely no.  On average, the B580 will perform better but not to such a degree I think it's worth it, better off waiting for a B770 if one comes or for AMD's 8000 series.",
      "How tf is 3060 faster than 4060 this benchmark looks wierd",
      "Whoa that's exciting! I didn't expect that big of an increase over Arc but I'm happy to see it. Can't wait to see more benchmarks!",
      "I'm here hoping that Intel soon announces the B770 or maybe B990. If they did, then this will be a lot better! This is how they did with the Alchemist. They usually announces the lower tiers Alchemist, then announces A750 and A770 some months later. So that means, we have to play the waiting game.",
      "male sure to post feedback. We never see HD2 stats and for me right HD2 is the only one that matter",
      "Ahhhhh. I am tempted to trade in towards a new camera lens or a NAS.",
      "If the B770 came out, nobody would buy anything else.",
      "> the b580 is a slap in the face to Nvidia and AMD to wake them up\n\nMy biggest concern is if they \"wake up\" they will likely crush Intel.",
      "There will be no B970 / B990. Lucky if there is a 32XE B770. \n\nWe may get 64XE Celestial which should be epic seeing how much improvement Battlemage is.",
      "Just wait. Even if you end up CPU bound it's always nice to have a little extra life in your GPU. 8 gb is killing mine earlier than I'd like."
    ]
  },
  {
    "brand": "intel",
    "generation": "battlemage",
    "tier": "580",
    "matched_keywords": [
      "b580"
    ],
    "title": "Finally uprading my RX580 to a B580.",
    "selftext": "Got mine today, though I might install it on Saturday because I want a clean install on Windows unless I find a good guide on how to remove AMD drivers properly 😅",
    "comments": [
      "Your upgrade path intrigues me. Please don’t upgrade again until the PTX580.",
      "just use DDU to remove AMD drivers",
      "GTX580 next?",
      "I like how this upgrade actually makes sense",
      "Based Yuru Camp enjoyer👌🏼",
      "This worked, installing drivers now. Thank you!",
      "If you have an amd cpu, please reinstall the chipset drivers also. DDU removes them in addition. I think there might be a setting to keep them but I wouldn’t trust it.",
      "Nah bro, I heard the ZTX580 is supposed to rival the highest end 5090.",
      "7500f",
      "Tremendous upgrade!",
      "The 580 man!! Congratz with your upgrade!",
      "Hell yeah budget bros unite",
      "I used DDU and everything is working fine as of the moment. I'll try and test it more when I get free time.",
      "why is this thread getting down voted XD",
      "ZTT580?",
      "Just to give you an example. My games used to get fps issues when I had my browser open (hw acceleration). Prime video used to glitch every 10 minutes causing noise frames etc. I thought my GPU is dying. DDU is a great tool but it only cleans the driver, not the software that got used to them. And then there is windows update that can mess everything up after the fact.",
      "isn't 7500f essentially a 7600 with no iGPU? 7600 works great for the b580",
      "Hell yeah",
      "Thats sounds like an awesome upgrade ! Have fun !",
      "If you run into any issues please still consider a clean install. I had so many weird driver issues in the past from not doing that!"
    ]
  },
  {
    "brand": "intel",
    "generation": "battlemage",
    "tier": "580",
    "matched_keywords": [
      "b580"
    ],
    "title": "Picked up an open box B580 Sparkle for $239. Should I keep it?",
    "selftext": "So I’ve been going back and forth. Ordered and cancelled a few prebuilts. I hate overpaying. \n\nI hopped in to Microcenter this morning and they had this B580 marked at $239. Open box but complete with full return policy and warranty. I’ve done a little research but I’m not sure if it makes sense for me. \n\nI grabbed the 7600x bundle for $279. So I’m around $500 for everything in the picture. \n\nI only play iRacing. Currently have a 970xt with a i5-6600. Assuming this would be a nice upgrade from that ancient set up?",
    "comments": [
      "You should sell it to me :) \n\n\n\nJk that’s insane definitely keep it! Amazing find and enjoy it 🫡",
      "Not unless you want to pay 3x as much for an equivalent card.",
      "I'M ORDERING YOU TO KEEP THAT GPU.\n\nYou are one of the few unicorns that managed to get a Arc B580 around MSRP, and on top of it, you got a platform that is a big upgrade to what you're currently using!  Did you find a crop of four leaf clovers each one the size of a California redwood by any chance?",
      "Probably, is it worth spending that much more money?",
      "Keep it, nice buy",
      "It'll be a massive upgrade over your 970. It's on par with a 4060 I think",
      "That’s what I’m realizing. I love bang for the buck products. I feel like with the insanity going on right now a 5070 is the only other card available at MSRP. Would a 5070 get me almost double the FPS?",
      "10% more than a 4060 on average",
      "I would pick up a second stick of that ram. It’s 40 extra dollars and you will be leaving a bunch of performance o on the table if you are only running single channel.",
      "I would go with the 9070 XT and get the 5080 performance for cheaper. But the B580 is a good card.",
      "That’s fair but he already has the b580 and for less than msrsp",
      "What kind of question is that? 🫠 I’d keep it.",
      "Definitely keep it. I would at least I got my sparkle titan for msrp and after tax it was 300 soyou got the best deal I've seen yet. Forewarning, someone probably returned because of the coil whine. It's kind of a lottery with the coil whine. Put heavy load on it and coil whine will eventually go away. Or maybe they just opened the box and never installed it and you have a brand new gpu for a great deal either way you can always return it if something is wrong with it.",
      "💀💀I got mine for 328$ after tax",
      "An almost complete 1440p system for 500,-, should you keep it? Ofcourse! You did good 👍",
      "UNDER msrp in fact. I'd keep that thing for the next 10 years probably",
      "Thanks. I’ll pick one up",
      "Likely, but goodluck finding an msrp offer. What games are you planning on playing? B580 should be fine for almost all, not super great at 4k, but it’s strong point is 1440p",
      "I just got the same bundle and did the same. Especially considering am5 is getting at least 1 more generation it seems to be a good opportunity to build now and get a future upgrade.",
      "GTA v,fall guys,pal world, fortnite, cyberpunk, dark souls, terra tech and some other stuff. Honestly I love the card before I was rendering every game at like 720p or lower on the lowest settings because I was playing on integrated graphics with a 5700g."
    ]
  },
  {
    "brand": "intel",
    "generation": "battlemage",
    "tier": "580",
    "matched_keywords": [
      "b580"
    ],
    "title": "B580 everywhere?",
    "selftext": "Its just me or all I see is people buying b580 like crazy.",
    "comments": [
      "It's not just you, it's the top pick for budget builds for a reason~",
      "This and 9070xt",
      "This sounds like someone that hasn’t actually ever used a B580.",
      "I wish I actually see more of the intel limited variants, since the current line up of B580 mostly look so ass.",
      "Yeston ples make waifu edition card!",
      "If you can afford a 9070 I don't see why you wouldn't",
      "Right now, at least where i live, is now down to almost msrp and with enough stocks, that's why i'am quite tempted to cancel my preorder of the 9070xt even if it is at msrp",
      "Because i'am coming from a 9 years old gpu, anything would be a massive upgrade, and with the same money i could jump from am4 to am5 platform, or get a better monitor and so on",
      "Must be an application specific thing. Lots of professional programs have no support for it because nvidia and AMD still heavily dominate the professional side while intel is damn near making up a double digit percentage of the new gaming card market.",
      "Y'all are both being toxic tbh",
      "I just got my 2 days ago",
      "I sold it to get a RX 9070",
      "Yes, it even outperform A770 in most scenario",
      "I find this funny because on the AMD subreddit you see Nvidia people saying the same thing and also getting downvoted. I'm sure there are still plenty of little things because Intel is so new to the GPU game but is definitely mostly stable. The amount of user error being deemed \"bad products\" is hilarious.",
      "I had one didn't like it, wasn't compatible with some programs that I frequently use so I sent it back and got the 7600 XT instead 🤷‍♂️",
      "I got my 7600 XT for $229 on Amazon about a week ago. Had it on a tracker to notify me when it went on sale.",
      "Naah I definitely prefer it the way it is",
      "Boy I'm glad that I've sent the GPU back now. The Intel fan base sure seems toxic. I told you what my personal issues with the card were and that's that my guy. 😁",
      "Well, basically it is the decently priced alternative for mid-level performance and for secondary computers, just have had mine for couple months and for good time since my 3080 build decided to be not working properly (still troubleshooting) but the B580is basically up to anything I need after I paired it with 11900KF.",
      "Yeah Nvidia got consumer gpu situation so bad it's actually acting as an advertisement for competitors. Apparently it works too good that there is no stock of either of them 😭😂"
    ]
  },
  {
    "brand": "intel",
    "generation": "battlemage",
    "tier": "580",
    "matched_keywords": [
      "b580"
    ],
    "title": "Is it time to leave Team blue? Seriously considering selling B580.",
    "selftext": "Now that the hype has died down and I've had about 2 months with this card, I am debating selling it.\n\nLast night, after Warzone crashed AGAIN, I'm at wits end with PC gaming. Every single time I play Warzone it crashes at least once mid game. When I look for solutions, the first thing everyone says is \"Sounds like it's your GPU since most games are optimized with Nvidia in mind\". I have frame rate issues with Delta Force. Other games seem to work well. \n\nI'm running 1440p High settings for both. I just don't like these random issues. I listed my entire PC for sale and might go back to Xbox but maybe as a last resort, I try to go team green and see if these issues go away.",
    "comments": [
      "They're not \"optimized for Nvidia\". They run just fine on AMD. But usually they're indeed, not especially optimized for ARC, unless Intel puts in the work",
      "pretty sure warzone has been bad for a while with arc cards. like, the worst performing game.",
      "How much ?",
      "https://github.com/IGCIT/Intel-GPU-Community-Issue-Tracker-IGCIT/issues/1074\n\nhttps://github.com/IGCIT/Intel-GPU-Community-Issue-Tracker-IGCIT/issues/890\n\nBoth seems to be known issues.\n\nGreen team has tons of issue since Blackwell launch btw.\n\nhttps://www.tomshardware.com/pc-components/gpu-drivers/game-developers-urge-nvidia-rtx-30-and-40-series-owners-rollback-to-december-2024-driver-after-recent-rtx-50-centric-release-issues",
      "I agree with the sentiment but it should be able to run codslop if they want to play codslop. Slop as it is it's still a huge game that should be a priority to have not crash at least.",
      "Well if u were able to upgrade to a 5080 then the b580 wasn’t meant for u anyway",
      "Only warzone Crash ?",
      "Everybody listen up. It's his Ram 100% guaranteed! That game uses way more RAM than it should of course only during spikes but that can cause crashes and is the most common cause for crashes in that game also there's a good chance something is wrong with his Ram also leading to the game crashing. Get a new set of ram go for 32 gig at least 3200 MHz if not more. Report back in a few days I'm sure that will fix your problem. I know it's not your card because I have several arc cards in my house that play the game with no problem including the b580 in my PC. The only issue that was had was on one computer that had the same problem as you and it ended up being the ram.",
      "Ahh sorry the gpu only.. but not in the US. Good luck and It's sad for the troubles.",
      "Your going to try to sell a b580 build for $1300 used?",
      "I just left team blue because they didnt have anything higher announced coming out any time soon. I upgraded to a 5080 and loving it. But reason im replying is because with nvidia warzone has crashed on me like 5 times so far and its only been warzone. It just freezes and saying it encountered a directx error. Just mentioning it because im thinking the issue is warzone and not intel.",
      "Seems like a hassle ngl",
      "I mean is only warzone Crash or the pc",
      "Drop the specs, yes, it seems like consoles are a better fit for you.",
      "Are you telling us or convincing yourself of this? Your hardware does not magically gain value because of your “labor” putting it together, that’s so ridiculous it’s funny. Computer parts LOSE value once you open and use them, not the other way around.",
      "This comment shouldn't even be upvoted...like at all. OP should be able to play whatever they want. Especially a game that's optimized to run on ancient potato hardware.",
      ">They run just fine on AMD\n\nActually I believe warzone is having issues on AMD 7000 cards atm",
      "Yes. Basically I only have issues with two games I have played thus far: Warzone and Delta Force. I have other games I want to try soon such as Assesto Corsa and Ready or Not.",
      "Hear me out. Before selling the card, if you buy another gpu you can run dual gpu's in your computer using lossless scaling\n\nThe Intel gpu can be the secondary gpu being used for frame generation up to 4k 180fps (assuming base fps of 60)\n\nThe primary gpu only needs to be able to run games at 60fps.\n\nLook up dual gpu lossless scaling on YouTube, it looks incredible, and the input lag is half of what DLSS 4 has.\n\nYou can always sell the card off after if you don't like the idea of it or need the money\nBut if you're planning on getting another gpu anyways, I would highly highly recommend trying this.",
      "I just priced most of those items on pcpartpicker canada. USD has a 1.4-ish exchange rate. I’m getting about $1600 for all the parts. New. In Canadian dollars. Of course there are taxes on top of that. But since you are American, that works out to be about $1142USD. For new parts. I assumed no name 2TB SSD, the cheapest 750W Corsair psu I can find, and the pro version of that case.\n\nSo yeah, I think $1300USD is a bit high."
    ]
  },
  {
    "brand": "intel",
    "generation": "battlemage",
    "tier": "580",
    "matched_keywords": [
      "b580"
    ],
    "title": "Why is my B580 showing 7.84 GB VRAM with new update?",
    "selftext": "",
    "comments": [
      "sorry needed to borrow 4gb",
      "Just updated BIOS, rolled back to a previous Intel Graphics Driver twice.\n\n  \nStill 7.84 GB VRAM.\n\nAny suggestions on how to fix this?",
      "Uninstalled all drivers. And started from scratch, when installing drives, the screen flickers and then goes permanently dark every time. So i must hard reset the PC.\n\nStarting to lean on a hardware failure here..",
      "Be sure to edit your post with a fix if you find one\nYou'll never know who will end up coming to reddit in 9 years looking for that one guy that had the exact same issue as you\n\nYou are the one guy 😂\nIf it ended up being hardware, update it anyways",
      "It's been 8 hours, give it back!",
      "B580 automatically became a580",
      "Someone out there has the 16gb version now😂",
      "wth",
      "Sounds like you have a bad RAM module or memory controller. The black screen after the driver recognizes the card is a dead giveaway. Have you tried using any other display ports when the card lost signal? Try disabling rebar and shutting down and then powering back on and re-enable it? Could be some weird Battlemage glitch but honestly sounds like a hardware failure. Also, the drivers are known to flash the bios on the cards too. I had a A380 die from a driver update. Worked totally fine until my kiddo updated the drivers and it just stopped working.",
      "Actually might be good advice. If linux shows 8gb - it is faulty. It uses different driver mesa. Id rma it if linux showed 8gb.",
      "No that would just kill the card since data is stored across all ram chips equally",
      "So, after a clean install of windows 11, formated the drives.\n\nDDU in Safe mode, installed previous graphic drivers that i know worked also in Safe mode.\n\nThe GPU-Z / Taskmanager / Delta Force still shows 8 gb of ram.\n\nAlso, now Intel Graphics Software does not work at all?\n\nThis HAS TO BE a hardware problem and not a software problem. After 10 hours of trying to fix this im done. Will contact support tomorrow.",
      "Device manager if applicable disable onboard /cpu gpu ?\n\nMake sure features in bios are enabled\n\nhttps://www.reddit.com/r/IntelArc/s/rNbmL8oGyY",
      "Ddu , uninstall any remaining intel software, download latest drivers, reboot, again run as admin and install drivers, reboot after.\n\nI had to reinstall/ddu a few times to get some stuff working unrelated to yours\n\nCheck gpuz in case intel is just wrong",
      "The other 4gb ram left to buy milk",
      "Yes, i noticed it while playing Delta Force, that the fps was lower and the VRAM said 8 gb which started my investigation.\n\n  \nGPU-Z also states the memory to be 8192 MB....",
      "On board graphics is disabled and Rebar is on per BIOS",
      "Does GPU give any warning that the gpu is fake or anything like that? Maybe someone somehow managed to flash a A580 or something to B580, swapped cooler and sold as B580. A bit far fetched but who knows maybe. Can you share GPU-Z screenshot so I can compare with my steel legend.",
      "Try in Linux with live CD image and some terminal command.",
      "Just to be sure, did you use DDU and in the safe mode?"
    ]
  },
  {
    "brand": "intel",
    "generation": "battlemage",
    "tier": "580",
    "matched_keywords": [
      "b580",
      "arc b580"
    ],
    "title": "Intel Arc B580 \"Battlemage\" Graphics Cards Review Roundup",
    "selftext": "",
    "comments": [
      "Nice, Intel really is in the game right now, hopefully B770 will come pretty soon. \n\nIf not, I seriously hope they don't axe the desktop cards right now, Celestial should be pretty amazing.",
      "It's a good start, priced competitively, looking forward to what B770 has to offer, we really need competition in this unfair market.",
      "Finally, a budget card at launch price that finally moves the price/performance goalposts.  We haven't seen this since the Polaris days 7+ years ago",
      "Let's see if they will bother actually competing, because their low-end GPUs were pretty meh for the last 5 years.",
      "The Arc B580 looks good compared to the GeForce RTX 4060 and the Radeon RX 7600, but those GPUs are 1.5 years old now.\n\nIf you need a new GPU ***right now*** and you only want to spend ~$250 to $300, the Arc B580 is a good option.\n\nWith new GPUs from NVIDIA and AMD coming very soon; however, if you don't need a new GPU right now, it's best to wait.",
      "Finally some good news. Intel really needed this.",
      "There are already known manifests from TSMC for G31 orders. It's obviously taped out and has been for quite some time.",
      "They respond to market pressure.\n\nIf they feel that Intel is a threat, they will respond.\n\nThat's how a market economy works.",
      "You're missing two very important puzzle pieces here:\n\n1. nVIDIA makes their money with AI and high-end cards such as the 4090, they don't give a damn about low-end anymore -> besides, people buy them anyway, look at the Steam Hardware Survey.\n2. AMD has EPYC, Ryzen and now MI series as well, cards like RX 7600 are extremely inefficient value wise for them (in terms of $/chip die), there's no big incentive for them to compete in the low-end as well - otherwise, the 7600 would have cost 229$ instead of 269$ day one.",
      "Did MLID and RGT tell you that? 🫢",
      "Can’t believe the RX 580 still costs $250!",
      ">Finally, a budget card at launch price that finally moves the price/performance goalposts. We haven't seen this since the Polaris days 7+ years ago\n\nThe Arc B580 is 15% faster than the Radeon RX 7600 launched 1.5 years earlier.\n\nFor comparison, the Radeon RX 7600 is 27% faster than the Radeon RX 6600 launched 1.5 years earlier.\n\nSource: Techpowerup",
      "Yeah so don’t buy it from scalpers",
      "7600XT launched at $320",
      "Good work intel....may your gpus sell well",
      "Bro why does that even matter your eyes can't even see above 30fps! /s",
      "Intel isn't making money at this price point. Intel is buying market share in order to mature their stuff. The reason I say AMD might not have a viable play is that, unlike Intel, AMD doesn't get anything good from fighting a price war.\n\nI don't know how good Navi44 is. Maybe I'm worried for AMD for no reason -- it is plausible they have a part that solves the problem without effort.",
      "I've read a couple of those reviews but they don't seem to mention XeSS 2 (including its frame generation and low latency options) much. \n\n\n\nIt seems Intel has yet to roll out a driver update for this:\n\nhttps://overclock3d.net/news/software/f1-24-has-become-the-first-game-to-support-intel-xess-2/\n\n>Sadly, Intel has not released driver updates for their hardware that enable support for XeSS 2. \n(...) \n>XeSS 2 will soon be available in more games, with Intel confirming that Dying Light 2, Robocop, Marvel’s Rivals, and others will soon receive updates.\n\nCould be a real game changer as I've always found XeSS better (loses less detail) than AMD FSR.",
      "I might check it out. Looking competative",
      "It is not like Nvidia is going to launch their mid-range to low end GPUs first, they will take nearly a year after the enthusiast launch before launching the low and mid range."
    ]
  },
  {
    "brand": "intel",
    "generation": "battlemage",
    "tier": "580",
    "matched_keywords": [
      "b580",
      "arc b580"
    ],
    "title": "So how is the Intel Arc B580 4 months after release?",
    "selftext": "I would love to hear from your guys' experience. Do you feel like the card is it's money worth? Do you enjoy it? Any issues you've had? Do you regret going for Intel? Are you glad you went for Intel? ",
    "comments": [
      "Bought one for my new build around 1 month ago.B580 was roughly half of the price 4060ti and 4060 is like 1.5 times. Havent had the chance to try it on many titles but  so far b580 did its job flawlesly for witcher 1,2 and 3, cyberpunk 2077, PoE 2 and DoTA 2. Not once i felt bad about my gpu.",
      "Sometimes I just feel bad that most games don't support Intel GPU or XeSS. One game I play is Wuthering Waves, this card doesn't have 120fps or ray tracing option enabled, but 4060 has it just because it's a NVDIA card. And I'm sure b580 can handle it, I want the 120 fps at least. \n\nIn MH Wilds, can't really use the framegen option with Intel XeSS. Not that I want to use framegen, but having the option would be nice. \n\nOther than that, it's fine. I can play the game I played well enough. The most demanding game I played is MH Wilds, but it's not just B580 that suffers from the game's bad optimisation.",
      "I think everyone on here will say it’s good and I’ll get downvoted for saying that",
      "It's great. No issues so far playing older games from GOG and modern AAA on Steam at 1440p. The most demanding is probably Black Myth Wukong. I can lock it at a smooth 60 fps at 1440p on medium with RT enabled. I have it paired with an i7 12700kf that I picked up on sale. I'd absolutely buy it again. No way was I willing to pay $800.00+ for a GPU or $300.00+ for a GPU with less than 10GB of vram in 2025.",
      "My 13 year Olds first build and I haven't had to do anything to help him. So flawless from a dad point of view.",
      "Nothing special ryzen 5 7600 non x no overhead so far. Also i play at 1080p so i imagine the performance would be even better for 1440p",
      "You can enable the 120fps and RT in WUWA in seconds with the DB editor. PS don't enable RT GI as performance sucks ass. With only RT reflections on high the gpu usage hovers around 60-75% in open grassy areas but in mostly reflective areas starts stuttering like crazy. Enable GI and Reflections tanks the performance like crazy and we dont have DLSS to help with the fps.\n\nIn general the B580 gets higher fps than the desktop 4060 but the 1 and 0.1% lows are worse than a laptop 4060. With custom engine.ini the stuttering is reduced but still not beating the 4060.",
      "The B580's performance in MH Wilds is honestly kind of impressive considering how hard it is to run on any card.  Wouldn't be surprised if my more powerful GPUs performed similarly in that game in particular.",
      "The overhead “disaster” is far from a disaster. The last few driver updates have mitigated the issue and it was overblown in the first place with a cherrypicked sample of extremely CPU-heavy AAA games like Spider-Man Remastered. Most games there is either no overhead or you wouldn’t notice the difference without a 4060 to compare numbers with side-by-side.\n\nYour 5600 will be fine.",
      "Hi there!\n\nI bought mine a month ago and I've been really enjoying it.\n\nI'm a casual gamer so the B580 is more than enough for 1080p gaming on highest settings.\n\nSome games have been having issues, especially the DX11 ones, but as long as they have DX12 or Vulkan variants then it's easily solvable.\n\nIt's not perfect, but I would say that it was a good purchase! Definitely recommend it for people who want to build a modern system on a budget, definitely worth the money!",
      "Nice",
      "NOBODY got banned for editing the ini and db files since launch. I have friends who uses custom skins and custom settings since the launch and not a single ban was given to them. Its only the ones that try injecting cheats bringing down the reputation if this.",
      "Fantastic card, very powerful, killer deal for $250",
      "What cpu you running? My plan was to put it in our old rig with a 5600 but after the overhead disaster idk now.",
      "I’ll be comparing my fps with my 5600x against nothing and jumping to conclusions and there’s nothing you can do to stop me!\n\nI’m getting my B580 today and can’t wait to wallow in misery due to 4fps missing that I have no way to verify.",
      "Got Sparkle Titan with 7600x3d, playing steam backlogs, very satisfied.",
      "I have found it's \"mostly\" fine, put one in my son's pc and not had major issues. There is texture flickering in hogwarts legacy and to a lesser extent in Spiderman. Other than that it's been good and for the price the performance is excellent.\nGames played: Spiderman, Spiderman MM, spiderman 2, hogwarts legacy, another crabs treasure, brotato, all orcs must die 3, Indiana Jones \nCPU:i5-12400f \nRam: DDR4 3200MHZ",
      "Not very satisfied with my B580. Obviously less progress on driver improvement than the Alchemist. Some major issues have not been resolved for quite some time already. Intel is struggling right now.",
      "I know it's possible to force 120fps and ray tracing, but I'm not gonna risk editing the game file or using third party app and getting my account banned, even if it's \"safe\"",
      "My brother bought one and paired it with the 5600 but his mobo didn't support rebar (it was a cheaper board) so he had very lackluster performance at first. Once he got a better mobo with rebar, it was night and day. He started getting great frametimes, especially for the price. He also says the encoder is great, and his clips/recordings were way better than his older RX 6600."
    ]
  },
  {
    "brand": "intel",
    "generation": "battlemage",
    "tier": "580",
    "matched_keywords": [
      "b580",
      "arc b580"
    ],
    "title": "Intel Arc B580 Overhead Issue! Upgraders Beware",
    "selftext": "",
    "comments": [
      "Already commented on the other more clickbait post. But just focusing on the actual 'issue' here with older CPUs, I agree that it should be maybe more clear but at the same time this test is with an R5 2600 when intel clearly says that the lowest platform supported is AMD Ryzen  5000 series or most AMD Ryzen 3000 series?\n\nWhy would I expect the B580 to work to the best of its abilities with a CPU that is lower that their minimum requirments?",
      "The reviewer confuses \"budget\" with \"old\". If you build a budget PC you won't build a 2000 or 3000 Ryzen System.\n\nWould've been much more interesting to pair with with a 14100F and such. The lowest end modern CPUs for a new build.",
      "I guess this is good info but I have to wonder who is expecting a ryzen 5 2600 to run 4K textures and ultra settings well? Like wouldn’t testing at medium - high range be better data?",
      "I see people downvoting posts bringing up this issue and I wonder why. You don't want to see Arc get better? Covering these issue is how Arc will improve, being defensive does not help.",
      "Because what is the actual issue here? I would say that if we see similar bad results with a CPU that intel say they support, i.e. > Ryzen 5000 series (and some 3000) or > 10th Gen Intel then sure, that would be a lot more interesting to take a look. \n\nBut a 2600? Not really - [https://www.intel.com/content/www/us/en/support/articles/000091128/graphics/intel-arc-dedicated-graphics-family.html](https://www.intel.com/content/www/us/en/support/articles/000091128/graphics/intel-arc-dedicated-graphics-family.html)",
      "Yea I was on a 1060 and on a 1600 ryzen, guess what? I upgraded my cpu as well, because I didn't expect an incredibly old cpu to be able to not create problems with a much newer gpu",
      "Especially when the 5500 or 5600 are roughly 100 euro and are a good upgrade to a 2600 anyway.",
      "There is no line, the moment you become CPU limited you will lose performance, if the game is super CPU heavy you may even lose performance with CPUs like 7800x3d.",
      "It’s a zen refresh aka zen 1 cpu. Almost 6.5 years old. \n\nMore importantly neither the 9600K or any sub 3000 series Zen CPUs meet min requirements. And likely for this exact reason. \n\nSo the lesson is don’t pair the GPU with anything less than the stated mins.",
      "The texture quality and most of effects are mainly done by GPU so ur example is a little silly. Why do you think higher resolutions hits GPU more",
      "No, it's clearly a driver overhead for the CPU. The problem has been known for a while. It's just that B580 is the first mainstream Intel GPU and now more eyes are on the Arc series. I got my A770 in April last year and already people here were saying: \"Get at least a Ryzen 5600\" which prompted me to switch my old 2700X with a 5700X. 2000 Ryzen CPUs are just too weak at this point, even with ReBAR enabled.",
      ">Why would I expect the B580 to work to the best of its abilities with a CPU that is lower that their minimum requirments?\n\nStop with the BS please. The B580 cannot work to the best of its abilities even with the 5700X3D and is giving me the 70% GPU utilization in many games at 1080p in the instance, where 6700XT/NV counterpart can go well over 95% utilization and way higher framerate.",
      "Because they also targeted those who are using older midrange GPUs like the GTX 1060, rx 480, GTX 1660, etc in their material.",
      "Speaking about real issues and allowing people to make a more informed purchase is \"trash the product\"? There was a bunch of posts daily on this sub from people claiming they have like 20-30fps in certain titles and no one knew what was the problem, while it was probably this. People bought a GPU that simply doesn't work for them and you call voicing any criticism towards that \"trashing the product\".",
      "Moreover, this is not just about 4--6 years old CPUs. This CPU overhead issue is seen with newer CPUs too, to some more or less degrees. The testing is ongoing, and I guess we will see multiple channels posting their findings soon. I don't see an issue if Intel is getting this feedback and fixes the issues.",
      "Hardware Canucks and Hardware Unboxed need to retest and compare a 9th gen Intel with a 10th gen and a 2000 with a 3000 Ryzen, 10th gen Intel/Ryzen 3000 are the minimum cpu's Intel and AMD both say officially support rebar/SAM. Without doing this one could say this is only proving these rebar workarounds (or backports if supplied by a bios update) for older systems are faulty somehow. Maybe Steve from Gamers Nexus could do this, he's much more thorough than these two.",
      "So.. where do you draw the line of budget cpu, that is capable of mitigating Arc's driver overhead issue.. Intel 10th gen? Am4 3000 series? Im interested to see a video like this if someone can publish it, how different gen CPUs scale with the b580\n\nImo anyone with anything older than the 2000 series or 9th gen should've just upgrade the whole platform or cpu already....if you are not gonna change, the b580 should not be considered \n\nSome games suffer, some games do not suffer that much. But it's a problem nonetheless, not blown out of proportion by reviewers \n\nI feel like this is a very hard blow to Arc as a whole, stellar reviews at launch, but then only to realize there are performance issues with old CPUs which this GPU is meant to target the budget sector. B570, is releasing in a few days or weeks which is even more damning for anyone looking for just a drop in upgrade\n\nI hope it's just another software flaw rather than another architecture one... Not looking forward to the b770 if it ever comes out",
      "It seems to also have problems with the 5000 series and 11th gen",
      "After all the rave reviews I see we’ve entered the trash the product phase.",
      "Very few \"reviewers\" took the time to thouroughly evaluate the cards. There was a wave of who can be the first to get clicks at any cost. Very few games and systems were actually benchmarked before everyone declared it \"big success\"."
    ]
  },
  {
    "brand": "intel",
    "generation": "battlemage",
    "tier": "580",
    "matched_keywords": [
      "b580"
    ],
    "title": "B580 disappointing performance",
    "selftext": "Update: Alright, so thanks to those who actually tried to help. BIOS update and redoing DDU in safe mode worked. At least for the most part. Most games now give me more FPS and stutters are completely gone from any game I play. Even R6 which many said has problems now easily runs 144 fps constantly.\n\nIT'S FIXED NOW. PLEASE LEARN HOW TO READ.\n\n\nMy god the amount of stupid comments I got now although it's fixed as I said. Deleted the rest here so people only see the update now smh. That I even have to do this.\n\nNever posting here again. \n\nAgain thanks though to the few actual nice people who were helpful. I appreciate you.",
    "comments": [
      "Turns out VRAM is not everything. Who knew.",
      "Is your bios latest?\n\nBecause with older AM4 board rebar is sometimes broken older bios.\n\nhttps://gitlab.freedesktop.org/mesa/mesa/-/issues/8032#note_2462421\n\nMake sure you have latest. Like in the issue i linked OP's issue was fixed with bios update.",
      "both of these rules are made up and arbitrary lol",
      "At my resolution it's important. Can't play some games with 8GB without getting abysmal graphics settings.",
      "[Going from a recent daniel owen video, it definitely shouldn't be running worse.](https://imgur.com/tpxuYWc) It should be running significantly better.\n\nI'm not sure what's the cause of your issues. Did you wipe drivers in safe mode and choose the \"wipe drivers and shut off\" option? Or did you do it in normal windows? Or, did you only wipe drivers AFTER installing the new card?\n\n[Regarding the driver overhead, this is only an issue if you run your games at 1080p or very low settings, as HW unboxed puts it](https://imgur.com/lvgpnwV).\n\nAt 4K basically any setting should be SEVERELY GPU bound, you shouldn't see any overhead. And, you mention having a 4K monitor.\n\n[In this benchmark, the b580 outperforms the 4060 in R6 even at 1080p](https://imgur.com/tJvncfG), your results are quite puzzling.",
      "BIOS update definitely improved it, thanks a lot.",
      "B580 is absolutely reliant on rebar, it’s a requirement. Update bios, (remember til enable ram XMP again) and enable rebar. It’s super important.",
      "I'm pretty sure the difference between 7600 and B580 has to do with your CPU and the driver. Either wait for driver updates or return it. The B580 is known to have a greater CPU overhead than AMD and Nvidia.",
      "Oh absolutely not. 2022 BIOS. Guess I'll try that first. Never did it because BIOS update is scary.",
      "It's done. Now is heavily improved. Stutters are gone and I get more FPS in most games. Thanks a lot",
      "To be fair, never change a running system I think is a stupid rule. Even systems with a GT710 would still run, just not the newest titles. Besides I never had any problems upgrading, no matter what it was. Only now with the B580.\n\n\nAnd with the 30% or more upgrade. The B580 would give me even more as I am able to play games that just require more than 8GB VRAM which are quite a few at 3440:1440. So it made sense still.",
      "I also never changed my car oil at the recommended per KM, never broken down, but it is common that engine fails if not followed the instructions.",
      "Not everything but extremely important in video editing",
      "My only recommendation would be:\n\nDownload the install files for the ARC drivers.\n\nTurn your wifi off.\n\nRestart in safe mode without wifi.\n\nUse DDU to wipe ALL graphics drivers.\n\nRestart to normal windows, make sure your wifi is still off.\n\nInstall the arc drivers with the files you had previously downloaded.\n\n  \nUpdate me again when that's done.",
      "Glad your problem got fixed. Ignore the ppl in the replies being immature and it really should be on Intel to have a manual of some sorts that has a list of \"things to do/check\" when setting up the card on the first place.",
      "It's just one graphics setting. Texture make it lower. it's not like B580 is super fast to run high texture and get huge performance uplift.",
      "> I'm playing on a 3440:1440 monitor",
      "I’ll buy the b580 of ya if interested.",
      "Maybe it’s your monitor. Seems that keeps being the denominating factor in every comment.",
      "glad it worked for you!"
    ]
  },
  {
    "brand": "intel",
    "generation": "battlemage",
    "tier": "580",
    "matched_keywords": [
      "b580"
    ],
    "title": "2 Months of owning a B580 here is my experience and opinion.",
    "selftext": "Well to be honest i’m thoroughly disappointed. The card itself can handle gaming well but as soon as i try to stream any games beyond rocket league or valorant on twitch my encoders get overloaded and my game/stream will crash. i have spent days optimizing settings all for it to keep happening. \nCertain games such as fortnite it is a gamble whether the game will actually run or not.\n\nThe driver updates are horrendous every time i update all i get is problems such as my pc completely not recognizing my GPU causing me to have to uninstall drivers and reinstall.\n\nThat being said for purely gaming it can handle high fps on high settings. but for someone like me who enjoys streaming it has been nothing but a nightmare. will be switching to a 3060ti for NVENC encoding\n\nthis is just my opinion",
    "comments": [
      "From my experience, OBS has always worked horrendously with my A750. Apparently it just keeps using the iGPU and not the Arc's encoder. Maybe try a different software instead.",
      "I mainly use Mirillis Action. It's a paid software but I prefer it over OBS for better performance and ease of use. Unlike OBS, it lets you pick the encoder if you have both Intel iGPU and Arc. It has a Steam version which is much cheaper and is on sale often so you can give it a try. For stability I'd recommend the standalone version which is a lot more stable and won't force you to update. The Steam version has a tendency to break every few updates, and can make certain games freeze/crash, which I don't get on the standalone version at all.",
      "Interesting, \n\nOBS has worked fine with my B580 and B570 since I got them around a month ago\n\nMy thing was making sure OBS ran in Admin mode in Windows\n\nMy driver updates have been smooth, no real reason to use DDU or tweak driver settings",
      "oh? i’ve never heard of this is there a software u recommend?",
      "I thought I was the only one with encoding issues. Can't get a single decent clip from OBS replay buffer. This used to run fine on my A770. I think I'll be switching back!",
      "Yeah, I always record at max quality and I haven't noticed any overload with my A750. That is with a few terabytes of footage captured over a year. With OBS I get horrendous fps no matter the config I try.",
      "you might be having a unique issue, since my a770 runs my gpu's acceleration for av1 just fine. one driver a couple weeks back forced the igpu to be used, but it was patched after two days",
      "7600X3D\n\nIve tried using AV1, H.265 and H.264 in games like Last of Us Part 1 and the Callisto Protocol\n\nRebar on",
      "what software and CPU do you use? windows and programs automatically assign streaming to the iGPU so that your gameplay isn't affected by streaming. eithe tinker with the recording software or get  CPU with a decent iGPU. (meteor lake of later)",
      "okay cool i’ll def look into it. everytime i try stream a demanding game my obs says encoder overload and everything crashes so hopefully this can be a fix otherwise ill have to buy a new gpu",
      "i’ll give it a go for sure… so you find no encoder overloads on it??",
      "it’s frustrating because for purely gaming it works rlly well… everything else is extremely questionable though",
      "Looks more like a software issue than the B580, unless you have the same issue on multiple recording apps. OBS is not a good example when I've seen it breaking on both Nvidia and Intel every once in a while.",
      "I think it's most recorders in general that Arc has a hard time handling, like Medal or Discord. I can't even stream my desktop (with no games running) with Discord at 1440p without my system tanking - hard stutters, audio bugs out. I'll stream Valorant at 1080p, which works alright, but my system takes a decent hit on performance.\n\nI'm disappointed too because my 1660 ti performed better than this when it came to streaming, even at 1440p.",
      "So i have had the 580 for about same timeframe and had the same issue here are my tips. Run obs or slabs or even prism as administrator. Inside the game as well as the intel software set vsync and frame lock at 60. I can post my settings inside obs later when im off work. But setting the frame lock helped tremendously i play on a 34 ultra wide and can play and stream just fine. Took me alot of playing around to get to this point.",
      "Discord probably has the worst performance on Intel in general from what I've seen. Even attempting to play a Youtube video on Discord causes tremendous frame skipping on Arc, and also bad on Intel HD/UHD, which doesn't happen when I view the same video on a browser. I wouldn't trust it for streaming either since I've had black screen issue on it before on my 1060.\n\nI just gave the newest version of OBS a test. Looks like they improved the performance a bit but frame pacing in the footage is still all over the place. I made sure the Arc media encoder was in use (as reported by Intel Graphic Software). OBS made the encoder work harder (higher usage) yet the final footage looks jerky, while the in-game FPS tanks quite a bit. Meanwhile Action uses less percentage of the encoder and results in smoother footage. This is on the A750 so I wouldn't be surprised if OBS handles the B570 or 580 worse, as those cards are much newer.",
      "i5 14400",
      "B580 has 12GB VRAM.",
      "the B580 is so close in price that I'd go for that for raw performance. I personally prefer 16gb of VRAM vs the 12gb, though. the choice is yours :3",
      "Based on my experience, it's most likely because these recording/streaming software don't prioritize them high enough. I have a need to record, and I also experience encoding overload for some GPU demanding games. Turning off HAGS works a little bit for me, but it still occurs sometimes. That's why I'm now recording with a capture card or windows game recorder."
    ]
  },
  {
    "brand": "intel",
    "generation": "battlemage",
    "tier": "580",
    "matched_keywords": [
      "b580",
      "arc b580"
    ],
    "title": "Intel Arc B580 Review, The Best Value GPU! 1080P & 1440p Gaming Benchmarks",
    "selftext": "",
    "comments": [
      "\"Nvidia would need to price the 4060 at $200, and AMD would need to price the 7600 at $180 to be competitive\" is really high praise for this GPU.  They're not going to do that -- I think Intel has a GREAT card here!",
      "Price/performance wise they definitely hit their goals. Some of the contenders (the 6700xt/3060 ti) you can no longer find them on the market (maybe used) so it's not even a competition. All things being the same this is basically the go to for budget builds. The next step in performance is paying another 100$ (for abysmal uplift) and the big jump happens after 7700xt but that is like 200$ more expensive so we are not in budget territory anymore.\n\nNow it is all up to the market. If the customers at that price point stop blindly going Nvidia then Intel can acquire a certain market and work from there. AMD is mostly targeting the mid-tier for rasterization while Nvidia is going hard on the high end with strong RT performance being the main attraction.",
      "I might actually consider sidegrading from my 3060ti just out of interest of trying new things. My wife needs a gpu update anyways. \n\nI paid 500€ for the 3060ti and that was a great deal at the time. That was a really awful time.",
      "Well nvidia values it by almost doubling the price, just look at 4060 ti with 16gb, insane price jump from $300 to $500. That is really what the b580 12gb is competing with most healthily. Enough vram for 1440p, and usually enough performance, especially with XESS 2, which is the only serious competitor to DLSS.",
      "I bought a B580 LE even though I don't need one just to support them. Really hoping they do a B770 with 16gb.",
      "Thanks Pat and GPU team!\n\nFire the board & Bring back Pat!",
      "I don't think new GPUs are around the corner for this price point. RTX 4060 launched 7 months after RTX 4090. RTX 5090 should launch in January, so that would put 5060 around August. AMD usually likes to launch their card slightly after Nvidia does.",
      "It's just Steve valuing additional 4gb of vram at $50",
      "Same here, no one in my family plays PC games, I bought it just to support the underdog , also I may use its compute power in some of my projects later on.",
      "Could make sense if you are interested in computers and have it as a hobby",
      "The 16gb version price compared to the 8gb one is fine. The problem is that the base has way too little vram and the 16gb has too narrow bus. There should have been just one version with 12/192 but then they wouldn't be able to upsale the 4070.",
      "I felt I should thank you. Thing is, in India, Intel GPU sells at actual dollar converted rate, but nvidia and AMD don't. \n\nFor example, take 4060 which is the most liked card because people can somehow afford it and it can give some reasonable level of gaming performance. \nBut it costs about 560-600 USD. \n\nI am hoping Intel sells more in India and thus earns enough profit to keep their GPU division going longer and we will get competition to Nvidia 70-70ti series cards soon from Intel at good cost.\n\nThis will actually, practically move the technology further than just in theory while keeping price competitive.",
      "Fortnite ain't that big anymore.",
      "Rumours say that the 5060 comes with 8GB of VRAM. Its going to struggle a lot going above 1080p with higher settings, unless NVIDIA comes up with some tricks to decrease VRAM usage.",
      "I've got to say, I had my hopes up for the B580 and it came out better than I thought! Now they just have to focus on the drivers to keep them competitive. Recording software similar to Shadowplay would also be an amazing addition to the overall ecosystem.\n\nIt is the new value king, unless we start going for the second-hand market.",
      "Here in Europe pricing is a mess. For example where i live 7700XT is only 100€ more than B580 and 4060 is 40€ cheaper.",
      "Intel Arc B580 is overwhelming good with those pricing, not only it beat RTX 4060 and RX 7600 but at some game even B580 able to match RTX 4060 Ti, not to mention Intel still have bigger room to improve with drivers.\n\nImagine if they dropped B770 with an RTX 4070/Super performance but only for $350, Amd and Nvidia will be in a big trouble !!",
      "Also thanks to Tom Peterson, he is always GOATED since his days at Nvidia.",
      "True but lot of people building around Christmas for sure",
      "nVidia gets to set their MSRP based on their costs and desired profit margin. \n\nIf people don't buy them, they can either drop their price or stop making them.\n\nThe market can't make nVidia sell cards cheaper if they don't want to."
    ]
  },
  {
    "brand": "intel",
    "generation": "battlemage",
    "tier": "580",
    "matched_keywords": [
      "b580"
    ],
    "title": "The first available intel B580 models in the EU cost €320...",
    "selftext": "",
    "comments": [
      "The reference card in the UK is £248 \n\nYou never see proper currency conversion though",
      "I payed 280 euro and got Assasins Creed Shadows(70 euro) for free.",
      "It is not about currency conversion, it's about EU import taxes",
      "I'd pay 70 euro just to not see this game",
      "every country besides US getting screwed over",
      "The £248 in the UK includes 20% VAT and any other tax \n\nIn the PC hardware market proper currency conversion including tax is never done. Usually they just change the currency sign\n\n€320 is roughly the same price for the same cards in the UK £259/260 etc\n\nThe third party cards always carry a higher RRP",
      "This is expected, just wait until the market saturates a bit.",
      "Europe once again getting screwed over for no reason at all",
      "Worst game of the decade edition?",
      "That the card in EU is not that awesome for FPS per money, as compared to the US market. It's great card for the money. I will get one, once it's available in my country. The A770 in my country is around 400 Euro.",
      "260 usd is $409 aud, so plus GST makes the LE price of 439 pretty much spot on RRP. Can't be mad about that\n\nThe rtx4060 is usually around $450-500, or 400 for a really good special",
      "Bought in Poland for 1289PLN = 309 euro\n\nyeah EU sucks",
      "Payed means you've put tar on a wooden ship's hull, paid is what you are looking for.",
      "Yes... In Europe for the current price it doesn't seem to be the better option apparently",
      "OCUK have stock \n\nThey were taking pre-orders and will be shipping 200 by the end of today \n\nThey have another 200 coming into stock next week",
      "So in Serbia i expect it to be at least 400. Long live 3rd world",
      "Tell this to CIS countries...",
      "he is talking about the so called \"trade war\" the EU is fighting against U.S. companies. (But gpu prices shouldn't be included in this discourse), for example Apple's new IOS update has AI features, but not in europe due to recent problems the EU has caused to Apple. So I agree with him, the EU isn't a good place for U.S. companies to sell products, however the intel Arc prices in europe are Intel's fault, NOT the EU.",
      "What?,😂 i bet you didn't do your homework",
      "The Steel Legend is $270 here in the US. I was able to get an LE for $260 but it looks like everything here is sold out already."
    ]
  },
  {
    "brand": "intel",
    "generation": "battlemage",
    "tier": "580",
    "matched_keywords": [
      "b580"
    ],
    "title": "The reality is that the B580 is still going to sell out…",
    "selftext": "\nNo matter what fud there is right now with the overhead issues the B580 will still sell out and you wont be able to get your hands on it. The card may be worse than the 4060 by 10-20% in 1080p but it is also 30% cheaper and destroys the 4060 in 1440p gaming.\n\nPlus I dont really see an issue as 1440p gaming is better than 1080p so Im glad thats still fine. Maybe its time to upgrade yalls builds. The reason its good as a budget gpu is because you dont have to spend the cost of the rest of the build on a single gpu. 1000$ budget on a gaming pc now will get you a nice build with the B580. ",
    "comments": [
      "Unless Nvidia drop 4060 TI to B580 price category, it still sell\n\nThe issue with 8GB card is they obsolete faster, you can upgrade the CPU but you will never able to upgrade the VRAM\n\nHistorically in last 5 year, there is a competition within CPU market, Intel and AMD keep try to lead against each other, upgrading CPU into faster one is easy\n\nMeanwhile on GPU space it’s the opposite, a very stagnant on subs 300$ price, 4060 and 7600 barely beat last generation, and in many case 3060 perform better because They not run out of VRAM",
      "I bought A770 on the release day. Not because it was a great GPU (but it wasn't bad), but I wanted to help develop better drivers (I talk about Linux, of course).  \n\nI daily drive 7800XT as the main GPU, but I am, once again, hyped to buy B770 when it's out. And still for the same reasons:  \n\n1. Why not?\n2. I can\n3. I want to",
      "things are not exactly like that...\n\nB580 is a decent card, but it comes 2 years after the competition to which it is compared and often vs the 4060 which is one of the cards with the worst price-performance ratio ever.\n\nAnyway it is a card that depends a lot on the CPU and there are tests where it is worse and not a little worse than the 4060 for the CPU, it works well only if combined with high-end CPUs.\n\nworks better (in some cases) in 1440p for the vram, but it is not the only card in this range to have 12gb, example:\n\nRadeon RX 7700 XT 12\n\nGeForce RTX 2080 Ti 11\n\nRadeon RX 6750 XT 12\n\nRadeon RX 6700 XT 12\n\nRadeon RX 7600 XT 16\n\nGeForce GTX 1080 Ti 11\n\nTITAN X Pascal 12\n\nRadeon VII 16\n\nGeForce RTX 3060 12\n\n\n\nIf one wants to make an informed purchase, one should at least wait for the release of the 5060/5050 and equivalent AMD.",
      "Pack it up people, acknowledging there's an issue with a product is considered fud now",
      "Nvidia have this with 8GB VRAm, doubt they change anytime soon",
      "Not true at all. Nvidia in the 90's couldn't keep up with 3Dfx or S3 at the time, but they stayed relevant and eventually came out ahead. Also, there are markets and sub-markets aside from gaming, which care more about best bang for the buck and not overhead issues and FPS in gaming. There's also consumers and businesses. If an engineering company needs to buy a budget PC for 3D CAD design and their I.T. department opts for gaming cards instead of workstation GPU's, plus go with as much VRAM as possible with the budget they have to work with, buying 2,000 PC's could save tens of thousands going Intel. \n\nAll these comments completely focus on gamers and while gaming cards are marketed to gamers, businesses and other non-gaming PC users and I.T. professionals use gaming cards as well and the non-PC gaming market is bigger than you could ever imagine.",
      "I see the \"maybe you just need to upgrade\" cope is in full effect. Who are you, Jensen Huang?",
      "Just upgrade you CPU for this budget GPU! The more you buy the more you save!",
      "Yeah no they won't. They don't care and every single leak shows 5060 having 8gb of vram and 5070 getting the 12gb along with major price increases across the board so likely the 5050 with 8gb will be the new $300 card",
      "If that rumored 24gb card comes out imma order that thing with a quickness",
      ">B580 is a decent card, but it comes 2 years after the competition to which it is compared and often vs the 4060 which is one of the cards with the worst price-performance ratio ever.\n\nEver ... so far. The only reason I could see 5060 maybe offering better price-performance than 4060 is that Nvidia got scared of B580. I doubt that will happen, though. I expect 5060 to again be pretty disappointing stuff.\n\n>Anyway it is a card that depends a lot on the CPU and there are tests where it is worse and not a little worse than the 4060 for the CPU, it works well only if combined with high-end CPUs.\n\nI think it's fine to wait for that story to become clear. So far, we have quite little data to go on and Intel hasn't made any comment.\n\n>If one wants to make an informed purchase, one should at least wait for the release of the 5060/5050 and equivalent AMD.\n\n5060 is not soon. The 40 series launched November 2022. The 4060 launched June 2023.",
      "It would probably be aimed at professional workloads, sure, but the initial rumor said it was a B580 with 24gb, and a newer one said it may be a B770 or B780.\n\nI don't really see a reason it wouldn't be able to use the same drivers",
      "Right?\n\nThe whole point of budget cards is being able to upgrade your gpu with typically lower end hardware. People with a ryzen 3600 or 5500/5600 pc. Those type of people who want to spend $300 max. To have to spend that + another $ on a cpu and maybe mobo too. Come on. That’s wack.\n\nIntel dropped the ball here on the drivers side. Cant recommend a b580 at all anymore. Too much hassle for lower end pc users",
      "I think you're just worried about your portfolio.",
      "\"It's cheaper than the competition\" does not justify the product having major issues. \"The 4060 is bad value\" and \"The B580 has a problem\" are statements that can co-exist.\n\nIf you really cared about Arc succeeding, you'd be hoping Intel fixes this, not closing your eyes, covering your ears and pretending nothing's wrong.",
      "Most budget gamers with 12th gen Intel or AMD equivalent will still buy this because it's cheap and works well.",
      "Isn't that card aimed at professional workloads?\nOr would it be decent for gaming too? \n(I don't know alot about architectures)",
      ">burning AMD stuff\n\nYup that's acknowledged because it was mobo vendors who decide to over volt them, or user error of installing the cpu\n\nAll those things was taken care of quickly",
      "Acknowledging isn't, but there is an ongoing FUD right now, as Arc's user base is not loyal yet.\n\nTake a look at burning AMD stuff. Everyone acknowledged it, literally 0 FUD happened, and people kept buying AMD, because they have a loyal user base.",
      "Why would I want to buy one now when it's allegedly \"time to upgrade my system\"?"
    ]
  },
  {
    "brand": "intel",
    "generation": "battlemage",
    "tier": "580",
    "matched_keywords": [
      "b580"
    ],
    "title": "B580 suffers from enormous driver overhead at 1080p",
    "selftext": "In recent days, I acquired a B580 LE to test on my second rig, which features a 5700X3D (CO -15), 32GB of DDR4 3600 MT/s RAM with tight timings, and a 1080p 144Hz display. My previous card, a 6700XT, offered similar raster performance with the same VRAM and bandwidth. While the B580 is a noticeable step up in some areas—mainly ray tracing (RT) performance and upscaling, where XeSS allows me to use the Ultra Quality/Quality preset even on a 1080p monitor without significant shimmering—I've also observed substantial CPU overhead in the Arc drivers, even with a relatively powerful CPU like the 5700X3D.\n\nIn some games, this bottleneck wasn't present, and GPU usage was maximized (e.g., Metro Exodus with all RT features, including fully ray-traced reflections). However, when I switched to more CPU-intensive games like Battlefield 2042, I immediately noticed frequent dips below 100 FPS, during which GPU usage dropped below 90%, indicating a CPU bottleneck caused by driver overhead. With my 6700XT, I played the same game for hundreds of hours at a locked 120 FPS.\n\nAnother, more easily replicated instance was Gotham Knights with maxed-out settings and RT enabled at 1080p. The game is known to be CPU-heavy, but I was still surprised that XeSS upscaling at 1080p had a net negative impact on performance. GPU usage dropped dramatically when I enabled upscaling, even at the Ultra Quality preset. I remained in a spot where I observed relatively low GPU usage and a reduced frame rate even at native 1080p. The results are as follows:\n\n* [1080p TAA native](https://ibb.co/Jrdym5j), highest settings with RT enabled: 79 FPS, 80% GPU usage \n* [1080p XeSS Ultra Quality](https://ibb.co/0ydqP5h), highest settings with RT enabled: 71 FPS, 68% GPU usage\n* [1080p XeSS Quality](https://ibb.co/GdJdVfd), highest settings with RT enabled: 73 FPS, 60% GPU usage (This was a momentary fluctuation and would likely have decreased further after a few seconds.)\n\nSubsequent reductions in XeSS rendering resolution further decreased GPU usage, falling below 60%. All of this occurs despite using essentially the best gaming CPU available on the AM4 platform. I suspect this GPU is intended for budget gamers using even less powerful CPUs than the 5700X3D. In their case, with 1080p monitors, the driver overhead issue may be even more pronounced. For the record, my B580 LE is running with a stable overclock profile (+55 mV voltage offset, +20% power limit, and +80 MHz clock offset), resulting in an effective boost clock of 3200 MHz while gaming.",
    "comments": [
      "Try to report the finding in Intel Arc Graphic Community Forum?   \n[https://community.intel.com/t5/Intel-ARC-Graphics/bd-p/arc-graphics](https://community.intel.com/t5/Intel-ARC-Graphics/bd-p/arc-graphics)",
      "All drivers will have a CPU overhead, Nvidia's driver overhead is ludicrous and has been for years but used to be worse under DX11 due to their software scheduler. Intel might be taking a similar approach? \n\nAMD has always used a hardware scheduler which has had pros and cons over the years \n\nI am running my B580 on a 8600G APU and not seen many CPU overhead issues tbh",
      "Yeah uh getting an answer there is about as probable as the world exploding tomorrow. I posted there about a week ago and only got a response by some bot account that said some random words.",
      "Nvidia's driver overhead is way less severe than the one of Arc. NV driver overhead is noticeable when you have really old CPU - in this case I would expect my problems with something like Ryzen 2600 or 3600 even, but not with 5700X3D.\n\nI expected that at 1080p there is a certain threshold where you will end up CPU limited, but the intensity of this overhead is very big - 5700X3D is still a pretty capable CPU and having a budget GPU like B580 with capped usage to 60% at 1080p maxed settings in some games, is just mind blowing.\n\nIt depends on which type of game you play. If you play game that are light on CPU, you're not gonna notice it the way I do. But already mentioned BF2042 is one of the most CPU heavy games, especially in multiplayer with 128 players.",
      "Yeah thats why they marketed it as 1440p gpu",
      "Try to update XeSS DLLs to 1.3.2. That solved for me the CPU overutilisation - spiky frametimes graph - in Talos Principle 2 (UE5).....with an Arc A380.",
      "Report it to intel customer support and on this issue tracker\n\nhttps://github.com/IGCIT/Intel-GPU-Community-Issue-Tracker-IGCIT\n\nWendel from Level1techs briefly spoke about the CPU overhead problems in his review. It needs to be investigated by other YouTubers",
      "It happens the same to me as it does to you with Battlefield 2042. In my case, I have a 7600X with an undervolt of -20 on all cores and 32 GB of RAM overclocked to 6000 MHz with reduced latencies, and the main one at only CL28. In this same game (1080P), with the previous GPU I sold, the RX 6700 10 GB from XFX, I had stable and constant performance above 100 FPS. However, with the Intel Arc B580 Steel Legend OC from Asrock, there are specific areas in the maps where suddenly the performance drops to 60-70 FPS, and at certain points, there are even some drops lower than that. This did not happen with the AMD GPU.\n\nDo you think the performance of this game will improve in the future with driver maturity? Honestly, I doubt my RAM or CPU would bottleneck this GPU in any way.\n\nI also tried testing Control with ray tracing yesterday, and it doesn't let me select the option in the game menu. I think it's because the game runs on DX11, and it doesn't give the option to start it in DX12... not sure if anyone knows a solution to that.",
      "Used 3080 will get you no warranty at all, just a 10GB vram buffer that is already very limiting at 1440p and130W higher power consumption. But yes, drivers are much less of a hassle I agree.",
      "Tried it, same result.",
      "And you're still ignoring Intel's problem here which is far worse and the point of discussion",
      "That's nonsense and you know it.\n\nMost reviewers are using 7950X3D or 9800X3D and despite the monster of a CPU it's still showing a bottleneck.\n\nNeeding a $500 CPU and still not performing to it's potential is a serious problem that needs to be addressed soon, especially because if you pair it with a more balanced pair like a $250 CPU then performance will drop even further.\n\nYour bias against Nvidia is blinding you.",
      ">Just because graphics card load drops doesn't mean you have CPU bottlenecking.\n\nProblem is clearly not my CPU, but the immature drivers in some instances. \n\n>  \nDoes the entire Arc series have significant driver overhead? Yes. Does that mean you have a BoTtLeNeCk GuYzZ? No, it doesn't.\n\nWhat is \"BoTtLeNeCk GuYzZ\" supposed to even mean? My whole point was that ARC has much more severe driver overhead problem at lower resolutions than any of the competitors. That is all. \n\n>  \nWho cares about the performance on 2008 resolution anyway?\n\nLiterally 63% of PC playerbase do play on resolution equal to 1080p or lower, according to Steam HW Survey from November 2024. So hey, vast majority of PC gamers as of now still do care about this resolution. \n\nSorry that I don't want to play games at 60 fps anymore. B580 is lower mid-end GPU at best, that may serve you well for 1440p in lighter titles, but without XeSS 2 FG, it's nowhere close to being enjoyable higher refresh rate 1440p card.",
      "And for years in the consumer GPU market you haven't sadly until now",
      "coz its not a critical experience issue? Can share the forum post link?",
      "1080p still performs way better than 1440p for B580, it's just that relative to competition it does way worse when paired with a much slower CPU than reviewers use.\n\nTPU, Hardware Unboxed, GamersNexus are all using X3D CPUs, and lot of them Zen 5 at that. And it still shows a bottleneck.\n\nThe issue is entirely Intel's period.",
      "Man don't even try to suggest that in this subreddit when 99% of people *still* think 1080p is less intensive on CPU's than 1440\n\n(I did it all year ago with the A series cards, I realized that this place has worse brain drain than related tech subreddits)",
      "That is the point of driver overhead problem. If 5700x3d is not enough to feed this fairly low end gpu, I don't know what you expect people would pair this $250 GPU with. A 14900K or 9800X3D?",
      "I know you are bit a of a degenerate, but this is purely a software issue lol. Hardware is perfectly fine.",
      "Nvidia driver overhead doesn't even compare to ARC. Intel needs to fix this before they get B770, and future parts like Celestial because it'll get worse... and worse."
    ]
  },
  {
    "brand": "intel",
    "generation": "battlemage",
    "tier": "580",
    "matched_keywords": [
      "b580"
    ],
    "title": "ONIX LUMI B580 came in :)",
    "selftext": "",
    "comments": [
      "I have to ask why the low profile cooler if there is enough room for a bigger one?",
      "Honestly, it's just for aesthetics lol. The cooler + 15mm fan is the exact height as my ram and I personally think it looks sleek.\n\nHere's a pic of the alignment: [https://imgur.com/a/sCo0sSz](https://imgur.com/a/sCo0sSz)",
      "CPU overhead differs from game to game. I mostly play e-sport-type games with a few graphic-intensive games being GTA V and modded Assetto Corsa so it doesn't apply to me or affect me that much.",
      "Ryzen 5 5600 undervolted (PBO -30)\n\nHere's my part list: [https://www.reddit.com/r/IntelArc/comments/1i767ne/comment/m8ib0pg/](https://www.reddit.com/r/IntelArc/comments/1i767ne/comment/m8ib0pg/)\n\nI just ran GTA V 1440p with everything on Ultra except Grass and Motion Blur, and FXAA On only. I averaged 70C via HWiNFO. Also, I'm in a tropical climate so I'm surprised it stayed around this temp lol.",
      "RYZEN 5 5600\n\nThermalright AXP90 X36 Black Low Profile CPU Cooler (I attached a Thermalright TL-9015)\n\nONIX LUMI B580 12GB\n\nASRock B550M-ITX/ac\n\nAsgard Valkyrie Series 2x16GB 3200MHz\n\nSamsung 970 EVO Plus 2TB M.2-2280 NVME\n\nKXRORS M02 SFX Mini-ITX Case\n\nCooler Master V750 SFX GOLD 750W 80+ Gold Fully Modular SFX\n\nThermalright TL-C12015 RGB (top exhaust)\n\nThermalright TL-9015 (rear intake)",
      "Love the look. Clean build.",
      "The total cost is \\~$1095.\n\nHowever, this price can be greatly reduced if you choose a smaller NVME or a cheaper SFX PSU. I went with parts that were a little more expensive due to the size or rarity at the time. Also, white and itx tax.",
      "thats actually pretty neat",
      "nice",
      "This is beautiful",
      "i have low profile cooler too in my full atx build. im not into overclocking so its enough for me.and of course for asthetics",
      "I chose 750W since it was the only available white SFX PSU at the time. A white SFX PSU was scarce (and still is I believe). The only other options were from Lian Li and Corsair, but Lian Li had weird fan curves that would make it loud and Corsair didn’t offer a white color way. Thankfully, Cooler Master had one so I picked it up :)\n\nI recommend a 600W PSU from a reliable manufacturer. You could run a 500-550W, but 600W is the sweet spot and you’ll have space for upgrades. You can search up “PSU Tier List” from cultists network and compare models you see within your budget and pick the higher-tiered one.",
      "What CPU, and how are the temps?",
      "Would a Ryzen 7 5700X3D work well with the B580?\nJust curious, thinking of getting a pc soon",
      "The ONIX ODYSSEY (Black) retailed for $259.99, clocked at 2670 MHz.\n\nThe ONIX LUMI (White) retailed for $269.99 but it is factory overclocked at 2740 MHz. So it's not just the color this time lol.",
      "Damn okay, Thats pretty solid. I can definitely see the aesthetic you were going for with that cooler. And lucky for you the temps work out. Solid build!",
      "Yes. If you plan/choose to stay on the AM4 platform due to budget or whatever reason, the 5700X3D is the best in price to performance. I plan on upgrading to the 5700X3D in the future as well.",
      "Nice. Most were having a hard time getting them at that price",
      "Nicely done",
      "looks clean. whats the total cost?"
    ]
  },
  {
    "brand": "intel",
    "generation": "battlemage",
    "tier": "580",
    "matched_keywords": [
      "b580",
      "arc b580"
    ],
    "title": "We Were Accused of Forgery: \"Fake\" Arc B580 Benchmarks",
    "selftext": "",
    "comments": [
      "Biggest forgery here is Steve not actually being bald",
      "I'm hoping to be running my B580 with a Zhaoxin KX-7000 tonight. I'll test some of my benchmarks against theirs, lol.",
      "I suspect he'll be tearing his hair out over the upcoming 5060 / 5060 Ti review, so perhaps it's just a preview.",
      "Hahahah… almost everyone downvoted me when I said “I rather trust hardware unboxed than some russian channel“ a few weeks earlier. Now I’m glad this proves %100 my point.",
      "The issue has been happening with Nvidia for 2+ years now, but people somehow forgotten about it. \n\nAMD will always be the superior choice for pairing with a low-end CPU.",
      "“How dare he make another video I don’t like!!!😡😡”",
      "Yes it’s not as bad as most people think on CPU’s like 5600 and up but anything lower those issues can really start to cause problems and I think people should know about it. Also this coverage might push Intel into trying to improve or fix it for future generations. If this would have gone under the radar again like Alchemist, maybe Intel would have not bothered trying to fix it.",
      "Their results were literally posted here in this subreddit.\n\nI hardly ever go here specifically and even I got to see it because it popped up to me on my feed.\n\nWere you complaining when HU did three videos where they were saying that XeSS was better than FSR2/3? Or are you complaining now because there's something that makes Arc look not as great?",
      "He really did lose his hair over this...",
      "The problem wasn't them posting wrong/fake benchmark results, it was them calling out hardwareunboxed for erroneous testing (or not testing at all) that was the problem.",
      "OK... If I start publicly telling people that you are bad at your job, and not just 'some guy on the internet', but you, your real name, your actual job/employers, and will give some 'evidence' that might seem right, but is actual wrong, will you just give up and accept it because fighting it would mean 'there's an agenda'?\n\nSome people see 'agenda' where ever there's something they don't like.",
      "Thats why i recommending for 1440p (best option for price) but not for 1080p",
      "I can see  this guy will be milking this issue for years. \n\nIn 4-5 years Intel Arc will be in the 5th generation, without having this issue since Celestial, and he will come back to test the B580 again for the 10th time, just to check if this problem has been fixed on that card. It seems that reporting this issue has become a matter of honor for him.",
      "AliExpress",
      "Yeah, it's price to performance is already terrible.  I would not pay $450 + tarrif for it now.",
      "Don't bother responding to the cultists here in the future. This small community used to be cool until some people starting believing they are doing something noble that would save humanity by going with Arc and they let it get to their heads.",
      "How did you managed to get a Chinese CPU?",
      "Thanks for the informative videos steve you are a hardworking one(specially ur motherboard testings). And for b580 i am giving recommendation for 1440p use for 4 build all was happy.",
      ">people would notice any performance hit with the naked eye\n\nIn some cases performance dropped by 50% (see the war thunder and spiderman benchmarks in the video), if you can't see that with the naked eye you should have your eyes checked.",
      "I just installed a contact frame on the lga 1700. It gave me a bit of a heart attack because it was running memory training when it booted up, and it took a bit longer than I was expecting."
    ]
  },
  {
    "brand": "intel",
    "generation": "battlemage",
    "tier": "580",
    "matched_keywords": [
      "b580",
      "arc b580"
    ],
    "title": "Intel ARC B580 might be the highest performing GPU to ever exist...",
    "selftext": "",
    "comments": [
      "Why didn't we think about going above 100% before?!?! Fools!",
      "nvidia never saw this one coming",
      "And this is to go even further beyond.",
      "I think B580 secretly has the MUG (Multi Utilization Generation). It can just magically perform 178315331633152.0% better.\n\nUnfortunately this feature only works in HWMonitor.",
      "158%?!",
      "Yea, something is weird about the reporting 🤣",
      "If it wasn't for that blasted driver overhead!",
      "go above and beyond ! PLUS ULTRA",
      "It uses more GPU per GPU\n\nCave Johnson would be proud",
      "They got lots of dedotated wam as well",
      "HWMonitor can be pretty weird and glitchy sometimes.\n\nI recommend switching to HWinfo64 when you get a chance",
      "You mean Magic Utilisation Generation?",
      "Yea, but Hwinfo64 isn't going to make me feel better about my purchase, though.",
      "I overclocked to 3100mhz and I gained like a 8 fps increase",
      "intel says \n\n you get 1 gpu and it will perform like one plus  and  a half  gpu\n\nnvidia says \nthe more you buy the more you save",
      "Use Hwinfo64 \n\nHwmonitor is notorious for weird readings.",
      "the real overclocking",
      "Instead of battlemage they should of called it Intel ARC Saitama",
      "Just proof that those giving 110% are just slackers.   Always give 178315331633152% like this hard-working GPU.",
      "Can someone explain me this image to me? What do those numbers mean?"
    ]
  },
  {
    "brand": "intel",
    "generation": "battlemage",
    "tier": "580",
    "matched_keywords": [
      "b580",
      "arc b580"
    ],
    "title": "Can everyone post their CPU/MOBO with the ARC B580?",
    "selftext": "For those who have the ARC B580, can you post your CPU/MOBO combo and your experiences?  \n\nI am still on the fence whether to go Intel or AMD.\n\nThanks.\n\nUPDATE 1:  Awesome feedback.  Thanks to everyone who shared their posts and to those who continue to post.  Based on the feedback so far, it looks like the majority of you are on AMD with a higher spec'ed out combo.  I'll do a bit more research on some of the boards you provided and hopefully make a final decision soon.\n\nUPDATE 2:  I decided on the i5-14400F for the CPU.  This was based on trying to maintain a budget/mid-range build.  My usage will be 30% gaming and 70% general usage (email, web-surfing, general office tasks).  Now I am looking for the MOBO.",
    "comments": [
      "CPU - i5-14400F (got a steal deal on one brand-new)\n\nMOBO - AsRock B760M-C\n\nThis setup is demolishing everything at 1080p, 240hz",
      "Mobo - Gigabyte B650M Gaming X AX\nRAM - 32GB GSkill DDR5\nCPU - AMD Ryzen5 7600X\nAmazing combo and zero overhead issues or stuttering. Ultrawide 4K monitor getting 50FPS in RDR2 on ultra settings at full rez which I think is pretty tough. Has been a major upgrade for me compared to my old PC.",
      "Asrock a620i \nIntel i514400f\nB580 le\nT-create 32gb ddr5 cl 30 6000hmz\n850w sfx coolermaster hold rated psu\n2tb gen 4 kingspec m.2 nvme ssd\nDeepcool ch160 case\nWith 3x noctua 120mm fan + deepcool assasin iv cooler \n\n0 issues.\nGame at 1440p\n\nCheers and gl",
      "- Core Ultra 9 285K \n- Asus ROG Maximus Z890 Extreme\n- ASRock Arc B580 Steel Legend 12GB OC\n- ASRock Arc B580 Challenger 12GB OC\n\n———\n\nNo issues, working great. No games installed though. I use it for 3D graphics programming, data processing, and deep learning.",
      "Ryzen 5500 and Asus Prime B450M-A II. I can definitely notice a bottleneck but it's not super detrimental to my gaming. Not perfect but for sure playable in all my games (at least to my standards)",
      "CPU ryzen 7 5800x3d, \n\nmobo MSI B550-A pro, \n\n32gb ddr4 3600 (cheapest i could get, can't remember make)\n\nNo problems with anything so far @ 1080.  Desperately saving for a decent 1440p monitor....",
      "Building a pc with 7945hx and the Minisforum mobo it comes with. Still waiting on ram and ssd to come in.",
      "11400 and ASRock z590, run 4k/60 on my tv",
      "I5-12400 with 32gbs of ddr5 6000 cl30 ram. \nThere's a slight cpu bottleneck in more cpu demanding games, but otherwise, it's good for budget 1440p. The only game that I've had issues with is Spider-Man remastered. It randomly blue screens, and I'm still not sure why.",
      "CPU- i7 14700K\n\nMOBO- ASRock Z790 Steel Legend WiFi\n\nGPU- ASRock B580 Steel Legend",
      "My B580 currently lives in a 14400F/Z790 setup with 6400mt/s RAM. It's solid. \n\nIt was also rather cheap; $130 Z790 board, $130 processor, $?? RAM (came out of another system that got an upgrade), $250 GPU. Currently waiting on a new M.2 because my only leftover has a failure warning, and then I'm debating recasing it as it's currently in a \\~9 year old cheapo case with minor cosmetic issues. \n\nZ790 is 0% worthwhile for a cheap processor, and I kinda got screwed on the WiFi/BT module used on the particular board for Linux use, but the B580 likes being under Windows anyway. Also, while I'd mostly recommend upgrading beyond the stock cooler on the 14400F for noise reasons, it makes *absolutely no change* with regard to performance.",
      "9600x w/ Asus B650m-E \n\n32GB t-force 30cl RAM \n\nPlaying at 1080p 180hz \n\nWorks like a charm",
      "CPU : Ryzen 5 7600\n\nMOBO : MSI Pro B650M P\n\n\n\n**Cyberpunk 2077 1080p + XeSS Ultra Quality**\n\n* Ultra : 100 - 120 fps\n* Ray Tracing (High) : 55 - 80 fps\n* Path Tracing : 25 - 35 fps\n\n  \nSo far, i haven't encountered any buggy/unplayable games, and i played a lot of old JRPG",
      "12400f + asrock Sonic B760m. Really cheap combo, plays all my fave games really well. Planning to get a 14600kf soon",
      "Asus x870 am5 gigabyte 8500f\n\nWish i knew 8500 was apu, once up and running disable the onboard gpu in device manager which fixes several games.\n\n\nLinks\n\nhttps://www.reddit.com/r/IntelArc/s/rP9dkmvu2b\n\nIts decent after tweaks",
      "I had an A770, which is similar in performance minus 5-10%. i9 12900KS, MSI Z690.\n\n(Can't complain! at 1440p it was excellent and gave me >60 fps.)",
      "Amd 7600X3D, 32bg 6000 ddr5, intel b580. I play at standard 1080p and triple wide 1080p. Overall I've been very happy with the B580. Only had issues on an older title (the evil within 2). Runs triple 1080s great for iRacing and Assetto corsa as well as runs cyberpunk in 1080 at ultra settings with ray-tracing with zero problems.",
      "Ryzen 5 9600x + ARock B850M Pro RS Wifi",
      "5800X3D x570 Aorus Pro WiFi. Worked like a charm. No real issues. If you’re on Zen 3 or 11th gen Intel, you should be fine. Ymmv on something like a 3700x. It’s usable but you might run into the cpu overhead issues at that point.",
      "12700k + MSI Pro Z790-S"
    ]
  },
  {
    "brand": "intel",
    "generation": "battlemage",
    "tier": "580",
    "matched_keywords": [
      "b580"
    ],
    "title": "The current GPU landscape",
    "selftext": "For a GPU that's reasonably priced and often restocked, B580 isn't a bad choice. Might as well not pay the inflated mid tier GPU prices and put it to a faster CPU. ",
    "comments": [
      "It’s not like the b580 needs any more advertising it goes out of stock incredibly fast if near msrp\n\nEven at 300 it sells out at microcenter",
      "Yeah I don't agree with this. It's doing great. Keeps selling out, keeps getting updates. Love mine.",
      "I paid $300 for my Sparkle B580 at Microcenter. Considering the large improvement in thermals over the Intel edition of the B580 I can avoid feeling too bad about paying over MSRP by a little bit.",
      "To be fair when it launched they were all losing their minds over the B580; it’s not as if they completely ignored it. NVIDIA and AMD launched shiny new toys so naturally they have to move on to covering those.",
      "B580 will be relevant when rtx 5060 and rx 9060 drops in market, for now the reviewers are focused on upper mid range GPUs so no talk on b580",
      "b580 is the only one at msrp",
      "I bought an A770 on the release day.   \nI helped to develop and debug Linux drivers for over a year, then I switched to 7800XT.   \nI would be more than happy to help once again but there is no B770 (or similar) on the market.   \nI don't really care for B580.",
      "Maybe that's true where you live, but where I live the b580 is around the same price of the 4060 even now, i waited for this gpu like many of us here, i really wanted it, but not at that price.",
      "Yeah now that they sold out of the sparkle they are selling a 2 fan Acer b580 for 330",
      "Definitely not the US",
      "What the fuck is this? Post made by Userbenchmark?",
      "Why are people who like the 9070 xt shilltubers? If you can find it at MSRP it is the best dollar per frame GPU on the market, it's obviously a completely different price bracket than the b580 but that doesn't mean they both can't be good options? And I do see the b580 recommended a lot for budget builds.",
      "According to the Tech power up video the 3 fan Sparkle and 3 fan Asrock cards run about 10 degrees cooler than the le. I really like the look of the le though.",
      "Because OP is bad at making memes, or is an Intel shill, or both. Those same \"shill tubers\" have been calling out AMD for how hard it's been to get the 9070/XT cards. Just because their reviews were good doesn't mean they haven't been vocal about the crappy supply and MSRP vs street price situation",
      "Probably, gotta make sure they offset AMD's advanced marketing strategies",
      "I bought mine for 300 in Europe. Idk where you live and what your prices are there, but 300 euros is a fair price in Europe because of the VAT tax.",
      "They do, that's my point.  \nAnd I want top of the line model from Intel if I am going to bother myself with it.  \n\nDon't get me wrong, I like Arc cards, I think it's a good thing that Intel released them.  \n\nBut B580 is not interesting for me.",
      "It went out of stock everywhere in Australia for a while",
      "I can't help but think that it goes out of stock so fast because Intel made 4 of them.",
      "Lmao what victim complex is this. No one thinks about gaming 4k everyday\n\nPeople aren't giving it a chance because of the underlying driver issues that happened in the 1st gen which put them off, the cpu overhead issues, lack of wide support for xess2 and the new features, the lack of availability worldwide and it's pricing"
    ]
  },
  {
    "brand": "intel",
    "generation": "battlemage",
    "tier": "580",
    "matched_keywords": [
      "b580"
    ],
    "title": "Oh boy does this card ever look good (B580 12GB Steel Legend)",
    "selftext": "",
    "comments": [
      "are you using a m.2 ssd for a gpu holder lol",
      "Nope it’s a 1TB 970 Evo that still has some important data and my old windows 10 install on it (recently switched to win 11). I just did it for picture only. Don’t have it lean on it all day.",
      "Your whole rig looks fantastic. The cards is just the cherry in the middle.",
      "Temporary solution until I 3D print something better",
      "🫡",
      "Considering my future white build, I am really looking forward to when the steel legend becomes available in my country.\n\nThat or the Gunnir white.",
      "i hope the drive is dead at least lol",
      "Thanks also just got the ASRock X870 Pro RS because my MSI B650 Tomahawk refused to boot with Sparkle A580 at all and the ASRock A770 with all SSD slots occupied for whatever reason, tried million things to get the A580 working but was so done with that board and just ordered a new one. With new board all cards booting perfectly and now I can continue my benchmarks without having to trouble shoot when switching cards.",
      "B580 Steel Legend sounds like a motherboard name ngl.",
      "Fair enough but I have one so it’s a few cents of plastic",
      "average linux chud the picosecond someone mentions a window(doesn’t even have to be the software)",
      "Holy shit I didn't even notice that but that is hilarious.\n\nOP did it not come with a gpu brace?",
      "I have a 5700X3D. Does it support AM4 and how good would it cool it?",
      "3D printing is cheaper",
      "They had us till the last two sentences",
      "Looks rad!",
      "Man that is one clean build. I love every part of it",
      "That CPU cooler is DOPE",
      "that looks sexy, my days, amazing build dude",
      "Battlemage makes it hard deciding gpu lol"
    ]
  },
  {
    "brand": "intel",
    "generation": "battlemage",
    "tier": "580",
    "matched_keywords": [
      "b580"
    ],
    "title": "Got a sparkle b580 for my birthday!",
    "selftext": "Upgraded from a 1060 3gb",
    "comments": [
      "Happy birthday",
      "happy birthday\n\nthat’s gonna be a day night difference lol",
      "I just booted up rdr2 and it is amazing. It’s like 80 fps on ultra settings this is so cool",
      "Thank you :)",
      "I like it, very huge upgrade from my old gpu, I’m able to properly run games at higher settings and actually able to play rdr2 now",
      "Nice, I've got the same card 👍",
      "Good for you bro, My birthday was three days ago and I ordered a B570 Sparkle as my first GPU. Can't wait to have it with me:)))",
      "Very nice 🙂. What are thoughts so far?",
      "Must be a huge upgrade for you. Congrats man , happy birthday , God bless you!",
      "That's a beautiful card, triple fan too\\~",
      "Happy birthday mate",
      "Ain't no way, I'm also upgrading from 1060 to B580 which I got for my birthday on the 25th what a crazy coincidence",
      "Soon... Soon my flair will change and I will be free...\n\nEdit:whoops thought I was on pcmasterrace I'm running a EVGA Nvidia 1050 ssc right now",
      "Idk, it’s probably the one on Newegg tho",
      "It feels so powerful. Thank you!",
      "Happy birthday.",
      "Happy birthday! You got yourself a nice gift",
      "Congrats!",
      "happy bday :) very nice upgrade, the sparkle card looks so nice too",
      "Happy birthday man 🎉"
    ]
  },
  {
    "brand": "intel",
    "generation": "battlemage",
    "tier": "580",
    "matched_keywords": [
      "b580"
    ],
    "title": "RX580 -> B580",
    "selftext": "The RX580 has aged well, I hope it will be the same with the B580.\n\n#team580 😅",
    "comments": [
      "Uninstall AMD adrenaline software, DDU in safe move to remove AMD GPU, update the board bios, enable resize bar and disable CSM in bios. Reinstall the chipset drivers from board support page. Congrats on the upgrade!",
      "The 580 lives on",
      "Good upgrade",
      "B580 needs a fast CPU and a motherboard that supports resizeable bar. I hope you have both.",
      "Similar update in my experience. I went from rx 570 4GB to B580 month ago. Good Lord!",
      "did not no there was a 2 fan model",
      "you’ll still experience the overhead issue but you probably won’t tell in gameplay",
      "3600x should be fine.  Bottleneck should be minimal. I'm sure it's not existent on 1440p.",
      "I have a 5 3600x, so there may be overhead problems, but I am replacing it with a 5700x. I think it should be enough.",
      "Goat card to goat card",
      "omg same",
      "It will be a non-issue unless you're playing on the very edge of your system's capabilities",
      "I downgraded from 4080 to b580 bcoz i want to try intel's gpu, mostly play at 1440p.No regret so far",
      "A B580 is kinda the perfect GPU for a 3600x.",
      "same here bro, i upgrade from rx 560 4gb to b580 :) going to get mine soon",
      "Same here! Got the 3 fan sparkle from micro center and waited a good long while for it. What an improvement!",
      "I hope you had the GTX580 before that",
      "580 Went from prescription to over the counter 😅",
      "Was the card you had before the rx580 the gtx 580?",
      "That’s a great upgrade man congrats. What did it cost?"
    ]
  },
  {
    "brand": "intel",
    "generation": "battlemage",
    "tier": "580",
    "matched_keywords": [
      "b580"
    ],
    "title": "The B580 scalpers were too quick..",
    "selftext": "Tried to buy one of the 3rd party B580 cards on Newegg and all of them sold out instantly..the closest I got was adding an acer nitro version to my cart and it literally sold out before I could checkout. So unbelievably frustrating. Already seeing them being listed on eBay for absolutely ridiculous prices of $380-400+ which at that price makes them a very poor deal and I’d be surprised if anyone actually buys them for that price when you could get something like a 6900XT for less than $100 more. I have a feeling once they restock more they will be sold out within minutes from all the bots and people who missed out on the first round. Still going to try though! ",
    "comments": [
      "One of the reasons I remain skeptical of the \"just wait for the next generation, the supply will be so much better and cheaper\" crowd. GPU's remain in high demand, and between people legit wanting cards for themselves, production limitations, and scalpers, it's not particularly easy to get new cards at launch. Especially when it's something as solid as the B580. \n\nGood luck getting your card. The restock alerts on Newegg do actually work pretty well, fwiw, but you need to be keeping an eye on your email and be ready to pull the trigger.",
      "Plenty of cards available for $300 like 4060 and stuff. No scalper is taking all this pain and tax and shipping for 20 bucks. \n\nIf they price it too high like 350 no one will buy, at 300 they cant make any money. Makes no sense to scalp these cards. I think most are genuine buyers.",
      "Been hearing that since 2020",
      "Cards on eBay make 0 sense anyways. They often have cards that are being sold as used that sell higher than New at Microcenter. People will buy them. If you were only trying from Newegg, that is why you didn't get one. They were available on Newegg as a preorder most of the day on the 11th. B&H had them for preorder for at least the first 4-5 hours this morning. It isn't some instant scoop up like you're making it out to be.\n\nIt is a brand new card. They are always 'low stock' in the beginning.",
      "Won't be any stock until the hype dies down or scalpers move on to the following generation.",
      "Take a winter vacation in Sweden, 40-50+ stock in most web-stores here...",
      "We need the GPUs to make it through.",
      "This and so much this. It is a for the people card. If some idiot is going to spend 4060 money on an Intel card, let them. This card should almost be scalper proof. Scalpers will buy everything fresh because the worst case, they break even. They won't make crap and 1 scam back on them, they lose hard. GPUs from eBay are riddled with people switching hardware and returning.",
      "\\> In Stockholm, the sun rises at 8:47 AM and sets at 2:55 PM in January\n\nMy brother in Christ. How do people even function. Is there a baby bump every sept/oct there?",
      "Well tariffs are coming",
      "Honestly the real scalpers here are Gunner. Dude their prices are so crazy high. Lol\n\nYou know it's bad when board partner pricing makes the eBay scalpers look like a good deal. 🤣",
      "NEVER buy anything from any scalper. If no one ever buys from them, they will eventually have to refund those cards and then those cards go back to the original retailers.",
      "I mean in a few weeks itll be fine, and then cheap on the used market when scalpers realised they bought too many",
      "Eh, you would think it's scalper proof, but there's an LE on ebay for $700 and a few AIBs for $400+. Scalpers aren't the brightest bunch.",
      "They can charge whatever they want, but click on Sold. They aren't selling for that. Only listed.",
      "It doesn't have to be selling to be scalped. But you're right, they'll find out quickly why you don't try to scalp cards like this.",
      "I'm in America. This is true for the USA. Outside the USA may have a different experience, but since I'm not there, I'm not going to make up crap to be inclusive.",
      "Their mark up is absolutely insane. Highly doubt they are any better than the LE model either. At least the sparkle, while being $20 more, was benched as quieter and more thermally efficient overall than the LE at least based on Steve’s testing.",
      "Brought one in micro center :)",
      "Keep checking Newegg.  After a swing/miss on the ASRock Challenger on Newegg (into cart, didn't place order in time), and maybe 100 or so \"refreshes\" over 12 hours, I scored an Intel Reference card this morning (and got the email auto notification).\n\nMicrocenter appears to be the main brick/mortar retailer that has them right now, they had both ASRock models available for pickup at my local one this morning.\n\nWas pretty pumped to get actual MSRP, all the 3rd party boards are marked up..."
    ]
  },
  {
    "brand": "intel",
    "generation": "battlemage",
    "tier": "580",
    "matched_keywords": [
      "b580",
      "arc b580"
    ],
    "title": " Arc B580 Overhead Issue, Ryzen 5 3600, 5600, R7 5700X3D & R5 7600: CPU-Limited Testing",
    "selftext": "",
    "comments": [
      "Thanks for posting this. People really need to wake up and stop using the ReBAR argument. This overhead issue is much worse than anyone could have imagined. I really hope Intel can fix this.",
      "A budget GPU that doesn't work well on budget systems. Incredible.\n\nIntel better hope this can be fixed in drivers because otherwise the B580 becomes pretty much unrecomendable.",
      "Most people will be pairing the Arc B580 with the Ryzen 7 9800X3D.\n\nClearly, this is a non-issue.\n\n...nothing to see here; move along\n\n/s",
      "Yep people were also trying to say its due to the processor being \"old\" as if that has any bearing on it with no instruction set requirements or features missing like rebar.\n\nI hope they can fix this as well as I dislike what intel did in the CPU market for a decade or so but their GPU division seems to be making a genuine effort (and the modern CPU attempts are getitng better), I want a great GPU competitor to the big two so we can hopefully drive the cosnumer cost down again.\n\nb580 is pretty good and looked really promising, hoping this can be fixed in the near future to make it onpar again with the competition regardless of a high end CPU, cant wait for them to enter the high end GPU market as well.",
      "I found out from some guys in PCMR that the B580 has fewer drawcalls than even the almost 8 year old RX 580\n\nHere's a comparison between them and a 7900 XTX and 4070 Ti Super for reference: https://imgur.com/gallery/arc-b580-api-overhead-comparison-u3UHMyZ\n\nI'm no software or hardware engineer. My knowledge on this type of thing is extremely limited, but from a short time Googling it looks like the more drawcalls are sent the more strain is put on the CPU. The Nvidia overhead talk from a few years ago makes a bit more sense to me now. But what doesn't make sense is Intel having *more* CPU overhead with a lot *fewer* drawcalls. There's something fundamentally wrong with their drivers still, or maybe the hardware. \n\nI hope they publicly acknowledge this soon and release a fix or at least some improvements. Because a budget card not playing nice with budget CPUs is a big problem for it's value proposition",
      "The issue happens on modern CPUs just one generation old like the 7600 and even the very well regarded 5700x3d. Which are both within Intel's supported cpu sheet. The \"old CPU so doesn't work\" argument makes no sense when the issue is this bad.",
      "but some guys on Intel sub told me I shouldn't pair \"ancient\" tech like R5 3600 and 5600 with B580 so this shouldn't be an issue. \n\nI'm sure most people will totally not use it with their 12100f's or 5500/3600's for their budget builds right? If they can't spend more than $250 on a cpu to run the $250 GPU in full power that's cleary user's problem. /s",
      "100% agree. We need Intel ARC to suceed, but they must adress their serious driver issues before that can happen.\n\nI think a lot of the backlash is due to[ this video](https://www.youtube.com/watch?v=Dl81n3ib53Y&t=696s) \\+ the vague official support spec info. The clip is one of the most egregious examples of misleading marketing I've seen, based on what we now know. **TL;DR:** F*or everyone with a 1060 and 1660 you can now safely upgrade to B580*, no asterisk about CPU or anything :C",
      "sarcasm bro",
      "The 3600 ***is*** supported. And there are tons of them out in the wild. It's not ***that*** old or ***that*** slow, and it's getting eaten alive here. Even the 5600 is leaving performance on the table. Looks like even the 7600 is too and that CPU is barely 2 years old...\n\nAlso, Coffee Lake is architecturally identical to Intel's 10th Gen. The only reason why the 10th Gen recommendation exists, ostensibly, is because it's the first generation where Intel is able to guarantee ReBar support. There's basically zero difference between a 9900k and a 10700k. If a Coffee Lake board has ReBar enabled via a bios update, it's going to perform the exact same as a 10th Gen equivalent.\n\nNo matter how you slice it, this isn't good.",
      "Well Intel is currently using a die that costs the same to make as a 4070TI to beat a 4060 when paired with a high end 9800x3d and it loses when paired with a 7600.... Something tells me the B770 won't compete with a 4080. I've just got this hunch.",
      "Watch the video, current midrange CPUs are losing performance.",
      "correct deduction, considering high price of 9800X3D, not much money will left for graphics card",
      "Look i can understand your optimism but man what kind of fantasy have you built yourself here lmao.\n\nThe B580 doesn't consistently beat a 4060/Ti which really means that there's no infinite scalling your thinking off.\n\n2nd of all the B770 won't be $349. And if it is it won't be anywhere near the 4080.\n\nWhat i also find fascinating is that in a post about real issue about a GPU you've somehow managed to spin it into something positive.",
      "Intel shooting themselves in the foot again.",
      ">Intel better hope this can be fixed in drivers because otherwise the B580 becomes pretty much unrecomendable.  \n  \nNeeds to #1 issue on their priority list now. There were probably loads of Ryzen 5600 or Intel 10400 (or any other similar tier CPUs) owners who might have been in the market to upgrade their GPUs to breathe a bit more life into their systems. The B580 was looking like the perfect candidate for those owners. But now that's definitely not the case. I would tell those people go scour your used market and try to pick up a 2080 Ti on the cheap.",
      "The Core i3-12100F and the Core i5-12400F are even slower than the Ryzen 5 7600",
      "Drawcalls aren't a physical thing, they're code submissions.\n\n\nWith that said, intel hasn't figured out how to submit a lot of them with cheap cpu usage.  Unfortunately it means you either need a newish processor,  or you have to run the b580 at it's maximum gpu limit (1440p) to make the video card the slowest component.",
      "[https://i.imgur.com/T8hu1M2.png](https://i.imgur.com/T8hu1M2.png)",
      "It's 4 years old and still being manufactured. The 5600 and 5700X3D are very popular among budget focused buyers. Intel is primarily marketing the B580 on its value.\n\nThe value GPU that doesn't work with value systems. Even the 7600, a modern CPU, shows some small issues.\n\nKeep in mind games are only going to continue getting more taxing on the CPU so Intel better hope to hell they can mostly address this with driver updates.\n\nAs it stands, this is a flop. It'll be fine for new builds if you pick the right CPU.\n\nBut it's a dud for the people just doing a GPU upgrade, which is a good chunk of what people spending $250-300 intend to do.\n\nIt also means a lot of the most popular bang for your buck CPUs that are currently in stores can't be considered. No 5600 or 5700X3D for you."
    ]
  },
  {
    "brand": "intel",
    "generation": "battlemage",
    "tier": "580",
    "matched_keywords": [
      "b580",
      "arc b580"
    ],
    "title": "Experience feedback for people who want to buy Arc B580 (a bit long post sorry for that)",
    "selftext": "Recently bought Gunnir Arc B580 to upgrade from GT1030. Everything was fine. Was able to uninstall the old driver using DDU on safe mode. Install arc driver. Play some games on it.\n\nOn next bootup, screen was stuck on glitched motherboard logo. I can't even access BIOS settings. Contacted the dealer to apply for replacement. The seller wouldn't accept replacement because my PSU is not Tier C and + on Cultist tierlist. \n\nBrought my GPU to a technician to check if my system is not compatible, or defective GPU. He had MSI MAG A-BN 650W PSU. Technician had same experience. He was able to boot for few times. Then experienced freeze on motherboard logo during boot.\n\nFor comparison, I changed the GPU back to GT 1030 and PC booted up normally.\n\nMy options are to send this to a technician for board level diagnosis and/or repair (more expenses ofc), or just give up on hopes of upgrading GPU.\n\nMy PC specs:\ni5 10400\nMotherboard: Asus h510m-v3\n2x 8GB Ram\nPSU: Cooler master Elite series 600W\nTP-LINK wifi card installed\n\nAny thoughts?",
    "comments": [
      "I’ve had my B580 LE in my old Z97 Xeon rig (no rebar) and it still worked pretty well.  Moved it to my new AM5 rig and also had zero issues.\n\nSounds like your GPU may be a lemon.",
      "Hey and tbh that's not representative of all experience with the B580. For example, mine has been running fine for about a month and I never had any difficulties besides the recent driver mistake by Intel.",
      "Either battlemage or you've got a defective GPU. Although my arc likes to throw weird stuff in bios sometimes too, but it boots at least",
      "I know where OP bought it because I bought mine from there too. His dogshit PSU pretty much killed his B580 lol",
      "Guess I'm cooked",
      "Sounds like the seller is sketchy. If contact your bank and try to get them to do a charge back. Never heard of a pain requirement for a GPU issue",
      "It sounds like the issue here is the vendor where you bought the card.\n\n* Is it a reputable vendor?\n* What is your location?\n* How did you pay for the card?\n* When did you buy it?\n* What did your technician say?\n\nSure it is possible that a bad PSU have broken the card, and it would probably not show the issue if you used the 1030, since it does not get PCIe power. I once had a xfx branded PSU that died and took my 780 MSI Lightning along with it. Shit does happen.\n\nThere are always a few bad products that make it past q&a. If you want 100% tested and validated products, you are going to have to pay for it, and you don't pay for it when buying anything budget oriented, that's just the reality of things.\n- and as you said yourself, it worked fine for a while after plugging it in. So that can be something that slips past q&a.\n\nIntel does have a professional lineup, where products are tested and verified. This is not one of them.\n\nIf you can't pressure your vendor into honoring your warranty, you should try to contact the brand or your local consumer service.\n\nIf the fault truly isn't your doing, the brand is going to want the card back for fault analysis, so they can avoid this issue on other cards.\n\nI would say that a cooler master PSU is proper for a budget build, as long as it is not 10 years old and otherwise working properly, I wouldn't be expecting that to be the cause. It sounds like you sadly got a lemon, and your vendor is trying not to honor their end of the contract.\n\nAnd do also keep in mind, you are having a beef with a Gunnir branded graphics card and a vendor that does not want to honor their warranty, not specifically with intel Arc. Gunnir will be the brand that has to honor the warranty, not Intel. - if the vendor honored their warranty, and gave you a replacement, would you have had any problems then? The problem here is not Intel Arc.",
      "You should’ve never went with Gunnir. Acer, ASRock, Onyx, or even Intel brand are the reliable choices.",
      "Fact op went with gunnir might mean the other brands aren’t available in his country but I digress",
      "Not all 600w psu's are equal... not by a long shot.",
      "Can't return it to where you bought it?",
      "No the drives didn't mess up the card itself but rather the software you use to control it",
      "The one that destroyed the graphics software",
      "I've got the gunnir b580. Works fine since December. Roommates bought it for me on the release date.\n\nSeems to pair nicely with 5950x. No driver overhead issues.",
      "This is a user error, not on the side of the seller. This user used an F tier PSU to run the B580 which posed so much risk in killing the gpu (which may have happened). The seller had clearly stated what can void the warranty in the product description (I know where they bought it). And out of virtue, they're requesting for the item to test on their own as well even though they don't need to given the warranty being voided.\n\nI would honestly want them to expound more as it seems like they left quite few details too.",
      "Rebar does help a lot for alchemist gpus (not sure about battlemage), but not having rebar support shouldn't prevent you from booting or accessing bios.",
      "Arc has their own problems, no one here is afraid to admit that. This just isn't an Arc problem. This community is really helpful to iron out those errors and finding workarounds until Intel makes official fixes for them.\n\nIt is the equivalent of complaining about a Mercedes car, because their after-market tire got a flat. - it does not mean that Mercedes is bad.\n\nThe vendor that refuses to honor the warranty is the culprit here, and if anything it is Gunnir that produced a lemon, not Intel.",
      "So contact Amazon via their chat or request a call and let them know that what the seller is saying. If you are in the return window then return it.",
      "Recommend specs for gpu say 600W... guess not.",
      "do you have ReBar enabled? Tell them you have a Tier C PSU and are what they say then, this seems like a DoA situation sadly"
    ]
  },
  {
    "brand": "intel",
    "generation": "battlemage",
    "tier": "580",
    "matched_keywords": [
      "b580"
    ],
    "title": "Broke down and finally bought a B580...",
    "selftext": "I'm upgrading from a1660ti which has served me well but it's definitely showing its age this generation.       I ended up finding a sale on newegg for one thats just 50-60 over msrp and it seemed like a decent price for a brand new card.\n\nWhat am I in for?  Some people claim the card is an experimental purchase, some claim its the Holy Grail of the budget gamer.  I did a fair amount of research but I want to hear from you guys about your experience.\n\nThanks for your time in advance.",
    "comments": [
      "I have one it’s a pretty good one. It can run almost all popular games at high setting. I have friends who work at computer store telling me that it has the best performance for the price range. It is sort of similar to a RTX4060 (If not in some cases better). The downside is that the Intel software is not as well updated like Nvidia and AMD, but this is a problem that can be solved in the future.",
      "Helped a buddy build a new PC recently and we used a Sparkle Titan B580 and he’s been super happy with it.  Like not even a single complaint since. \n\n12gb of vram is also very nice compared to Nvidias paltry 8gb options.",
      "I just bought Intel B580 LE, they're available here in Canada. It's all good so far! Did a clean windows install. I have a feeling it has serious Fine Wine potential",
      "Probably cleans your registry hives of all the unused crap and legacy display drivers. To say nothing of services u “acquired” from bloat ware and forgotten software packages.",
      "I was already on an AM4 and didn't think it was financially responsible to get AM5, new RAM, and an expensive CPU in this economy. If it can run games and help me do work then it's all I need.",
      "You will find out soon. I bet it will be satisfactory experience.",
      "I've been doing research for weeks, I just want to hear some first hand accounts from a thread that isn't a month old.  Not my first Rodeo little bro lmao.",
      "**It still is an experimental purchase**, especially if you've bought it closer to launch. But the experiment is paying off very quickly since the card has been performing better as drivers roll out. I used to have a fair amount of frustrations with the card. Namely texture corruptions, artifacts, low 1%, stuttering, weird Windows errors, blue screens, etc. So many to name. As March came, I realized that **I no longer had weird problems with the card** anymore.\n\nI remember the drivers that came with Pirate Majima, it was doing all sorts of weird glitches to the ocean and the shadows were oddly pixelated. Infinite Wealth would freak out and dip to 3fps or crash every time a shark would appear. But since 5 drivers ago, none of those issues exist anymore. I've been playing Fortnite, Marvel Rivals, Zenless Zone Zero, Skyrim, Oblivion Remaster, The Forest, Minecraft (Shaders+Iris), Ghostrunner, and EVEN OLD GAMES like Sid Meier's Pirates. Red Dead Redemption used to run like ass, maybe around 50-70fps. Today, it runs 120+ no problem even at 4K. Emulators also run perfectly, if you're into that.\n\nAs long as your CPU is at least 5600 or 12400, you'll be fine. I used to rock a 5600G (which is just a 5500) so I had to upgrade into a 5700X3D to make the most out of my purchase (I was due for an upgrade anyway).",
      "I game exclusively on 1080p (aside from steam deck), and going from an almost decade old gaming laptop (6700HQ, 970M) to a desktop with a B580 is a night and day difference for me. Maxing out all settings and getting comfortable 100+ fps framerates is so good. So far, the only game i don't max out is expedition 33, but it still looks gorgeous with medium-high settings and 50-60 fps at 1080p. Overall, it's different for a lot of gamers tbh depending on our perspectives, game selections, personal preferences, and (sadly) regional pricing. For me? I am extremely satisfied.",
      "Not sure exactly why it works just know that it does.",
      "What are you in for?\n\nA good time mostly. Yes the drivers have a few screws loose but they have been pumping updates out at double speed recently fixing bugs. I really hate the deprecated the screen capture feature but everyone uses OBS anyway. Considering Intel's XESS is pretty dammed good and VSR actually works, it's already a leg up on AMD. It's RT rivals NVidia but at this performance levels, that should not be a consideration.",
      "My A580 WAS a holy grail since the only cards at that price range were 1660 or a crappy 3050. Then again my previous card was a friggin 740GT, so at that point anything from 2020 onwards is great",
      "Hearing this is really comforting because I've decided to buy a b580 as my next video card. I've been trolling this sub to see if there are serious breaking problems with drivers but it seems there are just a few small things. Hope I get it soon.",
      "The clean windows install makes such a difference.",
      "Picked up a Ryzen 9 5900x on the cheap cheap awhile back.  It actually massively improved my gaming experience in itself just not graphically per se.\n\nI know its not technically a \"gaming\" CPU but I don't only play games on my pc lol, it's an all around work horse.",
      "Nice one bro, yeah the issues are mostly with the drivers but given time I think it will be just fine",
      "I'm running a Ryzen 5 5500 and it seems to be perfectly capable. I'm probably leaving a little bit of performance on the table as it's PCIe 3, but from reports online it's not as much of a bottleneck as you may think.",
      "That CPU has sufficient firepower to handle your B580. Go forth and game.",
      "Agh, that's rough buddy. Although I think AM4 is practically viable for another 5 years lol so it's not too bad. You might get a decent sell value out of it in the future too. As it stands, games these days are far more GPU intensive anyway",
      "It's okay card the for the price it doesn't like older cpu gens because of the card architectures it design to run with newer intel cpus and chipsets."
    ]
  },
  {
    "brand": "intel",
    "generation": "battlemage",
    "tier": "580",
    "matched_keywords": [
      "b580",
      "arc b580"
    ],
    "title": "Intel Arc B580 Review, The Best Value GPU! 1080P & 1440p Gaming Benchmarks (HUB)",
    "selftext": "",
    "comments": [
      "Bravo intel arc, bravo",
      ">completely destroys the 4060 in most games\n\n\n>Almost reaches the 4070 in a few\n\n\nDamn and I thought the b770 was supposed to be the 4060 killer lmao.\n\n\n\nIn reality this will actually kill Radeon it seems.",
      "Is this the first time that a video card has exceeded the hype?",
      "this kills any card below the 7700XT in the market",
      "Holy shit",
      "Tldw;\n\n12 Game Average:\n\n***FPS @1080p:***\n\nRTX 4060Ti 8G - 92\n\nRTX 3060Ti - 83\n\n**Arc B580 - 77**\n\nRX 6700XT - 75 \n\nRX 7600XT - 73 \n\nRTX 4060 - 72 \n\n***FPS @ 1440p:***\n\nRTX 4060Ti 8G - 63\n\nRTX 3060Ti - 58\n\n**Arc B580 - 57**\n\nRX 6700XT - 54\n\nRX 7600XT - 51\n\nRTX 4060 - 50\n\n***RT FPS @ 1080p:***\n\nRTX 4060Ti 8G - 75\n\nRTX 4060 - 56\n\nRX 7700XT - 47 \n\n**Arc B580 - 45**\n\nRX 7600XT - 29\n\nRX 6700XT - 26\n\n***RT FPS @ 1440p:***\n\nRTX 4060Ti 8G - 52\n\nRTX 4060 - 37\n\n**Arc B580 - 32**\n\nRX 7700XT - 32\n\nRX 7600XT - 19\n\nRX 6700XT - 17",
      "Are we kidding? The video kept saying it isn’t mind blowing performance but to me it 100% is.\n\n$250 to get, at a minimum 50 fps, but mostly 60 fps in games running ultra settings at 1080p.\n\nI think we need to remember this card was never going to be top of the line and set expectations straight. This is incredible performance, in my opinion; way better than I was expecting to be honest. \n\nI was waiting to see if a b770 would be release but man, this is very tempting.",
      "The B580 even beats the A770 across the board; if you're interested in a generational uplift and don't want to wait for the halo card later in 2025, grab the B580. :)",
      "Legit not expecting it to beat the 4060 but Dam it did",
      "Looks like they have ok power draw at idle. Apparently it was an issue with the A770.",
      "Matched 4060ti in various instances.",
      "Kudos to Intel ... I was kind of thinking they were going to get roasted or at least luke warm praise for the new cards but nope they have done a solid job.  Curious as to why Steve u/Seriously GN failed to test Blender, DAVinResl etc with the B580 as I was looking to see if those results had also improved.  \n  \nSeriously well done by Intel and Arc card is definitely on my list for my new PC.",
      "There's even the odd benchmark showing it competing with the 4070, though of course in the general case it does not.",
      "Sure, but paying $50 more to get an extra 4gb of VRAM is totally worth it, in my opinion. These results are very very good in my opinion.\n\nI’m excited to see what else comes out",
      "Gamernexus shows 34-36 idle pd. Its not resolved yet.",
      "The B580 looks very promising! :)",
      "Is there really any reason to go with any other GPU in this performance bracket now? Obviously will have to see what Nvidia has in store for the 5000 series but highly doubtful a 5060 will be comparable, especially not at $250.",
      "that's super helpful. seems like this is going to be my next GPU.",
      "MLID on the ledge!",
      "if i'm running this in a b450 motherboard with pci-e 3.0 am i going to take a performance hit?"
    ]
  },
  {
    "brand": "intel",
    "generation": "battlemage",
    "tier": "580",
    "matched_keywords": [
      "b580"
    ],
    "title": "Sparkle B580 in stock Newegg",
    "selftext": "They’re in stock now, GO!",
    "comments": [
      "Aaaaand it's sold out after 3 minutes...\n\nEdit: Holy shit, I kept hitting refresh and I got to the checkout screen and paid for it.",
      "every time you don't post the link, god kills a kitten\n\n[https://www.newegg.com/sparkle-intel-arc-b580-titan-oc-12gb-gddr6/p/N82E16814993013?Item=N82E16814993013](https://www.newegg.com/sparkle-intel-arc-b580-titan-oc-12gb-gddr6/p/N82E16814993013?Item=N82E16814993013)",
      "Lucky, I was ready to pay for it but was so surprised that I forgot my cards ccv and was wondering why it wouldnt let me pay for it. When I realized it was too late.",
      "Lmao completely overlooked in the rush to ring the bells 😂",
      "No, ppl have success. Just cus you didn’t or didn’t have the patience to attempt again in case someone who had it in cart failed to purchase it doesn’t mean someone else won’t be able to",
      "Damn, OOS in minutes.  I didn’t even get the email from NewEgg.",
      "womp womp",
      "Despite me having a bookmark folder with all the b580 links and checking them every 10 minutes, I did find op’s post helpful. I can understand your frustration not being able to get it even with posts like op’s (I couldn’t), I did get to see the “add to cart” button that I had never been able to otherwise.",
      "I just got one. Kept spamming buy till it let me, don’t stop refreshing and trying",
      "Yea they go quick, some ppl here get upset when someone posts these stock posts but ppl across Reddit have managed to grab one cus ppl alert others",
      "I’ve been watching this sub and my email all day.  Walked away for a couple mins and missed it.\n\nI just wanna upgrade my old Vega56 at a decent price.  That seems like a huge ask right now.  Lol.",
      "Right there with you had the cc code in there and confirmed and bam out of stock",
      "HotStock app on iOS. Don’t pay for their bs upgrades. I still barely got one after a few close calls. Newegg seems better than amazon.",
      "Bro, you're supposed to be ready at the drop of a hat.  I got my ccv memorized just for this. With the rest of the card information saved on Newegg. \n\nYesterday Newegg notified me when it came in stock but I was super busy at work and missed it. I didn't get a notification for this restock, even though I renewed the notification thinking that having had the notification canceled it out.",
      "Nah, bigger cooler and an extra fan mean better temps which means lower power draw and better/longer boost clocks",
      "I don't even need a new GPU, but those SPARKLE cards look awesome. Love the color and heatsink!",
      "Out of stock already",
      "They have some of the asrock Challenger at memory express in Calgary, Canada. I picked one up yesterday",
      "thats what happened to me yesterday I am super happy",
      "out of stock"
    ]
  },
  {
    "brand": "intel",
    "generation": "battlemage",
    "tier": "580",
    "matched_keywords": [
      "b580"
    ],
    "title": "How are most people buying a B580?",
    "selftext": "I am so curious how most of you are getting it.\n\n1\n\nA) paying more than MSRP\nB) paying MSRP\n\n2\n\nA) in a brick and mortar \nB) online\n\n3\n\nA) had a notification \nB) just got lucky \n\nI am just a casual looker as I really like my A750. But if I saw one at Newegg, I might hurry up and buy it.",
    "comments": [
      "Getting really lucky lol.  Walked into Microcenter 4 days ago and they had 3 B580 LEs sitting on the shelf for $249.99 MSRP.  Grabbed one quick then walked past people standing in line waiting to pick up their 9070s, 9070xts, and 5070tis lol.",
      "This sub got me mine. Happened to refresh the subreddit right as someone posted about Onix dropping their first set of cards on Newegg. Paid MSRP (plus state tax). \n\nSo to answer the direct question, I paid MSRP online after getting lucky",
      "Used a tracking website and grabbed one through BH.",
      "Randomly searching new egg at 9am at work one day. Got a b580+650w 80 gold power supply for $340",
      "God I wish Arizona had a microcenter",
      "I use hotstock app and nowinstock discord.  Got one on newegg at msrp.",
      "Ok, I'm curious - isn't having Microcenter in your state just one condition to be able to shop there. Arizona is big - even if you had the chain in the state, isn't there a big chance the nearest store would be far-far away. I know the American definition of a short drive is completely different from the European but still - would you drive 5 hours to a store?",
      "Depends. If they were going to open one here it would likely be in Phoenix since that's really the heart of the state, Phoenix is a big city but it wouldn't be an *insane* distance to travel compared to driving out of state. But yeah preferably one in my local area would be the best lol.",
      "I'm in the UK I paid £269.99 for a sparkle b580 through overclockers.",
      "Got mine at Micro Center. Total RNG",
      "Microcenters between Wed-Sat\n\nI have seen them get 15+ that sell out same day or within 2-3😭",
      "Best Buy in Canada, got mine for C$369.99",
      "1. I woke up at 6am\n2. I logged into new egg\n3. Dunked my head into spring water\n4. Added card to my cart\n5. Checked out\n6. Went back to sleep",
      "I went to the Tustin microcenter this weekend, they had tons of 5070s and b570s, plus a few 9070s. No 5070ti-5090s, 9070xts, or b580s though. Also the 9070s sold out when I revisited a few days later.",
      "Hi there!\n\nI live in a country where not a lot of people are interested in Arc (and even Radeon) GPUs, because of that they're pretty much always in stock here so I suppose it does fall under the \"I got lucky\" category~",
      "Microcenter and getting them with PSU bundles seems to be a common thread",
      "I got one of those that exact same way as well. Haven't even used it yet because I had just purchased another one through B&H Photo like 2 days before",
      "Yeah 😅 crazy how is bad it is over the pond",
      "My current drive to a microcenter is 7 hours including 2 10 minute stops. If I had one 5 hours away it would be worth a day trip imo but I would *just* get a b580",
      "1B 2B 3A"
    ]
  },
  {
    "brand": "intel",
    "generation": "battlemage",
    "tier": "580",
    "matched_keywords": [
      "b580"
    ],
    "title": "Price check! How much does the B580 cost in your country?",
    "selftext": "In europe the price is all over the place, I wonder if the prices will drop to a stable number anytime soon, so I wonder how much if cost in your country right now?\n\nThank you for sharing.\n\nHere is some of the comments summarized (AVG):\n\n||\n||\n|Country|Price|Additional info|\n|Canada|357 (CAD)|AVG|\n|Denmark|320 (USD)|\\~|\n|Germany|309, 330 (EUR)||\n|Netherlands|304 (EUR)||\n|Turkey |320(USD)|\\~ AVG|\n|Ukraine|320(USD)|\\~|\n| Malaysia|310(USD)|\\~|\n|Australia|285(USD)|\\~ AVG, all models|\n|Japan|335(USD)|\\~AVG|\n|Poland|330(EUR)||\n|Costa Rica|340(USD)||\n|Romania|310(EUR)|\\~AVG|\n|Hungary|339(EUR)|\\~AVG, all Models|\n|Norway|372(USD)|\\~|\n|Sweden|308(EUR)|\\~AVG, All models. Some data not included|\n|Singapore |430(SGD)||\n|Bangladesh|300(USD)|\\~|\n|UAE|377(USD)|\\~|\n\nSorry if I missed some of the countries.",
    "comments": [
      "Ontario, Canada: $360 CAD at Canada Computers.",
      "In Denmark it is 2599 danish kroner which is around 346,5 euros.",
      "Assuming you mean American. When people don’t say where they are from you can guess American because they tend to forget the rest of the world exists.",
      "Msrp Canada at Memory Express. $349.99 CAD. Limited stock but stock keeps popping up.",
      "N/A Malaysia",
      "Germany 309€ in Stock",
      "Right now only pre-order, for about $333 sparkle and asroc, there are resellers for $380 asroc and $476 le\n\nI got for $259 le in bph, shipping $17 and tax hopefully $35 total comes out to about $315",
      "Got the LE for 260usd plus taxes (8.25%)",
      "Bulgaria - cheapest is 327 euro (639 BGN)",
      "Ukraine: SPARKLE Guardian (2-fan variant) = **$320** (tax, import tax, shipping included)",
      "Between 8000 and 10000 local currency which converted to USD is around 386.69 - 483.36 Dollars on Amazon and Aliexpress and only the overpriced Gunnir version, no local computer stores sell it.\n\nHilariously enough, scalpers on Ebay sell it cheaper here for around 6600 which is around 300 Dollars lmao.\n\nFor comparison a 4060 on Amazon is 8000, and on Aliexpress is 6000.",
      "390 and 480USD trough Amazon mexico, shipped from the USA",
      "It's sad to say that we don't have them \nLike not even scammers or non official retailers have them, and that's for one specific reason. \n\nIf I'd try to buy it from Amazon, let's say for 299 USD, it'd cost me at least 385 dollars. \n\nJust for information in our country, we have only opened boxed A770 for 205 dollars, not used, and its some guy selling it, not a shop.",
      "Australia: \n\nAUD$449 for AsRock Challenger B580 (US$279)\n\nAUD$459 for Intel B580 LE (US$285)\n\nAUD$469 for MAXSUN Milestone B580 (US$292)\n\nAUD$479 for AsRock Steel Legend B580 (US$298)\n\nAUD$489 for MAXSUN iCraft B580 (US$305)\n\nAs a reference the Intel B580 LE is pretty close to MSRP plus local 10% GST at current exchange rate.",
      "Japan, here:\n\nSparkle Titan/As rock challenger - ¥50,000 (330 USD)\nAsrock Steel Legend - ¥53,000 (341 USD)\n\nFor comparison:\n\n4060 8gb - ¥46,000 - ¥50,000 (296 - 330 USD) \n4060ti 16gb - ¥75,000 (483 USD)\nRadeon 7600XT - ¥55,000 (354 USD)\n\nSo not too bad in comparison to other cards. I built up a system with The Asrock Steel Legend last week and its running nice.",
      "Yup. Went in and asked to be put on the list. As soon as it came in, he gave me a call. $350 + GST. No HST here.",
      "It costs $349 at memory express",
      "Dang, teach us your secrets",
      "I bought the LE in Canada for $359 CAD, from Canada Computers.  Haven’t installed it yet as I’m finishing collecting the rest of my PC parts I’m building around it. Almost there.",
      "340$ - Costa Rica"
    ]
  },
  {
    "brand": "intel",
    "generation": "battlemage",
    "tier": "580",
    "matched_keywords": [
      "b580",
      "arc b580"
    ],
    "title": "Intel Arc B580 Overhead Issue! Upgraders Beware",
    "selftext": "",
    "comments": [
      "For people who didn't watch the video, there's something weird going on. With a modern processor the B580 often beats the 4060. With the 2600, the 4060 is pulling ahead.\n\nLike in Spiderman Remastered the B580 is 20% ahead when both are using the 9800x3d. But with the 2600 it's 40% SLOWER than the 4060 also using the 2600.\n\nCPU scaling doesn't do that. \n\nWith a slower cpu bottlenecking the computer, we should see framerates be extremely similar. But they aren't.",
      ">\"Just reviewers not doing research before they open their mouth. Nothing new.\"\n\nI mean did you do any researce before posting that? This has nothing to do with Rebar. The Canucks video and this clearly say that.\n\nThis overhead also appears to be an issue with more modern CPU's like the 3600 and even 5600 even if not to the same degree. \n\nHell there was a post on the ARC subreddit pointing out this problem with a 5700X3D and i've even seen a 7800X3D example.",
      "It's an issue for anyone upgrading from an older GPU since apparently even the [5600 has issues](https://www.reddit.com/r/hardware/comments/1hsjqb2/intel_arc_b580_massive_overhead_issue/m5651pi/), especially in [\"CPU limited scenarios\"](https://www.reddit.com/r/hardware/comments/1hsjqb2/intel_arc_b580_massive_overhead_issue/m58kt64/).\n\nI'm sure we'll probably see more benchmarks with more CPUs since this seems to have only just been found out, so we'll probably know more soon.",
      "No. With a modern processor the B580 was ahead of the 4060. With an older processor, the 4060 pulled ahead of the B580.\n\nThere's something going on.",
      "Even the Ryzen 5 7600 [isn't good enough for the Arc B580](https://x.com/HardwareUnboxed/status/1875378992871809367).\n\nYou have to open your wallet for a Ryzen 7 9800X3D.\n\nNaturally, the Ryzen 7 9800X3D is the processor that most people would pair with the Arc B580. \n\nOh, wait!",
      "even with something as modern as [ryzen 5 7600 b580 can lose up to -33% performance](https://x.com/HardwareUnboxed/status/1875378992871809367/photo/1). I want you to look at me with a straight and serious face and tell me that ryzen 7000, on the ddr5 platform, is an old outdated and slow cpu platform and does not meet the system requirements to run a $250 gpu. Please go ahead, and thank you.",
      "In the same page you link Intel lists \"most 5000 series Ryzen CPUs\" and on the [test HWUnboxed did](https://youtu.be/00GmwHIJuJY?si=oHCcQWXaKlhZwJzC) it shows the 5600 suffering from this overhead issue. Your own source proves you wrong lol",
      "The card specifically made for budget PCs suffers from diminishing returns using budget CPUs. Even a relatively modern and decent 5700x3d suffers from the problem, yikes",
      "going from 9800x3d to ryzen 5600 (or 12400f/12100f which perform about the same), rtx 4060 loses about 13% performance. b580 loses [***50%***](https://x.com/HardwareUnboxed/status/1875378992871809367). Also with a ***ryzen 5 7600*** b580 goes from defeating 4060 with a healthy +20% lead, to losing by -10%. \n\nNow, please reply to me \"the 2 year old ryzen 7000 cpus on the am5 platform, with fast ddr5 6000+ ram, is old hardware and isn't fully compatible with new hardware that supports modern features\". \n\nplease go ahead.",
      "This is just blatanly wrong. Rebar or atlest the underlying tech behind it is a PCIE2.0 standard lmao.",
      "And they used the 2600 with Rebar. Rebar works on the 2600.\n\nIt always has with the correct bios and thats facts. Steve knows that and you should know that.\n\nRebar has nothing to do with whats the issue being pointed out in the video. Your latching onto the system requirements page when the same issue can be observed on Ryzen 3000, 5000 and even 700 cpu's.",
      "https://youtu.be/00GmwHIJuJY?t=111\n\nAlthough i would recomend the whole video as it goes more into the underlying issue of the B580.",
      "No one bothers to read Intels page on system requirements that pretty much said you must have 10th gen Intel or AMD Ryzen 3000 or later as those systems are when Rebar is introduced.\n\nJust reviewers not doing research before they open their mouth. Nothing new.",
      "Ryzen 5 7600 apparently [isn't \"modern\" enough](https://x.com/HardwareUnboxed/status/1875378992871809367)\n\n...gotta open your wallet for a Ryzen 7 9800X3D",
      "I'm just gonna keep saying this: Given a Ryzen 7600 isn't enough, this is a straight up defective product. Everyone who has one should return it, anyone thinking about buying it should avoid until the issue is either sorted or the price drops pathetically low.",
      "I'd say a large portion of gamers who buy budget GPUs have older systems and don't have enough to also do a whole motherboard, ram and CPU update",
      "Nononono.\n\nWe know that a 4070 will perform worse on a 2600 than a 5600. That's not what the video is about at all.\n\nWait, what do you think the video is talking about?",
      "You could very well be upgrading from 3600/RX 580 or GTX 1660 to this GPU. If your budget was 600€ back then and you want to upgrade for 300€, the reviews would have you believe that B580 is a good upgrade path over 6600XT, but you would be mistaken.",
      "Are you saying that a 4070 would suddenly start performing **worse** than a 4060 with a potato CPU? If so, I'd love to see the benchmarks.",
      "5700X3D also experiences these issues."
    ]
  },
  {
    "brand": "intel",
    "generation": "battlemage",
    "tier": "580",
    "matched_keywords": [
      "b580"
    ],
    "title": "I've tapped into black magic. RDR2 running 4K60 ultra without upscaling on B580. Thanks to Lossless Scaling Adaptive FG and the old friend GTX 1080 Ti in dual GPU setup",
    "selftext": "",
    "comments": [
      "Funny how dual GPU setups are starting to become more popular nowadays.",
      "On reddit. Nobody I know of outside of reddit and specific tech youtubers give a damn.",
      "So you're actually playing at 30fps. I guess it's borderline fine for controller games\n\nI'd much rather use upscaling than FG to achieve a target fps though, if possible",
      "May I know why dual gpu is becoming popular?",
      "Dual GPU is primarily becoming popular again for the \"budget\" gamer.   \nbecasue getting a $300 gpu is much easier to acquire than a 700+ gpu. 'specially when you keep the old one.\n\nvia a steam app \"lossless scaling\" its an open source software based Upscaler/Frame Gen for \\~7$ (Opposed to Hardware bassed DLSS/FSR) in the app it has an option to do the process of the Frame generation and upscaling on the second GPU if you so desire. \n\ndue to being software based it works with (practically) any game regardless of developer support.\n\nthe popularity is its crazy quality for its crazy price.",
      "What was old becomes new again",
      "Lossless scaling allows you to offload its processing to a secondary GPU. Run the game on one, and run LS on the other.",
      "The real trick is to use upscaling to hit 60, then use FG to hit 120 or higher.",
      "Acquire Lossless scaling via steam  \ndig through settings to find a Dual GPU mode,   \ntell it to game on main GPU, tell it to process on secondary GPU  \nset you upscale as desired, set your target FPS as desired.  \nplug display cable into the secondary GPU to see results. \n\n(this is the best way I can explain without having any direct interaction, this is just what I have learned from the casual doom scrolling I get.)",
      "Can you describe a little more about how this is set up?  I currently have both an arc a750 and a 5070 ti.  I've been trying to sell the second card and system it's in, but Facebook folks only want free shit or to trade used, poopy towels for stuff, so I'm considering keeping it and doing a dual GPU thing, but I'm really struggling to come up with any way in which it works and is actually useful.",
      "I don't care what anyone says, this is cool af regardless of whether it's worth it or not.",
      "Yes, I second this.",
      "So same as SLI",
      "They used Lossless Scaling as a way to generate more frames which i assume the program uses the GTX 1080 TI for the frame gen to not strain the b580",
      "allegedly yes. May very by game.\n\nit's generally recommended to not because the Generated frames create the feeling of input latency. where you click on a fake frame, you do still have to wait for a real frame for it processes. (same concept as DLSS/FSR)\n\nif you just upscale, this aspect should't be an issue. (again similar to DLSS/FSR)",
      "Lossless Scaling's input latency is too painful for me.",
      "Yep. Pretty much.",
      "I bet it fades just as fast if not faster too.",
      "My brother in Christ mentioned the 1080 ti and frame generation like its no big deal",
      "> I second this\n\nWhat are you, an extra GPU in a setup?"
    ]
  },
  {
    "brand": "intel",
    "generation": "battlemage",
    "tier": "580",
    "matched_keywords": [
      "b580"
    ],
    "title": "Update! B580",
    "selftext": "B580?  \n\nIt looks like it could be a 580 for Christmas.  What do you think?  \n\nUpdate*. Looks like a joined the Intel club.  Hopefully will be quite the upgrade from my 1050 ti.  ",
    "comments": [
      "Congrats and Merry Christmas!",
      "Congrats!",
      "Congratulations! I'm still working out the kinks for mine (I want it to be an eGPU setup), but I love the card, and it was very capable when I put it into a native PCIe slot. Enjoy your new card!",
      "1050 ti? You're going to love it",
      "Enjoy dude I'm tempted to get once to replace my RX580, it all really depends if AMD releases anything competitively priced or not",
      "I was so hoping for socks.",
      "in splinter cell pandora tommorow indonesia embassy mission \n\nwhen lambert says merry christmas fisher he means now it can kill many people he want",
      "The Thunderbolt setup that I had was an extreme bottleneck. It had to run through my iGPU, and it seemed like the Thunderbolt port was rate limited (possibly because it was going into L1). I'm getting an M.2 eGPU setup though, and that should work a lot better.",
      "I have an Asus Vivobook 14 OLED. It has a pretty capable CPU (i5 12500H), but the Intel Iris Xe iGPU really kills it. The screen is phenomenal (1440p)",
      "i too have rx580 and am just reading all the driver support issues people may be having with older titles but also recent titles like valorant have fps stuttering. just out of curiosity what game stop support for your 580 to make you wanna upgrade?",
      "Looking really great you lucky bastard! Enjoy 🎅",
      "Make sure you can enable resizable bar",
      "Congratulations! Interesting times where people now prefer Intel GPUs and AMD CPUs.",
      "Nice, does that work with your existing card too?",
      "Let me know how that goes I also want to egpu a b580 eventually currently using a 1080 ti",
      "No game stop support really, I've had it since new so bought it back in April 2017, so really I'm just due an upgrade, I'm going to wait though because I know new releases are coming from AMD and Nvidia, so I will pick the brand I want and the best price Vs performance graphics card I want.",
      "curious as to what laptop(?) you're running yours on. external gpu setups are always neat lol",
      "Probably will be a substantial upgrade to the 1050ti",
      "Great upgrade!",
      "Lucky… I’m still waiting for mine"
    ]
  },
  {
    "brand": "intel",
    "generation": "battlemage",
    "tier": "580",
    "matched_keywords": [
      "b580"
    ],
    "title": "UPS stole my B580 and I leave the country for a year on the 6th :( Newegg will only refund and told me I will have to order again when available :( Wanted to rant :c",
    "selftext": "",
    "comments": [
      "Cali, limited release item, day 1 never updated again, UPS confirmed it was \"lost\".",
      "It’s the holiday season, so it could be “lost” in a back log of packages. Trust me I work in a package sorting facility and they get swamped this time of year",
      "Can I ask how you know it’s stolen?",
      "Hello u/[ducktoucher0](https://www.reddit.com/user/ducktoucher0/) ! Can you please send me your order number on that Acer B580 GPU via Reddit chat? I want to look into that tracking with you and will assist the best I can. Thank you!",
      "Newegg W",
      "11 years old acc with 11k comment karma. If its a fraud its a really good one lol\n\nEdit: Also, some companies do that. When my GPU arrived and I had issues with it (I got a dead PSU as it turns out), so intel customer support reached out  to me in DMs. Good to see good customer support",
      "I will hope for the best then. My time frame definitely hurts my chances lol 💙",
      "Highly recommend using Newegg support through Reddit in the future. If anybody needs help, they were extremely helpful and seem to know what they're doing, no offense to regular Newegg support. They launched an investigation with UPS and whether it was from my phone call or theirs, my shipping status was updated. So everything worked out great, I hope lol",
      "Ya but would cost $70 plus import tax is 10% of retail. So $100. Id be better off getting another gpu. \nI have a steel legend on backorder with b&h, they are rumored to be shipping on the 2nd, with 2 day shipping. I only hope it will fit in my PC xD Also, it doesn't fit the color scheme, but who cares, it's a beautiful card lol",
      "Yes that is for sure. Do you have someone at your current address that could forward it to you if it does arrive?",
      "Just give it some time. It didn't update for me for a while either. Look for the date of next expected update, and if it hasn't updated by then you should be concerned.",
      "Unfortunately, UPS confirmed it was lost already. Also, it being in Cali basically doubles down on that lol.",
      "Wait Newegg is being nice now wtf??",
      "At least you got your money back",
      "Damn people be stealing Budget GPUs too?! Bruh",
      "W support. Rare to see",
      "people have been stealing candy from kid, so these villian will do their thing as always\n\nI hope they have stomatch issue for a year",
      "Idk if it's to be trusted tho. Like how do you know they're genuine?",
      "Oh, that's unfortunate. I was just speaking from experience. Mine was like that for almost a week before it updated. Still, give it some time. Maybe it'll turn up in their system.",
      "UPS is hiring thieves this year. They stole my brother's $2K Alienware laptop on Black Friday and it's been stuck in Maumee, OH for the last 3 weeks. Dell is still looking for it."
    ]
  },
  {
    "brand": "intel",
    "generation": "battlemage",
    "tier": "580",
    "matched_keywords": [
      "b580",
      "arc b580"
    ],
    "title": "Intel Arc B570 \"Battlemage\" GPU Tested In Geekbench: Roughly 12% Slower Than Arc B580 For 12% Lower Price",
    "selftext": "",
    "comments": [
      "%1 down the price for every 1% performance lower performance? That's absoutely incredible\n\nNvidia and AMD could never",
      "Let's make sure it doesn't need a 7800X3D to meet it's potential.",
      "Hopefully it is tested with midrange CPUs as well",
      "No, they aren't. These already showing its age. Intels drivers are Ok. It will be getting better over time. But soapy FSR scaling can't be fixed on current AMD gen cards, neither RT performance. Additional 4 GB of VRAM can't be added either. \n\n\nRegarding value. As per article, B580 still holds its value even when paired with 5600. Now look at it this way - you get nice performance bonus sometimes, pairing it with faster CPU. Which is additional value (I mean - upgrade path).",
      "Well, driver overhead is when cpu hits the wall and can't feed GPU fast enough. So GPU has to wait. Therefore common sense says that for lower performance GPUs driver overhead should be less noticeable. Of cause, RTX 4090 have the biggest driver overhead problem - just look at performance difference between 9800x3D and ryzen 5600 when using RTX 4090. :))",
      "great now hope we can actually get them for near msrp.",
      "Me still with a GTX 1080…",
      "Kind of missing the point there. AMD cards suck at RT and upscaling because they're cheaping out on hardware RT and AI accelerations, as well as encoding and others. Their die size is tiny mainly because they're skimping out on those features, their GPU design department was divided into RDNA and CDNA so they could skimp on features they think a consumer grade GPU doesn't need. They're (barely) cheaper than nvidia cards because they really are cheap to produce. Look at RX 7600's tiny die fabricated on last gen node. It should be much cheaper than it is now. Why is their driver better? Because they had acquired ATI long ago, one of the oldest high performance GPU producers, far older than Nvidia. They had been toe-to-toe with Nvidia since the late 90s.\n\nI don't think their last and current gen GPUs are necessarily good value. 6700 XT at $330 is definitely not good value, it's barely even more powerful than RX 7600 in rasterization in some games, and the gap is even smaller when you compare it to B580, with B580 dominating at some titles. It used to be $269 or something at some point last year but I guess the stock has run out. RX 6600 has been $190-200 since forever. 6600 XT and 6650 XT also haven't been cheap for a long time. In the used market, the supply of cheap RDNA 2 GPUs has also dried out. \n\nAnd unlike Radeon GPUs, B580 isn't only good for gaming. It has good hardware acceleration for video editing, streaming, 3D modelling, and such. Alchemist was also like that. Unlike intel with their CPUs, they don't nerf their GPUs or make arbitrary distinction between consumer grade and workstation grade products. $250 is well worth the money for a well rounded multi purpose GPU, the second best you could have with that money is an old RTX 3060 8GB.",
      "That's amazing.\n\nBut also: for the love of God, give us the B770 already 😅",
      "Intel 13400f is like $130 and fast enough to feed a B580.  You don't need a midrange CPU, even a low end one that's not 5 years old works.\n\nYou can get an i9 12900k for $290, and it'll be way more than sufficient for any game for a long time.  As is the i7 12700k for $200, honestly.\n\nYes, the 9800X3D is great.  But not strictly necessary.",
      "Because AMD constantly do this thing where they have a specific GPU they want to sell, they then price a significantly slower GPU B right next to GPU A in price to entice people to pay more for GPU A, for example the 7900XT and 7700XT were intentionally priced poorly to try and get people to buy the XTX and 7800XT",
      "Won't the B580 perform well still with a 7600x/9600x? I think (not sure) the performance drop happens with much older CPUs and the 7600x should be fine, you may lose some performance in some games but for the majority it would still outperform the 4060 right?",
      "Tbh had my RX6600 for 2 years and was always plagued with this annoying stuttering issue. Tried multiple fixes over that time nothing fixed it. Drove me nuts. Replaced it with a B580 recently and there is the slightest performance dip but thank the good lord the stupid stuttering is gone. All of this paired with the legendary 5600. Imo the overhead things blown up for no reason I’m honestly getting the performance I expected and hopefully it improves with driver updates or else I’ll just have to save up and pay the nvidia tax down the line somewhere lol.",
      "Looks like the price to performance is acceptable, then.",
      "Using this standard, Nvidia is giving you great value if you consider something like the 4070ti is 60% less expensive than the 4090 while giving you 40% less performance!\n\n  \nI don't think it's a great benchmark for value. Using something more standardized would be better ($/fps etc)",
      "rx 6900xt for under 250$? ill believe it when i see it buddy,full working with proof",
      "If they actually release it in volume, it's pretty darn good value for 10GB. 8GB isn't acceptable at all anymore, but 10GB is ~okay for the lowest of the low end cards, which this is.\n\nBut yes, I get your point; It may be 12% for 12%,, but it's practically more than 12% because it's losing ~17% of its VRAM. Upvoted. I think people missed your point.",
      "Wait for drivers maybe? Idk.",
      "this. I feel kinda weirded out by all the fuss tbh. Yes, the overhead issues aren't pretty. But all you need is a reasonable setup. Pairing a $150 CPU with the B580 (a $250 GPU) will result in fine performance. If you use your >10 year old CPU and jam the newest gen GPU into your system...what did they expect?\n\nAs far I know Intel even has 11th gen or newer as system requirement.",
      "Iirc 7600 already sees drop but its mostly caused by using old apis in games. Modern apis handle it much better and closer to top cpu performance"
    ]
  },
  {
    "brand": "intel",
    "generation": "battlemage",
    "tier": "580",
    "matched_keywords": [
      "b580",
      "arc b580"
    ],
    "title": "Intel Arc B580 rumored to get custom dual-GPU version with 48GB memory",
    "selftext": "",
    "comments": [
      "It will be sold out for eternity.",
      "Its not for gaming but for AI. If this is released then the 4090 will lose value on the used market.",
      "...***what***?\n\ntwo cores one pcb? we doin an asus mars 760 moment? intel is bring sli back?",
      "They sell it for $700 5090 GPUs become scrap metal overnight.",
      "It really wont, cause its significantly stronger single chip and 32GB of vram (compared to 2x24GB when memory pooling probably wont be a thing) will be still superior for many tasks.\n\nThat said, this is interesting and exciting news, no doubt.",
      "but it would still just be 24GB per GPU I guess and not shared?",
      "I imagine it will just be 2 cards on one board each using their own x8 pcie lanes",
      "AI workloads can use memory across multiple GPUs. Probably it won't work for gaming though unless they have a new approach.",
      "hopefully it should make the standard version more available though",
      "It depends on the workload. AI and workstation stuff can pool the memory, hence people building workstations with 2-4x 3090s since it's a cheap way to get lots of VRAM and decently fast GPUs. AI clusters have even more GPUs working together through special networking.",
      "9800GX2 was fun with literally two sandwiched 9800GTX PCBs and chips on it.  The PCBs faced inwards.",
      "If this comes out I might pick. I'm curious on the performance of it. I'm getting annoyed with Nvidia ATM and want to switch. Already said I'm getting Celestial when it comes out.",
      "24 vram is great for inference (load deepseek) but bus speed is not great for training",
      "They used to do this a lot on 90 series cards. Take 2 80s and make something 50% stronger.",
      "Not so sure. If this special version is from one of these China-only brands, I doubt it will affect the availability of the base B580 in other markets.",
      "Probably requires bifurcation support from motherboard to make the most out of the two GPUs",
      "5090: FORTY EIGHT?????? Nah I'm Cooked.",
      "Most games don't support multiple GPUs, most programs can pool 24gb of memory from two separate GPUs.\n\nIt can sell well for a very small portion of people, for most it will be useless due to the price to performance ratio.",
      "a bit overkill, no?",
      "In regards for ai??? Let’s say cost to produce is $500 for 2 2.4 GHz 20 core at 48GB DDR6? That’s the max throughput of a GEN 4 256 Bit bus, and they sell for $700 ? Even a $1000 , this would be a amazing enterprise cards considering a 5090 sells 3000 consumer and probably double enterprise , minimum, make it make sense"
    ]
  },
  {
    "brand": "intel",
    "generation": "battlemage",
    "tier": "580",
    "matched_keywords": [
      "b580"
    ],
    "title": "New B580 build",
    "selftext": "My B580 arrived today. \nI've paired it with an i5-12400 and 32 gbs of ddr5 ram",
    "comments": [
      "So much left over space. I love it.",
      "12400 is locked so there's no point getting an AIO. It will do fine with single tower air coolers like Thermal Assassin X, Arctic 36, SE 214 XT, Hyper 212, AK400, Frozn A410 etc",
      "Please upgrade from the stock cooler. Otherwise, awesome",
      "“Did you overclock your gpu” 🤓☝️",
      "Don't bother with AIOs, they have problems with long-term reliability. The 12400 isn't exactly a hot-rod anyway, so a more powerful air cooler should suffice.\n\nI recommend the Peerless Assassin 120 / 120SE. They're budget two-tower coolers that have actually good performance in cooling CPUs. For further information, Gamers Nexus has a review of the Peerless Assassin 120 on their Youtube channel.",
      "Lol, thanks",
      "Fractal Design Focus 2",
      "I don’t have a lot of experiences with AIO’s but a 12400 should be fine on air unless you really want a AIO. I would recommend the Thermalright aqua elite 360 since I have actually tried it and it worked great\n\nOn air the ID-cooling SE 214-XT ARGB",
      "Arctic 36.",
      "I got the peerless assassin 120 to replace my stock cooler on my 12400f and it felt like over kill.  Moved it over to my new build and it's a beast. CPU temp sits at between 56 and 60c normally. \n\nI only have about 2cm clearance between it and the case though. Absolutely no need for AIO",
      "Hey man I have GTX 1050ti I want to upgrade it to Intel arc b580. I have a ryzen 5 3600. Pls tell me should I upgrade it . In future I will upgrade my processor",
      "Please try to train a lora and let us know how it does",
      "damn thats a really nice clean looking system, love it.",
      "Lol, I'll have to look at the arc settings",
      "In gpu intensive games, there isn't a gpu bottleneck. But in cpu intensive games, there's a tiny bottleneck. However, it's like 1-5%, and my monitor maxed out at 1440p maxed 165 fps way before either was used.\n\nFor tripple a games, I think it'll be perfect. Maybe a little too powerful. I think I could've gotten away with a more powerful cpu. But if you get maybe a 5600x, then it's practically the same as an i5-12400. \n\nI haven't tested that many games yet, so please research more before pulling the trigger. But I think the b580 will be great.",
      "I actually went from a 1050ti to my b580 and it doubled my frames in most games just be careful of cpu bottleneck with that older cpu",
      "wonderful, amazing",
      "What case is this?",
      "can the rgb be changed?? i was initially wishing i got the b580 challenger instead of the le but saw it doesn’t have controllable rgb which is a massive deal breaker even as someone who will always use some form of rgb",
      "Looks absolutely fantastic!"
    ]
  },
  {
    "brand": "intel",
    "generation": "battlemage",
    "tier": "580",
    "matched_keywords": [
      "b580"
    ],
    "title": "First build, with B580",
    "selftext": "B580 because gpu market is broken, \n\nCPU 9900X",
    "comments": [
      "Bro got no likes in 30 minutes 😭\n\nLooks nice bro happy gaming!",
      "Chose the best B580 out there (totally not biased)",
      "It has double the power connections so it must have double the power. \n\nThat’s just math.",
      "Therefore double the performance, for just 50 more bucks, that's a deal of a lifetime right there!",
      "That's some fancy looking build, holy sht....I was confused at what I was looking at XD",
      "Love build but also the range of sockets this cooler supports. Own exactly same one and cant be more happy even under gaming with light OC is not exceeding 47 and 5600x is relatively warm on especially on OEM cooler",
      "Oc to 3150 MHz I love it",
      "thermaltake cte c750 air",
      "I guess I'm still confused, too...so all the I/O is on the top? It almost looks like the case in the pictures is sitting on its front. Is the PSU *under* the GPU?\n\nClean build - definitely an eye-catching look!\n\nEdit: [I found the case](https://www.thermaltake.com/cte-c750-air-full-tower-chassis.html) - and I understand what I'm looking at now!",
      "what case is that?",
      "Stylish. but gah the lights.",
      "Sexy steel legend wish I had one :(",
      "Looks beautiful! Happy gaming!",
      "i have the same thermalright mounted the same way",
      "I love it . Beautiful.",
      "Nice build now make it pay for it's self 👌",
      "this is just manasingly great. it looks sacredly awesome. nice build there",
      "What riser did you use for the GPU?",
      "It looks wrong, but cool pc",
      "Beautiful!"
    ]
  },
  {
    "brand": "intel",
    "generation": "battlemage",
    "tier": "580",
    "matched_keywords": [
      "b580"
    ],
    "title": "B580 successful? Just wondering if Intel is seeing the b580 as a success at this point? How many have been sold? Are they making money? What’s the figure of arc?",
    "selftext": "As an owner of a b580 I can say I think it’s a good product that offers a great value. Just kind of wondering if Intel will continue the current trajectory and give Nvidia and amd a run for their money? Pic is of my sparkle b580 right before I installed it. It’s running great!\n",
    "comments": [
      "Considering how much they are selling and how constantly out of stock they are, they probably consider battlemage a success, now whether they actually made a significant profit out of this is a whole another story.\n\n\nNobody knows really, only the execs at Intel know or something.",
      "I'd rather see something in the $350-400 range that competes with a 4070 or 4070 Ti, getting into the higher price range they'd have to compete with CUDA, DLSS, and the better RT performance of NV.  XeSS seems to be really good, QuickSync is great, and overall they're pretty solid but Intel lacks the mindshare to really break in to that price bracket at this point.",
      "It’s gaining market share. I just hope they see for to release a B770. Something about $500-$600 that competes with the 5080 would really stick it to Nvidia and force them to be more competitive.",
      "Anecdotal, but B580's are consistently sold out on newegg.  I don't know if they are making money at the low price but the goal was less about that and more capturing market share.",
      "well considering it sells out within 30 minutes or less after a restock. i think its doing alright its been a month and some. I’ve only seen the b580 stay in stock for two days at most and i think thats because the onix card doesn’t pop up on newegg sometimes and its not on pc part picker at all.",
      "The B580 made intel relevant overnight... AMD and Nvidia is yoo busy trying to milk their consumers...",
      "Surely you have to understand that Intel are selling their GPU's cheaply to gain market share as fast as possible right?\n\nIntel will use this time to gain experience with their GPU, gather consumer feedback and cover their losses with the sale of other products to further their market share going forward.\n\nSelling your product at cost or at a loss is a very very common strategy to gain market share.\n\n\nI think you lack common sense, as well as business sense.",
      "From the way the pre-launch publicity interviews went, I think they were a little surprised at how well received the cards were.  I seem to recall one of their reps saying \"please buy the cards.  Buy as many as you can.\" at the end of an interview.\n\nHonestly, I bet the engineers understood the value the B580 brought to the table, but it is harder to make the executives that bankroll the production and logistics understand.  They likely approved the initial manufacturing runs based on the Alchemist series sales numbers.",
      ">CUDA, DLSS, and the better RT performance of NV\n\nRT performance in Blender is almost on par already and even beats them by a little in some game titles because Nvidia tends to use smaller dies for the same class/price range. OneAPI is still not widely used like CUDA is, but any apps that do use OneAPI run just as fast. Similarly XeSS now has framegen. That's the main advantage i see intel having over AMD - they aimed for feature parity with NV from the start, not just raw raster performance.",
      "Intel said from the gitgo that they weren't making a whole lot of money off of the card itself and this was a \"gift to gamers\" so idk if well ever know but atleast they're stirring up excitement.",
      "I'd buy another!",
      "None of these companies tell you how many they produce, and sell, or what the profit is.",
      "5070 (ti) would be huge already. No way they match 5080. Nvidia has too much of a lead for that. But they don't really need to. To focus on 1440p is fine.",
      "If they have a B770 I’m sure they will have a B750. That would probably be what you’re interested in. Multi frame Generation DLSS looks horrible. Too many artifacts. Intel already does surprisingly well with ray tracing even with the A770. If the B580 is doing it better with less then a A770 then a larger B770 with more faster cores is going to have a large uplift. If it scales and the cores also go faster yet it might be 30 or 40% faster than a B580. XESS already has a good image. I’m not sure what that would work out to be performance wise compared to nvidia but I’m sure it would be a major win for Intel.",
      "I doubt Intel GPU division is profitable but this is a long game - they need quality, competitive products in the world just to put the flag in the ground. Then they can start building the base.",
      "I just installed the LE tonight. I love the design of that card.",
      "Making money no. Selling lots yes. They are forcing themselves into the market by selling at a a loss",
      "A $399 B770 will still be more profitable because fixed costs stay the same. GPU die cost increase isn't that much.",
      "The fact that the A770 competed with the 4060 makes me think the B770 competing with the 5080 is a truly delusional thought. Maybe the 5070 ti.",
      "Considering the 5080 is just a 4080s overclocked in performance then the 5070ti wont be that massive of a jump from a 4070s."
    ]
  },
  {
    "brand": "intel",
    "generation": "battlemage",
    "tier": "580",
    "matched_keywords": [
      "b580"
    ],
    "title": "1k worth it B580 prebuilt?",
    "selftext": "I have a budget of $1200 and I’m REALLY afraid of building a PC on my own. My local microcenter ONLY has the b580 in a prebuilt but I can build the same spec PC w b570 for $880. Is it worth the extra $200 for the 580 or is the B570 good enough??",
    "comments": [
      "Since the B580 needs a great cpu, I think 1k will work",
      "This prebuilt is an insane deal. People are sleeping on it because it's a Micro Center pickup-only exclusive :)",
      "Arguably, 32GB is the new 16GB. You don't *need* it, but it would be nice to have and not need it than need it and not have it IMO. It has DDR5 6000mhz CL30 G.Skill RAM so they're not bad sticks either.",
      "That CPU is.. ehh. Let's run the parts, rounded up from Amazon/NewEgg:\n\n* i5-14400f | $130\n* AS Rock B760M | $150\n* 32GB DDR5-6000 RAM (Corsair/G.Skill/T-Create) | $105\n* 1 TB SSD PCIe 4.0 (Samsung) | $105\n* That PC Case | $75 (An actual good-looking one would only run you up to $20 more)\n* 650w Bronze PSU | $65\n* ARGB Cooler Master CPU Coller | $25\n* Two ARGB Fans | $15, and that's pushing it\n* Keyboard & Mouse | $20\n* GPU Anti-Sag thingamajig: $5\n* Arc B580 | $270\n\nTotal: $975\n\nPart for part it's close to what you'd pay if you built it yourself, but I **really** don't like that CPU, and you could get a much better looking case than that.\n\nI was nervous as hell when I built my first PC and watched 3 different YouTubers walk me through it during the process, but it turned out good after a few hours. Watch some videos of people building them first just to really make sure you don't wanna attempt it. Here's a semi-depth one: https://youtu.be/wbujLJ25oUU?si=OmyJVvQYL10lC0hL\n\nIf you're still set on going with a pre-built after that, then this one is okay, but I would recommend getting a 12th - 14th Gen *600K/KF if you start running into performance issues during gaming.",
      "32GB is far away from overkill.",
      "Wait so there's a $200 difference between just the b580 and the b570 prebuilts? Wtf?!?",
      "Forgive Me. I rushed in.  Yes this is an excellent price",
      "I’m pretty sure, it doesn’t anymore. It changed with some driver updates.",
      "I run 32 gigs because I play a lot of games that are super ram heavy like space engineers but nothing wrong with having extra ram even if you don't need it .",
      "Oh my bad, I misread. I have the b580 and I'm loving it so far. TechPowerUp shows the B580 has 119% the performace of the B570; that 19% may make a difference. With newer games beginning to have trouble with 8gb VRAM GPUs, how long until 10gb has trouble? \n\nI guess considering you're terrified of building a pc (totally fair) plus the better VRAM of the b580, getting the prebuilt b580 may be worth it. Plus you're still a bit under budget.",
      "If you have a bit of patience, you can likely get a B580 from B&H or Newegg for under $300 and then get the rest of the parts from Microcenter/Amazon. I did this recently and managed to build a very nice workstation and get a 34” ultra wide for under your budget. \n\nB580 - $270\nCore ultra 7 or 9700x combo - $450/$500\n(Or save money with a tier lower cpu combo)\nThermalright cpu cooler and case fans - $50\n1TB SSD - $60\nPower Supply - $70\nCase - $70\nWin 11 pro from sftkey - $30\n\nIt’s a pretty impressive build for about $1k",
      "It doesn't need a great CPU just not the absolute worst.",
      "Thank you for the in-depth response and advice!  I’ve been looking at the reviews on the CPU and everyone seems to be correct about it being a possible issue down the road. I’ll look into those options you’ve mentioned and might just swap the CPUs. An extra $250 won’t hurt my budget",
      "If I get the parts and build my own the with b570 it’s $200 cheaper. The b580 isn’t sold solo at any MCs in my state",
      "The b580 is worth like $350 by itself , would be nice if this had a better CPU tho",
      "Something that nobody seems to have said but it is VERY important: \"check the exact model of the psu\"  i've seen too many times E or even worst F tier psu (F tier does not just mean bad, it means is dangerous) in these prebuild",
      "Yeah I mean its microcenter they tend to be one of the only decent prebuild sources.   \nBeats the shit out of a dell.",
      "Not a bad deal at all considering how bad prebuild prices can be",
      "I would recommend that you build what you can yourself. I can guarantee they cut a corner with at least one of the parts. It’ll be some unreliable brand you never heard of.",
      "Definitely worth it"
    ]
  },
  {
    "brand": "intel",
    "generation": "battlemage",
    "tier": "580",
    "matched_keywords": [
      "b580",
      "arc b580"
    ],
    "title": "Intel Arc B580 “Battlemage” Limited Edition card listed at $259",
    "selftext": "",
    "comments": [
      "I was scrolling through a few comments on the linked site, and they were quite bleak. I would like to  be cautiously optimistic and will wait and see what it's like after reviewers get their hands on it. Also would love to see a B770 or higher. I like what Intel is doing and don't want them to stop.",
      "I wouldn't pay much attention to the comments on tech forums, they are filled with some of the most toxic people you could ever come across. That being said, I wasn't expecting that price tag. It feels like a big jump for the 5xx tier cards but who knows maybe the performance will justify the price. And the B750 could end up being a budget beast.",
      "I was hoping for $199, but this is probably the highest they could price it while being reasonable. Hopefully it can reach AD106 perf",
      "If it gets good 1080p performance in games I could see myself getting it since I want to build a new PC at the end of this year",
      "if its gonna be 259 its probably faster than 4060 probs close to 4060ti",
      "Unlikely to exist. There's not much point when A310, A380, Core 200V, and Core 200S exist. Those GPUs will cover off the vast majority of people who want a GPU lower in performance than the B580.",
      "Um, yes, this is exactly how this works. Intel is unlikely to release additional SKUs for a segment that it is already the only option on the market. It would only be competing with itself, and the difference between two generations would not be enough for it to drive people who already have an A3xx to upgrade. It would be a poor business decision to put resources into making SKUs for that segment when those resources could go to segments that will make a bigger difference to Intel's competitiveness against AMD and NVIDIA. \n\nI would not expect a bottom-tier GPU from until until perhaps Druid, at which point people who purchased an A380 might be looking for upgrades, even at their lower budget.",
      "Hoping that at least the high idle power consumption issue is addressed with this model. Drivers will be a whole other thing.",
      "The a750 is already fairly good at 1080p. What kind of numbers are you looking for?",
      "$250 for 12GB sounds pretty good to me and also wait for new year sale might lower its price!",
      "I am not intel so its not my problem 🙃",
      "Well well well, that's a very promising price",
      "Seems like I got my predictions about right.\n\nI'm looking forward to real benchmarks now. If it's as good as the 4060Ti I'm probably snagging one on release, otherwise I might wait for the B770 or go Nvidia.\n\nEdit: The name B580 brings back memories of the legendary RX 580. I hope it delivers the same kind of value that the RX 580 did.",
      "When b310 or b380",
      "A true DLSS alternative.\n\nTechnically FSR 4 should be a true DLSS alternative, but as long as FSR 4 isn't available; AMD is pretty much a non-starter. At least unless the price is just out of this world good.\n\nXeSS is good and Intel seems to be at least somewhat in touch with what the market wants, just limited by the pretty damn terrible Alchemist architecture. If Battlemage is good and the drivers work this time I'd be very happy to get an intel card.\n\nLike I really, really don't want an Nvidia card with how insanely stingy they are with VRAM, but as long as Nvidia has DLSS and AMD doesn't, I'm taking Nvidia.",
      "See you in 6 months! \n\nEDIT: Assuming you've not deleted your account by then.",
      "I guess nobody read the article in the link, it says it's down to 246$ now.",
      "For $260 I feel it needs to match 3070 and 6700XT, as you can get those around that price used nowadays. If this card is slower than the 3070/6700XT, I don't see it doing well.",
      "The leaks are estimating (guessing) it will be at least A770 perf, but seriously, no one knows.\n\n  \nAlso that “step-up” estimation is an awful way to estimate performance, and is exactly how marketing tries to trick buyers into thinking they’re getting more for their money. While it may have held true for some past generations, it’s definitely not a good rule of thumb now. To use your example, the 4060 is slightly weaker than even a 3060ti, so it is not even nearly equivalent to a 3070.",
      "4060 is decently slower than 3070"
    ]
  },
  {
    "brand": "intel",
    "generation": "battlemage",
    "tier": "580",
    "matched_keywords": [
      "b580",
      "arc b580"
    ],
    "title": "Upgrade from rx 6600 to Intel Arc B580",
    "selftext": "I'm going to see how it goes with a ryzen 5 8600g ",
    "comments": [
      "Perhaps a hot take, but I did the same and really liked it.",
      "Nice, those ASRock cards look good!",
      "I'm talking with Intel about insufficient power delivery on the B580\n\nIf they see this as an issue, you should be getting a performance boost once they fix it.\n\nFor example.\nThe finals uses 154w to run\n\nMonster hunter wilds uses 138w to run\n\nAtomfall uses 158w to run.\n\nTDP is 190W\n\nNot a single game has gone that high.\n\nAnd to prove this, if you go turn your voltage up to 60%, your power draw will be higher and your framerate will increase.\n\nMonster hunter wilds goes from 45fps to 56fps in the same scene.\n138w to 165w.\n\nAnd before anyone says \"oh well blah blah it's not the cards fault\"\n\nThe RX 9070 can use up to 320w of power when it is rated for 230w, just by flashing the XT bios to unlock more power draw.\n\nThe B580 can't even get to its TDP with an overclock",
      "Combine them and use both for a dual GPU LSFG setup!",
      "Yeah went from 7600 to b580 and the extra vram is nice but still a few issues with some games, for the most part does fine and",
      "yeah power limit setting doesn't even work for me",
      "Went from an rx 6600 to an A770 16 gb last year in conjunction with switching from 1080p to 1440p, I recommend doing the same here.",
      "6600XT to B580 here 😊",
      "a cpu upgrade would be better but congrats",
      "I mean, I can play AC Shadows at 1080P high settings above 60FPS with my ARC B570, I imagine B580 can do even better so.",
      "With outstanding 1080p and now with 4 playing Fortnite between 75-90 fps all in epic, playing from bed connected to a 50-inch Smart TV",
      "Isn't the 6600/7600 about the same as the b580 performance wise?",
      "Ive been considering an upgrade from my 1660 gtx to the b580. But I'm uncertain about the driver issues and of course how new the company is to gpu manufacturing",
      "The funny thing is I always find it photographs terribly. Like even the official promotional photos I find it looks super cheap but in person it looks great.\n\nI do with the RGB could be adjusted though. You get Blue / Green or off; nothing else and no way to tune it.",
      "You would be fine as the minimum is a 5600X.",
      "How did that upgrade feel?",
      "i have regular 5600 would it do fine or no go?",
      "Yeah because the card doesn't even draw 190w at stock. Move the power limit down until you see a change and you'll see how much performance you could have if the card actually asked for it.\n\nIf you turn the voltage limit up to 60% you'll gain 300 mhz. Just out of nowhere.",
      "I mean. I haven't seen a graphics card yet that doesn't always run at its TDP during max load.\nIts a max power guideline, and if a card isn't at max power, then some of my card is locked away behind a wall. \n\n(9070 has a tdp of 230 but you can flash an XT bios to go all the way up to 320w, which improves performance to be as good as a stock XT with less cores)",
      "Yes."
    ]
  },
  {
    "brand": "intel",
    "generation": "battlemage",
    "tier": "580",
    "matched_keywords": [
      "b580"
    ],
    "title": "3 different GPUs, 1 CFD simulation - FluidX3D \"SLI\"-ing (Intel A770 + Intel B580 + Nvidia Titan Xp) for 678 Million grid cells in 36GB combined VRAM",
    "selftext": "",
    "comments": [
      "My FluidX3D CFD software can \"SLI\" any GPUs together, regardless of microarchitecture or vendor, as long as VRAM capacity and bandwidth are similar. Here I'm running FluidX3D on 3 different GPUs:\n\n* Intel Arc A770 16GB (Alchemist)\n* Intel Arc B580 12GB (Battlemage)\n* Nvidia Titan Xp 12GB (Pascal)\n\n12GB + 12GB + 12GB VRAM are pooled together via domain decomposition, allowing for one large CFD simulation using 36GB combined VRAM, to fit 678 Million grid cells. This is made possible the most powerful GPU programming language, OpenCL.\n\nFluidX3D is available on GitHub, for free: [https://github.com/ProjectPhysX/FluidX3D](https://github.com/ProjectPhysX/FluidX3D)\n\nThe model in this simulation is Santa's sleigh - with some X-wing modifications. Merry Christmas! :)\nThe CAD model is from Zannyth / Kevin Piper: [https://www.thingiverse.com/thing:2632246/files](https://www.thingiverse.com/thing:2632246/files)\n\nPS: My second B580 is currently in my other PC for testing, and for gaming... hence only one B580 here, and an A770 to fill the top PCIe slot instead :D",
      "Is that Santa's X-Wing?",
      "the aerodynamics of a sleigh fitted with x-wing parts, obviously",
      "FluidX3D splits the simulation box into equally sized domains, here 3x 12GB - this simplifies the implementation a lot. The extra 4GB of the A770 are not used.\n\nIt would also be possible to split into 4+3+3 domains, each at 4GB size, and deploy multiple domains on each GPU. But the communication overhead then would slow it down a lot.\n\nHaha yes I need an AMD card for the ultimate team Red-Green-Blue SLI abomination build :D",
      "Yes! Merry Christmas! :)\n\nThe CAD model is from Zannyth / Kevin Piper: [https://www.thingiverse.com/thing:2632246/files](https://www.thingiverse.com/thing:2632246/files)",
      "You mentioned that the pool is 3x12GB. Is the other 4GB of the A770 unable to be used, or is this actually a 40GB pool?\n\nThis makes me want to try a cursed 3-brand, 3-size setup of my own. 3080ti + A770 + 7900XTX should be interesting.",
      "What is it simulating?",
      "Best thing I've ever seen in this sub, amazing",
      "What motheboard are you using does the arc cards require bifurcation?\n\nThanks in advance for any info.  There is quite a few of us noobs that wants to try dual arc gpus.",
      "It would be the ultimate RGB Build",
      "I love seeing these kinds of posts. People actually using their computing horsepower for simulations etc.",
      "Asus ProArt Z790-Creator WiFi. That board supports PCIe 5.0 x8/x8 bifurcation on the first 2 slots, and the third slot is PCIe 4.0 x4. Here they are running at 4.0 x8/x8 and 3.0 x4. Bifurcation is definitely beneficial but not a must; would work with slower PCIe connections too but at a performance hit.",
      "What matters here is VRAM bandwidth. CFD performance is directly proportional to bandwidth. A770 is 560GB/s, B580 is 456GB/s, Titan Xp is 547GB/s. All pretty close to each other which makes them a suitable match.",
      "7700XT + 4070 + B580 would get every fully utilized, or A770 + 4080 + 7800XT.",
      "How did the ARC performance compare to Nvidia? I've been a Cuda user/dev since Cuda 1.0 but the ARC line is speaking to me",
      "When you say that only bandwidth matters but the architecture doesn't. Does that mean it'll work with any combination of gddr6 cards?\n\nAnd/or gddr5 pairings or gddr7 etc.",
      "You are a mad scientist!",
      "Would love to see AMD - INTEL - NVIDIA trio combinations, all in ref/LE for greater good!\n\nTried adjusting that triangle symbol to form RGB - AMD/NVIDIA/INTEL [https://imgur.com/rDiZZA8](https://imgur.com/rDiZZA8)",
      "you need an rx 6700 xt so you have a gpu from every current brand",
      "is 3x A770 is the cheapest way to go for this workload?"
    ]
  },
  {
    "brand": "intel",
    "generation": "battlemage",
    "tier": "580",
    "matched_keywords": [
      "b580",
      "arc b580"
    ],
    "title": "Intel Arc B580 rumored to get custom dual-GPU version with 48GB memory",
    "selftext": "",
    "comments": [
      "Perfect for video rendering, 3d rendering and ai.",
      "Ok now this one is stupid. I believe the 24GB ARC PRO B60 but this makes no sense.",
      "It will be for GPU Flex data center cards.",
      "It makes sense density-wise, i guess they would just need an onboard PCI-E multiplexer and then done, everything is managed though software anyway now. No need to like connect the memory like SLI or crossfire",
      "Yeah, there's the thing. They don't care about gaming when they design something like that lol \n\nAlthough I think technically UE5 can do multi-GPU",
      "This reminds me of the GTX 295 and that AMD/ATI Radeon 6990 (if memory serves).",
      "They don't even need a PCIe switch. Just give each card X8 lanes and that's it. The target workstation and server systems where such cards would be installed support bifurcation anyways.",
      "Not for gamers, but for markets like VDI it makes perfect sense. Heck, depending on price it would sell like hot cakes to AI enthusiasts. I'd buy one if it was under 1k",
      "A card like this wouldn't be being made for gaming. \nIf it becomes a reality, and isn't priced in to doom, I'll be replacing my A770 with it.\nReally hope it's real!",
      "Epyc has even more lanes, but that's missing the point. The reason to make such a card is never the number of PCIe lanes or VRAM. Nvidia makes similar cards for the same purposes (ex: Tesla A16).\n\nThe number of physical cards that can be fit on single 4U server is the main driving factor. Each GPU will get forwarded to a VM for accelerated VDI support. The A16 has four GA107 GPUs, each with 16GB VRAM.",
      "Yup. I'm excited for the simulation possibilities as well.",
      "Maybe not sold on the open market, but there's no shortage of weird hardware comissioned by companies for their own use cases. I've seen weirder stuff on ebay.",
      "Have a look at Intel Data Center GPU Flex Series and Max Series. They've done Arc on a dual GPU setup before specifically for that use. VDI, media encode, etc. is perfect for such a SKU. You're missing the forest for the trees.",
      "More details of affirmation?",
      "This probably doesn't exist. It's much more likely that we'll get the 24GB model.",
      "Please be real, and release at a good price!",
      "It was pretty common at the time for them to band even two lower end cards together essentially pre-packaged in SLI or Crossfire. It just wasn't that successful because it would negate the cost savings of buying two midrange cards and getting top tier performance",
      "What's a 1080p card ? Nobody cares about that in compute workloads.",
      "> a really unreliable website \n\nIt's not.",
      "Maybe the Melville Sound idea isn't dead. GPU Flex B250 or whatever could be a fun one. \n\nBut also makes me wonder why DeepLink HyperEncode and HyperCompute got discontinued. Maybe it's just getting replaced by a different technology?"
    ]
  },
  {
    "brand": "intel",
    "generation": "battlemage",
    "tier": "580",
    "matched_keywords": [
      "b580",
      "arc b580"
    ],
    "title": "I really want to believe Intel's claim that the drivers for its new Arc B580 1440p graphics card suffer from 'no known issues of any kind'",
    "selftext": "",
    "comments": [
      "Guaranteed there’s an internal bug database at Intel that shows there are in fact issues of some kind. Because all software has issues.",
      "> That is the reviewers' job.\n\nYou should know that a comment like this is bait for someone like me ;) I try to find at least one thing that reviewers miss with every cycle, the last being [loading time regressions with Arrow Lake](https://old.reddit.com/r/intel/comments/1gdib7e/a_regression_that_most_reviewers_missed_loading/)",
      "I'm tempted to buy a B580 just to put this claim to the test",
      "Of course there are issues, but I think they meant there are no big show-stopping issues, which I'm inclined to agree with.",
      "Save your money.\n\nThat is the reviewers' job.",
      "Where did Intel claim this?",
      "On the PC World podcast a couple days ago, Tom Peterson just said they aren't aware of any known issues. Literally just a CYA statement in response to a question that he was asked, then PC Gamer turned it into an article for some reason.\n\n36:08 in the video linked in the \"article\".",
      "oh that stuff was you? that explains the 'fuck it we ball' vibe",
      "I’m getting one. I’ve had enough of nvidia.",
      "he's had enough of refinancing his mortgage every time a 90 series card comes out.",
      "Even Nvidia and AMD have issues with some games from time to time, don't know why people expect perfection when it's Intel.",
      "Intel never said there were no known issues. The article's author just lied.",
      "No, I’ve had enough of the prices, lack of vram, overhyped raytracing (basically it’s useless on lower end cards), dlss is also overhyped and looks mucky. I’m currently using a 3070. The 4060 and 4070 were a joke, barely even an upgrade. Overhyped, overpriced and underwhelming.",
      "I’m so impressed by my intel arc a770, never had a problem with drivers of course just play Diablo 2 resurrected and path of exile weeee",
      "I hope Battlemage does well, XESS seems like it's a true competitor to DLSS, and the price to performance is competitive.\n\n\nThe extra VRAM & Bandwidth thanks to the wider bus widths will also age incredibly well.",
      "Bugs are fine, they can get fixed. \n\nI'm actually kinda intrigued and will most likely buy a B580 and then later upgrade to B770 once it comes out",
      "It's silly of them to make that claim. Arc software was garbage on release and  look at the Arrow Lake fiasco as a recent example.  Drivers and software have never been Intel's strong point and GFX drivers are one of those things that are constantly updated to address bugs and improve performance.",
      "XeSS intel actually did something very right there versus fsr which is still a blurry mess (but even that has value as it may enable gamers with big budget constraints to enjoy otherwise unplayable titles)",
      "All software has bug, but if they solve the major issue it's good enough",
      "\"known\" whoever said that isn't lying if they never checked"
    ]
  },
  {
    "brand": "intel",
    "generation": "battlemage",
    "tier": "580",
    "matched_keywords": [
      "b580",
      "arc b580"
    ],
    "title": "Intel Arc B580 Battlemage GPU specs leaked in accidental retailer listing — Arc B580 features PCIe 5.0 x8 interface, 12GB GDDR6, and 192-bit memory interface",
    "selftext": "",
    "comments": [
      "Hopefully we can get a A770 16gb successor\n: (",
      "They meant for the A770 to match the 3070, and the devil in the details is it *can* under synthetic loads and certain gaming loads where its particular design can shine.\n\nHopefully the B7xx model matches or exceeds the RTX 4070. I've been holding off on getting a used 40 series GPU because I want to see if Battlemage can deliver.",
      "A PCI-E card is always going to fit in a 16x slot by design.",
      "I'm not really a fan of this trend of making GPUs run at x8 electrically while fitting in a x16 slot.",
      "if they don't solve the idle power consupmtion without ASPM then my next gpu will be nvidia, even while watching youtube videos the card eats 40W while nvidia cards eats less than 10W",
      "My power outlet is capable of 1500W for the likes of toasters, hairdryers and electric kettles, I think it's a cop out that my night light fits into the same slot and barely draws any power. The port is capable of so much more, why don't we use it?",
      "maybe so on pcie 5.0 supported systems the gpu hogs less lanes? that's the only optimization i could think of. \n\nthose two extra 4x lane ssds are surely worth it or something lmao",
      "Baseless claim",
      "Fingers crossed. I’m hoping they will make the G31 die. With 0% market share and not much money they have no incentive to do so.",
      "i mean, it's supposed to be the point from how i understand, the A770 was no 3090 competitor but rather an actually reasonable 3060ti-ish card. same goes for the rest of the lineup (a380, a580, a750) all affordable cards given their each respective roles for what they offer.",
      "Now one thing that is weird is the fact that one model comes with one 8-pin, while the other comes with 2 8-pins. That's just straight up strange. If one came with 8+6 pins and other one with 8+8 I would get it, maybe the other model is a bit more overclocked and thus needed a bit more power, but jumping from 8pin to 8+8pin in one same GPU? \n\n(Could be also just an error and the 8+8pin is in fact a higher model but still strange)",
      "this =(\n\nbut i want 16gb and 256bit",
      "Not everyone has integrated graphics.",
      "Really? They gonna cut down 16gb to 12gb? I don't believe it",
      "I hope that it will work well on Linux. I also wonder if there will be a worthy upgrade over my 6700XT in the lineup.",
      "Meanwhile my 3090 idles at ~100W",
      "Yeeees, but I still think it's a cheap cop-out.",
      "for me it would work out since my CPU (8600g) i believe has a limit of x8 for the GPU. Obviously i want to upgrade the CPU at some point, but a nice upgrade to the B580 would be a nice interim GPU. Hopefully its price reasonably, is more performant than the A750 and actually releases in the UK.",
      "Get a halogen night light",
      "Why needs pcie 5.0 x 8 with gddr6 and 192 bit. What benefit of it?"
    ]
  },
  {
    "brand": "intel",
    "generation": "battlemage",
    "tier": "580",
    "matched_keywords": [
      "b580"
    ],
    "title": "B580 Crushes 1440p",
    "selftext": "I'm running on an $800 build and this thing just crushes 1440p.  I know 4k is like, the coolest, but I honestly don't know what 4k gives in terms of gaming experience that 1440p doesn't.",
    "comments": [
      "Play what you like\n\nI like 1440p ultrawide",
      "The B580 does seem to be a 1440p/60 card. That is the sweet spot.",
      "Unbelievably inexpensive to build out a DDR4 system, 32GB of Corsair 3200 was like $54 to go with this silly cheap mobo.  And $250 for a 12GB GPU...  It's like a golden age for PC gaming right now, in my wildest dreams I didn't think I could go on-brand, high-quality for every single part in my build for under $800 and play games like Metro Exodus on 1440p ultra with silk for FPS.",
      "Refresh rate is better than 4k.",
      "What CPU and motherboard are you running?",
      "I5-14400 on a gigabyte DDR4 B760m",
      "I run a 9800x3d/4090 on UW1440p OLED and its the most beautiful thing in every gane I try. Love me some ultrawide.",
      "Bruh when did he say that",
      "To me the 4k thing all comes down to display size.\nThe crispness of a 27 or 28 inch 4K is glorious.  I had a cheap 28 inch 4K@60 monitor for a couple years and \"upgraded\" to a nice Acer 27 inch 170 HZ 1440p and I wish I'd kept the 4k. I play a lot of strategy type games, so while the higher refresh is nice it doesn't make much difference in most of my gaming so I'd rather have the pixel count. \nDifferent people have different use cases, so while you may not see a benefit, some do. \nUltimately, though, you either play on what you want or you play on what you have. Don't let anyone else's opinions spoil your enjoyment.",
      "What if I told you I hooked up an Xbox controller to the PC too 🙃",
      "I play at 5120x1440 on my A770LE currently, but moving to B580 once it comes in next week.",
      "Yeah after the last driver update I'm getting 60+ FPS on cyberpunk with raytracing on. Shit rips.",
      "I mean 4K honestly is for TV gaming, otherwise not many reasons to need 4K gaming",
      "I agree completely.",
      "I'm running that same motherboard with a 14900ks",
      "The A750 does it well too.",
      "Pixel density is the metric you're thinking of I believe. 1440p on a 24 inch screen is very different than on a 28 inch",
      "I have a 4k OLED and a 4090. I bought a b580 and tested it out. Worked well at 1440p, 4K was a challenge outside of cs2. Performance from 1080p to 1440p scales better than you expect. Currently in my daughter’s build and working very well with her 5800x3d.",
      "I just got myself a 27\" 1440p monitor and so far I've only played RDR2 but I'm getting 100+ fps with almost everything on high.",
      "Honestly it can handle 1440p at 80-100 gps in most games"
    ]
  },
  {
    "brand": "intel",
    "generation": "battlemage",
    "tier": "570",
    "matched_keywords": [
      "b570"
    ],
    "title": "Future B series cards? ",
    "selftext": "Sorry for the ignorance, i genuinely tried looking up to see if intel had announced other B series cards other than the B580 and B570. I really want to make the jump to Intel cards, but the 580 would be a side-grade at best. \nHow was the A series roll out? Did it take time for higher end cards to be introduced? \nIt just seems odd to me they only announced two cards. ",
    "comments": [
      "The A series started with the A380, with the A580 being one of the last cards. This time the B580 and A570 (no Alchemist equivalent) came out first. I think if there is going to be a more powerful gpu it will be released in March next year.",
      "During a recent interview the head of Intel Arc said Celestial (Arc gen 3) is ahead of schedule. I think i remember from like back in 2022 they wanted to do YEARLY gpu updates... maybe Q4 next year is C770?",
      "It’s strange to me, I can’t even find anyone online asking the same question. It seems like everyone is just hyped about the two they released, no one is asking, or even speculating about future battle mage cards.",
      "I really hope they come out with something in the spring. I don’t want to wait another year lol"
    ]
  },
  {
    "brand": "intel",
    "generation": "battlemage",
    "tier": "570",
    "matched_keywords": [
      "arc b570",
      "b570"
    ],
    "title": "ASRock Intel ARC B570 Out",
    "selftext": "At your local Micro Center",
    "comments": [
      "I'm upgrading my son's PC from a GTX 1080 and the other one is for me. I work I don't need to scalp it",
      "> I work I don’t need to scalp it\n\nGood man",
      "Unfortunately, I think even with this post you're going to get some anti-scalping downvotes from people that don't bother reading lol thanks for the update though and I'm sure you'll both love the upgrades!",
      "Wait they are actually released!? What the heck, I thought they weren't going to be released so soon. I seen the listing on my local Microcenter store, but it got taken down right away. It's not even understand sold out!",
      "That's because the people jump to conclusions without reading",
      "One for his PC, one for his son's.",
      "Damn, i did ask too early, getting nuked in downvotes haha",
      "You have to get creative to get drivers working on those. The installer likely won't work, but at least one other B570 user was able to manually point Windows to the unpacked driver directory via the card's Device manager properties.\n\n\nIt reports as a B580, but should get you going until Intel updates with launch drivers.\n\n\nIf you can share some benchmarks, that would be great!",
      "Another braindead exaggeration smh",
      "I wouldn't be able to tell you I can only compare it to what I have which is the GTX 1080 never had an RTX would that said is definitely better than what I have 👍😎🔥",
      "1080 non-ti is somewhere around an 8 gb 3060 in performance.  B570 should be a slight upgrade, a bit faster than a 3060 and with 10Gb if on a modern CPU with ReBAR enabled.  Hardware XeSS would be a nice plus.\n\nThe big question is: does a PC from the 1080 era have ReBAR enabled, or can it?  My Gigabyte DS3H latest BIOS enables it on a 3600 or newer CPU, but none of the older BIOSes have the option.\n\n1080 non-Ti is what I'm running, and the minimum I'd bother as an upgrade is the $25 more expensive B580.  Holding out for the B770 or 9070XT for a true upgrade though.",
      "Okay, so I had to wrestle with the latest Arc drivers on Windows 11 Pro and manually install them. I used 7 zip to extract the drivers to a folder. From there I opened up the device manager right click on the Microsoft display adapter driver and updated the driver. From there I had to tell it to let me install my drivers and went through the extracted folder.  My workstation/server/gaming rig now sees the Arc b570 as a b80.  Crazy, right?  Playing Last of Us on Ultra, I only got 15-20fps, but after tweaking settings, I hit 50-60fps on High. That's with my W-2155. Haven't tried it on my other server (the W-2175 with 14 cores) yet.\n\nHP Z4 G4 workstation\n32 gigs of RAM ddr4\n2TB Western digital nvme\nIntel Xeon w-2155 processor\nIntel ARC B570",
      "What about this looks bad?",
      "Bro asked too early 😔",
      "rebar uefi mod.",
      "Hardware Unboxed did not find that it needs a 9800X3D to run fine and you know that.",
      "It's sold out everywhere and I'm not going to pay $150 over the mfp price which what I see on Craigslist eBay and even Facebook Marketplace",
      "Sold out everywhere. I am not paying $150 over manufacturer price",
      "Was getting ready to pull the trigger on one but:\n\n\nA) I found out these things suck at VR, which unfortunately is 50% of why I'm upgrading from an RTX2060\n\n\nB) found an RX6900XT for 80% of its price which well, destroyed the bang for the buck-ness of the Intel one...",
      "Don't be so sure.  The 1080, even non-TI, is on the same level as the 6Gb version of the 3060.  Not far off, at any case.\n\nThe B570 should be somewhere between a 3060 6Gb and 4060 8Gb in performance.  So don't expect a night and day difference, especially if you don't have a latest gen CPU."
    ]
  },
  {
    "brand": "intel",
    "generation": "battlemage",
    "tier": "570",
    "matched_keywords": [
      "arc b570",
      "b570"
    ],
    "title": "Intel announces Arc B580 at $249 and Arc B570 GPUs at $219 - VideoCardz.com",
    "selftext": "",
    "comments": [
      "It will probably also be around $500",
      "Intel is claiming that the Arc B580 is 10% faster than the GeForce RTX 4060 at 1440p\n\nhttps://cdn.mos.cms.futurecdn.net/9C9zEHTPExVJYkeAFNbvg-1200-80.jpg.webp\n\nhttps://cdn.mos.cms.futurecdn.net/42zbBqpa3CtyBcgp7fjw9n-1200-80.jpg.webp",
      "B580 for $250 sounds reasonable if the rumored spec is true, B570 feels like only exist to upsell B580.",
      "i think it is just there for the part defectly B580 chips.\n\nSo u can still sell those chips.",
      "And the scariest thing it will probably only have 8GB of VRAM",
      "I think that the pricepoint and VRAM amounts are definitely interesting.\n\nThe A580 looks really promising whereas the A570 may be a deal once it hits a sub 200 dollars street price.\n\nLet's see how the perform, Xe2 has been working great on Lunar Lake.",
      "4060 was also barely any faster than the 3060 and straight up tanks if vram limited (which can happen even at 1080p whereas a higher vram card can allow maxed out texture)",
      "did you write A when you wanted to write B?",
      "This looks like a pretty good deal and a real 3rd option to budget PC builders/buyers out there.\n\n12g of vram on a $250 card is pretty good.\n\nWaiting to see real benchmarks. I hope one day Arc GPUs can match 70-80 series nvidia performance, I might really consider going a full intel build for fun.",
      "It is also rumored to have 8GB of VRAM which will most definitely kill performance in modern titles",
      "No, Intel is claiming that it is 24% faster than the Arc 750 and 10% faster than the GeForce RTX 4060 at 1440p\n\nhttps://cdn.mos.cms.futurecdn.net/JasQiFARCQoPfWhn25V2Sm-1200-80.jpg.webp\n\nhttps://cdn.mos.cms.futurecdn.net/42zbBqpa3CtyBcgp7fjw9n-1200-80.jpg.webp",
      "Intel is claiming 10%, not 32%\n\nhttps://cdn.mos.cms.futurecdn.net/42zbBqpa3CtyBcgp7fjw9n-1200-80.jpg.webp",
      "This would have been impressive 2 years ago.",
      "Yes, the B570 might look weird at first blush, but it's there because of binning. And I suspect, like others, it'll drop in price to make the segmentation make more sense on the street.\n\nI only wish the power was down more.",
      "Its like 15% faster than the 7600 tho",
      "The 7900XT to B580's 7900XTX",
      "\"rumours\" this early are usually a bunch of nonsense and guesses. RTX 5060 won't launch until much later into 2025, the xx60 card has historically been released quite a few months after the top end xx90 and xx80 cards. So it's not gonna be relevant until maybe Q3 '25. Until then, B580 is exciting for the lower end market. It's cheaper, faster on average, more VRAM, better than AMD on the software side.",
      "I like your funny words, magic man",
      "You seem to not understand the problem. Problem being regression between generations in VRAM department. And the thing is that insufficient VRAM means:\n\na) faster aging of your card\n\nb) quality issues (look at RTX 4060Ti 16GB vs 8GB reviews, turns out that performance is one thing but 8GB version in multiple games outright loaded lower quality textures/had more visible pop-in effect)\n\nc) at some point you just can't pick higher quality textures just cuz you don't have enough memory\n\nd) customers should not have to decide whether they want a 3060 or a 4060, it should be a one sided upgrade (higher generation, same tier). \n\n>unless all you play is the handful of games that are VRAM hogs\n\nWhat is a \"VRAM hog\" today will be a normal amount needed for medium/high settings 2 years from now.",
      "272mm2 die is poor PPA Vs AD106 & 107 and likely Navi 44 & 48. Despite that Battlemage iGPU on LNL is much better in that regard. Great price points but I kinda dread if they're likely losing money on these things. I suppose that's why G31/B7x0 is canned as rumoured because it won't be cost competitive Vs N48."
    ]
  },
  {
    "brand": "intel",
    "generation": "battlemage",
    "tier": "570",
    "matched_keywords": [
      "arc b570",
      "b570"
    ],
    "title": "Intel Arc B570 \"Battlemage\" GPU Tested In Geekbench: Roughly 12% Slower Than Arc B580 For 12% Lower Price",
    "selftext": "",
    "comments": [
      "%1 down the price for every 1% performance lower performance? That's absoutely incredible\n\nNvidia and AMD could never",
      "Let's make sure it doesn't need a 7800X3D to meet it's potential.",
      "Hopefully it is tested with midrange CPUs as well",
      "No, they aren't. These already showing its age. Intels drivers are Ok. It will be getting better over time. But soapy FSR scaling can't be fixed on current AMD gen cards, neither RT performance. Additional 4 GB of VRAM can't be added either. \n\n\nRegarding value. As per article, B580 still holds its value even when paired with 5600. Now look at it this way - you get nice performance bonus sometimes, pairing it with faster CPU. Which is additional value (I mean - upgrade path).",
      "Well, driver overhead is when cpu hits the wall and can't feed GPU fast enough. So GPU has to wait. Therefore common sense says that for lower performance GPUs driver overhead should be less noticeable. Of cause, RTX 4090 have the biggest driver overhead problem - just look at performance difference between 9800x3D and ryzen 5600 when using RTX 4090. :))",
      "great now hope we can actually get them for near msrp.",
      "Me still with a GTX 1080…",
      "Intel 13400f is like $130 and fast enough to feed a B580.  You don't need a midrange CPU, even a low end one that's not 5 years old works.\n\nYou can get an i9 12900k for $290, and it'll be way more than sufficient for any game for a long time.  As is the i7 12700k for $200, honestly.\n\nYes, the 9800X3D is great.  But not strictly necessary.",
      "Won't the B580 perform well still with a 7600x/9600x? I think (not sure) the performance drop happens with much older CPUs and the 7600x should be fine, you may lose some performance in some games but for the majority it would still outperform the 4060 right?",
      "Kind of missing the point there. AMD cards suck at RT and upscaling because they're cheaping out on hardware RT and AI accelerations, as well as encoding and others. Their die size is tiny mainly because they're skimping out on those features, their GPU design department was divided into RDNA and CDNA so they could skimp on features they think a consumer grade GPU doesn't need. They're (barely) cheaper than nvidia cards because they really are cheap to produce. Look at RX 7600's tiny die fabricated on last gen node. It should be much cheaper than it is now. Why is their driver better? Because they had acquired ATI long ago, one of the oldest high performance GPU producers, far older than Nvidia. They had been toe-to-toe with Nvidia since the late 90s.\n\nI don't think their last and current gen GPUs are necessarily good value. 6700 XT at $330 is definitely not good value, it's barely even more powerful than RX 7600 in rasterization in some games, and the gap is even smaller when you compare it to B580, with B580 dominating at some titles. It used to be $269 or something at some point last year but I guess the stock has run out. RX 6600 has been $190-200 since forever. 6600 XT and 6650 XT also haven't been cheap for a long time. In the used market, the supply of cheap RDNA 2 GPUs has also dried out. \n\nAnd unlike Radeon GPUs, B580 isn't only good for gaming. It has good hardware acceleration for video editing, streaming, 3D modelling, and such. Alchemist was also like that. Unlike intel with their CPUs, they don't nerf their GPUs or make arbitrary distinction between consumer grade and workstation grade products. $250 is well worth the money for a well rounded multi purpose GPU, the second best you could have with that money is an old RTX 3060 8GB.",
      "That's amazing.\n\nBut also: for the love of God, give us the B770 already 😅",
      "Tbh had my RX6600 for 2 years and was always plagued with this annoying stuttering issue. Tried multiple fixes over that time nothing fixed it. Drove me nuts. Replaced it with a B580 recently and there is the slightest performance dip but thank the good lord the stupid stuttering is gone. All of this paired with the legendary 5600. Imo the overhead things blown up for no reason I’m honestly getting the performance I expected and hopefully it improves with driver updates or else I’ll just have to save up and pay the nvidia tax down the line somewhere lol.",
      "Because AMD constantly do this thing where they have a specific GPU they want to sell, they then price a significantly slower GPU B right next to GPU A in price to entice people to pay more for GPU A, for example the 7900XT and 7700XT were intentionally priced poorly to try and get people to buy the XTX and 7800XT",
      "rx 6900xt for under 250$? ill believe it when i see it buddy,full working with proof",
      "Looks like the price to performance is acceptable, then.",
      "Using this standard, Nvidia is giving you great value if you consider something like the 4070ti is 60% less expensive than the 4090 while giving you 40% less performance!\n\n  \nI don't think it's a great benchmark for value. Using something more standardized would be better ($/fps etc)",
      "If they actually release it in volume, it's pretty darn good value for 10GB. 8GB isn't acceptable at all anymore, but 10GB is ~okay for the lowest of the low end cards, which this is.\n\nBut yes, I get your point; It may be 12% for 12%,, but it's practically more than 12% because it's losing ~17% of its VRAM. Upvoted. I think people missed your point.",
      "Wait for drivers maybe? Idk.",
      "this. I feel kinda weirded out by all the fuss tbh. Yes, the overhead issues aren't pretty. But all you need is a reasonable setup. Pairing a $150 CPU with the B580 (a $250 GPU) will result in fine performance. If you use your >10 year old CPU and jam the newest gen GPU into your system...what did they expect?\n\nAs far I know Intel even has 11th gen or newer as system requirement.",
      "Iirc 7600 already sees drop but its mostly caused by using old apis in games. Modern apis handle it much better and closer to top cpu performance"
    ]
  },
  {
    "brand": "intel",
    "generation": "battlemage",
    "tier": "570",
    "matched_keywords": [
      "arc b570",
      "b570"
    ],
    "title": "Intel Arc B570 specs leaked: 18 Xe2-Cores, 10GB memory and PCIe 4.0x8",
    "selftext": "",
    "comments": [
      "an actual true budget card with 10gb vrm and under 200$",
      "\\>10gb\n\n\\>1x8 pin\n\nLow power draw budget GPU with better specs than a 4060?",
      "If it’s actually under $200 that would be awesome. My hope for battlemage has been it can help Intel grow into a true 3rd gpu competitor to keep the other companies in check. The market has gotten ridiculous due to a lack of competition.",
      "Honestly funny how for months on Videocardz, Intel was getting dragged through the mud, with everyone saying their dGPUs would never come out. But now that a few specs have leaked, there's been a total turnaround, and suddenly everyone is celebrating because the budget segment is back.\n\nI only hope Battlemage performs consistently well in most games and we get some serious competition for the sub 300$ GPUs.",
      "Now just take a look at this: the lowest end Battlemage for now has 10GBs of memory. Not 8, not 6, not 4. 10 gigs for lowest end card. Remember the time Nvidia or AMD did something similar?",
      "Really solid card. Hope we get some news on the B770 (or whatever it ends up being) with the press release next week, too. If that segment gets a similar glow-up could be a really attractive card. Looking to upgrade my A770 in the new few months, and would be happy to stick with Intel.",
      "Yeah, wishing for the same thing. Even alchemist gpus already have a better professional workflow than amd ones which is a travesty, how amd can dominant the cpu space and then be such a joke for everything but GAMING ONLY or apus in the gpu space is mind boggling to me. Really hoping Intel pushes it up so Nvidia has to actually innovate and amd wakes up.",
      "B580 is targeting 4060ti performance with 20 xe2 cores. 18 might as well edge out the 4060",
      "Not really, Intel still has massive market share in enterprise and business. Most pre-builts are also Intel systems. People saying they're on the verge of bankruptcy are simply incorrect, Intel is nowhere near bankruptcy.",
      "Well at this point it's B580 or I'm waiting for RDNA5.",
      "If the B580 is 250, then the B570 is probably going to be like $200 to $220. I don't think it'll be much lower than that. They need to turn a profit from this generation, and there's still Alchemist stock to sell off.",
      "Really waiting for the B770!",
      "It sounds cool but the thing that scares me away is Intel Arc's hit and miss performance in older games",
      "True with AMD, but they also didn't bring a lot new with 7600, still 8GB, still 128bit memory bus. Nvidia though is on a next level, giving the 4060 and 4060Ti such reductions in VRAM parametres. I hope Battlemage gets so successfull it'll force Nvidia and AMD abandon that petty 8GB 128bit memory config for lower end cards.",
      "To be honest, I'm more interested in the B770. Wonder when we'll see info regarding that.",
      "I hope people are actually buying and not wishing for a third competitor so they can buy cheaper NVIDIA.",
      "There was a similar feature developed under the ExtraSS name a while back, but they haven't really referenced it recently. ExtraSS is also a bit unique in that it's not an interpolative technique, but rather an extrapolative one. Pretty neat white paper, hopefully it ends up in a product at some point, either via future software rollout or otherwise.\n\n[https://wccftech.com/intel-frame-generation-technology-xess-coming-soon-extrass-frame-extrapolation-boost-game-fps/](https://wccftech.com/intel-frame-generation-technology-xess-coming-soon-extrass-frame-extrapolation-boost-game-fps/)\n\n[https://dl.acm.org/doi/pdf/10.1145/3610548.3618224](https://dl.acm.org/doi/pdf/10.1145/3610548.3618224) (direct PDF)",
      "Probably not. I think the B570 is probably going to end up somewhere around the A770 to 4060 range.",
      "Wait for reviews, nobody knows how it will perform in games. The synthetic benchmark (for the B580) is looking solid and even winning against the 4060 Ti based on some leaks.\n\n[Intel Arc B580/B570 and AMD Navi 44 may reportedly win with RTX 4060 Ti in synthetic tests](https://videocardz.com/newz/intel-arc-b580-b570-and-amd-navi-44-may-reportedly-win-with-rtx-4060-ti-in-synthetic-tests)",
      "B580 was listed at 260 usd"
    ]
  },
  {
    "brand": "intel",
    "generation": "battlemage",
    "tier": "570",
    "matched_keywords": [
      "arc b570",
      "b570"
    ],
    "title": "Exclusive: Intel Arc Battlemage to launch December 12th",
    "selftext": "Intel will unveil its Battlemage GPUs next week, launching mid-December. The Arc B580 and Arc B570 will be the first models from the Xe2-HPG-based series, with reviews expected to go live on December 12th.",
    "comments": [
      "Long awaited. Can't wait to see the benchmarks for these. I'm really hoping that these end up lighting a fire under AMD and Nvidia to improve their offerings for the lower end and mid-range.",
      "As someone only interested in the enthusiast sector these probably won't have anything that interests me but more competition in the market is always good. \n\nI'm just holding out for the 5080 hoping that the performance and price are decent.",
      "As someone who likes compare apples to apples... This card is supposed to list for $250.\n\nAs someone who hasn't been hiding under a rock for the last few years, the 5080 price will not be \"decent.\" It might actually be obscene.",
      "Forever the bane of GPU market competition: consumers. \n\nEveryone wants more competition, and then only ever buys Nvidia thus creating the self-fulfilling prophecy of Nvidia forever dominating sales and thus R&D and thus sales and thus…",
      "https://www.reddit.com/r/intel/comments/1h184nv/intel_arc_b580_battlemage_limited_edition_card/\n\nThey are claiming these b580 will list for $250, and come with 12gb RAM. 4060 ti level of performance in another leak, but gotta wait on 3rd party benchmarks, and then see how the newest Intel drivers are in various games. \n\nSince NVIDIA, and AMD doesn't have a decent $250 card, this could end up being a solid option depending on the games someone plays.",
      "Smart move by Intel to launch B570 and B580 first, obviously mid end GPU is what most people going to buy. B580 arround $200 but with RTX 4060/Ti performance is going to sell like hot cakes.",
      "The type of uninformed take that will forever keep the Nvidia hegemony alive.\n\nNvidia absolutely owns the top end, but everywhere from a 4080 and below has direct competition from AMD at every price point. DLSS and some more software like NVENC are definitely differentiators.\n\nBut to say that AMD only has a place in budget builds is factually and practically false.",
      "With the 8-core Xe2 LPG hitting 4.1K TimeSpy, I'm hoping a 20-core Xe2 at 40% higher clocks can at least hit 12K TimeSpy.",
      "I just want a B310 or B380 equivalent of the A310 and A380",
      "Its going to be 4060ti performance seeing the a770 is already on par with the 4060 now with the new drivers. Youre also forgetting the crucial vram amount.\n\n1440p monitors have really plummeted in price and this would be the perfect pair for value. Even the 7600 xt and the 4060ti 16gb suffer there because their memory bandwidth is too low but the b580 has 55% more than them.",
      "Hey alcoholicplankton69, your comment has been removed because we dont want to give *that site* any additional SEO. If you must refer to it, please refer to it as *LoserBenchmark*\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/intel) if you have any questions or concerns.*",
      "A Thanksgiving Battlemage Surprise - Let’s Do This",
      "Intel have the XMX XeSS which is DLSS level of clarity and have intel quicksync which is better NVENC. The only advantage nvenc had was super fast encoding, but now arc have the same speed.",
      "1440p gaming with the B580 and Frame Generation",
      "> I'm just holding out for the 5080 hoping that the performance and price are decent.\n\nif you are going 80 series then you will have the performance but will have to pay for it... I would think a 70 series ti would be better bang for the buck. plus with all the AI its not like these babies are going to go down in price I would bet expect the 50 series to be even more expensive. Especially if there is a new import tax.",
      "They probably won't release a card like that unless they have a lot of defects.",
      "Theres a big hardware change that made compatibility way easier. You can already see how much it helped with lunar lake thats also battlemage",
      "> their cards work on like 40% of games\n\nYou should be honest rather than just making stuff up.\n\nhttps://youtu.be/Y09iNxx5nFE?t=1207\n\nOut of 250, 218 worked flawlessly, 11 of the ones that required a \"fix\" (Disabling the iGPU) was because of the game, not intel, as the game has it set to launch on an AMD GPU if it detects an intel GPU.",
      "They don’t want genuine competition, they want another entrant to make their Nvidia purchase cheaper. Real shit.",
      "Excited to see if Battlemage will be the new go-to budget range"
    ]
  },
  {
    "brand": "intel",
    "generation": "battlemage",
    "tier": "570",
    "matched_keywords": [
      "b570"
    ],
    "title": "The Intel Arc B580's (estimated) Production Cost + Profitability Analysis",
    "selftext": "Hey everyone!\n\nA lot of discussion in this forum has centered around wondering if Intel makes profit on the Arc B580.  I will attempt to provide a best and worst case scenario for cost of production.\n\n**Important Disclaimer**: I am not a semiconductor industry professional. These are just very rough estimates based on a combination of publicly available and inferred information (and I'll indicate which values are estimated).\n\nLet's begin! A GPU consists of a few main components namely the die (the silicon itself), the memory (VRAM) and the board (PCB).\n\n# 1. BMG-G21 Die Cost\n\nAccording to [TechPowerUp](https://www.techpowerup.com/gpu-specs/arc-b580.c4244), the B580 uses Intel's BMG-G21 die.\n\nBMG-G21 has 2560 shader cores, 160 TMUs and 80 ROPs. If you're interested in reading more about the core microarchitecture at work here, Chips and Cheese has a fantastic breakdown [here](https://chipsandcheese.com/p/intels-battlemage-architecture). These numbers aren't too important as they can change between architectures and aren't directly comparable, even between the same vendor. The B580 uses a fully enabled version of the die, while the B570 uses the same die but with around 10% of the cores disabled.\n\nThe main things on that page that we care about are the \"process size\" and the \"die size\" boxes.\n\nLet's start with the die size. Underneath the heatsink, the B580 looks something like this:\n\n[Isn't it beautiful?](https://preview.redd.it/0lhwbz3aulle1.png?width=977&format=png&auto=webp&s=0fc9cba3ba2d4d3dfd2604c8c9c5d509c8fafc95)\n\nWe know from TPU and other sites (and a little pixel math) that the die measures \\~10.8mm tall and \\~25mm across. 10.8\\*25 = \\~272 mm\\^2. This is a rather large die for the performance class. For example, the RTX 4070 uses a \\~294 mm\\^2 [AD104](https://www.techpowerup.com/gpu-specs/nvidia-ad104.g1013) die, and the RTX 4060 uses a 159 mm\\^2 [AD107](https://www.techpowerup.com/gpu-specs/nvidia-ad107.g1015) die.\n\nTherefore, the B580 is \\~71% larger than a RTX 4060 and \\~8% smaller than a RTX 4070.\n\nThe second thing we need to consider is the node, which in essence is the \"type\" (very generalized) of silicon that the GPU is made out of. A node has a certain number of production steps required to achieve a certain level of density/power/performance etc.\n\nA good video for those who want to learn more about semiconductor production is Gamers Nexus' tour of Intel's Arizona fabs [here](https://www.youtube.com/watch?v=IUIh0fOUcrQ).\n\nThe node determines characteristics like **density** (how many transistors can be put onto a chip), **performance** (how fast can you make the transistors switch), **power** (how much power it takes to switch a transistor, how much power the transistors leak when they're not switching, how much power is lost to heat/resistance, etc.), **cost** (how much it takes to produce) and ***yield*** (how chips on a wafer are defective on average). A chip designer like Intel usually wants as high density as possible (more GPU cores = more performance), as high performance as possible (faster switching = higher frequencies = more performance), as low power as possible (low power = less heat, cheaper coolers, cheaper power delivery) and as low wafer costs as possible.\n\nIntel notably does not use its in-house fabs to produce the Battlemage cards - instead the GPU team decided to use TSMC's N5 node, first seen in Apple's A14 Bionic mobile CPUs in late 2019. Importantly, the Intel Ark site specifically notes [TSMC N5](https://www.intel.com/content/www/us/en/products/sku/241598/intel-arc-b580-graphics/specifications.html), rather than Nvidia's similar but more expensive 4N process.\n\nSince semiconductor cost is a function of wafer cost, die size and yield, we can use [SemiAnalysis' Die Yield Calculator](https://semianalysis.com/die-yield-calculator/) to estimate the cost of production.\n\nThis is where the variability begin. Unlike the die size, which can be measured physically, we can only guess at yield and wafer cost. We'll start with the wafer cost, which according to Tom's Hardware (citing sources) ranges from [$12730](https://www.tomshardware.com/news/tsmc-expected-to-charge-25000usd-per-2nm-wafer) in a 2023 article to $[18000](https://www.tomshardware.com/tech-industry/tsmc-may-increase-wafer-pricing-by-10-for-2025-report) in a 2024 article (apparently N5 has gotten more expensive recently).\n\nNext is yield, which is measured in something called a d0 rate, the number of defects per cm\\^2. This is much harder to verify, as the foundries guard this information carefully, but TSMC announced that for N5 the [d0 rate was 0.10](https://www.anandtech.com/show/16028/better-yield-on-5nm-than-7nm-tsmc-update-on-defect-rates-for-n5) in 2020. Defect rate usually goes down over time as the fab gets better at production; Ian Cutress (former editor at Anandtech) who has a bunch of industry sources pegged the N5 d0 rate at [0.07 in 2023](https://morethanmoore.substack.com/p/tsmc-oip-forum-fabs-n3n2bspn).\n\n[TSMC N5 Yield \\(2023\\) ](https://preview.redd.it/yv0ywh961mle1.jpg?width=1179&format=pjpg&auto=webp&s=455a11c7f3fd402981f6a4efb266b5fc3ca8fe14)\n\nKnowing this, let's set a d0 of 0.05 as our best case and 0.10 as our worst case for production cost.\n\nPunching these values into the die yield calculator gets us something like this\n\n[for a 0.10 d0 rate](https://preview.redd.it/b53hwp3r1mle1.png?width=1886&format=png&auto=webp&s=755a73ba536f908779fb758b1df81b43d12817dd)\n\nand\n\n[for a 0.05 d0 rate](https://preview.redd.it/5ufjsdxo1mle1.png?width=1886&format=png&auto=webp&s=99919520a3ea97e5e7640990d2015f607031d8eb)\n\nTherefore, best case scenario Intel gets 178 good dies per wafer and 156 good dies in the worst case scenario.\n\nFor the best case, $12,000 per wafer / 178 = $67.41 per die before packaging.\n\nFor the worst case, $18,000 per wafer / 156 = $115.28 per die before packaging.\n\nNext, the die must be put into a package that can connect to a PCB through a BGA interface. Additionally, it must be electrically tested for functionality. These two steps are usually done by what are called OSAT companies (Outsourced Semiconductor Assembly and Test) in Malaysia or Vietnam.\n\nThis is where there's very little public information (if any semiconductor professionals could chime in, it would be great). [SemiAnalysis' article on advanced packaging](https://semianalysis.com/2021/12/15/advanced-packaging-part-1-pad-limited/) puts the cost packaging a large, 628mm\\^2 Ice Lake Xeon as $4.50; since the B580 uses conventional packaging (no interposers or hybrid bonding a la RDNA3), Let's assume that the cost of packaging and testing is $5.00\n\nThus, **estimated** total cost of the die ranges from $71.41 to $120.28\n\n# 2. Memory Cost - 19 GBps GDDR6\n\nThis is the other major part of the equation.\n\nThe B580 uses a 12 GB VRAM pool, consisting of GDDR6 as shown by [TechPowerUp](https://www.techpowerup.com/review/intel-arc-b580/4.html).\n\nSpecifically, 6 modules of Samsung's K4ZAF325BC-SC20 memory are used. They run with an effective data rate of 19 Gbps. Interestingly this seems to be downclocked intentionally as this module is actually rated for 20 Gbps.\n\nWe don't really know how much Intel is paying for the memory, but a good estimate ([DRAMexchange](https://dramexchange.com/)) shows a weekly average of $2.30 per 8 Gb, or 1 GB with a downward trend (note: 8 Gb = 1 GB). Assuming Intel's memory contract was signed a few months ago, let's assume $2.40 per GB x 12 GB = $28.80\n\n# 3. The Board (PCB, Power Delivery and Coolers)\n\nThis is where I'm really out of my depth as the board cost is entirely dependent on the AIB and the design. For now, I'll only look at the reference card, which according to TechPowerUp has dimensions of 272mm by 115mm by 45mm.\n\n[Front of B580 Limited Edition PCB \\(TechPowerUp\\)](https://preview.redd.it/gszrkimxgmle1.png?width=1055&format=png&auto=webp&s=bc10b691443aa0aa85f6aa2f157bfc187e035c30)\n\nJust based on the image of the PCB and the length of the PCIE slot at the bottom, I'd estimate that the PCB covers roughly half of the overall footprint of the board - let's say 135mm by 110mm.\n\nAssuming that this is a 8 layer PCB since the trace density doesn't seem to be too crazy, we can have some **extremely rough** estimates of raw PCB cost. According to [MacroFab's](https://factory.macrofab.com/) online PCB cost estimator, an 8 layer PCB that size costs around $9 per board for a batch of 100,000. I think this is a fair assumption, but it's worth noting that MacroLab is based in the US (which greatly increases costs).\n\nHowever, that's just considering the board itself. TPU notes that the VRM is a 6 phase design with a Alpha & Omega AOZ71137QI controller. Additionally there are six Alpha & Omega AOZ5517QI DrMOS chips, one per stage. I don't have a full list of components, so we'll have to operate based on assumptions. [DigiKey has the DrMOS for \\~$1.00 per ](https://www.digikey.com/en/products/detail/alpha-omega-semiconductor-inc/AOZ5517QI-02/13922542)stage at 5000 unit volume. The controller [chip costs $2.40 per lot of 1000](https://www.edn.com/multiphase-controller-meets-intel-imvp-9-2/#:~:text=The%20AOZ71137QI%20also%20works%20with,in%20lots%20of%201000%20units)\n\nLooking up the cost of every single chip on the PCB is definitely more effort than it's worth, so let's just say the PCB cost + power delivery is like $25 considering HDMI licensing costs, assembly, testing etc?\n\nAgain, I have no idea of the true cost and am not a PCB designer. If any are reading this post right now, please feel free to chime in.\n\nThe cooling solution is an area that I have zero experience in, apparently Nvidia's RTX 3090 cooler costs $150 but I really doubt the LE heatsink/fan costs that much to produce, so let's conservatively estimate $30?\n\nThe total **estimated** cost of production for an Intel Arc B580 Limited Edition is **$160.21** on the low end and **$204.08** on the high end, if I did my math correctly.\n\n# Important Caveats\n\n1. No tapeout cost\n\nIt costs a substantial money to begin production of a chip at a fab (\"tapeout\"), details are murky but number is quite substantial, usually in the tens of millions of dollars for a near-cutting edge node like N5. This will have to be paid back over time through GPU sales.\n\n2. No R&D cost\n\nIntel's R&D costs are most likely quite high for Battlemage, [this article from IBS](https://semiengineering.com/big-trouble-at-3nm/) from 2018 estimates a $540 million dollar development cost for a 5nm class chip.\n\n3. No Tariff cost\n\nThe above analysis excludes any cost impact from tariffs. Intel's LE cards are manufactured in Vietnam but different AIBs will have different countries of origin.\n\n4. No shipping cost\n\nI also did not consider the cost of shipping the cards from factories in Asia to markets in the US or Europe.\n\n5. No AIB profit\n\nAIBs have a certain profit margin they take in exchange for investing in R&D and tooling for Arc production.\n\n6. No retailer profit\n\nRetailers like Amazon and Microcenter take a cut of each sale, ranging from 10% to 50%.\n\n7. No binning\n\nNot all defective dies are lost, with some being sold as B570s at a lower price. This will decrease Intel's effective cost per die. No binning process is perfect and samples with more than 2 Xe cores disabled or with leakage that's too high or switching performance that's too low will have to be discarded. **Sadly, only Intel knows the true binning rate of their production process**, so it doesn't give me any solid numbers to work with. Hence, I had to leave it out of the analysis.\n\nThanks for reading all of this! I would really love to know what everyone else thinks as **I am not a semiconductor engineer and these are only rough estimates.**\n\nIt seems to me that Intel is probably making some profit on these cards. Whether it's enough to repay their R&D and fixed costs remains to be seen.",
    "comments": [
      "I calculated this a long time ago—**the A770, A750, and A580 were all loss-making products**. Intel's profit and loss situation in the GPU market has largely been influenced by these models.\n\nThe **A770** had a production cost of **$250-$300**, while its actual selling price averaged **$220-$320**. It has now been **discontinued**, and its price will no longer drop.\n\nIn contrast, the **B580 and B570 are expected to have a production cost of $150-$180**, which is **a significant improvement** over the A-series. This is largely due to the **clock speed increase** from **1600-2300MHz in the previous generation to 2700-3000MHz** in the new series, effectively boosting performance **by 35% at the same cost**.\n\nThis means that a product of the same cost level can now be sold at **a 30% higher price**. Based on its specifications, the **B580 should be priced similarly to the A580**, but due to its **much-improved efficiency**, it can be sold at **30% higher pricing than the A580** while still being well-received in the market.\n\nBecause of this, **Intel has officially established itself in the discrete GPU market**. Of course, there is still **a considerable efficiency gap compared to NVIDIA**. Compared to AMD, **Intel is slightly weaker in rasterization performance**, but **significantly stronger in media engines and ray tracing**.\n\nI believe the **B770 will put immense pressure on AMD’s higher-end GPUs**, though it **won't directly threaten NVIDIA**.",
      "Just an FYI N5 is the cheapest of the lot in N5/ family and N4P is the most expensive an N4P wafer cost around 15.5K while N5 is approximately 12-13K and N5 is a really mature process it has D0<0.1 deflects/cm2.",
      "God! So well done job buddy.   \nThanks for your effort on this one.",
      "Please see caveat #7:\n\n>Not all defective dies are lost, with some being sold as B570s at a lower price. This will decrease Intel's effective cost per die.\n\nI do understand how binning works LOL. Defects aren't all created equally, Nvidia's Blackwell launch has shown us that. All chip designers build a certain level of redundancy into their chips, but there's no way to harvest all of the bad dies. If there's a defect on a specific chip, you better hope that it's not something critical.\n\nFor example, if leakage on a sample is simply too high, there's no way to sell that as a B570 and it goes in the garbage bin. \n\n**But since we have no way of knowing Intel's recovery rate for bad dies, there's no numbers for me to work with, so I left that out of the main body of analysis.**\n\nAlso please actually engage with the post on its merits LOL instead of on pedantic bullshit, a frame buffer is just a colloquial term for VRAM. I can edit the post if that makes you happier.",
      "This is very interesting. I knew that with the A-Series they couldnt possibly make money, but the B-Series seems a lot more economical for Intel. But still considering how exlensive R&D is I think at best they dont make a loss on it, but they very likely dont make profit. I would guess that only Celestial and later are going to make a profit, because while R&D might be expensive driver development is a serious cost factor and I think it was very expensive to get the drivers to work properly. And that is a cost that is currently split up between A and B series.",
      "Agree with all the points here, Intel was taking some really vicious losses on the A series.\n\nA 400 mm\\^2 N6 die and 16 GB of VRAM (especially back in 2022 when VRAM exploded in price) was doomed to fail if it was competing against a mature, dirt cheap GA106 on a shitty Samsung 8nm process that nobody used. \n\nIntel has made extremely meaningful strides this generation in PPA.\n\nI wouldn't necessarily agree with the analysis with frequency because you really don't know how they tweaked the architecture, Xe1 and Xe2 are not really comparable on a clock by clock basis and your realistic clock speeds are influenced by stuff like the node, the power budget etc.\n\nTo be honest on a PPA basis Intel is still behind AMD and Nvidia on raster and RT, but the gap has closed to maybe 1 generation behind rather than 2.\n\nIf a hypothetical BMG-G31 \"B770\" existed it could probably at least match the RTX 4070 and Intel could probably hit a $375-$400 price point without taking a huge loss.  But that's their decision to make. I would really love to see it though!",
      "Regarding the development cost, remember that the Xe2 architecture is used also in IGPUs and server GPUs (eventually in the case since falcon shores was cancelled, so this only applies to Xe3 or Xe4). Not sure how to account for that in total cost, but there is some discount to the battlemage program cost if you look at it that way. And this would further get amortized if there ends up being a B770, which we're not sure even exists.",
      "Digikey costs are very high in terms of volume manufacturing. US manufacturer prices are generally super high. They can be 2-4x in cost.\n\nThe actual power stage costs can be cut by at least half or more. The board costs similarly may  be cut in half.\n\nFor memory you said they aren't using the full 20Gbps speed right? So they could be getting the cheapest versions of them. We don't know exactly what internal deals they are getting either. Same with the TSMC manufactured die. Often the relationships with the manufacturer is important because you can get deals beyond what is there for public.\n\nHeatsink costs are likely high too, even at $30. I, as an individual can find significant discounts by talking to various vendors online. Now imagine that with a much higher volume. It's probably again about half.\n\nSo they are probably making some money at the BoM level. From a bigger picture point of view, it won't be significant, even if we theorize their R&D is mostly paid off by needing iGPUs. Because even $1 billion is chump change for Intel. 5% of the 10% of the 100 million shipments per year is 500K. So they are earning maybe $30 million per year assuming $50 profit per card, which is nothing.",
      "I don't think Alchemist or Battlemage were ever meant to make a profit. Both of them seem to be \"Public Beta\" products which are sold to customers at a low price for the performance you get in order to get the product out into consumer hands, learn/refine based on feedback, and gain marketshare/mindshare so that when Celestial is released, they will be poised for success and able to build upon it. More than likely, Celestial will be the first architecture with the intention of being profitable.",
      "Don't worry, I already covered this, I did a best and worst case in the post, I assumed 12k wafer cost and 0.05 D0 for the best case, 0.05 is a REALLY low defect rate.\n\nI also already said that N5 was cheaper than N4\n\n>Importantly, the Intel Ark site specifically notes [TSMC N5](https://www.intel.com/content/www/us/en/products/sku/241598/intel-arc-b580-graphics/specifications.html), rather than Nvidia's similar but more expensive 4N process.\n\nBut any further refinement of the analysis is difficult since we don't really know for sure the exact wafer costs/defect rates. I think the range I provided represents a good estimate.",
      "I mean the original Alchemist due was supposed to be a 3070/3070 Ti competitor.\n\nI bopenif B770 does happen it's 4070 Ti performance. I mean TBVH B580 should be 3070/3070 Ti performance.",
      "Thank you for digging in and breaking this down.  I actually got a bit of the warm fuzzies that my wild guesses were even remotely close to someone who clearly understands this stuff better than I do. \n\nMy estimates were pretty far off your much more detailed analysis.  \n  \nThe only reference I could find for TSMC 5nm wafers was $17k, I guessed somewhere between 0.04 and 0.08 on D0. I WAAAY overestimated the cost per GDDR6 module (I guessed $8 at best, $20 at worst), with a PCB cost somewhere between $5 and $25, not including the SMD components, which I estimated to be around $20-$100 (I had absolutely no clue how much some of those components cost)\n\nI think I came up with $175.66 to $373.79 per unit, with a more likely cost being somewhere around $180-$220.\n\nAgain, thank you lots for doing this analysis.",
      "Nice post, it was a good read I expected way higher costs. i didnt know it was made on N5. I hope 18A is gonna be good.",
      "The real problem for Intel is not the Bill of Material(raw cost), nor the cost of R&D, nor the cost for support.\n\nIt's that the absolute dollar amount is pitiful.\n\nSo a 250 million per year PC market consists of roughly 40% desktop, which makes it 100 million per year.\n\nThe dGPU's portion is 20-30%. Let's say it's 25%.\n\nIntel's share of the dGPU market is \\~5% during the peak. Now let's assume they are earning $100 per card.\n\n100 million x 0.25 x 0.05 x 100 = $125 million dollars\n\nEven if you assume they are earning $100 per card, it's a pathetic $125 million dollars. In reality it's probably less than half, so $50 might be reality. In that case it's just $50 million net profit on $150 million revenue. It's nothing for Intel.\n\nIn the case of Nvidia, they have 85% or so marketshare. And they might be earning $250 per card in average, maybe even up to $350. In that case they are earning $5 to $7 billion a year net profit. Much better.",
      "Man a celestial reboot on 18A in 2026 could be crazy good but Intel HAS to fix their driver overhead if they aim for higher performance tiers.",
      "Agree people keep asking for b770 but with this driver overhead i dont think it makes sense.",
      "Rn focus should just be to supply as many B580s as possible and keep rewriting and fixing the driving stack.",
      "You are counting retail prices and not manufacturer prices. \n\nAlso, a smaller price is made when there is \" economies of scale \" meaning instead of making 500 unit you place an order with suppliers for 50000 or more, then the price gets even smaller. \n\nI assume that what you calculated has to be divided by x2.",
      "Thanks :) glad you enjoyed it.",
      "Agree with all points here. Hopefully 18a yields are good enough for them to make Celestial on it, Intel's wafer cost is much lower for their own nodes. If you watch interviews that's what the engineers in charge of Arc say, it'll take them a few generation to work their way up.\n\nAnd yes, the expensive driver development cost is a big caveat I haven't considered yet."
    ]
  },
  {
    "brand": "intel",
    "generation": "battlemage",
    "tier": "570",
    "matched_keywords": [
      "arc b570",
      "b570"
    ],
    "title": "Intel Arc B570 Review, The New $220 GPU! 1440p Gaming Benchmarks",
    "selftext": "",
    "comments": [
      "Ya I agree with the review that B570 does not really seem worth getting when $30 more dollars get you B580. \n\n\nOf course with the B580 constantly being out of stock it might be a tempting alternative. Though it still suffers from cpu overhead issue that the B580 also suffers from.",
      "Does it really suffer from \"overhead issue\" that match?  \nLook at theirs 13 games average.  Going from 9800x3d to 5600 fps drops:  \nB570 - 4%, B580 - 8%, 4060 - 0%, 7600 - 3%. \n\nWith upscaling enabled, fps drops:  \nB570 - 9%, B580 - 14%, 4060 - 6%, 7600 - 6%.\n\nRemove \"Spiderman\" from their 13 games average, and you will be getting even less difference.",
      "Anecdotally as someone who owns a b580 with a 5600x\n\nI don’t notice the overhead issue. I’m sure it’s there but when you turn off the fps counter and just enjoy your game you don’t notice. I’m getting playable (60fps+) frame rates at everything I throw at it.",
      "I see his complaints about B580 being out of stock, but where are his complaints about the 9800X3D also still being out of stock? Why does he not attach that to his numerous CPU reviews.\n\nLooking at his data, the RX 7600 also has some overhead issue as well.\n\nNow were attaching upscaling to reviews and using FPS produced as a metric? OK fine, why not use the far better image quality XESS produces over FSR as a metric as well? Is he going to measure that?\n\nAll these new hurdles and metrics were now using because Intel has a very competitive GPU.\n\nWait, he actually came to the conclusion you should buy an 8gb $250 RX 7600? LOL!!! I do agree that B570 should cost no more than $200 though. Otherwise I'd just buy a B580. The 8gb 7600 and RTX 4060 are joke products in 2025.",
      "B580 is the price value king at its price range.\n\n\n\nB570 is the price value king at its price range.\n\n\n\nIntel gpu division is killing it!",
      "Honestly the extra ram itself is worth that $30. Nowadays you'll want as much ram as you can get if you're gaming above 1080p just in case a new feature that eats ram gets introduced",
      "No it doesn't. Look at Tech Yes City that looked at other GPUs with a Intel lower end CPU. And both AMD and Intel GPUs suffered. This is not an Intel exclusive issue and even this HWU video shows this.",
      "The \"overhead issues\" is a campaign by anti-Intel PR teams.",
      "Australia is small and prices are artificially inflated there. Europe pricing would be objectively more interesting or maybe select asian countries",
      "Spider-Man might be a bad case but even with 5600x still perfectly enjoyable. Tested this back on my A750 and 5600 and great experience. Now it also has FSR Frame gen so you’ll be able to get a very smooth experience.",
      "I’m just pointing out the real world effect vs reviews. People are stressing about this overhead issue, it’s minor and you won’t notice it in your day to day life. \n\nJust enjoy what you have",
      "Thing with 8GB Vram is that you can turn down the settings and increase the fps. With Arc you literally can not increase the fps unless you upgrade your CPU. But will people who buy $250 GPU really upgrade their CPU? Its better to spend that money on a faster GPU. Something like rx6700xt will always perform better than Arc and you dont have to upgrade CPU.",
      "This just seems really negative. Even in his worst case scenarios its still better value (even if just 5%), and this is a 'disaster'? \n\nAm I missing something?",
      "The only B580s I have seen in stock since they dropped are priced at or above 380.\n\nI just ordered an ASrock B580 for 220.",
      "Yeah I think it's a placebo effect when u have the fps counter on, u feel like the game is stuttering if u watch the fps fluctuate but if u dont see the fps at all u don't feel the placebo stutters haha",
      "Very well thought out response, very mature indeed",
      "It's definitely a healthier way to look at things, but at that stage is there actually much difference between different GPUs for you?",
      "RT is a joke argument, both of those cards cant run RT at acceptable performance. But you do you.",
      "Upscaling at 1080p to get a playable result that favours B580 is a result for sure.\n\nB580 has 2.4 million more transistors on more advanced node. The fact it can loose in anything against RX 6700 XT is kinda impressive, not in a good way.",
      "Point of testing with upscaler is not to compare quality of upscaler, its to compare max fps that you will see if you drop down resolution or quality settings. Problem with CPU overhead with ARC is that it makes games CPU limited and no amount of turning down settings can increase fps numbers. Nvidia and AMD have no such issues, and they are better buy if you have lower end CPU. In the future Arc will continue to perform worse and worse compared to competition as games become more CPU intensive."
    ]
  },
  {
    "brand": "intel",
    "generation": "battlemage",
    "tier": "570",
    "matched_keywords": [
      "b570"
    ],
    "title": "Intel starts to make its mark in new GPU sales stats with the Arc B580, just ahead of B570 release",
    "selftext": "",
    "comments": [
      "Where do you buy one?",
      "Plenty of people are still buying those processors.\n\nRyzen 5 5600X is the 3rd best-selling processor on Amazon.\n\nRyzen 5 5500 is the 5th best-selling.\n\nThat and Intel markets the Arc B580 as the GPU to upgrade to from the GeForce GTX 1060 and GeForce GTX 1660 Super.\n\nWhat are the chances that PCs with those GPUs would have relatively new processors?",
      "I picked up the B580 LE, fantastic GPU for $249.",
      "Probably terrific encoding and transcoding support too.",
      "Now, you are changing your argument.\n\nYou implied that the issue is unsupported processors, which is not the case.\n\nCompeting GPU products from Intel's competitors don't suffer nearly as much performance drop.",
      "There will be plenty.\n\nThe overhead issue is warding off a lot of potential buyers.\n\nHopefully the scalpers lose money over this.",
      "How has scalping still not been solved?",
      "Were you replying to someone else?",
      "Nearly every game I saw tested at 1080p had performance nosedive when using anything older than 7000 series cpus...\n\n\nEven a 7600x saw it falling behind a 4060 in most games, so let's not pretend this isn't a serious issue, especially since the market for this gpu will be the ones more likely to not have a brand new high end cpu\n\n\n\"Only specific games with old low end cpus\" is as blatant as misinformation gets, gross this is being upvoted",
      "12400 and 5600x are dirt cheap probably $200 or less  for cpu, mobo and ram combo. The problem with used gpu are reliability and lack of tech like xess2 so people prefer newer gpus. Thats a total system cost of $600.",
      "Why shouldn't we be hyper critical? We're spending our money. We have a right to be informed and Intel must have known about this.",
      ">Overhead issue is blown out of proportion. There is a reason they state system requirements for the GPU.\n\nHmm...",
      "Right now you cannot get one for less then $400-$450 thanks to scalpers.",
      "Overhead issue is blown out of proportion. There is a reason they state system requirements for the GPU.",
      "The overhead issue happens in all CPU bound scenarios while the GPU is in use, which is probably quite a common scenario for a lot of people. Some of the most popular games in the world are generally CPU bound.",
      "Ebay is flooded with tray 5600x for $80 price range. Same with 12400. Cpus are super reliable. If I would be building a low end system I would buy 12400 with 580 thats an excellent budget system. Total cost of system will probably be less than 600",
      "I’m interested to see the A770 vs B580 production numbers. The A770 was barely scalped.",
      "Currently the best on the market I imagine? Does a 4090 still beat it in raw performance or does the newer tech give it the edge?",
      "That's a good question.",
      "My guess is that there is not enough volume to overwhelm their budget nor an incentive to favor selling to legitimate users."
    ]
  },
  {
    "brand": "intel",
    "generation": "battlemage",
    "tier": "570",
    "matched_keywords": [
      "arc b570",
      "b570"
    ],
    "title": "First Intel Arc B570 performance leak: 12% slower and 12% cheaper than B580",
    "selftext": "",
    "comments": [
      "In germany 12% slower then a B580, but 15% cheaper. It seems to be a really good budget GPU, we will see in many builds.",
      "It isn't suprising being 2GB less Vram, the chip used is exactly the same on both. The B570 uses the chips that had minor imperfections and instead of throwing them away Intel decided to use them and name the card the B570 with less ram. It is win win for Intel if people buy them. Tom Petersen talked about this in a video but haven't got the link to hand.",
      "Intel: 12% slower for 12% cheaper\n\nNvidia: 12% slower but you'll buy it anyways so let's double the price and half the vram LOL",
      "A perfect balance xd",
      "Driver overhead \"issue\" is too much fuss about nothing. Depends on specific game optimization all cards may suffer from it to some extent. You can cherry pick set of games were AMD 7600 will be doing much worse than B580/B570...  \n[https://www.youtube.com/watch?v=mVC2eP9xmXQ&t=1s](https://www.youtube.com/watch?v=mVC2eP9xmXQ&t=1s)",
      "So why do we even need this card? Neither the performance or price is significant enough to make a difference in this price range.\n\nSounds like cards that did not make the cut in performance tests during production to become B580.",
      "Options are options.  I could see this more for budget prebuild machines.",
      "[https://www.proshop.de/Grafikkarte/Sparkle-Arc-B570-Guardian-OC-10GB-GDDR6-RAM-Grafikkarte/3324297](https://www.proshop.de/Grafikkarte/Sparkle-Arc-B570-Guardian-OC-10GB-GDDR6-RAM-Grafikkarte/3324297)\n\n  \nHave fun with it. :)",
      "People did this with A750s as well and were able to match the A770 in most games that didn't need the higher VRAM, so I look forward to seeing how the B570 overclocking goes :)",
      "Another price value king for its segment",
      "Anyone got news on that b780? Amds lineup is looking like this generations winner if the price and performance are close to the recent leaks. I would love to see Intel compete in the 450 dollar range.",
      "Notebooksbilleger has B580s for €309 so that would be 12% cheaper. For some reason Dutch NBB the ASRock model is €300.",
      "which website my brother?",
      "You can overclok b580 too",
      "Probably waiting on clearer release dates on the NVidia and AMD.",
      "I think both are the best bang for your buck we‘ve seen in the last few years. My overclocked B580 runs like a beast for 300€",
      "Yea i have a 1660super and a 5 3600 .........i was gona get this gpu but now i think i gona buy a 4060 or a amd gpu .....they can still fixt it tho i hope",
      "Based",
      "So, the price to performance is scaled correctly. Amazing.",
      "Yes you are right, most companies do this kind of thing, thats why we suddenly got the 5700x3d for example. All the chips meant for 5800x3d that didn't make the cut. It is a good thing, reduces waste, and provides cheaper products for people."
    ]
  },
  {
    "brand": "intel",
    "generation": "battlemage",
    "tier": "570",
    "matched_keywords": [
      "arc b570",
      "b570"
    ],
    "title": "Arc B570 at Micro Center",
    "selftext": "",
    "comments": [
      "It's ***not*** a problem with rebar.\n\nRebar is enabled.",
      "12600K would be fine",
      "If they can fix the driver overhead, it will be. I’m rooting for Intel here, but they have a lot of work ahead of them.",
      "My guy, R5 5600 supports resizable bar, and is enabled by default.\n\nhttps://youtu.be/CYOj-r_-3mA?si=xbJ5XBcwGjDGeQvP",
      "Is there even a driver that works out for the 570 yet? 580 runs fantastic paired with my 5600x. Super performant, cool and quiet (power draw is way lower compared to any other card I’ve had).",
      "Why do they store them in the freezer?",
      "This isn't the issue and it's been posted ad naseum. Hardware ubboxed just posted a video of him testing with an R5 5600 and he dropped up to 57% performance from a 9800X3D in certain games. The RTX 4060 and RX7600 he was testing against did not see such issues in the same games or their drop was much less.",
      "The driver overhead really is a problem, budget cards should *not* drop 15% of their performance on $150 CPUs.",
      "Been that way since Covid and the mining craze for all GPUs.",
      "So down votes for speaking the facts, love Reddit",
      "You obviously seem to care.",
      "Incorrect. Rebar works on most amd motherboards including b450, b550, x570, x470 and even some x370 with at least ryzen 2000 or newer cpus.  Older boards do need a bios update. Not all boards got one but most have them available.  I’ve used it on ryzen 3950x with x570 and another system with a b450 asus tuf motherboard with a ryzen 5700x. \n\nRebar is a pcie feature and goes back to like pcie 2.0 spec. Even some older intel motherboards support it like skylake / kabylake era stuff.\n\nThe arc problem is not related to rebar that they are talking about but you effectively must have rebar on for them to give decent performance.",
      "Ryzen 5 5600X is from 4 years ago and still the 3rd best-selling processor on Amazon\n\nCore i5-12400F is from 3 years and is also around the same performance and still a good option for budget oriented.",
      "Yeah, this sub is just like that sometimes.",
      "In the video he states he is working on a 12400F review with the B580 to test as well on Intel side.",
      "Yes.\n\nSomeone got the driver working by extracting the driver and pointing Windows to it.",
      "lol get a load of this guy",
      "Just pair high end CPU with a budget B570 roflmao.",
      "Because it’s immensely significant and not everybody knows about it - without it, the B580 is just the clear best value GPU, but with it, the B580 becomes very difficult to recommend.\n\nAnd honestly, I’m not sure how much or how quickly Intel *can* fix it - it’s not a hardware flaw, but it will probably require them to make fundamental changes to the software, all for cards that have a pretty short window to be competitive before Blackwell and RDNA 4 eat their lunch.",
      "B580 at MSRP is a goated card for 1440p gaming.\n\nnvidia 50 series starts at more than 2x the cost right now, and doesn't get you 2x the fps (not counting fake frames)."
    ]
  },
  {
    "brand": "intel",
    "generation": "battlemage",
    "tier": "570",
    "matched_keywords": [
      "b570"
    ],
    "title": "Intel Arc Battlemage B580 & B570 GPU Specs, Price, & Release Date",
    "selftext": "",
    "comments": [
      "You have to wonder if we're getting shafted by Nvidia all the same.",
      "Assuming that Intel’s claims are true (which is a big assumption), that would put the Arc B580 at around the same performance as the Radeon RX 7600 XT.\n\nI am guessing that AMD, in response, discontinues the Radeon RX 7600 and slashes the price of the Radeon RX 7600 XT",
      "His presentation seems reasonably optimistic for what is claimed to be only a small uplift above the 4060. He also talks about overclocking optimistically in a way that indicates he has already taken a shot at it and that he wants to do an OC stream.\n\nWe know review samples are already out due to the guy that showed one off on stream.\n\nI suspect the drivers are at least solid this time given his general attitude, and overclocking appears promising as well, hell, even official intel slides showed it running at well over 3.2 GHz. I just hope there is a chance to squeeze more performance out of it with the drivers. 272mm\\^2 is a big boy die for such a weak card.",
      "Yeah, and when Nvidia gives you a lesser card for 350 it is totally fine,",
      "You have to wonder if Intel is actually making any money on this.\n\nBMG-G21 (used in Arc B570 & B580) is 272mm2 on TSMC N5.\n\nNAVI 33 (used in Radeon RX 7600 & 7600 XT) is 204mm2 on TSMC N6",
      "Dat price per frame\n\n<3",
      "7600xt is stupidly overpriced anyway. 350€ for it or 520€ for 7800XT. Easy choice",
      "never mind AMD lol, AD107 is 160mm\\^2 on the same node.\n\nthe die itself is well under 100$, closer to 50$ i'd say, going by the latest publicly available pricing information, so they're probably doing *okay.*",
      "looks like overclocked 3060 12gb",
      "$249 for ~3060 Ti performance minus a few percent is… *good*, but nothing to write home about, and given that this is still ~RDNA 2 efficiency, they’ll have to be more than 20 bucks cheaper than a 4060 to justify the product’s existence.",
      "It's very difficult to break into an established market.\n\nThe Intel of yesteryears with an unlimited war chest and the world's best foundry might be able to do it.\n\nThe Intel today? I just don't see it.",
      "I don’t think the current goal is to suddenly blow out the competition but to be comprable. Intel still needs about 3 years to become competitive in that space.",
      "Intel's own numbers don't put this anywhere near a GeForce RTX 4060 Ti",
      "According to **Intel's own numbers**, the B580 is about 10% slower than the RX 6700 XT and about **15-20% slower than the RX 6750 XT**.\n\nThe RX 6700/6750 XT have been selling for $270-300 for over a year now.\n\nThis did not move the price to performance needle at all. We had this level of price to performance for a long time now.",
      "RT performance is weirdly the selling point in price to performance vs AMD.  \n  \nBut what is your use case for RT at this performance level? Playing 5 year old RT games like Control and Metro Exodus?",
      "Very possible he already tried it, they have to pretend to not know anything but sometimes it shows a bit.",
      "We definitely are, you only have to read their annual accounts and shareholder statements to know that",
      "[About 22% in 1080p and 29% in 1440p](https://youtu.be/7ae7XrIbmao?si=NlxgHhUn3KHAdUqj).",
      "Speculating that it will be 10% faster than a manually OC 3060, but only at 1440p and the B580 can be overclocked too.",
      "Intel needs a high performance GPU architecture. It’s important for APUs, it’s important for machine learning, and it’s important for gaming. It’s a growing field that their competitors (Nvidia, AMD, Qualcomm) all have offerings in. Intel can’t just be a CPU company with minimalist iGPUs going forward."
    ]
  },
  {
    "brand": "intel",
    "generation": "battlemage",
    "tier": "570",
    "matched_keywords": [
      "arc b570",
      "b570"
    ],
    "title": "Intel Arc B570 ships one month ahead of launch: gamer mods drivers to make it work",
    "selftext": "",
    "comments": [
      "I honestly still don't get why the B570 even exists, when the B580 is substantially better for just an extra 30$. I'll build my first PC with Arc, I'm not a hater. I just don't don't get the point of the B570.",
      "If I am not wrong b570 doesn't need external power and can just stay in the motherboard a low profile GPU these are used for people who don't play games but still need a GPU for tasks",
      "this way Intel can sell the partly-defect chips. thats it.\n\nless waste and more profit.",
      "My only guess it's for people that buy a really good motherboard and CPU but are going to upgrade the gpu later down the line maybe. But I don't know why they are making it honestly",
      "For those defective chips that can’t be used for B580 maybe?",
      "didn't consider this, completely forgot about low profile GPUs tbh",
      "Yeah it's literally 2x what the PCIe slot spec covers (75W).",
      "For some markets, cheaper options may be more suitable. Even if have just B570 and B580 in the scope.",
      "Market segmentation and die binning. $220 is probably a little high at first, but availability may be better, and the price will probably drop a little later on. It's the same thing as the A770 vs A750.",
      "Are you sure? the official slide deck shows it has an 8 PIN connector it is also way higher wattage than what PCIE slot is rated for. \n\n  \n[https://www.notebookcheck.net/Intel-Arc-B580-and-Arc-B570-New-desktop-graphics-cards-announced-with-affordable-price-tags.927306.0.html](https://www.notebookcheck.net/Intel-Arc-B580-and-Arc-B570-New-desktop-graphics-cards-announced-with-affordable-price-tags.927306.0.html)",
      "B570 will come in low profile version from various vendors soon. My small homelab server currently uses A380, B570 will be a major upgrade.",
      "The b570 exists to compete with 8gb VRAM GPUs at a similar price point. Basically to eat market share from NVIDIA/AMD low end GPUs",
      "Server build is looking more power efficient little by little 🫡",
      "On one hand Intel GPU division is doing amazing things  on the other hand desktop CPU  division keeps screwing things up",
      "You dont know how fabs and wafers work, it seems.",
      "That’s all I can think too",
      "lol their distributors keep messing up, not that I'm complaining",
      "Would be interested if it has better idle power consumption than the B580 cuz honestly I would get it since I don't care about 1440p and the requirement of ASPM to have the lower idle power draw continues to be a disappointment.",
      "I agree this card should probably be $180-200. But it is for 1080p gaming and not 1440p",
      "I wonder if OEMs will get steeper discounts on the B570?"
    ]
  },
  {
    "brand": "intel",
    "generation": "battlemage",
    "tier": "570",
    "matched_keywords": [
      "arc b570",
      "b570"
    ],
    "title": "is the arc b570/80 compatible with a asrock b650m-hdv/m.2",
    "selftext": "",
    "comments": [
      "Yes, it's compatible",
      "Everybody gotta start somewhere",
      "Yes but next time you should just use pcpartpicker, it shows what's compatible and what not.\n\nUsing that next time when you have a question you won't need to wait for people to respond",
      "Really?",
      "Yes, 7500F is enough for a B580.  Make sure you have a mobo that supports rebar.",
      "ryzen 5 7600",
      "thanks!!\nIm building my first pc and I couldnt find this information anywhere, so I dicided to just ask here",
      "is 7500f enough for b580?",
      "Yes, they are compatible.  But more importantly, what is the CPU?",
      "thanks!!",
      "that's really weird, is there a chance it could be because of the size for the case or something?",
      "You should have no issues with that combo.",
      "thanks!!",
      "Im actually trying to avoid any lightning, so it doesnt really matter for me.\n\nAlso, Ive seen one person saying that for newcomers this isnt a very good pick for a gpu",
      "Well vram is Like engine displacement the more the better but 10g should be enough for 1080p. Just search for some Reviews that compare both vram sizes. i don't know your Budget for me the 30-40*Insert your local currency* difference wouldnt Stop me.\n\nbut you probably wanna go for the Intel original Card.",
      "that's my mobo and I use the b570. yer fine",
      "Upgrade the BIOS and you should be good.",
      "I used the site but sometimes it was showing the 570 was compatible and other times it wasn’t. So I got confused lol",
      "Well… if im asking lol",
      "Hmmm I was afraid thats the case…\nSadly is the one of the few 12gb vram I can afford"
    ]
  },
  {
    "brand": "intel",
    "generation": "battlemage",
    "tier": "570",
    "matched_keywords": [
      "arc b570",
      "b570"
    ],
    "title": "Arc 570 performing far worse than expected",
    "selftext": "Hey everyone, just got my first Intel GPU, the Acer Arc B570 Nitro. Now I'd expect it to be a significant improvement over my VERY old GTX1060 but...it isn't. CoD Black Ops Cold War doesn't run at all, massive graphics bugs, though it seems that might just be how it is.\n\nHowever I also noticed the GPU going to 100% load on something like Stellaris. It slows down the whole system, can't even watch YT on my 2nd screen, it lags. I am not sure what is causing this, has anyone experienced something similar? I am happy to provide any additional info you need.\n\nSystem:  \n\\- Win11 (up2date)  \n\\- AMD Ryzen 5 5600X  \n\\- Gigabyte B450 GamingX v2 (BIOS updated and REBAR enabled)  \n\\- 32GB RAM  \n\\- Triple-screen setup, all connected via displayport, main screen 1920x1200, 16:10, at 60Hz\n\nTroubleshooting so far:  \n\\- driver up2date (GPU was mounted today)  \n\\- tried CoDBO:CW with the various workarounds like deleting compiled shaders mentioned on the web, none successful so far, extreme screen tearing on the left side slowly stretching to the right, currently loading the HD graphics pack to check if it gets worse  \n\\- Stellaris initially ran the GPU to 100%, after restarting the game it is alright but \"feels\" off, also crashes after about 5-10m which didn't happen with the old GPU\n\nEdit:  \n\\- erased drivers with DDU (both potential Nvidia leftovers and Intel), reinstalled new driver  \n\\- updated MB chipset  \n\\- found out the CoDBOCW issue is known, no fix: [https://www.intel.com/content/www/us/en/support/articles/000095319/graphics.html](https://www.intel.com/content/www/us/en/support/articles/000095319/graphics.html)",
    "comments": [
      "Did you try things like enabling rebar and downloading the latest drivers?",
      "Have you tried reinstalling the games? Both games work perfectly for me.\n\nSometimes you need to reinstall the games for it to work properly.",
      "Is this also Windows 10 or 11?",
      "I was having issues with my b580. I fully reinstalled windows (left the game drive alone) and things work much better now.",
      "Ddu all nivida drivers also double check the gpu is fully slotted in. All else fails clean windows install and see if that works if not possible bad gpu. It happens mass producted parts have bad eggs from time to time",
      "Reinstall windows, update chipset drivers.",
      "My CPU doesn't have any.",
      "Huh, you are saying something there. I actually struggled to seat the card properly. The Asus B450 Gaming X has a plastic covered part right next to the GPU slot, maybe that's the issue...will check tomorrow, thank you!",
      "Sorry if that was the impression, added more info.",
      "Enabled rebar (shows as enabled also in IGS), driver is clean fresh install. Installed in Win11.",
      "Thank you, and no, this one very specifically does not.",
      "Not yet. My internet speed is horrible, CoDBO:CW would take half a week. -.- But could do it if that's the only fix.",
      "Second this. I moved from Nvidia, and every game I reinstalled works perfectly.",
      "AMD Ryzen 5 5600X, added more info on the original post.",
      "Agreed. This was the case for me as well. Even though I used DDU to uninstall the Nvidia drivers, some games (like Cyberpunk) didn't work properly until I reinstalled them.",
      "Run DDU and wipe all display drivers properly, then install latest intel driver.",
      "I was planning on getting this card and pair it with my 5600. 😭💦 I have a A580 and a B580, so far I had no issues.",
      "Go to bios and enable above 4g decoding",
      "That doesn't seem normal at all. You will probably have more luck contacting intel support about this",
      "Cod just doesn't run as well on intel/nvidia as AMD bro. Rven a rx 6600 probablt performs better then a b570. One of rhe few games where it's the case but yeah"
    ]
  },
  {
    "brand": "intel",
    "generation": "battlemage",
    "tier": "570",
    "matched_keywords": [
      "arc b570",
      "b570"
    ],
    "title": "Intel Arc B580 or Intel Arc B570 for budget gaming",
    "selftext": "So the headline say it all, want to give a shot to Intel Arc gpu since new \"budget\" gpu's from amd and nvidia seems a total disaster.\n\nUsually every post i see about Intel Arc B570 is that ppl say just to buy B580 since its \"only 30$ more\", well there a catch in my country difference is more like 100-70 usd between this 2, so that said is it worth to pay 70$ ish or more for B580 or B570 is just about fine for the price? For reference B570 priced starting at 284$ min price in my country while B580 cheapest is starting at 351$\n\nIm sitting on gtx 950 2gb so yeah either one will be like travel in damn space for me that's for sure, but still want to know if it worth to pay 70$ more in this case\n\n(cpu ryzen 5 5600) and also as a note the fact that i still on gtx 950 kinda gives that away already but yeah if i buy either one of this or any new gpu i will more likely hold too it for a long while it's not a situation to buy it and replace in a year kind of situation for me.\n\nAlso ppl often recommend used market but is very bad here so not a real alternative either, used gpu being very overpriced and just a little off a new one like maybe 30% lower its crazy tbh",
    "comments": [
      "Not really bro. With a b570 the bottleneck is waaaay less thrn with a b580. I have ab570 with a 5600x and get similar performance to videos i see",
      "Get a used amd or nvidia used gpu. Your cpu will bottleneck you, but I guess unless you will buy used you don’t have a better choice",
      "And like guys i appreciate recommendation of alternatives i rly do, but i searched and weighted a lot of gpus that i can afford with prices in my region and B570 or B580 seems most optimal and cheapest in a long run for price to performance and future proofness (more vram) the main question i have is it worth to pay 70$+ or more for B580 or not, is the performance jump between B570 and +2gb of vram worth that kind of money or not that all i want to know.\n\n\n\n#",
      "B570 and B580 share same BGM-G21-GPU, so they're literally the same - but with some differences.\n\nHad the B570 (was 280), returned it for a B580 (was 330) - it just felt bad somehow, to have 2 GB less memory with lesser bandwidth, to have 2 cores less and remaining cores with less MHz, topped by 200somewhat less shaders. B570 is a failed B580, relabeled to still make some money from it. \n\nBenchmark-wise there's just 12% difference. So I thought, 150W vs 190W, that's 25% more power for just 12% more performance. Wanting a frugal system, I took the B570. But playing on 1440p it felt like I do miss those 2 GB of RAM. \n\nIt's a slight difference, in performance, in specs, in price. Only you can say, if it's worth it to you. For me it was.\n\nAround 20-25.5  I'd expect the AMD RX 9060 to be announced, perhaps you want to delay your decision unitl then.",
      "From lowest to highest price it seems your options are B570/$284, RX7600/$320, 4060/$341 and B580/$351. I think you have to look at the games you play. Newer games - choose B570/580 depending on how much you want to spend. Older games - RX7600 or 4060.\n\nIn terms of B570 vs B580 - how much is that $65 worth to you? It's probably 10% more performance a bit more future proofing, but I suspect your CPU might run out of gas before 10 vs 12gb VRAM becoms an issue.",
      "The B570/B580 still experience a noticeable drop in performance in certain games paired with a 5600. At 1080p, the B570/580 doesn't perform as well as it does at 1440p. \n\nFor competitive gaming, AMD and Nvidia are better choices. For story games, it varies. You should research the games you play and consider potential future performance gains with updates if you choose Intel.",
      "well i still using gtx 950 2gb so not very haha",
      "Then B580 is your best bet, the 12GB vram and higher specs meaning it'll remain viable for much longer. It can even go up to 1440p if you ever feel like getting a new monitor.\n\nI'm currently using a GT 1030 and looking to upgrade to a B580 in the future.",
      "Whats your CPU?\n\nWhat are the prices of the rtx 4060 and rx 7600?",
      "would be nice if you told us your country, that way people of the same country could give you more accurate recommendations",
      "sorun varsa buradan veya dmden sorabilirsin, 4 aydır kullanıyorum ve çok memnunum 1080p oynayacaksan 570 iyi bir tuning ile base 580 ile eşit ve ayarlardan bunu yapmak çocuk oyuncağı, 1080p için özellikle istiyorsan 2. el 3060ti 16gb vs işini daha çok görür ama ne kadar ileri dönük olur bilmiyorum, bu kart tamamen pc oyunu oynamak için bunu bilmen lazım ne vr ne render alırsın",
      "Used market is very bad here not worth at all like for example i was looking in rx 6600 and a used one is 195-180$ ish while new one is like 220-240$. WIth a newer models like used 4060/7600 situation even worse with only like maybe 20% off a new one with zero warranty so a cba that gamble can't afford to get burned like that",
      "5600",
      "Cheapest rtx 4060 is **341$ and rx 7600 is 320$**",
      "Thanks, i will w8 because why not it's close enough but tbh leaking info about price of RX 9060 is very disturbing",
      "Hmm tough choice.\n\nWhat resolution do you play on?",
      "1080p",
      "how often do you replace GPUs?",
      "If he has money for a monitor, he should buy a better GPU instead, which seems more logical to me.\n\nThe B580 still isn't the top budget GPU for all purposes, but its VRAM is beneficial for certain games. \n\nI recommend waiting 1 to 2 weeks for the announcements of the new RTX 5060 and RX 9060 (XT) to see if prices drop."
    ]
  }
]