[
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "low",
    "matched_keywords": [
      "3060",
      "rtx3060"
    ],
    "title": "Upgrading my GTX 980TI - what is most suitable?",
    "selftext": "Hi everyone!\n\nI want to upgrade my old GTX 980TI but I have absolutely no clue about PC building.  \nI don't really know what to look for or what's better. I used [Technical City](https://technical.city/en/video/GeForce-GTX-980-Ti-vs-GeForce-RTX-3060) to compare some GPUs I found and looked for numbers go big brrr (or low if the context allows that lol)\n\nSo the point is - I only have 250-350€ available. Unfortunately I cant get a big upgrade but I take everything that retires my poor old GTX 980TI.  \nFor now I found the RTX3060 to be most suitable - what do you guys think about that GPU?\n\nFor more context my specs :  \nMainboard : X570 Phantom Gaming 4  \nCPU : Ryzen 5700x   \nPSU : Don't know which exactly but I'm sure its up to 600 Watts\n\nIf I forgot any important info please tell me.  \nThanks for any help!",
    "comments": [
      "I would get a 3080 or a amd rx6800xt on the 2nd hand market.\nIf u must have brand new, 3060 12gb or a 6700xt.",
      "From what I can see your best bet new is a 6700 XT which is faster than the 3060 at more or less the same price. You can expect 100+fps at ultra/epic settings on those games with the GPU, also with the 3060 if you prefer to keep Nvidia. Also as you’re just using 60hz monitor you can even use Super Resolution on both brands to render the game at a higher resolution and downscale to 1080p although I would advise you to buy at least a 144hz monitor to take full advantage of your setup as you have a very nice CPU.",
      "3060ti, 3070 or 4070 would be my top pics for nvidia, but AMD gpus slaughter Nvidia under $500.  For AMD: 6700xt (3060ti equiv) or 6800 non xt ($400 or less) closer to a 3080 than a 3070 and 16gb vram.  6700 non xt is also a solid card for the price.  A 3060 is kind of a bad card for gaming only.",
      "4070 or the ti version",
      "Imo shop for a used Nvidia 3xxx series card, or AMD 6xxx series. Rtx 3070 or 6700xt for example.",
      "For 250-350€, your best bet would be\n\nNew: 4060, 7600, 6700XT and 6750 XT (if you can find it would be the best)\n\nUsed: 3060 Ti, 3070, 3070 Ti, 3080 (maybe), 6800, 6800 XT\n\n3080 and above (6800, 6800 XT) used would give you the most performance, but it is rather hard to find any of these for 350€. 3070, 3070 Ti you already can find. So realistically, try at least aiming for 6750 XT, 6700 XT or 3070/3070 Ti.",
      "3070 seems to be at the top of your budget.",
      "With your monitors being 60hz at 1080p I’d say you’ll be comfortably pushing enough frames with a 3060/4060",
      "I got my used 6800xt for 360 usd, its a mid to high end card, compared to the rtx3060 which is a low end card nowadays.\n\nKeep this in mind, you can get awesome perfomance for not a lot of money.",
      "6700xt",
      "Really depends on your monitor. If you’re doing 1080 I would go with the 3060/12 gig card. If you’re going 1440 then get the 4070/12 gig card. I just traded in a 3060/12 card to get the 4070 because I’m playing on a 1440 monitor. 3060 looked like shit with the 1440. There is only about $200 difference in the two card. \n\nGo to Userbenchmarks to see the comparisons on all cards. Good luck.",
      "You could get a used 6800 at the minimum for that, maybe even a 6800xt.",
      "with 3080 u need more than 600w...",
      "I have no experience with AMD GPUs at all\n\nHow is the compatibility with the featureset and most games? I read NVIDIA here, NVIDIA there but rarely AMD for groundbreaking GPU Tech used in Games for example.  \nBut that could be because I never actively looked for it.\n\nHow is the user experience? For example with NVIDIAs GeForce experience its very easy for me to update the suiting drivers etc. - does AMD also offer such a service? Is the control panel as costumizable (application by application settings etc.)?",
      "Can't find a 4070 for under \\~600€  \nThis is way above my budget :/",
      "Roughly 650w is enough, I've tried it. 600 if u undervolt, and that is highly reccomended to reduce heat.",
      "At what resolution and framerate are you playing? \n\nDo you have a freesync/gsync compatible screen?\n\nWhat kind of games do you play?",
      "Amd is more bang for buck n longevity(the extra vram means you can keep a card longer without it becoming a stuttering mess n forcing a replacement at the end of its life), but if your ryzens ram is unstable even slightly your going to get black screens n gpu crashes because the gpu talks directly with the ram(common on 3600mhz ram on a 5000 series ryzen to be appear and test stable but then be not entirely stable without ram voltage tweaks) \n\nFor example a 6800xt was the same price as a 3070 in my country, mt friend got the 3070 and I got the 6800xt , and the 6800xt gets double the frame rate in most titles stock, and much much more now that I have it overclocked to the moon for example he gets 115-130 in certain cod mw3 maps at 1080p I get 250-300 at 1080 and 199-250 at 1440p same maps, and my card has double the vram. \n\nDownside: amd doesn't like hibernate shutdown/fast startup, doesn't play nice with crappy out of spec hdmi and dp cables, needs a decent quality psu, and they have noticed the mid range cards can perform as good as the upper cards with a little overclocking so they limited the voltage, frequency and power and locked the bios's and powerplay tables to stop people getting free performance beyond a certain point\n\nNvidia will run into the same problem on unstable ram as amd, but the drivers don't pop up a warning window, so it makes screen go black or crashes out of game, alot of ppl shrug reload game n carry on\n\nUpside nvidia often works on any old trash cables you have, the lower cards draw less power n don't mind a meh psu\n\nNvidia down side, way more expensive for the performance gained, they chop the balls off alot of these expensive cards by limiting memory bus width, and they ensure you will be buying another one on time by giving you only just enough vram to get you thru the current games",
      "it will have peaks, i read a bit about the 3080 and have one. in peaks it will draw over 700 easily..  \nhad to get a 850w to be safe under full load with a lot of peripherie connected in my case. good luck! undervolt sounds ok i guess",
      "I have two monitors at 1920x1080 with 60hz  \nThey're rather old so not freesync/gsync compatible\n\nWhat I play depends on the current mood / hype I have lol  \nBut I think the games that need most framerate that I play are FPS"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "low",
    "matched_keywords": [
      "rtx 3060",
      "3060",
      "rtx 3060 ti",
      "3060ti",
      "3060 ti",
      "rtx3060"
    ],
    "title": "nVidia GeForce RTX 3060 Launch Analysis (Meta Review)",
    "selftext": "- compilation of 14 launch reviews with ~3610 gaming benchmarks for all resolutions\n- only benchmarks under real games compiled, not included any 3DMark & Unigine benchmarks\n- geometric mean in all cases\n- standard rasterizer performance without RayTracing and/or DLSS\n- stock performance on reference/FE boards, no overclocking\n- **factory overclocked RTX3060 cards performance normalized to reference clocks/performance for the performance average** (PS: normalized for the average only, not for the performance documentation of each review)\n- performance average is (moderate) weighted in favor of reviews who using cards on reference clocks\n- power draw for the GPU only, no system power draw\n- for the full results check [3DCenter's Launch Analysis](https://www.3dcenter.org/artikel/launch-analyse-nvidia-geforce-rtx-3060)\n\n&nbsp;\n\nPerformance Gain AIB Cards|Hardware|FullHD/1080p|WQHD/1440p|4K/2160p\n|:--|:--:|:--:|:--:|:--:|\nAsus Strix OC @ ComputerBase|Boost 1882 MHz, TDP 170W|+2.7%|-|-\nMSI Gaming X Trio @ ComputerBase|Boost 1852 MHz, TDP 170W|+2.1%|-|-\nEVGA XC Black @ TechPowerUp|Boost 1852 MHz, TDP 170W|+2%|+1%|+2%\nMSI Gaming X Trio @ TechPowerUp|Boost 1852 MHz, TDP 170W|+2%|+2%|+2%\nPalit Dual OC @ TechPowerUp|Boost 1867 MHz, TDP 170W|+2%|+2%|+2%\nZotac AMP White @ TechPowerUp|Boost 1867 MHz, TDP 170W|+2%|+3%|+2%\n\n&nbsp;\n\nTested Cards|Hardware|Perf. Effect|Reviews\n|:--|:--:|:--:|:--:|\nsimulated Reference Card|Boost 1777 MHz, TDP 170W|Reference|[ComputerBase](https://www.computerbase.de/2021-02/geforce-rtx-3060-asus-msi-test/), [TechPowerUp](https://www.techpowerup.com/review/msi-geforce-rtx-3060-gaming-x-trio/)\nGigabyte Eagle|Boost 1777 MHz, TDP 170W|same as Reference|[Le Comptoir du Hardware](https://www.comptoir-hardware.com/articles/cartes-graphiques/43557-test-nvidia-geforce-rtx-3060.html), [PC Games Hardware](https://www.pcgameshardware.de/Geforce-RTX-3060-Grafikkarte-277122/Tests/12GB-Release-Date-Kaufen-Benchmark-Founders-Edition-1367318/)\nZotac Twin Edge|Boost 1777 MHz, TDP 170W|same as Reference|[Eurogamer](https://www.eurogamer.net/articles/digitalfoundry-2021-nvidia-geforce-rtx-3060-review)\nKFA2 EX|Boost 1807 MHz, TDP 170W|estimated +1%|[PurePC](https://www.purepc.pl/test-karty-graficznej-nvidia-geforce-rtx-3060-maly-ampere-szybszy-od-geforce-rtx-2060-super-cena-startowa-dobra-ale)\nGigabyte Gaming OC|Boost 1837 MHz, TDP 170W|estimated +2%|[SweClockers](https://www.sweclockers.com/test/31414-nvidia-geforce-rtx-3060-fran-gigabyte-och-msi-ampere-antrar-mellanklassen), [Tweakers](https://tweakers.net/reviews/8698/nvidia-geforce-rtx-3060-een-videokaart-exclusief-voor-gamers.html)\nEVGA XC Black|Boost 1852 MHz, TDP 170W|estimated +2%|[Tom's Hardware](https://www.tomshardware.com/news/nvidia-geforce-rtx-3060-review)\nMSI Gaming X Trio|Boost 1852 MHz, TDP 170W|estimated +2%|[Guru3D](https://www.guru3d.com/articles-pages/msi-geforce-rtx-3060-gaming-x-trio-review,1.html), [Hardwareluxx](https://www.hardwareluxx.de/index.php/artikel/hardware/grafikkarten/55523-dreimal-kleiner-ampere-von-asus-inno3d-und-msi-die-geforce-rtx-3060-im-test.html), [Hardware Upgrade](https://www.hwupgrade.it/articoli/skvideo/5953/msi-rtx-3060-gaming-x-trio-12gb-alla-prova-nvidia-ampere-mette-la-quinta_index.html), [Igor's Lab](https://www.igorslab.de/nvidia-geforce-rtx-3060-12-gb-im-test-mit-einer-boardpartnerkarte-was-kann-die-msi-rtx-3060-gaming-x-trio-als-ampere-einstiegsdroge/), [SweClockers](https://www.sweclockers.com/test/31414-nvidia-geforce-rtx-3060-fran-gigabyte-och-msi-ampere-antrar-mellanklassen)\nZotac AMP White|Boost 1867 MHz, TDP 170W|estimated +2%|Golem\n\n&nbsp;\n\nFullHD/1080p||5700|5700XT|1080Ti|2060S|2070S|3060|3060Ti|3070\n|:--|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|\nGen & Mem||RDNA1, 8GB|RDNA1, 8GB|Pascal, 11GB|Turing, 8GB|Turing, 8GB|Ampere, 12GB|Ampere, 8GB|Ampere, 8GB\nComputerB|Ref.|96.9%|107.3%|-|94.8%|111.6%|_100%_|129.7%|147.1%\nGolem|Zotac|-|99.8%|92.2%|-|-|_100%_|121.3%|134.2%\nEurog|Ref.|-|106.8%|103.2%|-|108.0%|_100%_|127.9%|140.2%\nGuru3D|MSI|96.7%|104.7%|101.6%|92.6%|105.5%|_100%_|122.6%|134.2%\nHWluxx|MSI|92.1%|104.2%|105.3%|93.1%|-|_100%_|125.1%|142.5%\nHW Upgrade|MSI|96.8%|110.2%|103.4%|94.0%|109.0%|_100%_|127.8%|139.7%\nIgor's|MSI|-|103.0%|-|91.3%|108.2%|_100%_|128.0%|141.0%\nLe Comptoir|Ref.|89.3%|100.1%|103.2%|94.8%|111.0%|_100%_|127.5%|142.1%\nPCGH|Ref.|-|107.7%|108.8%|-|113.4%|_100%_|129.7%|148.6%\nPurePC|KFA2|-|103.5%|103.1%|93.1%|111.6%|_100%_|127.8%|145.3%\nSweClock|MSI/GB|90.7%|94.0%|103.8%|90.7%|109.3%|_100%_|125.7%|142.1%\nTPU|Ref.|92.9%|103.1%|106.1%|94.9%|109.2%|_100%_|125.5%|137.8%\nTom's HW|EVGA|-|-|-|93.6%|110.3%|_100%_|125.7%|136.6%\nTweakers|GB|92.2%|104.7%|100.6%|92.8%|-|_100%_|121.8%|137.6%\n**FullHD Performance Average**||**94.1%**|**104.7%**|**105.3%**|**94.2%**|**110.6%**|**_100%_**|**127.9%**|**142.9%**\nMSRP||$349|$399|$699|$399|$499|$329|$399|$499\nTDP (TBP/GCP)||180W|225W|250W|175W|215W|170W|200W|220W\n\n&nbsp;\n\nWQHD/1440p||5700|5700XT|1080Ti|2060S|2070S|3060|3060Ti|3070\n|:--|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|\nGen & Mem||RDNA1, 8GB|RDNA1, 8GB|Pascal, 11GB|Turing, 8GB|Turing, 8GB|Ampere, 12GB|Ampere, 8GB|Ampere, 8GB\nComputerB|Ref.|95.7%|106.7%|-|94.8%|112.0%|_100%_|131.5%|150.4%\nGolem|Zotac|-|97.9%|92.8%|-|-|_100%_|124.1%|139.4%\nEurog|Ref.|-|104.1%|104.4%|-|108.5%|_100%_|131.1%|147.9%\nGuru3D|MSI|96.7%|104.2%|104.2%|93.5%|108.6%|_100%_|129.3%|144.3%\nHWluxx|MSI|89.2%|101.6%|103.1%|90.4%|-|_100%_|127.9%|148.0%\nHW Upgrade|MSI|95.1%|108.6%|103.6%|91.3%|108.1%|_100%_|129.9%|143.3%\nIgor's|MSI|-|105.2%|-|91.3%|109.6%|_100%_|128.8%|147.9%\nLe Comptoir|Ref.|88.4%|99.5%|102.4%|94.2%|111.0%|_100%_|129.5%|146.9%\nPCGH|Ref.|-|106.7%|109.1%|-|113.3%|_100%_|130.0%|149.9%\nPurePC|KFA2|-|101.6%|102.9%|92.4%|111.0%|_100%_|128.9%|146.9%\nSweClock|MSI/GB|89.6%|100.5%|101.6%|89.6%|109.3%|_100%_|126.8%|147.5%\nTPU|Ref.|91.8%|103.1%|107.1%|94.9%|111.2%|_100%_|130.6%|146.9%\nTom's HW|EVGA|-|-|-|92.9%|110.4%|_100%_|128.8%|142.6%\nTweakers|GB|91.1%|103.6%|102.3%|93.0%|-|_100%_|125.1%|142.3%\n**WQHD Performance Average**||**92.6%**|**104.5%**|**105.6%**|**93.5%**|**111.2%**|**_100%_**|**130.4%**|**148.2%**\nMSRP||$349|$399|$699|$399|$499|$329|$399|$499\nTDP (TBP/GCP)||180W|225W|250W|175W|215W|170W|200W|220W\n\n&nbsp;\n\n4K/2160P||5700|5700XT|1080Ti|2060S|2070S|3060|3060Ti|3070\n|:--|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|\nGen & Mem||RDNA1, 8GB|RDNA1, 8GB|Pascal, 11GB|Turing, 8GB|Turing, 8GB|Ampere, 12GB|Ampere, 8GB|Ampere, 8GB\nGolem|Zotac|-|94.0%|93.8%|-|-|_100%_|122.3%|142.7%\nEurog|Ref.|-|103.7%|104.0%|-|112.0%|_100%_|134.5%|154.5%\nGuru3D|MSI|92.6%|102.2%|105.5%|93.4%|109.9%|_100%_|132.2%|150.2%\nHWluxx|MSI|88.0%|98.7%|101.2%|87.8%|-|_100%_|126.0%|146.3%\nHW Upgrade|MSI|91.5%|104.2%|102.7%|89.3%|105.1%|_100%_|130.6%|147.3%\nPCGH|Ref.|-|103.5%|107.8%|-|110.6%|_100%_|128.2%|148.6%\nPurePC|KFA2|-|99.6%|101.6%|92.0%|111.4%|_100%_|132.0%|151.4%\nSweClock|MSI/GB|87.4%|98.4%|102.7%|88.5%|109.3%|_100%_|127.9%|148.6%\nTPU|Ref.|90.8%|102.0%|107.1%|92.9%|111.2%|_100%_|134.7%|154.1%\nTom's HW|EVGA|-|-|-|90.5%|109.0%|_100%_|129.8%|145.9%\nTweakers|GB|89.3%|101.1%|104.7%|91.8%|-|_100%_|127.7%|148.6%\n**4K Performance Average**||**90.4%**|**102.0%**|**105.7%**|**91.9%**|**110.5%**|**_100%_**|**131.4%**|**151.3%**\nMSRP||$349|$399|$699|$399|$499|$329|$399|$499\nTDP (TBP/GCP)||180W|225W|250W|175W|215W|170W|200W|220W\n\n&nbsp;\n\nPower Draw|3060|3060Ti|3070|3080|3090|6800|6800XT|6900XT\n|:--|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|\nGen & Mem|Ampere, 12GB|Ampere, 8GB|Ampere, 8GB|Ampere, 10GB|Ampere, 24GB|RDNA2, 16GB|RDNA2, 16GB|RDNA2, 16GB\nComputerB|172W|200W|220W|322W|351W|231W|296W|300W\nGolem|-|200W|221W|319W|357W|221W|301W|301W\nGuru3D|175W|224W|208W|338W|364W|239W|300W|322W\nHWluxx|-|209W|221W|332W|-|265W|334W|338W\nIgor's|169W|198W|217W|330W|357W|225W|299W|304W\nLe Comptoir|172W|198W|216W|326W|363W|227W|307W|309W\nLes Numer.|-|207W|233W|326W|370W|235W|280W|-\nPCGH|171W|202W|221W|330W|355W|232W|302W|301W\nTPU|177W|200W|233W|339W|366W|223W|279W|299W\nTweakers|172W|195W|214W|311W|361W|229W|284W|296W\n**average Power Draw**|**172W**|**202W**|**220W**|**327W**|**360W**|**231W**|**296W**|**305W**\nTDP (GCP/TBP)|170W|200W|220W|320W|350W|250W|300W|300W\n\n&nbsp;\n\nPerformance Gain of RTX3060|FullHD/1080p|WQHD/1440p|4K/2160p|FullHD/Watt\n|:--|:--:|:--:|:--:|:--:|\n**RTX3060** vs GeForce RTX 3070|–30%|–33%|–34%|–10%\n**RTX3060** vs GeForce RTX 3060 Ti|–22%|–23%|–24%|–8%\n**RTX3060** vs GeForce RTX 2070 Super|–10%|–10%|–10%|+13%\n**RTX3060** vs GeForce RTX 2060 Super|+6%|+7%|+9%|+9%\n**RTX3060** vs GeForce RTX 2060|+22%|-|+31%|+13%\n**RTX3060** vs GeForce GTX 1660 Ti|+41%|-|+56%|–4%\n**RTX3060** vs GeForce GTX 1660 Super|+44%|-|+59%|+6%\n**RTX3060** vs GeForce GTX 1080 Ti|–5%|–5%|–5%|+31%\n**RTX3060** vs GeForce GTX 1080|+16%|-|+22%|+18%\n**RTX3060** vs GeForce GTX 1070|+39%|-|+50%|+19%\n**RTX3060** vs GeForce GTX 1060 6GB|+88%|-|+112%|+28%\n**RTX3060** vs GeForce GTX 980 Ti|+48%|-|+61%|+103%\n**RTX3060** vs GeForce GTX 980|+85%|-|+109%|+87%\n**RTX3060** vs GeForce GTX 970|+118%|-|+156%|+104%\n**RTX3060** vs GeForce GTX 960|+226%|-|-|+107%\n**RTX3060** vs Radeon RX 6800|–33%|-|–39%|–10%\n**RTX3060** vs Radeon RX 5700 XT|–4%|–4%|–2%|+23%\n**RTX3060** vs Radeon RX 5700|+6%|+8%|+11%|+7%\n**RTX3060** vs Radeon VII|–5%|-|–9%|+51%\n**RTX3060** vs Radeon RX Vega 64|+19%|-|+22%|+106%\n**RTX3060** vs Radeon RX 590|+71%|-|+85%|+119%\n**RTX3060** vs Radeon RX 470|+127%|-|-|+82%\n\n&nbsp;\n\nSource: [3DCenter.org](https://www.3dcenter.org/artikel/launch-analyse-nvidia-geforce-rtx-3060)",
    "comments": [
      "wow awesome ...thanks for making it so detailed.\n\nlooks very good uplift from gtx 960",
      "1080ti doing bits. Thats my boy.",
      "He’s upgrading from a 960 why would he hold out.  2060 did not follow the 1060 price bracket either.",
      "I think it's saying that the 3060 is 5% *slower* than the 1080Ti.",
      "You can swear on the internet.",
      "It's rather bold to claim\n> 2060-> 3060 is a 10-20% improvement (20% is on the high side, benchmarks show its around 10% in most games)\n\nin a thread where the OP has analysed across many different reviews and found\n> RTX3060 vs GeForce RTX 2060 \t+22% \t- \t+31% \t[perf/watt] +13%",
      "[https://www.techpowerup.com/review/msi-geforce-rtx-3060-gaming-x-trio/5.html](https://www.techpowerup.com/review/msi-geforce-rtx-3060-gaming-x-trio/5.html)\n\n>Benchmark scores in other reviews are only comparable when this exact same configuration is used.\n\nI'd be interested in seeing if you can find a single one of those reviews in which the reviewers were dumb enough to do what you describe, because it sounds more like you're just talking out of your ass.",
      "Whatever strange memory gamble Nvidia was trying seems to have compromised the value of the 3060.\n\nI imagine the went with a 192 bit bus in the hopes that they could release a 6gb card and save on both memory and the bus. Instead AMD has crammed 16gb into thier high end, and we'll likely see 8-12 across the rest of the range. That extra 6gb in the 3060 cant be cheap, I'm almost certain that a 256gb bus and 8gb config would have resulted in a slightly faster card that would likely be at least 30 dollars cheaper to produce, and a 3060 at 300 dollars would be much more appealing.\n\nNow if only it wasnt cut down from the 3840 core full die. We'd have 7% more cores (and likely 5 percent more performance) and in theory at 300 bucks it would be a better value offering than the 3060ti.\n\nWith the existing 3060 the 3060ti = 30% more performance for 21% more money. A 5% faster $300 3060 results in a 3060ti offering 24% more performance for 33% more money.",
      "These cards are around 1000 USD in my country (so sick). I was \"lucky\" to get one at a retail shop for \\~700. Handed over to a friend who needs a vga, so we can play together. I'm good with the prev gen. haha\n\nps. \\*\\*\\*\\* the scalpers",
      "The card doesn't matter if you cannot get one and that is exactly the situation. I can find nothing online and my local Micro Center got less than 40 units as they told me when 3060 launched.\n\nTherefore I am staying with my 1060.",
      "Nice summary. I feel the 3060 is almost great. Instead, it's just... meh. It doesn't do enough for the price.",
      "seems like it sits between the 2060Super and 2070Super and 5% faster than 1080TI. People kept saying its the same as the 2060Super but I'm glad its not the case. The actual retail prices are terrible right now, I'm in Canada and the cheapest 3060 is only 30 CAD lower than the 3060TI founders edition and most of the 3060 cost MORE than the 3060TI founder edition. But again, those are retail prices, I think once silicon is back in supply, the 3060 will actually sell at MSRP which is a good deal.\n\n&#x200B;\n\nEdit: 5% Slower than 1080TI...but still a good deal!",
      "During launch there were tons of comments on places like this saying it's comparable to a 1070 or 2060 or whatever. Glad things are finally getting cleared up.\n\nRegarding 1080Ti, the 3060 seems to be a bit slower. But the 3060 is also an ampere card with DLSS, resizable BAR, etc. that aren't factored in to cross-gen performance comparisons to make the tests more balanced",
      "Honestly its amazing the difference even 30 dollars make in the comparison.  With no other changers, at 300 bucks alone it would scale linearly with the 3060ti.\n\nTo put things in perspective, if it was $250 it would be absurdly good value (3060ti would offer 30 percent more performance for 60% more money)\n\nHell, at $280 it would be compared with the 1660ti which it is roughly 50% faster than.",
      "Lol. Yeah if you can’t beat ‘em join ‘em....selling a 3080 for $2200! That’s why people scalp....cuz you can make a lot of chedda.",
      "2060->3060 = 22% average performance gain, not including resizable BAR which gives the 3060 a 17% increase in games like battlefield 5 and will be more and more supported in the future.\n\n1060->2060 is missing context. The 6GB 1060 launched at $250 with a cheaper 3GB model, and the 2060 was $350 at launch.",
      "1000? So cheap!  \nWhere I live, they are selling them at 6000dls at minimun",
      "Ya the 3060TI is definitely the better deal but you gotta buy a bot to get it lol! I was able to backorder a 3060 at my local retailer in Canada but they wouldn't even let me backorder the other 30 series cards saying that they have no idea when they'd get stock.",
      "Oh don’t blame him one bit. I’d do the same thing. I don’t have a problem with any of it. The value of something isn’t it’s MSRP it’s what ever someone else is willing to pay for it. I bought a scalped 3080 the scalped price was still cheaper than what I was going to pay for a 2080ti. So more power to him.",
      "Is a shame that I will never be able to buy this card  \nThey are selling it like 6000dls here"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "low",
    "matched_keywords": [
      "rtx 3060",
      "3060",
      "rtx3060"
    ],
    "title": "Will a 550w psu be enough for RTX3060 + R5 5600?",
    "selftext": " \n\nI bought one for a different build a year ago, and I really am on a tight budget. I'm upgrading to RTX 3060 and R5 5600, but I still have my 550W PSU ([Corsair CX550M](https://www.corsair.com/us/en/Categories/Products/Power-Supply-Units/cx-series-config/p/CP-9020121-NA)). I just feel a bit uncomfortable, but if this works for me, it will be really nice. What should I do?",
    "comments": [
      "That's a 65W CPU and a 170W GPU. The whole system will never draw more than 300W so a 550W PSU is more than enough.",
      "Yes. It is considered as oc but dram sticks draw so low it doesn't even matter. Oc to the moon mate.",
      "Yes. That cpu draws 77w at max without any kinda oc and let's say rest of the system expect gpu draws 50w and that leaves about 420watt. That gpu draws 170w at stock fe so it is fine. You can even oc the system(5600will draw about 105w with pbo+auto oc) but be careful with gpu oc and monitor power draw. Gpus draw a lot in a short period of time (just peaks instantaneously) so it can trigger the psu. Without oc you're just fine.",
      "My cheap friend is using a 5600x with a RTX 3060Ti FE and he got a cheap old ass powersupply 500w without even bronze 80+. So it „should“ work",
      "Exact same system I had and it ran without an issue (though I always used eco-mode on the CPU).\n\nI have since upgraded to an 850W PSU as my CX550M had pretty bad coil whine under load.",
      "I run a 3060ti with a 5600x and no issues just make sure that the 12v rail is 550w and not 450w",
      "Get a Corsair TX550M **2021**, these older CX models are not that good (it will still work, but it's better to have a higher quality psu imo)",
      "Rule of thumb I follow is, if the system turns off on you while you are gaming, then you need more wattage.",
      "CX Lineup is the WORST",
      "Can I OC the RAM? Is XMP profile considered OC by this standard?",
      "I even ran mine with a 3060 Ti on a 450W bronze power supply.",
      "yes",
      "yes",
      "yes. I literally just paired these with a corsair cx550 for my sons birthday yesterday, you're good to go.",
      "no, how are you able to afford 400$ gpu but you are thinking about buying a 60$ psu? minimum 650w unless you like to fry your system when in the summer it hits 100% usage in some random new aaa game",
      "What's bad about it? Aside from the coin whine that I got when I first started using, I never had any problem since?",
      "meh, i ran a 9700k/RTX 3070 on a 550w for a couple of years. i recently upgraded to a 850w just last week, because i knew i was pushing it and the opportunity presented itself. but the 550w never let me down."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "low",
    "matched_keywords": [
      "rtx 3060",
      "3060",
      "rtx 3060 ti",
      "3060 ti",
      "rtx3060",
      "rtx3060 ti"
    ],
    "title": "Rtx 2080 vs Rtx3060 ti",
    "selftext": "Hi\nRecently I decide to upgrade my gpu from rog strix 2060 oc to tuf rtx 3060 ti but after some searching on local market and online markets i noticed that I can not afford the rtx3060 's price (because I live in iran and this stuffs are expensive) \nThey suggested me to buy an rtx 2080 (rog strix 2080 oc i think) so i compared rtx3060 and rtx 2080 on gpu user benchmark website and the is result is the rtx3060 ti has 4% extra power than 2080.\nSo there is a problem is it that 4% so important or no? \n\nhttps://gpu.userbenchmark.com/Compare/Nvidia-RTX-3060-Ti-vs-Nvidia-RTX-2080/4090vs4026\n\nSorry for my bad English",
    "comments": [
      "Your English is great don’t worry at all ! I wouldn’t use userbenchmark , if you can I would just do a quick look for some videos 2080vs 3060ti x game (pick a game you like) to see the performance difference, 4% power difference is within the margin of error really so no difference at all",
      "I wouldn’t use userbenchmark as a source. I would look for 3060Ti reviews and benchmarks from other sources. However, the 3060Ti and 2080 Super trade blows based on what I’ve seen but I’d find some other sources to confirm.",
      "In terms of gaming performance, the closest 2000-series / \"Turing\" equivalent to the \"Ampere\"-based [RTX 3060 Ti](https://www.techpowerup.com/gpu-specs/geforce-rtx-3060-ti.c3681) is actually the [RTX 2080 Super](https://www.techpowerup.com/gpu-specs/geforce-rtx-2080-super.c3439).  \n\nNote that there's not too much difference between the 2080 Super and [the original RTX 2080](https://www.techpowerup.com/gpu-specs/geforce-rtx-2080.c3224) though, so if you can't find the 2080 Super locally then the 2080 would match your stated needs.",
      "Thanks so much",
      "As if the fake benchmark scams on YouTube are any better than userbenchmark website. LMAO\n\nMeanwhile vast majority of the \"GPU vs GPU\" video creators do not own any of the graphics cards, they just spoof the videos.",
      "Haha that is indeed true , but there some decent ones out there , I’m sure you could find a gamer nexus video where Steve has a comparison between the two tbh , but yeah sometimes they are pretty useless"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "low",
    "matched_keywords": [
      "rtx 3060",
      "3060",
      "rtx3060"
    ],
    "title": "Rtx 3060 or 2060super",
    "selftext": "So i have a question performance wise which is better? \nKFA2 GeForce® RTX 2060 SUPER™ 1-Click OC 8GB\n\nOr the rtx3060/ti",
    "comments": [
      "The 3060-ti destroys the 2060 super in performance. The 3060 is looking to be a slightly boosted 2060 super/2070 based on it's tFlops and etc. I'd try going for the 3060 when available.",
      "Still better by a comfortable margin.",
      "3060 should be better, and its Ti brother clearly smokes both of them. \n\nBut my estimate is that 3060 will be around 2070S levels of performance on average, since it does not make sense when 3060@170W performs like 2070@175W.",
      "3060ti for sure",
      "Based on that nvidia promo video, 3060 is a 12g 2070 at best, your decision",
      "This sounds like good advice but anyone selling a used 20X0 card wants more than retail 30X0 cards.  There's no sense to any of this.",
      "I'm debating if i should get a €880 prebuilt msi with a 2060 super or built one myself with a 3060 ti but then it'll be about 1100. What should I do? How much of a price difference isbit worth.",
      "If you are going to buy a GPU bran-new, then it's best to get a series 30 card (3060, 3070, 3080, 3090), but if you are on a budget and want an used, but powerful card, then it's best to get a 2060 Super or 2070 Super or get a 2080-Ti from a miner that upgraded to 3090 (of course if the card is in great condition)",
      "And the normal 3060 from speculations?",
      "Then ill be waiting for it but i hope i can get one before it gets out of stock",
      "From what i heard from others the 3060ti is waaaaaaaaay better than the 2060super. So if you can afford it definitely go with it",
      "I think the speculation was that it was 22% better",
      "Then i hope i get to buy the 3060 when it launches cause itll be like 330€ where that 2060super8gb is 370 rn"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "low",
    "matched_keywords": [
      "3060",
      "rtx 3060ti",
      "3060ti",
      "rtx3060",
      "rtx3060 ti",
      "rtx 3060ti"
    ],
    "title": "Using daisy chain with RTX3060 ti",
    "selftext": "So, I have read a lot of posts about using or not daisy chain with RTX 30XX GPU, and some peoplesaying that it's a problem only on 3080 and 3090.\n\nIn my case, I have a [Corsair 550VS](https://www.corsair.com/ww/en/Categories/Products/Power-Supply-Units/VS-Series-80-PLUS%C2%AE-Certified-Non-Modular-ATX-PSU/p/CP-9020223-EU) and just bought the [MSI RTX 3060ti Ventus 2x OC](https://www.msi.com/Graphics-Card/GeForce-RTX-3060-Ti-VENTUS-2X-OC).\n\nMy corsair PSU has only 1 pci-e cable with 2x 6+2 pins as daisy chain, and the GPU has two 8 pins slots. Theoretically it's enough, but I'm not sure if it's safe.\n Do you guys think I should replace this PSU and get another one with 2 pci-e cables? If so, 550W is enough?",
    "comments": [
      "10/10 would use 2 separate cables. Id also recomend upgrading that psu so youve got some headroom for power spikes. I dont know the exact power consumption of each card but online tech reviewers seem to like the 750+\n\nThings to consider with the next PSU:\n\n-get a modular design and some kind of warranty",
      "750 is overkill. A high-quality 550 will do the job. Emphasis on high-quality.\n\nI highly doubt he will need more than 550W on an average CPU for the 3060ti. Might need more if he's rocking a bigger cpu.\n\nIf he plans to upgrade his cpu to smth bigger, then yeah get 650W or smth. 750W is still overkill for this build.",
      "You should be fine... the Daisy chain is really designed for a 2 6-pin GPU (75W +75W) which means 150 Watts for the single cable. The 3060 ti is a 200 Watt GPU... so with the 75 Watts that the PCI-e slot provides plus the 150W from the cable... you can handle 225W safely.",
      "Yeah, I was thinking if corsair would really develop something not safe and still receive awards and certifications with this PSU model. I think I'm gonna give them some credit and use this PSU.",
      "Hey did you end up using the daisy chain for the card  I've a similar psu and was thinking about getting rtx 3060 should i go for it?",
      "Hey i know this post is a year old but did you end up daisychaining your card because i dont know if i should daisychain my 3060 because i dont want to have so many cables in my case and some people are telling me to  do 2 seperate cables and some are telling me its ok to daisychain it",
      "Yes man! I'm using it for more than a year now and no problems so far",
      "I did it and it's still working fine 1 year later",
      "My CPU is a Ryzen 5 3600. \nI bought this PSU on August last year, so it's not THAT old yet. But anyways, for me safety comes first.",
      "That's amazing to hear! Waiting on the gpu to arrive thanks dude",
      "Check your manual."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "low",
    "matched_keywords": [
      "rtx 3060",
      "3060"
    ],
    "title": "NVIDIA Ampere Architecture for Every Gamer: GeForce RTX 3060 Available Late February, At $329",
    "selftext": "",
    "comments": [
      "\"Every Gamer\"",
      "\"Available\"",
      "Just comparing to the GTX 1060 6GB: MSRP was 250$ and Founders was 300$.",
      "\"$329\"",
      "Interesting we now live in a universe where the FE is the cheapest (even pre Tarif). \n\nI guess Nvidia learned that charging a premium for worse everything is a bad move. It’s much better to force hard to hit low prices on the AiBs so you can look like the hero.",
      "Founders Edition: $329\n\nScalpers Edition: $629",
      "I have a feeling there's a reason if they didn't show performance vs 1080 ti",
      "*out of stock joke goes here*",
      "They talked 1060, but how will this compare to a 1080 Ti?",
      "Late February 2022 or at 600$ it is then!",
      "Not to mention that most reviews tend to factor in the MSRP of the FE in their price performance ratio, even though they're impossible to get and no AIB cards even get close to MSRP.",
      "The 1080 ti still showing how it was and still is an amazing card for the money.",
      "3050 for some gamers when?",
      "Aaand here we go again everyone praising a COMPLETELY WORTHLESS MSRP. You will NOT be getting these GPU's at $329 USD. Has nobody here learned anything? This card will be $450+ for 99% of people, ~500 Euro for Europeans, and probably even more for non-Western countries.",
      "Hey guys we heard you weren't happy with the amount of VRAM on the 3080 and 3070.\n\nSo fresh out of Jensen's oven I introduce our first consumer Ampere card with 12 GB of VRAM, the RTX 3060.\n\nWTF, smh.",
      "Strange the 3050 is currently rumored to have 4GB\n\n3050 4GB\n3060 12GB\n3070 8GB\n3080 10GB\n\nReally strange I feel like the 3060 is going to be the big volume seller. Maybe they give it 12GB on purpose to seem like the most attractive option.",
      "https://cdn.videocardz.com/1/2021/01/NVIDIA-GeForce-RTX-3060.jpg\n\nSo realistically ~10-15% more performance than a 2060 at 10% higher MSRP.\n\nThoroughly underwhelming would be putting it mildly. It does have more VRAM but.... meh.",
      "this is a joke, full gp106 sold for $250, now full ga106 sells for $330?",
      "Bitter truth, its going to be best mining card for 12GB vram.",
      "Nope, seems to be worse"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "low",
    "matched_keywords": [
      "rtx 3060",
      "3060",
      "rtx 3060ti",
      "3060ti",
      "rtx 3060ti"
    ],
    "title": "RTX 3060 vs RTX 3060ti",
    "selftext": "I live Croatia, the price of 3060 is 400€ and the 3060ti is 500€. Is the 3060ti worth the extra 100€. I'll mainly gonna be doing some 1080p gaming and that's it.",
    "comments": [
      "None! Go for 6700xt. Should be cheaper and faster than both + has 12GB VRAM.",
      "this is the only right answer to this question",
      "The 3060ti is much closer to 3070 performance than 3060 due to being the same die I believe as the 3070.\n\nIf it's within your budget I would get the 3060ti over a base 3060.\n\nBut only if it's within your budget.",
      "3060ti is 400€ on Amazon ES. It ships to Croatia as its in the EU.",
      "Only if it actually has a gsync module in the monitor. If it's only gsync certified, it won't make a difference which brand GPU they choose. \n\nAMD has come a long way and it shows a lot recently. \n\nThe RX6000 series has shown that. Especially if they've managed to keep their prices low in comparison to their direct Nvidia rival. I literally just installed a 6950xt in my rig over the weekend because it was a flat out better option for the money compared to a 4070",
      "Depends on if you want to do streaming though - the NVENC encoding is far superior afaik.",
      "Rx 6700xt is better, same VRAM but  absolutely destroys 3060 but only if you find it at same price",
      "I had an 3060ti. Was a great card. Get the ti 100%",
      "Someone’s been out of touch for a while, AMD is perfectly fine. Nividia has driver issues too.",
      "Even with gsync module it will work with AMD",
      "Well, you might want to wait for rtx 4060. It will provide similar performance but with much lower power consuption. I just bought rtx 3060ti, no regrets so far, but to be honest, with new gpus around the corner, I would wait a bit.",
      "AMD offers far more performance at this price point, you’d have to have a very specific non gaming related use case for choosing Nvidia IMO.\n\nNvidia’s two main gaming advantages are ray tracing which isn’t really useable at this performance tier and DLSS which isn’t very effective at 1080p.",
      "Why are you lying? 3060ti is perfectly capable at RT even in Cyberpunk.",
      "3060ti refresh also uses GDDR6X instead of regular GDDR6.",
      "Or an A770 assuming pricing is decent.",
      "As someone here said some time ago. That 12 gb vram is like adding a race-grade spoiler onto a regular hatchback. 3060 ti will still perform alot better everytime",
      "As long as the board supports Rebar, then ARC is a viable option.",
      "yeah i saw how fine they were with 7900 xtx not receiving drivers for months and then other drivers making cards fry lol",
      "Oh are you taking about the 3090s dying when playing new world?",
      "Man i do 1080p on 165hz gaming and my 3080 is overkill apparently. In my humble opinion yes. Also think 3060 is 12gb vram vs ti at 8. And the reg 3060 lower clock speeds and bus speeds. I think v ram is needed more than the few mzh difference between the 2. But anyone that knows better can correct me."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "low",
    "matched_keywords": [
      "rtx 3060",
      "3060",
      "rtx 3060 ti",
      "3060 ti"
    ],
    "title": "GeForce RTX 3060 Ti Coming December 2nd. Faster Than RTX 2080 SUPER, Starting At $399",
    "selftext": "",
    "comments": [
      "£369 in the UK. Just watch these all sell out in about 5 seconds to the scalping twats!",
      "Nice so now there's going to be 4 cards from Nvidia nobody can buy until 2021.",
      "Better than a 2080s lmfao, GG Nvdia",
      "Spoiler: you won’t be able to",
      "Doesn't even matter, if you can't get it",
      "Really hope I can snag one. I am so sick of searching for an RTX card.",
      "I'm sure you can. For 2080s price.",
      "Cool another super fast card I won't be able to purchase.\n\n&#x200B;\n\nNeat!",
      "Linus will get them all\n\nI got two more at launch. It was easy. Wow",
      "Brilliant price. I was expecting at *least* £379, even as high as £399.",
      "narrator: he did NOT snag one.",
      "Please don’t kill this father for asking probably a dumb question; my son has a 980 ti. Is this a worthy upgrade?",
      "Get on EVGAs list right now.",
      "Best kept secret of the human race for sure.",
      "*AIBs have entered the chat*",
      "Massive upgrade. Definitely try to get one if you can.",
      "His review card already broke too",
      "*Scalpers have taken the chat and are selling it for £1300*",
      "And drop them all.",
      "Reviews are out, 3060ti follow suite along with the 3070 and 3080. It is a huge generation boost compare to the 2060.\nThis is a true 1080p very high fresh rate/1440p card.\nLooking forward to AMD response with 6700/6700xt."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "low",
    "matched_keywords": [
      "rtx 3060",
      "3060",
      "3060ti"
    ],
    "title": "Which GPU to chose between : RTX 3060, 3060ti, 4060, 4060ti ?",
    "selftext": "Hi guys, I live in France, I mostly play games but got into UE5 recently and with the release of Starfield and other games I really need to upgrade my GPU (GTX 1650)\n\nI have a budget around 400€ with 500€ as a hard limit\n\nI don't know if I should take a less powerfull card but with higher memory or the other way around (is 8gb enough or will I need 12 or more ?)\n\nI aim to play at 60hz 1080p\n\nOther usefull specs : \n\nI5-9400F\nGTX 1650 LP OC\n2 x 8gb crucial 2666mhz",
    "comments": [
      "6700 XT for 340€.",
      "This is AMD right ? I have a really bad history with AMD gpu especially AMD drivers, had a laptop with a R5 something in it i never understood how the software worked. So idk...",
      "You got that from user benchmark right? 💀😂\n\nhttps://preview.redd.it/fup81k3lkdeb1.jpeg?width=1170&format=pjpg&auto=webp&s=353be734f378f652770d1d2eca0241a13a27b302",
      "You got it all messed up, it's the non-Ti which has somewhat better value than the Ti - although it's still pretty crap.\n\n6700 XT is definitely the right choice here.",
      "You want to play Starfield?  \n\n\nThen it is a no brainer, get an AMD card and [get Starfield for free](https://www.amd.com/en/gaming/featured-games/starfield.html#bundle). If you get the 6700 or above, you get the Premium Starfield, worth $100, including early access, free DLS, etc. Ah, and it is a Steam copy, not a Microsoft one, which makes it even better.  \n\n\nWith a 500$ budget and some lucky you can get a RX 6800 which is leagues better than any of the cards you are considering. The 6700XT is equal or better than the cards you are considering and sells for pretty cheap nowadays.  \n\n\n  \nNow if you absolutely want to go with Nvidia (and miss the Starfield bundle, like... why?) then, ugh, these are all bad cards, honestly. I would only consider the 3060 12Gb or the 4060Ti 16Gb. Anything else in between only feature 8Gb VRAM (4060, 4060Ti 8Gb model, 3060Ti, 3070), and 8Gb for this day and age is a serious compromise. You would be asking for headache in upcoming AAA games by buying a 8Gb card right now.",
      "There really needs to be a pinned thread with the answer to this.",
      "Yes.\n\n> I have a really bad history with AMD gpu especially AMD drivers \n\nDon't worry about it, it's as stable as Nvidia now (mainly 6000 series, 7000 series might need some work).\n\nThe 6700 XT has both the performance and the VRAM, so there's nothing you can go wrong with it.",
      "That is indeed interesting, it's basically the 4060 12gb (slighly better apparently) that is missing from the 40xx series\n\nI will take this in consideration though I'll try to get other opinions on the whole drivers thing. Thanks dude",
      "Not 4060 and 4060ti. Unless they are at the same price point as 30 gen",
      "Amd for the win.  If you can't get a 4090.  Get. 6700xt.",
      "Yeah I just saw that, they give the full game with a 6700xt for less money than a nvidia less powerfull gpu, is it the AMD cards that are cheap or nvidia that are overpriced ? I bet on nvidia...",
      "I see a lot of people hating on the 4060 & 4060ti, from what I understand they are overpriced for theirs powers right ?",
      "I've been using amd for 3.5 years 5600xt, 6700xt and now 7900xt and I can say that amd drivers are perfectly fine. My 6700xt was already very good, had few weird crashes in my summer car and subnautica (like once a month) everything else worked perfectly fine and since upgrading to 7900xt it has been rock solid in my brother's pc.\n\nIf you have anything to ask about it feel free to ask, I'm more than happy to help.\n\nPs. By buying amd gpu you get starfield as a bundle with the gpu for free",
      "That much for a 3060? I live in Finland and here, despite the terrifying prices, you care get a 3060 for 289 euros. And that is the 12Gb model. Stay away from the 3060 8Gb.",
      "Just looked at [amazon.fr](https://amazon.fr) and you can get a 3060Ti for 330€. I would get that.\n\nThat or just go all out to an 4070 for 660€. But the rest of the system would be too slow for the card, so just get the 3060Ti.\n\nEdit: Just saw that Starfield is offered on new AMD cards. Just get an 6700Xt and call it a day.",
      "Yep I agree !",
      "Most of the modern weapons use a texture for the sight glass that AMD cards for whatever stupid reason can’t render and just show up as purple, it’s the reason why I use Nvidia since modded FO4 is still my main hour sink. \n\nUsed cards are fine, I’ve mostly only ever buy used PC parts, have for over a decade without issue. It’s well worth $50-100+ saved. I just got a 4070 Ti at 4070 MSRP looking at Amazon for used.",
      "A crash once in a while is normal guess, at least I'm used to it, i used to have a 750ti and now a 1650 they cause crash more than your 6700xt (the 1650... worst GPU i ever saw...)\nThanks for offering your help but I won't bother you, I just need to catch up with all the new technologies created since the RTX's and all. I'm still living in the era where the 1080 was the ultimate GPU... and now that AMD gpu are great now I will learn a bit more about them\nThanks dude.",
      "I'm definitely going for a 6700xt after everything i saw here, thanks",
      "I'm definitely going for a 6700xt after everything i saw here, thanks."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "low",
    "matched_keywords": [
      "rtx 3060",
      "3060",
      "rtx 3060ti",
      "3060ti",
      "rtx 3060ti"
    ],
    "title": "Should I downgrade to a RTX 3060 12GB from a RTX 3060ti 8GB because of the VRAM?",
    "selftext": "Hello,   \nI recently got an used RTX 3060ti for the price of a brand new RTX 3060. I play on 1080p, 60Hz. I was upgrading from a old GTX 1060 3GB, so I had high expectations. I started playing a latest game, Horizon Forbidden West. But I found that I cant put the texture quality setting anything above \"Medium\", or else the fps drops like crazy (like 40-45 fps), Sometimes even 15-20 fps due to the lack of VRAM. I'm really dissapointed and frustrated by this. I didn't spend all this money to play games on Medium settings, which definitely looks very ugly. So I'm really concerned that the upcoming titles might also exhibit the same issue, making this 8GB card completely obsolete. \n\nConsidering this, should I just sell this card right now and get a RTX 3060, which has 12 GB VRAM? How good or bad of a decision that will be? ",
    "comments": [
      "posts on the sub are insane... asking should i downgrade??? asking how bad a decision? this post was a bad decision",
      "Keep the 3060ti imo, it is the faster card overall. If you really want, sell the 3060ti and save up for something better or more future-proof but as of now it is better to just stay with the 3060ti.",
      "Keep the 3060 TI, turn down textures to save VRAM.\n\nThe 3060 12GB is to slow, just wait till a better GPU comes out next gen to upgrade or look to AMD or used Nvidia/AMD.",
      "It seems only the \"Texture Quality\" settings affects this. I tried with every other settings to \"low\" with textures kept to just \"High\", (Not even \"Very High\"), still this problem occurs. Then I tried with every settings to the max, only the textures to \"Medium\". Then the fps drop doesn't happen. But medium textures look very ugly and it is very much visible.",
      "Shut down background apps or turn off hardware acceleration for them. Run launcher and kill explorer.exe. This will save VRAM.\n\nYou can also safely OC your card using Nvidia app",
      "Nah. Always keep the faster card. At lower resolutions VRAM shouldnt matter THAT much.",
      "The official hardware requirements for this game recommends an 8gb card for 1440p@60 fps high preset, you should be fine with 8gb, if you are running at very high preset then that's probably the issue. The game dev recommends medium preset, high preset is above their recommendation, so very high is essentially for flagship cards.",
      "loving my PNY 3060 12gb running BF4 2042 2560x1440p in a 200+ fps (auto mode / competitive mode)",
      "Just wait until you can buy a better gpu",
      "The 3060ti is faster but the 3060 does have advantages with the 12gigs. It helps me more In VR where the 12gigs has an advantage over having 8gigs. I have no problems running anything with a 3060. i5 12400f and 32gigs ram.\n\nWhat some people don't realize that it's not just what hardware you have but also how you maintain your pc. Seen so many people unable to play a game that I am playing with no problems and they have a far better setup. Keep you pc clean, make sure sure you have at least 25% free space on your HDD, use SSD's for best performance.",
      "Yes I also have no idea. The game runs fine with 70+ for like 10-15 minutes, or after fast travelling few times the fps dips to 40-45 (sometimes even less) and stays there until I restart the game. After a restart, everything is again okay for a while. Its very annoying to restart the game every few minutes.  \n\nScrolling through several threads, I found out that people with 8GB vram or less suffer from this kinda problem. Others with 12gb or above can run the game fine.",
      "Yes, 12gb is fine up to 1440p for very high textures. If you swap to 3060, take your current fps and decrease it by 20%. HFW is one of a few games that is really VRAM sensitive. If you cannot set it aside and play at a later time when you have upgraded to a more powerful 12gb+ card, then there will have to be compromises, it is a very demanding game.",
      "Those benchmarks don't mean anything as they have only tested for a short time. HFW has issues with VRAM buildup over time and especially during cutscenes. It is a nixxes thing as they use a different kind of VRAM handling than most devs. You can play on high with 8gb at 1080p, but you would have to restart the game a lot to clear VRAM. Sadly these PS5 PC ports are unusually demanding than what they should be.",
      "Dude I own it and is playing the updated game right now. It isn't fixed, just delayed. It's not a leak or a bug, it is a feature of how nixxes handles VRAM for all their games. Ratchet and clank has the same issues and that was released a year ago.",
      "Rebar is enabled by default with a recent Nvidia driver. I have double checked it with profile inspector. From my testing, rebar seems to actually increase VRAM usage (though it could just be additional allocation)",
      "I think those 3070 users either don't play long enough for issues to appear, or have a lower threshold for what they consider an issue. I'm usually at 10-11gb at 1440p. I also think nixxes uses large VRAM chunks to load in, and they want to avoid it going over the threshold. But yeah it's not great either way. I don't think ram capacity beyond 16gb does anything for this game when I look at the stats during playing, it's usually like 12gb. SSD is required imo.",
      "Absolutely not. Do you want to lose performance in all games except for the 4 or 5 games that are poorly optimized? It's the developers fault, not yours. Keep your GPU and lower textures whenever you're in need to do so.",
      "That would be terrible idea. At 1080p the 8gb is ok. I have the 3060ti and at 1440p dlss quality and all high I never ran out of vram. No idea how you have problems at 1080p",
      "Buy lossless scaling from Steam. VRAM doesn't matter. It's just AMD neanderthal marketing."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "low",
    "matched_keywords": [
      "3060",
      "3060 ti"
    ],
    "title": "Upgrading from GeForce 970 to 3060 Ti RTX",
    "selftext": "",
    "comments": [
      "Nice. I switched from 950 to 3060ti and could not be happier.",
      "I upgraded from a 750TI. Just a \"slight\" upgrade..",
      "damn same cooler of their 3080 series. not sure if it ever pass 60C lol.",
      "You could probably get more for the 970 on ebay than MSRP on that 3060 🤣",
      "Bro same that’s what I was going to do as well. Can’t wait to play on higher FPS",
      "Like right in the middle of a manufacturing shortage that's hiking prices up!",
      "I guess at least it's a step up over the stupid box pictures. Especially the dumb ones strapped into a car seat.",
      "Just upgraded my MSI 960 to a 3070. Feels good man",
      "I got it for one month now and It's amazing to be able to play basically everything I want with max Settings.",
      "It depends, my Gigabyte Gaming OC PRO 3060Ti basically has the 3080/3070 cooler, and it rarely goes above 60°C lol.\n\nIt is really a beefy cooler for a \"weak\" card like a 3060Ti compared to the 3080.",
      "Thanks for letting us know.",
      "1440p is SO awesome. I play Warzone at 1080p on high settings with my 3060ti but I play Cod:Cold War, Doom:Eternal, and Cyberpunk at 1440p max settings. Cyberpunk is about 80-110fps unless i'm in a really busy street and Doom/CW both are capped at 141fps so I don't get any tearing above my 144hz monitor.\n\n&#x200B;\n\nits been so much fun. I can't go back from 1440p now",
      "That's a hell of a generational leap congratulations on finding one at msrp!",
      "Oooooh! A Palit card 💚",
      "Dude prices are nuts. I sold my PowerColor Red Devil on eBay and it went for $650 within 3 minutes of being listed. Dude was thrilled to get it for that price too. I paid $356 for it back in July. My 3060ti was $469.99. \n\nI just got a 3090 this morning through one of the drops and that definitely hit my wallet lol. But with the income from selling the 5700xt and the money from selling the 3060ti I’ll only end up spending about the cost of a 3080 which is what I really wanted, so it works out.",
      "Palit gaming pro",
      "what model is that, it looks fly af",
      "Nah it's great for 1440p too, got one myself",
      "It's for 1080p yeah. The new generation of games cant really be played anymore without setting the graphics down. I had roughly 50 fps on my 1080ti on cyberpunk 2077 1080p, the 3060ti is slightly faster, so reaching 60 should be ok (with rtx off).",
      "The 3080 has a bigger cooler , but the same design ."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "low",
    "matched_keywords": [
      "rtx 3060",
      "3060",
      "rtx 3060 ti",
      "3060 ti"
    ],
    "title": "Geekbench: GeForce RTX 3060 Ti is almost as fast as Radeon RX 6800 in OpenCL benchmark",
    "selftext": "",
    "comments": [
      "IT IS a 3070 that failed the necessary quality check to be sold as a 3070 while still being useable",
      "Isn't it just a RTX 3070 then? What's the point?",
      "I just want a 3060 that’s 300 - 350",
      "It hurts that that’s how much I paid for my 970 5 years ago",
      "GPU manufacturers check each die, if it still functions in some capacity (eg, lower clocks or just a few CUDA blocks don't function) they can sell it as a lower tier GPU.",
      "Absolutely. I got my EVGA 970 FTW3 for $340 and it came with a coupon code for Witcher 3 and MGSV. Those were the days.",
      "3060ti ones aren't good enough to run at the 3070 spec so they run at the lower 3060ti level. Sounds like it's not much difference though, especially for +25% on the price",
      "Almost as out of stock as the 6800 too I bet.",
      "It uses the same GPU as the 3070 (GA104), only with some of the cores disabled. The 3060 Ti is basically a \"defective\" 3070 being sold at a discount. The same is true for the 3080 (GA102) which is a defective 3090, and the 3090 in turn is a defective RTX A6000.",
      "This card has the benefit of being totally unknown.  Zero marketing, it's not even announced yet and it launches on Wednesday.",
      "What do you mean by necessary quality check?\n\nIf they're equal why would anyone buy a 3070 over a 3060Ti (assuming equal availability/supply/demand)?",
      "I am surprised nobody offered you a marketing job yet, you are really selling those cards well.",
      "\"Launches\".",
      "Idk if OC could make up all the difference. To be very basic, when they make these things, if part of it doesn't work right they disable those parts instead of throwing it away. That's why some of these cards are almost identical in specs. One will just have less CU bc they disabled the broken ones. That way they can still sell the ones that aren't perfect.",
      "$400 is the new mid range unfortunately",
      "I wish there was more news about the 3050ti",
      "Remember when Nvidia's top tier 80 cards came with an msrp of $500 even though people then felt that was far too expensive? Pepperidge Farm remembers",
      "it's not  marketing, just describing binning\n\nIntl, amd, nvda, aapl all do it\n\nwhy does this have 60 upvotes when my comment below as -50... are y'all not able to read usernames and see that I was not the one who made the comment that was disagreed with?",
      "I know - I am just making light fun out of the way you described Nvidias line up in the most unattractive way possible.",
      "Oh no. I thought it would be mid range. shit"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "low",
    "matched_keywords": [
      "3060ti"
    ],
    "title": "7 gpus arrive in the post. Been 2 weeks and still haven’t asked for them back.",
    "selftext": "Full story:\n\nI ordered a used gpu off eBay and it was broken, no output no display nothing. \n\nI asked for a refund or replacement and they said they would send one, I didn’t need to give back the broken one.\n\nWaited one week, and a package arrives. It is too big to be a gpu, but to my surprise when I open it it is not a gpu, but 7. \n\n3 gigabyte 3070s, 2 ev3a 3070s, a tuff 3070 and a founders edition 3060ti.\n\nI now have 8 gpus, one broken, and they are not asking for any back.\n\nUnfortunately for me, almost all of these have been in the mines until near death. Most of them output and work fine until they are out under any sort of stress; if they’re stressed their temps skyrocket (thermal paste?) and the system shuts down to avoid overheating. \n\nWhat do I do with these? Sell them for parts? Are they salvageable?",
    "comments": [
      "try a repaste and see if any lasts the stress, then you could keep one or sell on for profit",
      "As others have said, repaste with decent brand and if they all work. Get rid ASAP and use the money to bag a brand new 4090 and some serious upgrades 👍",
      "ok I will try it over the weekend and test them. (need to order thermal paste)",
      "sounds like they might need to be repasted and have the thermal pads replaced",
      "Instead of paste you should order ptm7950 as it won't pump out.",
      "eBay Seller: “if he can get any of these to work, they’re his. Good luck 👍”",
      "What? lol what do you think “fridge” is short for?",
      "why not double down and tell them you didn't get a working card. They're probably just getting rid of stuff they know is broken on people who won't bother complaining.",
      "I would list the most expensive one on ebay. Then wait until the person who bought it complains about it not working. Now you can just send them the rest of the gpus and keep the money. They will be too excited about the box of gpus to realize none of those work correctly either.",
      "Honestly 4080 or 7900xtx would be the sweet spot",
      "The fact the seller has 7 spare graphics cards which are nearing death with thermal related problems kinda implies they were constantly under stress, and thus, mining.",
      "And the chain continues 😂",
      "It's expensive, kinda weird to work with but otherwise great stuff.",
      "do you really want to be repasting and repadding a bunch of cards that the person/store might get back to you admitting their mistake and asking for back?",
      "Pretty sure you just need to repaste them. I'd enjoy doin this stuff at the table with the tv on. Keeps me busy and off the phone",
      "And maybe don't post online about it\n\n¯\\\\_(ツ)_/¯",
      "Depending on their local laws, they may not have to give anything back if it was sent from a company. If it was from an individual via ebay, then I am not sure.",
      "in the US, by law it's 100% ok to keep them.",
      "Don't worry I'm also disappointed in you.",
      "My thoughts exactly. What a weird thing to specify."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "low",
    "matched_keywords": [
      "3060",
      "3060 ti"
    ],
    "title": "Finally upgraded from 1660 ti to 3060 ti",
    "selftext": "",
    "comments": [
      "Hell yeah 3060ti gang",
      "No busty goth gf reigns supreme and undefeated",
      "Don’t you have a neck pain while looking at the tv?",
      "Is 3060ti significantly better than 1660ti?",
      "Not really I sit on my gaming chair inclined and sometimes with support of my neck pillow to play or watch\n\nI also watch it on my bed with nice angle hehe",
      "Very",
      "Is it like changing gf from a supermodel to a busty goth?",
      "Man I'm still on my 1660ti. I never seem to have the money or the opportunity to upgrade lol\n\nI keep looking at the 3060ti though I never seem to know if it's ENOUGH of an upgrade",
      "I'm here with you!",
      "Yet guess what.. for 1080p in spider man I'm getting cpu bottlenecked. Mine goes to 4.95ghz too",
      "3070 has a 7 in it,\n1440p has a 14 in it,\n7*2 is 14\n\nTherefore 3070 is better",
      "yes",
      "3060ti is a sweet spot for gaming pc",
      "What pc case",
      "Hell yeah",
      "It is called Rakk Haliya M\n\nIt is local in the Philippines only I think",
      "yeah that top tv doesn’t look pleasant",
      "Between the 4000 series being announced and when it actually gets released (and inevitably sells out!) Will be the best time to buy",
      "Cousins",
      "A lot of people who waited for the 3000 released ended up with no GPU for a long time.   Nobody knows what will happen on release.  If the launch is the same as 3000 series where demand far outweighs supply then the price of cards will go up not down.  Also more importantly it depends what happens with the crypto market"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "low",
    "matched_keywords": [
      "rtx 3060",
      "3060",
      "3060ti",
      "3060 ti"
    ],
    "title": "Rtx 3060 12gb or 3060ti?",
    "selftext": "Hi guys.\nI'm going to buy a rtx 3060 12g dual palit.\nAnd the reason I prefer it to 3060 ti is it's vram that really matter.\nIs it ok for my 4k UHD tv?\nMy bundle is i7-10700&z490-p&rtx 3060",
    "comments": [
      "3060 12g is a scam imo, it’s performance is terrible so the amount of vram it has doesn’t matter. Could have 16g wouldn’t make a difference",
      "Depends on the games, but I don't think 3060 or 3060 ti are good for 4k. Maybe 1440p.",
      "3060ti is better option, it can definitely drive 4K gaming more than 3060 could. and VRAM is not important in case of 3060 at 4K because it graphical power can't even handle gaming at that resolution.",
      "I have a 4k monitor and 3060 Ti. I usually run newer AAA games at 1440p and get 60-90 fps. Pretty much any game 2020 and before I run at 4k or upscaled 4 at 60-120 fps,  highly recommend it. With DLSS enabled, I get better frames.",
      "What 4K. I had the 3060ti and my train sims where running between 30/40 and 60/70 fps @ 4K and for me was enough. That said I would go for 12gb model",
      "Neither can do 4k, you need a more powerful card. \n\nIn terms of performance the 3060ti is a lot faster even if it has less memory, so it's the better choice in most cases.",
      "Tbh at that price point a 2080ti would probably fare better for 4K, or you could grab a 3080 on ebay for just about 100ish bucks more that would definitely run anything you want in 4K"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "low",
    "matched_keywords": [
      "rtx 3060",
      "3060",
      "rtx 3060ti",
      "3060ti",
      "rtx 3060ti"
    ],
    "title": "RTX 3060 12Gb vs RTX 3060TI 8Gb (Upgrading Super)",
    "selftext": "Heyo Reddit!\n\nSo I'm planning on upgrading from a 1660 Super to either an RTX 3060 (12Gb) (GIGABYTE) or 3060TI (8Gb)(INNO3D)  \nThe price difference is around $111  \nI'll mainly be using it for gaming (Fortnite/Minecraft/Valorant), streaming, editing (Premiere Pro/After Effects) and Blender.\n\nSo is it worth paying the extra $111 for the TI with less ram or is the 3060 gonna be good enough for now? \\[Plus I reallllllly don't know anything about INNO3D, so kinda skeptical\\]\n\nHere's my current specs:   \nCPU: i5-11400F  \nGPU: 1660 Super  \nRAM: 4x8Gb 3000Mhz  \nSSD: 980 Pro 500 Gb  \nHDD: 2TB Barracuda\n\nI would really appreciate your help!",
    "comments": [
      "If your only choices are 3060 and 3060ti, get the Ti. Adding 1TB of VRAM on the 3060 wouldnt make it any faster. \n\nIf you really need the vram then consider AMD.",
      "Go for the 12gb card, you will thank me later\nOr you can prolly get a 6800 for the same price range",
      "Wait for the 4060/Ti and see what they have to offer.",
      "3060ti would be overkill for those games, 3060 would be plenty.",
      "They’re doing video editing and Blender. Generally Nvidia is the much better choice for anything outside of gaming, although if you’re only working as a hobbyist it doesn’t matter too much",
      "4060 Ti is rumored for $450 (and I’ve seen newer rumors saying $400), so, yes, absolutely wait. At worst it’ll drop prices for the 3060/3060 Ti.\n\nBTW, are those prices USD? There are 3060 Tis on Amazon (US) for under $400",
      "it's converted from INR to USD and unfortunately, the cheapest 3060ti available is $480, which does suck tbf\nbut yeah, I'll wait, thank you!",
      "What are the prices for each card? I know you said $111 more for the Ti, however, I’m asking as the RTX 4060 + 4060 Ti are expected in the next few weeks with the rumored pricing being similar (within $50) to the 3060 + 3060 Ti msrps.",
      "How big are the Blender scenes you work with? The 3060ti is a lot faster, but if you’re working with big scenes, the extra VRAM might be of more use",
      "3060 12gb",
      "Have you never taken a look at Blender benchmarks?",
      "thanks for the suggestion!",
      "the blender scenes are small currently, but I'm planning on shifting to UE5 soon. but after consulting with others, I've decided to wait till i can afford a 4070ti/4080 [The prices are wack over here]",
      "Any particular reason you prefer to spend more on Nvidia for less than what you can get from AMD in this price range?",
      "Did you end up getting a 40 series?  The 4080 is still almost $1500, the 4060ti is around $600 for the same amount of Vram but much faster processing.  \n\nImo a 3060 still sounds good for you.  If you're only doing small scenes or projects, both the 3060 and the 3060ti will perform well for you.  I'd go for the cheaper 3060 if you know you're not going to be pushing into next gen titles at 4k ultra settings.  Whatever you get will be a huge leap from the 1660s, which imo is still a fantastic card.",
      "yeah as the comments said, reliability.",
      "i saw that it's confirmed for the 4060 to also have 8gigs of vram",
      "hello hello. I'm just planning on upgrading to a 4060, since it's the same price as a 3060 over here, just doing some final confirmation",
      "3060 is $370 and TI is $481\n\nSo yeah, worth waiting? orrrrr should I just get it right now?",
      "Reliability. do you really think amd is being consumer friendly offering cheaper cards?"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "low",
    "matched_keywords": [
      "rtx 3060",
      "3060",
      "rtx 3060ti",
      "3060ti",
      "rtx 3060ti"
    ],
    "title": "GIGABYTE RTX 3060 EAGLE OC 12gb vs ZOTAC RTX 3060TI, which one should I pick?",
    "selftext": "Hello everyone!\n\nI can't decide between these two cards, I've looked at the [graph](https://imgur.com/V8cpRL7) and the 3060ti seems much better performance wise, however I don't completely trust ZOTAC and I've heard their cards run a bit hot + can have some issues.\n\nI have an old case, which is a bit small and without any external fans. On top of that my PSU is 600w, the 3060 reccomends 550w so I'm good to go, while the 3060ti reccomends 650w, so I would have to change the PSU as well (I want to be 100% sure).\n\nWhat is getting me is the price difference tho, the 3060 is at 330$ while the ZOTAC 3060ti 380$, which is pretty close and doable for me...\n\nI mostly want to do some gaming medium/high settings, but I would like this expense to be worth on the long run to, I've had a 1050ti for YEARS (7+) and just recently had the need to replace it.\n\n&#x200B;\n\nCan you help me decide? Thank you so much.",
    "comments": [
      "i wouldn't go dual fan on a xx70 or xx80 series. \n\nxx60 or xx60ti is a lower temp chip. dual is fine for those. above that you really want a full size cooler. xx70 series is kind of borderline, but i'd just go with a 3 fan cooler for it too.",
      ">. It's also far more power efficient and has 40 series features that last gen lacks (frame gen, AV1 encode plus something else I'm forgetting)  \n>  \n>btw, you wouldn't need to change the PSU for t\n\nThanks! I'll see what I find :)",
      "A 4080 at 380 is an absolute steal or scam"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "low",
    "matched_keywords": [
      "rtx 3060",
      "3060",
      "rtx 3060ti",
      "3060ti",
      "rtx 3060ti"
    ],
    "title": "RTX 3060 (3 fans) or RTX 3060Ti (2 fans)",
    "selftext": "Hello, I'm going to build my first gaming PC!\n\nI'm building it for 1080p60 streaming and 1080p light gaming (I don't really think I'll play any \"expensive\" games, maximum something like Hogwarts Legacy, but only once a year tbh). I'll also do occasionally video editing in Adobe Premiere Pro, but nothing wow.\n\nI chose Ryzen 5 5600 as a cpu, and a 1080p 165hz full hd ips monitor, but I can't decide for the GPU.\n\nWhat should I choose between: MSI RTX 3060 12GB (3 fans) for 320€, or a KFA2 RTX 3060ti (2 fans) for 350€ ?\n\nThere is no 2 fans 12gb 3060 available here, the one mentioned earlier is the cheapest 12gb 3060 available in my country.\n\nWhat should I choose? My budget is on the limit.",
    "comments": [
      "If you can afford it, the 3060 Ti, it is 20-30% faster than the 3060 depending on the game and resolution. In addition, no amount of cooling via an extra fan is going to make up for the lack of power that the 3060 has compared to the 3060 Ti. I will say this though, if you run a game where 8GB of VRAM is not enough then the 3060 12GB will take a performance lead, but those scenarios are the only ones and if you're playing light games like League of Legends, CS:GO and Valorant etc you won't have an 8GB of VRAM problem at all. So in summary, 3060 Ti or look for an AMD option like the 6700 XT.",
      "3060ti is the way in your use case",
      "3060 Ti is much more powerful. If you can afford it, you should definitely get it. It not, the non ti 3060 is still good enough to 1440P DLSS high quality gaming.",
      "3060 Ti easily in this situation.",
      "I don't think any game will need more than 8gb vram, when they fix it with patches. On 1080p that is. The thing is , they released some crappy ports and everyone thinks its a problem. If they want to sell PC games, they will have to optimise them better, 99% of steam users has 8gb vram or less. Also they already fixed the last of us. The only game I can think of it has problems now is Hogwarts Legacy, but it should never be that demanding, graphics are way worse than most new games.",
      "Those are ex mining gpu check them thoroughly before you buy them, use furmark for 1 hour.",
      "Where the hell you find those prices lol?",
      "Doesn't Hogwarts Legacy have VRAM issues?",
      "Go with 3060ti.\n\nAnd buy a Noctua fan to reach 3 in total if it matters to you. /s",
      "3060ti vs 3060.. 3060ti always better choice. 3070 even 15-20% better.\n\n The 12GB doesnt mean anything.",
      "![gif](giphy|8nRK1Edesqsc7gBY0G)",
      "320 and 350\\* :))",
      "hard miners.",
      "In the beginning, yes, if they fixed it now - I don't know, already completed it.",
      "As far as I can tell, the stuttering is gone but the texture issues still occur on 8 GB."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "low",
    "matched_keywords": [
      "3060",
      "3060ti"
    ],
    "title": "nVidia GeForce RTX 3080 Ti Performance Summary: 8 reviews & 940 benchmarks compiled",
    "selftext": "- compilation of 8 launch reviews with ~940 gaming benchmarks at the 4K/2160p resolution\n- only benchmarks under real games compiled, not included any 3DMark & Unigine benchmarks\n- geometric mean in all cases\n- stock performance on reference/FE boards, no overclocking\n- only launch reviews with **complete adoption of rBAR & SAM** were evaluated _(check PS2)_\n- standard performance without RayTracing and/or DLSS\n- missing results were interpolated (for a more accurate average) based on the available & former results\n- performance average is weighted in favor of reviews with more benchmarks\n- results were cutted in 2 tables, because as one table it becomes to wide (all results are comparable between the two tables)\n\n&nbsp;\n\n4K Perf.|Tests|6700XT|6800|6800XT|6900XT|2080Ti|3080Ti\n|:--|:--:|:--:|:--:|:--:|:--:|:--:|:--:|\nGen & Mem||RDNA2, 12GB|RDNA2, 16GB|RDNA2, 16GB|RDNA2, 16GB|Turing, 11GB|Ampere, 12GB\n[ComputerBase](https://www.computerbase.de/2021-06/nvidia-geforce-rtx-3080-ti-review-test/)|(17)|60.9%|76.2%|88.6%|96.3%|68.1%|_100%_\n[Golem](https://www.golem.de/news/geforce-rtx-3080-ti-im-test-nvidias-ti-tan-mit-halbem-speicher-2106-156854.html)|(8)|59.4%|77.8%|90.6%|99.7%|-|_100%_\n[Igor's Lab](https://www.igorslab.de/en/nvidia-geforce-rtx-3080-ti-fe-in-test-almost-an-rtx-3090-but-with-halved-memory-expansion-for-gamers/)|(9)|61.7%|75.8%|87.8%|95.2%|-|_100%_\n[Le Comptoir d.H.](https://www.comptoir-hardware.com/articles/cartes-graphiques/44118-test-nvidia-geforce-rtx-3080-ti.html)|(19)|59.2%|75.0%|86.9%|94.1%|68.1%|_100%_\n[PC Games Hardware](https://www.pcgameshardware.de/Geforce-RTX-3080-Ti-Grafikkarte-277501/Tests/Test-Benchmarks-Vergleich-mit-RTX-3090-1372951/)|(20)|-|-|-|93.2%|-|_100%_\n[PC World](https://www.pcworld.com/article/3620654/nvidia-geforce-rtx-3080-ti-review.html)|(11)|-|-|-|91.9%|-|_100%_\n[TechPowerUp](https://www.techpowerup.com/review/nvidia-geforce-rtx-3080-ti-founders-edition/)|(22)|61%|77%|89%|95%|68%|_100%_\n[WCCF Tech](https://wccftech.com/review/nvidia-geforce-rtx-3080-ti-12gb-founders-editions-pure-titanium/)|(8)|-|74.2%|88.3%|95.1%|64.7%|_100%_\n**average 4K performance**||**60.3%**|**75.6%**|**88.1%**|**94.8%**|**68.0%**|**_100%_**\nTDP (TBP/GCP)||230W|250W|300W|300W|260W|350W\n\n&nbsp;\n\n4K Perf.|Tests|3060|3060Ti|3070|3080|3080Ti|3090\n|:--|:--:|:--:|:--:|:--:|:--:|:--:|:--:|\nGen & Mem||Ampere, 12GB|Ampere, 8GB|Ampere, 8GB|Ampere, 10GB|Ampere, 12GB|Ampere, 24GB\n[ComputerBase](https://www.computerbase.de/2021-06/nvidia-geforce-rtx-3080-ti-review-test/)|(17)|44.0%|59.4%|68.8%|90.4%|_100%_|102.3%\n[Golem](https://www.golem.de/news/geforce-rtx-3080-ti-im-test-nvidias-ti-tan-mit-halbem-speicher-2106-156854.html)|(8)|51.7%|-|-|92.2%|_100%_|103.7%\n[Igor's Lab](https://www.igorslab.de/en/nvidia-geforce-rtx-3080-ti-fe-in-test-almost-an-rtx-3090-but-with-halved-memory-expansion-for-gamers/)|(9)|-|59.7%|68.1%|90.3%|_100%_|102.0%\n[Le Comptoir d.H.](https://www.comptoir-hardware.com/articles/cartes-graphiques/44118-test-nvidia-geforce-rtx-3080-ti.html)|(19)|-|59.5%|68.2%|90.0%|_100%_|104.0%\n[PC Games Hardware](https://www.pcgameshardware.de/Geforce-RTX-3080-Ti-Grafikkarte-277501/Tests/Test-Benchmarks-Vergleich-mit-RTX-3090-1372951/)|(20)|-|-|-|90.6%|_100%_|104.8%\n[PC World](https://www.pcworld.com/article/3620654/nvidia-geforce-rtx-3080-ti-review.html)|(11)|-|-|-|90.0%|_100%_|103.8%\n[TechPowerUp](https://www.techpowerup.com/review/nvidia-geforce-rtx-3080-ti-founders-edition/)|(22)|45%|61%|70%|90%|_100%_|101%\n[WCCF Tech](https://wccftech.com/review/nvidia-geforce-rtx-3080-ti-12gb-founders-editions-pure-titanium/)|(8)|-|-|-|89.9%|_100%_|102.6%\n**average 4K performance**||**45.1%**|**59.2%**|**68.2%**|**90.3%**|**_100%_**|**103.0%**\nTDP (GCP)||170W|200W|220W|320W|350W|350W\n\n&nbsp;\n\nAt a glance|GeForce RTX 3080|GeForce RTX 3080 Ti|GeForce RTX 3090\n|:--|:--:|:--:|:--:|\n4K performance|90.3%|_100%_|103.0%\nMemory|10 GB GDDR6X|12 GB GDDR6X|24 GB GDDR6X\n(real) power draw|325W|350W|359W\n(official) MSRP|$699|$1199|$1499\n\n&nbsp;\n\nSource: [3DCenter.org](https://www.3dcenter.org/artikel/launch-analyse-nvidia-geforce-rtx-3080-ti)\n\nPS: Comparison of 3080Ti Cards from Asus, EVGA, MSI, Palit & Zotac [here](https://old.reddit.com/r/nvidia/comments/nuvtdn/comparison_of_3080ti_cards_from_asus_evga_msi/).\n\nPS2 (June 10th): PCWorld's statements about the status of rBAR/SAM were unfortunately misunderstood on my part. After clarification, the status of rBAR/SAM at PCWorld must be changed to \"not active\", although the appropriate hardware was used for this. Unfortunately, there is nothing more to change on the results and evaluations, but the effect of this error on the overall figures should be rather marginal.",
    "comments": [
      "$500 for 10% increase in performance. That has to be the worst deal in history.",
      "Thanks for the tables, but wow, only ~~10%~~11% faster than the 3080 and 3% slower than the 3090, so many cards with so much different prices, but all of them with similar performances lol",
      "Nah, $800 for 13% increase is even worse (3090). But yea, still awful. Lol.",
      "shy wine secretive silky innate shame squash stupendous pocket deer\n\n *This post was mass deleted and anonymized with [Redact](https://redact.dev)*",
      "that 10% is dwindled when you factor in AIB cards too because its all the same fucking chip.",
      "TBH it seems like the value proposition of the 3080 Ti is a marketing issue. If instead the new card was called the 3090 lite, it would seem like a great deal, only 3% less performance but 20% cheaper? OR HELL just call it a 3090 12GB! That's what it pretty much is anyways...",
      ">$500 for 10% increase in performance. That has to be the worst deal in history.\n\nThat is for 4K also. For 1080P and 1440P, that drops to like 4-6%.",
      "I will never understand why people will use the OC argument. If you can OC one, you can OC the other... and theoretically the Ti should have more headroom given it's much higher core count, memory, and bus width.",
      "For anyone doing VR Gaming I can say with absolute certainty that the 3090 is *incredible.*\n\nMy wife and I are very active VR enthusiasts having logged a couple thousand hours with the Valve Index over the last year and a half and play nightly. Our VR rig had an i9-9900KF and 2080 Ti in it prior to snagging a 3090 FTW3 from EVGA on launch (at retail price mind you). Our frame times dropped significantly which was to be expected with just the rasterization increase from that card to the 3090, but where it *really* shined was being able to supersample existing VR titles. Some games that struggled at 100% resolution scaling before at max visuals in-game were now able to be supersampled at 160% with max visuals all from the significant increase in VRAM.\n\nI also use a 3090 K|NGP|N on my desktop gaming PC and the extra VRAM helps there as well with running multiple 4K monitors. So while I agree it definitely doesn't make sense for gaming if you're doing 1440p or even just regular 4K/60 gaming (I do 4K/120 with a PG27UQ monitor), there's definitely some aspects of gaming where the 3090 with the extra VRAM is an absolute game-changer as far as overall experience goes.",
      "Yeah like I’m not here to say the 3080ti is a good value, it’s clearly not.  But comparing OC of one card to stock performance of another makes no sense.",
      "In a world with options, of course the 3080 non-Ti is one of the best choices. \n\nBut considering that most are $1500+ and 3090s are $2000+, I'm happy to have lucked out on a 3080 Ti for \"only\" $1400. And get a 10% boost to feel good about myself thanks to our NVIDIA overlords.",
      "And you can also overlock the 3080ti…",
      "A 2080ti for $599, this guy had a 3070 years before everybody else lol",
      "In Poland price delta is minimal... All 3 models for 10000-12000 PLN which translates to roughly $2725- $3275. This includes 23% of VAT, but mostly is due to scalping margin. Normally we used to have MSRP + VAT similar to most EU members...\n\nI will have to live with my 1080Ti until crypto market has a major crash...",
      "It's the same chip but not the same GPU. All 3080s have the same number of SMs and the same memory bandwidth. All 3080tis have the same increased values. AIBs only change the power budget, stock clock speeds and cooling.",
      "Didn't the 1080ti have a 30% perf difference from the 1080 for only $200 more?\n\nMiss those days.",
      "Well for people that should be using the 3090, there is a lot of research and work related activities that can use that 24 GB of VRAM. \n\nThe 3090 shouldn't be bought by gamers... if there were no stock issues...",
      "Thank you. The OC argument is brainless lol",
      "Honestly I’ve said from the start that the 3090 is effectively just a renamed Titan not the 80ti replacement that most tech tubers made it out to be.\n\nThey should have kept it as a Titan and saved 3090 for this card and truly done what the tech tubers though was going on, because it isn’t outrageous, they have just done an appalling job at making sure people understand the product stack.",
      "I’ve always bought the “Titan” class of card every 5 years or so when I upgrade knowing full well I’ll get fucked by the ti card 6 months later… but I have to be honest I feel like I got a good deal this time around… 3090 at £1300 new.. saw a 3070 being sold in a shop used for £1200 yesterday… crazy times"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "low",
    "matched_keywords": [
      "rtx 3060",
      "3060",
      "rtx 3060 ti",
      "3060 ti"
    ],
    "title": "Finally upgraded to an RTX 3060 TI from my 1660 Super. Really happy with the jump in performance.",
    "selftext": "",
    "comments": [
      "Hoping to do the exact same upgrade!! Really excited",
      "Go for it. I waited till this day to play cyberpunk. I'm having a blast with it.",
      "Up until january I had a Ryzen 5 1600 and a 1660 Super. I pulled the trigger and got a 5600X. The bottleneck was so hard at 1080p(even at 4ghz) that it felt like a GPU upgrade.\n\nNow, after a lot of thinking I found a very good deal on a 3060 TI Aorus Elite. I'm really happy with this model. It's the first time I don't have to fiddle with undervolting since my HD7950. The temps are great, the card is dead silent, no coil whine. I even got an easy overclock of +80 core and +800 memory with no issues.\n\nFull specs:\n\nASRock B450 Pro4\n\nRyzen 5 5600X @ 1.2v 4.5GHz\n\nDeepcool Gamaxx 400 with a Noctua NF-F12\n\n2x 8gb XPG 3200 CL16\n\nRTX 3060 TI Aorus Elite\n\nXPG 256gb NVME\n\nCrucial MX500 500gb\n\nSeagate Baracuda 2tb\n\nAsus Xonar DGX\n\nCorsair CX 550\n\nCase is a Fractal Design R3 clone\n\n3x BeQuiet Silent Wings 3\n\n\nNo RGB, no glass side panel.",
      "I'm getting good frames with my 1660 super, but definitely notice the drops. I'll definitely get it when I can!! By next month hopefully.",
      "Deepcool is mad at you for using a Noctua fan on their heatsink",
      "Yeah the 3060ti is a beast",
      "Neat! Welfome to rhe rtx club, i jumped from the 1070 to the 3080. Happy days\n\nStock is more available now! I want to get one 3060 for my kid, how much was this beaty?",
      "I just upgraded from a 1060 and, yeah, the jump in performance is dramatic and suddenly I'm interested in gaming again.",
      "watercooler arent that good tbh, good air cooler > cheapass watercooler/aio",
      "I upgraded from an 1080 to an 3060 Ti two weeks ago. Have been playing Ghostwire Tokyo since then. Ray Tracing and DLSS really make a difference, more than the pure performance gain. Pity I had to pay 650€ for it but msrp is only a wet dream (wet from my tears).",
      "Same here. I had 1600AF on 4ghz and 1660S. Then I got 2700x on stock. Now 3060 + 2700x. I should buy a better CPU",
      "I got my 3060ti at launch, best $400 ever spent!",
      "The 1070 its still a good graphics card even today for 1080p",
      "I actually had almost the same path as you went from 1070 to 3060ti and play cyberpunk with maxed out settings it was sweet you’ll love the ray tracing!",
      "*Scoffs in 720p*",
      "Your comment, along with previous one, doesn't make sense as he WAS talking about liquid cooling cpu. To which, I also agree, airflow is a better setup for a variety of reasons, cost being the biggest.",
      "3060 ti gang",
      "I'm probably a special case in this matter. I had a 1080 back in the day. Had to sell it due to money issues. Got a 570. Sold it and got a 1660 Super right before the pandemic hit. It was serving me very well, and I could still hold on to it for a little longer. But I really wanted a jump in performance without paying a big ammount of money. In my country the 3080 is almost 3x the price of a 3060 TI.",
      "Air cooling is stil really good",
      "You type like you're 11, go to bed"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "low",
    "matched_keywords": [
      "rtx 3060",
      "3060",
      "3060ti"
    ],
    "title": "Rtx 3060 (12gb) vs 3060Ti (8gb) exclusively for VR?",
    "selftext": "I am planning to upgrade from a 1060 and i was wondering wich one of the two cards performs better in VR, i am especially concerned about the vram disparity between the 2.\n\nHeadset is a Quest 2",
    "comments": [
      "If you're playing SkyrimVR, go for the regular 3060. The extra Vram is worth the downgrade in GPU power itself.",
      "All the title i mentioned will be played in VR mode so they need better raw gpu power over vram?\n\nI really considered a 6750xt in VR but seeing all the problems especially with driver updates so that you have to roll back to older ones, the slow time it takes for amd/vr devs to address them or improve general rx VR performance it just doesn't inspire any trust software-side for me.",
      "On average the 3060 ti and 6700xt are both matched in raster at 1440p - \n\nhttps://youtu.be/pnZRuY-jFVM. \n\nIn rt 6700xt obvs gets destroyed. Now gimme a sec to find the MULTITUDE of Reddit threads explaining why nvidia > amd in vr because of Nvidias superior encoders",
      "He’s using a quest 2. He needs Nvidias encoders to have a better experience.",
      "Here’s a thread with everyone saying Nvidias betters, there’s tens of these with a single search btw - \n\nhttps://www.reddit.com/r/OculusQuest/comments/tg8o50/amd_or_rtx_gpus_with_quest_2/?utm_source=share&utm_medium=ios_app&utm_name=iossmf\n\nAnd here’s a more in depth breakdown of the difference in encoders and why this happens -\n\nhttps://forums.guru3d.com/threads/amd-amf-and-gpu-encoding-issues-and-discussion-notably-for-vr.443275/",
      "10:49 is the 1440p average across all 50 games. Literally says right at the top, same performance at average…",
      "3060 Ti for sure. \n\n[https://babeltechreviews.com/vr-value-wars-the-hellhound-6650-xt-rx-6700-xt-vs-the-rtx-3060-3060-ti/](https://babeltechreviews.com/vr-value-wars-the-hellhound-6650-xt-rx-6700-xt-vs-the-rtx-3060-3060-ti/)",
      "The 3060 is slightly faster than the 2070.  Get the ti....",
      "I'm planning on playing No Man sky vr with low enough settings, Zenith: the last city, Assetto Corsa, DCS, Il2 Sturmovik obviously all with settings for an optimal experience.",
      "Get a 3060 ti bro. Vram won’t hold it back and  3060s 12gb isn’t a 1:1 comparison to the 60 ti due to bus width, bitrate etc. For example the 6800xt has 16gb of vram and the 3080 has 10 but due to those factors I listed plus the faster gddr6x, they both end up using the same proportion of their vram in games.",
      "Eh, I guess go with Nvidia? CBA to read all that but the guy has sources so it's probably true",
      "Then go for the 3060Ti.\n\nHowever, if you're buying it because \"nurr nvidia is better than amd\" save yourself some money and get a 6700XT. Better raster performance and the feature set of the 3060Ti won't help much in VR titles (that being the RT performance and DLSS)",
      "I have heard nothing about Nvidia having better encoders. I don't think the difference will be big enough to make it a difference in purchasing. The difference in raster performance is large enough to actually change games from unplayable to playable.",
      "In what world is this equally matched? It is beating it in almost every game. Also note that a 3060Ti OP would buy nowadays is much weaker in games than the one in this benchmark."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "low",
    "matched_keywords": [
      "3060ti"
    ],
    "title": "Upgrading from 710 to 3060ti",
    "selftext": "",
    "comments": [
      "Going from 30 FPS to 300",
      "30fps? More like 7fps right?",
      "M.2 and a new CPU cooler next?\n\nGreat gpu upgrade!",
      "My bro rocking a 9 fans RGB setup with a stock cooler lmao.",
      "Oh shit you right",
      "This was a little before I have a 3600x and my buddy had a extra prism cooler. Yk the big one ryzen 7 have and it’s more than enough. I bought a sata m.2 instead of nvme m.2 that’s why the top slot it’s missing m.2",
      "😂",
      "The 710 is worse than modern Integrated graphics. By Intel.",
      "Bro at that point why even upgrade. The 710 is a monster\nof computing power you dont need the 3060ti",
      "Exactly that’s the problem, my power supply couldn’t keep up with my 710 gt 😂",
      "Not anymore",
      "I think the 710 is worse than my 2002 DX9 GPU.",
      "That's a hell of an upgrade!\n\nCongrats and enjoy.",
      "As someone who upgraded from a SATA SSD to an NVME SSD recently on my workstation-with-occasional-gaming rig, my observation was that games and apps loaded faster, but not dramatically faster.\n\nYou'll notice, but its not anywhere near as dramatic as the hard drive to SATA SSD conversion. Instead of like going from 30 seconds to 8, it will be more like 8 seconds to 6. Present but not overwhelming.\n\nI'd recommend it.",
      "Nah, it's not that bad, but it is very bad",
      "What pc case is that?\n\nShare full specs while you're at it, someone is gonna ask at some point anyways",
      "“This was a little before I have a 3600x and my buddy had a extra prism cooler. Yk the big one ryzen 7 have and it’s more than enough. I bought a sata m.2 instead of nvme m.2 that’s why the top slot it’s missing m.2”",
      "Totally depends if your sata is Dramless or not.  \n\n\nIf it has a proper Dram, system responsiveness will barely be different, however, pagefile and sequential read/write will be night and day.  \n\n\nIf your SSD is dramless... Even a hard drive is better, so go get a proper SSD with Dram. (in this case go straight for M.2 if your motherboard supports it)",
      "I feel this. Changed a few weeks from a 750 Ti to a 1650. Its a blessing!",
      "Real question, what are the benefits of m.2 if I already have a sata ssd? My games will load 0.1 seconds faster? Can you even tell the difference if you are an average pc user?"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "low",
    "matched_keywords": [
      "rtx 3060",
      "3060",
      "rtx 3060 ti",
      "3060 ti"
    ],
    "title": "RTX 3060 Ti Launchday Thread",
    "selftext": "# Subreddit Protocol:\n\n* **Launch Day Megathread** will serve as the hub for discussion regarding various launchday madness. [You can also join our Discord server for discussion!](https://discord.gg/nvidia)\n* Topics that should be in Megathread include:\n   * Successful order\n   * Non successful order\n   * Brick & Mortar store experience\n   * Stock Check\n   * EVGA step up discussion\n   * Any questions regarding orders and availability\n   * Any discussion about how you're mad because you didn't get one\n   * **Literally everything about the launch**\n* **ALL other standalone launch day related posts will be removed.**\n* **Subreddit may go on restricted mode for a number of times during the next 24 hours. This may last a few minutes to a few hours depending on the influx of content.**\n\n**Reference Info:**\n\n[RTX 3060 Ti Review Megathread](https://new.reddit.com/r/nvidia/comments/k4mctp/geforce_rtx_3060_ti_review_megathread/)\n\n# Remember not to buy from scalpers (fuck em). If you are buying from website that allows 3rd party sellers (e.g. Newegg/Amazon), please make sure you are buying from said retailer. Anything else means you're buying from scalpers. Do not buy from scalpers. Treat the product as out of stock and wait if the official retailers are not selling them.",
    "comments": [
      "> Lauch time, 9AM EST\n\n> Bestbuy: “No, I don’t think I will.”",
      "Bestbuy is that friend that says he'll be there soon but he hasn't even left the house",
      "at this point id find more comfort in \"out of stock\" than \"coming soon\"",
      "Getting a 30 series is like entering a giveaway but you have to pay for the item",
      "Computeruniverse.net now listing 3060tis for up to EUR 799, *plus shipping*.\n\nSeven. Hundred. And ninety-nine. \n\nI suggest everyone remember how these companies are treating their customers right now next time they whine about being replaced by giants like Amazon.",
      "My disappointment is immeasurable and my day is ruined",
      "Screw best buy. Screw Nvidia. Never in my life have I had a more miserable experience trying to give someone money.",
      "haha putting a megathread up 20 minutes after launch. Good planning!",
      "I would have rather gotten scalped in 20 seconds than sit up waiting for 3 hours just to have Best Buy tell me there's nothing available within 250 miles.",
      "I literally took a shower like I said and it’s still coming soon",
      "Yeah I had the FE in my cart like 4 times and 3 times was the location limbo, one time was an error, and then I actually had a shot of picking one up at a Best Buy like an hour from me and when I tried to get that option it got removed from the cart.  \n\n\nGlad I got to experience the feeling of having one in my cart, further than what I got for 3080/3070.",
      "Why is newegg so terrible?  Just saw one come available but you cant add to card and the product has been delisted again.",
      "why you gotta do me like that dude",
      "I think a Best Buy employee tripped on a server cord.",
      "At this point I just want best buy (US) to say sold out so I can continue about my day.  I know I will not get one anyways.",
      "fuuuuck best buy. I had a FE in my cart. get to checkout so its RESERVED for ME. best buy wont let me pick a store for pickup. It will not let me pay without picking a store for pickup. I try picking multiple stores within a 250 mile radius that are both eligible and available but keep getting multiple website errors, or messages saying that pickup dates have changed. I call customer service hoping they can somehow figure it out from me on their end while I still have one reserved. 20 min later I get someone who has no idea what I'm talking about and transfers me, 30 min later a woman answers and after giving her the rundown she says she has to transfer me to sales. on hold for an hour. All the while I'm still refreshing stores and trying to continue pickup with multiple stores eligible. won't continue. after an hour and a half the site kicks me out of checkout and its gone.",
      "I felt this, still refreshing best buy for the fe card",
      "I just want to consume product",
      "Still refreshing at Best Buy 🤡",
      "I just want a gpu i’ve been waiting for months and i refuse to use scalpers :("
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "low",
    "matched_keywords": [
      "rtx 3060",
      "3060",
      "rtx 3060ti",
      "3060ti",
      "rtx 3060ti"
    ],
    "title": "Zotac RTX 3060Ti OC or MSI RTX 3060 Gaming X?",
    "selftext": "Basically, as the title says. In my country, I can either have MSI RTX 3060 Gaming X or Zotac 3060Ti in the same price range.\n\nPlease help me decide. I've heard that MSI is a great variant whereas with Zotac, I am getting a better card.\n\nP.S: Its my first time building my PC.",
    "comments": [
      "The Ti is a performance tier higher than the non-Ti, so the Zotac 3060Ti every day!",
      "Obv the Ti. If you got the option though another brand, as they are both kinda shit.",
      "Ti\"e\"",
      "Ti",
      "Ti",
      "Ti.  Check the performance graphs, it's a no brainer.  Only possible ( not valid) counter argument could me more ram on OG 3060... but if the GPU can't pull it's weight anyway, you're not going to be running high-rez 4k textures regardless.\n\n3060ti at 400$ is the sweetspot: pretty close to the 3070; same daggerhashimotto #'s (around 60) if you're going to mine in the side.\n\nHope that is helpful!",
      "You can slightly undervolt/underclock the Zotac card to get better temps/noise and still be miles ahead of the MSI 3060",
      "Ti everytime",
      "Ti.\n\nDon't know abou Zotsc, but MSI has lost me as a customer forever (I used to have two of their cards, the 970 was great, tye 2080 Gaming X so-so).",
      "3060Ti, the only upside with the non ti is the vram",
      "Faster VRAM > More VRAM",
      "Asus is the best when u look at cooling temps and bios...",
      "Ti since it's performance is similar to 2080 super while the non-ti is just an updated 2060/2060s",
      "Performance wise, Ti is better, it's the second generation and a faster version of the regular 3060.\n\nBut as a brand, i can tell you we get A LOT more RMAs (return of a failed product) from zotac than MSI cards. We consider zotac a brand that is more likely to fail than MSI.",
      "3060 TI but not Zotac. I had a Galax RTX 3060 TI and it was a beast. Never bought MSI so ???",
      "Any 3060 Ti will be a lot faster than any 3060 non-Ti. [30% faster](https://www.youtube.com/watch?v=qQvYzBleETs&t=363s&ab_channel=Jarrod%27sTech) to be more precise.  \n\n\nNvidia really messed up this naming scheme. That mere *\"Ti\"* is pretty much a generational difference in terms of performance. For the same price, it is a no-brainer."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "low",
    "matched_keywords": [
      "rtx 3060",
      "3060",
      "3060ti"
    ],
    "title": "Asus Strix RTX 3060 or Zotac 3060ti twin oc",
    "selftext": "Please help me both the cards are on a deal for me. (Both cards are same price)",
    "comments": []
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "low",
    "matched_keywords": [
      "rtx 3060",
      "3060",
      "rtx 3060ti",
      "rtx 3060 ti",
      "3060ti",
      "3060 ti",
      "rtx 3060ti"
    ],
    "title": "RTX 3060TI FE vs EVGA RTX 3060 TI XC GAMING",
    "selftext": "Hello everyone,\n\nI have been lucky enough to be able to get 2 RTX 3060TIs, one from best buy and one from the EVGA queue. \n\nI am planning on giving one of them to a friend, but I was wondering which one I should keep for the long term. I have read that the FE is slightly quieter and has a slightly higher clock, but is this true? \n\nAny advice which one to give away and which one to keep?",
    "comments": [
      "Yeah, but when you open it there she goes smiling back at you lol.",
      "I personally love the sleekness of my 3060 TI FE but that just me.",
      "I mean ideally you'd keep the FE and your friend gets the EVGA XC in terms of warranty, since the XC's warranty is transferable and the FE's isn't iirc. Of course if you're okay with handling RMAs for your friend if needed (assuming he gets the FE) then this is a non-issue.",
      "I love the look of the FE too, but my case is enclosed and you cannot see into it",
      "hmm, that's also good advice, thanks",
      "Well to give you an example, a friend of mine as FE version of 3070, i have XC3 BLACK 3070. Pretty much the same as the FE version when it comes to clock speed, but, it does have a 3 fan setup. And i am able to OC to a point where i have about 8 to 10fps lead VS my friends FE version.",
      "From my testing my 3060ti XC is the same or very slightly ahead of the FE even with only two fans. Stressing mine tops at 66c.\n\n\nThe PCB being the same size of the XC cooler is probably a big part of it. The other 3060ti cards with longer coolers have the same PCB. They mostly reused 3070 coolers for cost reasons.\n\n\nIMO the XC is perfectly fine and is quiet. I got mine two days ago for 397.69 and couldn't be happier. Thanks EVGA notification system!\n\n\n\nI've went, in the last two weeks, from a 1080ti to a 2080 (that died Sunday sad day) to a 3060ti. Small gains in performance each time haha.\n\n\nAlso I'm probably gonna undervolt my 3060ti soon and it'll perform better than every other 3060ti at that point at stock and probably boost higher as a result.",
      "great, thanks for the answer, that puts it into perspective",
      "EVGA for better warranty.",
      "Well, if your friend doesn't want it pm me. $",
      "Do you know when you signed up for the que? Rough estimate? I wasn’t even sure if they were still fulfilling the que",
      "FE - keep, EVGA - give to your so called \"friend\"",
      "thanks, I assume they perform about the same though?",
      "I got in the queue on December 1st, 7:13 PST. The queue opened at 6:00AM PST so it seems theyve gone through the first hour of the queue in the last 2 months",
      "Any recommend guide on how to undervolt?",
      "Not from me but they exist. YouTube has them as well."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "low",
    "matched_keywords": [
      "rtx 3060",
      "3060",
      "rtx 3060 ti",
      "3060ti",
      "3060 ti"
    ],
    "title": "is this a good 3060ti card this is the name of the gpu KFA2 NVIDIA GeForce RTX 3060 Ti",
    "selftext": "",
    "comments": [
      "On the box, is this a photo of the guy who sold it to you?",
      "I would love to see where this goes lol",
      "Galaxytech and KFA2 are the same company, but they market their video cards in different world markets. They also change the brand names of the GPU hardware they sell on occasion. So, video cards with the Galaxy, Galax, and KFA2 come from the same company. If you look at the boxes for each brand, the illustrations and pictures are the same, only the brand name is different.\n\nI don't see these brands in the North American markets, but they're definitely sold in Honk Kong and Taiwan since the brands were founded in Hong Kong. I haven't seen the brands sold in the Indian Ocean region. I've seen the brands selling online, but not at retail brick and mortar stores around me.\n\nThe good news is that because the brand isn't that well known. You have a better chance of getting these video cards a lot closer to MSRP than the other competitors and the markup for being an AIB card is less than the Founder's Edition version or the competition. Unfortunately they don't sell as many as Nvidia, so, you still may have a hard time buying them.",
      "I can get it for 600 euros but i dont want it overheating constanly. Thanks for the explanation"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "low",
    "matched_keywords": [
      "rtx 3060",
      "3060",
      "rtx 3060ti",
      "3060ti",
      "rtx 3060ti"
    ],
    "title": "PSU for RTX 3060 and 3060ti?",
    "selftext": "Hey guys,\n\nIs a Corsair CV550 enough for a RTX 3060? And for a RTX 3060ti?\n\nThe CPU is a Ryzen 5 3600.\n\nThank you.",
    "comments": [
      "Yes it's perfectly fine. For reference I've run a 3070ti and Ryzen 9 3900X with a Corsair CX550M and it was fine. So you should be perfecty fine. You don't need a rx750m, contrary to what the other guy says.",
      "corsair cv shit. go rx750m for extra headroom and efficiency cos it's like 5$ more expensive than 650w"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "low",
    "matched_keywords": [
      "rtx 3060",
      "3060",
      "rtx 3060ti",
      "3060ti",
      "rtx 3060ti"
    ],
    "title": "NVIDIA GeForce RTX 3060 listed early for almost as much as RTX 3060Ti [VideoCardz.com]",
    "selftext": "",
    "comments": [
      "500 GBP is US$684 ... they can keep that 3060 non-Ti.",
      "For that price, they can also keep the Ti version as well. It's insane that we are now considering 684$ to be acceptable for a x60Ti card. Hell, it's way too much even for a 3070 as well. This thing is near 3080 MSRP price.",
      "They can keep those prices well away, I'm just glad to have lucked out and scored 60 Ti FE at actual MSRP.",
      "Is that meant to say it almost costs as much as the MSRP for the 3060 Ti, or The current street price of the 3060 Ti? Both are bullshit but the latter even more so",
      "Makes me glad I just said fuck it and bought the more than I needed 3060ti while I could. If the lower one isn't going to be 100-150 cheaper what's the point",
      "When is actual release date ?",
      "Wtf cant even buy the ti no stock anywhere"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "low",
    "matched_keywords": [
      "rtx 3060",
      "3060",
      "rtx 3060ti",
      "rtx 3060 ti",
      "3060ti",
      "3060 ti",
      "rtx 3060ti"
    ],
    "title": "EVGA RTX 3060ti XC or MSI RTX 3060 Tİ VENTUS 2X OC",
    "selftext": "Which of these two cards do you prefer and why? Does Evga RTX 3060 ti xc model have fan stop (0db) technology? (for users) thanks in advance",
    "comments": [
      "Pretty sure all GPUs have a default fan curve programmed into their firmware, but it can be easily overidden with a fan control software like MSI Afterburner or EVGA's own X1 Precision software.\n\nI have heard that by default, the XC has a 0RPM idle mode when the temperatures on the card are low enough, but since I use Afterburner to set the fan curve, they're never lower than 50% of their max speed on mine.",
      "EVGA.  I \"settled\" for an XC Gaming as they were the only ones my local Microcenter got in, and after undervolting it (.925v) it maintains a steady 1980MHz boost on the core and 8000MHz on the memory with zero issues.  Idles at around the mid to high 30's, stays around the mid-60's on load.  Fans are a little loud though, but nothing you'd notice if you're wearing headphones.",
      "EVGA - Awesome Customer Support with Step Up opportunity besides overall quality",
      "I have the EVGA and the fans dont spin up until at least 50c as far as I remember. Dont know about the MSI myself",
      "rtx 3060 ti evga xc model you mentioned, right? So do you have an auto fan?",
      "&#x200B;\n\nrtx 3060 ti evga xc model you mentioned, right?",
      "I have a fan curve set up in Afterburner for it.",
      "So there is no fan control, I understand"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "low",
    "matched_keywords": [
      "rtx 3060",
      "3060",
      "rtx 3060 ti",
      "3060ti",
      "3060 ti"
    ],
    "title": "3060 ti Hey ! So I live in France and just managed to put hands on a 3060ti for 500€ that I should receive in December. Is this a good deal ? Was it worth it ? The model I got was the GIGABYTE EAGLE OC RTX 3060 ti",
    "selftext": "",
    "comments": [
      "For the same has the 3070 is not a good deal at all, to anyone if you can wait till the supplies normalize I would advice to wait.\n\nIf you can game on your current gpu there is no need to spend 3070 money to have less performance but this is my opinion of course",
      "then in that case yes buy that gpu",
      "Yes I know but components are overpriced here and the 3070 cost like 650€+",
      "can you play with the one you have now? till the things get to normal",
      "Nah I’m building my pc and am trying to have it built by Christmas"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "low",
    "matched_keywords": [
      "rtx 3060",
      "3060",
      "rtx 3060ti",
      "3060ti",
      "rtx 3060ti"
    ],
    "title": "RTX 3060Ti VS RTX 3060 VS RTX 2060S VS RTX 2060 | Gaming Benchmark Review |",
    "selftext": "",
    "comments": [
      "2060S is still a great card IMO."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "low",
    "matched_keywords": [
      "rtx 3060",
      "3060",
      "rtx 3060ti",
      "3060ti",
      "rtx 3060ti"
    ],
    "title": "RTX 3060Ti VS RTX 3060 VS RTX 2060S VS RTX 2060 | Gaming Benchmark Review |",
    "selftext": "",
    "comments": []
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "low",
    "matched_keywords": [
      "rtx 3060",
      "3060",
      "rtx 3060ti",
      "3060ti",
      "rtx 3060ti"
    ],
    "title": "RTX 3060Ti VS RTX 3060 VS RTX 2060S VS RTX 2060 | Gaming Benchmark Review |",
    "selftext": "",
    "comments": []
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "low",
    "matched_keywords": [
      "rtx 3060",
      "3060",
      "rtx 3060ti",
      "3060ti",
      "rtx 3060ti"
    ],
    "title": "RTX 3060Ti VS RTX 3060 VS RTX 2060S VS RTX 2060 | Gaming Benchmark Review |",
    "selftext": "",
    "comments": []
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "low",
    "matched_keywords": [
      "rtx 3060",
      "3060",
      "rtx 3060 ti",
      "3060 ti"
    ],
    "title": "NVIDIA official GeForce RTX 3060 Ti performance leaked - VideoCardz.com",
    "selftext": "",
    "comments": [
      "Looks pretty impressive. Still, an x60 tier card at ~$400 is also pretty expensive.",
      "So $399 then :)",
      "If its really 400$ or less, then i'll be one happy motherfucker.",
      "> Now, I can safely go for a 3060 Ti. \n\n\\*next summer if lucky",
      "Damn, thanks CD Red Projekt\n\nI was hoping to replace my GTX 1060 for Cyberpunk because I'm playing on 1440p now and want to go with RTX on too.\n\nIf Cyberpunk was released this spring, pretty sure I would have been forced to take a 2060 this summer.\n\nNow, I can safely go for a 3060 Ti.",
      "Yes.",
      "Sold out everywhere for the next 365 days.",
      "#*Laughs in 3090*",
      "Seeing it like that, it's really more worth to get a 3060Ti lol",
      "So it's right between the 2080S and 2080 Ti, about 5-10% behind the 3070.",
      "Just in time for the CP2077 release then!",
      "At these prices, most people are better off getting the new consoles. \n\nAlso upgrades are going to be much further apart. This only makes sense if Nvidia thinks the average cycle is now going to be 4+ years, with generational improvements dropping to CPU levels, with each release every year or two but most people skipping several gens between upgrades.\n\nAnd if that's really the case, it's only a matter of time until Intel figures out how to get competitive iGPUs, possibly with larger surface area as a result. if you can go 4-5+ years between builds you might as well do everything at once, and that means it can be combined for engineering efficiency.",
      ">what's the purpose of the 3070 now?\n\n5-10% more performance.",
      "But everyone complained about the 20 series pricing so maybe not the best example?",
      "Can't wait to not get one on launch day! /s\n\nOn the bright side, if bots are distracted on the 3060 maybe a 3080 or two will slip through the cracks for non-bot customers.  3070 is in an awkward spot, depending on 3060TI pricing.  This is almost like comparing 1660 Super to RTX 2060: performance gap isn't that big and the 1660 feels like better value.\n\nAnother take, this might make it easier to get a 3070 if people \"give up\" on getting one if the performance gap is small.  Still, the 3070 is a very good card and i'd love to have one right now, or a 3080.",
      "I cringe at every time I see this comment. Inflation is more than just money in circulation. Due to the pandemic the velocity of money has shrank dramatically. Inflation in the last 8 months is at an almost 4 year low because our economy is on life support. It's actually still below the traditional 2% annual inflation target.  \n\n\nThe original 2070 released at...guess what, $500. So that makes the current MSRP of the 3070 actual lower than the $500 when inflation is taken into consideration.  \n\n\nThe 2080 was $800 at launch. The 3080 is $100 cheaper.  \n\n\nAre we in a period of deflation or did the pandemic hit in 2018?",
      "Well, 3070 doesn't look as good value now!",
      "3060 for $250 (which performs between 2080 and 2080S) and 3060Ti  for $350(which performs between 2080S and 2080Ti), my dream lol",
      "Seems more like 10-20%.\n\n[https://www.techpowerup.com/review/nvidia-geforce-rtx-2080-super-founders-edition/27.html](https://www.techpowerup.com/review/nvidia-geforce-rtx-2080-super-founders-edition/27.html)\n\nThat puts this card very close to the 3070.",
      "yea... 5-10%... like... what's the purpose of the 3070 now? It's 100 USD difference ...."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "low",
    "matched_keywords": [
      "3060"
    ],
    "title": "Coming from a 2060 - is the 3060 12 GB or the 4060 a better upgrade?",
    "selftext": "It's not urgent or anything but I'm thinking about an upgrade. At the moment I have an RTX 2060, which is fine, but it's been a decent while and I'm thinking about an upgrade. I see a lot of bad press about the 4060, saying its not worth it, but every test I've seen shows it outperforming the 3060, even the 12 gb model. Granted, its not too big of an improvement but I digress.\n\nI also do a lot of video editing and motion graphics, besides gaming. \n\nDo y'all think the 3060 12 gb, or the 4060 is a better upgrade? At the moment they're only a $50 difference, the 3060 being $250 ish and the 4060 being $300.",
    "comments": [
      "This sub is damned, OP asks a super simple question. Option A or option B and if so why? And then people still say \"forget A & B, get C wich is just $250 more expensive\"",
      "4060 for frame gen",
      "Do you have a moment to talk about our savior AMD Radeon 6700 XT?",
      "Don't listen to people who don't know how the architecture between series of gpu's work, doesn't matter if the 4060 has 8gb, it outperforms the 3060, if you want you could get the 4060 ti, but the 4060 is amazing, it also depends on the rest of the set up you have, the least cpu I'd pair with it is a 11700 or 12400, good luck!",
      "This is the answer, OP: even bad frame-gen is pretty great, but if you can run a game >45fps it’s a fucking black magic spell that doubles your frame-rate and makes you more attractive and intelligent in real-time while running.",
      "This sub is damned, OP asks a super simple question. Option A or option B and if so why? And then people still say \"forget A & B, get C wich is just $250 more expensive\"",
      "no youre so right barely anyone is giving me a straight answer, i really only need one or the other",
      "I honestly don’t think the 4gb of vram makes a difference for the 1080p resolution these cards are intended for. The 4060 has the advantage of having one of the lowest TDPs seen in recent memory. If it matters to you it uses 115w vs 170w. Which should also translate to lower heat output. I think I’ve read somewhere that the 4000 series has some sort of improvements for creative work but it was irrelevant to me so it didn’t stick. You could look into any performance differences in the applications you use.",
      "lmaoo real",
      "Agreed 4060 is the way to go here.",
      "The 4060. If you're gaming at 1080p your don't need 12 GB of vRAM. You're just never going to use them.\n\nThe 4060 is faster, has newer features such as frame generation and is more power efficient so it runs very cool.\n\nIf you do machine learning or stimulation calculations that are GPU accelerated then maybe the 3060 would be better. Otherwise, the 4060 is objectively the better card.",
      "Thing that screws the 4060 up is the 128 bit bus width.\n\nNvidia screwed up on the 40 series. \n\n4070 series above is the only reasonable ones my opinion.\n\nOverwise look at AMD. Truth is I hate asking people to go AMD because they fanboys think they the good guy but the truth is they both shit in the same basket.",
      "If you have $300-ish 6700xt I'd take that in a heartbeat.\n\nBetween those 2 it's kind of a toss-up. If you need the vram get the 3060. Otherwise I'd say the 4060. But then again the 6700xt is a better buy at roughly the same price as the 4060",
      "Just get a 4090",
      "These comments help me as I also have a 2060, thank you OP",
      "Ye bro needs to just get the 4070ti and call it a day.",
      "I've got a r5 3600, and a b450 tomahawk max mobo, does that change anything?",
      "I'd say 4080, but maybe he could stretch a little bit and go for the 4090",
      "1000000% - 4060",
      "3060 is not much better than 2060 (15-20%) aside from double the memory. If you cant get above $300 then get the 4060, also not much faster than 3060 but it adds up. Personally id save up for the cheapest 4070 i can get, or find secondhand 3080/ti."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "low",
    "matched_keywords": [
      "rtx 3060",
      "3060",
      "rtx 3060 ti",
      "3060 ti"
    ],
    "title": "GeForce RTX 3060 Ti Review Megathread",
    "selftext": "# GeForce RTX 3060 Ti reviews are up.\n\n[Image Link - GeForce RTX 3060 Ti Founders Edition](https://preview.redd.it/mnc7yfus6l261.jpg?width=3840&format=pjpg&auto=webp&s=d85827250b78acf27e7db7ff8419406e63355b13)\n\n# Reminder: Do NOT buy from 3rd Party Marketplace Seller on Ebay/Amazon/Newegg (unless you want to pay more). Assume all the 3rd party sellers are scalping. If it's not being sold by the actual retailer (e.g. Amazon selling on Amazon.com or Newegg selling on Newegg.com) then you should treat the product as sold out and wait.\n\n# Below is the compilation of all the reviews that have been posted so far. I will be updating this continuously throughout the day with the conclusion of each publications and any new review links. This will be sorted alphabetically.\n\n# Written Articles\n\n# Anandtech - TBD\n\n# [Arstechnica](https://arstechnica.com/gaming/2020/12/nvidia-announces-the-399-rtx-3060-ti-and-weve-tested-it/)\n\n>Otherwise, there's not a ton to say about RTX 3060 Ti that hasn't been spelled out with its costlier siblings. DLSS still impresses as a proprietary upsampling and anti-aliasing system, and that, combined with solid ray-tracing tech, continues to make Nvidia cards a tantalizing option—especially when clock speeds and CUDA cores have been reduced to hit the $399 sweet spot while still otherwise looking quite performative.  \n>  \n>Meanwhile, if your favorite games don't tap into DLSS, you should expect to tinker with their settings to maximize their 1440p or 1080p performance levels—and I can't help but imagine AMD has a response to this exact use case with any future lower-priced RX 6000-series GPUs. But nothing of the sort has been announced yet, so for the time being, Nvidia takes the lead at this price point.\n\n# Babeltechreviews - TBD\n\n# [Digital Foundry Article](https://www.eurogamer.net/articles/digitalfoundry-2020-nvidia-geforce-rtx-3060-ti-review)\n\n# [Digital Foundry Video](https://www.youtube.com/watch?v=JfASASNLgIk)\n\n>Across the bulk of our testing, the RTX 3060 Ti has shown itself to be a solid value, often delivering nearly 90 per cent of the performance of the RTX 3070 while costing closer to 85 per cent of the price. In most games, the 3060 Ti manages to hold a clear advantage over the RTX 2080 Super, a card that costs £320 more and came out just last summer, underlining the impressive boost Nvidia has been able to find this generation.  \n>  \n>In more modern games, especially those that use RT effects, the 3060 Ti is even better still. It's a particular blow against AMD, with the 3060 Ti out-muscling the significantly more expensive RX 6800 XT in most of the RT game scenes we tested. The 3060 Ti is also among the most power-efficient cards we've found so far, although the 3070 and RX 6800 were able to deliver a superior 'joules per frame' measurement in one of the two games we used for judging this. Clearly, the Ampere architecture is as competitive in the mid-range as it is at the very top.  \n>  \n>But perhaps the best argument to be made for the RTX 3060 Ti comes in its performance differentials against the 10-series Pascal cards, where you're often getting 80 to 90 per cent more performance than the venerable GTX 1070, with even GTX 1080 Ti often humbled by the output of the new card. While RTX 3060 Ti will work best at 1440p resolution, the fact is that 1080 Ti still runs a wide range of games well at 4K resolution - where 3060 Ti will do considerably better, even before we factor in the inclusion of DLSS. We're *really* looking forward to testing this with Cyberpunk 2077.\n\n# [Guru3D](https://www.guru3d.com/articles-pages/geforce-rtx-3060-ti-founder-edition-review,1.html)\n\n>Gosh, I think I spoiled it all in the very first paragraphs of this conclusion page; the market needs cheaper cards that can easily beat the new consoles at performance and price for PC gaming to keep making sense. The GeForce RTX 3060 Ti is a bit of an inbetweener. I think it performs extremely well, but realistically graphics cards in the sub 500 USD range are all 100 USD too expensive. How cool would this product have been at 299 USD? See what I am getting at? I know, I know .. wishful thinking.  \n>  \n>Performance-wise we cannot complain; it is RTX 2080 SUPER and even 2080 Ti territory that this card is tackling. An ongoing trend with all new technologies, of course, is an increase in graphics memory, or better yet, growing demand and thirst for it. Up-to 2560x1440, really, you're good to go with 8GB for now. In Ultra HD, you'll quickly run out of VRAM in the future and thus stamina as frames bounce back and forth due to the lack of it. Overall this is a solid performing product that will please the masses. You'll get excellent framerates in the aforementioned resolutions with bitter-sweet eye-candy at the best quality setting. It's also a graphics card that allows you to fool around and twiddle a bit with Hybrid raytracing.   \n>  \n>On DX-R, we stopped testing games that are marked with Raytracing that only do shadows. It's a waste of performance as the rasterizer engine is simple by far good enough. Games with raytraced reflections, that's what you should be after, and that's what we''ll call a properly raytraced game. For this card, DXR in Full DH is a good option, and you can get a nice buddy assist when the game also supports DLSS v2.0.  \n>  \n>The GeForce RTX 3060 Ti overall performs well on all fronts, performance, cooling acoustics, and yeah, the new founder edition cards look sweet as well. The big question will remain to be availability. NVIDIA\" biggest challenge for weeks now. DO NOT even dare to buy these products even 20 bucks over reference prices at etailers. Purchase it when prices are FAIR. It's the only way scalpers and greedy etailers will learn and understand, bring back respect to what allows them to keep running their businesses, you guys .. the customers should come first. The last line (I promise) would have loved to see this card being 299 USD for it to be a hit. But even at its current pricing, it's a product we can certainly recommend.\n\n# [Hexus](https://hexus.net/tech/reviews/graphics/147016-nvidia-geforce-rtx-3060-ti-founders-edition/)\n\n>Nvidia extends the reach of its gaming Ampere architecture by releasing the best value model yet. GeForce RTX 3060 Ti takes much of the '70's goodness and distils it down to a £369 price point. Still not cheap, of course, but there's enough horsepower under the attractive hood to play the latest games at excellent framerates at a QHD resolution and also make a decent attempt at rendering 4K visuals with acceptable performance.  \n>  \n>Crucial to Nvidia's ambitions with this GPU is that rival AMD presently has nothing new to counter it. RTX 3060 Ti is comfortably faster than last-gen RX 5700 XT and crushes even the latest Big Navi cards once ray tracing and DLSS are turned on.  \n>  \n>The Founders Edition is barely discernible in a quiet chassis when full-on gaming, so Nvidia has set the bar very high for AIC partners building their own cards, presumably with a hefty price premium attached to them.  \n>  \n>We come away impressed with the GeForce RTX 3060 Ti FE 8GB card because the gaming performance is more than adequate for 90 per cent of gamers out there. Building a £1,000-£1,500 base unit or upgrading from much older graphics and want to play with all the eye candy turned on at decent resolutions? It's hard to look past this card, and FE in particular, so we hope there is enough stock to sate what is sure to be significant demand.\n\n# [Hot Hardware](https://hothardware.com/reviews/nvidia-geforce-rtx-3060-ti-gpu-review)\n\n>GeForce RTX 3060 Ti cards are slated to start shipping tomorrow. The NVIDIA Founders Edition card has an MSRP of $399 and overclocked partner boards like the [MSI GeForce RTX 3060 Ti Gaming X Trio](https://amzn.to/2KWqRhH) will obviously be priced higher (usually by about $20 - $60), depending on the level of customization, additional features, and how high the GPU clock is, etc. GeForce RTX 3060 Ti Founders Edition cards will be available directly from Best Buy and Microcenter, and partner boards will be sold by all of the usual suspects, though product is likely to disappear quickly, as has been the case with all of the recent GPU launches.  \n>  \n>Assuming customers can get their hands on cards at or near MSRP, the GeForce RTX 3060 Ti is an excellent option. Performance is in the neighborhood of the GeForce RTX 2080 Super, and well ahead of cards like the Radeon RX 5700 XT or RTX 2060 Super, all of which are currently selling for much more than the 3060 Ti’s MSRP. This card's 8GB frame buffer may give some of you pause, but for 1080p – 1440p gaming, it shouldn’t be a problem for the overwhelming majority of titles, and it’s par for the course in this price bracket anyway.  \n>  \n>We’ll have to wait until the current craziness ends to see where pricing on previous-gen cards ultimately settles, but if you’re looking for a GPU in the $400-ish price range, the GeForce RTX 3060 Ti is the obvious choice. It offers performance in-line with more expensive cards, arrives at the same MSRP as the GeForce RTX 2060 Super, and its feature set it second to none.\n\n# [Igor's Lab](https://www.igorslab.de/en/nvidia-geforce-rtx-3060-ti-ampere-fatter-far-far-far-away-and-point-on-quiet-path-from-this-claw/)\n\n>In general, the GeForce RTX 3060 Ti is successful all around, because it is faster than a GeForce RTX 2080 Super, costs significantly less than its counterpart at that time and has become significantly more efficient. For a final assessment, including that of the market positioning, one will, however, have to wait for the launch of the new Radeon RX 6700 XT. I already wrote that NVIDIA’s feature set ranges from the usual RTX components such as raytracing and DLSS 2.0, to various RTX software (video, voice) for the end user, to the entire studio and workstation applications.  \n>  \n>Especially in the semi-professional areas AMD is currently rather at a disadvantage and you will have to wait and see what will be launched in the future besides the new hardware. So everyone will have to set their own premises and ask themselves what value which feature and use case really has (or not) for them. A review can’t take this decision away from anyone, it’s up to each person to decide for themselves. I repeat myself, also with regard to the text on the RTX 3070? The cards are so similar in their orientation that you can hardly think of anything else.  \n>  \n>The MSRP of EUR 399 is certainly an incentive, but there is initial information on board partner cards that they are likely to be considerably more expensive. A circulated MSRP of 470 or 500 USD for cards from MSI or Asus is a somewhat harder announcement, unfortunately. In principle, however, it would also straighten the FE loosely, because it has no faults. If it should really be available. I prefer not to make any predictions.\n\n# [KitGuru Article](https://www.kitguru.net/components/graphic-cards/dominic-moass/nvidia-rtx-3060-ti-founders-edition-review/)\n\n# [KitGuru Video](https://www.youtube.com/watch?v=3lmPLt2vO2k&feature=youtu.be)\n\n>The **Nvidia RTX 3060 Ti** is the latest in a long line of GPUs to have launched over the past couple of months, but importantly it is the cheapest of those, with a UK MSRP coming in at £369. Availability aside, the RTX 3060 Ti is an important step in getting the Ampere architecture to the wider market.  \n>  \n>Despite the lower price tag, Nvidia claimed the RTX 3060 Ti is faster than the RTX 2080 Super, which launched for £669 in July 2019. Based on our testing today, that claim does hold true. Averaged over the 14 games we benchmarked, at 1080p the RTX 3060 Ti is 2% faster than the RTX 2080 Super, and that increases to 3% at 1440p. At most, the RTX 3060 Ti was 8% faster, and it came in 5% slower at worst. It’s clearly not a big difference at all, and generally we’d call that level of performance a tie. Of those fourteen games we tested though, the RTX 3060 Ti is only slower in three of them.  \n>  \n>That means this new Ampere GPU is on average 34% faster than the RTX 2060 Super at 1080p, and 39% faster at 1440p. It even looks relatively good against the RTX 3070, as it is just 11% and 12% slower on average, at 1080p and 1440p respectively – not bad considering it is also £100 cheaper.  \n>  \n>It really is a very capable GPU for high refresh-rate 1080p or 1440p gaming, delivering solid frame rates across the board at either resolution. In fact, at 1440p, the lowest average frame rate we saw with the 3060 Ti was exactly 60FPS, and that came when playing Red Dead Redemption 2 at ultra settings, which is about as demanding as it gets.  \n>  \n>We also tested 4K, but I wouldn’t focus too much on this aspect of the card’s performance. Just like the RTX 2080 Super, it certainly can play at 4K, hitting 60-70FPS in less demanding titles like Death Stranding or F1 2020. Anything that will stress the GPU more – something like Control, Gears 5 or the aforementioned Red Dead Redemption 2 – sees the frame rate drop down into the 30FPS. For me, this is a quality 1440p 60FPS+ GPU, so while it can do 4K *sometimes*, for a proper 4K experience you’d need to step up to at least the RTX 3070, but ideally the RTX 3080.\n\n# [Legit Reviews](https://www.legitreviews.com/nvidia-geforce-rtx-3060-ti-founders-edition-review_224067)\n\n>The performance of the GeForce RTX 3060 Ti Founders Edition was impressive. It bested the NVIDIA GeForce RTX 2080 Founders Edition ($799) from 2018 in everything and traded blows with the NVIDIA GeForce RTX 2080 Super ($699) from 2019. It ripped through the 1080P game titles with ease and shows that it was a very capable at 1440P game titles as well. 4K gaming performance was solid for this price point with its 8GB of GDDR6 memory, but the GeForce RTX 3080 and RTX 3090 are still the best choice for those gamers looking to run at 4K or beyond.  \n>  \n>Power consumption, noise levels and thermal performance of the GeForce RTX 3060 Ti was exceptional. We never broke 70C while gaming on our open air test platform and couldn’t hear the GPU cooler fans running over our AIO liquid cooler and other fans that were running. There as no choke noise and the power numbers were good with the card using at most 235 Watts on our 3DMark Time Spy run.  \n>  \n>The NVIDIA GeForce RTX 3060 Ti appears to be a solid upgrade option for those that are wanting a performance boost at the $399 price point. AMD doesn’t have a new Radeon RX 6000 series card to compete against at this price, so NVIDIA’s GeForce RTX 3060 Ti is easily the card to get.\n\n# [OC3D Article](https://www.overclock3d.net/reviews/gpu_displays/nvidia_rtx_3060_ti_founders_edition_review/1)\n\n# [OC3D Video](https://www.youtube.com/watch?v=Y2_bhg13Eu0)\n\n>There is no doubt that when it comes to looking at purchasing a new GPU it is, for all but the very luckiest ones amongst you, a balance between the performance you desire and the performance you can achieve. Yes we'd all love the insanity and futureproofing that a RTX 3090 brings to the party, but few amongst us have remotely got the financial clout to have one. Especially after this year which has been trying to say the least.  \n>  \n>The RTX 3060 Ti has a whole different cast of comparisons depending largely upon the graphics card you currently have in your system, the graphics card that Nvidia claim it is comparable to, and of course the price point it launches at. Some of these are much easier to cover with blanket statements than others. If you've got any card that was released before the Turing Nvidia ones, GTX 1080 Ti or below, then the RTX 3060 Ti will blow you away with its performance. To say it would be an upgrade compared to those cards is to very much under value how much of an upgrade it would be. It'll stun you with how quickly the performance possibility has moved on and how affordable that level of ability is now, certainly compared to how much it would have cost to upgrade from a Maxwell to a Turing card.  \n>  \n>If you've got a RTX 2060 or RTX then it will still be a decent improvement if you're just looking to get a little more out of your system without breaking the bank. Once you reach RTX 2080 territory though, in either vanilla, Super, or Ti forms, then things get a little trickier. You've already spent a considerable wedge on those cards, and the RTX 3060 Ti wouldn't give you enough of an upgrade to justify the outlay.  \n>  \n>Looking at the RTX 3060 Ti in a vacuum the performance is consistently good throughout all of our testing. Certainly at the super popular 1080 or 1440 resolutions it really gets the job done and is smooth no matter what we threw at it, either AAA games or older but still visually lovely games, with everything cranked to the stops. At 4K it's not so amazing but then it's not really aimed at 4K gaming, even though you could get away with some careful setting tweaking to bring the frame rate up. It is also close enough, ish, to the RTX 3070 that if your budget is extremely tight then you'll expect to have to make some settings adjustments to give you the smoothest game play. Very few of us have ever had the system to be able to just stick everything on full and play.  \n>  \n>The RTX 3060 Ti FE requires you to change fewer settings than ever before to get buttery smooth game play in any title around, and we think that is the biggest string to its bow. It's a sub £400 card that acts like a card costing twice the price just a generation ago. If your budget is strict then you can't get more gaming prowess for your money, bang for buck if you like, from anything else around. At this price it makes them a whole lot more accessible - lets hope they actually have enough stock they don't all sell out in 10 minutes again.\n\n# [PC Perspective](https://pcper.com/2020/12/nvidia-geforce-rtx-3060-ti-founders-edition-review/)\n\n>As promised, this review was pretty short. NVIDIA’s GeForce RTX 3060 Ti launches tomorrow (December 2) for $399, and considering the performance (better than an RTX 2080) we saw here – which marks quite a substantial upgrade over the RTX 2060 Super it replaces at this price point – the RTX 3060 Ti is a fantastic choice in the fantasy world in which it would be widely available at launch.  \n>  \n>Once again, this is a launch review. We haven’t seen availability yet. The Founders Edition we looked at will be sold exclusively through NVIDIA.com and Microcenter here in the USA, which means sales at the $399 list price – when the card is in stock.  \n>  \n>So, assuming you can find one, I think it’s easy to recommend this new GPU – particularly as AMD does not currently offer a 6000 Series product to compete at this price level.\n\n# [PC World](https://www.pcworld.com/article/3599092/nvidia-geforce-rtx-3060-ti-founders-edition-review.html)\n\n>At $400, the GeForce RTX 3060 Ti immediately kills any remaining value proposition for comparable last-gen graphics cards like the Radeon RX 5700, 5700 XT, GeForce RTX 2060, and 2060 Super, unless you score one at a massive discount. Don’t count on seeing those discounts in today’s economy, though. Rather than splurging on older tech at this point, be patient and wait to get your hands on this GPU.  \n>  \n>Nvidia’s unorthodox RTX 30-series Founders Edition cooling continues to impress, though less so the further we move down the stack. The GeForce RTX 3060 Ti FE’s 72-degree Celsius temperatures and soft, but audible noise levels don’t disappoint, especially for a card made by Nvidia itself, but there is room for partner cards from EVGA, Asus and others to improve things. (Stay tuned for many custom RTX 3060 Ti reviews in the coming days—we’ve already got several in our hands.) We still dislike the proprietary 12-pin power connector that Nvidia used with its Founders Edition cards this generation to squeeze in a smaller PCB. The company includes an adapter in the box, but that adapter is too short and looks chunky and ugly compared to nicer traditional cabling options.  \n>  \n>Don’t let that dissuade you, though. Performance this fast cost twice as much last generation and landed near the top of the RTX 20-series stack. Getting this much eye candy for $400 is *very* welcome indeed. The GeForce RTX 3060 Ti is spectacular—a virtually flawless 1440p GPU, minor Founders Edition design squabbles aside. Here’s hoping stocks are plentiful and custom variants aren’t priced as extravagantly as the higher-up RTX 30-series options, because this GPU should sell like hotcakes.\n\n# TechGage - TBD\n\n# [Techpowerup](https://www.techpowerup.com/review/nvidia-geforce-rtx-3060-ti-founders-edition/)\n\n>With the GeForce RTX 3060 Ti, NVIDIA is finally pushing Ampere below the $500 price point, which makes it attractive to an even larger audience of gamers. The new RTX 3060 Ti is based on the same GA104 graphics processor as the RTX 3070, just with some rendering units disabled. The RTX 3060 Ti is targeted at definite 1440p gaming with 60 FPS and entry-level 4K at lower details or with DLSS enabled. Raytracing is a core focus of NVIDIA's Ampere lineup, too. The RTX 3060 Ti will offer a great RT experience at 1080p and 1440p in most titles.  \n>  \n>NVIDIA is positioning the GeForce RTX 3060 Ti Founders Edition at $399, which is an extremely competitive price. At that price point, it offers price/performance comparable to the GTX 1660 Super, which has the best price/performance ratio of all NVIDIA offerings. It would also be a better deal than the Radeon RX 5600 XT. If you can find an RTX 3060 Ti at $400, then definitely go for it. I'm having my doubts, though. Looking at recent launches from both AMD and NVIDIA, it seems the MSRP price points are a fantasy true for only the first batch, there to impress potential customers, with actual retail pricing ending up much higher. Looking at the other RTX 3060 Ti reviews today, we had a hard time getting price points out of many manufacturers, and what we got was substantially higher than $400, with the ASUS STRIX at $500, MSI Gaming X at $470, and Palit at $440+. From vendors, I heard that \"the supply should be pretty good,\" but that \"it also might not be enough for more than a few hours\" or that \"we might see $500 soon,\" so let's wait a few days and hope people will actually be able to buy this fantastic graphics card at reasonable pricing.\n\n# Techspot - TBD\n\n# [The FPS Review](https://www.thefpsreview.com/2020/12/01/nvidia-geforce-rtx-3060-ti-founders-edition-review/)\n\n>We think the new GeForce RTX 3060 Ti is exciting for several reasons.  At its $399 price point, it is reachable to more gamers.  According to our testing, it can provide up to 50% better performance compared to the previous generation GeForce RTX 2060 SUPER at $399.  For the same price, that’s a nice upgrade only one year after the RTX 2060 SUPER launched.  It also provides an upgrade path from people on Radeon RX 5700’s or Radeon RX 5700 XT’s.  If you have a Radeon RX 5700 series GPU this one will give you a 30-40% upgrade in performance.   \n>  \n>It is also exciting because here is a $399 video card matching and beating a $699 GeForce RTX 2080 SUPER, and it’s doing it with less power usage.  The performance per Watt and efficiency have been improved.  You are getting more, for less, and that’s exciting.   \n>  \n>We think the GeForce RTX 3060 Ti is going to be “the” card for a lot of people.  Not just for gamers, but also for streamers and creators.  We truly think that this is the perfect card for streamers using NVIDIA Broadcast.  It’s at an attractive price point and with its machine learning and AI capability with Tensor Cores is a powerful streaming card.   \n>  \n>A streamer may not need the fastest gaming card there is, but still the ability for esports gaming performance and such.  This would be the perfect card for that, not too expensive, plenty fast for the types of games streamers stream, NVIDIA Reflex support, and the flexibility of NVIDIA Broadcast.  We just see this card being popular among that group. For gamers, it’s also a good card.  If you aren’t a 4K gamer, you still game at 1440p or 1080p this is the card you are probably eyeing the most, and rightly so.   \n>  \n>At the end of the day, NVIDIA hit the mark on this video card, it’s very exciting.  It still gives you 8GB of RAM, not that 6GB nonsense, and will give you a great gameplay experience with useable Ray Tracing and DLSS.  The only problem is the supply of GPUs lately, but that’s an issue shared by everyone due to world issues.  We just have to get through this period of time, eventually, the cards will be available and out there in quantity.  Therefore we can review them now for you, so you know if it’s good when they become available. When they are, you owe it to yourself to give this one a look.\n\n# [Tomshardware](https://www.tomshardware.com/news/nvidia-geforce-rtx-3060-ti-founders-edition-review)\n\n>Now that we've seen the RTX 3070 along with AMD's RX 6800, we have a better feel for the GPU market we're likely to see during the coming year. AMD doesn't have a viable alternative to the GeForce RTX 3060 Ti at the $400 price point yet, so for now, this is the undisputed upper mainstream champion. Some might say $400 isn't really a mainstream GPU, but given the sales of previous-gen GTX 1070 and RTX 2060 / 2060 Super cards, there are clearly plenty of people willing to spend that much money on a graphics card. And to be clear, this is a great card for that price.  \n>  \n>The RTX 3060 Ti is about 35-40 percent faster than the previous-gen 2060 Super and about 30 percent faster than AMD's RX 5700 XT — and that's without even getting into ray tracing or DLSS support. In ray tracing games, the 3060 Ti lead grows to 40-45 percent over the 2060 Super, and AMD's RX 5000 series doesn't even have the option to try and run DXR games. Even against AMD's new RX 6800, though, the RTX 3060 Ti delivers better overall DXR performance — and can improve by around 30 percent on average for games that support DLSS, using DLSS Quality mode  \n>  \n>If you already have an RTX 2080 Super or even a 2060 Super, there's not much need to upgrade to an RTX 3060 Ti. But if you purchased a GTX 1070 back in 2016 and you're still sitting on it today, you can now double your GPU performance for roughly the same price that the GTX 1070 launched at. Again, assuming you can find one in stock. As for AMD, an RX 6700 XT could be a formidable opponent, particularly in games that don't use ray tracing or DLSS. How long will we have to wait for those cards to arrive, and will AMD ship as many GPUs as Nvidia? After the RX 6800 launch, we're guessing the answer to the second part of that question is no, but we'll probably find out more in early 2021.  \n>  \n>Right now, Nvidia just gave a nice boost in performance and features to the $400 market. The GeForce RTX 3060 Ti is a relatively small step down from the RTX 3070, with a larger step down in price. That hits the sweet spot in both price and performance — in fact, out of the current and previous-gen GPUs, it's the best overall card in price to performance ratio (fps per dollar). If you're hoping to upgrade to a new graphics card, the RTX 3060 Ti definitely belongs on your shortlist.\n\n# [Computerbase - German](https://www.computerbase.de/2020-12/nvidia-geforce-rtx-3060-ti-asus-msi-test/)\n\n# [HardwareLuxx - German](https://www.hardwareluxx.de/index.php/artikel/hardware/grafikkarten/54788-viermal-geforce-rtx-3060-ti-inklusive-founders-edition-im-test.html)\n\n# [PCGH - German](https://www.pcgameshardware.de/Geforce-RTX-3060-Ti-Grafikkarte-276807/Tests/vs-3070-vs-2070-Super-Benchmark-Release-Review-Preis-1362666/)\n\n# [PCMR Latino America - Spanish](https://www.pcmrace.com/2020/12/01/nvidia-geforce-rtx-3060-ti-founders-edition-review/)\n\n# Video Review\n\n# [2kliksphillip](https://www.youtube.com/watch?v=dYZ8HPD2xdI)\n\n# [Bitwit](https://www.youtube.com/watch?v=e7EHYqeyiXU)\n\n# [Digital Foundry Video](https://www.youtube.com/watch?v=JfASASNLgIk)\n\n# [Gamers Nexus Video](https://www.youtube.com/watch?v=t9H2PfYDFok)\n\n# [Hardware Canucks](https://www.youtube.com/watch?v=hpXxzzLOw00)\n\n# [Hardware Unboxed](https://www.youtube.com/watch?v=Owrk_OnaPJo)\n\n# [JayzTwoCents](https://www.youtube.com/watch?v=EjF2w8MVjLA)\n\n# [KitGuru Video](https://www.youtube.com/watch?v=3lmPLt2vO2k)\n\n# [Linus Tech Tips](https://www.youtube.com/watch?v=oGyWz866AoM)\n\n# [OC3D](https://www.youtube.com/watch?v=Y2_bhg13Eu0)\n\n# [Optimum Tech](https://www.youtube.com/watch?v=fjg9Cgl8zWQ)\n\n# [Paul's Hardware](https://www.youtube.com/watch?v=tduvVvsx0Xk)\n\n# [Tech Yes City](https://www.youtube.com/watch?v=GFuHVyypnFs)\n\n# The Tech Chap - TBD\n\n# [Techtesters](https://www.youtube.com/watch?v=lkJ_9u5CYvg)",
    "comments": [
      "Having just weathered the 6800/XT launch, it feels weird to have reviews available ahead of launch like this. This is how a company proceeds when they're confident in a product.",
      "I believe all Ampere cards except 3090 have pre-launchday review.",
      "Wow guru3d actually commented on the pricing situation, I hope this makes more people aware that these cards should be $300 again to make it competitive with consoles. It’s good value compared to 3070 absolutely but it’s still too expensive for budget minded pc gamers. We need a lot more cards in the <=$300 space. This is especially important for those living outside of USA where prices are even more ridiculous ($600 in Canada, same price as series x).",
      "EVGA queue\n\nhttps://www.evga.com/products/product.aspx?pn=08G-P5-3667-KR",
      "Seems like a great card and it seems like the RTX3050Ti/60 will be similarly great products but... I don't know how I'm gonna keep up with the price level increase. This MSRP with AIBs and EUR conversions will be easily above 500 when it hits my retailers. And then I'm optimistic to say stock levels won't be a problem in a few months. And exchange rates in my country are dogshit, with 500 eur prices this card is gonna cost 200k HUF. That's insane. An entire PS5/XSX is cheaper than that.\n\nAnd this is the 60 line, the supposedly mainstream, mid-range cards for everyday Joe's like me. I'm paying the same for middle tier cards ass I used to pay for the premium best.\n\nOh well, maybe I'll get lucky with a 60Ti or I'm waiting for the poverty edition cards (and I mean, I could pay for these, but it's hard for me to justify spending this much on gaming).",
      "Budget minded pc gamers also don’t need a 2080S level of power. Are they playing at 1440p? If they are they sure as hell aren’t budget minded gamers and for 1080p the card is overkill.",
      "Why do you care what the last two digits of the model number are? This card is faster than the 2080 Super at a fraction of the price.",
      "Will still be a better fit than a 6800 with a whopping 16 GB it's never going to use.",
      "Why are you comparing to last gen, budget gamers absolutely want 3060 level performance. The last gen is irrelevant. The xx60 series has always been the entry level goto perf  card until Turing screwed everything up. As next gen games release, requirements will go up making 3060 necessary for good quality / performance even at 1080p. The xx50 cards have always been terrible and only suggested to people on a really low budget.",
      "Wow what an AMD fanboy! \"AMD has more VRAM, more MHZ! MUST BE BETTER RIGHT!!\" So disgusting. Both AMD and Nvidia cards are good. However no one can deny that AMD has done some scummy things this release. stop being a fanboy they're not your friends",
      "Before anyone asks, it's not yet up on the EU site.",
      "I'm running a 3070 with a 550w power supply, you will be OK.",
      "The 5060 Ti",
      "I mean, they did the same thing with Ryzen 5000. Are you gonna tell me that they weren't confident in that product? Seems like just a typical marketing department decision (\"when people see the reviews, they might decide to buy it, so we should have them available to buy.\")",
      "Budget is what the 50 cards should be.",
      "Wait more for what?",
      "If they actually offer good performance I’m okay with it but in the past anything below xx60 is often not worth it unless you absolutely can’t afford anything better. It’s often better to get something used from a previous Gen since they’re so bad. Amd also used to fill this gap with their x80 cards, but so far it doesn’t look like they want to compete in the budget space any more.",
      "This isin't true.",
      "I'd rather be confident in a company that is several years ahead in DLSS and is currently spanking the 6800 in 4k despite having far less VRAM.",
      "Consoles are moving to 4K so your argument about 1080p is silly in my opinion. Budget 7 years ago is different from budget now, technology has increased. But yes a mid range card like the xx60 should absolutely give +80 FPS at 1080p and 1440p60 on high settings and actually will, the problem is the price. \n\nIf you’re suggesting budget gamers move down to the xx50, historically they provide a 1080p 30 FPS experience which is not ideal for anyone. Now if nvidia actually announces a rtx 3050 with ray tracing with promise of 1080p 60 at $200, or 1440p 60 without ray tracing at medium settings that would actually be a good budget option and would be similar to Xbox series s. Nothing amd or nvidia has done or said suggests this will happen."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "low",
    "matched_keywords": [
      "rtx 3060",
      "3060",
      "rtx 3060 ti",
      "3060 ti"
    ],
    "title": "[Gamers Nexus] NVIDIA GeForce RTX 3060 Ti Founders Edition Review: Gaming, Thermals, Noise, & Power Benchmarks",
    "selftext": "",
    "comments": [
      "Nearly a 3070 for $100 less.",
      "Sounds like normal high-end card price:perf scaling.  XD",
      "Just looking at those benchmarks, did Nvidia just kill the 3070 like 2 months after release and 2 months BEFORE widespread availability? The 10% or so difference isn't that much and much more importantly, theres nothing about the 3070 that promises to age better. \n\nSpecifically the same 8 GBs of vram running at the same speed  is puzzling - so whats the point of the 3070 now? If it had 10 GBs, or the 3060ti only had 6, you could make an argument for the 3070 being *slightly* more futureproof at higher resolutions but thats clearly not the case.",
      "Yea having a 3070, that stings a bit. 10-15% faster for 25% more at the mythical MSRP.",
      "It seems like 3080 and 3060Ti is the card to buy (at least now), and 3070 is kinda awkward sitting at that position. 3080 offers great performance increase from 3070 with a reasonable increase in price, while 3060Ti offers 90% performance of 3070 for 75% of the price.\n\nNo wonder why 3080 is still OOS everywhere, 3060Ti need to be better. Also lift the review embargo before launch (while just 1 day) is a pretty ballsy move.",
      "Probably easier to bin 3060tis, for now at least maybe.",
      "Why upgrade from a 2070s for 15%",
      "3060 Ti provides about 85% the performance of 3070\n\n3060 Ti is about 80% of the money of 3070\n\nYes 3060 Ti is a better value but it's not that big of a delta in the price/performance curve. \n\nI had 2080 Ti which is where 3070 lands and I can tell you that in a lot of applications at 1440p, 2080 Ti is the difference between breaking 60fps vs not breaking 60fps with 2080 Super.",
      "it is just a lower binned 3070",
      "This lineup is literally one of the cleanest they've ever done in recent memories. \n\nOnce you see where 3070 was going to land, you know exactly where all the lower end cards will land\n\n3070 = \\~2080 Ti replacement @ $500\n\n3060 Ti = 2080 Super+ performance @ $400\n\nRumored 3060 = Probably 2070 Super performance @ $300-350\n\nRumored 3050 Ti = Probably 2060 Super performance @ \\~$250\n\nRumored 3050 = Probably 2060 performance @ \\~$200",
      "That's literally how every products are. It's called binning and it's in both CPU and GPU market.",
      "Because when the time comes in which you will have a choice, you'll want to have reviews ready as a reference available right at that moment - instead of waiting for reviewers to catch up with market situation, leaving potential product customers blind.",
      "Yea and since the RTX 3060 will be based on an entire new and lower tier GPU (GA106) I expect it to not be great value vs the 3060 Ti (GA104). The value kings will probably end up being the 3080, 3060 Ti and 3050 Ti.",
      "I just consider myself very lucky to even have a 3000 series card -3070 to be specific. Complaining over $20, $50, $100 for an item that will give me countless hours of enjoyment is just - sad to be honest. Its an expensive hobby so we have to either deal with it or get a \\*shudders\\* console /s.\n\nComing from a 1070, the performance increase just blew me away and I am sure it will continue to do so with new titles that are coming out in the future - looking at you Cyberpunk :D",
      "exactly...\n\n&#x200B;\n\nThe fact that the 3080 and 3070 are about equal in perf/euro is crazy bad , especially since they both skew towards high prices (if they were both cheap then sure)",
      "the best card in 2020 is the one you can buy",
      "I'm honestly puzzled as to what our two favourite, much loved GPU manufacturers are thinking sometimes. This nvidia lineup is all over the place even without supply issues and AMD... Well, someone at AMD owes me 10 bucks, put it that way.",
      "I mean yeah, alright. But if the 3070s only reason to exist is to provide cut-downs for the 3060ti, I'm still not seeing a reason to buy it.",
      "Thats why nvidia was extremely wise to show off the 3070 with the 3080 and 3090, generate excitement, then get as many as they can to pay the extra money and keep the 3070 killer very quiet. There were leaks but this was basically a surprise launch. No teaser or announcement or anything from nvidia. \n\nPeople thought the 3060ti would be shit like the 2060, with no vram or gimped in some way but its really good. Kicks the 5700xt ass for the same price and obliterates amd cards in ray tracing and games that have dlss. This and the 3080 are the value cards of this generation. Just like the 1080ti and the 1060 were with pascal.",
      "The consensus seems to be that it's actually a little faster than a 2080 super"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "low",
    "matched_keywords": [
      "rtx 3060",
      "3060"
    ],
    "title": "[Gamers Nexus] NVIDIA RTX 3060 GPU Review & Benchmarks: Aaand It's Gone",
    "selftext": "",
    "comments": [
      "> Some things never change, like the fact that the 1080ti remains the GOAT\n\nman 1080ti chads got some real fucking mileage out of this beast might as well just skip to 40 series.",
      "Actually disappointing.\n\nWhile it's ~2x the performance of a 1060 6GB or RX 580, the gap between the 3060 and 3060 Ti is larger than expected.\n\nThe 2070 Super and 1080 Ti are still a bit faster than the 3060, and the 3060 Ti is a whopping ~28% faster than the 3060 (3060 Ti is a tiny bit faster than a 2080 Super).\n\nSo seems like the 3060 is a bit underpowered for what it should be, and the 3060 Ti is the better buy.\n\nI'd speculate they're allowing a gap for a 3060 Super to come later.",
      "Its the most expensive 2060 Ive yet to see at launch :/",
      "This card is doa. The performance is worse than almost 2 year old 5700xt which was available widely for sub 400$\n\nAlso the 3060ti beats the sh\\*t out of this while  costing just 70$ more.   \nThis should cost 250$ max.",
      "Yeah performance at about the level of a 2060S is super disappointing, especially as the 3080 broke new ground and other higher end parts did very well vs previous gen. \n\nWith 3070=2080Ti and 3060Ti=2080S I was kinda hoping the 3060 would clock in at about 2070S level performance.",
      "I can't help feeling that the 3060Ti should have been called 3060. And the 3060 should be called the 3050",
      "Nvidia never would have imagined they could release a 2060S in disguise and sell it at $600.",
      "Oh for sure. 1080ti is just a monster value gpu that will never happen again.\n3 flipping generations and still going strong , that's impressive",
      "TLDW: On avg slower than 2060S and 1080ti, only 1% better price/perf than 2060.\n\nLooks DOA to me.",
      "That 1080ti just aged like fine wine.i even think 980ti did pretty well, but 1080ti tho.",
      "Overpriced and absolutely trash value for money. I am convinced no cards in future will match the value to performance ratio of a 1060 6GB or an RX 580.",
      "Sheesh... Im really surprised by the performance differences between this card and the 3060ti, it's pretty massive. For the 400 to 500 dollars you're going to have to spend to buy this thing, it's a complete rip off.\n\nReally too bad, the more options the better generally, but this cards almost insulting.",
      "Soooo... it sold well ?",
      "It will sell well just because its cheap.",
      "Yeah cant wait to play 4k games with all textures etc maxed out while having 20fps.",
      "Cheap. $450 is a cheap GPU now (because despite what Nvidia says, you'll *never* find one for $329).",
      "NGL is just \"meh\" 2060S price for 2060S-ish  performance 2 years later.",
      "$320 still is overpriced. That’s a $270ish  card at most",
      "This is what it is \n\n3060 has 28SMs/48ROPs/15ghz G6 (360GB/S)\n\nWhat it should have been 30SMs/64ROPs/16ghz G6 (384GB/s)\n\nI'm pretty sure the current 3060 is ROP starve the laptop version has 64rops desktop 48.  \n\nFor reference the 1080ti had the same amount of Cuda cores (3584) but had 88 rops instead of 48, I know it's 2 different architectures but ROPs are ROPs and 48 isn't alot especially since the consoles have 64 both of them and the PS5 is clocked at 2.23ghz.",
      "Perfect summary. I'm going to continue squeezing every drop of performance I can out of my GTX 1070 @ 1440p until I can get a card with 2080 Ti/3070 performance for $550 USD incl. tax, and I don't care if that's not until December 2021. I'm just not willing to support these bullshit prices."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "low",
    "matched_keywords": [
      "rtx 3060",
      "3060",
      "rtx 3060 ti",
      "3060 ti"
    ],
    "title": "[Digital Foundry] Nvidia GeForce RTX 3060 Ti Review: Faster than 2080 Super, Easily Beats 1080 Ti",
    "selftext": "",
    "comments": [
      "The funny thing is that rtx 3060ti cost the same as rtx 3070 in my country 550$ weird lol",
      "3070 it is!",
      "Thank you EVGA queue. Got a 3060 Ti on the way to my brother's system tomorrow.",
      "Meetings are on Tuesday’s",
      "Take a number",
      "Too bad bustbuy screwed me over",
      "and the 3070's cost as much as a 3080",
      "Does anyone how I can get one of these. I missed the release and it was perfect for my price/performance expectations.",
      "When did you sign up for it?",
      "they're not even sold out in my country because the shops themselves are selling them for 650 euro :))) so not much point for scalpers to get involved",
      "Interesting. I run a 1070 and I know it's time to upgrade. I FEEL IT IN MY LOINS! So for me this video was super informative. Two main factors affecting the upgrade are card supply and the amount of work I have with covid beating us all down.",
      "But you in the other hand have a card in your hand that plays video games. \n\nIf you had waited there’s a very high likelihood you’d still not have any card and might not for a while",
      "If you are asking at this point you might get a chance to buy it in a few months. And go to [Evga.com](https://Evga.com), create an account, and then use that email to sign up for Auto Notify on each product you want to be notified about.\n\nExample link for 3060 TI: [https://www.evga.com/products/product.aspx?pn=08G-P5-3667-KR](https://www.evga.com/products/product.aspx?pn=08G-P5-3667-KR)\n\nOnce you enter the auto notify queue, evga will send you an email when its your turn with the link to an instock item for 8 hrs, so you are guaranteed stock if you get the notification email. Its moving very slowly for some cards though, they are still on like September 19 signs ups for the 3080.",
      "It ain't easy. I've been actively searching since the second it launched and still don't have one. The release was a mess. I've been barely sleeping to try and get a resupply drop.",
      "And 3080 cost as much as rare earth diamond.",
      "They definitely dont help",
      "The reference card is slightly cheaper than the reference 3070 in mine, but it's not that big a difference and there are cheaper 3070 partner boards than some of the higher end 3060 Ti. If I were needing a new PC i'd either wait for the 3060/3050ti/3050, or get a 3070.",
      "How does one get into the queue",
      "It probably won't be 6 months until these cards are outclassed by new cheaper super cards.",
      "12/1/2020 6:26 AM PDT"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "low",
    "matched_keywords": [
      "rtx 3060",
      "3060"
    ],
    "title": "Gpu recommandation",
    "selftext": "Hi guys, Im going to buy a new gpu for cyberpunk. I cant decide between a used 2080ti (from a mining rig that has been treated heavenly dw) or a new/almost never used 3070. \nI want to play in 1440p hight/ultra settings with Dlss quality and rtx medium.\nWhat are your thoughts ? Is the lack of vram on the 3070 an issue for 1440p gaming ?!\n\nUPDATE :\nHeres are the NEW requirement for [cyberpunk](https://static.cdprojektred.com/cms.cdprojektred.com/afd5ed6b7573ee6133c8c31902323f4453ad15e5.jpg?1bctf) . I think its safe to say that yes the 3070 will still be capable of what I want to achieve except for rt medium i think ill need a 10gb minimum card for that.\nAlso heres are the average prices of gpu in my country :\n\n- used rtx 2080ti : 250€-300€\n- new rtx 3060 : 300€\n- used/almost new 3070 : 350€\n- used/almost new 3080 : 350-500€\n- new 4060 : 400€\n- new 4060ti : 500€\n- new 4070 : 650€\n\nI know amd can cp for lower prices but I compatibility is a problem in my case",
    "comments": [
      "3070 is still a solid card for 1440p. You doesn't seem to have any issues with DLSS on.",
      "RT cores and DLSS works better on 2nd gen 3070, compared to 1st Gen 2080Ti. Especially if heavily used, I’d go for new 3070, no question.",
      "2000 series has the 1st gen RT cores, 3000 series has the 2nd gen RT cores.\n\nSo while the 2080ti and the 3070 my be similar in raster performance, the 3070 excels in RT. Its the better card if you want to use RT in games.",
      "buy 4070.",
      "3070 for sure. It has enough juice for 1440p and I'm guessing it's not beat to heck.",
      "3070 is an excellent budget card for 1440p gaming. And no, VRAM isn't nearly as big of an issue like many people will tell you. Theres people recommending the 6700xt over the 3070 which is pretty funny to me considering the 3070 is clearly faster. At most you'll just have to turn settings down from max a little bit. Keep in mind not a lot of games require over 8gb of VRAM at 1440p ultra.",
      "3070 ti owner here, I'd downgrade to a 2080ti if I could. RTX performance isn't much better and path tracing pretty much requires frame generation(40 series), and VRAM is starting to be a issue with titles like CP2077 and diablo 4. and the people saying dlss performance is different between the two are delusional.",
      "the 3070 is barely more efficient than the 2080Ti, cause Samsung is trash and all hail our TSMC overlords",
      "I think ill go with that then",
      "As an owner of the 3070, I can tell you that it definitely does have VRAM issues in some of the most recent titles. I've been experiencing textures popping in and out, stuttering, framedrops, and generally low FPS at 1440p ultra textures with raytracing, even when using DLSS in quite a few newer games. I honestly wouldn't invest in an 8gb VRAM GPU in 2023, and I'm personally looking to upgrade in the very near future. \n\nThe RT performance on the 2080ti wouldn't be as good when not limited by VRAM, but you will be able to use ultra textures much more often on the 2080ti than the 3070, so it really depends which you value more. \n\nIf you can stretch your budget to get a 4070, or even a used 6800/6800xt, it will probably be a better buy.",
      "For everything he wants to do and for upcoming games he should save a little more and just get the RTX 4070 instead because for a lot of newer games at 1440p will be using more than 8gb of Vram which the 3070 only has.",
      "What is a 2nd gen 3070 ?",
      "There are console wars, and we here have VRAM wars 👀",
      "Electricity bill is not factor",
      "none of the games i play have ray tracing and with heavy modding i often exceed 8gb vram. I’m not a streamer and the only productivity workloads i use are music production. I use FSR2 Quality from time to time and it never bothers me. In one game i think it actually makes it look better lmao. But long story short, I don’t think it’s worth it to pay extra for features i don’t use.",
      "Recently played cyberpunk with my 3070 and ryzen 5600. Consistently locked at average of 100 fps on ultra preset without raytracing. A thoroughly enjoyable experience. I don't care about ray tracing as in the heat of the gun fights etc it's not noticeable. And the game has amazing lighting without raytracing.",
      "I'm still on my EVGA RTX 2080 Ti here paired with my i9-9900K, and use a 1440p 144hz ASUS ROG monitor as my primary display. I also play Cyberpunk 2077. In your case, especially as the 2080 Ti is a heavily mined card, I would go for the RTX 3070. The 2080 Ti and 3070 really goes head to head in terms of performance, but from a longevity, wattage, and newer architecture standpoint, I would say the 3070 has the slight advantage here. The slightly less VRAM won't be a big issue in most games as long as you keep your 1440p display for awhile. Good luck!",
      "This. I own a 3060ti which is close to a 3070 and RT anything is not playable IMO. That said game is still plenty enjoyable without RT.",
      "physical pci-e 8x connection; fuck that.",
      "There is no such thing as a 16gb 3060ti."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "low",
    "matched_keywords": [
      "rtx 3060",
      "3060",
      "rtx 3060 ti",
      "3060 ti"
    ],
    "title": "Newegg 3060 Ti Links (NA)",
    "selftext": "Pieced these together while looking in Newegg's API. Below is a list of links for the majority of RTX 3060 Ti graphics cards (that I had time to find at least). These links will go live on launch day, and will not appear if you search for them until after they are sold out, hence why saving these is important.\n\nEDIT 1: Updated with ca links, adding more links as I can find more cards in Newegg's API.\n\nEDIT 2: Updated with current inventory numbers from their backend and will continue to update them.\n\n**Asus -**\n\n* **NA** \\- ROG Strix 3060 Ti - **27 In Stock:**  [https://www.newegg.com/asus-geforce-rtx-3060-ti-rog-strix-rtx3060ti-o8g-gaming/p/N82E16814126470?Item=N82E16814126470&Tpk=14-126-470](https://www.newegg.com/asus-geforce-rtx-3060-ti-rog-strix-rtx3060ti-o8g-gaming/p/N82E16814126471?Item=N82E16814126471&Tpk=14-126-471)\n* **ca**\\- ROG Strix 3060 Ti - **84 In Stock:**  [https://www.newegg.ca/asus-geforce-rtx-3060-ti-rog-strix-rtx3060ti-o8g-gaming/p/N82E16814126470?Item=N82E16814126470&Tpk=14-126-470](https://www.newegg.com/asus-geforce-rtx-3060-ti-rog-strix-rtx3060ti-o8g-gaming/p/N82E16814126471?Item=N82E16814126471&Tpk=14-126-471)\n\n&#x200B;\n\n* **NA** \\- TUF 3060 Ti - **96 In Stock:** [https://www.newegg.com/asus-geforce-rtx-3060-ti-tuf-rtx3060ti-o8g-gaming/p/N82E16814126471?Item=N82E16814126471&Tpk=14-126-471](https://www.newegg.com/asus-geforce-rtx-3060-ti-tuf-rtx3060ti-o8g-gaming/p/N82E16814126471?Item=N82E16814126471&Tpk=14-126-471)\n* **ca**\\- TUF 3060 Ti - **166 In Stock:** [https://www.newegg.ca/asus-geforce-rtx-3060-ti-tuf-rtx3060ti-o8g-gaming/p/N82E16814126471?Item=N82E16814126471&Tpk=14-126-471](https://www.newegg.com/asus-geforce-rtx-3060-ti-tuf-rtx3060ti-o8g-gaming/p/N82E16814126471?Item=N82E16814126471&Tpk=14-126-471)\n\n&#x200B;\n\n* **NA** \\- KO 3060 Ti - **0 In Stock:** [https://www.newegg.com/asus-geforce-rtx-3060-ti-ko-rtx3060ti-o8g-gaming/p/N82E16814126474?Item=N82E16814126474&Tpk=14-126-474](https://www.newegg.com/asus-geforce-rtx-3060-ti-ko-rtx3060ti-o8g-gaming/p/N82E16814126474?Item=N82E16814126474&Tpk=14-126-474)\n* **ca** \\- KO 3060 Ti - **0 In Stock:** [https://www.newegg.ca/asus-geforce-rtx-3060-ti-ko-rtx3060ti-o8g-gaming/p/N82E16814126474?Item=N82E16814126474&Tpk=14-126-474](https://www.newegg.com/asus-geforce-rtx-3060-ti-ko-rtx3060ti-o8g-gaming/p/N82E16814126474?Item=N82E16814126474&Tpk=14-126-474)\n\n&#x200B;\n\n* **NA** \\- Dual 3060 Ti - **76 In Stock:** [https://www.newegg.com/asus-geforce-rtx-3060-ti-dual-rtx3060ti-o8g/p/N82E16814126468?Item=N82E16814126468&Tpk=14-126-468](https://www.newegg.com/asus-geforce-rtx-3060-ti-dual-rtx3060ti-o8g/p/N82E16814126468?Item=N82E16814126468&Tpk=14-126-468)\n* **ca**\\- Dual 3060 Ti - **0 In Stock:** [https://www.newegg.ca/asus-geforce-rtx-3060-ti-dual-rtx3060ti-o8g/p/N82E16814126468?Item=N82E16814126468&Tpk=14-126-468](https://www.newegg.com/asus-geforce-rtx-3060-ti-dual-rtx3060ti-o8g/p/N82E16814126468?Item=N82E16814126468&Tpk=14-126-468)\n\n&#x200B;\n\n&#x200B;\n\n&#x200B;\n\n**Gigabyte -**\n\n* **NA** \\- Aorus Master 3060 Ti - **375 In Stock:** [https://www.newegg.com/gigabyte-geforce-rtx-3060-ti-gv-n306taorus-m-8gd/p/N82E16814932375?Item=N82E16814932375&Tpk=14-932-375](https://www.newegg.com/gigabyte-geforce-rtx-3060-ti-gv-n306taorus-m-8gd/p/N82E16814932375?Item=N82E16814932375&Tpk=14-932-375)\n* **ca**\\- Aorus Master 3060 Ti - **0 In Stock:** [https://www.newegg.ca/gigabyte-geforce-rtx-3060-ti-gv-n306taorus-m-8gd/p/N82E16814932375?Item=N82E16814932375&Tpk=14-932-375](https://www.newegg.com/gigabyte-geforce-rtx-3060-ti-gv-n306taorus-m-8gd/p/N82E16814932375?Item=N82E16814932375&Tpk=14-932-375)\n\n&#x200B;\n\n* **NA** \\- Gaming OC 3060 Ti - **606 In Stock:** [https://www.newegg.com/gigabyte-geforce-rtx-3060-ti-gv-n306tgamingoc-pro-8gd/p/N82E16814932376?Item=N82E16814932376&Tpk=14-932-376](https://www.newegg.com/gigabyte-geforce-rtx-3060-ti-gv-n306tgamingoc-pro-8gd/p/N82E16814932376?Item=N82E16814932376&Tpk=14-932-376)\n* **ca** \\- Gaming OC 3060 Ti - **0 In Stock:** [https://www.newegg.ca/gigabyte-geforce-rtx-3060-ti-gv-n306tgamingoc-pro-8gd/p/N82E16814932376?Item=N82E16814932376&Tpk=14-932-376](https://www.newegg.com/gigabyte-geforce-rtx-3060-ti-gv-n306tgamingoc-pro-8gd/p/N82E16814932376?Item=N82E16814932376&Tpk=14-932-376)\n\n&#x200B;\n\n* **NA** \\- Eagle 3060 Ti - **205 In Stock:** [https://www.newegg.com/gigabyte-geforce-rtx-3060-ti-gv-n306teagle-oc-8gd/p/N82E16814932378?Item=N82E16814932378&Tpk=14-932-378](https://www.newegg.com/gigabyte-geforce-rtx-3060-ti-gv-n306teagle-oc-8gd/p/N82E16814932378?Item=N82E16814932378&Tpk=14-932-378)\n* **ca** \\- Eagle 3060 Ti - **0 In Stock:** [https://www.newegg.ca/gigabyte-geforce-rtx-3060-ti-gv-n306teagle-oc-8gd/p/N82E16814932378?Item=N82E16814932378&Tpk=14-932-378](https://www.newegg.com/gigabyte-geforce-rtx-3060-ti-gv-n306teagle-oc-8gd/p/N82E16814932378?Item=N82E16814932378&Tpk=14-932-378)\n\n&#x200B;\n\n&#x200B;\n\n**EVGA -**\n\n* NA - XC Black Gaming 3060 Ti - **0 In Stock:** [https://www.newegg.com/evga-geforce-rtx-3060-ti-08g-p5-3661-kr/p/N82E16814487533?Item=N82E16814487533&Tpk=14-487-533](https://www.newegg.com/evga-geforce-rtx-3060-ti-08g-p5-3661-kr/p/N82E16814487533?Item=N82E16814487533&Tpk=14-487-533)\n* ca- XC Black Gaming 3060 Ti - **0 In Stock:** [https://www.newegg.ca/evga-geforce-rtx-3060-ti-08g-p5-3661-kr/p/N82E16814487533?Item=N82E16814487533&Tpk=14-487-533](https://www.newegg.com/evga-geforce-rtx-3060-ti-08g-p5-3661-kr/p/N82E16814487533?Item=N82E16814487533&Tpk=14-487-533)\n\n&#x200B;\n\n* **NA** \\- FTW Black Gaming 3060 Ti - **0 In Stock:** [https://www.newegg.com/evga-geforce-rtx-3060-ti-08g-p5-3662-kr/p/N82E16814487534?Item=N82E16814487534&Tpk=14-487-534](https://www.newegg.com/evga-geforce-rtx-3060-ti-08g-p5-3662-kr/p/N82E16814487534?Item=N82E16814487534&Tpk=14-487-534)\n* **ca** \\- FTW Black Gaming 3060 Ti - **0 In Stock:** [https://www.newegg.ca/evga-geforce-rtx-3060-ti-08g-p5-3662-kr/p/N82E16814487534?Item=N82E16814487534&Tpk=14-487-534](https://www.newegg.com/evga-geforce-rtx-3060-ti-08g-p5-3662-kr/p/N82E16814487534?Item=N82E16814487534&Tpk=14-487-534)\n\n&#x200B;\n\n* **NA** \\- EVGA XC Gaming 3060 Ti - **0 In Stock:**  [https://www.newegg.com/evga-geforce-rtx-3060-ti-08g-p5-3663-kr/p/N82E16814487535?Item=N82E16814487535&Tpk=14-487-535](https://www.newegg.com/evga-geforce-rtx-3060-ti-08g-p5-3663-kr/p/N82E16814487535?Item=N82E16814487535&Tpk=14-487-535)\n* **ca** \\- EVGA XC Gaming 3060 Ti - **0 In Stock:**  [https://www.newegg.ca/evga-geforce-rtx-3060-ti-08g-p5-3663-kr/p/N82E16814487535?Item=N82E16814487535&Tpk=14-487-535](https://www.newegg.com/evga-geforce-rtx-3060-ti-08g-p5-3663-kr/p/N82E16814487535?Item=N82E16814487535&Tpk=14-487-535)\n\n&#x200B;\n\n* **NA** \\- EVGA FTW Gaming 3060 Ti - **0 In Stock:** [https://www.newegg.com/evga-geforce-rtx-3060-ti-08g-p5-3665-kr/p/N82E16814487536?Item=N82E16814487536&Tpk=14-487-536](https://www.newegg.com/evga-geforce-rtx-3060-ti-08g-p5-3665-kr/p/N82E16814487536?Item=N82E16814487536&Tpk=14-487-536)\n* **ca** \\- EVGA FTW Gaming 3060 Ti - **0 In Stock:** [https://www.newegg.ca/evga-geforce-rtx-3060-ti-08g-p5-3665-kr/p/N82E16814487536?Item=N82E16814487536&Tpk=14-487-536](https://www.newegg.com/evga-geforce-rtx-3060-ti-08g-p5-3665-kr/p/N82E16814487536?Item=N82E16814487536&Tpk=14-487-536)\n\n&#x200B;\n\n* **NA** \\- EVGA FTW Ultra 3060 Ti - **200 In Stock:** [https://www.newegg.com/evga-geforce-rtx-3060-ti-08g-p5-3667-kr/p/N82E16814487537?Item=N82E16814487537&Tpk=14-487-537](https://www.newegg.com/evga-geforce-rtx-3060-ti-08g-p5-3667-kr/p/N82E16814487537?Item=N82E16814487537&Tpk=14-487-537)\n* **ca** \\- EVGA FTW Ultra 3060 Ti - **0 In Stock:** [https://www.newegg.ca/evga-geforce-rtx-3060-ti-08g-p5-3667-kr/p/N82E16814487537?Item=N82E16814487537&Tpk=14-487-537](https://www.newegg.com/evga-geforce-rtx-3060-ti-08g-p5-3667-kr/p/N82E16814487537?Item=N82E16814487537&Tpk=14-487-537)\n\n&#x200B;\n\n&#x200B;\n\n**MSI -**\n\n* **NA** \\- Gaming X Trio 3060 Ti - **0 In Stock**: [https://www.newegg.com/msi-geforce-rtx-3060-ti-rtx-3060-ti-gaming-x-trio/p/N82E16814137611?Item=N82E16814137611&Tpk=14-137-611](https://www.newegg.com/msi-geforce-rtx-3060-ti-rtx-3060-ti-gaming-x-trio/p/N82E16814137611?Item=N82E16814137611&Tpk=14-137-611)\n* **ca**\\- Gaming X Trio 3060 Ti - **0 In Stock:** [https://www.newegg.ca/msi-geforce-rtx-3060-ti-rtx-3060-ti-gaming-x-trio/p/N82E16814137611?Item=N82E16814137611&Tpk=14-137-611](https://www.newegg.com/msi-geforce-rtx-3060-ti-rtx-3060-ti-gaming-x-trio/p/N82E16814137611?Item=N82E16814137611&Tpk=14-137-611)\n\n&#x200B;\n\n* **NA** \\- Ventus 2X OC 3060 Ti - **0 In Stock:** [https://www.newegg.com/msi-geforce-rtx-3060-ti-rtx-3060-ti-ventus-2x-oc/p/N82E16814137612?Item=N82E16814137612&Tpk=14-137-612](https://www.newegg.com/msi-geforce-rtx-3060-ti-rtx-3060-ti-ventus-2x-oc/p/N82E16814137612?Item=N82E16814137612&Tpk=14-137-612)\n* **ca** \\- Ventus 2X OC 3060 Ti - **0 In Stock:** [https://www.newegg.ca/msi-geforce-rtx-3060-ti-rtx-3060-ti-ventus-2x-oc/p/N82E16814137612?Item=N82E16814137612&Tpk=14-137-612](https://www.newegg.com/msi-geforce-rtx-3060-ti-rtx-3060-ti-ventus-2x-oc/p/N82E16814137612?Item=N82E16814137612&Tpk=14-137-612)\n\n&#x200B;\n\n&#x200B;\n\n**Zotac** \\-\n\n* **NA** \\- Zotac 3060 Ti - **20 In Stock:** [https://www.newegg.com/zotac-geforce-rtx-3060-ti-zt-a30610e-10m/p/N82E16814500506?Item=N82E16814500506&Tpk=14-500-506](https://www.newegg.com/zotac-geforce-rtx-3060-ti-zt-a30610e-10m/p/N82E16814500506?Item=N82E16814500506&Tpk=14-500-506)\n* **ca** \\- Zotac 3060 Ti - **0 In Stock:** [https://www.newegg.ca/zotac-geforce-rtx-3060-ti-zt-a30610e-10m/p/N82E16814500506?Item=N82E16814500506&Tpk=14-500-506](https://www.newegg.com/zotac-geforce-rtx-3060-ti-zt-a30610e-10m/p/N82E16814500506?Item=N82E16814500506&Tpk=14-500-506)\n\n&#x200B;\n\n* **NA** \\- Zotac 3060 Ti - **50 In Stock:** [https://www.newegg.com/zotac-geforce-rtx-3060-ti-zt-a30610h-10m/p/N82E16814500507?Item=N82E16814500507&Tpk=14-500-507](https://www.newegg.ca/zotac-geforce-rtx-3060-ti-zt-a30610h-10m/p/N82E16814500507?Item=N82E16814500507&Tpk=14-500-507)\n* **ca** \\- Zotac 3060 Ti - **0 In Stock:** [https://www.newegg.ca/zotac-geforce-rtx-3060-ti-zt-a30610h-10m/p/N82E16814500507?Item=N82E16814500507&Tpk=14-500-507](https://www.newegg.ca/zotac-geforce-rtx-3060-ti-zt-a30610h-10m/p/N82E16814500507?Item=N82E16814500507&Tpk=14-500-507)\n\n&#x200B;\n\n&#x200B;\n\n&#x200B;\n\n&#x200B;",
    "comments": [
      "Will update with more links asap.",
      "> if you are committed to spending $630 on a gpu why not just get the 3080 for $70 more and get far far more performance?\n\nbecause you can't get a 3080 for only 70 more....",
      "To support the poor companies /s",
      "I had a double take when I saw your username",
      "When is launch day? Does anyone know a specific time I should be F5-ing?",
      "I think these are the links but they haven't been officially posted yet, so there's no product. Save them for when they do, you'll already have the links for the card your interested in",
      "At what hour (timezone) the card will be release ?",
      "Anyway of finding the following links on Newegg.ca?",
      "Some people really value silence. If the FE is launching at $400 then no 3060Ti is going to have an MSRP of $630 though. Usually even the most expensive air cooler models are only 100$ more expensive than the simple models.\n\nGiven how close the 3060Ti seems to be to the 3070 I don't think it's that strange. Some people will trade away 10% performance for a really good cooler. I've heard a Strix 3080 can get pretty close to a basic 3090 for example. It's the same reason why some people undervolt instead of maxing overclocks.",
      "Will get ca links.",
      "Haha that's amazing, never seen anyone with a username similar to mine",
      "Added Zotac 3060 Ti's, fixed Strix 3060 Ti link, and added Canadian links.",
      "FEs are gone and never coming back, its partner boards only from here on out so a 3080 for $700 is never gonna happen",
      "Will try and dig around for prices next.",
      "You just gave the Links to the Bot users.",
      "Nice job. Newegg disabled their API because of you lol.",
      "Hi, it says it cant find the item, how do u find them?",
      "not really, as any of the paid bot services are all over the APIs they are not using reddit posts to gather links they would have had these anyway and this way at least a few end users were able to grab them.",
      "sure, some people will be able to buy from them. And that the grouds on which they will say 3070 is a 500 dollar card. But didn't nvidia stopped selling FE cards? Given the price differences, why would anyone buy AIB cards instead of FE?\n\nNvidia is making a couple thousand FE cards at launch and selling them with no profit margin or even at cost. This way they get to say their cards are cheaper but in actuality 3070 will cost substantially more than 500.",
      "Well, I don't think you can really get a 3080 for $700. Just because few people have managed to get one, doesn't cover the tons of people who've tried and didn't."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "low",
    "matched_keywords": [
      "rtx 3060",
      "3060",
      "rtx 3060 ti",
      "3060 ti"
    ],
    "title": "Bosnian retailer puts Gigabyte GeForce RTX 3060 Ti EAGLE on display",
    "selftext": "",
    "comments": [
      "Weird this is happening everywhere for the 3060 Ti but didn't for any of the other 30 series cards, even the 3070.  We're supposedly still 2 weeks away from release, too.",
      "Launches in 13 days, if supply is good and price is not too high, this will be a very popular card (possibly better value than the 3070 even).",
      "No, Nvidia hasn't even acknowledged that the 3060 Ti exists, but Videocardz says it will launch on December 2nd. This is also the date the review embargo lifts. They have sources at AIB's and reviewers, who already [leaked the official 3060 Ti performance slide to them.](https://videocardz.com/newz/nvidia-official-geforce-rtx-3060-ti-performance-leaked)",
      "Anyone remembers when cards were sold at MSRP?",
      "Has Nvidia officially confirmed the launch date?",
      "I really hope gigabyte makes a vision version of the 3060 ti, such a good looking card",
      "I've been waiting for the less expensive cards to come out already but unfortunately the question of getting one in the first place is an even bigger problem :(",
      "That seems like such an incremental update. whats the refresh rate of your monitor?",
      "I am hoping nvidia announces their TI variants soon. 3060ti and 3080ti are definitely happening but I think they scratched the 3070ti as no one would buy the 3080 if they made 3070ti.",
      "Wow.  In the us 3070 is $499, the 6800XT is $649",
      "What is your opinion on moving from a 2080 to a 3060ti.\n\nI only game in 1080p and, over the year, beef'd up my pc for Cyberpunk. Going from a R5 2600 to a R7 3700, 16Gb 2666 to 32Gb 3200 mhz and trading my 2070 for a 2080",
      "I mean if you don't need that much power, go for it.\n\nI'm pretty sure the 3060ti will even be enough for 1440p over 60fps",
      "It’s a cut down 3070 die, there is still going to be a regular 3060 on a separate die",
      "Nvidia has some pretty awful pricing in places like Europe and Australia from my understanding.",
      "First you don't realize that the Euro is stronger than the Dollar, then you think that jacking up prices from MSRP has anything to do with VAT, and then you try to shift the focus onto something that's even less related. What's your idea here?",
      "It's not sold in Europe at all.",
      "So most games that are optimized well should run at 144 on a 2080 at 1080p, if you had a 240 hz screen I could see wanting to upgrade. But even then isn't the 3060 ti basically gonna be a 2080 super but with better ray tracing? Why not go for a higher end gpu and a 1440p monitor/240hz 1080p monitor?",
      "Because right now 1€=$1.19.\n\nSo if VAT is around 19% €-prices should be similar to US $-prices without VAT. \n\nLet’s list VAT in some European € countries:\n* 16%: Germany\n* 17%: Luxembourg\n* 18%: Malta\n* 19%: Cyprus\n* 20%: Austria, France, Estonia, Slovakia\n* 21%: Spain, Belgium, Ireland, Latvia, Lithuanian, Netherlands\n* 22%: Italy, Slovenia\n* 24%: Finland, Greece, Portugal\n\nIn most countries VAT is significantly lower on some goods like food. But this list should generally hold true for GPUs.\n\nThe official MSRP of the 3070FE is 499€ in Germany and 519€ in most other countries. It’s $499 in the US. Same with 3080FE: 699€ in Germany and 719€ in most other countries. $699 in the US. European official retailers adding several hundred € to the MSRP is ridiculous.",
      "Then whats the point of upgrading?",
      "all 2 of them"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "low",
    "matched_keywords": [
      "rtx 3060",
      "3060"
    ],
    "title": "RTX 3060 12GB or RTX 4060 8GB?",
    "selftext": "I'm looking to upgrade my 1660 super so I can run Jedi Survivor better, those 2 cards are the exact same price, so I don't really care if the 40 gen was a dissapointment, I just need to know which one is the stronger card, considering they are the exact same price in the store ",
    "comments": [
      "try to find used \n3060ti or 3070",
      "Honestly though? How about the 6700XT or 6750XT?  \nAt least give it a look to see the price and performance.",
      "I just mentioned it because, when I look at all the reviews, the 6750XT is way better than the 3060 and even the 4060 TI, and since the prices have come down quite a bit on AMD, it's worth a shot.\n\nThe only person who misses out if you don't consider all the options is yourself. I have an Nvidia card now, maybe I will again in the future, but whatever I upgrade to, it will be what I feel is the best buy at the moment.",
      "I understood it's disapointing because it's only slightly faster then 3060, even slightly faster for the exact same price is worth it, I see no reason in buying an older card for the exact same price of the newer if for my needs it's faster and it also have DLSS 3, I asked since I'm not a tech guy and I didn't really knew what 12GB mean, and I got an answer that it's for higher res which I don't use, so yes, 4060 might be only slightly better, but for the same price, it's a better choice for me, if that make me a fanboy, so be it",
      "Don't be an idiot. Nobody needs to be a fanboy nor hater. 3060 and 4060 are both 300$ cards and 4060 is clearly the better choice. Why wouldn't anyone buy it?",
      "I'm not against getting another company, I couldn't care less who make my card, this is also why I have both consoles, those wars are dumb, it's just for convienace, the same reason I keep buying Sumsong phones, it's easier to use interface of something you know, if my current card was AMD, I would probobly look for a new AMD first for the same reason, to get less confused with the interface\n\nAgain I'm not a tech guy so I use mostly Benchmark to test what parts are better, it showed that the 4060ti is better for that price, 6750 is better then 4060 but also more pricy, so between 4060TI and 6750XT it seem that I should choose 4060TI",
      "I have rtx 3070 and its great for 1080p.",
      "Its ok for 1080p. Not for 2k though.",
      "Jedi Survivor.\n\nYeah, 3060.",
      "4060 for 1080p definitley. 8gb is enough for 1080p. Only idiots, that don't admit that devs messed up in some badly optimised games say it isn't. The last of us, RE4, Hogwarts etc now work with ray tracing maxed on 1080p 3070 8gb no problem. It was just lazy porting.",
      "Just save for 4070 or 7800XT. There is no point in squabbling over two bad options.",
      "Just buy the freakin 4060. Those that say 3060 are nuts...",
      "I haven't checked non-Nvidia ones since I would have to get used to another interface, but those two specific cards don't even appere in the store page, there is a 6800XT but it's priceier then even the 4060 ti",
      "Those idiots are making non-enthusiastic people to spend their money badly.  Don't let them fool you. They are just haters on a hype train. A company will always release their products. They may be good or they may be bad but its not our business. Yes we all would want a better 4060 but it is what it is.\n\nYou just need to care about your own money. If they're at the same price or close, you should by 4060(BTW just focus on the cheapest AIB models. They all perform same). Reasons? \n\n1- Faster gpu(actually this one alone is enough)\n2- 3060 consumes %50 more power(which means more bills and heat)\n3- DLSS 3(You'll use this more often than you think. It'll help a lot)\n4- Latest generation(Longer support and higher possibility to unlock more features in the future.)\n\nYeah there is a 4gb vram difference but these things I've mentioned are much more important than this. Especially if you play on 1080p. \n\nIts your hard earned money, be careful to spend it.",
      "this is no longer true",
      "4060ti (8gb, not the upcoming 16gb), is 100 dollar more, while it might me 33% more in US prices, in Israel, 4060 cost around 600 dollars and 4060ti around 700 (AMD is also the same price range here and also other cards, for comparing,  4090 here is 2k at best and over 3k at worst), everything here is much more pricy, my PS5 was like 1k dollars, not scapled, store price\n\nWith Israel prices, getting 4060ti is better since the % of diffance is much lower, and is actully more avilable, the 4060 is only in 1 store",
      "3060Ti is better",
      "AMD is worse in ray tracing. If you plan to pay anything with RT don't go AMD since the 6750xt is slower than a 3060 in the vast majority games with ray tracing enabled.\n\nThere is a mod for Jedi Survivor for DLSS3 but I'm not sure how well it works. 4060ti is like 20-25% faster than a 4060 but usually costs 33% more.",
      "We have internet. Finding good prices isn't hard. \n\nNvidia vs amd is a totally different topic.",
      "I don’t know about Jedi survivor but I have an rtx 3060 12gb and it runs similar games at like 100-180fps"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "low",
    "matched_keywords": [
      "3060ti"
    ],
    "title": "Best GPU for a 650w PSU?",
    "selftext": "I'm looking to upgrade my GPU from a 3060ti and would rather avoid the hassle of switching my PSU. I was thinking about trying a 4070 TI Super or even a 4080. Would either of those be okay with these specs or is it too risky?",
    "comments": [
      "I'm running a 5070ti undervolted on a 650W psu. It is technically working but freezes for a bit right after boot (maybe 30 seconds). I will likely upgrade sometime soon but mine is a bronze unit. You might be okay if you know what you're doing.",
      "I’m running a 5070 on a 650w PSU\n\nI undervolted and overclocked a lil but it’s not necessary, the box says it requires a 650w PSU minimum\n\nWith my current undervolt and oc it doesn’t pull over 200W according to MSI afterburner",
      "it's not about that you CAN run it. it's about the stress on the PSU being somewhere in that 50-60% range. it will be better for longevity and stability overall.\n\nI wouldn't recommend anything more than 4070/5070 for 650W.\n\nAlso it matters if you PSU is a Seasonic/Corsair 650W or a noname PSU with 650W\n\n  \nIt also matters what platform / cpu are you using - do you have a lot of USB/PCIE devices etc.\n\nWith Intel I worry that even for 4070/5070 a 650W PSU might be insufficient.",
      "Planning a build around a PSU is nonsense",
      "I'm experiencing a similar issue. Every time I boot, as soon as the windows login screen appears, the PC freezes for like 10-20 seconds. After that everything works fine, tho I have a 1000W PSU with a 5080. I had the same issue with a 5070ti as well.\n\nMay I ask what motherboard are you using? I'm running a MSI b650 tomahawk.",
      "Your 12600 is drawing 117W according to the Intel website.  If you’re not playing in 4K you shouldn’t need the 80 series. You’d prob be fine w a 5070 and they recommend 650W power supplies.",
      "Friend of mine uses a 4070 Ti Super with a 600w just fine. I have also used a 3070 Ti with a 600w for over two years with 0 issues, and it draws about the same amount of power as the 4070 Ti Super and 4080.",
      "Upgrade your power supply. In 25 years of building computers I've had 3 power supplies fail and 1 motherboard. Think of the power supply as the root of the tree, if you don't have strong roots your tree will die. Good power supplies are relatively cheap compared to Covid days. \n\nBetter power supply then any GPU will work great. Just my opinion",
      "I’ve been running my 5070ti on a 650w bifenix formula gold for 2 weeks now without any kind of issues so far. I’ve even increased the power limit by 15%.",
      "I'm using a 5070ti with a 650w PSU, no issue.",
      "You should also upgrade your ram, now it sits at low frequencies (2666 mts), just buy a 32gb 3200 kit",
      "In my old workstation I had a 1080 which consumed 180W max.\nI replaced it with a 4070, which consumed 220W max.\nIt was right near the PSU's limit. 650W.\nA xeon e3 1275v5 with 64GB ECC RAM and 4 SSDs and 2 NVMe drives.\n\nI used to play 4k games but not everything maxed out.\nMy 4070 model was an overclocked kfa2.",
      "Oh really? Maybe it's not a PSU issue then, that was just my hunch. \nI am running a B450 Tomahawk with 5700x3d. Wonder if it's something specific to that series then??",
      "I've also saw someone with a MSI x670e gaming plus with that issue. It was mentioned somewhere that apparently the MSI boards are sometimes having issues with PCIE5 cards (and even setting the MB to PCIE 4 won't help). The 5070ti works perfectly fine in my friends Asrock B550 Taichi board.\n\nEverything else works great for me so far so I'm not too worried, but I'm actually considering swapping off MSI and getting a Taichi board again (they're really great)."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "low",
    "matched_keywords": [
      "rtx 3060",
      "3060"
    ],
    "title": "NVIDIA GeForce RTX 3060 to launch on February 25th",
    "selftext": "",
    "comments": [
      "Define \"launch\"",
      "Truth: ONLY the picture of 3060 will be launched.",
      "but they haven't even launched the 3080 wtf",
      "https://www.reddit.com/r/EtherMining/comments/lckvh9/got_my_rtx_3060_nonti_today_no_free_pci_slots/?utm_medium=android_app&utm_source=share\n\n...Minner has already gotten the gigabyte 3060.",
      "Fortunately he cant use it because there are no drivers available. But yes, its a very serious concern that someone got one almost a MONTH before launch.\n\nHe could sell it to plenty of folks (tech reviewers, etc ) for a massive profit im sure. I imagine someone could probably put together a driver that would get it functional.\n\n*I asked nVidia too. They were surprised I have it and tried to make me say where I bought it. Of course I didn't, I'm not a rat.*",
      "People don't mine bitcoin with GPUs, they mine ethereum.",
      "Launch...? Well let’s see about that...",
      "I’m not sure I blame them, there is such a small performance gap between the 3080 and 3090 I don’t know what they could put in that gap.",
      "Bitcoin is a specific cryptocurrency, akin to the US dollar.\n\nEthereum is another cryptocurrency, for purposes of the analogy we'll call this like the Euro.\n\nThey are similar, can be used for the same things, but they are different.\n\nAs far as mining Bitcoin with a GPU, it doesn't get done as there are \"Application Specific Integrated Circuits\" or ASICs that are specifically designed to do Bitcoin math faster than a GPU can, to the point it's pretty much useless to mine Bitcoin with a GPU.\n\nEthereum is designed to be resistant to setting up a specific chip to perform the calculations, so GPU mining is still possible and profitable.",
      "That's nice but where's the 3080ti?",
      "I know it's a joke, but the 3080 almost caught up to the 2080 Ti in the steam hardware survey so it isn't a very good one, seems pretty \"launched\" to me if you ask. It's also sitting at 50% the share the 1080 Ti still has.\n\nWhile there are shortages for several reasons, they have still managed to ship what seems to be fairly normal amounts of GPUs in this price segment.",
      "It sounds like Nvidia can't decide what the \"3080 Ti\" should actually be.",
      "even though its slower memory i wanna see how 12gigs of vram holds up on that card compared to the 3060ti and 3070",
      "I wish this website had a \"Poop\" award because I would give it to this lame ass comment every time someone says it for the last 6 months.",
      "No point in buying the card at least this year. Price will hike up to  €700 in an instant.",
      "404 - Page Not Found",
      "There's an embargo on the RTX 3060 which will end on February 19th: technically speaking on that date only \"select reviewers\" could get their hands on the RTX 3060, but we all know how these things play out. Contact your local friendly scalper for prices and availability. ;-)\n\nIf you live in Europe here's what I've been able to dig out: there is still no official release date for the RTX 3060 and, much more critical, there is still no MSRP for most third models except ZOTAC. ZOTAC apparently lists two variants for preorder, one priced at €428 and the other at €600. Please note that I haven't been able to preorder either and please compare with US pricing: who needs scalpers with these distributors?",
      "Good luck getting one, still trying to get a 3080.",
      "yeah I'm so sick of these ebay assholes selling pictures of the 3000 series",
      "Prepare your Anus for over 600€ price tag at Scalpernate"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "low",
    "matched_keywords": [
      "3060",
      "3060ti"
    ],
    "title": "[Guide] How to distinguish between LHR and FHR variant of RTX 3000 series cards",
    "selftext": "I see some confusion between both variant so I made this post. The infos come from various distributors, MFG representatives and so on...that I talked with.\nThis info only applicable to 3060-3080. 3060Ti/3070Ti/3080Ti are already LHR card. 3090 will not get LHR variant.\n\n+Gigabyte: LHR card will have REV 2.0/REV 3.0 text printed on the sticker, both on the box and card. FHR card do not have those text.\n\n+EVGA: P/N of LHR card end with \"-KL\". For FHR card it is \"-KR\".\n\n+Asus: REV 2.0 text on the box and card stickers for LHR. No Rev 2.0 text for FHR.\n\n+MSI: currently there is no way to tell beside testing the card with internal software or ask the distributors, they get advanced info from MSI which batch is LHR. One unofficial way is to look at MFG year/month (13th-16th number in serial number, like \"2106\") and check, 2106 and later has a high chance of LHR card.\n\n+Colorful: series or P/N end with \"L\" for LHR. FHR card is \"V\".\n\nAlso for all MFGs you can look at MFG month, all MFGs started production of LHR in Week 2, June 2021 while Asus started a week later, Week 3 June 2021. But this method is not exact.\n\nI will update this post once there are more infos. Also if you have any new infos please leave comment below.\n\n*UPDATE* : Update some info about EVGA\n\n*UPDATE 2*: Update about Colorful",
    "comments": [
      "Yes, because the 3070ti and 3080ti are all LHR models. Not necessary to write it on the box.",
      "Nvidia mandated to make it easily visible if a gpu is LHR or not. If you purchase a gpu and there is no LHR in the name of it then it is not LHR.\n\nIt's also clearly visible on the box. Every LHR gpu has LHR writing on the front of the box.",
      "My 3080 ti doesn't have LHR on the box and it is LHR by design.",
      "fucking classic horseshit consumer practices by MSI, lol.",
      "FHR = full hash rate, meaning the card has no built-in hash rate limiter (to nerf Ethereum mining). LHR = low hash rate, a card with a hash rate limiter, which has nerfed mining speed. The limiter has no effect on performance, it only affects crypto mining speed.\n\n*edit: sorry had to edit comment I explained it wrong way around*",
      ">Nvidia mandated\n\nI want that link :(  Pretty please.",
      "Sure but why not just blame nvidia.\nnvidia-  Hey guys I know you all are super wealthy so in order to keep you from updating to the latest stuff we're selling, we're going to go for a money grab, charge super high prices, and keep you from making any money off the overpriced gpu, limit the usefulness of the gpu, create more wasted silicon, because there will be no resale value, and make it harder for cheap people like Mr-coin to afford updating pc for another 10 years. We wouldn't dare encourage people to limit how many gpu's they sell, if anyone we want to sell more. How can we sell more? \n\nme- Instead of letting me pay off gpu with mining they told me to f off. Thanks nvidia, for reminding me how corporations do not care about the consumer. But at least I know nvidia helping is create an even worse bubble in the secondary market. Just prevent all mining or get bent\n\nI bought an gpu 6 years ago for $250 and they still sell above $300 on ebay. I used to play rocket league while I mined on one gpu, so f u nvidia. I guess nvidia ignored the idea that the secondary market will be even worse for gpu's for non lhr and the lhr cards will not go for resale value. Essentially creating more e-waste. \n\nIt shouldn't matter to anyone what my needs are, but come on nvidia",
      "I recently bought an MSI 3080, its non LHR and the serial has 2105 in it.",
      ">Clear Communication to Gamers\n\n\n>Because these GPUs originally launched with a full hash rate, we want to ensure that customers know exactly what they’re getting when they buy GeForce products. To help with this, our GeForce partners are labeling the GeForce RTX 3080, RTX 3070 and RTX 3060 Ti cards with a “Lite Hash Rate,” or “LHR,” identifier. The identifier will be in retail product listings and on the box.\n\n>This reduced hash rate only applies to newly manufactured cards with the LHR identifier and not to cards already purchased.\n\n\nhttps://blogs.nvidia.com/blog/2021/05/18/lhr/\n\nThere were other articles and quotes of nvidia as well, but this will do it. Otherwise google it yourself. This took me literally 10 seconds to find. It was the first result with the keywords 'nvidia lhr news'.",
      "but\n\n>+MSI: currently there is no way to tell beside testing the card with internal software or ask the distributors, they get advanced info from MSI which batch is LHR. One unofficial way is to look at MFG year/month (13th-16th number in serial number, like \"2106\") and check, 2106 and later has a high chance of LHR card",
      "Heads up!! EVGA \"KR\" cards can be LHR as well.",
      "From what I found out so far, LHR cards should have the indicator at the end of their P/N. For instance:\n\n\"ZT-A30800D-10PLHR\"\n\ncomparing to non-LHR \"ZT-A30800D-10P\"",
      "I edited the comment, I had accidentally switched the two around.",
      "At first I thought i did something wrong because I only got a little over 60 MH/s... :(I was just trying it out with my Zotac 3080 TI AMP HOLO (not an professional miner; thought I could amortize the cost of the purchase)",
      "Yeah, that’s unfortunate that Nvidia applied LHR 💩 on their cards. 60Mhz on ETH is what a RTX3070 generates before LHR. With the amount of money people paying for 3080ti, it should give them 110MHz, if not more, consider 3080ti is on par with 3090. Neither gamers nor miners gain, everyone ends up paying more. Cunning Nvidia got their end game dialled.",
      "Inno3D 3080 owner here, so what I take from this is I have a FHR since i bought it a while back in Dec 2020. What is the difference between FHR and LHR or REV 2.0?",
      "~~FHR: Full Hash Rate?~~\n\nJust saw the clarification above.",
      "My evga 3060 xc kr is lhr , nothing written on the box",
      "What about Zotac? any news?",
      "what about 10G-P5-3885-KH?"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "low",
    "matched_keywords": [
      "rtx 3060",
      "3060"
    ],
    "title": "My 1060 is officially no longer viable, looking to upgrade",
    "selftext": "I'm looking to upgrade my GTX 1060 because I'm tired of playing my games on ultra low settings. However since I'm planning to build a fully new pc in a couple years, right now im looking for a second hand GPU upgrade so I can at least enjoy my games again.\n\nLooking at other posts, it seems the RTX 3060 is definetly a good upgrade, but what price should I be looking at?\nMy current setup:\n\n- Ryzen 5 1600\n- 2x 8GB DDR4\n...\nPlaying on 2560x1440\n\nYes my CPU will be a bottleneck, so if you got any recommendations for that too, feel free to share!",
    "comments": [
      "i salute you for beeing so patient to play 1440p with a 1060\n\nthere will be a drop in replacement dependend on that your Chipset/ bios supports, but I´d guess Ryzen 3xxx should be possible at least",
      "You can get a 6750xt for a similar price as a 4060 right now. Or even a 6800xt for a bit more.\n\nNvidia 4000 is not worth buying at the lower end.\n\nPreowned 3000 series cards are an absolute steal also.",
      "Upgrade the CPU to a $130 R5 5600, just update your current motherboard bios\n\nNo Nvidia GPU makes much sense until you hit the $530 4070, due to lack of performance and VRAM for the money vs competitors but it does depend on your region\n\nUpgrades you should be considering between $190 & $530:\n\nhttps://pcpartpicker.com/list/fWNnqR",
      "4060 is trash. 8GB of Vram for 1440p is just bad. 6700xt is the same speed or faster for less money with 50% more vram despite being a generation older. 4060 is easily the worst buy of the generation.",
      "No need to even get a whole new system. Update your bios and get a 5600(x). For GPU, try looking for a used 6700xt",
      "As someone with a 3gb 1060 I tell you that you will need the extra vram for the future. Back then I was also like you thinking who would need more than 3gb for 720p, but times move.",
      ">the games just «use» the extra VRAM because it’s poorly optimized.\n\nWhich means absolutely zero. Fact remains you dont have enough vram regardless of the issue. Its entirely irrelevant.\n\nAlso thats not even true.",
      "Thx, seems like a 6750xt is the way to go in my case",
      "Source: Your anus.",
      "Looks like the best choice atm is a Ryzen 5 5600(x) and a 6750xt reading your comments, will be on the lookout for used ones.",
      "Nonsense, OP can upgrade to 5600, 5700X or either X3D chip and remove a huge CPU bottleneck.",
      "Yes because the 4060 is bad. It's a waste of silicon and shouldn't exist.",
      "Ryzen 5 1600 is socket AM4, so is 5800X3D. \nAs long as a BIOS update exists for OP's motherboard it's an in-socket upgrade.",
      "I’m still gaming in 1080p.\n\nLast year I upgraded my i5 7600 rig to a i5 12400, but kept my old 1060 6GB. My main game is Division 2 and the CPU upgrade was huge. From constant lag with 100% usage of CPU in the in game benchmark to 4% usage! Game became so smooth with the same settings!\n\nA couple of weeks ago I finally upgraded the GPU to a 4060, now that prices have dropped to more normal prices. Big upgrade, could push up settings greatly without performance loss. \n\nCPU and GPU needs to work in combo. Find your bottleneck and upgrade there. For me it was CPU more than GPU. \n\nThe 1060 is the longest lasting GPU I’ve had, from 2017 to 2024. Played perhaps not the biggest AAA titles but many hours of Division 1 and 2 and some dabbling in other games. Helldiver 2 is my jam at the moment.",
      "Get a 12Gig 3060. I used 3060 with 1600AF for a year and I think 1600 is enough for a short term use. Or you can sell it and buy a used r5 3600.",
      "There are many games that will use more than 8GB VRAM at 1440p. I have a 3080 10GB that I play at 1440p and I still run out of VRAM in some games.\n\nWhy use fake frames when you can just get that performance out of the box?\n\n4060 is simply bad value at it's price point especially considering there are options for the same money that perform better and age better.",
      "So you're probably not going to want to get rid of that mobo either. You could go with the 5600X, as long as the manufacturer has a firmware update for you to support it. Otherwise, probably go with the 7600X if you're upgrading to a modern board. If you're budget conscious, it's probably actually time to consider AMD. The 7800XT would actually give very good performance at 1440p and sits around the $550 range. Really good price and performance ratio, along with the extra VRAM over Nvidia. RTX performance is not as good, but I would only become extremely concerned about that at this point if you're buying high-end components. It's competent now.",
      "His mobo supports 5000-series lol. Follow your own advice.",
      "My motherboard *does* support a Ryzen 5 5600 to my surprise.",
      "I'm well aware of this, some games just need more than 10GB now."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "low",
    "matched_keywords": [
      "rtx 3060",
      "3060",
      "rtx 3060 ti",
      "3060 ti"
    ],
    "title": "Kinda overwhelmed picking a new gpu. Is RTX 3060 Ti 8GB ($300) still a decent card ?",
    "selftext": "Found on Craigslist so not sure if the price is firm. Is this still a good card/is price okay?\n\n\n\nI still have a gtx 950 (😭😭) and desperately need to upgrade. Really dont wanna go over 300 but I'd be willing to go a little more. There's so many cards idk what to choose lol. Any help/guidance is much appreciated!",
    "comments": [
      "that's a really bad deal imo look for a used 40 series ideally 4070",
      "Price is not worth it and 8gb of vram will hold you back with today's games at high/ultra settings. 4070ti would be the best option if you dont want to wait for a 50 series. If you must go 30 series, a 3080ti would be the best option. I would cross reference a bunch of prices for the 30 series as I was seeing people sell 3080s for $300-400.",
      "For that money you could try to get a 3080 instead, which is a lot more powerful.\n\nGenerally I wouldn't want to go for the XX60 models, especially from older generations. They don't hold up long.",
      "3060ti is a good deal at like $200..",
      "If your budget is like $300 look for a used 3080 instead. I would recommend r/hardwareswap",
      "A 3070 at that price could be decent. Or maybe the 16gb ti.",
      "If all you play is in 1440p and older games then ya it’s good. 8 go of vram will limit you a lot in current games unless you game in 1080p",
      "Way over my price range..lol",
      "Yeah I've been looking for 3080s but the only ones I've found have been way over 300 :(",
      "Yeah you'll have to actively monitor the new posts there to get good deals before other people do. People will normally price them around $400 now. Otherwise you'll find 3070s around the $300 price instead.",
      "I actually found a Msi Rtx 3060 Ventus 3x listed for $245. Think if I could get it down to 220 it'd be a good deal? I'm not looking for anything crazy i just want the ability to play modern games on medium setting lol",
      "I would say pick a model first based on your needs, then search for previous posts in the last month to get an idea of what's a good or bad price for them. That way, you can offer immediately if you see a good one pop up. Haggling doesn't work super well with GPUs given the demand for many of them."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "low",
    "matched_keywords": [
      "rtx 3060",
      "3060",
      "rtx 3060 ti",
      "3060 ti"
    ],
    "title": "RTX 3060 ti for $500 or RTX 3080 12GB for $800?",
    "selftext": "Which gpu is the better option when it comes to price/performance (Both cards are msi ventus models BTW)",
    "comments": [
      "just get the 3060 ti then",
      "it depends on your uses\n\nwhich you didn’t provide\n\nso it’s gonna be hard to determine which is good for you",
      "I have a 144hz 1080p monitor, and want to select a card that can make the best use out of it for the next 2-3 years.",
      "Go 3080 if it's available\n\nEveryone disses 1080p gaming but in the end it defeats all cards, so grab the one that'll handle it the longest",
      "3080, you'll be happy you did.",
      "I disagree. For the next two years at 1080p the 3060ti should be enough to do medium or high with Dlss",
      "For 1080p - 60ti is best value GPU on the market no question, but, be aware you are setting yourself up to be on the low end of the spectrum for performance in the coming years.",
      "The Ventus is actually trash. MSI is also absolutely not bottom tier OEM.",
      "Yeah people vastly underestimate what these cards are capable of. I'm playing 1440p high settings on a 3060 in all games",
      "Rtx 4090 ti",
      "How much does $300 matter to you?  If you make >$50 per hour or so, get the 3080.  If $300 is a lot of money to you, get the 60 Ti.   \n   \nIf you make good money, I’m assuming you’ll upgrade to 1440p in the near future",
      "You relating the 3060ti to 1080p and I'm playing my games in 4k with it...........",
      "1080ti in 2017: amazing 4k card\n\n3070 (30% better than the 1080ti) in 2020: amazing 1440p card\n\nfr everyone assumes you only play AAA games on ultra and as such you cant use anything less than a 3080 for 4k",
      "3080. You can crank everything to max including RT though believe it or not, some games will still have issues (looking at you, WD Legion) and DLSS is generally less useful at 1080p so don't count on that. But $800 is a steal for that card. It sounds like it's in your budget if you're even considering it and the 5800x3d is overkill for the 3060 ti.",
      "Would buy 3080, my 3060 ti struggle to keep 60 fps, ray tracing max at 1080p when play cyberpunk.",
      "3080 12 gb has no MSRP but theoretically should be more than $100 above the 3080 10 gb (or perhaps just about $100 over, depending on who you ask). The 12 gb is considerably faster and has more vram. $800 is a steal.",
      "Same here. DLSS really is a godsend. And even without, 1440p +80/90 fps High/Ultra is very doable in most games not named Cyberpunk 2077. I can even throw in medium RT in some games as well.",
      "If you have the money. Get the best one you can afford. With GPUs you can't really go wrong with the best one you can afford.",
      "3080 is just a safer bet and that's a great price for it.",
      "Wait wait, $800 USD for a 3080 12 GB is very cheap - which model card is this? What is the retailer?"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "low",
    "matched_keywords": [
      "rtx 3060",
      "3060",
      "rtx 3060 ti",
      "3060 ti"
    ],
    "title": "GIGABYTE GeForce RTX 3060 Ti EAGLE already on sale in Saudi Arabia - VideoCardz.com",
    "selftext": "",
    "comments": [
      "What the \\*\\*FUCK\\*\\* is going on at NVIDIAs management?",
      "annnnnnnnnnnnnnnnnnnnnd no longer allowed to distribute Nvidia hardware",
      "They have to realise that they need to have supply first in order to sell the cards. I don't understand their dumb fucking logic.",
      "30 series being traded for oil.",
      "i doubt it. [https://www.e-retail.com/](https://www.e-retail.com/) is an official Nvidia partner here in Saudi Arabia and they're selling 3070's for 800+ us dollars and 3080's 1200 USD meanwhile 3090's are 2266 USD. basically scalpers money from an OFFICIAL NVIDIA PARTNER. it's infuriating but not surprising sadly. hope Nvidia see this comment and handle the situation with them.",
      "It's real...\nVideo : https://streamable.com/k7t6uq",
      "> So their plan is to keep releasing new SKU’s instead of fixing their supply issue first\n\nyou can't use unsuitable chips for 3070/3080/3090",
      "Meanwhile, my 3080 order from September has yet to exist. \n\nKeep launching more cards Nvidia, that'll solve the problem...",
      "Caption translation:\n\nExclusive and a first in the Kingdom (of Saudi Arabia)\n\nEven ahead of the official launch",
      "So their plan is to keep releasing new SKU’s instead of fixing their supply issue first, nice.\n\nI think they’re covering every category of the market from entry to enthusiast before AMD does but what’s the point if people can’t buy them easily?",
      "I think the cameraman makes corny 80’s pornos in his free time.",
      "Its not like that particular card or the 3070 use the same chip as your 3080.",
      "These are almost the same prices as Dubai. Clearly whoever is in charge of managing MENA region doesn’t give a fuck about what the distributors and suppliers are charging from customers.",
      "It will also probably have like 4gb of vram because fuck customers",
      "Isn't 2070s nearly a 2080?",
      "3060 tis are just 3070s that weren’t good enough, they don’t affect stock",
      "I mean you are not wrong. But if the rumours are true then they are sitting on a good amount of 'defective' chips. Those are not good enough for the 3090 nor 3080 but might suffice for other products. Also same story. I'm still waiting for my september order :p",
      "nice! this is perfect for 8gb. bye 3070",
      "Wtf is that camerawork? Are they trying to pretend like we’re on a boat in rough seas?\n\nWhy so much twisting and turning",
      "agreed. FFS"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "low",
    "matched_keywords": [
      "rtx 3060",
      "3060",
      "rtx 3060 ti",
      "3060ti",
      "3060 ti"
    ],
    "title": "nvidia 3060 ,3060ti or 4060,which is better",
    "selftext": "I want to upgrade my GPU. My main purpose is training deep learning models and playing AAA titles (like RDR2).\n\nWhich one should I choose among these three options?\n\nRTX 4060 has fewer CUDA cores and less VRAM compared to the RTX 3060. RTX 3060 Ti has better raw performance than both.\n\nI have an HP 22fw 75Hz monitor and an Antec CSK 550W PSU.\n\nIf I go for the RTX 3060 Ti, will I need to upgrade my PSU to 650W?\n\nNote: I am looking to buy a second-hand GPU.\n\n",
    "comments": [
      "If you don't mind waiting longer to train models, 12GB VRAM definitely helps a lot. That said some layers can be offloaded to system RAM as well on other 8 GB GPUs, but that's quite slow. And DLSS 4 breathes some new life into old cards. \n\nOr wait for the alleged 24GB B580, but software support isn't as great as nvidia or cuda, but definitely workable.",
      "Nvidia changed the number bracket, the 60 series cards is the 50 series and the 70 series is the new 60",
      "Yes i read my post, were did i state that i said 3060ti has 12gb of vram? i literally said AI models use alot of v-ram so your generic \"12gb of vram is a waste of a card\" is utter nonsense lmao.",
      "Did you even read his post? He wants to use deep learning AI models, which uses ALOT of vram lol.",
      "I have a 4060ti and it works fine on a 650w bronze psu, the 3060ti i think is faster in most cases than a regular 4060, also the 3060 has a 12gb vram model probley helps as well, i would aim for a 4060ti, if you can stretch ur budget if not the 3060ti is probley best out of ur three options you listed",
      "3060 TI is the best",
      "For AAA Games in 2025 and especially deep learning: VRAM, VRAM, VRAM, VRAM. For ML 8G is basically unusable, 12G is manageable, 16G is decent, 24G is good. For AAA Gaming 8G was tight in 2022, in 2025 its too little. 12G is enough.\n\n\nBest bang for your Buck ML GPU is likely used 3090, 2080ti, 3060 12G. In that order.",
      "Or forgotten, series, 2060, 2080 rtx🤔🤔",
      "If u thinking about training models, 12GB will be much better, for playing 3060ti probably best, but only 8GB is another issue on its own.\n\nAnd the 4060 is a trap, it has gimped PCI speed, so u need to consider what motherboard u have too use it, many still have pcie 3, so in that case 3060 will still be better or the same.",
      "none of them are worth your attention unless u buy used and found one dirt cheap",
      "Thanks everyone for the advices. I bought the 4060 selling my 1650",
      "3060 ti - no need to upgrade psu",
      "For deep learning I agree. The gaming part however is simply not true. A 3060Ti will still outperform the 3060 by a significant margin in like 95% of scenarios.",
      "but doesnt it draw 200w?compared to 4000 series which has lower watt consumption",
      "Depending on the scenarios, you look. But for new games in 2025, 8GB is a no-go for me. And also testers advise against such low VRAM in 2025: [https://videocardz.com/newz/pcgh-demonstrates-why-8gb-gpus-are-simply-not-good-enough-for-2025](https://videocardz.com/newz/pcgh-demonstrates-why-8gb-gpus-are-simply-not-good-enough-for-2025)",
      "3060ti is only 8gb, 3060 is too slow to need 12gb so it’s a waste of a card",
      "Brother did you read your post? They never made a 12gb 3060ti"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "low",
    "matched_keywords": [
      "rtx 3060",
      "3060"
    ],
    "title": "[LTT] I'm still mad… but buy it anyway - RTX 3060 Review",
    "selftext": "",
    "comments": [
      "Trash card that in reality should have been the RTX 3050 Ti for 160$",
      "Damn the 3060ti looks like an absolute BEAST in comparison",
      "the lowest 3060 I can find is only $30CAD cheaper than the 3060ti FE. $30 to go from 2060s to 2080s performance is more than worth it",
      "After seeing how good Ampere is on the upper end (stock issues aside) I'm surprised how bad the 3060 is, even if it was available at MSRP. Would have been good at $250, but we know we won't ever see that. And yeah wtf it consumes as much as a 1080.",
      "You got a 3060 and didn't even realize it",
      "Because it is. It's only like 15% behind the 3070 which already matches stock 2080 ti performance.",
      "what does that have to do anything with the review of the gpu\n\ni guess different priorities",
      "This card makes no sense at its 329$ msrp. Specially when comparing the 399$ 3060ti which is a lot better.",
      "I just wanna finish my first build man...",
      "Imagine caring this much what others watch....honestly, it's pathetic.",
      "Yep, this should be a 3050.  It's out of place when the 3060TI outclasses it for not much more money.  3060TI is almost as good as a 3070 (which is on par with 2080TI), whereas this is closer to a 2060.\n\nYou can make a case for picking a 3070 over a 3060TI (TI is the better value overall, but 3070 is still worth it), but there's no reason to get a regular 3060 when the 3060TI is so much stronger for not much more money.\n\nThis is of course assuming there is supply.  Which is another issue.",
      "Wonder what this means for cheaper cards. The days of the 1060 6gb for $250 are long gone...",
      "Yeah... 3060Ti costs just 70$ more and much more powerful.",
      "Incel",
      "> 3060Ti costs just 70$ more\n\nFind me a $329 3060. Even before scalpers and retailers jack up the price above MSRP.\n\nI'll wait....\n\nIn reality, this card costs more than the 3060Ti (which is still $399 for the FE if you're lucky enough to get it at MSRP), which is just bonkers-insane.",
      "Sad thing is most manufacturers are charging 500 *before* scalping",
      "I like how he says \"Go upgrade your GTX 1060\", when I got mine 1060 for 100$, and 3060 is already being sold by local shops for 1000$+. Even though it's only 2x as powerful as a 1060.\n\nI guess instead of getting exponential performance growth we are supposed to get exponential price growth now.",
      "I thought i'm the only one, this card seems like a huge dissapointment. It's between 2060/2060S, only in RTX it pulls ahead more, being barely better than 2060 which was panned for crap price/perf is a dissapointment in my book. After the top end (3080/3070) was a decent gain this seems even worse, it jump from 3080 being +20% over 2080ti and 3070 being 2080 Super to 3060 being between 2060 and 2060 Super? What the heck",
      "I think I still have my old BFG 9600GT in the basement if you're interested.\n\n^^^^/s",
      "Inshallah."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "low",
    "matched_keywords": [
      "rtx 3060",
      "3060",
      "rtx 3060 ti",
      "3060 ti"
    ],
    "title": "VideoCardz: \"NVIDIA officially launches GeForce RTX 3060 Ti with GA103-200 GPU\"",
    "selftext": "",
    "comments": [
      "Probably won't do much one way or the other in terms of performance or general availability.  Not that I have a problem with it, as it's always good to have more opportunities for less-than-perfect GPU dies from Samsung to get put into a retail product instead of just thrown away.",
      "how dare you express a reasonable opinion. you're supposed to be shouting at nvidia to make more GPUs instead of releasing new ones!",
      "3060TiTi",
      "After all these releases. Nvidia will have a Ti model for the majority of each series.",
      "Just a desperate move to get cards into production so they can be sold at way above reasonable prices because scalpers have been allowed to drive up prices.",
      "The almighty 3060 tie tie",
      "Yeah let me know when I can get any graphics card at msrp.",
      "Ehhh, 3080 12GB and other shady shit like that definitely falls into that category... but this is a bit different, they're rejected laptop dies being turned into midrange desktop cards. Yeah they'll be selling for way too much, but the alternative was just leaving them in a warehouse while there's still no cards on the shelves. I'm not interested in this card, but it's not like just throwing these dies into the trash is going to somehow alleviate supply issues.\n\nAlso that amount of deactivated cores is fucking hilarious.",
      "From WCCFTech:  \n> The NVIDIA Ampere GA103 GPU is a power-optimized SKU that sits between the GA104 and the GA102 GPU cores. It was officially intended for the mobility segment in the form of the GeForce 3080 Ti chip since the GA102 GPU was a bit too power-hungry for the laptop platform. The chips that aren't making their way to the GeForce RTX 3080 Ti mobility GPU end up recycled by NVIDIA for their GeForce RTX 3060 Ti lineup.",
      "Im pretty sure defects still happen late in a production span. Chiefly due to silicon impurities, contamination, and human error.",
      "you’re thinking of the 2060KO being a cut down 2080. i think it was also an EVGA exclusive.",
      "Its not a new GPU, well its a new die for the 3080Ti on mobile but the config used for the DT 3060Ti using this die is the same\n\nIts just die reuse, like how the 3050 desktop uses GA106 (and will use GA107 later)\n\nNvidia has a tendency to do this alot, 1650 with TU116 and TU106 are out there for example\n\nIts not a really issue although these different dies may offer a slight different power profile due to binning and stuff",
      "I figure that NVIDIA must've had a reason to break with precedent and design an intermediate G*x*103 die, which I don't recall ever happening in any previous architecture.  From there it only makes sense for NVIDIA to find some additional fallback uses for slightly-defective chips.\n\nOf course it's also easier to be this laid-back about the news seeing that I already managed to buy a 3060 Ti for $460 via the EVGA Queue.  Perhaps I'd be somewhat less understanding if like many others I'd spent dozens to hundreds of hours fruitlessly chasing down a quasi-affordable Ampere GPU, though.",
      "3060 Tiddy Edition",
      "Yields arent just \"working\" or \"not working\" chips, GA103 is for laptops so the binning is biased to efficiency so any chip that is remotely leaky gets thrown at this\n\nBeing the 3060Ti config, ensures that basically any \"bad bin\" in any sort of yields (leaky or not working portions) can be easily cutdown and reused",
      "What queue lol",
      "Feel like expecting the FE price is extremely unrealistic at this point.",
      "Yeah, that's the one I was thinking of.",
      "People just refuse to be reasonable, I've put some cards for sale for less then the scalpers with the intention of investing in more effeciant ones and Im always getting people offering below what it would cost retail because \"they don't mine.\" well.... good for you I guess? but you not mining with it to make your money back doesn't make the card less valuable to me.",
      "so what would you want? random core counts on every box?\n\nthat would make the scalper's market even worse."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "low",
    "matched_keywords": [
      "rtx 3060",
      "3060"
    ],
    "title": "NVIDIA GeForce RTX 4060 is on average 23% faster than RTX 3060 12GB in 3DMark tests - VideoCardz.com",
    "selftext": "",
    "comments": [
      "It should be faster than a 3060ti...",
      "Not bad performance uplift. but this whole generation's products seem like they're named 1 higher than they should be.",
      "i dont think they care about gamers to bring prices down to normal again.",
      "Let's do some math. \n\nIf the 4060 is 23% faster than the 3060 for 9% less money($330 -> $300), that means it offers a 35% increase in price to performance. \n\nFor reference, the much loved 1060 was 71% faster (TPU database) than the 960 for 50% more money ($200 -> $300), giving it an 18% increase in price to performance.\n\nAnd this is before taking into account record inflation over the last couple years.",
      "Baffled by this card, don't see why anyone would buy it when they could get a 3060 ti for cheaper.",
      "Even without any power limits the 4090 rarely pushes up to 450w though while delivering much better performance than the 3090ti. Ada is just much more efficient than ampere.",
      "23% increase for like 55W less power and new features, at a lower price (because of inflation) -seems good.",
      "if it's actually 20%+ faster in games, kinda impressive from those specs and makes the 4060ti look weird and show just how memory bandwidth limited it is. Now the pricing+naming is a whole other topic...",
      "Vram and memory bus will be a problem above 1440p, but who realistically buys this thing to play at 4k?",
      "the performance jump in recent gens is mostly because you get a whole lot more CUDA cores. The free node jumps are over so you no longer get more CUDA cores at lower prices. That's really it. In fact you are getting less with this one.",
      "What about it looks good?",
      "So you think higher wattage is a good thing? The lower the wattage, the better, because this means lower power consumption, less noise, less heat in the room and more reliability for the GPU. Best is as much performance as possible with as little wattage as possible.",
      "Maybe you should start practising writing before assuming this...",
      "960 > +72% > 1060 > +59% > 2060 > +19% > 3060 > +23% > 4060\n\n970 > +47% > 1070 > +37% > 2070 > +50% > 3070 > +31% > 4070\n\n980 > +51% > 1080 > +39% > 2080 > +63% > 3080 > +49% > 4080\n\n980Ti > +67% > 1080Ti > +28% > 2080Ti > +56% > 3080Ti > ~49% > 4080Ti\n\n\n\nLook at how the growth of xx60 series stagnate due to the 960 to 1060 to 2060 leaped forward too much. It is cheaper at $299 ya sure, but then it's going to be very limiting due to the 8GB VRAM and it won't age very well.",
      "Not gonna lie, it looks good for a 299 card",
      "Idk i think the 4080 and 4090 are named accordingly but the 4080 was just priced too much. The 4070 ti can match the 3090 ti which is good for a 70 card but again like the 4080 its priced bad.",
      "No it s bad because it s not even faster than a 3060 ti which is the first time it happens where a 60 class doesn t beat the previous 60ti",
      "No, you should have written a grammatically correct sentence.",
      "Only 1060 FE was 300, AIB started at 250",
      "Then there's the $500 4060ti 16GB lol."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "low",
    "matched_keywords": [
      "rtx 3060",
      "3060",
      "rtx 3060 ti",
      "3060 ti"
    ],
    "title": "3060 or 3060 TI for 1080p as much future proof as possible?",
    "selftext": "Hi,\nSo I'm building new pc and trying to decide between these two cards. The only thing that stops me from picking 3060 TI is less vram than 3060(12). Meanwhile the TI has 8. I heard that more vram is more future proof? I know that TI has better performance overall. Not sure which one to pick.\nHere is my build :  https://de.pcpartpicker.com/list/bhBgZw.\n\nNow the prices : \n Gigabyte GeForce RTX 3060 GAMING OC 12G \n462€\n\nGigabyte GeForce RTX 3060 Ti|8 GAMING OC 8G (rev. 2.0), 8 GB, GDDR6\n600€",
    "comments": [
      "Despite the VRAM difference I believe the 3060 Ti will have more longevity because of it's better raw performance. The 3060 can't really fully utilize 12 GB VRAM, yes it's possible to fill it, but usually only when playing games at 4K resolution at higher settings, and the card isn't really fast enough for that anyways.\n\nAlso, when playing games with DLSS enabled, the VRAM usage is reduced and that will also help the 8 GB 3060 Ti last a while.\n\nKeep in mind that most popular games are developed with consoles in mind, and both PS5 and Xbox Series X have about 16 GB shared memory (divided between system RAM and VRAM), so most games being developed in the next 2-3 years will be targeting about 8 GB VRAM max for \"medium/high\" settings. We probably won't see many games push past that until the next generation of consoles surface in a few years, and even then, most games will be build for backwards compatibility with the current consoles of today for at least a year after the next gen consoles launch, so they still should work fine. In addition to consoles, the vast majority of gamers have 8 GB VRAM cards now so game developers will be sure to make games that work on 8 GB VRAM just fine, because they don't want to lose those sales by having too-high system requirements.",
      "Haha you convinced me. I will stick to 1080p. And maaaaaaaaybe 1440p, but probably not. I guess TI is the way to go.",
      "Even with a 3090 Ti there is no such thing as futureproofing... future prolonging in the other hand...\n\n&#x200B;\n\nI'd still say go for the 3060 Ti.",
      "The 3060ti is actually much better than the non ti. I think that's the minimum if you are going to get a 3000 series tbh",
      "3060 if you're a creative/gamer. 3060 ti if you're just a gamer. The extra vram is crucial if you open an app like Unreal Engine. I use over 9gb just opening some levels.",
      "is not useless, it's a pretty darn good card for entry level Machine Learning, 3D rendering and other lines of work",
      "Ty kind sir.\n\nI have my son running an EVGA 3060 Ti and he plays a lot of games in high settings, doesn't complain about anything. \n\nMy daughter is due for a 30-Series card, currently running a 1660.",
      "Sweet family. Also is I5 12400F good for 3060 TI? I know it's great for 3060, but what about TI?",
      "Definitely 3060 TI",
      "The vram in the 3060 is slower",
      "Pound for pound, dollar for dollar. The 3060 ti is an amazing card. And in the future if you do decide to get a 1440 it can do it fine too. You won’t max it but I had one and loved it.",
      "I see both of these cards having amazing longevity. The Ti with the less VRAM is more powerful, there is a lot of reason for these. \n\nRegardless, the 60 series of GPU's are the most common GPU. The 1060 is still the most used card on steam.\n\nUnpopular opinion for some reason. A 3060ti and a decent cpu is more powerful then a PS5 or XBX",
      "12 GB on 3060 is useless. Card isnt able to utilize it fully as rest of the components cant keep up. 8 is enough so go for 3060 Ti as long as you want just 1080p or occasional 1440p gaming",
      "future proofing is kind of pointless. theres no statistical proof that spending **more money** nets you more performance over a long period of time.\n\nthe more you spend the less you get, usually. from 0 to an actual gpu at the bottom line is a huge jump, low range to mid range is a large jump, mid range to high range is a not very big jump and very expensive.\n\ngpu's get cheaper over time, both on the used market and overall. \n\njust get what you can afford and fits your use case. i would reccomend the TI. most games are still and will likely still use less than 8gb of vram. im making this judgemnt based on the ram available in consoles, as well as consoles push for faster storage rather than more memory.",
      "If you're wanting to future proof, I'd be holding off the build for another 3 or 4 months and buying into a 13gen DDR5 system with a 4060 (or amd equivalent). \n\n\nThe concept of future proofing isn't all that great, there's always something faster around the corner, but you're almost at the start of a new gen.  Might as well get the most for your dollar.",
      "I will go for 3060 ti for sure.",
      "Uh, probably every possible category lol. I'm more of a student and I don't have much time for gaming. I would play for example csgo, warzone, sea of thieves,battlefield, dying light, skyrim,apex,pubg,AC,MGR, gta V, KSP, maybe rdr2 if I can afford it lol and some other games.",
      "Aight, thanks. Ur pc specs dang, beast.",
      "Well for now they won't use anything like that, but in the future about 2-3 years there might be higher vram usage.",
      "I would make the step up to the 3070, for 50 euro I think that's worth it, if you can swing it. I have never used a Gigabyte Eagle 3070 but I'm sure they are fine if you aren't trying to overclock it. I have a gigabyte 1660 Ti in one of my computers and it's been perfectly fine. If it's noisy, you can easily lower the power limit with the MSI Afterburner software (works on all cards, Gigabyte included), and make it run quieter while still outperforming the 3060 TI."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "low",
    "matched_keywords": [
      "3060",
      "3060ti",
      "3060 ti"
    ],
    "title": "RTX 4090 Undervolt, UV + OC, OC and PL Limit on 7 Synthetic benchmarks, 6 games and vs RTX 3080",
    "selftext": "Hi there guys, as always I do with my newer GPUs, like of the 3060 Ti, [here] (https://www.reddit.com/r/nvidia/comments/lzd8mz/rtx_3060ti_comparison_with_stock_undervolt/), which was a 3060Ti Gaming OC Pro with 270W max TDP, or the 3080 [here] (https://www.reddit.com/r/nvidia/comments/qmv37w/rtx_3080_shunt_modded_comparison_with_stock/), which was shunt modded (480W).\n\nNow I did the same, but with the RTX 4090 ASUS TUF non-OC, which by default comes with 450W Power limit and 600W max, with 4x8 pin connectors (or 12vhpwr)\n\n**NOTE: I have a Ryzen 5 5800X, which IS BOTTLENECKED at 4K in some games, and at 1080p in some benchmarks, so I made my best to make the GPU usage to be pegged at 99%**\n\n**NOTE 2: My TUF 4090 is an way below average overclocker, so if you have a good chip, you will get better results**\n\n**Driver used was 522.25**\n\nThe tests were made trying to do always the same conditions, but sometimes the ambient temp did a part. Also spent about some days testing the stability of the undervolts and overclocks. (same as the 3080, this took a lot of time)\n\nImportant to mention that I do, as you may know as **Undervolt Method 2**, which is undervolting by moving the curve, and not individual points. Because this, there isn't the effective clock issue with Undervolt Method 1.\n\n**The profiles are these and will be used on the tables:**\n\n* **Stock**: Stock is 2700 up to 1.05V, which is probably on the low end of the binnings. At stock, I've never seen above 450W besides benchmarks. No Perfcap reason.\n* **PL Limit 78% (350W)**: Basically same as stock, but with power limit set at 78% for 350W, since this was requested. Percap reason is Pwr.\n* **Undervolt**: 2745Mhz at 0.975V. +1000Mhz on VRAM. No Perfcap reason.\n* **Undervolt + Overclock**: 2830Mhz at 0.995V, No Perfcap reason and +1000Mhz on VRAM.\n* **Overclock 1**: 2940Mhz at 1.05V, +1000Mhz on VRAM and Perfcap reason is VRel and VOp.\n* **Overclock 2**: 3030Mhz at 1.1V, +1000Mhz on VRAM and Perfcap reason is VRel and VOp.\n\nThe benchmarks software used were:\n\n* **3DMark FireStrike** (1080p, small **CPU** bottleneck)\n* **Unigine Superposition** 1080p Extreme: (**CPU** bottleneck)\n* **3DMark SpeedWay** (1440p, small **CPU** bottleneck)\n* **3DMark Port Royal** (1440p, **GPU** is the bottleneck)\n* **3DMark TimeSpy** (1440p, **GPU** is the bottleneck)\n* **Unigine Superposition 4K Optimized** (**GPU** is the bottleneck)\n* **3DMark TimeSpy Extreme** (4K, **GPU** is the bottleneck)\n\nFirst let's start with the synthetic benchmarks, and the gain/loss in percentage.\n\n|RTX 4090 TUF (non-OC) (Points)|Stock|PL 78% (350W)|Undervolt|UV + OC|Overclock 1|Overclock 2|\n:--|:--|:--|:--|:--|:--|:--|\n|3DMark FireStrike|85620|85763|85342|86752|89018|90331|\n|Superposition 1080pE|21420|21302|21105|21551|22334|22713|\n|3DMark SpeedWay|9941|9679|10122|10292|10508|10626|\n|3DMark TimeSpy|36843|36522|36545|37195|38109|38584|\n|3DMark Port Royal|25969|25262|26427|26948|27510|27786|\n|3DMark TS Extreme|19608|18965|19779|20065|20735|20946|\n|Superposition 4KO|33978|33271|34980|35359|36098|36215|\n|Average|**100.00%**|**98.29%**|**100.69%**|**102.37%**|**105.04%**|**106.22%**|\n\n\nYou can see the UV gives roughly the same performance, or a little bit better, but later with the table temps, you will notice why this is worth (as it was the case with the 3080). OC 2 is likely stable in like 99.9% except on Port Royal, where the clocks were 15Mhz less to make it not crash.\n\nNow, for the games, are these ones with settings:\n\n* **Control**: 4K, maxed and maxed Raytracing, no DLSS.\n* **Cyberpunk 2077**: 4K maxed, RT Psycho, no DLSS. \n* **Modded Skyrim**: 4K with ENB series, **there is CPU bottleneck**.\n* **Shadow of the Tomb Raider**: 4K maxed, RT shadows, no DLSS, **there is an small CPU bottleneck**.\n* **Forza Horizon 5: 4K maxed**: \"RT\" enabled, no DLSS, **there is CPU bottleneck**.\n* **Metro Exodus Enhanced Edition**: 4K maxed, RT at extreme, no DLSS, **there is CPU bottleneck**.\n\nThe results and gain in percentage look like this:\n\n|**RTX 4090 TUF (non-OC)**|Stock|PL 78% (350W)|Undervolt|UV + OC|Overclock 1|Overclock 2|\n:--|:--|:--|:--|:--|:--|:--|\n|Control|70.5 (100%)|70.5 (100%)|74.2 (105%)|75.2 (107%)|76.6 (109%)|77.3 (110%)|\n|Cyberpunk 2077|38.67 (100%)|37.22 (96%)|38.96 (101%)|39.64 (103%)|40.53 (105%)|40.85 (106%)|\n|Modded Skyrim|104 (100%)|104 (100%)|105 (101%)|107.2 (103%)|109 (105%)|110 (106%)|\n|SOTTR|109 (100%)|109 (100%)|111 (102%)|112 (103%)|116 (106%)|117 (107%)|\n|Forza Horizon 5|107 (100%)|107 (100%)|108 (101%)|109 (102%)|111 (104%)|111 (104%)|\n|ME: Enhanced Edition|70.82 (100%)|69.61 (98%)|72.02 (102%)|72.72 (103%)|74.62 (105%)|75.03 (106%)|\n|Average|**100.00%**|**99.09%**|**101.90%**|**103.26%**|**105.63%**|**106.35%**|\n\n\n\n\nHere you can see that the gains on Control and Cyberpunk are among the higher ones (where there is no CPU bottleneck), but the rest drag the average to be lower.\n\nAnd the gains only on CP2077 and Control look like this:\n\n|RTX 4090 TUF (non-OC)|Stock|PL 78% (350W)|Undervolt|UV + OC|Overclock 1|Overclock 2|\n:--|:--|:--|:--|:--|:--|:--|\n|Control|70.5|70.5|74.2|75.2|76.6|77.3|\n|Cyberpunk 2077|38.67|37.22|38.96|39.64|40.53|40.85|\n|Average|100.00%|98.13%|103.00%|104.59%|106.73%|107.64%|\n\n\n\nNow, averaging both, it would look like this.\n\n|RTX 4090 TUF (non-OC) Average %|Stock|PL 78% (350W)|Undervolt|UV + OC|Overclock 1|Overclock 2|\n:--|:--|:--|:--|:--|:--|:--|\n|Benchmmarks|100.00%|98.29%|100.69%|102.37%|105.04%|106.22%|\n|Games|100.00%|99.09%|101.90%|103.26%|105.63%|106.35%|\n|Total|100.00%|98.69%|101.29%|102.81%|105.34%|106.28%|\n\n\nNow, one of the most important metrics: temps and power consumption.\n\n|Temps and Power usage max load (TimeSpy Extreme 4K), fans speed = temp + 20|Stock|PL Limit 350W|Undervolt|Undervolt + Overclock|Overclock 1|Overclock 2|\n:--|:--|:--|:--|:--|:--|:--|\n|Max Power Usage|450W|350W|370W|400W|470W|560W|\n|Max temperature [Core]|57°C|52°C|53°C|55°C|60°C|66°C|\n|Max temperature [HotSpot]|69°C|64°C|66°C|68°C|73°C|82°C|\n|Max temperature [VRAM Junction]|65°C|62°C|64°C|65°C|70°C|78°C|\n\n\n------\n\n|**Temps and Power usage max load (Cyberpunk 2077 4K), fans speed = temp + 20**|Stock|PL Limit 350W|Undervolt|*Undervolt + Overclock*|Overclock 1|Overclock 2|\n:--|:--|:--|:--|:--|:--|:--|\n|Max Power Usage|400W|350W|350W|370W|420W|500W|\n|Max temperature [Core]|55°C|52°C|52°C|54°C|59°C|61°C|\n|Max temperature [HotSpot]|67°C|64°C|64°C|66°C|70°C|78°C|\n|Max temperature [VRAM Junction]|63°C|62°C|64°C|64°C|67°C|74°C|\n\n\nThe results link are OMW, since I'm stupid and forgot to save some, so gonna re do it some tests again and post them.\n\nThe 3DMark comparisons links will be here soon.\n\nNow, against the 3080, the 4090 looks like this on Stock, UV + OC and OC (3080 Shunt modded) on benchmarks.\n\n|RTX 4090 vs 3080|TUF 3080 Stock|TUF 4090 Stock|%4090 on 3080 (Stock)|TUF 3080 UV + OC|TUF 4090 UV + OC|%4090 on 3080 (UV + OC)|TUF 3080 UV + OC|TUF 4090 UV + OC|%4090 on 3080 (OC)|\n:--|:--|:--|:--|:--|:--|:--|:--|:--|:--|\n|3DMark TimeSpy (Graphics score)|17658|36843|**208.65%**|18283|37195|**203.44%**|19936|38584|**193.54%**|\n|3DMark Port Royal|11547|25969|**224.95%**|11740|26948|**229.54%**|13090|27786|**212.26%**|\n|3DMark FireStrike (Graphics score)|42991|85620|**199.16%**|43655|86752|**198.72%**|48642|90331|**185.71%**|\n|Superposition 1080pE|11076|21420|**193.39%**|11386|21551|**189.27%**|12078|22713|**188.05%**|\n|Superposition 4KO|14872|33978|**228.47%**|15303|35359|**231.06%**|16538|36215|**218.98%**|\n\n\n---\n\n|RTX 3080 vs 4090|Average% 4090 gain|\n:--|--:|\n|Stock|210.92%|\n|UV + OC|210.41%|\n|OC|199.71%|\n\n\n\nWhat do I use daily:\n\n* Most of the time, UV + OC, same power consumption or less, for a little more performance.\n* Also the temps are so good, that OC1 or OC2 are not an issue, but they're not needed and the increase of power is not worth.\n* **Similar as the 3080, in zero cases I use stock**, it's way better to undervolt the card, or overclock if you're aiming for the best performance possible.\n\nI hope all these info helps someone which is looking for undervolting, overclocking or both on their RTX 4090.",
    "comments": [
      ">**PL Limit 78% (350W)**: Basically same as stock, but with power limit set at 78% for 350W, since this was requested. Percap reason is Pwr. \n\nAn interesting comparison for the 7900 XTX",
      "For Port Royal Only\n\nStock vs +1500 Memory vs +195 Core + 1500 Memory vs 0.950V @ 2745 +1500 Memory\n\n[https://www.3dmark.com/compare/pr/1863534/pr/1863684/pr/1863656/pr/1863716](https://www.3dmark.com/compare/pr/1863534/pr/1863684/pr/1863656/pr/1863716)\n\nFor the 4090, you get more from OC memory for this generation.\n\n[Memory OC alone (+1500 Mhz) = +9-10% in performance](https://www.3dmark.com/compare/pr/1863534/pr/1863684#)\n\n[Core OC +195 + 1500 Mhz Only added 3.2% more](https://www.3dmark.com/compare/pr/1863684/pr/1863656)\n\n**The silicon lottery this generation is in the memory.**",
      "Im too afraid to oc my card until I get myself a proper sf psu haha",
      "I think except for the adapter issue, if they added an ECO mode out of box this would have been a pretty good launch.\n\nOverengineered cooler designs are still an advantage, especially with a healthy undervolt. \n\nAt 60% power limit my fans barely turn on",
      "I've come to the same conclusion.\nI'm unsure as to where the average sits, I think the best IMC/memory cards are around +1700 on the memory?\nBest mine can do is 1550, 1600 artefacts in benchmarks.",
      "My TUF also has han horrible coil whine, fixed it by putting outside my room lol\n\nAlso it coils whine undervolted, but wayyy less than stock.",
      "Not when you compare 78% to 100%.",
      "I’m running my FE at .95mV and 2745mhz. Works great. However it runs at 2730mhz, no matter how many times I redo the UV + OC on afterburner. Hits about 350 watts. Plus or minus 10 watts. I haven’t messed with the memory but maybe I’ll try +1000 as you did and work from there.",
      "I’m running UV .975mv with 2800mhz on core clock and +1500 vram and no problem whatsoever. Highest wattage I’ve seen probably 380w so I’m satisfied with it.",
      "long story short. Set power limit to 74% - 78%, watch 100-150W drop in power for 2% perfm drop...in synthetic, and if u want 2% more o/c. :D  \n\n\nWhat i find funny is nvidia could have targeted 350W and still would have had no competition at the top tier from AMD, while also being able to boast about power efficiency.  \nCooler design could have been smaller to reduce cost, and not require vertical brackets or squished cables or adaptors melting (if they just slap 2x8pin)...but i guess someone had to shat the bed :D",
      "Also very interesting on its own, with up to 100W of power giving you only 2-4% performance.",
      "It would probably be a bit worse than UV, since overclocking VRAM increases power consumption by 30W (+1000Mhz) or by ~40w (+1500Mhz)\n\nSince the PL is reduced, the power will have to battle between the core and the VRAM.\n\nBut it probably may be better than stock, since VRAM is the most important overclock on the 4090, over the core clocks",
      "quit your bullshit. as per your own comment history, you sold the gaming trio and kept the GIG OC:\n\n“I had an MSI RTX 4090 Gaming Trio that I returned because it had a good amount of coil whine and the fans were noticeably louder compared to the Gigabyte RTX 4090 Gaming OC that I now have. Can’t speak for the Aorus Master but my Gigabyte RTX 4090 Gaming OC has no coil whine at all.”\n\nyou made these comments on the same day, what a moron.",
      "Average based on overclock.net, is probably around +1500 or so. Below that is kinda bad VRAM chips (like mine), and above that is better. Some people can do +2000Mhz and get a good amount of performance above stock.",
      "+1500 seems to be the average, I think we're good.",
      "It's a bit of a mixed bag, but it's a value king for gaming. \n\nIf you don't play a large variety of games and have no production workloads, it's the best cpu",
      "That’s interesting, it isn’t always the case tho, it’s like it picks and chooses when it does this. I had it running at 2715 and that’s where it always stayed. I went up to 2745, and it stays at 2730. I closed after burner and redid the settings, bam it held at 2745, until it didn’t lol. Got sick of messing with it, but I’m gonna toss in some increased memory and set the core to 2760 to get it to stay 2745 I guess lol. Thanks for the info.",
      "It has to do with temperature(or power draw, or both), which is related to how hard the load is as some games have higher power draw at 100% gpu usage than others, like plague tale requiem for my 3080 UV was like 300-320W when not in cpu bound areas, but cyberpunk is 250-270W with dlss q, 270-290W native or FH5 is even lower than that 230-270W depending on the area, when all are at 99%+ gpu usage, so plafue tale drops the clocks by 15mhz compared to others.\n\nNow be thankful that nowdays GPU boost decides to only go down, not up like pascal UV sometimes decided \"hey let's go two steps up, because the temp is low\" when on low load, which was not great for stability, so you had to set it 2-3 steps lower than was stable rather than 0-1.",
      "Power consumption and resulting power-limited clocks vary from game to game. So you can *raise* the voltage cap to get even more performance in games that normally wouldn't reach the desired power ceiling - while ensuring that no game, or accidental power virus ever goes over the power ceiling. \n\nIn my experience on Turing, you could have a ~150MHz difference between different games. So capping it low means leaving these 150MHz on the table in less power-hungry games.",
      "The most demanding games would be around 1800MHz at 140W on my 2060, after undervolting. The Witcher 3, Scorn, many others - I don't always pay attention. Less demanding games would be Forza Horizon games, also recently Ghostwire Tokyo with DLSS and raytracing - around 1950MHz at 140W. Mirror's Edge Catalyst was somewhere in the middle as far as I recall."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "low",
    "matched_keywords": [
      "rtx 3060",
      "3060",
      "rtx 3060 ti",
      "3060 ti"
    ],
    "title": "RTX 3060 Ti Brand Comparison / Buy \"Decision\" Aid - Had some request's to do another chart for the 3060 Ti, so here it is. I have added a few different things from the previous files and will be posting an updated 3060/70/80/90 comparison with like GPU's. Hope these help with making a decision!",
    "selftext": "",
    "comments": [
      "$499 for the Strix OC with an average fram rate of 147.6. For the same $499 you can get a FE 3070 and get an average frame rate of 159.6 instead...",
      "FE winning big again in the important categories: $/frame, noise, wattage, and the fact it’ll fit in 2 slots (though not quite as big an issue for the 60 as the 70 and 80 AIB Partner cards).",
      "Just a few frames. Very minimal IMO",
      "[3080 Comparison](https://www.reddit.com/r/nvidia/comments/jvmj1o/rtx_3080_comparison_buy_aid_by_popular_request/?utm_source=share&utm_medium=web2x&context=3)",
      "Yeah, makes no sense. Very happy with my 3060, but they're only a good buy if there's a significant price gap to the 3070.",
      "[3060 Ti/3070/3080/3090 Comparison](https://www.reddit.com/r/nvidia/comments/kbgz8w/rtx_3060_ti_3070_3080_3090_same_gpu_comparison/?utm_source=share&utm_medium=web2x&context=3)",
      "Nice chart! If only they were in stock!",
      "[3070 Comparison](https://www.reddit.com/r/nvidia/comments/jw0ezh/rtx_3070_comparison_buy_aid_again_by_popular/?utm_source=share&utm_medium=web2x&context=3)",
      "Now for the availability chart",
      "It’s a solid card, look how small the differences are in FPS and standard deviation across the board.",
      "I have only added cards that have been reviewed by Tech Power Up, so as they review more cards I will add them to chart",
      "The power limits are hardcoded in VBIOS, right? Non adjustable? But thanks for the explanation, your adjustment sounds like a great improvement. Very cool!",
      "No one buys AIB models for performance, but for thermals\\\\acoustics. That Zotac card was shown to be super loud compared to the other 3060 Ti in reviews. I'd definitely pay another 40$ for silent operation and a card that doesn't run hotter than even FE.\n\nThat said not everyone cares. If you don't, fair enough.",
      "What's causing the 46W increase in power between the FE and MSI X Trio? That's such a large power increase for such a small performance gain. Not worth it in my opinion. If the power budget of the Trio X can be controlled back down to FE levels, I wonder how all the numbers would look. Thermals and noise would probably be even better.",
      "No data on the 3060ti VENTUS 2x?",
      "Boost the fan curve up and overclock core +120 and memory + 400. You should get stock Gaming X performance.",
      "Excellent chart, yet again, thanks for making and sharing.\n\nOne thing that puzzles me, which isn't really a question for you but it's on my mind: why do the boost clocks, presumably from reviews, bear no relation to what Afterburner shows when gaming?",
      "Gaming X Trio is (somehow) the 2nd cheapest 3060 Ti in my region, according to this chart and other reviews I've seen on it I think I'm gonna pull the trigger.",
      "Thanks. Those high power draw are sick with 1-2 fps gain, what a waste.",
      "Yup! I got a bit lucky in my situation and feel good getting my XC3 Black. Got the launch edition which was -$30 off the $529.99 price, then someone gave me their associate code and I paid $474.99 for my EVGA 3070. The price for performance for me is great."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "low",
    "matched_keywords": [
      "rtx 3060",
      "3060"
    ],
    "title": "RTX 4060 8GB or RTX 3060 12GB for general/multipurpose use?",
    "selftext": "Hello.\n\nI recently got a pc (went with Ryzen 7 5700G as the cpu because I didn't have the funds to get a gpu at the time) and was looking for a good gpu option for general use.\n\nThe best options I have in my price range (as well as availability) are the 4060 and the 3060 12gb brand new.\n\nI don't play recent game releases that demand a lot of vram and only plan to play at 1080p at best. I'm currently playing Monster Hunter World at a low resolution with average 55fps but would like a higher resolution.\n\nI consider any fps past 60 as amazing.\n\nI'll be testing the gpu with Batman: Arkham Knight at max, maybe Control at whatever the gpu limits are at.\n\nI'll also be using it for stuff like video editing, UE5 (for mostly basic stuff since I'm just starting out), and anything else that would benefit from a dedicated gpu.\n\nFor the price range, the two are roughly similar in pricing and are available in the shop I frequently visit, and I don't plan on upgrading for a while since I'll be saving up for an eventual AM5 build which will definitely have high-end specs and gpu.\n\nThanks in advance.\n\n**Update:**  \nAfter reading and answering some comments, the 4060 looks to be the better choice.  \nI've also done a bit more reading myself and came to the same conclusion myself.\n\nI'll be checking the comments a bit more for the next few days then finalize my choice once I have decided when I'll buy the gpu.\n\nThanks everyone!",
    "comments": [
      "A cheap, maybe even second hand, 3060 will work until you do your planned new build.",
      "It seems like OP is sticking with 1080p. Does video editing at 1080p hit VRAM limits at 8GB? The 4060 supports AV1 video encoding and DLSS frame generation for gaming, so I think I’m leaning the opposite direction overall (assuming similar price).",
      "/u/CompetitionStatus646\n\n>The 4060 isn't much faster\n\nIt is, actually. It's faster in >85% of games, and in 1080p it is significantly faster across the board.\n\n>the VRAM really helps with your editing\n\nNo, it doesn't. It's RAM that matters, not VRAM. You can get away with 2GB cards if need be, though 4GB is recommended in general. The computing power of the 4060 *will* help, though. It's significantly faster in synthetic applications. It also consumes a third less power.",
      "Question: are the 3060 and 4060 you’re looking at close in prices, or are they both just in your price range with a gap? If they the same price, I’d actually recommend the 4060 for a few minor reasons (AV1 encoding for video, DLSS frame gen for gaming, etc). If there’s a price-gap between the two, then the 3060 is better. For general use, the extra features aren’t worth a premium unless you know a feature would be worth it.",
      "The 4060 also uses about 2/3 the power at full tilt, compared with the 3060. It'll probably also get new drivers for longer. \n\nFor an extra 20USD, it would be my preference.",
      "will the extra money spent on the memory be enough to push your options to a 4070? id rather have 16gb RAM with a 4070.\n\nif not, the 3060 is better now, but with how good framegen is becoming,  the 4060 might last longer just on feature set alone",
      "That is just plain misinformation. VRAM only matters in specific applications that need to load in a lot of data at once, i.e. Blender with a ton of assets or high resolution textures. That's pretty much the only scenario where a 3060 12GB can beat a 3060 Ti. What matters more in general is raw computing power, where the 4060 wins.\n\nAlso, you should read OP's post properly instead of skimming through it. They are playing older games in 1080p, in which case the 4060 shits all over the 3060.",
      "fair enough, but once again, at 1080p, the 4060 and 3060 are very, very close in performance,  but the 4060 has the advantage of framegen that will only improve. At 1080p the 8GB VRAM of the 4060 will not be an issue. personally, i would get the 4060 just because of DLSS3 and its long-term implications as well as extended driver support",
      "I read this all over this thread. Do people on reddit genuienly not know that the 4060 is faster than a 3060?\n\nRoughly 15%.",
      "Ventus on 3000 series is pretty bad.\n\n4060 is a better GPU: https://www.tomshardware.com/pc-components/gpus/rtx-4060-vs-rtx-3060-12gb-gpu-faceoff\n\nBut the question is whether you think you can fit your work into 8gb of VRAM.",
      "Thanks! I'll keep that in mind",
      "The price gap is around 20 USD converted.\n\nI don't really see myself playing games like Hogwarts Legacy which need powerful gpus to make the most out of, and I'm not sure how much difference it makes when it comes to the 4060 features.\n\nBoth gpu options are MSI Ventus 2X, and changing brands will definitely make the price gap bigger.",
      "You mentioned Control as an example game so I figured there was a chance you might play with some light ray-tracing in games, even if you’re not playing the most demanding ones. Regardless, DLSS features are nice because they help GPUs stay useful longer. A “less demanding” game 5 years from now might be equivalent to a “more demanding” game right now, ya know? Both GPUs get DLSS upscaling, but only the 4060 gets DLSS Frame Gen. If the extra latency isn’t an issue with the game you’re playing, Frame Gen probably preserves image quality better than upscaling at 1080p.\n\nUltimately, with a $20 difference, the main question is if 8GB is “enough” VRAM or if the 12GB 3060 would be better. If you’re sticking with 1080p for both gaming and video editing and you’re not planning anything super ambitious with UE5 (or Blender/etc) for now, I think 8GB should be sufficient. It’d also be sufficient for video editing small amounts of 4K footage - just not a ton of 4K.\n\nEdit: Apparently video editing either uses primarily RAM or VRAM more depending on the software/workflow. If your workflow uses RAM more, then VRAM is less relevant even with 4K footage.",
      "The cheapest 4070 that the store is selling (MSI GeForce RTX 4070 Ventus 2X 12GB GDDR6X OC) costs around 300 USD more (actual cost is roughly 700, converted to USD), and the 16x2 ram that I plan to buy costs around 100 USD\n\n4070 simply won't be in my available budget for months, and I would benefit more from having the gpu as early as possible.\n\nWhich means the 3060 is the preferred choice by everyone so far\n\nThere's also the option of going for 7600XT 16GB for a bit more than the 4060 but idk how much difference it makes when it comes to my use case, and didn't add the option since r/nvidia",
      "Additional info that might help:  \nI have 16GB ram and I plan to add 32GB (16x2) the same day that I buy the gpu)  \nI have a 750W PSU\n\nUpdate: The GPU options are both MSI Ventus 2X with around 20 USD difference (converted)",
      "3060 12 GB has my vote. The 4060 isn't much faster and the VRAM really helps with your editing.",
      ">Which means the 3060 is the preferred choice by everyone so far\n\nI would 100% go with the 4060. Even with 20$ price difference. It's genuienly wild that anyone prefers a 3060 actually. \n\nThe 4060 is 13-18% faster, has much lower power draw and more modern features.\n\n8GB is absolutely planty for 1080p gaming. It doesn't even matter for 4k right now. The difference between a 16GB 4060TI and the 8GB version is less than 1%. Tested with over 20 modern games. This is at 4k mind you.",
      "I have a rtx 4060 and at 1080p gaming it can run pretty much anything at ultra even with ray tracing. I don't know about the 3060, but the 4060 has dlss3 frame gen and it almost doubles your fps in some cases. It is a big advantage. I can never max out the 8gb video memory in 1080p. Neither in 1440p. Maybe there are some cases in 4k. I haven't yet used it for video/photo editing. I will do it in the near future. Is it a real worth buy.",
      "Go for the 4060.",
      "4060 is gonna be the choice I believe. The GB matters but it’s sort of deceptive at the same time in this circumstance."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "low",
    "matched_keywords": [
      "rtx 3060",
      "3060",
      "rtx 3060ti",
      "rtx 3060 ti",
      "3060ti",
      "3060 ti",
      "rtx 3060ti"
    ],
    "title": "Planning to upgrade GPU",
    "selftext": "My system is \n\n\n\nAMD Ryzen 5 5600X 3.7 GHz 6-Core Processor\n\nID-COOLING SE-914-XT ARGB 45.8 CFM CPU Cooler\t\n\nASRock B450M Steel Legend \n\nKingston FURY Beast 32 GB (2 x 16 GB) DDR4-3200 CL16 Memory\t\n\nRTX 3060 Ti\n\nLian Li LANCOOL 215 ATX Mid Tower Case\t\n\n650w psu\n\nNow I'm planning to change from rtx 3060ti to rtx 4080 super and 850w psu. I mostly play the games with heavy gpu load story games at 1440p. I am fine getting above 100 fps in all games. Is there any issue with my setup?",
    "comments": [
      "At 1440p with a 4080s you'll likely be held back by your 5600x. Especially with all the un-optimized crap coming out.\n\n\nI'd pull the trigger if you really want to upgrade and find a deal.",
      "Id definitely upgrade the cpu, to either am5 or a 5700x3d",
      "You will get 100fps in a lot but you also won't get 100fps in alot and that's mostly due to bad optimisation",
      "4080 is close to a 4K card and you will get more than 100 FPS at 2K but bad optimization will not allow you to get that .. thats the main issue of new games coming i will never blame the hardware again ..",
      "I would go for an 4070 ti super 16g since its cheaper and works great for 1440p",
      "yes, i end up buying rtx 4070 ti super for very good price (discount) and save money for mb and cpu.",
      "thank you so much for the advice, but i end up buying rtx 4070 ti super for very good price and now saving for mb and cpu.",
      "Sure, I'm just saying that cards of this caliber can brute-force 1440p even when the optimization is bad. Only time when that isn't the case is when there's CPU shenanigans or traversal stutters.",
      "I totally agree with you in that man",
      "i end up buying rtx 4070 ti super for very good price and now saving money for mb and cpu changes for near future. But now, the experience is not that bad. I'm getting above 100 fps and in some cpu intense area i'm getting like 80 to 90 fps in stalker 2. Thank you so much for the suggestions.",
      "Thank you for the advice! I'm planning to upgrade other components in the future as well. I chose the RTX 4080 for its excellent performance and 16GB of VRAM, which makes it a solid choice for future-proofing.",
      "yes, i bought rtx 4070 ti super and i'm getting above 100 fps most of the time. But in some cpu intense area, i'm getting like 80 to 90 fps.",
      "You can easily get 100+ FPS in UE5 games too. It's not like OP is demanding that kind of performance in 4K",
      "yes, i end up buying rtx 4070 ti super and the experience is very good with 1440p.",
      "Of course he will but im talking about games how they perform due to bad optimization i meant sometimes its not the fault of hardware in general",
      "Yes, wait for a couple months and get 5070ti instead.",
      "I'd say at this point it's a safer bet to wait for 5070ti, you either get that or a second-hand barely used 4070tiS for much cheaper."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "low",
    "matched_keywords": [
      "3060"
    ],
    "title": "Upgrading from 3060",
    "selftext": "What do you recommend to upgrade to from a 3060 ROG Strix? 4K. Under 1k, yes it will fit. INTEL i7 129, 1000w",
    "comments": [
      "No budget, so obviously a 4090\n\nhttps://preview.redd.it/dy4nsnj1ggnd1.png?width=1260&format=pjpg&auto=webp&s=098bda247be7ba9cd2c83c86b942bd01e9f8855d",
      "You do realize some context is absolutely necessary to recommend, right? What's your budget? What's your monitor resolution? What frame rate is your target? Do you play mostly competitive games or AAA single player games? What's your PSU wattage? \n\nWith all that, we could narrow it decently.",
      "4090 is a child's play. If money is not an object, get an enterprise version of Nvidia Gpu with a massive amount of VRAM if you want the absolute best in the industry. They go for tens of thousands of dollars if you want one.",
      "But when the 5090 comes out the 6090 will be just around the corner. Wait for that.",
      "🔥",
      "4070 Super and above.",
      "He should wait and buy 5090",
      "7900xt was what I upgrade, from 3060ti",
      "wait for the 50 series to come out. \n\nNo reason to upgrade now\n\nYoull get a new card just to be few months later behind. \n\n3060 will hold you over till the new cards are announced and by then some of the 40 series cards will drop in price",
      "4080 Super",
      "And then during that time the 7090 will come out with specs that compare to a 4090",
      "4080 super should fall at $999",
      "I went from a 3060 to a 4080 (used) and it was a big difference. solid upgrade from what i previously had. \n\nOnly real options for your budget are 4070 ti super and 4080 super.",
      "4080 super",
      "You have 3 options under 1K bucks imo : 4070Ti Super , 4080 , 4080 Super",
      "Everyone is saying 4090 but honestly I wouldn’t buy a two year old flagship device. Thug it out a little and put that 4k towards the newest and greatest.",
      "depends on your cpu and psu, if your budget is limitless and if you gonna upgrade everything yeah go for 4090.\n\nbut if you dont wanna upgrade your psu or cpu you need to get a gpu which will work in harmony with your existing components.",
      "Literally anything? Gotta let us know your budget. What resolution? What games do you play? Does a 4090 fit in your case if not? Get something smaller. Idk man",
      "1000w and Intel i7 129",
      "It was all given in the post, his budget, CPU type, and PSU.  People don't read anymore."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "low",
    "matched_keywords": [
      "rtx 3060",
      "3060",
      "rtx 3060 ti",
      "3060 ti"
    ],
    "title": "Is it worth it to switch from 1440p to 1080p with RTX 3060 TI ?",
    "selftext": "Currently i got 24 inch 1080p monitor.\n\n\n\nEdit: I made mistake. I meant from 1080p to 1440p\n\nEdit2: So I did it i get the 1440p monitor and i love it thx for help guys !!",
    "comments": [
      "1440p 144hz on a 27 inch monitor is the sweet spot. A 3060 Ti will certainly have no trouble with most games with that config. You could also use your current monitor and run a dual monitor setup.",
      "Oh god yes. I recently went from a 24’ 1080p monitor to a 27’ 1440p monitor and wow does everything look more crisp and clear. I mean on the 1080p monitor I was able to see pixels and things just generally looking ‘jaggy’.",
      "I think you meant from 1080 to 1440p?\n\nIMO it will run good yes, but at 144Hz maybe not; for example I have a 1440p 144Hz monitor where do I use my 3080, and a 1080p 144Hz monitor where I use my 3060Ti, since I think those 2 fit well in those 2 resolutions.\n\nI tried 1440p on my 3060Ti and some AAA games do not reach 100FPS for example, with high-ultra settings",
      "Most definitely! Sweet spots are:\n\n* 1080p:  24\"\n* 1440p: 27\"\n* 4K: 28 to 32\"",
      "Yes the visual difference is worth the slight fps dip but it also depends on what you’re playing",
      "Well yeah i am not expexting to get 100+ on newer titles i just want to know if the visual difference will be good enough to sacrfice fps or if i should get 1080p with 144hz. Curently i have 1080p 75 hz",
      "Nah that's 3060. 3060ti is a good 1440p card even with ray tracing enabled.",
      "Well, it depends, really. If you game on your living room, that's fine. If you game \\_and\\_ code or work with documents and spreadsheets, that big 4K TV will suck. Don't ask how I know it.",
      "Not everyone only plays games in their office though. There's different use cases.",
      "Yeah when first purchasing that 1080p monitor I didn’t realize that when people said 24’ is the max you should go for 1080p they meant it.",
      "I'd argue that even if your current GPU can't handle 144hz that it's worth it going for one of these if you can afford it since you'll probably hold onto the same monitor for much longer than your current GPU.",
      "Equivalent of 1440p on a 32in monitor. Could see pixels.",
      "went from 24 1080 to 32 1440 and it's a game changer",
      "The sweet spot for monitor size at a given resolution is definitely a range. I've always hear that the sweet spot for various resolutions are as follows:\n\n* 1080p: 23 to 24\"\n* 1440p: 27\"\n* 4K: 28 to 32\"\n\nI have two 4K monitors: 28\" and 32\". None of them display individual pixels (at a table setup distance), but the 28\" is crispier. In it, it looks like a PDF document is written in nanquim ink!!\n\nI'd assume that you'd get the same general feeling from a 24\" 1440p monitor. Is that why you liked it better than 27\" versions?",
      "29\" is ultrawide 24\", 34\" is ultrawide 27\". \nSweet spot is 34\" 1440p (3440*1440).",
      "I'm not sure how you got that from my post as I'm only talking about refresh rate. I'm just saying that if you have the money for it, I'd argue that for gaming 144hz monitors are likely still a better purchase than 60hz even if your current GPU can't consistently handle 60+ fps in the games you intend to play due to how you'll probably change your GPU more often.\n\nI'm using the same 1440p 144hz gsync monitor since 2015 for example, and in that period of time I've already went through R9 390, GTX 1080, RTX 2080 Ti and RTX 3080 (which was actually a free upgrade from warranty after my 2080 Ti died). Back then I considered going for a 1440p 60hz monitor due to my needs at the time with the R9 390 but I'm glad I didn't. \n\nAnyway, 3060 Ti is more than enough for 1440p and I'd even argue it's also more than enough to justify 60hz+.",
      "I have to be like the one person on reddit who hates 27inch monitors. I wish 24 inch 1440p monitors were still a thing",
      "I didn't get that from your post, I just clarified my previous post which you seemingly misunderstood, given you started your post with \"before you say such things\" to then bring up something I didn't discuss.",
      "Yes, if you care about visual quality more than insane frame rate, then get a 1440p monitor at a decent size (right around 27\" or so) it will look noticeably sharper. And obviously you'll have more screen real estate too. Your gpu can handle 1440p gaming so I'd go for it.",
      "Using a 3060ti with a Lenovo Legion Y27Q-20 (1440p 165hz), and it dominates."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "low",
    "matched_keywords": [
      "rtx 3060",
      "3060"
    ],
    "title": "Inno3D announces GeForce RTX 3060 series starting at 329 USD",
    "selftext": "",
    "comments": [
      "Was expecting $349.99 baseline for these, pleasantly surprised.  Tariff tax will bump them to at least $360 (+10%) unfortunately.",
      "Anyone else remembers when a x70 card used to cost 329?",
      "Probably 400€ in EU ...",
      "In what timeframe? Eventually, sure. \n\nBut we haven’t even reached “eventually” (not even close) for cards that were released almost 4 months ago.",
      "$329 makes this a ripoff. The 1060 came out over 4 years ago and they still won't give us 2x the performance for the same ($250-200) price point. What a fucking joke.",
      "More like $370 unless my math skills have worsened significantly.",
      "I bet it'll be even higher.",
      "Think they will be able to make enough of them to satisfy demand this time?",
      "More like 500€ on the current market.",
      "Not to mention the MSRP is now meaningless. The card will probably sell at $399!",
      "...\n\nIm still waiting on my RTX3080 , its been 4 months now..\n\nWhy cant they produce enough of one product before they make new ones...",
      "the rtx adds 100$ to msrp.\n\nthough i don't think they will refresh the 16 series so idk",
      "it's not just about perf, it's also the availability of raytracing/dlss/other accelerated tech that the 1060 can't do",
      "It'll run raytracing smooth at 800x600.",
      "With it having 12GB VRAM, it will be gone before the Ethierum market crashes",
      "Aaaaaaand they're gone.",
      "Pepperidge farms remembers.",
      "where tho , aliexpress?",
      "You can sometimes find weird brands from Hongkong selling the cards for a decent price to EU since tariffs with china are much lower. Takes time to find a decent one and not a scam tho.",
      "Console also costs $60 to use basic functionality... Also by that metric literally no PC parts are a good deal. Wtf are you on?"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "low",
    "matched_keywords": [
      "rtx 3060",
      "3060",
      "rtx 3060 ti",
      "3060ti",
      "3060 ti"
    ],
    "title": "Upgrading from GTX 1650 to RTX 3060 ti",
    "selftext": "I have slowly gotten back into gaming and have been looking towards to upgrading my PC little by little. Currently on some games the 1650 is having some issues and not seeing the performance I would like.  I have been looking on eBay for used 3060ti from $250 - $300. Seems like a fair price.\n\nDo you think I should look into getting a 3070 at used price or getting a 2080 ti or super? Have been doing some research, they do better in performance than the 3060ti. Willing to pay upwards to $310 for a GPU.\n\nI am also rocking a Ryzen 7 5700x, T-Force 32 gb 3200 mhz ram, 650w gold plus watt power supply\n\nLet me know if anything will bottleneck or if anything looks funky for the gpu I want to get. :)",
    "comments": [
      "Your going to love it when you upgrade. Pretty much upgraded from my old 1650 to your exact build + my new 4060 ti.\nIt’s a drastic jump in performance, so enjoy once you make a decision!",
      "Nice. Last year, I upgraded from a rtx 2060 to a rtx 4070 and it's been great! But damn, 1650 to 4060ti is such a nice large jump!",
      "Watch out the Reddit vram gang will tell you you made a bad purchase",
      "Bro save up for 4090 RTXXXNXX LGBTBBQ+++ PRO MAX 8K ULTRA OC, otherwise its a wast of money.  /s",
      "The 4070s is like more than double the price lol",
      "I would get 3070 over 2080ti unless the later was noticeably cheaper.\n\nIn the end it all depends on your budget and what you can get for it. Perhaps if you would list all your options, then we would be able to advise a little more.\n\nBtw if you do not care much about ray traycing, then consider some of the AMD GPUs. They often provide noticeably more rasterization power and they tend to be cheaper. GPUs like RX 6700XT/6750XT or RX 6800/XT are solid price/performance choices and they have 12GB/16GB of VRAM respectively.",
      "At least get one with 12gb of vram. Consider the rx 7600 xt aswell!",
      "Never looked into amd graphics card is the quality build better or just over better in performance.",
      "I hear that 4070 is nice! Someone was trying to talk me into it but I didn’t want to come off of the extra money. Are you sticking with that for a while or moving to something different in the future?",
      "Nah, cant even do 1080p. You need a Rtx 4090TiSuper xtx Ultra Gaming oc Beast minimum for 1080p!!!  \n\n\njkjk",
      "I am keeping my gpu for a few years.",
      "You can get a 3060 for that price would go for a 12 gb idk if they make 12 gb 3060ti though since I have only seen 8gb on the market",
      "Cool guys… For anyone looking for maximum optimization here are the undervolt overclock settings. Was able to maintain EVGA RTX 3060 Ti stable at Core 1920mhz at 0.875v and +1000 memory clock. So far so good no problems. For anyone wondering what CPU I have it’s the Ryzen 7 5800x3d. In Ghost of Tsushima 1440p very high settings with DLSS dynamic resolution was able to maintain fps between 60-75 fps. Probably better to vsync it to 60fps. GPU instead of 200w, it stayed at at around 160w and maintained a solid 69c temperature.",
      "Never buy a 2000 series card. 3060 ti seems fine for your needs",
      "The 3070 is a pretty sweet card.  (I went from a 650ti boost 2GB to a 3070.  4k FPS bench went from 15fps to around 90...)  \nThe 3070 is a comfortable and capable 1440p card.  I mostly play older games at 4k and I've only seen VRAM issues once while playing Forza Horizon 5 at 4k, and this was on the settings that the game optimized and I just get a low VRAM warning occasionally.  I've been using the 3070 as a 4k card for older games, Fallout IV, Skyrim with mods, Metro 2033, Last light...   Forza Horizon IV.    It's a lot of fun.    \n\nAny newer games are best played at 1440p.",
      "Do you think the 650w power should be fine for it??",
      "Pretty good price have been seeing way higher prices on eBay upwards to $400+",
      "They are looking for a $300 gpu, so out of the question",
      "The quality seems to be hit or miss.\nSome people have been using them for decades without fault.\nOthers always seem to have bad luck with AMD.\nIt's not as bad as Intel but problems can arise.\nThat being said some people have issues with Nvidia, not quite as high a percentage but regardless GPUs aren't always as plug & play as you'd hope, but eBaY has strong buyers protection so you should be able to get a refund if you have problems.\n\nAs far as AMD vs Nvidia it basically comes down to better raster performance vs better features.\nPersonally features like RTX HDR & DLSS are too important to me to ditch Nvidia (RTX HDR is awesome if you've got a good monitor/tv and DLSS is miles better than FSR). But some people don't care as much.\nAnd then there's ray tracing, you may think you don't care but it's becoming more of a standard setting each year. There are a whole host of games who's lighting systems are heavily reliant on RT and look a generation behind without it.\nDragons Dogma 2, if we ignore its awful optimization is a good example. Without RT all the indoor/shaded options look considerably worse.\nSo without RT, high/ultra settings are increasingly not really high/ultra.\n\nI had a 3070 mobile up until a month ago when I built a 4070 ti PC. That laptop chip has performance equivalent to a 3060 ti and it still runs great.\nI only upgraded because I play at 4k and  that wasn't possible anymore, but at 1440p/1080p it'll still be a great performer.\nAs far as the 3070 goes, it's definitely noticeable upgrade if not a revelatory one.\nYou won't be doing things you can't with the 3060ti but you'll be doing the same things with more confidence.\nA shaky 50 becomes a solid 60, DLSS performance becomes DLSS quality and so on.\nFor me thats worth it for a bit more money but to you it might not be.\nMy advice, look at your budget, if the increase to the 3070 is no big deal (i.e. a little more saving, skipping a few uber eats deliverys etc) then do it.\nBut if it'd be a noticeable hole in your finances better spent on more important things then get the 3060 ti.\nYou'll be happy with either one, happier with the 3070 for sure but only a little bit.",
      "I gotta 3060 and play at 1440p it does alright but after a year or so I've been itching to get out of the 60s into 70 or 80s. So I can get 100+ fps on high settings.\n\nI haven't played the games you are playing for example but right now I'm playing red dead redemption 2 on 1440p monitor, I'm using dlss and after going through optimizations (I kept alot at high and ultra) I get 75 frames a second on average.\n\nI have a 12gen i7-12700 cpu I believe and 32 gb ddr4 ram"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "low",
    "matched_keywords": [
      "3060",
      "3060ti"
    ],
    "title": "Ultrawide 1440p 144hz Monitor - 3060 or 3070?",
    "selftext": "Long story short, I thought my laptop would be able to handle this monitor. It can't\n\nSo im trying to build a pc, i have most parts picked out, but I cant seem to find any info that shows if a 3060 could run 1440p gaming on an ultrawide\n\nWould it? Or should I get a 3070? Obviously ignoring the shortage\n\nOr is the 3060ti a safe middle ground? \n\nAny other recommended cards that might be easier to find that would be able to handle 1440p gaming? \n\nThanks in advance!",
    "comments": [
      "Depends what you are prioritizing. To be honest if you are trying to get high frames on an ultra wide you are going to want a 3080. \nI’ve got a Samsung G9 and i am surprised with how demanding it is.",
      "I run 1440p UW with a 3070, it runs pretty well, some games I have to tinker with a few settings but generally it’s stable enough, would defo say 3060 isn’t strong enough tho",
      "my 3080 FE was barely able to get a stable 65fps on 1440p while playing RDR2. in cyberpunk 2077, it got around 85fps with optimized settings and DLSS on. due to the shortage, get whatever you can. 1440p ultrawide is gonna be tough to run.",
      "If you're playing 1.75 resolution scale at 1440p, you're actually playing at 2520p, which would explain your below average fps",
      "> any card you can get right now is the one to grab.\n\nPretty much this.",
      "I can confirm this. I have a 3440x1440 and play warzone with a 3080. I struggle to get 140 frames on medium settings. Love the screen but damn is it demanding.",
      "Uh what? Barely able to get a stable 65FPS at 1440P? I can max out RDR2 and get 70-90 FPS with my 3080 at the same resolution. Only that I slightly turned down is water quality because the highest setting does nothing other than kill frames",
      "To be fair warzone is poorly optimized",
      "Lmao this is too funny.",
      "TAA - HIGH\nFXAA - ON\nMSAA- OFF\nTAA SHARPENING - 1/4 to 1/3",
      "Came here to say this. Ultrawide does require extra \"ooumf\" compared to 1440p non ultrawide. I mean it's 25% more pixels to push, after all.",
      "Id go for a 3080 too.   Im currently gaming at 3440x1440 with a 3070 and its totally 100% perfect for the games I play (mainly Warzone, Cold War and a few other AAA games)  BUT....   i have strong doubts this card will stand up to the test of time.    8GB of vram will no doubt be an issue sooner than later.  \n\nI bought my 3070 having accepted that and am enjoying it for what it is right now.   The fact that its nearly paid itself off by running nicehash at nights and while at work takes the sting away too (but the window for being able to make that work might be narrowing right now).  \n\nI expect Ill be looking for a gpu upgrade in 2022 or early 2023 at the latest",
      "Well if i cant find anything by May 25th im going to try getting the 3080ti",
      "What size 1440? If it’s a 27 then stop giving advice. Ultrawide are way way more demanding.",
      "I've been running 3440x1440 for years. First on a GTX 1080, then on a 2080Ti. Trust me when I say you want the best GPU you can afford for this resolution.",
      "3060ti is probably the safe bet since it’s just a little weaker then a 3070. Honestly... any card you can get right now is the one to grab.",
      "World of warcraft doesn’t use much ressources. \nAs someone who had an ultrawide back in 2016 i can tell you that my 1080ti struggled a lot on aaa games.\n\nI remember playing ghost recon wildlands with crappy fps, barely 40 average on highest settings.\n\nThe dude has a 144hz refresh rate on his monitor, a 3060 isn’t gonna cut it.\nThere is no point spending extra money on high refresh rate if you aren’t gonna use it",
      "Actually the g9 is 5120x1440. \nSo 7,372,800 pixels. Still not quite 4K but also rendering a wider fov.",
      "I wish I was enough of an asshole to buy 2 of them two pay off the 1st",
      "Good luck with that. You're not just going against people who want the 3080ti, you're going against almost everyone who didn't get a 3060ti, 3060, 3070, 3080, 3090, and amds 6000 series. Not to mention the bots lol. But hey, you might get lucky like me, so good luck."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "low",
    "matched_keywords": [
      "rtx 3060ti",
      "3060ti",
      "rtx 3060ti"
    ],
    "title": "Was purchasing an RTX 3060ti worth it?",
    "selftext": "Hey, I recently upgraded from my 1050ti to an RTX 3060ti, now don't get me wrong the 3060ti is a beast and a huuuuuuge upgrade from my 1050ti, now I want to know if it was smart purchasing the 3060ti or should I have bought a 3070 or 3080?",
    "comments": [
      "Honestly the 3060ti is enough for most new titles at 1440p. Locked at 144hz? No, but 100+ with gsync you'd be hard pressed to tell the difference.",
      "You got yourself the famous case of \"I need to upgrade everything\".    The 3060ti is a beast and the best 1080p GPU you can get, the 3060ti can even do 1440p and get 60 to 100 fps so it's great for story mode games.     You have to keep in mind, if you want a 3070 or 3080, you won't see any performance increase unless you also upgrade your monitor to a 1440p or 4k monitor. \n\nYou also need to keep in mind that you most likely have to upgrade your PSU if you upgrade from 3060ti to 3080.\n\nThe question is, how do you like 1080p resolution at ultra settings ?  If you don't mind it at all then the 3060ti is more than enough.\n\nIf playing at 1440p or 4k resolution is something you would really like, then go 3080, but you need to upgrade your Monitor and PSU",
      "Hey, I have both a 3060Ti and 3070. The 3070 is ~10%+ better on most games. Not a massive increase in performance they’re very similar cards.",
      "RDR2 hits 90-100 fps on high with a 3060 Ti so something might be wrong with your card or setup. https://www.youtube.com/watch?v=QlgfRVmpzlg",
      "Obligatory correction: the 3060 ti will also run most multiplayer titles @1440p 120fps max settings. Warzone, Destiny 2, Battlefield etc etc - 120fps (even moreso or higher with DLSS).\n\nPeople always seem to overlook that this gpu is more powerful than anything in the new consoles - which also occasionally target 120fps in popular online shooters.\n\nI find the continued [none insidious] misinformation in relation to this card to be quite bizarre.\n\nHave people forgotten that 1440p gaming was already a regular and expected thing with the 2080 Super?",
      "Something's wrong then. My 3060 Ti runs RDR2 comfortably at 1440p 60+fps with everything on high-ultra. Are you sure you don't have any bottlenecks or system settings limiting your performance?",
      "In short, the value proposition of the 3060 Ti and 3080 are *so good* it makes every other card much less appealing.  Should be stating the obvious here... There's a reason the 3080 is the hardest GPU to obtain, and the most scalped.  The 3060 Ti is in 2nd place right behind it.\n\nFor example, the 3060 is about 20% cheaper than the 3060 Ti but also 30% slower, which is insane since cheaper cards are usually a better value -- the exact opposite.  I can't even recall the last time this happened.  In normal times, the 3060 would be about 20% faster... or 20% cheaper... than it currently is.\n\nThe problem is that AMD and Nvidia realized they could exploit the market this year, so all the new cards (3060 and beyond, 6700 XT and beyond) are garbage-tier cards because both manufacturers know they will sell.  The 3070 and 3090, both launched last year, are still much values than everything else that's launched in 2021.\n\nThe 3060, 3070 Ti, 3080 Ti, 6600/6700 only exist in their current state to fuck over PC gamers.  We already know this because there have been multiple leaks showing cards being revised over and over from the last 6+ months.  Nvidia even gouged the 3080 Ti's MSRP from $999 to $1299 at the last minute.\n\nAll of this just makes the awesome cards from 2020 look even better.",
      "Idk what to do, these GPU prices are crazy.",
      "I'm confused by some of the comments here. I thought 3060TI (not 3060), was the best value in gaming right now. It beats the 2080SUPER, and when properly cooled and OCd it reaches 3070 performance. \n\nIt's better than the next gen consoles, and is also the best GPU you can fit in a sub9L SFF case (EVGAs dual fans at 202mm length), all for $400-500. \n\nI personally got chosen to buy one and am upgrading from a 2060 to play 1440p and 4k games, which the 2060 did a decent job at anyways. But even if I wasn't personally invested, I would be confused. Not sure where this notion that 3060TI is only good for 1080p. It's probably the best performance/value for 1440p as well based on reviews I've seen. \n\nAgain all this goes if you got it at MRSP, or relatively compared to the prices of other GPUs in your region.",
      "If you are not good with PCs and new to this, how are you giving advice on PC hardware?",
      "It's this generation's \"GTX 970\", unbeatable value and frankly makes nearly every other card on the market obsolete.  Between the 3060 Ti and 3080 there is little reason to buy anything else.\n\nAssuming you got it for MSRP.",
      "This is my exact same gpu + cpu + monitor setup! Extremely happy with it.",
      "I paid £445 for my Asus Dual OC 3060 ti right at the start of the shortage (last December) and it's the best damn purchase I made all year, it plays everything @1440p minimum 90fps (bar Cyberpunk for which I could give a single solitary fuck). I paired it with a 5600x and a Dell S2721DGF monitor and my system is now my pride and joy after my kids lmao.",
      "Yes",
      "Idk based on what people say it's not worth when they don't even know where you're from. 700 eur is okay price for it in easter europe for example. I got it from EVGA lottery for 580 eur last week. Normally a simple 3060 is around 700 eur here, and a 3060ti is ~1000 eur. And can't buy from nvidia here. Just enjoy your card.",
      "Don’t return it man. If you can afford it just enjoy and don’t put yourself through the torture of finding another card. You may not find a better or even equal deal.",
      "700Eur",
      "Lol when hdmi is on the MB",
      "Eh, it's hardly apples and oranges. I'm literally talking about GPUs - not closed systems built up of various different parts, I'm not comparing a person's entire PC to a PS5. The Sony and Microsoft platforms both feature a GPU inside them, as does a gaming PC. Thus, of course individual hardware components can directly compared, and they will be - it's been happening since the year dot lol. Digital Foundry literally make a living out of it!",
      "that was a long *short.*"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "low",
    "matched_keywords": [
      "3060"
    ],
    "title": "Is it okay to buy a Ebay Refurbished gpu ?",
    "selftext": "I’m looking for a new gpu but with the prices going up i don’t know what to get.I was looking for used gpus and found a 3060 12gb on ebay but it is refurbished? Is it still good to buy ?\n\nLink: https://www.ebay.com/itm/296945476089?chn=ps&norover=1&mkevt=1&mkrid=711-166974-028196-7&mkcid=2&mkscid=101&itemid=296945476089&targetid=2275367127251&device=m&mktype=pla&googleloc=9031745&poi=&campaignid=21761710509&mkgroupid=169252181898&rlsatarget=pla-2275367127251&abcId=10045971&merchantid=107418080&geoid=9031745&gad_source=1&gbraid=0AAAAAD_QDh_VUMZj0C7aBjBJZVnc43pXa&gclid=EAIaIQobChMIlZmmo8-kiwMVfCNECB1_gDB5EAQYFSABEgKd6fD_BwE",
    "comments": [
      "Refurbished are usually great, I prefer it over regular used and they come with warranties",
      "I have an rtx 3060ti for sell if you are interested in the same price of this one you found",
      "How much vram does it have ?"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "low",
    "matched_keywords": [
      "3060",
      "3060ti"
    ],
    "title": "Which card to buy?",
    "selftext": "I've had 1080ti for a while, and it served me great. But now, I've  bought lg oled 65 for gaming, and I want my GPU to be on par with the  display. I play only single player games, and play approximately 1 game  every 3 months. I've recently played NFS Heat, God Of War 2018, Red Dead  Redemption 2, with plans on playing Hogwarts Legacy, Horizon Zero Dawn,  Cyberpunk, etc...\n\nI haven't deep dived into what each of the new  nvidia series is bringing to the table, and how much do RTX and other new features contribute to rendering quality, specifically for 4K OLED display. I don't have a limited budget, but I don't want  to spend a fortune since I don't even play that much.\n\nFrom what I  can find through quick google search, seems like 3080 is recommended  for 4k 60fps for cyberpunk and rdr2. Will this be enough? Will I get any  visible benefit if I go with 3080ti? Is then something like 3070  sufficient for 4k but slightly less fps?\n\nSince my question is relatively tied to the current GPU prices, here are some example prices where I'm currently located:\n\n2060 - 150e\n\n2070 - 250e\n\n2080 - 260e\n\n2080ti - 300e\n\n3060 - 240e\n\n3060ti - 260e\n\n3070 - 300e\n\n3070ti - 320e\n\n3080 - 420e\n\n3080ti - 520e\n\n3090 - 600e\n\n4060 - 360e\n\n4060ti - 390e\n\n4070 - 600e\n\n4070ti - 800e\n\n4080 - 1300e\n\n4080ti - not available\n\n4090 - 2000e\n\nWhich graphic card will give me a meaningful bump in quality given my setup, without it being an overkill?\n\nEdit: Added 4080, 4080ti and 4090, to put pricing into perspective\nThanks for great responses! I'll probably go with 3090",
    "comments": [
      "If you’re going to 4K 120hz gaming, its either a used 3090/3090ti, 4080, 4090, or 7900XTX",
      "No competition even in Single Player RPGs for 120 hz vs 60 hz.",
      "Don’t listen to people who “can not play at 60HZ anymore”. 60FPS is totally fine for casual gaming. \n\nI also don’t play that much, I need 2-3 months for 1 game. Currently completing Elden ring. I have 4070 and I play at 4K60 on my QLED. Right now this card is capable of 4K. Sometimes it’s native resolution, sometimes it’s DLSS Quality. Of course I don’t turn on RT and of course it is not maxed out graphics quality in every game. Personally I am very satisfied with the performance/cost ratio. \n\nSo back to your question. If you want eye candy graphics in every game go for 4080/4090. \nIf you want to save your money and don’t mind to fiddle with settings go for 4070. 4070TI does not worth additional $ because of the same 12GB as on 4070, imo.",
      "I mean sure, but is 4090 that better that I should pay 2000e instead of 500e for 3080ti?",
      "Nope. Get the 3080ti or 4070",
      "This. 3090/3090ti used should be the cheapest but will have the weakest performance. 4080 and 7900XTX are the midrangers here but the XTX is cheaper and usually is neck and neck, even a bit better in certain games so we'll call them equals. 4080 is more expensive generally but is more reliable if you happen to do productivity stuff or AI. XTX is the best value for just gaming usually here at 4k. 4090 is the undisputed king of all but at the heftiest price and only for people who have no budget.",
      "4070 or better 4000 series... Do not buy a 3000 series... with DLSS on Frame Gen. you can run anything just fine for casual gaming on a 4K TV.",
      "VRAM is the main reason I didn’t include it in my comment. You absolutely can clear 12GB of VRAM at 4K",
      "4080",
      "People just parroting benchmark results, where the YouTubers use Ultra settings on 4K without DLSS",
      "I have the 4090, if you don't want to pay for it the 7900xt or xtx I really think are great cards especially for the money.",
      "SLI is dead, but my second 3090 runs@100% on RDR2. 130FPS@4K Ultra. If you play that, GTA, and The Witcher just grab another 1080 Ti and an an SLI bridge lol. Would be cheap. CP2077 with 4090/13900k, Im still not interested enough to go back and play through. Id highly recommend a 3090 if priced right though. No reason to buy a 4070 when you can get a 3090/6900/50XT for very simular prices.",
      "My personal recommendation for 4k/60fps will always be the RX 7900 XTX. Same performance as 4080 while being much cheaper.",
      "For what it's worth, I'm having a great time on a 4k 60 TV with the RTX 4070",
      "I don't think I need 120hz, I'm not playing any FPS games",
      "yeah worst case you just drop the visual a little and turn on DLSS. I don't understand where the obsession comes from with having to play at ultra.\n\nEverybody says that DLSS is great and but nobody here accounts for it when talking about a card being able to play a certain resolution or not",
      "Depending on the title you can get 3090/3090ti level RT with a 7900xtx.\n\nControl is an example I used as it was brought up in another comment, 3090 and 7900xtx are equal with RT on there",
      "Oh ok, sounds good, didn't know that.\nI seen also that Unreal Engine 5 seem to like AMD cards and RT is also pretty equal there.\n\nSo I guess the answer may not be so obvious in high end as it may seem, while in low end and mid end, AMD is the best values now.",
      "I'm running a 4090 and i always play 4k a native resolution. DLSS super resolution is a good technology but the quality difference is clearly visible, Frame generation is a lot better for me but artefacts can boring.",
      "would be cheaper and probably better to buy the 3080ti and upgrade to a 5080/6080, no need to look far into the future with this type of graphics card, do what works for you now/in the near future.\n\nif you want 4k 120hz a 4090 is recommended, if less is ok than I would go with cheaper cards."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "low",
    "matched_keywords": [
      "rtx 3060",
      "3060",
      "rtx 3060 ti",
      "3060ti",
      "3060 ti"
    ],
    "title": "Need help undervolting 3060ti",
    "selftext": "Hey, I’ve got an RTX 3060 Ti and I’m looking for a tutorial to undervolt it (I’m a beginner and wouldn’t be able to figure it out on my own). My case doesn’t have great airflow, and it gets really hot where I live, so I’ve always undervolted all the GPUs and CPUs I’ve had so far (just undervolting, I’m not into overclocking). It’s always worked out great, but with the 3060 Ti, I haven’t been able to find any settings that actually make a difference in temps. Could you recommend some specific settings or maybe explain how I could figure them out myself?",
    "comments": [
      "Just lower the power limit with the Nvidia app or Afterburner, to 80% or so. This will lose you only a little performance."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "low",
    "matched_keywords": [
      "3060",
      "3060ti"
    ],
    "title": "RTX 3070 and a single pcie 8 pin power cable compared to the 3060ti's power draw.",
    "selftext": "I'm making this thread after the recent thread of a user's pcie cable and connector on the back of their EVGA (name and shame baby) power supply melting because he used both 8 pin connectors from a single cable to power his RTX 3080.\n\n&#x200B;\n\n***I've been doing some digging and reading about the subject and below is what I have learned. It is my interpretation and I welcome corrections. It is long, there is no TLDR.***\n\n&#x200B;\n\nApparently the issue lies in the  connector on the back of the psu (which is not a factor with a non modular psu)  and the thickness of the cable itself:\n\nWith 300watts passing through the pcie connector on the back of the psu  (which was designed for 150watts) the thin pins and surrounding plastic  will heat up and can melt and burn out.\n\n  \n**Power cables:**\n\nThe  thinner a power cable the higher the resistance, more resistance = more  heat at the same current. Many power supplies apparently cheap out on  the pcie power cables (using 20 gauge wire) since they're only rated for  150 watts. If it passes that you can sell it.\n\n**AWG info: (this might need correcting)**\n\n*AWG is a measure of how thick a cable is.*\n\n20AWG  gauge copper wire is rated for 1.5A @ 120V or 175 watts. Above that  it'll heat up too much and fail (or melt the plastic components it  touches, like the power plug and the insulating cable sleeve.)\n\n18AWG gauge copper wire is rated for 2.3A @ 120V or 279 watts, quite a bit more.\n\n16AWG gauge copper wire is rated for 3.7A or 444W, plenty to power *any* gpu with a single cable and then some.\n\nIt's impossible to find the AWG of pcie power cables on most if not all power supplies. They don't list it  anywhere. If you're lucky they list the AWG of the main power cord that goes into your wall socket.  \nAnd even if they did you still don't know if the connectors  itself are engineered for double power draw. **(If you know where to find this info, please correct me)**\n\n*Keep  in mind we are talking about sustained load, apparently 3080 ampere cards can spike up to nearly 500watts for a couple of milliseconds, but  obviously the cable can easily absorb that and won't heat up instantly.  Average sustained power consumption is what matters when talking about  cables heating up.*  \n*Any talk of high transient loads only matter in the context of overcurrent protection tripping on power supplies.*  \n\n\nAn RTX 3070 overclocked can pull about about 250watts sustained.  \nAt least 65 of that will come from the pcie slot (Up to 75w, most mobo's underprovision it).  \nThat leaves 185 watts for the pcie power cable and connector. Too much for 20AWG cables, potentially too much for the 8 pin plug on the back of the modular power supply regardless of how thick the cable is.\n\nI would like to  assume common sense from manufacturers and that a thicker cable also  means the plug and pins are engineered for 300watts as well.  \nSadly (*warning: opinion, try not to downvote the entire thread if this part triggers you*) every single brand's non server parts seem to be the equivalent of gaming  brand headphones: advertise your product through one over engineered  part or feature, and do the absolute minimum you can get away with for everything else as long as it meets minimum  standards to pass regulation.\n\nSome contraindicators for all of the above:\n\n\\-  PSU manufacturers put two 8 pin connectors (daisy chained) onto a single  cable, even with modular power supplies with three 8 pin plugs on the back and 3 pcie power cables. Each cable still has 2 connectors on it. Common sense would  indicate that SURELY the cables and connectors would be designed to  support this.  \nApparently not and the function of these extra connectors  is to power cards with 3 8 pin connectors like this:\n\n[https://i.redd.it/qfwh3kboeyl51.png](https://i.redd.it/qfwh3kboeyl51.png)\n\n(the upper right configuration)\n\n\\-  PSU manufacturers (like EVGA with my 600b power supply) sell 600watt  power supplies with 49A (588 watts) on the +12volt rail intended for  use with cards with 8+6 or 8+8 power connectors, yet only have a single  cable.\n\nIt's impossible to find the AWG of  pcie power cables on most if not all power supplies. They don't list it  anywhere. And even if they did you still don't know if the connectors  itself are engineered for double power draw.\n\nI've emailed EVGA asking about this and haven't had an answer yet.\n\n&#x200B;\n\n**The 3060ti and how it seems like a contradiction about the above info and what nvidia says about the cable requirements for the RTX 3070 (it's definitely accurate for the 3080)**\n\nThe 3060ti is a cut down 3070, some overclocked AIB models come with a single 8 pin connector, and some of them can easily reach 230watts of sustained power draw out of the box, 10 watts more than a stock 3070. I'm trying to find which ones also allow raising the power limit beyond that, but haven't been able to find this info yet.\n\n&#x200B;\n\n[https://www.hardwareluxx.de/index.php/artikel/hardware/grafikkarten/54788-viermal-geforce-rtx-3060-ti-inklusive-founders-edition-im-test.html?start=7](https://www.hardwareluxx.de/index.php/artikel/hardware/grafikkarten/54788-viermal-geforce-rtx-3060-ti-inklusive-founders-edition-im-test.html?start=7)\n\n&#x200B;\n\nOnce you oc, and with a power hungry game or when running a power virus like furmark, you're able to go well above the power draw of a stock 3070.\n\n&#x200B;\n\nSo why is it fine to run this off a single 8 pin connector (and cable), but not the 3070 with 8+6 pin off a single cable? My guess is this recommendation solely exists for the models which allow significantly higher power limits than the reference card, and for the 3080.\n\n(but then why does nvidia ask for 2 cables on the reference 3070)\n\n&#x200B;\n\nSo  either we'll see a bunch of power supplies melting from 3060ti's in the coming weeks,  or there is literally no reason why a 3070 ran at stock voltage and power limits shouldn't be perfectly fine  too.\n\n&#x200B;\n\n&#x200B;\n\nIf you made it this far, have a cookie :p",
    "comments": [
      "I'll receive a 3060 ti tomorrow and I have a 500 watt PSU with one PCIe cable. I'll let you guys know when my PSU is melted. For science",
      "TLDR\n\nIts not so much about sustained load declared by the card but about peak loads that the card can generate. 3080 and 3090 are really what matters here. 3070 could be fine with single cable but why risk telling a customer that and potentially taking the blame?\n\nCables are not the issue. Seasonic uses 18AWG conductors but there are multiple conductors in the cable so you have to multiply it's current carrying capability.\n\nConnectors are the issue as they heat up under load - test sheet for PCIE 6pin connector (8pin has only 2 more sense wires no additional current caring so results should be the same) [https://www.molex.com/pdm\\_docs/ts/TS-5556-002-001.pdf](https://www.molex.com/pdm_docs/ts/TS-5556-002-001.pdf)\n\nEvent then in ideal world of laboratory conditions everything should be fine with 1 connector.\n\nBut we don't live in a lab. In real world connectors are often not plugged in all the way, have dust on them, the connection is not perfect, there are manufacturing defects. Pair that with a higher than previous gen current draw and you have a potential issue that Nvidia and PSU manufacturers seek to avoid with multi cable recommendation. And everyone should listen.",
      "Yes I have a cookie and am now smarter too\n\nThanks",
      "One cable, one GPU power connection on the GPU.\n\nEach 8 pin connection should have it's own dedicated cable.",
      "> With 300watts passing through the pcie connector on the back of the psu (which was designed for 150watts) the thin pins and surrounding plastic will heat up and can melt and burn out.\n\nYou stopped digging too early, the socket is not limited to 150w.",
      "Ok, sorry, I'm not too experienced and not sure I'm understanding this.  I'm using a single 8-pin connector from my PSU to the 8-to-12 pin adapter provided with my 3070FE.  Can you help me figure out what cable(s) I need to get to hook it up properly?  My PSU is modular.",
      "So here is the update. I have been playing for a few hours and so far no problems (yet). \n\nMy total system power usage is around 340 watt. My PSU is a pretty old Enermax modu87+ 500 watt and I connected my MSI gaming x 3060 ti with one cable which has 2x 6+2 pins. \n\nShadow of the tomb raider and Resident evil 2 remake used the most power at around 340 watt. Final fantasy 15 used less at around 260 watt. Perhaps it's the location (Altissia) but I wasn't getting a high fps there. \n\nSeems fine to me to use single cable.",
      "I've read 3000 series can be heavily undervolted to reduce consumption from 350w to more contained 250-280s, while retaining it's performance. That should give you enough wiggle room if you only have one cable.",
      "Yes, the 8 pin connectors are rated for 150W. \n6 pin connectors are rated for 75W.\nPCI-E delivers 75W through the slot.\n\nThat is easy to find and reference info, it's even on wikipedia. Some of the info is fundamental electronics and electrical engineering. I am not an electrical engineer myself, but my dad is and I grew up doing this stuff. You can ask an electrical engineer to fact check me and if I am wrong I would truly like to be respectfully corrected.\n\nhttps://www.gpumag.com/gpu-power-connectors-explained/\n\nhttps://en.wikipedia.org/wiki/PCI_Express#Power\n\nIt takes a bit of digging but you can find the engineering specs if you really want to go that deep. I found a bunch for PCI-E(PCI-E publishes them all,) but still trying to find some PSU engineering spec sheets currently.\n\nAlso Buildzoid has an excellent video that talks about this where he specifically says daisy chains should be fine unless we get into 400W territory. That video is 3 years old and was made before we even had 2000 series.\n\nhttps://www.youtube.com/watch?v=9nM80JmzKvc\n\nIf you have a Daisy chain with connectors rated at 150W and the cable can handle more you have an issue at the PSU side. The PSU can only safely draw 150W through it's single connection and somehow deliver more than 150W to two 8 pin power connectors at the GPU. Electricity does not magically increase amps and volts to make more watts. Actually because of resistance and voltage drop you get less than you asked for in the form of less voltage and the same(or more) current(amps.) This creates heat at the connectors, unused or inefficient electricity turns into heat. \n\nAlso lets remember you're NOT getting 100% efficiency(that's almost impossible) and you're not going to get the full 150W you're asking for. And that he cables should be 16 gauge for pigtails, but is typically 18 gauge which isn't as good.(Lower numbers are thinker wiring.) Also some could be using Aluminum wiring instead of copper which creates more heat. There is apparently enough variability in PSU specs and design that a daisy chain could work fine on PSU and be magic smoke on another. Is that alone a risk worth taking?\n\nIf we do the math each PSU end power connection is 150W send and each GPU power connection is 150W request. So if we have a daisy chain on an EVGA FTW3 Ultra we have on the PSU the ability to send 150W x 2 + 75W from PCIE slot(375W total, 25W short of the 400W power draw at max load.) The GPU will be asking for potentially up to 3 X 150W +75W PCIE slot which is 525W total potential power requested. This is obviously not good if the PSU is trying to deliver more power than the connectors and cables are capable of handling. You'll only get that demand during peaks, but it only takes one 500W plus peak to make magic smoke.\n\nWhen you ask for more power that means more current(amps) and voltage. Wattage is literally volts multiplied by amps (W==v*a). Voltage can be modeled as the \"amount\" of electricity and current modeled as the \"pressure of flow\" in a sense. Current is more dangerous as a lot of electricity without \"flow pressure\" moving it doesn't do much except maybe look cool and tickle a little. You give a little voltage a 1 amp of current and that can kill people in contrast. When your GPU asks for power it's that extra current it's not rated to handle that will create the magic smoke.\n\nIf we ask for more than the cable and/or connection can handle we have risk of \"magic smoke.\" The PSU and GPU assume the cables can handle what they want to do. If the cable isn't good enough we get magic smoke at worst case. With a Daisy Chain we are asking for potentially 300W through a cable not at the correct gauge to handle that through a single 150W rated connection at the PSU. Also how does the PSU and GPU know to not push too much power through the Daisy chain cable? It doesn't know it's a daisy chain, it sees three 8 pin power connections and that it's getting power from them. How could it know not to push more than 150W through the daisy chain? (It doesn't, it could easily overload the daisy chain on the assumption that it's a properly rated cable.)\n\nIt makes 0 logical or rational sense to use a daisy chain for 2000 or 3000 series. 3000 series is definitely drawing too much power for it to be smart to use a daisy chain. 2000 series seems to be borderlining it depending on specific GPU and PSU.\n\n1000 series had low enough power draw it was permissible. But even then I would not recommend it to be on the safer side. Jayz 2 Cents found his OC and performance was slightly limited on a 1080 something using a daisy chain. His results have not been verified by others repeating the same test, so scientifically it's not exactly solid data(yet.)\n\nNow add in that it kinda depends on your PSU and how well it followed specs like 16 gauge wiring for a daisy chain cable and copper wiring it seems like it's just not worth the risk to use a daisy chain at all, ever.\n\nI've come to question their existence. And now think they should not have ever been made. Daisy chains seem like a recipe for user error to destroy components. When it comes to making and selling a product an uniformed consumer could easily destroy it's prudent to minimize giving them ways to enact disastrous failure. Especially when there's a fire hazard potential. \n\nThe rule of thumb should be this: One cable per 8 pin GPU connection. If they're 2 x 6 pin that's actually fine as 6 pin is only 75W and a daisy chain on 2 x 6 pin is 150W(2*75W.) But for newer builders than can be a point of confusion so we should really stick to a \"One cable per 8 pin connector\" mantra when it comes to GPU power.\n\nThanks for coming to my Flange Talk. ;)",
      "I only have 1 pcie though. Tell me where to buy another one and I'll buy you a lobster dinner and two brazillian hookers",
      "Seasonic advertises the gauge of their 12 pin FE cable as specifically 16 Aug :)\n\nI believe the gauge of their stock PCIE cables on their OneSeasonic Prime PX-1000 and TX-1000 are 18 gauge.",
      "I was doing some digging on my own and Buildzoid did a video on daisy chain GPU power cables.\n\nHe was saying those daisy chain cables should be 16 gauge, but almost never are.\n\nAlso there is lot of variability in power supplies to the extent that a daisy chain can be hit or miss depending on several factors.\n\nPersonally on my old 2070(now on an EVGA 3080 FTW3 Ultra) I had instability issues caused by using a daisy chain power cable. When I went to 2 separate cables everything worked perfectly. Even on 2000 series they can be a problem.\n\nAlso last time any Tech Tuber covered this was 3 years ago on the 1000 series which we're way past that and into much higher power draw. They need to do some updated content to get the word out to not use daisy chain cables for 2000 or 3000 series.\n\nNow that we're seeing 400W power limits with an optional 450W bios from EVGA we're at level beyond what's safe for those daisy chain power cables. Unfortunately you can see even EVGA Jacob is running a daisy chain in his build(check his Twitter.) It's like people are still going on 1000 series thinking without realizing that thought no longer applies to 2000 and 3000 series.\n\nThe new mantra should be \"one cable, one connection\" when it comes to GPU power. \n\nI don't care that EVGA and Seasonic says it's acceptable for a 3080 to use a daisy chain on 3x8 pin power. I'm not taking that risk when the data seems to say they're incorrect.\n\nI've come to think that one should have ever should have even made those daisy chain cables.",
      "So i managed to get an MSI 3060 TI ordered from best buy that asks for 2x 8pin. My seasonic semi-modular PSU has a 2x 6+2 cable in there by default and an optional additional 2x 6+2. \n\nFrom my poor understanding of this, i should use one 6+2 connector from each \"line\" just for maximum safety's sake? That doesn't cause any other issues?  I do plan on fiddling a bit with some overclocking.",
      "I've been trying to find out if i can use a dual 6 pin or 2x 6+2 pins to connect to my 3070 thats on the way",
      "Aerocool made my PSU so it’s out of the question. Check out their support page https://aerocool.io/tech-support/\n\nIts like a bad joke. I bought it back in 2014, didnt think much of psu’s and i would never have done it again. I did submit a ticket a few days ago but I don’t expect much of a reply\n\nEdit: i take it all back, they actually replied, although my psu has been discontinued and they can’t help",
      "So? \n\nPsu’s have not really changed since then. If it aint broke no need to replace it. Although since my post i did end up buying a new one just because I couldn’t bother with the hassle.",
      "I have a 3070 Gigabyte OC Gaming that has a 8 and a 6 pin power connector. I have it daisy chained right now with no issues but now I am starting to get worried that I need to go out and buy more connectors.",
      "I do love me some science.",
      "You are fine on the FE with this.  The 3070FE is a 8pin to 12 pin adaptor, though spec'd for 225watts with the PCIE slot power you should be able to handle spikes to 275watts with well built power supplies as previous gen cards were doing that for the last few years.",
      "If you were getting less FPS on Final Fantasy 15 and the game was using less power, do you think that using 2 PCIe cables would have helped?"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "low",
    "matched_keywords": [
      "rtx 3060",
      "3060",
      "rtx 3060ti",
      "3060ti",
      "rtx 3060ti"
    ],
    "title": "Dell Alienware R10 GPU upgrade",
    "selftext": "Currently have a GeForce RTX 3060 12Gb GPU want to upgrade to better card also upgrading to 1000w psu,  the spec sheet shows Dells “supported” gpu upgrades below. do i have to stick with the following list? if so which would be a significant upgrade and I’m assuming it has to be Dell card or if won’t fit inside the case. ?\n\nAMD RX 5300\nAMD RX 5600\nAMD RX 5700\nAMD RX 5700 XT\nAMD RX 6800 XT\nNVIDIA GeForce GTX 1650 Super\nNVIDIA GeForce GTX 1660 Super\nNVIDIA GeForce GTX 1660Ti\nNVIDIA GeForce RTX 2060 Super\nNVIDIA GeForce RTX 2070 Super\nNVIDIA GeForce RTX 2080 Super\nNVIDIA GeForce RTX 2080Ti\nNVIDIA GeForce RTX 3060Ti\nNVIDIA GeForce RTX 3070\nNVIDIA GeForce RTX 3080\nNVIDIA GeForce RTX 3090",
    "comments": [
      "You could put in any card if you're upgrading the GPU as well. It just has to physically fit in the case! \n\nI would look to a 4070 or similar. Perhaps even a 4070 ti super....",
      "That’s what i thought, i’m used to building my own pcs but i bought my step son this Dell a couple years back and the case is tighter it won’t fit 3-fan style GPUs, i tried to buy through dell their sold out of everything and tech support guy told me i needed to use one these recommend cards but was eyeing the MSI GeForce RTX 4070 Ti it’s dual fan design should fit and be significant upgrade to the 3060 just need to swap the psu",
      "physical dimensions of the cards are usually well documented. sites like newegg allow for very granular filtering, including the size. the powersupply is so comically oversized that any consumer gpu should be fine as long as it will fit inside the case.",
      "Could always run it with the case side off. Or find a smaller variant of the 4070 like the FE"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "low",
    "matched_keywords": [
      "rtx 3060",
      "3060",
      "rtx 3060 ti",
      "3060 ti"
    ],
    "title": "RTX 3060 TI Heaven Benchmark",
    "selftext": "",
    "comments": [
      "Hi guys is this a descent score? I cant find any comparisons at the moment.",
      "Oh I nearly got a heart attack. Holy!",
      "I will run it on mine, brb",
      "I have mine coming on wed. I’m interested in running it on superposition benchmark on high settings at 1440 to compare to my other rig which has a 2060 super.",
      "Can you give me your exact settings? \n\nI got a 3060ti TUF OC running around 1940MHz and a 3700X and my score is only 3451 with 137 average fps. Sometimes is off",
      "Running my 1080ti now...\n\nfps:200.9\n\nscore:5062\n\nmin fps: 49.5\n\nmax fps:452.1\n\nLooks like you have solid 1080ti level performance.",
      "Just ran one. i9-9900k oc to 5.2ghz. 303fps\nMax FPS 592 \n7537 score",
      "The picture already showed the exact settings tho",
      "thats a very good score!",
      "Superposition is a more modern one, but it’s a heavy bench.",
      "There are quite a number of them, 3dmark fire strike or portroyal is another widely used benchmark, you can look them up on YouTube",
      "You were wise to notice. I did have AA on X8. Re ran the bench with it off and the score was 3787. FPS 150, max 305.3. \n\nIdk what percentage that would be over yours. I don’t wanna math it.",
      "That’s pretty good. I got mine up to 4358 so that’s pretty much right in the sweet spot",
      "I just ran a heaven bench on my 2060 super with a OC 75 on the core, plus 700 on memory. Ryzen 7 3700x, \n\nThe bench used same settings as you. My score was 2535, FPS 100, max fps 195, min 47",
      "Did it, same settings,  2080 Super\n\nFPS: 220.3\nScore:5549\nMin: 51.6\nMax:445.9",
      "RTX 3060 TI FE +100 core, + 500 memory, i7 10700k. \n\nFPS: 202.2\n\nScore: 5094\n\nMin FPS: 45.7\n\nMax FPS: 469.4\n\nSame exact settings.",
      "Hey, I've just received my Msi 3060 ti Ventus 2x. With the same settings I get a score of only 3883.. I have done my usual when settings things up, DDU, clean install of gpu drivers etc. Anything else that can cause this? Or is this just a shit card?",
      "I am having the same problem, after running it a couple of times i got a relatively consistent score  4488, 178.2 fps 9.7 min 404.1 max. Running a core i7-8700 non k with the same settings. I am also getting massive lag spikes and frame drops seemingly out of nowhere. Fresh drivers, Nvidia control panel balanced, 165 hz.",
      "5370 with my  zotac twin edge non-oc 3060 ti. Power management max performance in nvidia settings. \n\nFans loud as fuck though, think I need to undervolt before cyberpunk :)",
      "I have a Gigabyte 3060ti Eagle Oc with Ryzen5 3600. I got \nFPS: 204.4\nScore: 5149\n\nAlmost same as yours. Thanks though i was kinda worried when i ran my benchmark in other games"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "low",
    "matched_keywords": [
      "3060",
      "3060 ti"
    ],
    "title": "Help me choose the right GPU, please",
    "selftext": "Hi everybody,\n\nI need an advice. What would you choose between these cards:\n\n[ASUS Dual GeForce OC 3060 ti - 638€](https://www.amazon.it/ASUS-GeForce-DisplayPort-Funzione-Axial-Tech/dp/B098R4K8PV/)\n\n[Gigabyte GeForce OC 3060 ti (triple fan) - 634€](https://www.amazon.it/Gigabyte-GeForce-3060-GAMING-V2/dp/B09968R87B/)\n\n[ASUS Dual 3070 - 751€](https://www.amazon.it/ASUS-Grafica-DisplayPort-Overclock-Consigliata/dp/B098JXFQD6/)\n\n[Gigabyte 3070 - 750€](https://www.amazon.it/Gigabyte-GeForce-RTX-3070-EAGLE/dp/B096YKPCC6/)\n\n[Anything from this list?](https://www.amazon.it/s?bbn=460090031&rh=n%3A460090031%2Cp_6%3AA11IL2PNWYJU7H&dc&qid=1661261752&rnid=490203031&ref=lp_460090031_nr_p_6_7)\n\nI'm targeting 1440p gaming, would love a quiet GPU.  I have a 4k TV but 3080-90 are too pricey for me. The budget is max 750€ but if there is a better price/performance it would be great.\n\nThank you\n\nEdit: Just wanted to thank EVERYONE who read and replied to the thread.",
    "comments": [
      "For 1440p definitely the 3070, which is 15% faster than 3060Ti. Especially if you want higher framerates. For quieter, they are simialr, the Gigabyte might be quieter since it has 3 fans (might run at a lower rpm but can't say for sure).\n\nhttps://static.techspot.com/articles-info/2270/bench/Average_1440p.png",
      "the prices are to high at least for germany 3070 = 600€, 3060ti 500€. As you are from the EU region might be worth checking geizhals.de or .at",
      "How about [RX 6800 for 650€](https://www.amazon.it/XFX-SPEEDSTER-SWFT319-RadeonTM-RX-68XLAQFD9/dp/B09KW68M2G/ref=mp_s_a_1_1?keywords=6800&qid=1661264030&sr=8-1) ?\n\nIt's quite a bit faster than the 3060ti (1.25-1.3x, sometimes more) so it could make up for the lack of DLSS in some scenarios.\n\nUnless you want to use ray tracing then the 3060ti is a bit better + usually get DLSS making it much better.",
      "Don't agree with this, it's a 15% gain on average at 1440p.",
      "For 1440p clearly the 3070 or 3080 if you find a good deal but if I was you I would wait for the 4000 either to take one or got a 3000 at a good discount",
      "Ended up finding a 2080 for \\~30% less than a 3060ti. It's a loss of 10 fps on AAA titles, which for me isn't noticeable. Great card for the price!",
      "It is, a quick google shows this for example. Average with 12 games tested, 15% faster:\n\nhttps://static.techspot.com/articles-info/2270/bench/Average_1440p.png",
      "I didn't mention AMD because I thought it would be OT. On Amazon there are also these:\n\n[6700 XT](https://www.amazon.it/Sapphire-PULSE-Radeon-6700-12GB/dp/B08Y7ZYNDN/ref=sr_1_1?__mk_it_IT=%C3%85M%C3%85%C5%BD%C3%95%C3%91&crid=2ILT228VQJD6B&keywords=6700+xt&m=A11IL2PNWYJU7H&qid=1661263027&refinements=p_6%3AA11IL2PNWYJU7H&rnid=490203031&s=pc&sprefix=6700+xt%2Caps%2C149&sr=1-1) \\- 571€\n\n[6750 XT](https://www.amazon.it/dp/B09ZHV5PN3?tag=pcp06-21&linkCode=ogi&th=1&psc=1) \\- 564€\n\nthat are cheaper then the 3060 ti that I seem I can't find lower then 634€.\n\nMy only fear is losing the DLSS for the future.",
      "Geizhals.de is to compare offers of retailers--> caseking being a retailer. So caseking is not always the cheapest option",
      "I'm happy with my 3060ti, average 80fps at 1440p DLSS Quality on Control with all RT options on and almost everything set to max (except volumetrics). In Europe the 3070 is still a bit expensive for what it's worth, go with the 3060ti imo, I also average 80-100fps on RDR2 1440p with DLSS on Quality and almost everything set to Ultra. On God of War I average 110-145fps with DLSS Quality on 1440p using DF Optimized settings, quite a beast of a card",
      "https://www.scan.co.uk/products/msi-nvidia-geforce-rtx-3080-gaming-trio-plus-lhr-12gb-gddr6x-ray-tracing-graphics-card-8960-core-175\n\nThose 3070s are such a rip off get this instead its the best card you can get in your budget",
      "Have you checked ebay ? I usually find rtx 3070 for 640€ new and sold by professionals which adds a guarantee. I can find you one if needed",
      "What kind of games are playing? At what refresh rate in your monitor? Is the TV 60hz? None of those GPUs are really quiet but triple fans should keep things more quiet compared to dual fans. You can also undervolt whichever GPU you buy and have lower temps with the same performance hence having a quieter card.\n\n I personally wouldn't buy an 8gb GPU now, I upgraded from a 3060 Ti to a 3070 Ti for performance and didn't cost me a thing at the time but recently upgraded to a 3080 12gb because of VRAM. I also play at 1440p 165hz Gsync and on a 4K TV and with Ray Tracing on and max textures my VRAM was being maxed out in a lot of games even at 1440p. \n\nSo if you don't care about Ray Tracing I would go for the 6750XT at that price. If you care about Ray Tracing I would just wait for the 4000/7000 series at this point.",
      "2080ti is an option too. I run most games at high / ultra and reach 70+ fps on demanding games like FH5 and most of the time 165 fps on games like Rocket League.",
      "I have a rtx 3060ti and it's more than enough at the moment for 2k gaming, even at higher refresh rates. It even runs cyberpunk smoothly",
      "Is caseking.de any good?  They seem to have the lowest prices in Germany as of right now?",
      ">For 1440p clearly the 3070 or 3080 if you find a good deal\n\nYeah, I think if you want high FPS or performance long term then parring a higher end card at 1440p is the way to go, 3060 TI is better for 1080p gaming IMO, although could still do well at 1440p if the OP isn't targeting demanding games long term.",
      "Thank you for your time. I play adventure/action games (Control, RDR..), racing games and some sport games.\n\nI have a 4K 120Hz TV and a non-gaming monitor capable of 1440p 60Hz. I don't stream or play competitive gaming.\n\nAs you said the VRAM is a central topic, but I can't afford a 3080, it's too pricey here. In that case I should look at 6700 XT with 12 GB of VRAM.",
      "+1 for this. If you can, see if you are able to save a little more for this, plus will allow you to play in 4K on your tv!",
      "For low noise and temps at the same time imo you have 4 lines of cards: Asus TUF, Asus ROG, MSI gaming x and MSI gaming z. \n\nIm quite sensitive to noise and the msi gaming line always do the job for me. My current 3080 gaming x is the most silent card ive owned in a very long time, even at 100% load. Ive never owned an Asus tuf or rog, but they have very good reviews.\n\n\nOf course everyone has different noise tolerance. But for me, all the cards you listed would be too noisy..."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "low",
    "matched_keywords": [
      "3060",
      "3060ti"
    ],
    "title": "To anyone who bought a 20 or 30 series GPU in Europe, where and at what price?",
    "selftext": "Especially looking for 3060 or 3060ti",
    "comments": [
      "3080 FE, 699€ from the Nvidia online Shop in germany, September 2020",
      "Location: Netherlands @ Alternate.nl\n\nGPU: MSI RTX 3080 Gaming X Trio \n\nPrice: €780\n\nStatus: not yet received, queue position: 69",
      "Lucky one",
      "Location: UK @ Scan via nVidia.co.uk\n\nGPU: 3090 FE\n\nPrice: £1399\n\nDate: Mid Feb 2021",
      "3090 FE for MSRP, 1499 €, over at notebooksbilliger.de.",
      "3080 FE for £660 Scan.co.uk",
      "Nice",
      "3070 Gaming OC for €729 from computeruniverse back in December.",
      "MSI 3080 Gaming Trio X on release day for 840€ in Germany",
      "Asus Rog Strix 3080 OC for 920€ on proshop.at at release.",
      "GPU: Palit RTX 3070 GamingPro \n\nMarket: Amazon.co.uk (Nov 2020)\n\nPrice: £482 / €565 EUR",
      "Location: Denmark @ Proshop\n\nGPU: MSI RTX 3080 Gaming X Trio  \n\nPrice: €860",
      "Yeah, at the time I was just happy, but now it’s crazy that I got an FE one week after launch.",
      ";)",
      "Order made September, received in December.",
      "MSI RTX 3080 Suprim X, bought back in November for 939€ at ProShop (Denmark), with free shipping to Finland.",
      "7 minutes after release in Poland at MSRP in x-kom. Waited 2 months though.",
      "3090 at 1499€ in December at NBB",
      "3080 for £739 from CCL.",
      "Germany - Asus WebShop\n\nGPU: Asus ROG Strix 3080 OC\n\nPrice: ~ 900€ early January"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "low",
    "matched_keywords": [
      "rtx 3060",
      "3060",
      "rtx 3060ti",
      "rtx 3060 ti",
      "3060ti",
      "3060 ti",
      "rtx 3060ti"
    ],
    "title": "PC UPGRADE: RTX 3060 TI VS RTX 4070 TI",
    "selftext": "Hello Folks,\n\n  \nHere today to clear up some confusion I have. My current PC has following confugiration:\n\nProcessor: i7 13700k  \nGPU: Zotac nvidia rtx 3060TI Twin Edge  \nRam: 16 gb Corsair Vengeance 3600mhz (8x2)  \n1TB SSD: NVMe Kingston (500x2)\n\nSo I was recently planning to upgrade few things such has:\n\nAdditional 16gb ram  \n1 TB SDD OR HDD\n\nOR\n\nRTX 4070TI\n\nI can opt for only 1 one of the above upgrades. So can you let me know if the upgrade to new version graphics i.e. 4070ti will make any significant changes in my gaming performances or should I just upgrade the other two things instead.\n\nI have read online comparisons between rtx 4070ti and 3060ti and on paper it seems 4070ti does have a higher edge in almost everything. \n\nAny suggestions are appreciated.",
    "comments": [
      "Thanks buddy",
      "Depends on your resolution I guess, 32 GB RAM are neat but there arent many games which require or benefit from it especially on lower resolutions. Also stay away from HDDs unless you want just to back up stuff its not worth while for anything else in 2024.\n\n  \nSo the GPU seems the better deal for now, you can add more RAM later or buy some used ram later",
      "You'd get more of a noticeable improvement to your setup by going with that 4070 TI, on average it's basically twice as fast as the 3060 TI, and in some cases even more",
      "Unless you are buying used at a good discount, the 4070 ti isn't recommended anymore since it was replaced by the 4070 ti super.",
      "4070 ti is trash value. Go for a 4070 super + ssd or a 4070 ti super\n\nAlso 32 gb of ram will be less significant than upgrading to more ssd storage",
      "I have two 4k display, 250hz dual monitor setup.",
      "Ya I was inclined more towards graphic not gonna lie..but the price factor on which i get the graphic in comparison to other two products is huge. \nUsual gaming which I do:\nValorant\nFall guys\nRocket league\n\nEditing:\nDavinci\n\nThats about it. So I was just confused will upgrading graphic is worth a shot or should I upgrade the ram and other stuff to boost ny overall performance",
      "Oh didnt knew that. So if I am buying 4070 ti...then super is the recommened one. Thanks man, wasnt aware about that.",
      "Prolly 4070ti then if you are fine with having to drop some settings in a few games",
      "Well you don't need 32GB to play thos games you mentioned so getting more will amount to nothing, idk about Davinci as I have no use for these types of software, if anything that extra 1TB might be the only competition but storage is pretty cheap if you're not looking at only the high end stuff so I'm sure you'll be able to easily snag another 1TB at a great price in the near future, same for RAM.",
      "Thank you buddy."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "low",
    "matched_keywords": [
      "rtx 3060",
      "3060",
      "rtx 3060ti",
      "rtx 3060 ti",
      "3060ti",
      "3060 ti",
      "rtx 3060ti"
    ],
    "title": "RTX 3060 TI or RTX 4060 in terms or performance and value",
    "selftext": "Rtx 3060 TI - 300Eur and Rtx 4060 - 333Eur.\n\nI use Ryzen 5 3600 cpu. If I will change to rtx 4060, i have to upgrade my cpu to Ryzen 5 7600X which leads to change of MBO to DDR5 version and I have to change my DDR4 ram to DDR5.\n\n&#x200B;\n\nSuggest me which will be the best option at the moment on Price ¬ value ratio.\n\n&#x200B;\n\nShould I just change my GPU to RTX 3060Ti or Change the whole setup to RTX 4060/Ryzen 5 7600X DDR5 MBO and RAM?\n\n&#x200B;\n\nSay yours thoughts. I appreciate your opinions.",
    "comments": [
      "3060ti is the superior card",
      "I would go with 3060ti since it's a faster card + costs less. The 4060 has Frame Generator, but for new games it might not be useful, because it's worth to use when base frames are like 50+.\n\nIf you're fine with 8GB vRam then get the cheaper one and save for a new set in couple years. You can go also the AMD way gaining more vRam but loosing DLSS which is superior over FSR. Ray Tracing is not an issue here, since xx60 cards are not designed for that. \n\nBTW. There's no need to upgrade to AM5 for neither of those cards ;) Eventually you may watch discounts/offers or used market for things like 5700x (better single core performance + 8 cores), since 5800x3d have crazy prices nowdays.",
      "The rtx 4060 with dlss3 will help you when you are cpu bottlenecked so you can postpone somewhat your cpu/mobo/ram upgrade. So I suggest rtx 4060.",
      ">If I will change to rtx 4060, i have to upgrade my cpu to Ryzen 5 7600X which leads to change of MBO to DDR5 version and I have to change my DDR4 ram to DDR5.\n\nWhy do you think you need to do this?\n\nYou might not get all you can out of a 4060 with your current CPU, but you are *not* compelled to upgrade it. A 4060 will still work in a PCIe 3.0 slot (even though the GPU is a PCIe 4.0 device), though it only having x8 PCIe lanes is a bit more of a bottleneck when running at PCIe 3.0, compared with e.g. a 4070 with x16 PCIe lanes running at PCIe 3.0 instead of its native PCIe 4.0.\n\nThe 4060 is about 12-21% slower than the 3060Ti (GDDR6X), but uses less than 60% of the power, so it may cost less in the long run, and also gives you DLSS 3.x etc.",
      "3060 Ti is the better choice in this situation. 3060 Ti and 4060 perform about the same. Getting the 3060 Ti will save you money from having to redo the build.",
      "That's like 500 euro, and he had the option of a €300 3060ti.",
      "You can upgrade ypur cpu to 5800x3d, which itself is on par with a 7700x and put the mpney tpwards a 4070",
      "Neither. Get a 4070 or wait for a 4070 super 16gb. Getting a 8gb vram card in 2023 for anything past 179 USD is a horrible deal. If you're stretched financially, pick up a Rx 6700 10gb or 6700xt /6750xt. They are the best deal for the low to mid range.\n\nLook at hardware unboxed or gamers nexus on YouTube. There's no point getting a 3060ti or 4060 when better cards exist. If you really need Nvidia for some reason, 4070 is the best for budget, 4090 for anybody else. That's it.",
      "If your PC can handle it, go for a 6700 XT - same price as the 4060 but 12 GB of VRAM and much better raster performance. Best option if you don't care about RT or DLSS.",
      "With your pricing options, the 3060 Ti is a much better deal, just make sure it's tested, since you say it's a second hand deal.\n\nSome people might say that you are missing out on FG and advanced RT features, but on a 4060 level... those features might as well as not exist. Unless you really need your GPU to consume least amount of power, 3060 Ti. Otherwise, 4060.",
      "Like others already said, get a 6700XT or a 4070 if dlss is important for you. Both cards you named are not future proof. 8GB vram is not enough and low memory bandwidth makes 12GB on 3060Ti and 16gb on 4060Ti useless.",
      "Them new 40 series settings get a shit load of more fps on warzone 3 and thats NO CAP 🧢",
      "So I had assembled this 3 years ago - ryzen 5 3600 with gtx 1660 super and I play 1080p games. \n\nI want to upgrade to an nvidia RTX gpu because AMD gpu’s are expensive compared to RTX.\n\nAmd rx6700xt - 375€ \nASUS dual oc RTX 4060 - 333€\nRTX 3060 ti - 300€ (unused 2nd hand deal) seal is unbroken\nNew RTX 3060ti from stores is 372€\n\nI live in Latvia and the prices for these are crazy",
      "But DLSS for low/mid level card is superb. It's often a better compromise to use DLSS Balanced then reduce some details.",
      "In which application? At which resolution? Using which tool; Intel PresentMon?\n\nOr a bottleneck calculator...?",
      "I dunno where you calculated that but in nearly all benchmarks I saw the 4060 performs in like an 1% margin of error in PCIe 3 and 4. You shouldnt feel the difference",
      "Lol which 4k ultra texture games you gonna be playing a a 6700xt in 2-3 years? Avatar runs on 8gb comfortably at 4k and it uses some of the highest rez assets I've ever seen.",
      "You're not going to notice a CPU change with either of those cards. The cards are too limiting, unless you're playing like Valorant or something very CPU limited, and not graphically intensive.\n\nI'd just change the GPU to either card. Probably to the 3060ti if you just want to play low latency eSport titles. 4060 if you want to play triple-A Unreal 5 games with frame generation in the future.",
      "40>amd>30 40 has this nice frame generation",
      "used 3070 or 3070ti"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "low",
    "matched_keywords": [
      "3060",
      "3060ti"
    ],
    "title": "Suggestions on a 3060ti or better?",
    "selftext": "Looking to get a new GPU. Rocking a 2070 here and looking to upgrade thanks to a thicc bonus at work. Not really looking to get a 40 series that would be overkill imo. 3060 would be ideal but if theres a better one for a reasonable price I'd love to hear some opinions",
    "comments": [
      "Here are the most recent Steam hardware stats for VRAM. So yes, the majority of users has 8GB still:\n\nVRAM\n      \n128 MB0.80%-0.07%\n\n512 MB 3.06% +0.01%\n\n1 GB 5.13%   -0.30%\n\n2 GB 3.66%  -0.13%\n\n3 GB 1.47%   -0.06%\n\n4 GB 8.10%   -0.49%\n\n6 GB 13.86%  +0.09%\n\n8 GB 35.44% +0.65%\n\n10 GB 2.99%  -0.11%\n\n11 GB 1.29%   -0.09%\n\n12 GB 18.39% +0.60%\n\n16 GB 2.88%   +0.05%\n\n24 GB 2.21%   -0.17%\n\nOther 0.73%   +0.01%",
      "Where you from? Normally people from Europe like the 3060/3060ti. If you are from Europe, I have no clue what you should do\n\nIf not, I’d be looking at buying a used 3080, 6800xt, or 3080 ti. If you want new I’d be looking at the 6800",
      "Do you only play really old games? Maybe upgrade to 1440p?\n\nSwitch to AMD? It was like a breath of fresh air when I swapped from 1080ti - rx 7900xt. \n\nFor you at 1080p id suggest: rx 6700xt/6750xt, 7700xt. \n\nFor 1440p those GPUs would still be options but increasing to Rx 6800xt, Rx 7800xt would be optimal 1440p GPU's. \n\nThe rx 7900GRE is $550 USD for the best value 1440p GPU but that would probably be overkill as it's just above rtx 4070 super performance. \n\nFor Nvidia better than 3060ti but not 40 series really limits yourself lol, not sure why your against the 40 series, not that I think they are great value tbh. AMD this current gen is alot better value.",
      "6700xt-6750xt are better than the 3060 ti with more vram and cheaper. Around the 300$ range. Rx 6800 or 7800xt are great options as well. 7800xt being close to 4070 super performance. On nvidia side 4070 super is the only real semi budget option that’s worth it , 3060 - 4060 are a waste if $. Obviously going 4080 super is high and a great choice but that’s expensive, up to you.",
      "USA.",
      "3080 used is a bad advice, because it only has 10 GB vram and while slightly better than 8 GB vram, is still broken in lots of games already.\n\nalso there are a lot fewer 10 GB vram cards, so devs will target 12 GB vram for much longer than the rare 10 GB vram.",
      "Second paragraph then unless you can find a 3060 or 3060 ti for super cheap",
      "Phoenix RTX 3050 Gaming 8GB, almost strong as a 4060. Alot of people keep misinformation with an RTX 3050  \nEDIT: misinformation, because people won't add in Phoenix to the Phoenix RTX 3050, they just say 3050 and that's it.",
      "Definitely not rare. We are on a graphics card subreddit so we naturally think everybody has a 7800 xt and up. Truth is that a very very small percentage of pc gamers are packing gpus that powerful. Most people are still playing at 1080p and don’t have 12GB of vram\n\nI agree with you that lack of vram is not ideal, especially for my type of gaming. That’s why I went with a used 6800 xt and I love it. There’s no better graphics card on the market that beats its price to performance unless you get a really good deal\n\nBut ops talking about a 3060 ti. A used 3080 is the cheapest out of the listed gpus above. Maybe he can’t go over $300? That’s why I gave him gpus at several price points: 3080 at $300, 6800 at $360, 6800 xt at $380, and the 3080 ti at $415. \n\nI truly don’t believe he could go wrong with any of these options, and I don’t believe my advice can be classified as bad advice. Where’s your advice?",
      "Reasonable yes. Very reasonable to want a 16 gb graphics card.  But if he can’t go over $300 the 3080 is a good option . 6700 xt is also good at that price point, averaging less frames but the extra vram will come in handy as games becoming more demanding \n\nIf he was able to stretch the budget from his initial $220 (price of a 3060 ti) to $350+, he would be well rewarded. But not all of us have that option",
      ">3060 would be ideal but if theres a better one for a reasonable price I'd love to hear some opinions\n\nall 8 GB vram cards are broken in lots of new games.\n\nso the best low end card to get is the 3060 12 GB. AVOID the 8 GB version for said reasons.\n\nabove that, there are the 6700 xt, 6750xt and rx 6800.\n\nthe rx 6800 costs rightnow 370 us dollars, which would be the best performance/dollar to get and it has 16 GB vram, which is the amount of vram you want to have at least going forward.\n\n12 GB is the minimum, 16 GB is desired. 8 and 10 GB = broken.\n\nso if the thicc bonus is enough, look at the 370 us dollars rx 6800 i guess.\n\nif that is too much, the 3060 12 GB or the 12 GB amd cards (6700 xt, 6750 xt) are what you should look at.\n\nagain don't waste your money on 8 GB vram cards.\n\ndaniel owen and hardware unboxed did plenty videos by now on how broken 8 GB vram cards are, even at 1080p in some games.",
      "my advice is here:\n\n[https://www.reddit.com/r/graphicscard/comments/1elw3sp/comment/lgvey1k/?utm\\_source=share&utm\\_medium=web3x&utm\\_name=web3xcss&utm\\_term=1&utm\\_content=share\\_button](https://www.reddit.com/r/graphicscard/comments/1elw3sp/comment/lgvey1k/?utm_source=share&utm_medium=web3x&utm_name=web3xcss&utm_term=1&utm_content=share_button)\n\nrecommending the 12 GB 3060 as the cheapest option to get and pointing to youtubers to look at the 8 GB vram issue if desired and recommending 3 cards above the 3060 12 GB if more money or buying used version of them is acceptable.\n\nand in regards to 8 GB, YES lots of people are still having 8 GB vram cards rightnow, however the minimum to play without issues moved on the graphics industry especially nvidia refused to do so, despite game devs screaming at nvidia to give cards the bare minimum of vram.\n\nso 8 GB vram cards will still run games at 1080p with massively lowered textures and vastly worse visuals, but it is a bad experience and becomes an afterthought more and more.\n\nand 10 GB is already an issue,  but what is the new high effort target to hit? well it isn't 10 GB, but 12 GB. nvidia selling a lot of 12 GB vram cards, amd doing so as well.\n\nso it makes sense to dodge sth, that won't be thought of longterm at all.\n\nif nvidia stays a piece of shit, but won't double down on insane 8 GB next generation, then it will start at 12 GB vram minimum, so that will just further push the 12 GB vram for ideal experience target.\n\nso it certainly seems reasonable to avoid the rare 10 GB cards and go straight to 16 or at least 12 GB.\n\nno rx 6700 or 3080."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "low",
    "matched_keywords": [
      "rtx 3060",
      "3060",
      "rtx 3060 ti",
      "3060 ti"
    ],
    "title": "NVIDIA GeForce RTX 3060 Ti already arriving to first customers",
    "selftext": "",
    "comments": [
      "3060 Ti: virtually everything about it leaked weeks in advance, including official marketing slides\n\nNVIDIA two days before alleged launch: *3060 Ti? Never heard of it.*",
      "*act suprise when nvidia announce the 3060ti*",
      "Some countries somehow got them really early, Saudi Arabia is selling them for over two weeks now, retailers in Serbia and Bosnia and Herzegovina have been selling them for over a week now, Croatian PC shop already listed prebuild with it.",
      "First customers? When were we (they) able to buy them?",
      "is it the new gamer bread?",
      "No, actual announcement is supposed to come tomorrow.  Source: random sketchy tech site on the internet.",
      "$399 MSRP for the FE according to Videocardz. AIB cards will be more expensive.",
      "So are the reviews coming out tomorrow? Are they just going to announce it and launch it right away? I really want one of these",
      "Pre-ordered mine in Canada last night.",
      "Add suprised Pikachu face",
      "That's an almost hilariously long cooler on that card. The PCB stops several inches before the cooler does. Might as well chop off the end and get some more case compatibility there.",
      "Customers? Do they mean bots?",
      "Where? I haven't seen them anywhere",
      "525 Euro.\n\nThat will be the price of a good 3070 model when the stock catches up.",
      "My RTX 2070 Black is just like that too.  And I don't even remember anyone ever making a compact 2070 despite the availability of the small PCB for it.",
      "I'm guessing $670 cad so a little over $500 US after taxes?",
      "What’s the rumored msrp for the FE?",
      "It's probably cheaper to fab a cooler that size rather than refit all the machinery",
      "⣿⣿⣿⣿⣿⡏⠉⠛⢿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⡿    \n⣿⣿⣿⣿⣿⣿⠀⠀⠀⠈⠛⢿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⠿⠛⠉⠁⠀⣿    \n⣿⣿⣿⣿⣿⣿⣧⡀⠀⠀⠀⠀⠙⠿⠿⠿⠻⠿⠿⠟⠿⠛⠉⠀⠀⠀⠀⠀⣸⣿    \n⣿⣿⣿⣿⣿⣿⣿⣷⣄⠀⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢀⣴⣿⣿    \n⣿⣿⣿⣿⣿⣿⣿⣿⣿⠏⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠠⣴⣿⣿⣿⣿    \n⣿⣿⣿⣿⣿⣿⣿⣿⡟⠀⠀⢰⣹⡆⠀⠀⠀⠀⠀⠀⣭⣷⠀⠀⠀⠸⣿⣿⣿⣿    \n⣿⣿⣿⣿⣿⣿⣿⣿⠃⠀⠀⠈⠉⠀⠀⠤⠄⠀⠀⠀⠉⠁⠀⠀⠀⠀⢿⣿⣿⣿    \n⣿⣿⣿⣿⣿⣿⣿⣿⢾⣿⣷⠀⠀⠀⠀⡠⠤⢄⠀⠀⠀⠠⣿⣿⣷⠀⢸⣿⣿⣿    \n⣿⣿⣿⣿⣿⣿⣿⣿⡀⠉⠀⠀⠀⠀⠀⢄⠀⢀⠀⠀⠀⠀⠉⠉⠁⠀⠀⣿⣿⣿    \n⣿⣿⣿⣿⣿⣿⣿⣿⣧⠀⠀⠀⠀⠀⠀⠀⠈⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢹⣿⣿    \n⣿⣿⣿⣿⣿⣿⣿⣿⣿⠃⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢸⣿⣿",
      "Yet I'm still waiting for my launch day ordered 3080..."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "low",
    "matched_keywords": [
      "rtx 3060",
      "3060",
      "rtx 3060 ti",
      "3060 ti"
    ],
    "title": "[Eurogamer/Digital Foundry] Nvidia GeForce RTX 3060 Ti review: faster than 2080 Super, easily beats 1080 Ti",
    "selftext": "",
    "comments": [
      "No it bloody well not...\n\n[Sad 1080ti owner noises] :(",
      "It's the same as the Pascal, when the 1060 6GB beat the crap out of the 780 Ti, which was 2 generations old at that point.",
      "It's fine in like 8 months we can upgrade to a 3080.",
      "True except the 1060 6gb was also less than 300. Still a good deal by today’s standards but Inflation moment",
      "Summary charts imply roughly ~15% on average (1080Ti). Individual games may show larger/smaller differences than that, so depending on your tastes they may be worth something.\n\nI generally wouldn't consider the 3060Ti an upgrade for 5700XT/1080Ti owners. You'll have to spend more than \"$399\" to see an actual upgrade. \n\nIt does replace a 5700XT as the card of choice for WQHD though, at the very least until the 6700 makes its debute.",
      "The 1080ti is a beast tho! Still running strong. Plus it's paid for.",
      "I kind of hate my 1080ti...I want to upgrade but it plays everything so well at 1440p Its hard to justify a 3080 and $800+ lol",
      "How much does it beat it at 1440p? Id love to get as high as possible in my 144hz monitor without spending $500/700 on the 3070 or 3080",
      "Don't forget your 1080ti's resale value, still going for over $400/£400 on ebay. If you manage to get hold of a 3000 series card that's a solid discount.",
      "Hell yeah it's paid for itself, very strong card!",
      "I'd be lovely to get a 3080. 1440p is quite a sweet spot for 1080ti right now but CP77 is looking really nice with 3080/90s and full DLSS - RT :(",
      "1080ti was like the deal of the decade",
      "Don't you worry, they wouldn't release Cyberpunk until then :)",
      "People kinda forget how good the 1080ti is. It’s practically a 2080, even if the 3060ti was equal to a 2080 for 400 dollars that’s sick.",
      "ikr but damn wanna play that sweet Cyberpunk 2077 with RT.",
      "It's got nothing to do with inflation. This is companies being greedy and running up the supply:demand ratios like crazy.",
      "Except 1080TIs have held their value really well so you could turn around and sell the 1080TI for nearly what you paid for the 3060TI",
      "Nonsense. The 3080 destroys the 1080Ti and the 3090 SKU is for morons or professionals.",
      "Will hold out for the 460ti. This 1080ti is probably the best purchase I’ve ever made.",
      "For budget gaming this is a great card. But if you have a 1080Ti, you're going to want to go with 3080 or 3080Ti. Still this is good to see how far tech has come in only four years"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "low",
    "matched_keywords": [
      "3060",
      "3060ti",
      "3060 ti"
    ],
    "title": "New 4060 or used 3060 ti / 3070 (1 year)",
    "selftext": "I dont know what graphic card I should buy, this would be my first graphic card, I have a 550w PSU and wattage matters for me, the 4060 and 3070 costs 300USD, and the 3060ti cost 190USD, the 550w PSU is completly new so I can't afford a new PSU, I also have a R7 5700g.",
    "comments": [
      "3070 if in good condition. 550w is recommended for it so ur PSU is enough.",
      "- The RTX 3070 is the better GPU, as long as it's in good quality   \n- If you have a good quality PSU, you should be OK   \n- Look at Techpowerup's review of the RTX 4060 (https://www.techpowerup.com/review/msi-geforce-rtx-4060-gaming-x/31.html), and the average FPS:   \n   **At 1080P:**   \n   The RTX 3070 8GB averages 121.3 FPS   \n   The RTX 3060 Ti 8GB averages 106.4 FPS  \n   The RTX 4060 8GB averages 96 FPS",
      "3060ti beats the 4060 and is like 90% performance of the 3070. Best value/frame by far.",
      "Update: the 3070 has 9m of use and 1 year of storage",
      "I never realized how close those cards are. 10% slower but $80 cheaper feels worth.",
      "Yeah, the problem is the 3000 series are both triple fan, and they use 220W at least with spikes of 250W, and I have a 550W PSU, I dont wanna get a shutdown and it's impossible for me rn afford a new PSU cuz the 550W is literally new",
      "Make sure to buy from a trusted seller. GamersNexus has a really good video on how to check used GPUs for defects: https://www.youtube.com/watch?v=J2VkkEHDG5E&pp=ygUVZ2FtZXJzIG5leHVzIHVzZWQgZ3B1",
      "3060ti is basically a underclocked 3070 with a bit less cores.",
      "The 3000 series are from FB MarketPlace, and the 4060 are from one of the most popular selles here in Mexico \\[DDTech\\]"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "low",
    "matched_keywords": [
      "3060ti"
    ],
    "title": "Best NVIDIA GPU for mid-range (around 400-450€)",
    "selftext": "Hi Guys, my 1060 6GB is slowly but surely starting to show its age and I was thinking about an upgrade since I noticed that GPU prices are dropping now. I haven't been really following the whole situation with LHR, 3XXX series and so on, but would like to ask you guys - which GPU would you recommend for around 400-450 euros? From what I've seen, a **used** **3060Ti** looks to be the way to go but will gladly hear from you.   \n\n\nFor the record, I live in the Netherlands and would be gaming on **1080p** (preferably 144FPS, but I'm not locked on that, main goal is **60fps with RT** if possible). No upgrade to 4K yet in the foreseeable future. I don't mind using DLSS in games either.\n\nEDIT:\nJust learned about 40XX series and since it's not urgent I'm also keen on just waiting out for 4060.",
    "comments": [
      "3060Ti",
      "1080p 60 fps with RT? 3060Ti.\nCan try your luck and get used 3070 for 450-500 euros",
      "Nvidia options - 3060ti, 3070ti(used)\nAmd options - 6700xt, 6800(used)",
      "RTX 4060 ti when it comes out. Don't suck up to Nvidia and pay MSRP for 2 year old cards.",
      "nowhere to be found for that price in EU..",
      "I understand, I currently live in Germany and the MSRP of 3060ti on Nvidia's website is 440 Euros which might even get lower in 2 months.  \nYou can also join notification groups on telegram or use sites such as GPUTracker to get a better understanding of your region.  \nPersonally, spending 600 Euros on a 3060ti is way too much considering that the new GPUs are just around the corner(fall of this year)  \nOne more thing I would to like add is that 3060ti is not an amazing card for RT with the mentioned price even though it does have the best value/price ratio(MSRP) but again for 1080p it would be sufficient.",
      "With quality DLSS, Ultra RT, and 1440p, a smooth 60fps goal isn't viable in Cyberpunk 2077. You get around 40-50fps average and it dips below the 40s sometimes. So I think it's important to set expectations here correctly, people are asking spending advice here, man.\n\nIn my experience, I had to lower DLSS to Performance in order to get a smooth 62fps average (benchmark) for Cyberpunk 2077, 1440p with everything Ultra RT. Even then, it will still dip to the high 40s (especially during Johnny's reunion gig).",
      "Oh really? I'm curious as to why you would call that 'maxed.' Because 'maxed' in DLSS for Cyberpunk 2077 is either Quality or Ultra Performance, Performance is somewhere near the middle of the spectrum. Anyway, it's still far from your 80-90 fps at Ultra RT 1440p claim.",
      "3070 second hand",
      "I would like to add that it's not urgent purchase. I am okay with 1060 for a couple more months. Had no idea about 4060, so that seems also like a good option (to at least wait and see benchmarks)",
      "used 3070 for 400$",
      "Problem with 3060ti I have is that the new one around me is 600€ which is bit outside the budget",
      "even if you end up not wanting a 40 series, the announcement and subsequent release of the newer GPUs will decrease the 30 series' price allowing you to get a more powerful 30 series",
      "It does sound great! It is quite difficult to get 3060Ti though for under 500€ around here tho so I'm trying to wait and see",
      "be careful with the 3060ti, among these video cards there is a defective batch with hynix vram",
      "Are there any shops you'd reccomend getting pc hardware from?",
      "I recommend checking http://nl.pcpartpicker.com since it shows the lowest price for all their trusted shops (and nl. since it then shows all Dutch shops). Did the same thing with a friend. Sometimes you might be able to find it cheaper elsewhere, but it’s still better than checking every website manually.",
      "[Mindfactory.de](https://Mindfactory.de)  \n[Notebooksbilliger.de](https://Notebooksbilliger.de)   \nFor used GPUs, you can use the German eBay \"[E.ebay-kleinanzeigen.de](https://E.ebay-kleinanzeigen.de)\"",
      "4060 likely won’t be until next year if you want to wait. It’ll be one of the last 4000 cards to drop",
      "Yo will get dips below 60 with dlss quality and Rtx ultra on a 3080 at 1440p. No bueno on a 3060 Ti"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "low",
    "matched_keywords": [
      "rtx 3060",
      "3060"
    ],
    "title": "Is a GTX 1080 worth buying right now?",
    "selftext": "I've been tracking gpu prices on the used market in germany for a long time now (probably since Jan 2021). The general trend of gpu prices finally going down for the first time in almost 2 years is a huge opportunity for those who where left with a complete PC build but still missing a graphics card in their system.\n\nI have a GTX 970 (paired with a R5 3600 - horrible combination) right now, but with the games I'm playing are really not running well at this point on 1080p. I'm considering buying a 1080 for about 300-350€ since the price to performance ratio is far better than with a new rtx 3060 at \\~550€ or a 6600xt for \\~500-540€. \n\nMy main concern is the longevity of the 1080 which is why I'm asking in this subreddit. Is it worth buying a GTX 1080 for 300-350€ used in terms of its lifespan for the next 3-4 years?",
    "comments": [
      "Its already out lived its lifespan, it's only going to go down hill from here.",
      ">Well, I have a 1080, beats anything bellow a 2070, 3060 and 5700xt.\n\nMore like below a 2060. Still a great card.",
      "Or if OP looking for used card, look at 2060.",
      "I dont think anyone said the 1080 was obsolete, still an amazing card.",
      "Yeah, yesterday I was comparing my 3060 to 1080 and 1080ti in the new cyberpunk patch, and in the benchmark run they added, the 3060 was 25% faster than the 1080 and 5% faster than the 1080ti.",
      "Modern AAA games are shit anyways so no real loss",
      "Honestly I'd stretch to atleast am RTX card just for DLSS. It helps keep the card performing well",
      "Last summer I sold my 970 for double it’s worth, put some more money and got the 1080, I’m very happy with it, I play on 1080p ultra wide whit 60+ fps, 8gb of vram so no problem on that regard, unlike the 970\n\nAnyways, if you can get it for a good price, it may suit you, but 30x series whit dlss it’s definitely better",
      "Nice assumption, but keep your assumptions to yourself next time. I have 960 4gb myself so even older than yours :)\n\n>saying something that's 0 facts but 100% feelings and opinions. \n\nHow ironic\n\nIt's still an ok card, and works well enough for my needs. My point being, with all the wear I doubt it will last the next 3 years without at least 1 fan stopping working completely. Fans can of course be replaced, but the risk of it just outright stopping working/developing those weird lines grows with age.",
      "Stop.\n\nStuff doesnt get better with age when it comes to gaming tech.\n\nIf youre happy, that's great. But stop pretending a RTX30 series card doesnt offer a ton more than a 1080. Because they do. In the real world, that is.\n\nThere is no argument here",
      "!remindme 3 years",
      "it depends\n\ni'm using one and i'm yet to find a game i can't run at full settings, though that may be because i'm using a 1080p monitor\n\ni *could* say it's worth buying but i'd much recommend trying to get an rtx card, you'll get great features like rtx and dlss",
      "Since GPU prices are falling, I'd just wait a tad bit long and not give in, you will likely find better deals soon. Just like you I'm in similar situation when it comes to cpu power vs gpu, not a great combo.",
      "GTX 1080 is good for 1080p gaming imo, but maybe not for another 3-4 years (it would be 8-9 years old at that point). Keep in mind the performance is around RTX 3060 level. Then once you enable DLSS or use any RT features even a 3060 will blow the 1080 out of the water. I went from a 1080 to a 3070 when I finally found one at a good price, 1080 resold at 75% of what I paid for it 4 years ago, huge increase in performance.",
      "I don't really buy used shit at all. I'm just not dumb enough to treat almost 6 year old technology as \"new\" in spite of what it supports and what its support lifespan will be like just because I found it \"new\" in box. It's still an old card and lacking in areas whether you bought it in 2016 or 2018 or 2022. Baffling you don't get that.\n\nAnd those 3 years of operation you think is a huge difference literally only matter if someone ran the piss out of it with negligent overclocking skills for that time period. The card is going to be EOL before the hardware life ends.",
      "I'd really consider RTX 2060/3050 instead because they both offer DLSS which is actually great for longevity and then Turing/Ampere are better suited for modern games.\n\nOn the other hand if you game at 1080p and you can get the card at a decent price, go for it. In terms of power efficiency GTX 1660 Ti is a lot better though while being just ~15% slower.",
      "Date of release is what matters, not date of purchase. If you found a GTX 280 new in box and bought it, it's not suddenly a new card from 2022. \n\nDate of purchase literally only matters for warranty claims otherwise no one gives a shit.",
      "eh i really don’t know what to do about gpus really. i only really play minecraft and GTA and i wanna play with the best graphics i can possibly get while still keeping the game playable. i have an i5 8400",
      "\"hurr I've never heard of driver support, game support, relative power, or EOL\" -you",
      "Date of product release absolutely is important. It's going to be the best indicator of support lifespan. As well as an indicator of what tech standards it was designed around/supports. \n\nThe only way to get a more definitive answer on support lifespan beyond that is the company coming out and telling you \"yeah we're cutting support next year...\" but they don't generally disclose that super early."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "low",
    "matched_keywords": [
      "rtx 3060",
      "3060",
      "rtx 3060 ti",
      "3060 ti"
    ],
    "title": "Is it worth upgrading GTX 1660 to RTX 3060 for Ultrawide 1440P?",
    "selftext": "So I recently upgraded my 1080p monitor to 1440p 144hz ultrawide and now I feel like I need a graphics card upgrade. In my country there isn't really any MSRP options, so the cheapest 3060 costs 600€ (Gigabyte Eagle). I was considering a RTX 3060 TI as well, but the cheapest one is around 800€, so that isn't quite an option for now. Is it worth upgrading to RTX 3060 for such price or should I wait bit more and buy 3060 TI for lower price?\n\nEdit: Thanks to everyone that answered, I will wait for 3060 TI to drop price a bit and then will go for it. By the way I'm not targeting 144fps with this gpu, I know that for this resolution something like 3070 or 3080 is more reasonable.\n\nEdit 2: If anyone will stumble across this post, I bought RTX 3060 Ti around 2 months ago for 580€. GPU is great not only for Ultrawide 1440P, but it also manages to play many games in 4K Ultra with DLSS (obviously)",
    "comments": [
      "I say wait and save. This will let prices fall more and hopefully stock to improve so you have more choice.",
      "nope. Warzone, World of Warcraft, Cyberpunk, new world, Battlefield V etc all drop below 140 fps in many areas if you don‘t have a super optimally binned 10900k with fast 4000+mhz ram, overclocked cache and a super high end system. \nI have an overclocked 3080 at 2040mhz, a 10900k at 5.3 ghz and the cache is at 4,7ghz, ram at C16 16 16 19 and I still get drops to low 120s in some area and my average fps are at 140 high settings  no raytracing in almost all the games except cyberpunkt at 2560x1440. in cyberpunk I get 70-100 fps at ultra with rtx on. so no, the 3080 is not overkill for this screen in any way.",
      "3060 Ti will handle 1440p well enough, but in the newest AAA titles you may want to lower settings to med/high.",
      "how did you get those fps? share your settings please.. i ahve similar build 8700(nonK) 3080Ti 5120x1440 just getting 100-120fps on COD:CW, in WZ is even lower depends on map..",
      "You need a 3070 to fully utilise that monitor",
      "you won‘t get the fps your screen can display. you need at least a 3070 ti or better a 3080",
      "3060 is a 1080p card, it wont do 1440p 140hz on every title. \n\nyou need 3060 ti and 3070 for that",
      "Not really. Cyberpunk hits a solid 80 with DLSS set to quality with my 3070. While a 3060 won't be sufficient for it, a TI should pull close enough to hit 60 with a few settings turned down.",
      "you‘re cpu bound bro. warzone and cold war will not fully utilize your gpu because of your cpu. you can increase your fps by overclocking your cpu, lower the ram timings (if you can) and overclock your cpu cache.  these few steps added about 20 fps in downtown for me. i‘‘ at 125-145 fps in downtown now on my 3080 10900k 3600 mhz 16-16-16-19 ram setup. all high settings 1440p",
      "Honestly I always felt like the 3080 was the perfect card for 1440p if you want great frames at max settings. When I saw a 3070 was recommended in the specs for cyberpunk for 4K I was thinking yeah maybe at 30 fps? lol",
      "Well that was kinda stupid, I’m not sure why you thought more cores were gonna give you big difference in FPS",
      "No. Games cannot just utilise all the CPU threads you throw at them.",
      "I run that with a 3080 and comfortably run what I want, but I'd suggest a minimum of a 3060ti, if not better and you'll be having a good time.",
      "I’d wait until an affordable NVIDIA 3060Ti FE or if you really want the 144hz 1440p performance on max settings not even a 3090 will deliver that on all titles especially AAA graphical showcases, well not without DLSS. An FE 3080 not a 3070 will be a reasonable and cost effective better alternative. I own a 3060Ti FE and am happy with its performance reaching 75fps on all my games on ultra wide but I don’t play at 144hz, which you can do with a 3060Ti if you lower settings to high and use DLSS where you can.",
      "Even with a 3060 you'll need to turn settings down to hit 60FPS",
      "I recommend anyone to just go next gen consoles until GPU prices aren't insane. I got a Asus Tuf 3080 for $699 December of 2020, now they're like $1800. It's just not worth it right now unless you can write the cost off with work.",
      "So, i too have a 3440x1440 100hz Monitor and a 3060 (before i had a 1070) and i have to say its obviously better but a 3060 wont get you even 100 fps in most more intense games i would have gone with an msrp 3080 but yeah you know how the sitiuation is, id recommend waiting an buying the best gpu your budget will allow",
      "My 3060 vision oc plays games fine at 1440p",
      "Not really. I made do with a 2060 for a full year, and had no issues hitting 60 FPS even in AAA titles.",
      "2080S is fine, 3060Ti would also be fine."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "low",
    "matched_keywords": [
      "rtx 3060",
      "3060"
    ],
    "title": "Best RTX card to buy right now?",
    "selftext": "**READ THIS BEFORE YOU CONTINUE + TL;DR: THE TITLE HAS A TYPO, THE QUESTION IS WHAT'S THE BEST RTX GPU TO BUY RIGHT NOW THAT'S NOT EXTREMELY EXPENSIVE SO I CAN GIVE IT TO MY YOUNGER BROTHER (PREFERABLY FOR HIS BIRTHDAY)?**\n\nSo I built my first PC ever for myself. Once I was done doing that, I gave my older Pre-build to my younger brother — for anyone interested, my PC is an R9 5900X and MSI Ventus 2 GeForce RTX 3060; not the best 3060 on the market but it's a sound card based on my experience, so it is what it is. My younger brother is 7, so I'm not expecting him to be a legitimate gamer any time soon, but he's already starting to experiment with Minecraft mods so it's only a matter of time.\n\nThe problem: The prebuild doesn't have a dedicated GPU, it has a R5 5600G — it only has Vega graphics. It's an okay computer, nothing really wrong with it, but if he's already experimenting with Minecraft mods, sooner or later, he might go in a direction of gaming where he needs a legitimate graphics card and a more robust CPU.\n\nI already know what CPU to get him (an R7 5700X or R7 5800X) but I need ideas for the GPU. I want to get him a GPU that isn't too expensive, but will also support ray tracing and DLSS - so GTX 1600s and below are already out of the question, and any 3000s or 4000s series RTX is out of the question. So that leads me to the 2000s series; RTX 2050 is probably the cheapest of the RTX GPUs (IDK) but it's also the weakest of the RTX GPUs, so excluding that one, that leaves the 2060, 2070, and 2080 (including all Ti and Super variants of each). Fortunately, we can't get legitimate 4K UHD monitors, so 4K gaming just isn't going to be an issue, but the GPU still needs to be able to do decent 1080 gaming at least. I'm already kind of nervous about jumping into the used GPU market, and some of these cards were used for mining (not that it was as much of a problem as it was hyped up to be, but that was the reason the GPU market was and still is F---ed up) so I thought it's probably better to ask a bunch of strangers on Reddit to help me with this decision (along with praying).\n\nSo my question is, what is the best RTX GPU I can buy on a budget?\n\nEdit: since a few people are asking this question, I'll provide the answer here.\n\nSo my budget for the entire upgrade (assuming I can get away with the power supply I already have) is about $500 (more or less). About $200 of that would go to the CPU so that leaves $300 for the GPU. I guess generally speaking, I could just get an RTX 3060, but most of them are in the high $300 range (almost $400). So going older might be my best bet — despite the used GPU market being horrible too",
    "comments": [
      "Best RTX card to buy: 4090\n\nez\n\nTitle: 3/10 for not being specific\n\nReal answer: IDK get a 4080 I'm not reading allat",
      "4090",
      "It took a lot of research, but we both ended up with the same solution for OP. The best RTX card is the 4090.  Let's mark this as solved and close the thread.",
      "I wouldn't waste $$ upgrading the CPU. The benefit will be minimal (maybe 10%, check YouTube benchmarks). That $$ could go into a more powerful GPU, which would have a more noticeable impact. I know you are asking about RTX cards, but you can get pretty good bang for your buck with non RTX. Eg a used 1080 Ti is $200 on eBay and is more powerful than your GPU. If you want to avoid used cards, there have been a lot of good AMD deals recently -- 6600 $200, 6700 $290, 6700xt $305. Or you could get a 6950xt for yourself ($600, more powerful than a 3090 and close to 3090 Ti) and give your bro the 3060. Note that you may need to get a new PSU if you get a 1080 Ti or 6950xt.",
      "2070 maybe? That 8GB of VRAM is going to be essential.",
      "I mean i really can’t think of other than that one. I'd say 4090 too",
      "[SOLVED]",
      "Seriously….",
      "4070 ti",
      "and thats how a 7yo kid ended up with a 4090",
      "Ah my friend, on a budget of $2000 or less the answer is the same: 4090",
      "That current CPU is solid.\n\nTake the combined 500, stretch it slightly, and get a used 3080 or discount 4070.\n\nOr just get a 3060 12gb and call it a day.",
      "RTX 2070 or RTX 3060 I would say",
      "What's the right price for you here?  Honestly curious.  You said it can't be too expensive but not sure what your budget is.",
      "on a budget you are looking at the 6700xt, if you can spare the extra cash for a 4070 though, dlss 2&3 have a big impact in games that would otherwise be unplayable. \n\nlower tier 40 series cards won´t have enough vram, and are somewhat bandwidth limited.",
      "If you get a 3060 get the 12gb and not the 8gb.  The 8gb is ~20% slower.  #justnvidiathings",
      "I was researching similar situation recently also for my younger brother, and even though he is not 7 and budgets are higher, we did consider reusing some parts and going the cheaper route with 12400f+3060 type of segment, which is exactly what you are trying to do. The closest alternative to save some money that would still be competent (having DLSS, working well with older games, not too old and etc) would be used 2060 Super. It may vary by region, but here it can be found for around two thirds of the price of new 3060 and it is almost the same performance, but they are rare. Stretching for new 3060 would still probably be more reasonable though.",
      "Give him your 3060 and get something better.",
      "That was the card I was thinking of, I just wanted to make sure I wasn't looking in the wrong direction.",
      "The difference between a 5600G and 5600X in games is <10% (probably closer to 5%). See here: [https://youtu.be/ReN06Kw4y4I?t=273](https://youtu.be/ReN06Kw4y4I?t=273) \n\nIMO it isn't worth dropping $150 on the CPU (or the hassle of trying to recoup some $$ by selling the 5600G)."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "low",
    "matched_keywords": [
      "3060",
      "rtx 3060ti",
      "3060ti",
      "rtx 3060ti"
    ],
    "title": "Undervolting has no effect on a 3060ti Gaming X...but kind of has??",
    "selftext": "Recently I got an \"MSI RTX 3060ti Gaming X\" (LHR), and just like any other GPU I ever got I decided to take a tour in MSI Afterburner, Overclocking, Undervolting, Experimenting, find the sweet spot for everything in general...\nAnyways, after playing with the curve editor in the voltage section a bit while running MSI Kombustor in the background I noticed that no matter the curve use, nothing was changing, no drop in wattage nor in temperatures, actually some curves added 1-2 C° to the temperature..weird right? Well, it's about to get weirder...\nSo at some point I just assumed theres some sort of Voltage lock and moved on.\nAfter few days while playing Warzone I noticed that I was getting less temperatures while I was experimenting, so I decided to run it back, and indeed, at 825mv by 1800mhz dropped temperatures by atleast 5 degrees and wattage by 10 watts, not much but noticeable, you might think it worked right? Well, not entirely..after testing more games it was obvious that the card acts undervolted in some titles while completley ignoring it in others!\n\nHere are some of the games and the results I got for each one:\n- CoD MW3/Warzone: 64 C° -> 58 C° :✔\n- Metro Exodus: 67 C° -> 60 C° :✔\n- Cyberpunk 2077: 67 C° -> 63 C° :✔\n- Red Dead Redemption 2: 70 C° -> 70 C° :❌\n- Hellblade Senua's Sacrifice: 70 C° -> 70 C° :❌\n- Rocket League: 67 C° -> 67 C° :❌\n\nAs you can see, temperatures did drop in some games but no effect on the rest for some reason.\nI'm really losing it, I cant seem to find anyone with a semilar issue nor have I been though it my self...I have been doing this for years.. 1650, 1660 Super, 2060 Super, 3060, it was as simple as a couple of clicks for these cards and the results were about 10 C°/ 20 Watts less on all games no matter what.\n\nSo what do you guys think? Voltage Lock? Driver Issues? The fact that it's an \"LHR\" card has to do with this? Please enlighten me I'm really lost",
    "comments": [
      "why would you need to do this.. ?",
      "Afterburner >  General settings > try different Compatibility options.......   when you see your curve setting does not seem work, click reset button and do it again by slightly different setting, say if 1800 @ 825 is not seem to be working then do 1834 @ 825 or 1800 @ 835....... my undervolt is substantial i play 4k 60fps fortnite with dlss quality with 120-140 watt , i have a gainward card tho (stock card is specced as 240watt)",
      "Well first 70c isn't going to hurt anything. I am just an idiot with this stuff. I don't think you can compare between games. One might utilize the gpu more than another. In MSI Afterburnner it shows you the 825mv you set it to. Does it go higher than that? Just because you set it to 1800mhz doesn't mean it won't go higher. Find a benchmark tool and run tests over and over as you make adjustments. Not all games are optimized the same. Nor are all the in-game settings the same. I have a 3060ti. Benchmark and look at similar scores with similar specs.",
      "Stock fan curve honest reaction:",
      "My MSI 4080S does. I have the same type of undervolt curve as I did for my last 4 GPUs (2 AMD, 2 NV) and it works great. In 3DMark, the card runs at stable 2715MHz @ 1000mV, instead of hitting the power limit at around ~2700MHz and ~1100mV.",
      "It does. Its actually the other way around, amd only allows you to work in parameters.",
      "You might be more cpu bottlenecked in those titles.",
      "Yeah to be honest I am still using my 3060ti that I used for some mining during the boom, after I posted this I remembered that I have done it, I had a founders 3060ti and under volting did help keep temps down, the founders card was really good with memory OC's even undervolted.",
      "[https://github.com/LunarPSD/NvidiaOverclocking/blob/main/Nvidia%20Overclocking.md#undervolting](https://github.com/LunarPSD/NvidiaOverclocking/blob/main/Nvidia%20Overclocking.md#undervolting)",
      "Also again I am an idiot. Your undervolt to mhz seems like your leaving a lot of performance on the table. I don't know what fps your shooting for but at such a low frequency your gpu might have to try and run at 100% to reach it. There are undervolting guides on YouTube for thr 3060ti. Seems you might have been doing it wrong for years.",
      "When the card isn't being limited by Vsync, framerate limit, power limit or low GPU utilization, it will clock as high as possible. So your undervolting can result in your card clocking higher with the same power consumption and heat. \n\nSo some of your games may have framerate limits, or be CPU-bottlenecked, or be less demanding - then you'll see a decrease in power consumption.",
      "As I understand nvidia GPUs don’t really respond to under-volting in the same way AMDs do. Right?",
      "I tried all the numbers on the graph bro, I went too low that games started crashing...its simply not working, I do see that the voltage stays at 0.820V when I set the curve otherwise it would be at around ~0.850V, but no effect on the temperature or the wattage",
      "Not even a fan curve worked lol",
      "This actually makes sense, I have it paired with the i5 10400f at 1080p, something like Warzone could be not benefiting from it's full potential",
      "but I still can't put my finger on the issue here, why cant it be undervolted? I've seen atleast 2 people on YouTube with the exact same variant managing to do it nice and smooth",
      "I think they do about the same, I think it's just this specific variant for this specific card, cause as I said, no semilar issues were reported + I can see it works perfectly for people online",
      "ok i read again your post more carefully, yea if its crashing  youre going too low, if card does not go beyond 0.850 / 1800mhz that  is an undervolt,  and you're wrongly thinking  its not working. 3060ti default voltage goes up to 1.05 or something, depending on load. did you try stress testing with fur mark and check total gpu wattage? yours is 220watt is max, if you get less then that, its undervolted (or throttled in other ways)\n\nALSO note, different games can utilize internal gpu chip differently and in different proportions, so benchmarking temperatures across titles might not give obvious clear results",
      "The undervolt is working but the card wasn't fully loaded in the first place due to the cpu bottleneck. Lowering gpu performance by 5% won't be noticed if the card only loads up to 70%.",
      "AMD doesn't have that kind of direct access to the frequency/voltage curve as nVidia does, but AMD's undervolt is more stable - you can just set a -100mV undervolt and it will be applied to the curve without question. On NV, things will sometimes deviate from the curve, or MSI afterburner will just randomly do some weird alterations to the curve during restarts etc."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "low",
    "matched_keywords": [
      "3060",
      "3060ti",
      "3060 ti"
    ],
    "title": "MSI 3060 TI Gaming X or iGame Advanced RTX 3070Ti?? ",
    "selftext": "hey there, got a deal for these 2 here in my country. When converted, $245 for the 3060ti while the 3070ti is $285. \n\n  \nI know this is a no brainer but I just want to check if any of you guys has experience with these brands? \n\n  \nMy current rig is 1050ti, so this would be a BIG leap. I mainly edit 1080p videos, sound engineer, and light gaming (league of legends) \n\n",
    "comments": [
      "Um 3070 ti of course lol",
      "technically, these deals are 2nd hand and sad to say, there are no 4060s going around in good deal as of the moment. \n\njust a follow up question, does the performance difference is not worth the 40$ extra?",
      "3070ti.",
      "If you do only light gaming, and power consumption is a concern, I'd go with the 3060 Ti. Otherwise, the 3070 Ti.",
      "Thanks for your input dudes, much appreciated! went with the 3070TI but it has oxidation issues but I don't think it will affect with the performance I guess?",
      "knew it already from the start, just here asking for unsolicited opinions blinded by brand names lol xd",
      "What? U realise the 4060 is slower than the 3060ti let alone the 3070 ti right",
      "ignore this guy.",
      "plus 4060s or TI's are relatively expensive than these two",
      "Then go with the 30 series options!",
      "3060 Ti since AFAIK, they're both 8GB in VRAM and you can use the $40 for something else considering you do other things outside of gaming.\n\nOtherwise, how much do 4060s go in your country? That might be worth the premium over the 3070 Ti."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "low",
    "matched_keywords": [
      "rtx 3060",
      "3060"
    ],
    "title": "RTX 3060 with i5 12400f?",
    "selftext": "Guys need your help. I am going to build a pc with rtx 3060 and i5 12400f. Is it enough to play all games at 1080p 60fps with High to ultra settings.",
    "comments": [
      "Easy",
      "the 12400f is such a good budget processor its not even funny and the 3060 is like a 2070 with 12gb vram, you are absolutely golden for 1080p, hell on a lot of games you can probably push 1440p",
      "It's like a 2070 super/1080ti/6600xt/5700xt\n\nHonestly with dlss and optimised settings(ultra settings is a waste anyway) it can easily do 2k",
      "Probably even 100+ FPS at that res unless you turn on ray tracing or the game is terribly unoptimized.",
      "12400 is great, you can even aim higher with GPU.",
      "This a perfect combo and this is literally my current build with 16gb ram 3200mhz. All games will run flawless at 1080p and 1440p at high settings. 1000% would go for the 12400F and a B660 with 4 slots for future proofing.",
      "Yes I saw YouTube comparison and rx 6600xt definitely 5 to 10 fps better in most games. But dlss2.0 one of the reason I'm moving towards Nvidia.",
      "Positive!!\nMake sure you use a 4.0 SSD",
      "For 1440p you for sure can reach that 70fps to 80fps range.",
      "I honestly still cant recommend a 3060 Ti over a regular 3060. 3060 Ti's are still a bit high imo. I tend to see 3060 occasionally go back in stock at msrp for a short time which is how I got my EVGA 3060 for $389 a month ago. Unless 3060 Ti prices magically drop or it goes on sale then I would for sure spend the extra cash.",
      "**ALL** games? No. No graphics card can run everything smoothly at 60fps because some games (even newer games) are just poorly optimized and some old games are wonky on newer systems. But you should be able to **EASLIY** run Ultra 1080p@60fps *or higher* on all properly made games.",
      "I built my very first PC on that specs and it works so good.\n\nI used i5 12400f with rtx 3060 12gb ventus OC edition along with gigabyte B660m and Samsung SSDs and NVME. Go with it.\n\nhttps://preview.redd.it/k212lo4wqc5a1.jpeg?width=2048&format=pjpg&auto=webp&s=1862e0f29a9f1cc732116dd1bdfe721d18cf811a",
      "I’m sure it can handle most 1440p well too. Not GPU intense stuff on really high settings, otherwise though…",
      "Yeah, if i was OP and he has a 4 ram slot board id just spec out 2 ram sticks for now 16gb (2x8gb) and get a smaller cap nvme for boot (256gb) and try stretch that budget to pick up a 3060ti instead, with how good the 12400f is, that would be a very respectable rig and should last years, and would be an excellent all round system that would be good at everything, OP can always add two more sticks of ram in a few months and a bigger 2nd ssd when they have the funds.",
      "why?",
      "Maybe it will CPU bottleneck on some games but I'd search i5 6500 3060 on YouTube and look at utilization. If 3060 is 90% or above most of the times in almost all/all games then it's good",
      "It was slightly slower than a 2070 super but that was at launch and we've got so many drivers, so I'm assuming the 3060 is atleast on par with a 2070 super which is plenty enough for 1080p with ray tracing.",
      "If you could slightly push your budget to a 3060ti you should consider it, the performance jump over the regular 3060 for games at least is huge, the 3060 is great and its nice to have 12gb of vram, but a 3060ti is basically a 2080 super, its a very very good card, so along with the 12400f you spec'd you'd be good for a while, that machine will be excellent for a bit of everything, mid - high end VR even and your budget shouldnt be too crazy now GPU prices have come down.",
      "Cheers for the quick response, unfortunately my budget won't allow it. But I'm a very casual gamer, only play at a single small-ish monitor and don't care that much for ultra settings, just want a good setup that is easy to navigate and will see me through for the next few years. My old build is an R260 AMD or something, all SATA no SSD. Considering that, would you still recommend it?",
      "I tried now and it runs about 55/60 fps with almost everything on ultra. \nThank and happy Cake Day!"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "low",
    "matched_keywords": [
      "3060"
    ],
    "title": "Gaming & Deep Learning: RTX 4060 8GB or the 3060 12GB?",
    "selftext": "Hi Im considering both of these cards for both gaming needs (mainly for Starfield at above medium graphics) and deep learning e.g. finetuning quantised LLMs. \n\nBecause of the increase VRAM of the 3060 I was thinking its the better card despite it being slightly (?) worse for gaming.",
    "comments": [
      "You might be one of the few people who the 4060ti 16gb is for lol",
      "The large VRAM needs of machine learning demands 12GB as a minimum.\n\nThere is the 4060ti 16GB for more breathing room.",
      "Definitely go for more vram =atleast 16gb. It will keep you sane while working with big models. Anyway, probably better to just buy gaming card and do your training on cloud. This way you can game while you train your model.",
      "8GB is just not enough for ML, it's the bare minimum and in most cases you'll just need a little bit more or your model will crash, because it immediately crashes after it takes more VRAM than it's available.  Also it's much better to use your own GPU than to use some online service. Most of them are too expensive I've used such services before I bought my 3060 and I think it's much cheaper to use your own hardware. For ML,  RTX 3060 it's just the best bang for buck. Also you can play games pretty decently, you'll just change the settings a little here and there and every game will run with descent performance and max settings. \n\n I also intend to play Starfield and I think it would run if not at max settings it'll run close to max settings. \n\nAlso there's soon going to be DLSS 3.5, which will include all RTX cards. \n\n Don't make that mistake to get 8GB card and then not be able to run the models, on games you can change resolution and other settings, but you can't run some models at all if you don't have enough VRAM. \n\n It seems most people who answered your question saw only the \"gaming part\" of the question, because getting a card with 8GB is bad advice for ML card.",
      "Tbh, I don’t see either of these cards running Starfield above medium settings. At least with the 12gb 3060 you could turn textures to ultra, then use DLSS to boost fps. 1080p DLSS quality isn’t nearly as bad as people say it is.",
      "I'll check this one out",
      "4060 doesn't have a 16 GB variant does it? Ti does",
      "It's a poor suggestion vs the RTX 3060 for your use case scenario. \n\nYes, the 3060 Ti is quite a bit more powerful than the vanilla 3060 (\\~25-30% increase), but the non-Ti variant having 50% more VRAM is going to be far more beneficial for machine-learning purposes. \n\nIf your choices are exclusively the 4060 8GB or the 3060 12GB, go with the 3060. However, I'd also suggest looking at the 4060 16GB variant. At $500 USD it's generally considered poor price-to-performance but - for you - VRAM is king and there aren't any better 16GB options from Nvidia near that price point.",
      "3060 with 12gb VRAM.\n\nYou're gonna need the VRAM w/ the way stuff's going these days.",
      "Is that even a question?\n\n3060 is better here especially for LLM. I use 3090 that have 24gb VRAM can handle something like 4bit 30B param model",
      "Get a 3090Ti/3090 for ML. 60 class is not meant for these applications",
      "If you get a 3060, buy it used, and buy two of them. 24GB total isn't bad, even though the speed isn't the best.\n\nAlternatively if you have the budget, buy a used 3090.\n\nThe 4060ti 8GB won't do much, the 16GB costs more than two used 3060s, and the 4080 costs more than the 3090.\n\nQuantised models are nice to have, but there's a point where if you go too low you lose more than you gain from having high parameter count. Grab yourself some more VRAM for a bigger model, you'll thank yourself later.",
      "If you care about deep learning you may want to ask on a r/deeplearning and say what you want to run. Or more dedicated forums like [https://forum.level1techs.com/t/mi25-stable-diffusions-100-hidden-beast/194172](https://forum.level1techs.com/t/mi25-stable-diffusions-100-hidden-beast/194172) \n\nNo one knows how Starfield will run yet, you will have to wait for benchmarks.",
      "They said Chinese companies buy a lot of 4060 ti 16gb for ML.",
      "Yeah good point, in that case would you recommend the 4060?",
      "Why do you recommend this one?",
      "We really need companies to start pushing for higher vram capacities. 16GB RTX 5050, 24GB RTX 5060, 32GB RTX 5070 and so on",
      "Is there a source stating this? Genuinely asking out of curiosity",
      "🫡Thanks.\n\nGonna get more ram with the money saved.",
      "both of these are so slow for LLMs that I question what you're planning on doing with them. If you just want to play around then it depends on dataset size (obviously more vram for larger sets).\n\n4060 will be faster until you hit larger than 8GB buffer load requirements and the 3060 will be faster at > 8gb. Both will be pretty slow, but the 4060 will be faster for most current games. This may not be the case for starfield since its an open world game by Bethesda and may eat VRAM for dinner."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "low",
    "matched_keywords": [
      "rtx 3060",
      "3060",
      "rtx 3060 ti",
      "3060 ti"
    ],
    "title": "Believe the Nvidia RTX 3060 Ti hype, GPU manufacturers are busy prepping cards right now",
    "selftext": "",
    "comments": [
      "I wish they'd prep to make some 3080s.",
      "So customers from another price bracket can feel annoyed too",
      "\"Believe the Nvidia 3060 Ti hype..\" \n\n(×) Doubt",
      "I love how 2080 ti level performance is now meager... Give a mouse a 🍪...",
      "there prepping there entire stock of 10 cards?",
      "And some 3070's",
      "Right? As if demand for a 3060Ti and 3080Ti and whatever else they come up with won't be already crazy enough. Maybe Nvidia could try to at least swallow their last bite before they take five more.",
      "All this stuff about database listings and rumors, but we've literally already seen the cards and packaging lol.\n\nhttps://www.notebookcheck.net/fileadmin/Notebooks/News/_nc3/Gigabyte_RTX_3060_Ti_Eagle_OC_SV_Comp2.jpg",
      "They want to annoy rich and poor alike. They are an equal opportunity annoyer\nThis generation they are also selling buyers remorse for dummies who went 3090 (ie: me)",
      "Just more shit that's gonna sell out and be scalped",
      "Nvidia handles vram better than AMD. Check out TPU's watch dog legion benchmark: NVIDIA cards with 3 GB and 4 GB VRAM do much better than their AMD counterparts in this memory constrained situation. For example, the 4 GB RX 5500 XT drops to only 12 FPS, whereas the GTX 1030 3 GB runs twice as fast at 22 FPS. This just confirms what we've been seeing in such scenarios previously—NVIDIA handles memory pressure much better than AMD.\n\nEdit: I don't want to get into a scrap with you and you are entitled to your opinion. But the assertion that 8 gb is not enough is mere speculation. As it stands right now, the 3070 is still offering good value to those that can get it. AMDs current closest offering is 80 more and they utilized SAM in their benchmarks, so we really need to see the third party reviews to get a sense of perf/dollar. But they are probably in the same ballpark. If you are under impressed with Nvidia's performance, you will likely be under impressed with AMD's. RAM don't mean jack if the horse power isn't there, #radeon7.\n\nAlso, I'm a proud owner of an AMD cpu for the record.",
      "$350 and I'll get hyped. $400 is out of my budget.",
      "Pheew....At least Youtube influencers will get one, so that's a relief. Almost had me worried there for a minute.",
      "I believe they’re different chips. \n\nGA102 - 3090 and 3080\nGA104 - 3070 and this rumored 3060Ti I believe?\nGA106 - 3060?",
      "They ain't wrong though, it will all be about hype and a nonexistent amount of cards.",
      "It’s 9",
      "Laughs at 1660ti pheonix. That shit had terrible thermals",
      "I don't blame you. GPU pricing is ridiculous and unfair right now. 60/70 series should be mid-range. Many vendors don't stick to MSRP either, so realistically you might be paying $420-$450 for a 3060Ti.",
      "2080 super",
      "If the 3090 serves u well than ur buyers remorse may wear off"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "low",
    "matched_keywords": [
      "rtx 3060",
      "3060",
      "3060 ti"
    ],
    "title": "RTX 3060 12gb vs. 3060 Ti 8gb for deep learning",
    "selftext": "Long story short, I'm a PhD student and have been using a RTX 2060 to train my networks. Lately, I needed a bit more grunt so have been looking at upgrading to a 30xx. The type of prediction tasks I'm working on aren't *that* memory intensive (or at least the current paper I'm working on isn't). Batch size of 5k almost takes up all of my 2060's 6gb memory. So, between the 3060 and 3060 Ti, one has more memory but the other more CUDA cores. I also suspect that even though 3060 has 12gb, you can theoretically fit a larger model but it will take a long time to train. Which one would you choose?\n\n&#x200B;\n\n[Spec](https://preview.redd.it/wvny8ryap3r61.png?width=1442&format=png&auto=webp&s=6874e91e7578c5338136b44e61063d8de2407675)",
    "comments": [
      "Literally get on Google collab 50% of the time you get a T4 50% of the time you get a V100. And it's free.",
      "I vote 12gb. Slower is better than not being able to do something at all.",
      "I don't know if you get it man, he is doing phd research with extensive computational requirements in his/her experiments. Colab is not good for that.\n\n Maybe for you and your small projects it worked, but not for him/her.",
      "Upload your dataset to Google drive ahead of time then mount it in colab to train.",
      "If you have to, personally i recommend 3060Ti over 3060 as sometimes bandwidth are the bottleneck instead of the VRAM size. But it can also depends on how much you can scale your model or stretch the batch size. \n\nAlso one bonus point for 3060Ti because it can run model designed with 1080Ti or 2080Ti in mind (11GB), just slower.",
      "I use a 3090 for my ML work and i still need more vram..",
      "Unfortunately not the case anymore, they'll kick you for any process longer than a few minutes.",
      "I guess price and availability are an issue as well. In my country (Aust), 3060 is \\~A$750, 3060 Ti is \\~$1-1.1k and 3070 is \\~$1.5k. 3060 is somewhat easier to find but 3060 Ti is next to impossible to buy unless you join the backlog. So it could be weeks to months before I can get my hands on one",
      "As it turns out, you're [right](https://medium.com/analytics-vidhya/m1-mac-mini-scores-higher-than-my-nvidia-rtx-2080ti-in-tensorflow-speed-test-9f3db2b02d74)\n\nI'm genuinely only using this for ML. Last time I've played PC games was maybe 2 years ago.",
      "Now you can suggest colab on every researcher in Deep Learning HAHAHAH hilarious person.",
      "Thanks for this tip, but my data set is 3gb and it disconnected just waiting for it to upload",
      "Yeah not really, it gives me K80 which sucks very-very hard in comparison to 3060",
      "Thanks for the offer!\n\nIf it's not too much hassle, can I trouble you to try the Lambda AI speed test? Instructions here:\n\nhttps://github.com/lambdal/deeplearning-benchmark/tree/master/pytorch\n\nAnd their reference numbers:\n\nhttps://lambdalabs.com/gpu-benchmarks\n\nThanks again!",
      "So do you mean you're voting for 3060 Ti?",
      "If you're using the ML as an excuse to buy a graphics card to use for gaming then just get either one.\n\nIf you're genuinely interested in ML then buy an M1 Macbook Air. Nvidia is currently hugely ripping people off. For the prices you have to pay for a basic card you can get an entire premium laptop (cpu ssd ram motherboard screen etc.) and it's a BEAST for Machine Learning.",
      "My GTX 1070 is %15 faster than google Colab with these 2 GPUs. The Cpu in google Colab is bad so that can be a bottleneck and Google Colab doesn't give u full access to the power of the GPUs, Colab probably put some limitations in power usage or something like that and u can't use it for more than 12 hours maximum and even less if u are training big models bc they take more resources to train.",
      "This is for small datasets. Go larger and the M1 shits itself, and I've got both the M1 and rtx 3060ti. If you're doing serious deep learning work then it's dedicated graphics for now.",
      "I ended up picking up a 3080 Ti at launch ¯\\\\\\_(ツ)\\_/¯",
      "While I acknowledge that this is a 2 year old comment that the OP likely doesn't even need advice on anymore, the 3060 at the time of this comment was literally a drop in replacement for the 2060 at this time, and is far more comparable in performance to a 2070. Even today a 12GB 3060 is excellent, and the extra VRAM will net you more capabilites for running larger LLMS like GPT and RWKV, and image generators like Stable Diffusion at far larger batch sizes/resolutions.",
      "but do you think colab will work on big datasets and run on research experiments? have you tried it? \n\nIt's literally in the FAQs."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "low",
    "matched_keywords": [
      "rtx 3060",
      "3060"
    ],
    "title": "GeForce RTX 3060 | The Ultimate Play",
    "selftext": "",
    "comments": [
      "Would you prefer 6GB? Because that's how this works.",
      "It's a 1080p card for AAA gaming, 1440p for old titles.",
      "it was either that or 6 gb. nothing in between was possible",
      "I mean, sure, if it brings the cost of the card down.",
      "It's almost as if the 3060ti and 3070 also use DDR6 and not DDR6x. The 12GB decision is still stupid.",
      "3060 advertised performance looks..\nWeird.\nhttps://i.imgur.com/ovlX986.png\n\nThat's 1080p, in traditional rendering it's around 10 percent faster than regular 2060, which makes it equal to 2060S but in CP2077 and Watch Dogs with RT enabled it's almost on par with 3060Ti which is wayyy faster than 2060S",
      "So, they're putting 12 GB's of VRAM on a card that will become pretty much obsolete long before hitting the 12 GB actual usage? What? Not to mention, the card is weaker than the 3060Ti. What?!!?!",
      "Yeah based on that info and the graphs this card will be 2070 level.  People were predicting 1080 Ti/2070S so this is actually a bit disappointing.",
      "They never mentioned what level of dlss was at use in those games. That’s actually an important indicator. There’s a significant difference between DLSS Quality and something like DLSS Performance. Not specifying that in your graphs can be misleading.",
      "What do you guys think about this card for 1440p  ?",
      "192bit memory bandwidth forces either 6GB or 12GB, and 6GB isn't enough even today sooo",
      "Yeah, I chuckled when I saw the DLSS [promotional video](https://www.youtube.com/watch?v=CWpHPGnUo9c&feature=youtu.be&ab_channel=NVIDIAGeForce) they showed on stream. Next to bottom-of-the-barrel DLSS setting when most people will want to go Balanced/Quality...but of course they'll advertise the fps boost with Performance.",
      "I have a legit question, but is it the card's fault that the games you mention barely reach 60 fps or games are just unoptimized?",
      "No, it allocated 7 gigs. Thats not utilization. Do you people not read anything ffs\n\nHere you go:  https://www.youtube.com/watch?v=5qwdlY95J0c\n\nEven at 1440p, all ultra, ray tracing quality it uses about 7.7 Gigs. It's memory allocation, not utilization. Stop spreading false info idiot.\n\nIf you think the RTX 3060 is a better buy even though it gives lower performance overall, but has more VRAM, then I really feel sorry for your parents lmao",
      "12GB of vRAM. Is this a joke? That's more than the 3060ti, 3070, and 3080. LOL!",
      "If you’re willing to tweak settings, then sure this will do 1440p/60 FPS, but this looks more like a 1080p card. Even the 3070 is questionable at 1440p when you consider games like cyberpunk and assassins creed Valhalla just reach 60 FPS.",
      "I’d like to blame the game devs or publishers for releasing unoptimized games, but it still sucks to see a new $500 card just reach 60 FPS at 1440p for the new titles. It makes wonder what the next 2-3 years are going to be like. \n\nThe people that say 3060/3060-ti is a great 1440p card are right for games from the past. But if we’re to look to the next 2-3 years, these cards would be better off at 1080p (or at least 1440p with compromised settings).",
      "Cost. And since it's already so closely priced with the 3060ti whilst being significantly weaker (supposedly, no benchmarks yet), it needed a marketing gimmick. 12gb sounds nice to most consumers.",
      "This may finally be the perfect card to replace my 970 for iray rendering if the price is stable and availability is decent. The 970 can barely render anything and 12GB is such a huge step up from 3.5/4.",
      "This is only like 10% maybe 15% faster than the 2060, like come on the ampere architecture is meant to be the biggest leap, its such a weird card considering amd is gonna release their 12gig versions in March. Nvidia haven't set the bar high on this one"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "low",
    "matched_keywords": [
      "rtx 3060",
      "3060",
      "rtx 3060 ti",
      "3060 ti"
    ],
    "title": "Will RTX 3060 ti work with 500w PSU",
    "selftext": "I have a 500w psu and I was just wandering if it could run the rtx 3060 ti before buying it as I don't want to be in a sticky situation. Is the 500w anough of should I buy a 550w or 600w. Any advice  id welcome.",
    "comments": [
      "im using 3070 and r5 3600 with 550W. Don’t worry 500W will just work fine if it’s good quality.",
      "If it’s of good quality and has almost all of the 500W available on the 12V Rail, it will work. I use a Seasonic X-560 with a Ryzen 5900X and have plenty of headroom. Currently, I use an old GTX 670 OC with similar wattage.\nI hope my 3060 Ti FE will arrive next week 🙃",
      "Nvidia recommends atleast 600",
      "I have corsair cx 500 and gonna buy a 3060 ti. I am having a 3600 too. So no problem right? Or i have to upgrade my psu?",
      "u don’t really need to upgrade psu.",
      "I'm coming to the same dilemma, i want to upgrade my GPU but don't want to have to buy a brand new power supply :(",
      "This, just look at the sticker\n\n&#x200B;\n\nA good psu will give you like 480watts on the 12v rail, a shit one might only give you half.",
      "Using this for almost 3 months on my sff build. 3060ti oc with R5 3600. No issues so far. My 3060 TI OC never gets past 200W. If I am not mistaken, the SGX gold 500w has 492W on the 12V rail. Still plenty of headroom. More or less a hundred watts",
      "it comes with an adapter in the box for your pci e power connectors",
      "I also want to ask,  can i run 3060 ti , Ryzen 5 3600 with Seasonic S12III 500W 80+ Bronze, 420w on 12v ?\n\nAlso, whats the worse scenario that can happen?",
      "same",
      "I have a be quiet! Pure Power 10 500W Power Supply 80+ bronze which is similar, I would like to know too.",
      "You got two 3060’s die on you, damn thats sad indeed. But somehow i don’t believe that its the psu’s fault?",
      "I have the same cpu and just bought gigabyte r x 3060 ti eagle I have psu 500w, 456 12v rail, I'm going to connect it now with ill uodat you if it's giving me troubles",
      "yes.",
      "mine gives 456w on its 12v rail, think i can run a 5600x with a 3060ti with my 500w psu ?",
      "Will a evga 500w be bronze work?",
      "Same",
      "It is \"Ventus 2X\" model. Not that two pieces died on me. That would be major red flag. I got the new piece next day. After installing newest drivers, all is good and works well. Installed Doom Eternal. Damn it is tough game, I might lower the difficulty to second lowest or even lowest to actually enjoy. Does not feel funny to repeat the level 40x.",
      "Yeah how was it?"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "low",
    "matched_keywords": [
      "3060",
      "3060ti"
    ],
    "title": "3060 vs 3060ti - which do I keep?",
    "selftext": "Hi, I just picked up a cheap pc off Facebook and it came with a 3060ti 8gb but my current system has a 3060 12gb. I plan to sell one of them but am not sure which.\n\nI do light video gaming and light video editing but honestly not much of either and if I sell them, either will roughly go for $200 give or take 20 bucks so money wise I consider them about the same.\n\nShould I keep the faster card or the more RAM card? \n\nThanks for any advice!\n",
    "comments": [
      "Keep the RTX 3060 Ti",
      "Faster card no question.",
      "Sell both get a better GPU?",
      "If you are into text to image, keep your 12GB Vram. If not, probably 3060i has better performance.",
      "12gb",
      "Keep the 12gb card and lean hard on DLSS. You can compensate for the lack of shader performance. you cant compensate for the lack of VRAM (generally)",
      "Keep the 3060 Ti. You can always reduce Texture details a bit, but can't make up for more fps.",
      "That's definitely an idea for me to keep in mind but I mostly bought the FB PC to upgrade what I can, sell the rest and try and break even or better and I need to sell 1 keep 1 for the math to work out.\n\nThanks for the idea though! Didn't even consider it"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "low",
    "matched_keywords": [
      "3060",
      "3060ti"
    ],
    "title": "Can anyone help me decide between 3060 12gb & 4060 8gb as a non techy person?",
    "selftext": "Basically I just want an upgrade from the 1660 super to an rtx card on a tight budget but can't decide which is which. I'm planning to get a 1440p monitor for it in the future as well. I'm gonna use it for vr gaming too. It might be possible for me to stretch it to 3060ti but the vram drops down to 8gb.\n\n3060 costs like $300, 4060 is $360, 3060ti is $450 (from where I am)\n\nI've watched the comparison videos and it seems the 4060 is performing better than the 3060 but then again 3060 has 12gb of vram and I heard you need a lot of vram for vr gaming. Another conflicting thing is that the community seems to hate the 4060 just for its price? or something about buses idk. I did however try finding some rx 6 smthn XT but its whopping expensive. I am eyeing on the 4070 too for the year 2024-2025 if the prices goes down bc I heard this one is one of the best but I'm not really shooting for the stars here.",
    "comments": [
      "3060 will never utilize 12gb of vram gaming unless ur doing vr or Ai",
      "Board is PCIE 3.0 so the 4060 will take another hit in performance and bandwidth since it's a 4.0 8x card and the 3060 is 16x. With that and your CPU limiting  the difference will be negligible at best so get the 3060 if it's cheaper.",
      "4060 is actually better so I'd go that route especially if you upgrade later on.",
      "What is your CPU and motherboard like?",
      "As a owner of a 3060 you're better off waiting for the next series and hope nvidia isn't so greedy on vram.",
      "Just go for a 3060 now. In the future, buy a full new system instead of a VR headset.",
      "Have you considered buying used? You could find a used 3070 or 3080 with luck in that price range and both of those would perform better",
      "4060 is the better upgrade more features plus u can use av1 for vr which older card don’t have",
      "I found some but either they get sold pretty fast or looks like I might need a new PSU for it since it requires a 16 pin power connector and I only have 8 :(\n\nbut thats okay. I'm going for the 3060 and just have it for awhile until I upgrade to 4070 with new mobo,cpu,psu as months pass.",
      "Other effects of low VRAM include stuttering and low res texture not updating and stuff like that when the memory is full, so headroom is very nice. I wouldn't get 8 GB today unless you're 1080p exclusively for 2-3 years.",
      "It could handle a 4060 fine. Choose what ever card is the best value for the money you can spend.",
      "That's very true, for 1080p it'll last till 2025 when 50 series is out, if getting the 3060 12gb now",
      "Would go for RTX 3060 since it uses full PCIe bandwidth unlike RTX 4060 which using only 8x bandwidth.   \n\n\nIf you're installing RTX 4060 into older mobos with PCIe 3.0 only, you will get PCIe 3.0 8x only.",
      "IMO if youre aiming for 1440p vr gaming then you can wait a little bit 'cause Nvidia has announced that they will run 40xx Super in early 2024. Then 4070 4060Ti (16GB) price maybe drop. 4060 and 3060 are both still good but for the 1440p mordern gaming isn't enough.",
      "If you are on a tight budget, go for the 3060 preowned if possible, in Europe they have a market value of 250€. \n\nIf you prefer a brand new card with warranty, and the games you play support Frame Generation, then go for the 4060.",
      "an i5-10400 and a gigabyte b460m.\n\nIt's gonna bottleneck but I'm willing to take it. Just slowly upgrade one part a time.",
      "Doesn't matter too much right now, but when TLOU came out I was using 10gbs of vram on my rtx 3060. 2K res.",
      "It's not.",
      "That sounds good too, enjoy your new card",
      "Here you can see the difference: [https://www.youtube.com/watch?v=ptcHFG3QR88](https://www.youtube.com/watch?v=ptcHFG3QR88)"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "low",
    "matched_keywords": [
      "rtx 3060",
      "3060",
      "3060ti"
    ],
    "title": "Am I missing something? The RTX 3060 is amazing",
    "selftext": "Hey all! I am not sure if this is the right place for this sort of thing or not, but it seemed appropriate.\n\nI did a lot of research on graphics cards, needing a new one a while back. I'm not a heavy gamer, but do play a large variety of games at least a couple times a week, and greatly appreciate smooth gameplay and high resolution goodness. I also work with Adobe programs, so wanted something that would work reasonably for all of that.\n\nI signed up on the EVGA queue, adding the 3060 and the 3060ti, thinking either one would be fine for what I needed, and reasonably priced. During the time I waited to be selected, I noticed a lot of people saying how inferior these cards are (especially the 3060), and that you need at least a 3070 or better to get reasonable results, particularly in 4k. I knew I probably wouldn't ever spend the extra money for a higher end card, but worried I'd be disappointed with one of the 3060 varieties.\n\nCut to now. I wound up being selected for a 3060, quite a few months ago, and bought it. I have it connected to my Hisense U8G through HDMI 2.1. To my delighted surprise, I have yet to play any game that I couldn't set to maximum, HDR depending on game (some autoHDR), in 4k resolution at 120fps (if applicable). Gameplay is perfect and smooth, looks incredible and I've yet to have any problem.\n\nSo, I am genuinely wanting to know, what am I missing? How am I able to play everything at max settings in beautiful 4k if this card is supposed to only be good at 1080p gameplay at best? Everywhere I look that is what people say and I am baffled. I keep expecting something to show me the limitations of the card but it just isn't happening. Don't get me wrong, I'm not complaining and am SUPER happy with the card, I just want to understand why so many people put down this card when it seemingly performs incredibly well on every game I've thrown at it in 4k.",
    "comments": [
      "You are either playing very old/undemanding games or you're compromising elsewhere in image quality to get that kind of performance.",
      "There's no way you can play Control at 4k120 with a 3060. Even a 3090 sometimes struggles (Digital Foundry corridor of doom) to even get 4k60 with quality DLSS.",
      "There's no shot you're playing actual demanding games maxed out ultra settings at 4k above 60fps.\n\nSource: I have 2080 ti and 3440x1440 screen which is lesser than 4k - I can max out some of these AAA ultra demanding games but definitely nowhere near 120fps and sometimes even 60fps is pushing it. Mind you, my 2080 ti is faster than your 3060.\n\nYou purposefully didn't list all the games you're playing. If you at least gave us a list we could figure it out but as it is, it's anybody's guess what you're doing. Maybe you're actually playing at 1080p and don't use 3840x2160 resolution.\n\nThere's also a separate and important factor, you did mention Control in the comment section and Control has DLSS which helps immensely all the RTX cards including your 3060. That's what DLSS is for, sacrificing internal render resolution for performance uplift, so if you're using that to get 60+ fps in 4K then cool.",
      ">So, I am genuinely wanting to know, what am I missing?\n\nActually selecting 4K would be my guess. \n\n[https://www.techpowerup.com/review/evga-geforce-rtx-3060-xc/29.html](https://www.techpowerup.com/review/evga-geforce-rtx-3060-xc/29.html)\n\n23 games tested, zero got to 120fps or triple digits even. About a 1/3 or just under that managed 60fps.",
      "> I don't keep track of the exact FPS happening throughout the game\n\nHow do you know you're getting 120 fps then?",
      "You literally said that you were playing games at 4k 120fps.\n\nIf you're not actually measuring it, how do you know?",
      "It's substantially worse than the 3060 Ti for not much cheaper in most places. That's why people deride it – the fps/$ ratio is much worse. It's still a latest gen x60 card which means it's performant enough to run any game.",
      "I’ll be honest brother coming from a regular RTX 3060 XC EVGA \n\nTo a RTX 3060 TI OC Zotac, 1440P runs no problem. \n\nDon’t get me wrong the RTX 3060 did a great job, but the newest games it did dip easily down 65-68 FPS at 1440P. Even with overclocking it. But I wish I would’ve have invested when I had the chance, but I took what I could get at the moment that was the cheaper solution.",
      "The resolution applies for current \"AAA\" games\n\nAll cards are great the right factors to account for is the use case and price tag :)",
      "Hey, thanks for the response! I actually just got an email today for the queue again, for the 3060ti and have been debating whether to get it since I've been pretty happy with the 3060. That's what spurred this conversation I think, although I've been thinking about this for awhile anyway.",
      "4k and up to 120fps, doesn’t mean you’re playing at 120. Also, because your tv is 4k doesn’t mean the input from your pc is 4k, it could be 1440p or even 1080p. Your Tv might have some AI upscale/enhancements to make a lower resolution look higher (output) whilst still having a lower input resolution. Some TVs also add in black frames or blur to smooth out images and give the perception of a higher frame rate.",
      "Lmao you are clueless.",
      "OP just straight up lying about 3060 performance acting like the rest of us can't go look up benchmarks and performance reviews.",
      "I call bullshit",
      "I think OP got a 3060, which is worse price to perf - 3060ti is sweetspot",
      "If the 3060 does what you need... game on! I have a 3060 Ti in both of my PC's with 4K/60 Monitor/Screen. I do not play AAA FPS games so my needs are different than those that do. I can play Forza Horizon 5, MS Flight Sim 2020, and all my Indie games at 4K.",
      "I highly doubt that we're taking about the same scenes, or the same settings in that case.",
      "The 3060 is about the same performance as a Series X, so it's not a bad card, but there's no way it's giving you 4K120, not even a 3090 can do that.",
      "1440@90-110fps here on my 3060ti with Quality DLSS.",
      "Yeah, sure, the 3060 can play a lot of games at 4K with high refresh rates. That is, if you're almost exclusively playing indie titles that don't even require high-specs to begin with.\n\nThe 3060 is a great 1080p/144hz card, but it's going to begin to struggle at 1440p. If you want to play 4K, and not lower settings to hell and back like you're most-definitely doing, you need a 3080 at the minimum."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "low",
    "matched_keywords": [
      "rtx 3060",
      "3060",
      "rtx 3060 ti",
      "3060ti",
      "3060 ti"
    ],
    "title": "MSI Ventus RTX 3060 Ti 3x LHR",
    "selftext": "I'll get to the point, so I upgraded from my MSI Ventus RTX 2060 to a used 3060 Ti for my R5 7600/B650 Tomahawk/32GB DDR5 6000CL30/Superflower 650W Gold-rated white ARGB.\n\nI DDU > Clean and shutdown > remove the 2060 before Installing the 3060Ti using safe mode with Ethernet cable unplugged.\n\nDownload and Installed Nvidia drivers version 566.03 from official website and adjust the settings on control panel to whatever the majority consider optimal or best for better performance and visuals. No NVCleanstall app used for this driver.\n\nCurrently, using Windows 11 Pro 23H2 on a SN850X as my boot drive.\n\nThe question I wanted to ask is:\n\n1. What is vBIOS? and how to do I update it for my specific GPU model? Why do I need to update my vBIOS? Does it improve performance?\n\n2. 24H2 still hasn't rolled out on my PC even though I check for updates almost every day as I heard and watched HUB long ago that it is the best windows build for AMD Ryzen 5000/7000/9000 CPU owners.\n\n3. Is there anything else I can do to squeeze more out of my GPU? I don't seem to be getting the performance I deserve. \n\nWhat I tried on my side:\n\nI updated BIOS, NVMe firmware, Display firmware, GPU drivers, Chipset drivers, OS updates all to latest patch. Enabled ReBAR, AMD EXPO profile 1, Game boost in BIOS, HAGS and Game mode on W11, plug 2nd monitor (60hz TN LCD) to my iGPU and 1st monitor DP to GPU DP output port. Disabled Core isolation, 4G decoding in BIOS, WiFi/BT, UnP, UEFI over CSM. PCI-e is set to 4.0 x16, no OC or Undervolting applied using MSI Afterburner it is running at  stock speed (no values modified). I did unscrew the shroud and backplate remove all the grey dust particles and repaste this GPU with Arctic MX-4 as it has been 3+ years since this GPU was made back in 2021 May (according to GPU-Z).\n\nSorry for the huge amounts of information that may be unnecessary and waste of time, but this is my 2nd GPU and I really want to utilize this to its maximum on my LG 27\" 1080p 144hz that I soon plan to sell and get a 1440p 165hz. Is there anything else I can do with my card to improve my overall framerates?  ",
    "comments": []
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "low",
    "matched_keywords": [
      "rtx 3060",
      "3060",
      "rtx 3060 ti",
      "3060ti",
      "3060 ti"
    ],
    "title": "3060ti uv",
    "selftext": "I will be picking up my Nvidia GeForce RTX 3060 Ti 8GB on Wednesday. I plan to undervolt it and I was wondering what are the typical settings most people are using to undervolt this card? \n\nAlso, I have a 520 watt Seasonic Bronze PSU. According to PC part picker my cpu, mb, and the 3060ti will draw 385 volts. I have 4 small fans and all my other components are very middle of the road, ssd, hdd, ram, etc. just the basic stuff, no extras. Nothing top of the line.  I know Nvidia recommends a 550 watt psu but I'm hoping I won't have to replace the one I have. Any suggestions are appreciated.",
    "comments": [
      "My girlfriend has been using 1935 MHz at 900 mV on her 3060 Ti FE for a year and a half now. It's perfectly stable, keeps the temps under 70°C, the fans under 1200 RPM and the power consumption around 150W max (-50W).",
      "They exaggerate the PSU recommendations because of people who use trash-tier PSUs that can't deliver their advertised power or can't deal with micro power spikes, so you should be fine",
      "i run mine 900 mV 1950mhz and it still boosts to 1965mhz for some reason but it never crashes and temps and fan speed is a lot lower.",
      "You guys are great, this will help a lot! Thanks!",
      "Here are my 3060 Ti undervolt results (compared against Stock and OC):\n\nCyberpunk 4K Custom RT+DLSS (avg/final rpm)\r  \n\r\n\n* ST: 58.63fps - GPU: 66.2c HS: 82.0c - 1700/1880rpm - 1840Mhz - 198W 935mV - 3,37W/fps\r  \n\r\n* OC: 62.76fps - GPU: 67.2c HS: 83.2c - 1780/1980rpm - 1998Mhz - 208W 930mV - 3,31W/fps\r  \n\r\n* UV: 60.48fps - GPU: 63.1c HS: 78.5c - 1430/1580rpm - 1935Mhz - 169W 850mV - 2,79W/fps\r  \n\r  \nPUBG 4K Custom\r  \n\r\n* ST: 88.9fps - GPU: 67.1c HS: 82.8c - 2000rpm - 1725Mhz - 199W 865mV - 2,24W/fps\r  \n\r\n* OC: 96.8fps - GPU: 68.4c HS: 84.1c - 2090rpm - 1890Mhz - 208W 867mV - 2,15W/fps\r  \n\r\n* UV: 97.3fps - GPU: 66.9c HS: 82.6c - 2040rpm - 1935Mhz - 201W 850mV - 2,07W/fps\r  \n\r  \nForza Horizon 5 4K Ultra\n* ST: 66fps - GPU: 67.0c HS: 82.1c - 1960rpm - 1905Mhz - 198W 987mV - 3,00W/fps\r  \n\r\n* OC: 70fps - GPU: 68.0c HS: 83.3c - 2080rpm - 2065Mhz - 207W 983mV - 2,96W/fps\r  \n\r\n* UV: 65fps - GPU: 58.6c HS: 73.3c - 1500rpm - 1935Mhz - 143W 850mV - 2,20W/fps\r  \n\r  \nFlight Simulator 4K-High Tokyo DF\r  \n\r\n* ST: 40.3fps - GPU: 67.3c HS: 83.5c - 2000rpm - 1765Mhz - 200W 886mV - 4,96W/fps\r  \n\r\n* OC: 43.1fps - GPU: 68.6c HS: 84.9c - 2100rpm - 1915Mhz - 209W 876mV - 4,85W/fps\r  \n\r\n* UV: 43.1fps - GPU: 65.8c HS: 81.8c - 2000rpm - 1935Mhz - 193W 850mV - 4,48W/fps\r  \n\r  \n3DMark Port Royal\r  \n\r\n* ST: 6798 - GPU: 66.3c HS: 82.1c - 2000rpm - 1837Mhz - 199W 934mV - 34,2pts/W\r  \n\r\n* OC: 7312 - GPU: 68.2c HS: 84.1c - 2075rpm - 1987Mhz - 209W 923mV - 35,0pts/W\r  \n\r\n* UV: 7110 - GPU: 63.5c HS: 79.1c - 1710rpm - 1935Mhz - 173W 850mV - 41,1pts/W\n\nFor more info: https://www.reddit.com/r/nvidia/comments/v71fw1/stock\\_vs\\_oc\\_vs\\_undervolt\\_part\\_ii\\_3060\\_ti/",
      "Thank you emperor, festina lente!",
      "Not really looking to do that but thanks.",
      "Best I could do on mine was 1920@.975v it was not worth it for me, so I was better off OCing. \n\n\nIf your card is not great at undervolting, consider just lowering the power limit. It's basically the same but will use a bit more voltage, and can also be more stable.\n\n\nYou can also lower the power limit while overclocking, which will give you the similar results as a manual OC + UV",
      "Based on the number of replies you've typed it seems you do care. Also, based on the number of articles I've read, the videos I've watched and  other replies I've gotten I'm not the only person who is in your words, \"ignorant\". \n\nYou are correct that I asked on a forum, but just to be clear I never asked IF I should do it, I only asked for recommended settings so you're answering a question that was never asked at all. To me answers on a forum should pertain to the question that was asked instead of opinions on irrelevant things like the conversation we are having right now.",
      "They recommend a 550? You are fine.. 30 wouldn’t make a difference unless it’s old psu. If it’s old I would recommend you get a new one. \nUsually you want double supply than demand so I would suggest going 750 or 800 psu if you upgrade",
      "Just a heads up, nvidia recommends 600w psu, and some aib models require 650w minimum, I had to learn that the hard way myself when trying to figure out why my 600w psu kept shutting off even tho my 3060 ti was drawing 150w less than the psu threshold, turns out that the transient spikes in 3000 series gpu's are no joke.. and while you may get away with a 520w psu considering it's seasonic (tho I don't think so), don't count on it",
      "Great question! I’ll like to know suitable UV settings for a Asus Tuf gaming rtx 3060 OC as well? I’ve been doing a lot of research but there aren’t many information out there. Thanks in advance for your inputs",
      "Certainly seems that way.\n\nHave had a 3060 Ti running happily on an old but decent Cooler Master 500 Watt PSU for a few months on stock settings. Not had any problems.",
      "Thanks for your input. I bought the psu when I had an rtx 2060. I had to give that to my daughter a little over a year ago when her older gpu died. I've been waiting since then for the prices to come down. The psu is no more than 2 years old. When I built the computer I was trying to keep costs in check which is how I ended up with the 520. I will stay with the 520 for now but I will definitely take your advice if I upgrade. Thanks again.",
      "Good luck!",
      "Yea you may not have to, but just keep in mind that there is no guarantee it will work, you should try running the system under full load for extended period of time to see it the psu will hold up or turn itself off, who knows maybe it will",
      "welcome, here are my 3dmark results, hopefully you win the silicon lottery! [https://www.3dmark.com/spy/23562339](https://www.3dmark.com/spy/23562339)",
      "The stuff I've read agrees with you. Thanks for the input!",
      "I'm not really worried about anything. From what I've read undervolting can actually make your gpu run better with less power consumption and less fan usage which means longer life for the gpu. Even if it takes a performance hit it will be negligible and probably unnoticeable so there really is no reason not to do it in my opinion.\n\nYou seem overly worried about what I intend to do which seems strange to me. Regardless, thanks for your input I appreciate you taking the time to chime in.",
      "I'm going to copy paste the second half of thast last paragraph lol. I've needed to say that so many times. Good luck with the 3060 ti :D"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "low",
    "matched_keywords": [
      "rtx 3060",
      "3060",
      "rtx 3060 ti",
      "3060 ti"
    ],
    "title": "RTX 4060 TI or RTX 3070 TI",
    "selftext": "I have an RTX 3060 TI and I'm thinking of upgrading since I got a new 27” 1440p monitor. I'm considering upgrading to either an RTX 3070 TI ($350-400) or an RTX 4060 TI ($350-450). These are the prices I could find in my country. Some of the cheaper ones are second-hand, although there aren't many second-hand 4060 TIs available.\n\nI've been eyeing the 40 series lately because of their DLSS 3 technology. However, I've been using Lossless Scaling for about two weeks now, and sometimes it’s enough for me. Because of this, I was considering just getting a 3070. But, the artifacts can get annoying, and they're still far from the real thing.\n\nMost people on the internet say that the 3070 is better, but people in my country claim the 4060 is better. Well, my countrymen aren’t that savvy with this kind of stuff anyway; they always think newer stuff equals better quality.\n\nPlease give me some insights on this, or should I just keep my 3060 TI and wait until 4070’s prices drop, and then get that one?",
    "comments": [
      "Neither of those are good upgrades for a 3060 ti. Wait until you can afford at least a 4070 super",
      "or play until 50xx series release, the 3060Ti is still a viable option",
      "Do not buy 8GB card. Even at 1080p, new games are hitting vram limit. Going to 1440p will get things even worse. At that is the situation right now. New releases will require more vram. \n\n  \nIf you need gpu right now, buy AMD/ Nvidia with minimum 12GB. Or wait to Q1 2025 when newer GPUs will be available from both AMD/ Nvidia.",
      "3070ti over the 4060ti for sure.  You will get better performance out of the 3070ti.",
      "At least? 4070s just now is the best choice.",
      "You'll double hit it with nvidia as I find turning on features tkes you over most often.",
      "Yes, I just meant upgrading anything below the 4070s level is not really worth it.",
      "4070 super tier performance, basically"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "mid",
    "matched_keywords": [
      "3070"
    ],
    "title": "RTX 3090 vs. 3080 vs. 3070",
    "selftext": "",
    "comments": [
      "Ive always been told width is more important than length, but you need a little bit of both for maximum efficiency.",
      "Everyone is rightfully talking the length of the 3090, but it's fucking wide too. Length just barely fits in the Meshify Fractal C, but idk about that width...",
      "**G**iant **P**enis **U**nit",
      "We still talking about GPUs?",
      "Damn the 3070 is dwarfed by the 3090 and even the 3080.",
      "I have a felling 3090 cooler will cool as good as any high end AiB cooler and look 10x better on the way.\n\nLook at that size compared to 3080 and it has to cool only extra 30w compared to 3080, looks like a beastly cooler!",
      "Yes, definitely",
      "If there was ever a card that deserved the name \"Titan\" it's 3090.",
      "I have a feeling that if 3090 doesn't come with a bracket its going to break alot of motherboards.",
      "BFGPU",
      "I have no use whatsoever for the 3090 on a 60hz TV but I desperately want one of the bad boys.",
      "Why is there a piece of plastic on the 'blow through' part of the 3090? Shipping protection?",
      "It actually is small. Small is relative. For example, in comparision to the Reichstag, the RTX 3090 is small.",
      "Having three actual PCIe brackets will be better for support, versus a lot of AIB cards that only use 2 brackets but are 2.7-2.9 slots anyway.\n\nThe full length metal frame should also help with drooping at the end of the cards.",
      "Big floppy",
      "RTX 3090 乇乂ㄒ尺卂 ㄒ卄丨匚匚 edition",
      "Certainly looks removable",
      "Where's that OP at that tried to claim the 3090 is actually a small card? LOL.\n\nEdit: [https://www.reddit.com/r/nvidia/comments/inp88v/3000\\_series\\_are\\_not\\_big\\_3070fe\\_is\\_just\\_really/?utm\\_source=share&utm\\_medium=web2x&context=3](https://www.reddit.com/r/nvidia/comments/inp88v/3000_series_are_not_big_3070fe_is_just_really/?utm_source=share&utm_medium=web2x&context=3)",
      "Well at 4K 60hz it still makes sense for running demanding games at the highest settings. I game on a 65 inch OLED and I’m picking up a 3090.",
      "That's why I find a lot of the 2.x \"slot\" cards stupid. Just use 3 PCIe brackets FFS."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "mid",
    "matched_keywords": [
      "rtx 3070",
      "3070"
    ],
    "title": "pcmr member send rtx 3070 and rgb keyboards to our internet Cafe in yemen",
    "selftext": "",
    "comments": [
      "Hey man, glad to see the gaming Cafe is still going strong. Hope everything is well.",
      "That's awesome! It's always nice seeing wholesome gestures like that with everything else going wrong in the world today. I hope your patrons are enjoying getting to use the GPU and the new keyboards.",
      "Kid is gaming on a keyboard that is more expensive than 99% of us have lmao",
      "thanks",
      "That's amazing! Happy to see this",
      "And, as an owner, I can tell you it's not worth it. The battery is shit (2w top with RGB but with battery saving enabled), the range with the lightspeed mode is atrocious, the keycaps rattle, the rubber keys are even flimsier, and worst of all - the app that controls it fucking sucks balls, if it even starts up. Did I mention this 250usd MSRP keyboard doesn't even include a wrist rest in the box, or dual Bluetooth device functionality? And that you'll be hitting the G-keys on the left side accidentally a LOT of times. Yep... \n\nOh and you better be ready to charge it up with that microUSB no device around the house likely uses anymore.",
      "As a owner of the G915 TKL, I find the keyboard totally worth it. No RGB. Last recharged 2 months ago, battery still at 70%. I game every single day. No issues with rattling unless you vigorously shake the keyboard (don't know why one would do that). Lightspeed connection has been flawless since Day 1.\n\nFor me, this keyboard has served me very well and I hope it continues that way (Purchased it 2 years ago)",
      "Are you aware what is happening in Yemen right now? \n\nHe is offering a safe space for people to escape a literal conflict. The currency has tanked, there are major blackouts.. life sounds pretty awful over there currently.. if he is making a bit of money himself off it or not (which I doubt based on how things are and how he’s spoken about the business, and if he’s making a little, so what, he still needs to make money) he is still doing a great service to his community. \n\nAs somebody who plays games and lives a privileged life imagine what losing your ability to practise your hobby would make you feel , probably a little sucky. Then add a civil war, famine and zero sense of stability to that!",
      "Yemen is one of the most war torn places on the planet. School my ass, these kids are lucky their town isn’t under some sort of attack right now.",
      "Damn playing in a gaming cafe was some of my best memories. Like 15 years ago. They all closed now.",
      "Mining is fucking dead lmao",
      "Yeah, just the USB being micro is enough to never buy or recommend this product in my eyes.",
      "I don't care honestly. The dude is doing a service to these kids in a war-torn country by allowing them to learn computer skills and to play games they normally wouldn't have the chance to. So what if he reposts some pictures in search of donations?",
      "Hey its me ur brother with the internet café",
      "I also have the TKL and agree with everything here. I run the rgb at the lowest setting and still only have to charge once a month. Absolutely love it",
      "Awesome! Game on",
      "Hmm, I have a 2080 just chillin in my shed I wouldn’t mind sending over.",
      "a friend set up a gofundme https://www.gofundme.com/f/help-us-keep-an-internet-cafe-in-yemen-running",
      ">keyboard elitists\n\nHad the displeasure to be in contact with them elitists before. Something seriously wrong with those particular people... It's a keyboard that was gifted, yet they can't seem to take a hint - they HAVE to tear it all apart, jfc...",
      "As an owner too, i'll give my piece aswell.\n\nBattery lasts 3 weeks with rgb at 50%, dims to 25% after 1min, off after a few. I find 3w of battery for 2-3hrs of charge to be absolutely fine.\n\nI never had any issue with Ghub, not once. I have heard other people complaining though.\n\nI dont randomly hit G keys? That was a bit odd.\n\nAnd keyboard is so low profile that i personally dont find it uncomfortable not having a wrist rest\n\n\nI do agree tho that keycaps stability is really bad and that the media buttons feel super cheap.\n\nI cant speak for range as i only bring it to my lap while being on my chair and never had any issues, as its only like 60cm away from the dongle.\n\nLastely i do agree that microUSB is dumb and annoying. My fix to this is to use one singular, magnetic cable, and have the various bits stay in the devices i use (micro usb bits for my keyboard, mouse (g pro) and headset (hyperx cloud flight S), usb c in my phone)\n\nThat way i never have to actually plug things in while fearing of breaking them. Screw micro usb. But magnetic cable with all the bits was like 15€.\n\n\nAll in all i'm really happy with the keyboard, i like the very low key travel time & actuation time, and the long lasting battery, for a keyboard with RGB.\n\nIts probably also helping that i paid 147€ for it."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "mid",
    "matched_keywords": [
      "rtx 3070",
      "3070"
    ],
    "title": "16GB vs. 8GB VRAM: Radeon RX 6800 vs. GeForce RTX 3070, 2023 Revisit",
    "selftext": "",
    "comments": [
      "I really like what HUB has been doing. Nvidia needs to get the message that people aren't happy with its low VRAM strategy. Both players and game devs.\n\nTo anyone who's complaining... keep in mind that nothing bad can come out of this. At worst Nvidia will ignore all the fuss and continue releasing 8gb cards in 2023 and beyond or they will wake up and start putting reasonable amount of VRAM in their cards just like AMD and even Intel have been doing.\n\nVRAM is [cheap](https://twitter.com/Buildzoid1/status/1642672652111282176), there is no reason for Nvidia to continue doing this.",
      "I've had a 3070 for over 2 years now and while I personally never had any issues with it so far there is no denying Nvidia cheaped out on VRAM. It's shocking to see a $500 card capable of performing well but is bottlenecked by VRAM, planned obsolescence as clear as day, they want people to upgrade but I certainly won't.",
      "Plagues Tale Requiem, 1440P ray tracing on 3070: 2FPS lows\n\n2. TWO. FPS.  \n\n\nSo much for ray tracing performance.",
      "Yep. The fact that it's cheap just supports the theory that it's planned obsolescence. There's no way Nvidia is just clueless.",
      "Conclusion by steve: 8gb GPUs should now be sub 200$ products.\n\n12 gb should be the new entry point\n\n16 gb should be low end-mid range\n\n24 gb beyond that, meaning high end",
      "Mfw a 1080ti gives consistent frametime compared to RTX 3070 💀",
      "I got downvoted to shit for this exact opinion a few weeks ago. Granted I wasn’t very polite in my answers but my points were valid then, and are valid now.\n\nThe 2080 Ti is a demonstration of the real power of the 3070’s silicon, its such a shame to see it held back because of 8 gigs. \n\nI’m still gonna hold on to the card because I’m a cheap bastard, but I’m going AMD or Intel in 2024 when hopefully all of them have a new line of cards that don’t suck for price to performance.",
      "It’s making me switch to amd. I’ll give up ray tracing.",
      "In my opinion 12GB of VRAM for the +1000€ RTX 4070 Ti is ridiculous. It's now barely enough for some titles at 1440p and in couple years it might have similar issues that 8GB cards are facing now. Plenty of power to run games even with RT enabled but not enough VRAM. It's probably planned obsolence from NVidia to force people to buy 5000 series GPU at some point. I'm struggling with my 3070 Ti at 1440p and don't wan't to face the same issue again.\n\nMy choice would be the RX 7900 XT which is slightly cheaper in my country and has 20GB of VRAM. Too bad it's slower with Ray Tracing and FSR doesn't look as good as DLSS. I believe it will still last much longer and you will never have to worry about VRAM usage. And it has plenty of rasterization power.",
      "Nvidia has been doing this low vram crap on their cards for close to 20 years now. I remember them doing it for 7800 GTX all the way back in 2005. It really should have 512MB to begin with. It didn't bite them as much with 6 month product cycles but it's finally caught up to them.",
      "3070 owner, can confirm.  It's aged faster than any card I've ever owned.  Mediocre performance already in a few games I purchased (and I'm not talking just games released in the last 3 months).  I certainly can't go to some of the highest texture settings, and modding has been meh.  Q.Q   This thing was so expensive and I'd just been happy to see stock and wanted EVGA before they were gone.  Ugh.\n\nHad it for only a year too.  \n\nI literally feel like I have clown makeup on.",
      "3080 10GB owner here, totally ok that a similarly priced card from 2 generations prior has more VRAM. I'm not sweating at all. Really. Not. At. All.",
      "i recently switched to 6800xt because it was cheaper than a 3070 (non ti) where im from. no regrets. once nvidia stops the greed and drops their prices again and start thinking about the consumer, ill consider switching back",
      "> there is no reason for Nvidia to continue doing this.\n\nI disagree. They want you to buy the new generation every two years. So they are purposefully nerfing the GPU with low VRAM.",
      "My RTX 3060 Ti is crashing on RE4 Remake and Callisto Protocol because its running out of VRAM, not crashing on Last of Us although it slows down like a bitch because its running out of VRAM.",
      "![gif](giphy|UiBmJv6Hh6FfW|downsized)",
      "Considering sub $200 gaming GPUs from nvidia are no longer a thing pretty much yes, if a 6500 XT can ship with 8GB VRAM I see no reason for a more expensive product not to have at least 12GB.",
      "1080ti gang",
      "> 12 gb should be the new entry point\n\nSo 600$ and 800$ products from Nvidia are now entry points... \n\nJust great.",
      "„*AMD Unboxed bla bla bla*“"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "mid",
    "matched_keywords": [
      "rtx 3070",
      "3070"
    ],
    "title": "ASUS developing GeForce RTX 3070 with Noctua cooling solution (VideoCardz)",
    "selftext": "",
    "comments": [
      "YES YES YES YES",
      "finally, an all beige and brown pc... Just like the simulations",
      "If they keep at it, this will make me want an asus card for my next gpu.",
      "oh god its happening",
      "So ugly and so quiet and cool.",
      "so, just a bit better and not really '' a whole new level''",
      "This looks like something from Star Wars!",
      "[you rang?](https://imgur.com/a/fnasy0K)",
      "This comment hit me hard. I will spend a whole day undervolting a CPU, overclocking RAM, overclocking and undervolting GPU, etc. and my wife will not notice a single shred of difference. Actually, she doesn’t even notice the difference between 1080p and 4k Netflix on an 82” screen. Wait a minute. My wife is blind",
      "they already have two AIOs with noctua fans:\n\n[https://store.asus.com/us/item/202004AM080000002/desktopaccessories-ASUS-ROG-Ryujin-240-RGB-AIO-Liquid-CPU-Cooler-240mm-Radiator-%28Dual-120mm-4-pin-Noctua-iPPC-PWM-Fans%29-with-LIVEDASH-OLED-Panel-and-FanXpert-Controls](https://store.asus.com/us/item/202004AM080000002/desktopaccessories-ASUS-ROG-Ryujin-240-RGB-AIO-Liquid-CPU-Cooler-240mm-Radiator-%28Dual-120mm-4-pin-Noctua-iPPC-PWM-Fans%29-with-LIVEDASH-OLED-Panel-and-FanXpert-Controls)\n\nGuru3D did a thoroughly review, as usual, and recommended it:\n\n[https://www.guru3d.com/articles\\_pages/asus\\_rog\\_ryujin\\_and\\_ryuo\\_aio\\_kits\\_review,1.html](https://www.guru3d.com/articles-pages/asus-rog-ryujin-and-ryuo-aio-kits-review,5.html)\n\nmaybe the GPU follows that standard.",
      "Good news for silence but bad for aesthetics",
      "I love the brown Noctua fans.",
      "I overspent a bit to switch from an MSI 3080 to an Asus ROG Strix 3080. Never regretted it for one day, it's a whole new level.",
      "EVERYBODY STAY CALM",
      "What makes it a whole new level? And lemme buy that other one lol.",
      "It's just a 3d render from the web though, not the actual card.",
      "Noctua takes the 1950s mantra about children and extends it to your PC:\n\nSeen but not heard",
      "This...oh and not use the shittiest thermal pads ever which destroys the performance!",
      "WHATS THE PROCEDURE?!",
      "Ha sorry, already sold it a long time ago.\nAnyway it runs cooler, it has ~5% better performances and the fans are wayyyyy less noisy. It's just a better package, something I trust way more to be durable in time."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "mid",
    "matched_keywords": [
      "rtx 3070",
      "3070"
    ],
    "title": "Mission Complete: Zotac RTX 3070 Twin OC White Edition",
    "selftext": "",
    "comments": [
      "Lian Li Strimer Plus",
      "Which cables are those?",
      "I request elaboration",
      "RGB, fully customizable (pattern, color, speed, brightness).",
      "You are familiar with the thought experiment the Ship of Theseus in the field of identity metaphysics?",
      "Beautiful setup man!\n\nIs that the ASRock Phantom Gaming itx/ac motherboard you are using?",
      "A thing of beauty. Nice cables. What kind of PSU?",
      "Lian Li Strimmer Plus. I use them in my build. Just a heads up get the Strimmer Plus, they are more expensive but look WAY better than the normal strimmer. Its $60 for the 24 pin and $40 for the 2x8",
      "Are they rgb or single color?",
      "For anyone wondering this is the full setup: \n\nhttps://i.redd.it/tijv3373zn471.jpg",
      "Neither is the true ship. Both are the true ship.",
      "Oh nah man, if you already have a fully functioning PC then you don't need these cables. \n\n\n/s",
      "Compatible with all, they’re just extensions",
      "the super hero from Marvel",
      "we are the same ship bro",
      "Not sure where the disconnect is lol but there are 3 types of the Strimmer plus. A 24 pin for the mobo, a 2×8 for the GPU and a 3x8 for GPU's that have 3 8 pin connectors. Now remember these are extensions not straight up cables so you cant just replace the cables you have but you can extend them.",
      "What gave it away? Good job man, that's correct.",
      "Thanks man. The PSU is tucked away in the back. It's the Corsair SF750.",
      "Oh i bought mine at microcenter lol. I guess they are hard to find at msrp",
      "Looks so clean you can perform surgery in there."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "mid",
    "matched_keywords": [
      "rtx 3070",
      "3070"
    ],
    "title": "Modded GeForce RTX 3070 with 16GB memory gets major 1% low FPS boost - VideoCardz.com",
    "selftext": "",
    "comments": [
      "I hope every single review of the upcoming 4060s include RE, Hogwarts and CoD on ultra settings and leads with their results.",
      "Quite an improvement actually. 10fps more on the average and a huge amount more fps for the 1% and 0.1% lows.\n\nThey should bring back GPUs with socketed VRAM :)",
      "The problem is that the frequency that's necessary for the high memory bandwidth of modern GPUs requires excellent signal strength. If you introduce connectors (and longer traces that would also be necessary) you wouldn't be able to achieve the bandwidth that is currently reached. \n\nHonestly Nvidia should have just put 20$ more vram into the 3070 to make it 16gb.",
      "Nvidia: \"but but but, you can turn on frame generation! That 15 FPS 1% low will turn into 30 FPS*\"  *(that feels like 14 FPS in terms of latency!\")*\n\nAlso, inb4:  \"You shouldn't buy a 4060 and expect to run High/Ultra settings!\"  *card costs $450 or whatever absurd price*",
      "It's really disgusting that nvidia was making money hand over fist during the pandemic yet they were so stingy with vram. Literally what's the point of squeezing that extra few dollars of profit even when you're already making hundreds per card. Really regret buying my stupid 3070Ti.",
      "Nvidia will get super mad if people start upgrading the VRAM on there GPU's, lol\n\nKind of sad how Nvidia are segmenting the stack by VRAM, they where so mad that 1080 TI's where used for professional work instead of pro cards. They never forget.",
      "That's the plan, they want you to buy another GPU from them",
      "So fps gained 7% overall with a very healthy 400-500% increase in 1% lows, seems like Nvidia had to know this at the time of release and just screwed everyone.",
      "Newly released GPU that costs more than a console can't handle max settings -_-",
      "And yet there are huge amounts of people on this sub that like to cover their eyes on all of these posts and continue preaching that 8GB of VRAM is not an issue, it's blown out of proportion.\n\nOh alright, then let me just enable RT on Resident Evil 2 aaaaand it crashed.",
      "Nvidia could release the RTX 3070 Super Ti. Now with 10 more fps on average and 16gb GDDR6.",
      "Planned obsolescence. And an army of fanboys to help hide it.",
      "Ironically frame generation requires more vram compared to standard DLSS, even up to 2GB at 4k.",
      "> So fps gained 7% overall with a very healthy 400-500% increase in 1% lows, seems like Nvidia had to know this at the time of release and just screwed everyone.\n\nThey didn't intend to screw you. That was a side-effect of maximum profit goal.",
      "Can't sell professional cards at professional prices when consumer cards are just as good at consumer prices, y'know.",
      "I know, it was more a joke than anything else.\n\nSockets would also require a different height.",
      "No. Don't suggest they bring that back. Manufacturers will just sell you the same card with less VRAM for the same price and say \"hey look, you have *options* now.\"\n\nFuck that. They should just put sufficient VRAM on the card in the first place.",
      "NVIDIA has a strangle hold in the professional market with their Quadro line which gets proper VRAM. They don’t want their gaming cards replacing quadros in the professional market which is why their VRAM is almost always half what the Quadro equivalent is. AMD is more than glad to throw VRAM on cards because they want market share anyway they can get it. Until AMD or Intel truly threaten market share on NVIDIA, they are going to keep this VRAM divide to maximize profits.",
      "It existed?\n\nI dream about been able to upgrade memory on my RTX3070 as I know it's a capable GPU. Lot of games play fine at 4K with the help of DLSS, only VRAM is the problem...",
      "It's ok tho cause the 50 series will have slightly more vram than the 40 series.\n\nOnly slightly though, gotta ensure the product doesn't function great after a couple of years to encourage upgrading."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "mid",
    "matched_keywords": [
      "rtx 3070",
      "3070"
    ],
    "title": "NVIDIA GeForce RTX 4060 Ti expected to offer RTX 3070 performance for less than $500 - VideoCardz.com",
    "selftext": "",
    "comments": [
      "I'm no expert... But the 3070 already offers 3070 performance for under $500",
      "What a joke. The 3060 Ti G6X already closes the gap to the 3070 and is just slightly slower than a 3070 at this point. Now Nvidia releases a card that is 5% faster for probably 10% more money after two years🤡",
      "Absolutely. Green team hoping we don't know how to add 1 + 1.",
      "You mean $499? because thats the number I think Nvidia will price it.",
      "Which due to inflation now equals 3",
      "I really hope sales for this generation (outside of 4090) will be abysmal, so that maybe NVIDIA realized ...  bloody consoles offer a complete package for $500 while your mid-tier 128bit (!!!) card alone costs as much and requires a PC (CPU + cooler, RAM, mobo, case, kb and mouse) on top of that.\n\n3070 performance for 3070 price two years later. WTF are you doing and thinking NVIDIA?",
      "Looks like shit",
      "But 3070 already offers 3070 level performance for less than $500",
      "The headline sounds like that's a good thing.\n\nThat's awful. The article says closer to 500 bucks. That means, even if it's a bit less, same price performance point + dlss3 + better RT performance + probably less wattage.\n\nThat's a joke. That's like they release the 3070 with improved RTX features. 3070 Super would be an appropriate name.",
      "Yes, Nvidia recently phrased out the original RTX 3060 Ti with GDDR6 memory and replaced it with faster GDDR6X at the same price. The increase in memory bandwidth puts it even closer to the 3070 now as even the original 3060 Ti was like about 10% slower than the 3070.",
      "NVidia gloated to their investors that consumers are willing to pay $200-$300 more for a card then they used to. \n\nIt feels like this is so ingrained in Jensen’s head, that he now just straight up adds that number to any reasonable price for every 4000-series GPU and calls it a day.",
      "4070 rumoured with 3080 performance and price, 4060ti rumoured with 3070 performance and about or less the price.\nSo three years of technological development the only thing we get is software(dlss3) and less power usage?",
      "Fuck them",
      "😂🤣 you’re an expert in my eyes",
      "G6X refers to Gddr6x, correct?",
      "Guys, you’re killing PC gaming. What is entry point anymore",
      "If you have a 3080 you shouldnt even consider upgrading, unless you have the 10 gb version, that i see it vram limiting the gpu at 4k at least.",
      "fuck spez -- mass edited with redact.dev",
      "It is, sadly. That's why I'm staying with my 3080 OC'ed. I thought about 4090, but it is ridiculously expensive",
      "My GTX 1080 it's gonna live forever."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "mid",
    "matched_keywords": [
      "rtx 3070",
      "3070"
    ],
    "title": "My first pc build rtx 3070 and ryzen 5600x case 275r airflow",
    "selftext": "",
    "comments": [
      "Gamers Nexus approved",
      "Nice build and well done on the rad placement, pipes down.",
      "Friday the 13th.. and its 2020... we are doomed",
      "128GB of RAM really increases the performance and girth of your ePeen, especially if it has RGB.",
      "r/beatmetoit",
      "All the shit hit the fan on Friday the 13th in March. Maybe this one will close the door.",
      "God damn this circle jerk has gone too far. Actual engineers have said this isn't an issue...",
      "I swear the pipes just aren't long enough in most cases to reach the bottom (front mounted). \n\nI have the h150i and it's not even close to reaching.",
      "Is that the gigabyte eagle card?",
      "Actual engineers don't give a fuck about noise levels though, which is to my understanding the largest upside with this placement.",
      "I thought Gamer Nexus only approved the radiator on top of case with hose going down\n\nBut i still dont think it matters (unless you have the radiator on the bottom of the case with the hose going up...they didnt like that version one bit)",
      "What RAM is that? I'm shopping for some, and like the way it looks.",
      "No, it's the gaming oc.",
      "Looks like Corsair Vengeance Pro RGB to me. I just bought a 128GB kit.",
      "??? According to gamers nexus the engineers at the companies he talked with, all thanked him for spreading the message. Less failure rate is always a good thing.",
      "I haven’t ever heard of noise issues until they released that stupid video and now everyone is freaking out that their AIO will explode or cause them to go deaf",
      "How did you find updating the BIOS for Ryzen? Was it easy enough?",
      "[Said video](https://youtu.be/BbGomv195sk) tl;dr:\n\nRad at top with pump beneath = good\n\nRad at front with tubes down & pump beneath top of rad = good\n\nRad at front with tubes up but pump beneath top of rad = fine in terms of performance & longevity, but may cause gurgling/bubbling noise as air pools at the top of the rad and gets circulated through the tubes & pump\n\nSmall rad at front with pump above top of rad = bad, air will pool in pump, severely impacting cooling performance, may damage pump if not a magnetic levitation type (most modern aio pumps are this type and do not require lubrication from the cooling fluid to function, but some still use older style pumps that do need lubrication), causing excess noise at low loads due to poor cooling performance, elevated temperatures may increase rate of coolant permeation, shortening lifespan of aio\n\nRad at bottom with pump above = bad, see previous point",
      "No, the pump can't be higher than the reservoir.",
      "😂"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "mid",
    "matched_keywords": [
      "rtx 3070",
      "3070"
    ],
    "title": "Made the RTX 3070 in Blender while waiting for the release",
    "selftext": "",
    "comments": [
      "Please don't put an RTX 3070 in a blender",
      "Ampere dust - don't breathe this!",
      "[There you go](https://imgur.com/LfPqT96)",
      "Looks absolutely sick, did you try rendering it in a different color?",
      "[Sure thing](https://imgur.com/1H2099L)",
      "Thank you, I didn't try any other colors yet... which colors would you like to see?",
      "[:)](https://imgur.com/CHcEjgJ)",
      "Damn.... this made me salivate",
      "[Here is red one (my favorite so far)](https://imgur.com/kwmLOyW) I'll be back in a few minutes and will render the other colors too",
      "All white!",
      "great throwback to the *will it blend* series!",
      "[There you go](https://imgur.com/v6hCcLd)",
      "[RTX 3070 Geforce Edition?](https://i.imgur.com/PVC7ti9.png) :D",
      "FE looks so much better than basically every AIB might go for founders.",
      "Oh wow that looks crazy good holy moly. Nice work man!",
      "snort!",
      "[is that you Dave2D?](https://imgur.com/SOsv2Dz)",
      "RTX 3070 Radeon Edition",
      "[Modeled it after renders from Nvidia site so I think it's confirmed](https://imgur.com/SMzhh0n)",
      "[Hot pink with lime green](https://imgur.com/heazPDG)\n\n[Black and orange Halloween special\n](https://imgur.com/Cxm4jP0)\n\n[Black with red accents](https://imgur.com/CUBfVRT)\n\n[Pride edition roygbiv](https://imgur.com/Rk6iv2D)"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "mid",
    "matched_keywords": [
      "rtx 3070",
      "3070"
    ],
    "title": "GeForce RTX 3070 (and 3080 + 3090) Launchday Thread",
    "selftext": "# Subreddit Protocol:\n\n* **Launch Day Megathread** will serve as the hub for discussion regarding various launchday madness. [You can also join our Discord server for discussion!](https://discord.gg/nvidia)\n* Topics that should be in Megathread include:\n   * Successful order\n   * Non successful order\n   * Brick & Mortar store experience\n   * Stock Check\n   * EVGA step up discussion\n   * Any questions regarding orders and availability\n   * Any discussion about how you're mad because you didn't get one\n   * **Literally everything about the launch**\n* **ALL other standalone launch day related posts will be removed.**\n* **There will not be any Megathread for the third party card reviews**. They can and should be posted individually.\n* **Subreddit may go on restricted mode for a number of times during the next 24 hours. This may last a few minutes to a few hours depending on the influx of content.**\n\n**Reference Info:**\n\n[RTX 3090 Review Megathread](https://new.reddit.com/r/nvidia/comments/iyy5sx/geforce_rtx_3090_review_megathread/)\n\n[RTX 3080 Review Megathread](https://new.reddit.com/r/nvidia/comments/itw87x/geforce_rtx_3080_review_megathread/)\n\n[RTX 3070 Review Megathread](https://new.reddit.com/r/nvidia/comments/jj8k0l/geforce_rtx_3070_review_megathread/)\n\n[RTX 30-Series Information Megathread](https://new.reddit.com/r/nvidia/comments/iko4ir/geforce_rtx_30series_ampere_information_megathread/)\n\n[RTX 3080 Board Stability, New Driver, Capacitors + Game Ready Driver 456.55 - \"Improves stability in certain games on RTX 30 Series GPUs.\"](https://new.reddit.com/r/nvidia/comments/j1k5sq/rtx_3080_board_stability_new_driver_capacitors/)\n\n# Remember not to buy from scalpers (fuck em). If you are buying from website that allows 3rd party sellers (e.g. Newegg/Amazon), please make sure you are buying from said retailer. Anything else means you're buying from scalpers. Do not buy from scalpers. Treat the product as out of stock and wait if the official retailers are not selling them.",
    "comments": [
      ">got it in my cart\n\n>selected payment\n\n>random error wouldn’t let me purchase 😎\n\n>was already sold out in my area 😎😎\n\n>wouldn’t let me select shipping😎😎😎\n\n>final all sold out error 😎😎😎😎\n\n>thanks guys!",
      "i feel like im registering for college classes",
      "I got the RTX 3070: Out of Stock Edition",
      "Best Buy \"Due to high demand, we're having everyone go through one more step before it can be added.\n\nPlease try again.\"\n\n\nWhat extra step is there lol",
      "pain and suffering",
      "Forever in our carts, RTX 3070 💔",
      "Dr. Ligma Sak",
      "I knew it was going to be hell, but this is just disappointing. I had a 3070 FE in my best buy cart for well over 15 minutes, but i kept getting slapped with \"shipping is unavailable in your area\" and other assorted errors, and i could never check out.\n\nI get that stock's low, but jesus christ how hard is it to have a functional cart system on a major retail website???",
      "Who here is actually going AMD because of this abysmal launch?",
      "LOL Nvidia Founders Edition instantly out of stock in Germany.\n\nWell, looks like I'm getting a Radeon this generation...",
      "Edit: sounds like just about everyone in the thread is running into this, lol\n\n\"No longer available for shipping\"\n\n\"Pickup unavailable within 250 miles\"\n\nGee, thanks for nothing Best Buy",
      "That extra two weeks to \"build up inventory\" really paid off, huh. I liked Best Buy's advice to quickly checkout once the card was in my cart. Once I had a FE 3070, Best Buy threw every pop-up at me they could: \"You've got another shipping option,\" \"Want it tomorrow?,\" \"Pick-up available.\" By the time I clicked through all of the options it was no longer in my cart.",
      "which prof did you get for chem?",
      "My local microcenter got 180 cards in total!  I was worried when I showed up a couple hours early and there were over 50 people in line.",
      "AMD here I come.",
      "2 weeks delay for another shit show. What a freaking joke man.",
      "Fuck nvidia and fuck bestbuy.",
      "on BB: \n\n \n\n## How it's going to work:\n\n* Every few minutes, we're going to release more inventory.\n* Shortly, the button below will turn back to yellow (unless we sell out).\n* At that point, try adding it to your cart again.\n\n**Pro Tip:** If that works, checkout as fast as you can. It won't be reserved until you are in checkout. Good luck!",
      "me. Nvidia is straight up smoking dick if they think that this is a winning strategy for their company. i just tried so hard to literally throw them 500+ dollars of my money for me to get shafted while the item was in my cart. This will be the last time i wake up at 5:50 AM for their bullshit",
      "We knew what was going to happen and we were still disappointed. FUCK NVIDIA"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "mid",
    "matched_keywords": [
      "rtx 3070",
      "3070"
    ],
    "title": "RTX 3070 Comparison / Buy Aid - again, by popular request, here is the TechPowerUp.com reviews all together and again I add a few things more - Hope this helps everyone in their buying decisions!",
    "selftext": "",
    "comments": [
      "Interesting to see that now the dust has settled, the FE is actually a good buy considering it's cheaper than everything else and doesn't fall considerably behind in performance. It's just (*relatively) hot.",
      "It's really not hot at all, 74c is a very stable temp to run at and my 3070 FE never exceeds 70c paired with an airflow case.",
      "This will help me in 10 months.",
      "Most of the 3rd party cards also have way better temps than the founders cards. Lower temps = no/minimal throttling and higher boost frequencies you can reach",
      "I think it would be amusing to include games like among us and fall guys on these lists just to prove the point that a 3070 is overkill for people who just play those.",
      "I don't think any cards are on the market are gonna thermal throttle unless you have really bad airflow. I think you mean just higher boost clocks with lower temperatures",
      "Great work, already have my FE but love seeing this all charted out",
      "Guess I should have said relatively hot.",
      "You'll notice that every single card in here other than the FE has a factory OC (OC in the name). That means they overclock it from the factory. \n\nYou can go into afterburner and do the same thing and get performance closer to these cards.\n\nAlso yes cards from aibs generally run cooler meaning slightly higher boost clocks. \n\nMind you that the differences in fps here are not significant. If you look at the average fps between cards, the highest delta is 4 fps. Is it worth it to pay the $100+ AIB premium for a 4 fps boost? Methinks not.",
      "I'm not terribly surprised but I also don't care. A maximum delta of 3.9 FPS @1440p is nothing. Especially since I'm coming from console gaming anyways.\n\nIt's the cheapest and it's pretty quiet, I'll take that.",
      "i would agree but here in Czech Rep. its practically non existent, even more so than the actual aibs which is like 2AM in the morning F5 style lottery. Shame that TPU didnt test the AIB models that are actually more common in EU in terms of occasional stock.",
      "Zotac builts like a tank and gives the longest warranty which is 5 years",
      "So in other words, buy the cheapest one available. No one will be able to tell the difference in a blind test.",
      "the question is how their fulfillment actually pans out",
      "https://www.reddit.com/r/nvidia/comments/jvmj1o/rtx_3080_comparison_buy_aid_by_popular_request/?ref=share&ref_source=link",
      "It's always the same with every card, the only meaningful differences are cooling, noise, looks and warranty.",
      "Its honestly not hot at all. My 1070ti hits 80 C on a daily basis.",
      "Surprised to see red across the board lol. At least it's not much of a gap.",
      "Dude last time i sayed something like this Ive got so much hate.. I agree completely with you. People should buy accordingly to their needs.",
      "Bought the Zotac as it was the only one left at MicroCenter. I must say, I’m quite happy with the cards performance in many areas."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "mid",
    "matched_keywords": [
      "rtx 3070",
      "3070",
      "3070 ti",
      "rtx 3070 ti"
    ],
    "title": "NVIDIA RTX 3070 Ti 16GB and RTX 3080 12GB are postponed - only the RTX 3090 Ti is still on schedule | igor'sLAB",
    "selftext": "",
    "comments": [
      "3090 Ti has got to be the dumbest shit ive ever heard of.",
      "Wait till they release a RTX 3090 Ti Super Max",
      "I’ll never get my hands on a graphics card",
      "Rtx 3090 TiTius P3pp3roniuz.\n\nEdit: thx for the silver :P",
      "Very easy to get… over msrp",
      "Why doesn't the RTX 2060 12GB have a MSRP attached? Have they all gone to bulk purchase miners & scalpers?",
      "It has no msrp so that retailers and AIBs can charge whatever they feel like. The first listings spotted had them at around 600-700 euros",
      "2% performance uplift go brrrr.",
      "It is very possible, likely even. You can't get that much more out of a GA102. We're talking about a small memory clock increase, NO memory bus increase (already maxed out), and a mere TWO SM's being enabled (3090 already has 82/84 possible SM's). \n\nThat's not going to result in much. 2% is probably just about right.\n\nFor reference, 3080 > 3090 is like 7-15%, mostly \\~10%, and the differences there are much more stark:\n\n* 19 vs 19.5GBPS memory speed \n* 320 v 384 bit bus\n* almost a 200GB/s memory bandwidth advantage to the 3090 because of the above two things alone (760 vs 936)\n* 68 vs 82 SM's (10496 v 8704 CUDA cores),\n* similar differences in RT/Tensor cores and the like. \n\nThe only way a '3090 Ti' level card makes any sense imho is if it is called a Titan, and gets a few more workstation features enabled in the driver to justify it's existence lol.",
      "That's literally super fucked if you ask me...",
      "Are 3080’s still impossible to get? I’ve been a bit out of the loop",
      "Rtx 3090 ti noctua edition with a 5 slot cooler",
      "My local stores charge gpu based on 3dmark scores. Every generation of cards is getting more expensive.",
      "[3090 Ti Super Max launch event ](https://youtu.be/ZBJCgrrQhx4)",
      "I weep with you, brother.",
      "Delayed by Nvidia or Delayed by Scalpers.  \n\nSame shit anyway.",
      "Ehi guys, what's about all this hate?\nScalpers will get the majority of this Gpu so chill, nothing will change for we poor normal users.\n\nPs fucking scalpers, I still can't upgrade from my Gtx 980 to  the 20xx or 30xx.\nPorco dio.",
      "Can't wait to not be able to buy these",
      "I'd buy that (if I could)",
      "At least that makes more sense than the 3070 one that actually exists lol"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "mid",
    "matched_keywords": [
      "rtx 3070",
      "3070"
    ],
    "title": "New MSI RTX 3070 DOA out of sealed box, MSI is useless!",
    "selftext": "After months of trying to buy a 30xx series card, my friend in another state that I've known since high school managed to buy me an MSI RTX 3070 for $598 + tax at Best Buy.\n\nHe sent me the new and sealed card.  When I installed it in my computer, all I got were lines all over the screen.  Reseated it multiple times, tried other slots.  It's dead.\n\nBecause Best Buy was sold out of them I decided to RMA it to MSI.  I sent the card in about 6 weeks ago.  Got notice recently that they don't have replacements available and they want to offer me a refund of $475.  $475 what on earth?  Below MSRP for an insanely high demand card!?  I told them I can't accept that and that I paid almost $660 with tax and another $10 to send it to them.\n\nI told them I just want a card and I'm okay with waiting longer.  Also hinted that if they have a RTX 3080 I wouldn't mind upgrading.  They then said they can try to \"compromise\" if I show them the receipt and \\*might\\* be able to refund me for what I paid, but they can't pay for my shipping to send in the defective card.  Unreal.\n\nAnyone have issues like this?  I asked them to escalate this to a manager.  Unacceptable for a manufacturer to be selling cards but not be able to support the defective ones.  Any suggestions for getting this resolve with MSI, anyone I can reach out to?  \n\n\nEDIT:  02/17:  Someone from this forum PM'ed me contact info for a manager at MSI.  I contacted him and a few days later he called me and told me that they can't touch new stock for RMA purposes but he did manage to get me a brand new card that they'll be sending out in a few days.  So hopefully they follow through and soon I'll have this mess behind me.",
    "comments": [
      "Get them to send you a new 3070, its not like they wont be making more of them. Anything else is them trying to weasel out of their obligations.",
      "MSI is useless. Totally useless. Discovered this when registering a new motherboard two months ago. All bullshit on their end from the beginning. Ridiculous waste of time on an issue that wasn’t even relevant. My thoughts after successfully registering it (took 2 weeks) that I will never even try to deal with them if a real issue should ever arise. And in the the future, I’ll never buy their products again. Hope your dilemma \n is resolved promptly.",
      "How is this even legal to refund you less than you got it for?? I can sort of get them not wanting to cover shipping but this is insane.",
      "Their reputation has gone down the shitter over the years. I remember during the Pascal days they were well liked and made some nice custom GPU's with good custom PCB's and components and everything.",
      "The dude responsible for making MSI marketable and customer friendly jumped out of a building. Thats what they said happened. Im beginning to think he was thrown out and MSI is returning to the poo brand they were always famous for being.",
      "They’d rather refund OP so they can sell the other cards at a premium.",
      "Fuck dude. I’m sorry you’re having this experience.\n\nMy EVGA 3090 was defective as well, and when I did the RMA through EVGA, they had a new one mailed to me within literally 6 days. Same exact card. \n\nTL;dr\n\nEVGA has amazing customer service.",
      "Well hold on a sec...if a retailer sells an MSI product for 5x the msrp, MSI shouldn’t be held liable to refund you that 5x price. If you want your money back, go to the retailer who charged you above msrp. If you want a replacement/fixed card, go to the manufacturer (or retailer).\n\nI agree MSI shouldn’t be offered you less than msrp, but you can’t expect them to offer you more than it either.",
      "Yea, I don't think it would be legal for them to offer you less than what you paid.  \n\n\nIt's especially frustrating after spending like 20-30 hours, including staying up at 5AM on launch day to try to buy one.",
      "Yeah that's why OP should push for a replacement so they don't have to pay again.",
      "Without receipt they have no clue how much was paid till thats provided they can offer whatever. But ya refund is to be handled by place of purchase then manufacturer reimburses the business for the defective card. Otherwise its a messed up gain for bestbuy but huge loss for msi especially if marked up or rewards points used. Im shocked they offered any refund honestly.",
      "agreed, I stick to Asus all the time when I can",
      "Yep, with the 30xxx series cards you can't really chose what brand to buy though, as its hard enough to get one, let alone get your brand preference.",
      "Me too. Although Asus doesn’t have a good RMA history either, but in my experience I’ve never needed to RMA an Asus product. I wanted an Asus 3080 but they have been impossible to get in my area. Even the microcenter near me are only getting 2-3 of them at a time. So I wound up with an MSI 3080 as they were getting dozens of those and EVGA models. I’m happy with it but much would’ve preferred an Asus. My STRIX 970 is still kicking just fine.",
      "Ok but isn't best buy the one you should talk to? You bought it from bb, not msi right?",
      "RIP to one of the good ones",
      "Wait, isnt bestbuy the one that should refund you since they got your money?",
      "EVGA is simply the best. I will say; I had a good experience with Corsair lately. I ordered an HX1200 from Amazon. It was part of a defective series of lots that would cause my pc to power cycle. Call them in the morning and had a new PSU on it's way to me the same day. Returned the old one all shipping billed to Corsair. It's nice when a company does what it's supposed to do.",
      "I know you want a working card, my response was more so in reply to your comment “I don’t think it would be legal for them to refund you less than what you paid”",
      "Exactly why I'm holding out, I will never buy a card from anyone but EVGA. They're literally the best option if you don't want to worry about getting a replacement or dealing with bullshit customer service. Also they have better re-sell value because you can transfer the warranty to second-hand users. You also have the option to pay $50 for a 10-year warranty after their 3-year warranty, which means when it eventually dies, you will basically get a free upgrade. MSI and ASUS have lots of dark stories of their customer service. I will never buy 1 component from them."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "mid",
    "matched_keywords": [
      "rtx 3070",
      "3070"
    ],
    "title": "NVIDIA allegedly cancels GeForce RTX 3080 20GB and RTX 3070 16GB - VideoCardz.com",
    "selftext": "",
    "comments": [
      "Hopefully, they'll still be launching the regular 10GB versions.",
      "Did they cancel the 10 GB version of the 3080 as well because where the fuck is it?",
      "Looked good on paper?\n\n\nEdit: uh, flair updated.",
      "Nah. They’re scarce but there still are a couple thousand legit cards trickling in. I got a FE during a drop two weeks ago (though I didn’t make a big post about it). I guess I could dig up the receipt if you really need convincing but I’d bet that the majority of posts you see are first-hand cards.\n\nEdit: although now that I think about it there probably is something to be said about the overlap between the type of person to buy from a scalper and the type of person who feels the need to post proof of their card for validation.",
      "all the people in this sub with their constant posts of \"dont have to hit f5, my card came in\" guaranteed got it off ebay. do you know how many cards I see get sold there? for $1200+? theres a ton right now with a bunch of bids.\n\nimo people should be required to post the receipt where they got the card from before they can post their build in this sub",
      "Just make sure that we have a reliable supply of regular 10Gb 3080s. While the 20Gb version would be appreciated, it's entirely uncalled for to overstretch your production lines with yet another model when you can't produce the basic one quick enough.",
      "Oh shit, thats bad news...1.) because yeah people wanted a 20gb version and waited for it.\n\n2.) if they cancelled it, maybe big navi isn't that much of a competitor so there is no need to release a more powerful card. (hopefully not true)",
      "Must really be a supply side issue. I cant imagine they want to leave enthusiast money on the table. \n\nI doubt the “lack” of VRAM causes issues for 3080s before the next gen or GPUs release, but fuck if some people wont be annoyed AMDs offering has a bigger number next to it. The 3070 is a bit surprising. With DLSS in a lot of upcoming games that is hypothetically a 4K card, & 8gb could end up being an issue as newer games push boundaries. \n\nSuppose they might want to save their materials stock to meet current demand rather than be able to make/sell even less high VRAM cards.",
      "Give us a 12GB 3080 Ti that is 3090 with half the VRAM instead.",
      "The good news is that even if they’d have tried it wouldn’t have mattered. So no harm done!",
      "looks like nvidia has someone refreshing reddit all day.",
      "I understand the supply chain issues but this feels like some poor planning on nvidias part.  \n\n\nNot having that 20GB 3080 really sucks for 3D designers like myself. Making the 3080 not NVLink compatible and then only having a 10GB variant forces most of us to move to the 3090 (or have issues with vram ussage) which costs double but isn't double the performance.",
      "It just screams \"unconfirmed product rumour continues not to be confirmed\" to me...",
      "Some people forget that none of the leaks before were confirmed. Yes, they were most likely true like most other leaks. But until nvidia confirms it don't be upset if they just cancel it. \n\nThere is a reason why they weren't confirmed yet, and if there wouldn't have been any leaks about it you wouldn't even be upset now.",
      "the shift to 7nm might come soon though",
      "So they've canceled all the models that were never confirmed to begin with. Interesting.... lol",
      "How many times do we have to say it. This was \\*not\\* a paper launch. They literally sold at least ten 3080s.",
      "> \"soon\" \n\nSwitching nodes for a GPU doesn't just happen with a flick of a switch.\n\nIf it comes at all i wouldn't expect it before spring or summer next year in a form of a refresh. Releasing it sooner is probably tehnicly not even posible and would also just piss of people.",
      "And if a real performance boost arises, people are going to be *pissed*...",
      "\"The reason behind RTX 3070 16GB cancellation is unknown\"\nWell how are they gonna sell this shitshow to the ones who bought a 3080.. lol"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "mid",
    "matched_keywords": [
      "rtx 3070",
      "3070"
    ],
    "title": "NVIDIA GeForce RTX 4060 reportedly consumes more power than RTX 3070 (220W) - VideoCardz.com",
    "selftext": "",
    "comments": [
      "Have they seen the cost of energy. Hard pass from me if so.",
      "Nevermind the cost of energy, the heat output in the summer would be actually painful. Looks nervously at 260w gpu...",
      "Everybody here taking this as no-question gospel, even though this person's claims have been wild and all over the place.  According to them, the 4090 will be released next month.  Cant take them seriously.",
      "My 3090 in my upstairs office in central Texas is already a poor choice",
      "seems they just want to push as much power as possible through smallest arount of silicon/die area to maximise profit margin and to hell with energy efficiency\n\nvery greedy will sooner pickup a series x then get a gpu that throws money(energy) and card lifespan away pushing max watts and heat, and forces me building more expensive and noisy case/system like a wind tunnel to deal with stupid heat output.",
      "So you two are why Texas has the power outages lol",
      "My 3070 and the ac are always fighting to see who will win the 3070 comes on top and th rest of the house is like super cool and my room is sauna",
      "No offense, but it gets frustrating to see people have no idea what the term efficient means as if they never had physics in school.\n\nThe RTX 4xxx series is obviously going to more more efficient than the RTX 3xxx cards, I can't believe I am even writing this. This would be the case even if the architecture would remain, simply due to the new process node. But the arch will obviously bring two years worth of improvements aswell.\n\nThe fact that NVIDIA releases higher and higher TDP configurations for certain price points is disappointing, but has literally nothing to do with the efficiency.",
      "Austin 3090 crew checking in. Here come the triple digit days with no end in sight.",
      "Undervolt or limit the power draw.\n\nEspecially undervolting pushes the power draw down.\n\nMy lowest undervolt for my 3080 is 750mv 1700mhz. It's uses roundabout half the power than stock 320w while it performance not even 10% below stock with 370w.\n\nI mainly use a different undervolt, but that one shows how far you can go.",
      "I probably would rather stick with my current 3070 if the rumoured 300W - 400W becomes the truth for 4070, i couldn't even imagine how much i am going to handle that much heat in my room that already averages at 30c ambient temp, curse of living in a hot tropical country and no AC.",
      "They leaked obscenely high prices for the 30X0 cards before the official announcement. Everyone here knew what they were doing. Granted with the supply chain constraints those obscenely high numbers looked like a bargain.",
      "Why would you upgrade after one gen?..",
      "Their cards have always been pushing past the point of diminishing returns - even when they had lower power consumption than AMD's cards. \n\nSo what's really going on is that they're inflating the difference between the generations. Like when the 2060 had a bigger GPU than a 1070. Same with this \"4060\" - if they called it a 4070, the progress from the 3070 wouldn't look impressive.",
      "I helped, but undervolted my 3080 so Abbot could get his crypto farm up and running",
      "We know but the jokes help us forget about that 😅",
      "I'm pretty sure perf/W has *never* gone down from gen-to-gen. In the case of Turing > Ampere, the perf/W gains were very small or even trivial depending on which SKUs you compare, but it was still technically an improvement. Once you compare both architectures at a more reasonable voltage, Ampere pulls further ahead in perf/W; as opposed to comparing them stock-to-stock, where they have almost the same perf/W, suggesting Ampere is tuned more aggressively out of the box than Turing so as to cancel out most of the efficiency gains of TSMC 12 > Samsung 8. I think seeing Ada running at lower voltages is going to be illuminating because I refuse to believe that the perf/W potential of Samsung 8 > TSMC 5 is anything short of significant. By all accounts Samsung 8 is a fairly crummy process (even for its era/technical specs) while TSMC N5 is, expectedly for TSMC, a great quality process. If Ada doesn't have a *substantial* perf/W improvement over Ampere when comparing both architectures at reigned in voltages, you'd have to wonder what went wrong in the engineering department.",
      "Do that 20 more years and the lowest end card will be 1000w",
      "Nah, Texas shitty privatized power grid is to blame 🥴",
      "I guess you have no clue how powerful undervolting for the 30 series  is.\n\nYou decide what goal you have. You don't have to lower your performance I also never talked about 20% less. I gave an example of an extreme undervolt which almost halves the power draw while costing not even 10% performance.\n\nI mainly use 875mv 1905mhz, which performs close to max OC with 370w but only pulls 250-270w on avg.\n\nMeans saving almost one third power but gaining performance compared to stock."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "mid",
    "matched_keywords": [
      "rtx 3070",
      "3070"
    ],
    "title": "Nvidia's 16GB RTX 3070... Sort Of: 16GB A4000 vs 8GB RTX 3070 (Hardware Unboxed)",
    "selftext": "",
    "comments": [
      "We should all hope they succeed.  Nvidia should be giving us sufficient VRAM, particularly when the products are so expensive.",
      "Holy shit... the difference is pretty big. People were claiming that Hogwarts Legacy got fixed, but looks like \"optimization\" just meant not loading textures. Seeing how the consoles have 16GB VRAM with 12GB usable, current gen exclusive games won't run properly on even the 3070ti. Hope the upcoming 4060 8GB & 4050 6GB cards fails so that Nvidia learns a lesson.",
      "As I’ve stated in a different post, until Intel or AMD truly challenge where Quadros dominate, NVIDIA is not going to have their gaming products with the same amount of VRAM as their Professional cards, they are always going to gimp them. It maximizes their profits. AMD honestly loves NVIDIA pricing because they can raise their prices too. If AMD truly cared, they would be pricing cards $100 to $150 less themselves but they won’t because they love money just as much as NVIDIA.\n\nNo corporation is your friend or cares about you. They only care about your money.",
      "People kept saying the games were unoptimized, this just proved that their hardware is low end.\n\nBlame Nvidia for having less than half the VRAM of a console.",
      "They’re really going hard on this VRAM stuff. They’re not wrong either, just a lot of content. Trying to pressure nvidia I guess",
      "Both can be true at the same time tho",
      "I think the biggest takeaway from everything is that a lot of games are developed for consoles first. If your GPU has less VRAM than current/next-gen consoles you'll likely run into issues with the latest games.",
      "All the sudden I want to mod my gfx cards",
      "The 3070 should have had 16gb of ram at launch.",
      "There was a Russian guy a few years ago who modified a 2070 so that it had 16GB of VRAM. I don't remember the details, but he did get slightly better performance after doing that. He desoldered the old VRAM and replaced them with 2GB modules. He also had to create a custom BIOS that would recognize the extra capacity.  \nSo if you're serious about it, you could look that up and give it a try. Please share your results if you do.  \n\nEdit: There was a recent guy who modded a 3070 with 16GB.   \n\nhttps://www.tweaktown.com/news/91194/modded-geforce-rtx-3070-with-16gb-of-vram-shows-impressive-performance-gains/index.html",
      "TL;DW: 90% of people with 3060ti - 3070 are not going to be strongly impacted by VRAM and you’ll just have to lower settings on brand new, massive, AAA games as the card ages. \n\nI really struggle to think of a game that if optimized well for lower end cards, would need more than 8GB of vram occupied constantly. \n\nThat being said, going forward, probably steer clear of low vram models",
      "With this video, it will seal the argument for those who questioned HUB using Radeon as comparison.\n\nStill wanna defend Nvidia for releasing a shitty product? Turing should be the last generation Nvidia can get away with 8GB Vram on a 256bit bus GPU. Nvidia took it way too far with Ampere & still doing it in ADA GPU by shifting SKU up 1-2 tiers.",
      "Journalists keep doing what crap? He's highlighting the fact that NVIDIA has been consistently handicapping their GPU performance by putting as little VRAM on their cards as possible.",
      "I almost got a 3070 a couple of months ago, I'm so glad I didn't now.",
      "Everytime I see these videos I panic thinking 8GB isn't enough then I remember that I primarily only play esports games/multiplayer games then I stop caring again",
      "PC never had and never will get the optimization for ***lower end*** hardware than consoles. Multiple devs stated, if the consoles have X amount of VRAM, PC needs around 2X, because it is not unified and you do not have a special ASIC like consoles, combine with what you want to be higher settings.\n\nThere is the meme asking if you PC is stronger than a console, and a lot of people now are in denial that the answer is No. If you need something 4x better than a console to get 4x the quality, not even a 4090 is close.\n\nNvidia talks with devs, they knew the VRAM requirements.",
      "The problem with \"lowering settings\" is the following: The most effective way of lowering vram usage is using lower res textures. You won't get any performance improvement from that, it just stuff fits into your vram. However, that will be a *huge* visual downgrade. VRAM questions are quite binary, as in you either have enough or dont. Historically there were only some gens where vram was an issue, like maxwell. AMPERE / ADA low-end will be the next gens with such problems. About game \"optimization\" people should realize like 95%+ of games are made for consoles, and later on get ported to pc. When devs designed games for ps4, 8gb vram was enough. Now new games will come designed for ps5. The whole engine is built up on assumptions that there will be 16gb ram (Maybe 12gb or so used for gpu). When someone ports this game to pc, they cannot \"optimize\" it down, as that would require rewriting half of the engine. These engines are not really designed to scale down. So you are right, soonish 8gb will be enough for 1080p low, with atrocious visuals compared to older games.",
      "You shouldn't be. It runs at a lower core and memory clock, so it's no surprise that it sips power.",
      "The biggest takeaway to me is that cards designed to be good at RT are shit at RT.  Makes the balance between Nvidia and AMD tighter",
      "looks like you never heard of frametimes and minimum fps"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "mid",
    "matched_keywords": [
      "rtx 3070",
      "3070",
      "3070 ti",
      "rtx 3070 ti"
    ],
    "title": "Best Buy Will Only Sell Nvidia's RTX 3070 Ti Online This Time",
    "selftext": "",
    "comments": [
      "autobots ready to roll",
      "what a great fucking idea",
      "In other words ... Best Buy has essentially already sold these units to scalpers.",
      "Scalpatrons roll out",
      "It's pretty revolutionary; good on them for thinking outside of the box.",
      "All the botters and scalpers are going to be really happy about this.",
      "what bullshit",
      "I wouldn’t want to deal with the savage horde of nerds at my store door",
      "I was blown away until I read the article and it says they did an in-store only 3080ti launch and it sounds like they didn't like the large crowd + limited supply. It's hard to be *that mad* when they tried in-store only for the better card.",
      "That literally is the worst possible model for a big box store. You want to get people to the store because they are more likely to purchase something else. No wonder they are closing stores left and right.",
      "My experience camping out last week was very chill. Because they did the whole ticketing thing based on who was actually in line, there was no savagery; it was all very friendly and chatty. We basically had a small party for the evening and into the early morning.",
      "Outside the big box store!?! Wuuuuttt",
      "Welcome to Cyberscalp 2027 europe edition, this is how it is since launch here (or at least in countries like here in Germany). At least offline there was a decent chance to obtain one for you in the us, online its so much worse and hopeless to get one when they shadow drop with the mrsp price.",
      "0900 to 0900.1",
      "No, the base model is the teaser rate.  It was never meant to be sold long term.  $1399 is the expected price.",
      "Fucking Best Buy geniuses",
      "Bots are licking their lips right now.. Scum of the earth",
      "What a stupid, try-hard edgelord thing to say.\n\nThese days you buy what you can.",
      "Kill me.",
      "There’s a good chance that in the future, Best Buy will become a mainly internet-based entity. At least that’s definitely what it seems like they want to do. I work there and they’re slowly moving from ample sales staff to ample product flow staff to complete online orders, as well as having a constant rotation of people working digital sales via phone or chat. Just watch, eventually all the remaining best buy stores will just become shipping hubs with a small front section with a handful of core products and accessories."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "mid",
    "matched_keywords": [
      "rtx 3070",
      "3070"
    ],
    "title": "[VideoCardz] ASUS GeForce RTX 3070 with Noctua cooling has been pictured",
    "selftext": "",
    "comments": [
      "Shut up and take my money. My current ideal card is de-shrouded with noctua fans on it anyway, let's streamline that.",
      "I don't care the inevitable \"it looks terrible\" crap: it's fucking beautiful and I want it.",
      "I'd like to say the cooling on that will be insane if they match up the heatsink properly and use the right fans. Not that the TUF or Strix arent already great cards.",
      "\"should of\" makes my brain hurt. Please stop.",
      "Would you pay $1200 USD for it? That's insane\n\nI could deshroud my 3080 and slap two noctua fans on it and still be under $800\n\nGranted, I was lucky and got it at MSRP but still",
      "It should of had a copper heatsink. Thats my only complaint. That copper accent behind noctua's fans would have been awesome.",
      "I can't see why a 3070 would need such an awesome cooler but goddamn I wish the 3080/3090 got this treatment. My strix 3090 is already insanely quiet but I can't imagine it with noctua fans.",
      "It's funny because they use \"should of\" incorrectly and then later use \"would have\" correctly.",
      "They absolutely *are* some of the best you can buy, I never said otherwise - but people seem to think they're unbeatable.\n\n\n\n[Here's a video using the same testing methodology, just including radiator+heatsink applications](https://youtu.be/XVPV9omPuyw?t=442). Yes, the A12 is near the top, but the only way it pulls ahead is on a heatsink at low RPM, and on a radiator at low*ish* RPM.\n\n\nThey absolutely are great fans, but they're awful value relative to other options and unless you're planning on tossing them on a rad in a config where they'll never be above x RPM, they don't excel in any noteworthy way and actually fall flat at high RPM.",
      "\"Noctua fans are not that special\"\n\n\"There's no fan that's quieter, cheaper, and pushes more CFM\"\n\nDa fuck?",
      "The price of course is mental in this market, more a sentiment of how much I like the collaboration (at least on paper)\n\nI run a de-shrouded TUF 3080 I got at launch, but with Arctic P12's, the poor man's A12x25",
      "They are pricy, but \"largely outperformed\"? No, while they have some respectable competition, like BeQuiets fans, noctua fans are top tier. My metric here is noise vs performance.",
      "I think a lot of zoomers will absolutely love this. \nWhy do you think vaporwave and synthwave are so popular rn?",
      "Lol and the Phanteks that beat Noctua isnt a normal sized 120 and is louder than Noctua at equal RPM’s. \n\nIt’s 20% larger at 30mm over the standard 25mm for all other fans. \n\nAlso, due to size, has larger motor, can spin to 3000rpm, which the Noctua iPPC fans do as well, so idk why they dont compare the two, unless these noctuas beat em.\n\nANYWAY, Noctua will always be bae as long as they do dope shit like replace fans for basically their entire existence and ship you new chipset mounting for older coolers.",
      "I would have mostly agreed with statement until very recently until I finely forked over some cash for some Noctua to see what the hype was about... Noctua are in a completely different league. \n\nTheir fans feel, look, and run a lot like the industrial fans i find in the industrial equipment I work on...",
      "Pretty much. It's not inherently a *bad* thing as, well, they're fans lol, and their products were ahead for some time - but mindlessly praising and defending them as if they're objectively the best fan in existence and will forever remain that way is absurd.\n\n\n\nThey're the best if you need 120mm fans for a radiator that isn't spewing *too* much heat, but short of that; there are numerous other superior options - some of which are also cheaper.",
      "Looks like 2 NF-A12x25s glued to a 3070\n\nprice $1,000 (guessing)",
      "I can't wait to watch the scalpers buy it.",
      "In the way that everyone reading these comments agrees with, and all the reviews I've ever read.\n\nI mean it's not hard mate.  They are the best fans and you eloquently outlined why.",
      "I don’t know a single fan that outperforms Noctua’s A12x25 for a given noise level."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "mid",
    "matched_keywords": [
      "rtx 3070",
      "3070",
      "3070 ti",
      "rtx 3070 ti"
    ],
    "title": "RTX 3070 Ti Founders Edition :)",
    "selftext": "",
    "comments": [
      "This is interesting following JTC's video yesterday...hows the overall fit and finish of the card?",
      "JayTwoCentz made a video earlier saying that no one got a F, and the reasoning might be because of the build quality. But, holyshit congrats man it look sexy",
      "Bottom fans are blowing down not up, flip them for better temps all around.",
      "I saw that some 3070ti FE dropped in the UK on Scan, but as far as I'm aware, none have been officially sold in US/Canada",
      "Linus also talked about it in the WAN show, no ody was able to send him a picture of a FE 3070ti",
      "Got a bent fin. Probably a review sample. These things don't exist in the real world.",
      "Well even in this shot you can tell the fins are a little bent.",
      "You're not an idiot, you just misread the comment - that's what they're suggesting.",
      "Well if you guys keep dropping them then the fins will definitely be bent.",
      "Definitely can, must just be another one of the hundreds or so of review samples.",
      "Am I an idiot?",
      "Was about to say this. He’s robbing the card of intake air",
      "Stabbed a YouTuber",
      "Yup, didn’t see it the first time I looked, but there it is, in the middle. My card has these big fins that make me feel safe, lol",
      "Yes, At least you have a sense of humor though",
      "Yep can also confirm that they were definitely available via Scan. Whether they’ve been shipped is another story but generally I put my faith in Scan as a business.",
      "A bunch dropped in EU/UK earlier this week I believe.",
      "Oh wow, thanks for pointing that out!",
      "I agree. Most set ups are right and bottom sucking in. Left and top blowing out. But again that's most",
      "I might be an idiot, but doesn't hot air rise by itself and you would be helping it by taking in bottom side and blowing out topside? With the side mounted fans going richt to left"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "mid",
    "matched_keywords": [
      "rtx 3070",
      "3070"
    ],
    "title": "[Gamers Nexus] NVIDIA GeForce RTX 3070 Founders Edition Review: Gaming, Thermals, Noise, & Power Benchmarks",
    "selftext": "",
    "comments": [
      "[Interesting, they don't recommend 1080ti owner to upgrade to this.](https://youtu.be/NbZDERlshbQ?t=1925)",
      "Aside from the 30xx series, the 1080 Ti is still, what, the third fastest gaming GPU on the market today? Nestled between the 2070S and the 2080S.",
      "In other words, if you have a 2080Ti, you shouldn't even be looking at the 3070 because it is in no way better. If you are below 2080 Super territory, sure, it will be a pretty good jump.\n\nI recommend we wait to see what AMD has to offer. Things will get pretty heated soon!",
      "If you are playing 4K, the 3080 is the way forward not just for RAM but also for performance, 1440P is where this card is slotted and in that case 8GB will be fine.",
      "It's a tough card to upgrade from. I am more and more inclined to stick with mine for the time being.",
      "It's hilarious that people try to place 3070 at 1440p only, when nvidia has always marketed 1080ti and 2080ti at 4k. They even compare the 3070 directly to the 2080ti.\n\nIdk why people are so adamant about making a previous flagship now being mid range such a big deal. That has always been the case with each generation. It's nothing new. If anything it has gotten worse, because midrange is now $500 instead of $300.",
      "thats what she said...",
      "Seems silly to upgrade from a $700 1080 Ti to a $500 3070. If your financial circumstances have changed, that's one thing, but otherwise, just wait for stock to normalize and get a 3080.",
      "GN is always a little too conservative in his upgrade recommendations.   The jump between the 1080ti and the 2080ti/3070 is good, it just wasn't worth $1200.   For $500, its a different story (IMO)",
      "A card is only able to reliably run games at 4K for the 1-2 years of its production cycle (if even that long). By the time the next series comes out, games are already pushing the old 4K card to its limits, forcing you to drop detail or resolution.\n\nThis is why I still refuse to invest in 4K. We were told the 1080Ti was the last 4K card we'd ever need in 2017. By 2018/2019, it was already struggling with new AAA games. Similarly, 2080Ti performance is already being pushed to its limits (and will only get worse as newer games come out). You can bet the 3080 will be inadequate for 4K gaming by 2022.\n\nI just can't convince myself to invest in the new flagship every 2 years to maintain high fidelity and FPS at 4K.",
      "Looks so much smaller than I thought.",
      "I was weak and grabbed a cheap b-stock 2080 to replace my 1080ti (to at least have RTX available).\n\nJudging by the performance of the 3070, it doesn't look like used GPU prices will be dropping anytime soon :/.",
      "3440x1440 is the sweet spot right now in my opinion.  60% of the pixels of 4K but with all the immersion and high framerates you need.  Heck if I had a LG CX48 I'd probably run it at 3440x1440 with letterbox on demanding games.  4K is fine if you don't mind running 60fps average with dips below, but I really like 100+ fps myself for the smoothness.",
      "It’s foolish to think that a GPU will always be for a specific resolution. \n\nGTX 780 was marketed as a 4K card when it was new, and it wouldn’t keep up with a GTX 1660 these days. \n\nGame workloads are not fixed. Especially with the new generation of consoles.",
      "For 1080p gaming, the 2080 is a very good card.  If you are selling it to him for $200, he would be dumb not to take that deal over this card imo. Now if he plans on upgrading to 1440p or 4k in the near future it could change things although the 2080 is solid in 1440p.",
      "[78% according to Techpowerup](https://tpucdn.com/review/nvidia-geforce-rtx-3070-founders-edition/images/relative-performance_2560-1440.png). Assuming your games aren't CPU bound.",
      "> 8GB seems too little for many 4K games which was elucidated in Hardware Unboxed's video\n\nI think by \"many\" you mean, 1 game, using \"ultra nightmare\" 4k textures.",
      "Wait, when did Hardware Unboxed mislead on the capacitator fiasco? I thought they were reserved and mentioned their TUF also crashed so they said wait on jumping on the capacitor issues blame.\n\nPlus the DOOM Eternal result when using ultra textures that stays around or below 7GB VRAM the results are then the same between 3070 and 2080Ti, but when going above 8GB texture setting there was a difference in performance. I mean is that VRAM buffer or bandwidth?",
      "Both cards are pretty much 1440p cards in 2020, and a 1080 ti is fantastic at 1440p",
      "Allocation is not the same as \"using\"."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "mid",
    "matched_keywords": [
      "rtx 3070",
      "3070",
      "3070 ti",
      "rtx 3070 ti"
    ],
    "title": "[Gamers Nexus] Gaslighting GPU Buyers: NVIDIA RTX 3070 Ti Review & Benchmarks",
    "selftext": "",
    "comments": [
      "A way to legit up the MSRP on the same silicon.\n\nAs OC3D says, the only reason to buy one is you know that at launch time tomorrow, there will be some cards at MSRP, and you have at least a remote chance of getting one.",
      "Rtx 3070 very close to the 3070 ti  yikes",
      "Fewer chips for the 3070. Very nice. I miss the days of 1060 vs 480/580. When both companies tried to create an ultimate budget GPU. Both cards are still amazing today",
      "When did Ti become Halo product? The Titan was the halo product. A Ti for like 5 generation had crazy ridiculous performance gaps.\n\nEven the 2080ti steamrolled the 2080. I'd consider 3090 a halo product, but the 3080ti supposed to a class leading card. Both Ti are really bad cash grabs.\n\nMan... Nvidia just been all kinds of scummy since the mining boom with the 1080ti.\n\nI think two things happened.\n\n3090 was always a fake Titan, but really a 3080ti with professional level of ram\n\n3080 was supposed to be nerf, but AMD scared them.",
      "> GN is becoming a joke. Prices are inflated but value is determined by what else your money can buy. What card new or used can you buy to get more power for less?\n\nI mean, you admit the prices are inflated. I dunno if I'd call GN a joke for calling out price inflation without actual, backing improvements. I am not mad at Nvidia for capitalizing, it is just not a good time to buy graphics cards for consumers generally, and Steve hasn't exactly been shy about saying you should wait if you want better/fair pricing.",
      "Glad to see that Steve is on point about the value perception, unlike the segue man",
      "*eatspopcorn.gif*\n\nI'm glad Steve addressed Linus in this. I was waiting for a retort video lol.",
      "It is physically not possible to implement 16GB on the 3080Ti, since it has a memory bus width of 384-bit, meaning either 12GB or 24GB can be implemented since GDDR6X only comes in 1GB modules. If 16GB were to be implemented the memory bus width would have to shrink to 256-bit, which plummets performance.",
      "For real these benchmarks makes me glad I went with a 3070 when I had the chance instead of waiting for the Ti like I wanted to, 4-10% difference is not worth the wait nor the difference in price. The 3070 should have had G6X memory but Nvidia likes to milk consumers with a pointless upgraded version.",
      "Yeah, that GDDR6X. No wonder that shit gets really hot",
      "3080Ti is ~70% more expensive than the 3080 (MSRP to MSRP) and provides a ~10% performance boost, hence the negative value perception from the gaming community. If you think that's good value then props to you, but that's not how most people feel.",
      "I think you're missing his point about all of this - he is fully aware of how awful the supply situation is and indeed that's the only reason nVidia can even get away with this, because people don't have any other options.",
      "Yeah, same thing with the 3080 Ti. As I said so many times before, nvidia sees how much scarpers are making on  these video cards and they are thinking \"Why is this money not coming to us instead of these scalpers? We can be the  scalpers!\"  \n\n\n3080 should have had more than 10 gb of ram when it launched, and $500 more for not even 16gb is just dumb.",
      "You're not gonna get \"better for cheaper\" within the same year, obviously. Value is derived by comparing performance for price in comparison to what else is on the market.",
      "Get out of here with your \"logic\" and \"reason\". We're gamers; conspiracy theories as to why we don't get exactly what we want at the price we want is way more important than facts!",
      "Just an FYI, laptop GPU's are generally underclocked/limited in some way vs the same model desktop card and tend to have significant lower performance as a result.",
      "The market is too fucked up for budget GPUs right now (in a business PoV). Hopefully when things go back to normal we'll have more options cuz the potential for budget GPUs is there.",
      "Every statement of \"they're overpriced\" is objectively wrong based on simple market demand. \n\nIt would be more accurate if every reviewer instead said, \"I wish this GPU wasn't worth this much money.\"",
      "So, what, are all reviewers supposed to just throw their hands up and say \"This is great, rush out and buy it, because you don't have any choice\"?",
      "Markets frequently make mistakes pricing things because humans are idiots. The card is absolutely overpriced."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "mid",
    "matched_keywords": [
      "rtx 3070",
      "3070"
    ],
    "title": "RTX 3070 - £469 / RTX 3060 Ti - £549 Restocked on Nvidia - what does everyone think? Worth a pickup?",
    "selftext": "",
    "comments": [
      "I'd buy it\n\nA 3070 at MSRP is decent value, and the 40 series will initially sell out at launch as every GPU gen does at the start\n\nAlso who knows the landscape when they actually launch or the price and perfoemance of the 4070\n\nEdit - for anyone who misses the FE 3070, the 70ti is also okay value, it's not the best, but equally compared to AIB cards at retail it's a steal",
      "Wait, why is the 3060Ti more expensive than the 3070, am I missing something here?",
      "Likely they meant 3070Ti.  Typo.",
      "Do the same trick.\n\nBuy this one, sell when the 40XX is affordable.",
      "People in Europe like to see the end price when they buy stuff because the sales tax is already added. Remove 19% sales tax (for germany e.g.) and you will be around the same prices.",
      "This is the same thing I am asking myself. I sold my 2070s for 600 euros now I am in dilemma should I get 3070 or wait for 4000.",
      "These European prices are nuts.",
      "yeah I would also suggest a base 3070, also way more appealing in the used market once a new series is out.",
      "I’m sure people who are looking at buying a 30 series card right now would like to upgrade and if so, why not wait for the new cards which will be better performing for (hopefully) the same price range?",
      "They are similar to US prices when you remove the high VAT/sales tax.",
      "It's not, the 3060 ti is £369.",
      "Because they more than likely will sell out in minutes, and prices are probably gonna be a lil higher, I just read an article that says the price for these new cards will most likely will not be cheaper, so I'd rather just get something now rather than wait and watch all the bots/ scalpers buy everything up in minutes",
      "Still too expensive, 18 months after release.",
      ">A 3070 at MSRP is decent value, and the 40 series will initially sell out at launch as every GPU gen does at the start\n\nI'll never understand why people think this is such a big deal, as if having one of the new GPU's day one is so super important that you should just buy something else instead.",
      "Wait till october or november\n\nSource: trust me bro",
      ">Because they more than likely will sell out in minutes,\n\nAgain, this is exactly what I was talking about.  This weird need to have one of the new GPU's instantly on Day 1.",
      "Nobody “needs” a top of the line gaming rig. If you want people to be more conscious of spending habits the pc gaming community is not the place to be, it’s full of unnecessary spending.",
      "Do it. I'll buy one when I get my payment, so I can retire my GTX 1070 finally. I was also thinking about to buy a 4000 when they come but the chance to get one is probably low",
      "Yesn't, 40xx reveal is just few months away. But Intel and AMD expect the Shortage to last til mids 23, which means that the condition could get worse once 40xx drops, and like 2020/21 you may not be able to get the last-gen GPUs. (let alone next-gen)",
      "Think worst case scenario, RTX 4000 might disappear in an instant, and the cheapest 4070 could be 900 euros.\n\nAlso, I wouldn't go blindly into the 4000 series without any third-party benchmarks. The power draw is going to be so much higher this time around, it may not be worth it..."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "mid",
    "matched_keywords": [
      "rtx 3070",
      "3070",
      "3070 ti",
      "rtx 3070 ti"
    ],
    "title": "NVIDIA GeForce RTX 3070 Ti spotted with 16GB GDDR6 memory - VideoCardz.com",
    "selftext": "",
    "comments": [
      "inb4 3080ti",
      "I bet they will have a 20 gig 3080",
      "Because the 3070 is 256 bit and the 3080 is 320 bit.\n\n3070: 8GB, 16GB etc\n3080: 10GB, 20GB etc",
      "It's quite probable.",
      "Also this is gddr6 and gddr6x and x is probably more expensive",
      "Makes a lot of sense.\n\nThere is no way they would let the 3070 Ti have **60%** more memory than the 3080. That would be crazy!?\n\nPlus then all of the deep learning researchers (me included) would just buy the 3070 Ti and not the 3080 because of the larger VRAM (assuming 3090 is out of budget--which it is, unfortunately).",
      "gotta wait for a 3080ti/super to replace my glorious 1080ti",
      "Why would they put more memory into this than the 3080?",
      "I hate launches like this. Can't nvidia just spell out their plans early so that people can make the decision on which card to get in the generation? It's annoying deciding whether to jump on a 3070 or 3080 not knowing if they will randomly throw out a ti or not.",
      "This is exactly why I'm buying a 3090. To hell with all these later, better releases...\n\n>Videocardz has spotted a 3090ti",
      "Notice how in the spec sheet it says \"Standard memory configuration\" for each of the cards:\n\n[https://www.nvidia.com/en-us/geforce/graphics-cards/30-series/](https://www.nvidia.com/en-us/geforce/graphics-cards/30-series/)\n\nI wonder if that is to leave room for these AIB and OEM double memory variants.",
      "Where the hell do you live in the EU that a 3080 is the price of a 3090.",
      "Wait a sec 60 ghz",
      "hello fellow researcher that's also too poor for the 3090",
      "16GB GDDR6X?  dude. not even chimps have that much VRAM.  Jamie, pull that up, how much VRAM do chimps have?  \n\n30GB?  What?  No wayyyyyyy!  Chimps will tear your face off with that much VRAM",
      "Monitor companies hate him, see how this small redditor is changing the monitor industry with one simple letter.",
      "... what have they done since introducing GeForce...? They always release a Ti variant. Expect it. Be patient.",
      "1080 ti master race",
      "Yup, that's the exact reason why I am leaning towards 3090 instead of 3080. The moment I buy that thing, they will announce a 20GB version and make me deal with all those selling/buying stuff again.\n\nOn top of that, with all the taxes and shipping cost of 3080 and 3080 Super/Ti whatever it is, it might cost the same with a 3090. At least for me residing in EU. Still need benchmarks though.",
      "Yeah lots of leaks have pointed to that.\n\nI also wouldn’t be surprised if we get a “3080 Ti” next year with 22 GB/352-bit memory bus"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "mid",
    "matched_keywords": [
      "rtx 3070",
      "3070",
      "3070 ti",
      "rtx 3070 ti"
    ],
    "title": "RTX 3070 Ti Launchday Thread",
    "selftext": "**Subreddit Protocol**:\n\n* **Launch Day Megathread** will serve as the hub for discussion regarding various launchday madness. [You can also join our Discord server for discussion!](https://discord.gg/nvidia)\n* Topics that should be in Megathread include:\n   * Successful order\n   * Non successful order\n   * Brick & Mortar store experience\n   * Stock Check\n   * EVGA step up discussion\n   * Any questions regarding orders and availability\n   * Any discussion about how you're mad because you didn't get one\n   * **Literally everything about the launch**\n* **ALL other standalone launch day related posts will be removed.**\n* **Subreddit may go on restricted mode for a number of times during the next 24 hours. This may last a few minutes to a few hours depending on the influx of content.**\n\n# Reference Info:\n\n# [RTX 3070 Ti Review Megathread](https://new.reddit.com/r/nvidia/comments/nvxh5s/geforce_rtx_3070_ti_review_megathread/)\n\n# [US Best Buy Information](https://www.pcmag.com/news/best-buy-will-only-sell-nvidias-rtx-3070-ti-online-this-time)\n\n# Remember not to buy from scalpers (fuck em). If you are buying from website that allows 3rd party sellers (e.g. Newegg/Amazon), please make sure you are buying from said retailer. Anything else means you're buying from scalpers. Do not buy from scalpers. Treat the product as out of stock and wait if the official retailers are not selling them.\n\n# This thread will be sorted by NEW for latest information.",
    "comments": [
      "I'm getting really tired of seeing that Best Buy employee's face next to the \"Have Questions? Chat Now\" Box lol... I've started blaming him every time I refresh and still see \"Coming Soon\".",
      "Guys, the release will happen in about 10 minutes. I know this because I am about to leave my computer to get lunch",
      "\"Congratulations NVIDIA on yet another successful graphics card release\", said fucking no one!\n\nScan UK had nothing and there wasn't even a buy button for the Founders on the NVIDIA site. Seriously, this is just beyond a joke now!",
      "not the 3070ti lmao",
      "Alright so I have been on the chat with support over and over again just to see if I can get different answers. \n\nSo far the answers I got are\n\nAfter 11 central\n\nAfter 12 central\n\nNo timeline\n\nAnd the kicker\n\n“As I said you don’t need to worry about stock. We will not run out”\n\nI think this definitely proves Best Buy support has no clue what’s going on lol. Not gunna run out of stock my ass lol.",
      "1. Purchase from Microcenter\n2. Walk Outside, take picture, post to ebay\n3. Profit\n\nFreaking scalpers....\n\n[https://imgur.com/a/DahtANx](https://imgur.com/a/DahtANx)\n\n&#x200B;\n\nebay listing: https://www.ebay.com/itm/384215120641?hash=item5975017b01:g:4FkAAOSwbl9gwhyQ",
      "WTF Best Buy just do it already so I can be disappointed and start my day!",
      "At this point, I am just praying for it to change to “sold out” and put us out of our misery.",
      "im going to drive the price up with some anti scalper burner accounts ad then not pay",
      "So when is Best Buy gonna release a statement about how utter garbage their system was? I haven't seen one single post or comment about somebody getting a founders off BB today.",
      "I'm going to give you a piece of advice for the people calling or chatting with Best Buy agents asking for details.\n\nI worked for a company for 11 years that had Best Buy as a client, we hosted their call and chat centers. Almost none of the chat or phone reps you talk to are actually hired by Best Buy directly. These agents have zero idea what is going on. They are tired of getting asked the same question all day so their supervisor gave them something to say to get people out of chat or off the phones quick.",
      "I'm over it. I got shit to do.   \n\n\nGood luck boys.",
      "Got super lucky and reserved my place in the EVGA queue for the FTW3 at 6:01am. At 10:45am I got the email saying I could buy it, then just completed the order a little bit ago. 5 years to the day after ordering my GTX 1070, it's like it was meant to be.",
      "Nvidia?  More like novidia.... cards",
      "At this point, I've started refreshing the subreddit more than Best Buy...",
      "I asked a goat in front of the gas station what time and he said 2 est!  Everyone get ready!",
      "See you guys in 2045 after the chip shortage is over.",
      "On a positive note. Newegg shuffle winners will know if they won before bestbuy releases theirs.",
      "don't worry folks, my baby just woke up from his nap so i have to step away; Best Buy should be going live in a few minutes.",
      "Well now I can never tell my Wife I dont have time for anything because she will use this instance where I sat in front of a screen for 4 hours clicking refresh doing absolutely nothing. She will hold this against me for years to come....."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "mid",
    "matched_keywords": [
      "rtx 3070",
      "3070"
    ],
    "title": "GeForce RTX 3070 Availability Update",
    "selftext": "",
    "comments": [
      "Hopefully they actually make it into gamers hands...\n\nAlso pls ramp up them 3080s while you're at it lmao",
      "Ramp up 3080s and 90s first since those cards \"launched\" already.",
      "Hahahaha all this is going to do is make it so it sells out in 2 seconds instead of 1.",
      "yeah, either Nvidia is on a winner with the 3070 or possibly a price drop?",
      "> GeForce RTX 2080 Ti (which sold for twice the price)\n\nlol yeah not like they hiked up the prices themselves and now come back to reasonable prices. pat on the back lol",
      "2 seconds is generous. There will be functionally no difference between the 29th and 15th. The card will still sell out instantly. This is almost certainly primarily to screw with AMD's announcement and hype.",
      "I mean were probably not getting anything other then AMD benchmarks at the reveal event which mean very little. Same as Nvidia's at their reveal event. We won't know the real performance of RDNA2 untill it actually comes out in November.\n\nIts probably a move to steel some hype that will come after those announcements.",
      "Refreshing for a 3080 every min I have available since launch in Italy and have yet to even just see it as available once.",
      "they can't produce enough cards to match the demand and people argue they will lower the prices?",
      "I have heard people call it a budget card. People have totally lost perspective on what is reasonable to pay for a graphics card, Nvidia played us like a damn fiddle.",
      "Not many people who's looking for a $499 card will be willing to spend $200 more for a $699 card. \n\nThat's a 40% more money.",
      "As true as that may be, it is nice to actually feel like you are getting your money’s worth this time. But in no way would I call a 500$ card cheap... it is still a premium product not a midrange product.",
      "I think you're underestimating the power of impatience. Theres plenty of posts on this reddit of people looking for 3080s and getting a 3090 instead because they found one available and didnt want to wait - and thats over double the cost of a 3080 :/",
      "I'm happy that Nvidia is listening to some critiques, and attempting to mitigate the fiasco that was the 3080/3090 launch.  Having said that, unless Nvidia offers substantive bot protection, 3070 customers won't be spared from the 3080/3090 launch experience.",
      "All the 3070 kids will now be officially on the hunt for the 3080 knowing they have to wait a month. Awesome.\n\nJust wish I could of pre ordered a product to plan a build vs competing to find a needed part of a build.",
      "And to screw with people that have already been waiting patiently for the 3070 release",
      "So they pushed the release date to ensure better supply (That's good!) but will the review NDA's stay the same? if the review date is pushed we know AMD has something worth at least looking at.",
      "I wonder if the review embargo will be postponed too, to try to steal hype from AMD.",
      "I wonder if AMD will give digital foundry a card with the same restrictions as Nvidia gave them with the 3080. Kind of independent, kind of restricted analysis that gave a pretty fair impression of performance before 3rd party reviews. Probably AMDs best shot of reducing ampere hype.",
      "There is a huge difference between someone already willing to pull 700-800$ for a gpu and someone aiming at 500$. As strange as it may sound, the first group is much more likely to go for a much more expensive option than the second group, even if the difference in price is much bigger for the first group."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "mid",
    "matched_keywords": [
      "rtx 3070",
      "3070"
    ],
    "title": "D4RKHOLD is finally complete with the RTX 3070 HoloBlack",
    "selftext": "",
    "comments": [
      "Clean af",
      "Big tron vibes",
      "Yep, that looks good.",
      "Nice work",
      "Beautiful build and awesome color scheme my friend.  \n\nIt looks similar to mine.  I'm also on a Strix Z490-E - same RGB Fan Config + CableMods RGB strips shining in.  Lian-Li Lancool II Mesh and Trident Z NEO RGB RAM though.\n\nI have mine set to a darker breathing Navy Blue.  If I set my RGB to that blue, I'd double-take your thumbnails like it was mine haha.\n\nAnd yo, that Zotac is a seriously good looking card.  Like...damn. First time I've seen it lit up in a Rig.",
      "My first choice was actually EVGA but then again these days you would be lucky if you get away with any GPU. Anyways it's a good card so far.",
      "I paid a small fortune for this card in local store but I'm fed up with having a good PC like fancy piece of metal without GPU",
      "On the subject of giving your pc a cringe gamer name: don’t",
      "NZXT AER2",
      "The RG**B** on it is probably my favourite implementation on any card",
      "Chill guys please the name is just for fun. It’s not like I’m going to call it by name it’s just a PC",
      "This has a very Tron Legacy type of feel. Awesome look!",
      "Not many posts about that card online that I was surprised how beautiful it is when I got it out of the box in installed it",
      "I second this notion. I mean, do you actually tell this to other people in person, like: „And now behold - D A R K H O O O O L D ! ! !“. Have you considered calling it „Darky McDarkface“ instead?\n\nNo, just kidding, it’s yours so do with it as you please. Also, it looks absolutely sick and you did a great job building it. Or should I say… FORGING DARKHOLD!!! Wait a moment, maybe add an Umlaut: DARKHÖLD!!!! Yes!!! \n\nDamn it is so stupid that I gotta find a cool cringe name for my rig now. „Guys, wait, let me boot up… DOOMSLAYER real quick.“ - „Hm, let me google that in NIFELHEIMSDOTTIR.“ - „Currently, DARKSWORD OF DOOM gives me 144 fps in that game.“ - „Sorry, I don’t habe time, I need to patch CYBER MJÖLNIR.“ - „This Excel-spreadsheet was created on DEMONSLAYER TURBOSATAN 666.“",
      "Yeah, it just seems a waste to not go for 1440p/144 Hz though. You've got enough power for it.",
      "Crispy.",
      "clean build! which fans are those?",
      "Clean af man",
      "What's the RGB numbers for this color? I really like the tron style coloring but mine always ends up having to much blue",
      "Gorgeous"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "mid",
    "matched_keywords": [
      "rtx 3070",
      "3070"
    ],
    "title": "RTX 3070 FE Build",
    "selftext": "",
    "comments": [
      "Props on arranging the gpu cable in such away. I honestly Ike it, different yet pleasing.",
      "where is the GPU.. oh nvm",
      "Specifications :\n\nCase : Lian Li Dynamic EVO Black. \n\nProcessor : Intel i7 12700k.\n\nMotherboard : ASUS TUF GAMING Z690 PlUS WIFI D4. \n\nCooler : Lian Li Galahad SL Edition 360mm Black.\n\nRAM : Crucial Ballistix RGB 32GB CL16 3600Mhz.\n\nGPU : Nvidia RTX 3070 FE.\n\nSSD : Gigabyte Aorus Gen4 7000s 1TB.\n\nHDD : Seagate Barracuda 2TB @ 7200rpm.\n\nPSU : Corsair RM1000x Black.\n\nCase Fans : Lian Li ST120 3 Pack (I used those with AIO) , Arctic P12 Slim PWM PST (4 of these).\n\nWires : Corsair Premium Individually Sleeved PSU Cables Type 4 Gen 4 (Black).\n\nAccessories : Lian Li Upright GPU Kit with PCIe Gen 4 Riser Cable , Front Mesh Panel Kit (Yet to use this kit).",
      "Great job, I’ve seen YouTube streams trying to do this setup and it always looks like crap. Really looks great from what I’ve seen 👏🏼👏🏼",
      "Thank You.. I did the best i could :)",
      "The Rizer Cable arranged like this looks really cool, good job!",
      "Lol",
      "Thank You that means a lot!! This is actually my first build and it took me 4 days to try every possible idea to make it look tidy. My finger tips swelled up by the time i finished it. :)",
      "Looks like a bowtie, I love it!",
      "Hey bro you have genuine question and you're not retarded lol. The display cable runs from behind the right side of radiator (not visible in pic) towards back chamber of case and from there it runs in left direction all the way to the rear end of the case exiting from there.\n\nImagine cable running like  -----,  \n\ni hope this cleared your doubt and if not then just google Lian Li Upright GPU Kit installation. :)",
      "Awesome looking build. Congrats!",
      "Thank You!! :)",
      "Ah so thankfully those fans behind it are blasting air away from it and there is more fan options for the case should it need more intake. Had a feeling it would be fine. I Would imagine it wouldn’t be smart to just treat it as an intake or exhaust fan on its own.",
      "Hey, I think I’ve seen this before! \n\nclean build btw",
      "At first I had no idea where the GPU was.",
      "What’s the massive power supply for?",
      "Thank You!! :)",
      "I'm glad you found GPU in a minute. Most people are waiting for GPUs longer than a year ;) lol",
      "John Cena edition 👋👋lol",
      "Oh no no.. i was kidding with you just for a laugh.. dont be sorry i understood what you meant very well :)"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "mid",
    "matched_keywords": [
      "rtx 3070",
      "3070",
      "3070 ti",
      "rtx 3070 ti"
    ],
    "title": "NVIDIA GeForce RTX 3090 Ti to launch on January 27th, RTX 3070 Ti on January 11th - VideoCardz.com",
    "selftext": "",
    "comments": [
      "Why even announce it? No one is ever gonna get one for MSRP lol",
      "im confused isnt the rtx 3070 ti already a thing?",
      "I guess they are announcing it for the miners and scalpers, their main target for the past (almost) two years",
      "This one has double the VRAM. I just bought an 8GB :(",
      "Wow, another card I will not find!",
      "Oh my god how many skus is that at this point?",
      "799$/999$/1999$ so Jensen will use them as direct price counterparts comparison when he announces the 4000 Series.",
      "Well they want to use every die they have basically with this shortage, so it makes sense to make more SKUs. Something like a 3070 Ti could have been a regular 3070, but if you have more potential, why not give it to customers, rather than lock it away?",
      "> Something like a 3070 Ti could have been a regular 3070, but if you have more potential, why not give it to customers, rather than lock it away?\n\nMore like why sell it for 3070 prices when they can charge an extra $100+",
      "Miners started it with their fucking high ass demand for gpu’s",
      "Cool...still trying to find an RTX 3070 over a year later to replace my GTX 970. These announcements from NVIDIA about new cards is just insulting at this point and makes me hate the company.",
      "Still gon' drop a notify signup on evga lol",
      "Only 256 more cores? This will be slowest most pathetic Ti model ever. 3080ti was already a joke excrpt for the ram",
      "All these announcements have a distinct feel from the general public of callous indifference, nearing on the snarky \"who cares?\" not because those people are uninterested, but because individuals are unable to engage with this form of technology in any meaningful way, regardless of desire.\n\nIt causes the consideration of enjoying the newest tech only the province of the time rich, money rich, or tech obsessed. That was always pretty-much the case, but now it seems like new tech isn't even an option for the wealthy or the obsessed. And then after a few years and even the newest tech isn't available in any meaningful way for a casual consumer like myself.\n\nSomething tells me if this doesn't shift, the whole industry is going to have to shift away from \"SUPER UBER GRAPHICS/Lighting/Shading\" to more optimized and consumer (\"do not use uber-hardware for our game it is a waste\") friendly. Feels like companies are able to optimize their games but they want to be able to \"push the new technology\" and so they consider older tech as obsolete and therefore not functional.\n\nedit - jeez, for the person who downvoted me,  I would be interested to hear the reason. I made this comment out interest for technology and the way that the market has shifted over the past 5-10 years.",
      "Well they're also going to sell the 3050 Ti as a GA106 die with 3072 CUDA Cores which is around two GPC's in total, this is the same die that they use for the 3060 and 3060 LHR, except those dies have more GPC's available to use because they're not as cut down. Whereas the RTX 3050 is going to be GA107, with around 1.5 GPC's, so 2304 CUDA Cores. \n\nIf your theory is right, they wouldn't bother to sell a lower level part with a better die, they could easily sell a full GA107 die as the 3050 Ti with the full two GPC's, like they're going to do with the 3090 Ti and it's full 7 GPC's. Even something as simple as the 3060 Ti could have been a full GA106 die with 3 GPC's, with 4608 CUDA Cores, that's not a crazy difference compared to the 4864 CUDA Cores it currently ships with, but obviously the supply is much better with GA104 for 3060 Ti.\n\nSo in summary, the yields are just better to cut down a larger die like GA104 or GA106 compared to full GA107 die performance and thus your whole argument of selling a larger die for an extra price falls apart. I can tell you now, there's going to be a lot of potential 3060's that are now going to be 3050 Ti's just to meet demand from customers who are looking for a smaller GPU, not to mention that it should be cheaper due to lower VRAM even if the die's the same, we're talking 8GB vs 12GB.",
      "even if i can buy it at MSRP. this is completely dumb imo. this is literally like the 2080 super and the next year the 3080 came out lol.  waiting for the 4090 at this point.",
      "That's the thing, 3090 was already so close to the full die there isn't much else to enable",
      "Your comment and attitude is part of the current problem",
      "Will be interesting to see the msrps of these gpus.",
      "So why are you wasting queue spots on GPUs you don’t want?! Who does that?"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "mid",
    "matched_keywords": [
      "rtx 3070",
      "3070",
      "3070 ti",
      "rtx 3070 ti",
      "rtx 3070ti",
      "3070ti"
    ],
    "title": "Should I upgrade from RTX 3070 Ti to 4070 Super?",
    "selftext": "Hi everyone!  \n\n\nI currently am using MSI RTX 3070Ti Gaming X with 1440p @ 144hz. Should I upgrade it to 4070 Super?  \n\n\nThe things that caught my attention:  \n\n\n\\- Lower Power Consumption  \n\\- 4GB extra VRAM (although I wish it was 16GB)  \n\\- Smaller Design  \n\\- DLSS FG  \n\\- Overall better performance? How much % on average  \n\n\nPlease let me know what you guys think.",
    "comments": [
      "3070ti 1440 180hz here. Make sure to try the AMD frame generation mod first. It's easy and works really well. Allows you to turn on FG in games as though you have a 40xx card.\n\nIt's called dlssg-to-fsr3.",
      "It’s not worth it, wait until the 5000 series come",
      "Hmmm, i don't think its worth it.  \n\n\nBut if you want upgrade so bad then wait for the other Super cards, especially 4070 Ti-S, would be a nice value and regular one probably will drop the price.",
      "No, what the fuck. Don't go pissing money away to these companies by upgrading so frequently. Let your high end PC hardware last 5+ years.",
      "First I’m hearing this.. thanks!",
      "No. 3070 Ti will keep up with modern games for years.",
      "1. Can OP afford it and future upgrades whenever they want? If so, sure.\n2. If OP is the kind of person to hold and use a GPU for 4 years each time, no. Always skip the next generation, and wait until the post generation's prices have gone down.",
      "I don’t think so. It’s pretty much on par with a 3090. 4070 Tisuper a much smarter option with 16gig and will be basically a slightly cutdown 4080",
      "for 12% performance increase? not worth it imo. If you are coming from a 2xxx, it might be",
      "It's not worth it for the tiny increase, wait for the Next Generation! 👍🏻",
      "I second this, the 5070 or 5060 are about a year away, and the 3070ti should be more than enough for games now on 1440p until you can get one of those. Unless you have something that specifically isn't playing like you want, I don't see the need for an upgrade now.",
      "no, usually triggers anti-cheat.  thats kind of the only reason to consider moving to a 40xx.  i use it on cyberpunk and now get like 130+ fps on high/ultra settings with RT.... its awesome.  lag isnt an issue.  really makes the decision to upgrade from my 3070 to a 40xx hard now",
      "You really shouldn't treat FG as real FPS. It's a \"boost\" that works if you have a lot (60+) of frames already. If you have 30-40 it works but you begin to question if using it is better or worse than native. Below that value it's pointless and won't make unplayable games playable.",
      "I've been considering buying a 4070 super (coming from a 3070) since I play on 3440x1440. Gonna definitely check this out.",
      "TL;DR summary:\n\n* Only for Nvidia RTX cards (20\\* and 30\\*) and games that support frame gen - use **dlssg-to-fsr3**.\n* For any cards and for some games that don't even support frame gen - use **LukeFZ FSR2FSR3** mod (paid, but leaked online). This mod did wonders to Ready Or Not game - doubled FPS on my RTX 2080Ti without noticeable input latency.",
      "Agreed, i went from 2080 TI that just now bricked and got the 4070 super. Had my 2080 TI not gone and unalived itself, I would have continued using it till the 5000 series released.",
      "Look up optimized settings for hogwards. It should end up looking exactly like ultra but running much better.\n\nAgree that 8gb is a limit but try optimizing FC6 settings too. reducing shadow maps can claw back vram. turning that games mediocre RT off can as well, without visual impact.",
      "Search nukem dlss fg on google. Download the mod from nexus. Copy paste some files in game folder. Run the reg to disable nvidia checks. If you have 60fps in cyberpunk it will easily reach 100-110 fps.",
      "Went from 3080 to 4070ti. Most would say stupid nonsense. BUT way less noisy because it’s so much more efficient and draws less power so easier to cool. Can use NVIDIA DLSS 3 frame generation .. etc",
      "no. either 4080S or 5000 series."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "mid",
    "matched_keywords": [
      "rtx 3070",
      "3070"
    ],
    "title": "Upgrading from RTX 3070 to RTX 4080 Super for $900 worth it?",
    "selftext": "I’m planning on upgrading my RTX 3070 to an RTX 4080 Super.\n\nYou think is worth the upgrade or should I wait until RTX 50 & RX 8000 series are launched? I’m currently playing @1080p 240Hz. I play AAA games, indies, competitive games and also some RPGs. I have a Ryzen 7 5800x and 32GB DDR4\n\nEdit: Thank you all for the comments :) at the end I will wait until 50 series and RX 8000 series launch and then I will decide. In the meantime, I will upgrade to a 4k 144hz monitor or a 1440p 240hz monitor. Also will upgrade my CPU to a 7800x 3D to avoid the possibility of bottleneck ",
    "comments": [
      "if you're not considering 1440P then no.",
      "Kind of a waste to use a 4080 for 1080p gaming",
      "Id wait for rtx 5xxx if i was in your shoes but thats just my opinion. I wait atleast a gen before upgrading. What cpu are you running also cus that will matter even if going 1440p.",
      "If you’re playing at 1440p, then yes 100%. Just jumped from a 3070 EVGA XC3 to a 4080 Super Founder’s Edition.",
      "Yup, I’m considering 1440p, maybe this week I will get one",
      "Upgrade your monitor to a 27\" 1440p one and get a 4070Ti Super.",
      "3070 should already in games where these FPS matters.",
      "I have a 4080 super and plays all the games I play at 4k max settings. 4080 is fine for 4k. Don't listen to people who say its not. It simply isn't true. CoDMW3 at max settings with DLAA runs at my C2s max refresh of 120fps. That pretty much seals the deal for me. It really depends on what games you play.",
      "You should upgrade your monitor. I doubt the 4080 super would disappoint you if you could get the most out of it but not knowing what your CPU is and knowing that you're just on 1080p you might not notice a difference at all in some games.",
      "There were a bunch of people saying you NEED a 4090 for 4k...😭",
      "4080 is a 4K GPU\n\nWell at least when it costs 1500€ it should be 4K",
      "I went from an RTX 3070 to an RTX 4080 (original launch) and that was a pretty mindblowing difference in performance on a 1440p 180hz monitor. I could actually saturate all that framerate headroom way more often without having to reduce settings very much or at all, depending on the game. If you are okay spending the money for the horsepower, it should feel like a substantial jump to most people. Also -anecdotally- framegen feels like black magic.",
      "Not for that resolution. You should really consider investing in 1440p 240hz.",
      "If staying at 1080p or maybe moving to 1440: no.\n\nIf moving to 4K: yes.",
      "Not a bad suggestion either.  The 70tiS and the 80S are nearly identical.  The only differences are the 80's have 1800ish more Cuda cores and some of the 70's are actually clocked faster",
      "Who said it wasn’t good at 4K?",
      "No it's not?",
      "I have a friend and he has a Evga 3080 10gb with an i7 5820k, and a 60hz 1080p monitor.",
      "I have a Ryzen 7 5800x, and yea, that’s a good idea tho",
      "Yeah, the point was that for the same budget OP would have both a better monitor and a faster card (one that is still fast for the 1440p resolution)."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "mid",
    "matched_keywords": [
      "rtx 3070",
      "3070"
    ],
    "title": "Small beginner's undervolting guide for rtx 3070 FE",
    "selftext": "I managed to get the 3070 FE, and I have to say that coming from a 1070 (gainward phoenix), the noise/temps are really quite disappointing considering all the reviews, which mostly praised the low noise. It has 0 fan mode for idle, when not idle it spins at 30% minimum which is 1000 rpm, which is very quiet.\nAfter that, it starts to be noticeable at 1200 rpm, and by 1600 it's very audible. \nConsidering it will go to around 1800rpm in games at unlocked framerates, one needs to do something if a quiet PC is the goal, and this is where undervolting comes to the rescue.\n\n&nbsp;\n\nCurrently, modifying the fan curve in afterburner seems to result in loss of 0 fan mode, which I hope is a bug that will be fixed (edit: afterburner 4.6.3 beta2 solved this issue, so use that or a newer version, EDIT2: actually, the issue is solved because the custom fan curve isn't taken in consideration, in this version you are just stuck at default no matter what).\n\nIs is pretty much like the 3080 guides, but I find most of them, at least the written ones, not that clear.\n\n&nbsp;\n\nThis is meant as a complete beginner's guide, so please point out if something wasn't properly explained. Also use the images included at the end to get an idea where everything is in the interface.\n\n&nbsp;\n\nSo one needs MSI Afterburner, in the pictures I have I used the skin called 'a touch of modern', which you can select in settings.\n\n&nbsp;\n\n - First press Press Ctrl+F and see the default frequency/voltage curve. This curve should probably look like mine (for the FE at least), but some say that it will shift up and down depending on temperature (I have not seen this, no matter what I did, maybe something changed in newer afterbuner). You should do this at idle just to be sure. Link to my defaults: https://imgur.com/arN3zk6\n\n&nbsp;\n\n - Then in the main afterburner window drag the core clocks to minus 200mhz, and press apply (the 'tick' on the down-left corner), and the whole curve will shift down. The actual value you need to put here is to make the top right of the graph go under 1800 mhz (by a little), in case your graph doesn't match mine. So in my case it was -200 (because my uppermost part went to 2000 mhz). 1800 is about the sweet spot to lose very little performance . Image that shows where is what: https://imgur.com/Of1jLlJ\n\n(much later EDIT: at least 1800 is the sweet spot on my card, now after looking at more people's results, I would say a better way is to go by voltage, and try to squeeze as much as possible from 850mV, most people get from 1800 to 1900 mhz at that value))\n\n&nbsp;\n\n - Now put memory +1000 in main interface and press apply. In techpowerup's reviews, all the various 3070 versions they had could go at least +1000, so it should be a safe value but at the limit, so keep in mind that it may need lowering if you just can't achieve stability in the later steps. This is an optional step if you want to gain a little bit of performance back, but if you don't like the idea of overclocking, just leave it at 0.\n\n&nbsp;\n\n- In the voltage/frequency window (the one that opens with ctrl+f), click the little dot that corresponds to 850mV, and drag it up to 1800 mhz (you can also use the up/down keys on the keyboard to fine tune) (https://imgur.com/2AtjXh2). Press apply. That's it, you can close the freq/voltage window and minimize afterburner (this is how mine looks after apply: https://imgur.com/7EHOMUY).\n\n&nbsp;\n\nTest stability using time spy demo (not benchmark), which I find to be quite sensitive to instability (it will just stop prematurely if there are problems). A loop of 10+ minutes of unigine heaven or supeposition is also pretty good at this. For me, the most sensitive ultimate test I found was metro exodus, maxed with raytracing at ultra, and playing for about 10 minutes (raytracing enabled will put more stress on the gpu).\n\n&nbsp;\n\nThese values have been stable for me, but maybe you can squeeze more, (850mV to 1900mhz for example), or maybe less, depends on how lucky you were with the card. Based on numbers from reviews, mine seems worse than all of theirs, so do try more aggressive values.\n\n&nbsp;\n\nSo with these settings I got 13400 in time spy graphics score, instead of 13500 on default, so almost a match (the average clocks in default were fluctuating around 1880, now it's locked 1800 but higher memory clocks). Power in time spy went from 220w to 170-180w, so a decent amount lower, and temps about 7-8 C lower, which made the fans spin much lower, 1400rpm at most instead of 1800 (very big difference in noise).\n\n&nbsp;\n\nOne can be even more efficient going lower, losing more performance. One good value is 1700 mhz. Reduce clocks to -100 more than what you used before (for me -300 instead of -200). Drag the 800mV to 1700 mhz, hit apply. And test around those values for stability. This will give around 150w max at about 12800 score in time spy, so same power as a gtx1070 from 4 years ago, but 2x the framerates.\n\n&nbsp;\n\nSome more tips on afterburner:\n\n- you can save the settings to up to 5 presets, on the right of the interface, so you can make a higher and lower power presets to switch to.\n\n- if you messed up the curve or whatever, reset everything to default pressing the little icon above the apply button (core clocks and memory will also be reset, so don't forget about them).\n\n- the curve to the right of the point you drag up and hit apply needs to be completely straight. If it's not, you needed to lower the core clocks more in the beginning, reset and redo.\n\n&nbsp;",
    "comments": [
      "Just wanted to join in for anyone like me finding this thread after finally getting my hands on a 3070 FE.\n\nI settled at .85v 1830Mhz with a max GPU temp of 68C.\nCould have gone for a more aggressive .9v 1920 Mhz at 72C but the performance gains (at least in Time Spy) weren't worth it imo.\n\nDefinitely not the best silicon in this thread but I'm just happy to be here :)\n\nEDIT: Also thanks to OP for still answering questions in this thread 2 months later. People like you really keep this community thriving.",
      "Thanks will try this when ever getting my 3080",
      "I would suggest moving to Port Royal rather than TimeSpy - RT cores tend to be more picky with their voltages, so stability tests outside of Port Royal or Control (+RTX) may give a false positive, and more voltage may be required.",
      "bit of an update here, 1845mhz was not stable in Heaven on extreme settings.. would crash eventually.. but 1830mhz/1000 at 850mv is fully stable, after many loops of Heaven on extreme, which i recommend using as a stability test. Unigine super position ran the card fine at 1845 mhz and worked fine in games..  but crashes on the first loop of Heaven, run atleast 5 loops on heaven extreme before coming here and claiming you achieved such clocks because they might not be completely stable in very demanding loads on the gpu.",
      "im at 2025MHz, 0.975V, Temps are never above 68°\nStock it was boosting to 1980Mhz at 1.125V and Temps were at 73-75°. \n\nFps stayed basically the same in Unigine / all games i tested.\n\nNow its almost silent, while stock it was really loud. \n\nAre those good values? First time doing this because the loud fannoise was driving me crazy.\n\nbtw. i have a inno3d iChill X3",
      "\\-160 / 0.925/1965 consumes 190w, and I got 250 more points than stock setting at time spy.\n\nasus 3070 dual oc",
      "My pleasure.\n\nFor the 3080, the curve will be different, but the sweet spot of fps/watt is still around 1800mhz from what others have been saying. There is an explanation in there on what to do if the default curve isn't like mine, so the guide is still applicable to all 3070 and 3080 models.",
      "Did you download the newest afterburner beta 4.6.3? I think it should fix the fan curve problem",
      "Ok, this is amazing. I have an EVGA 3070 XC3 Ultra gaming.\nWith your guide I managed 1850 mHz @ 0.85V with Memory at +1000. \nTime spy score increased from 13668 to 13763.\nTemperature decreased from 70C to 61C. \nFan speed decreased from 1800 rpm to 1500 rpm.\nPower draw went down to 150 watts. \n\nIts stable in Cyberpunk on max settings with RT on ultra.\n\nThank you so much!",
      "That is a very good result.",
      "In theory it sounds great and I have tested this extensively since it makes sense. \n\nThe problem is the power cap doesn't put a cap to the clocks, and in certain scenarios, where the card requires less power per clock, the card will boost higher and reach unstable freq\\voltage points (or those clocks will just not be as high to maintain stability). In other words, you can have a bit better fps for your power with capping.\n\nLet's say for my card I have +200 mhz at 1800 and it's capped there, which gives me 80% max power in the worst spot of time spy. If I put the whole curve at +200, and cap the power to 80, I will reach instability in certain scenarios, because the points to the right of 1800 can't do +200 (and they will get there in somewhat lighter situations, like the beginning of time spy). So the performance in most intensive moments, when I really need it, will be lower at the same power. So the capping is really about fine tuning one point, if that point keeps moving, you cannot fine tune it as well anymore.",
      "Man, thankyou.. using an Asus dual 3070 I was having issues with temps chugging along at 80-82c while playing games, ive followed this guide was able to get 1845mhz at 850mv, any higher it crashes.. im using +1050 on the memory and it actually scores 100 points higher in unigine super position (1080p extreme) than at defaults, and runs 10+c cooler ! wow.. didnt exceed 67c after playing cod for hours and performs exactly the same, this is magic honestly thankyou very much, my pc now does not blow stupid amounts of hot air into my room while gaming, i appreciate this.. I was very dissapointed in the thermals of this card and now im absolutely loving it.",
      "Thank you so much, my 3070 FE was hitting 80 degrees and sounded like a jet engine even at 55% fan speed. Now it's barely hitting 68 degrees and the I've set the fans to stay at 40% from 55 degrees to 75 degrees. It's basically silent, also I was able to push mine to 1900mhz at 850mv without any issues.",
      "thank a bunch man. Starting from your guide, my 3080 Vision OC, ended up with 0.875/1900mhz, almost the same time spy score vs stock at around -150w!",
      "hi thanks for the guide, i undervolt my 3070 MSI Ventus 3x, i got the card stable at 1845mhz@0.819V. Watt down from max 220W to max 165W, card temperature down from max 68c to max 61c. GPU fan max 1000RPM, so basically silent.\n\nand all that just with 3 FPS drop on Microsoft Flight Simulator.\n\nlove this!",
      "I'm new to undervolting so maybe I missing something here so I hope someone can help me understand.\n\nAs I understand it the point of undervolting is to reduce temps to get as much core clocks for the least voltage possible right?\n\nSo I get the whole idea of capping the higher clocks and testing how low of a voltage we can get them to run at. That makes sense.\n\nWhat confuses me it the first thing you did when you reduce the core clocks of every node down 200 mhz [https://imgur.com/Of1jLlJ](https://imgur.com/Of1jLlJ). Aren't you now basically telling the GPU to load the low clocks at a higher voltage than they were before, which is the opposite of what we want, no?\n\nFor example if I zoom in [https://imgur.com/a/N8gUgtr](https://imgur.com/a/N8gUgtr) the GPU originally had it set to pushing 1400 clocks at 775 mV (the green x) but shifting everything down now has it pushing only 1200 clocks at 775 mV (the red x).\n\nFollowing this pattern all the lower node points have more volts going into less clocks.\n\nMaybe I'm completely wrong here but could someone clarify why we need to do this?",
      "Just did this to my 3070 Ultra i got today.\n\n1815 MHz @ 850 mV and +1000 memory OC\n\nSuperposition default was 8756\n\nUnderclock/volt was 8531\n\nWent from ~240W down to about ~170-180W\n\nPretty good drop in power with little performance impact.",
      "Thanks for this guide man! Ive successful got an undervolt at 0.925, clock of 1995mhz and memclock of +1000 - ive not done a full suite of testing but a couple of time spy runs done and no issues, gpu score was 14450!\n\nHit max temp of 70°c while being fairly quiet!",
      "upped to 1920mhz with same voltage, still stable in timespy",
      "This is just the fast way of doing it to bring the curve down. Yes, you are right, a part of the curve will be overvolted actually (not sure until what point, the middle idle clocks at 1000 mhz, or idle at 210 mhz have the same value no matter what). But it doesn't matter, since the card doesn't really stay at any of those clocks it goes straight to the upper few.\n\nThe more correct way would be to move the clock slider to around +200 (in this case with 1800mhz at 850mV), press apply, than drag each of the points at the right of it under 1800 and press apply, and it will automatically make a flat line, since it can't have the curve going down. It's just more tedious, because those tiny points are a pain."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "mid",
    "matched_keywords": [
      "rtx 3070",
      "3070"
    ],
    "title": "The MSI RTX 3070 Gaming X Trio’s come with a really cool comic style instruction booklet!",
    "selftext": "",
    "comments": [
      "Where's the panel where the little dragon scalps the card?",
      "So did my 3080.\n\nTo bad msi dragon center sucks ass. Ruins the dragons name.",
      "That's like not supporting Walmart because you saw an employee steal a few items.",
      "[Much better than their old instructions](https://www.youtube.com/watch?v=V48KJEP1-sE)",
      "The MSI products always come with these little booklets. It's a nice touch. The mobo I bought from them had a similar booklet, and the laptop I bought back in 2016 came with a laptop backpack, a plush, and some stickers. \n\nOverall, they have decent little knick knacks. I still use the backpack to this day, even after my dog got ahold of it.",
      "Agreed, it's the #1 thing that makes me regret buying the 3080 Gaming X Trio on release day, and then I realize you STILL can't get these things.",
      "All I care about is Mystic Light. Just give me that MSI.",
      "Should have been the dragon in a bikini, very disappointing.",
      "So if you saw a bad employee swearing and stuff at 1 McDonalds you are telling me the entirety of McDonald's and all their chains are now bad???",
      "Yeah i was surprised by this booklet too. Bought the exact same gpu.",
      "*Shit! I hope my Swiss Army knife has a Phillips head screwdriver.......*\n\nOh wait I can’t find a 3080.",
      "What the actual fuck",
      "It’s the *no horny month* so go to horny jail..",
      "[https://download.msi.com/archive/mnu\\_exe/vga/Installation-Guide-NV.pdf](https://download.msi.com/archive/mnu_exe/vga/Installation-Guide-NV.pdf)  \n\n\nEnjoy guys :D",
      "I got a similar booklet when I purchased the 2080 Gaming Trio",
      "I have a MSI Z390 motherboard.\n\nDragon Centre sucks ass so bad, I downloaded [Mystic Light 3](https://www.msi.com/Landing/mystic-light-rgb-gaming-pc/download). It's not officially supported but it works.",
      "This is a cute way to make instructions less daunting.",
      "1. Install Dragon Centre\n2. Go in to Dragon Centre and disable everything apart from Mystic Light\n3. Close Dragon Centre completely and from the system tray\n4. Go in to task manager and find the processes named \"MSI Central Service\" and \"MSI. CentralServer\" and end the tasks\n5. Navigate to \"C:\\program files (x86) \\msi\\one dragon centre\"\nIn here you will find many small folders that contain each \"module\" the program has. Here we can start uninstalling them.\nIf you look through most of the folders you will find some with a program called \"unins000.exe\"\n\nGo through each folder that has this in and run the uninstall executable for each folder. MAKE SURE TO LEAVE the folders \"Mystic_light\" and \"Base Module\" alone!!\n\nRestart your PC.\n\nEnjoy your new dragon centre without all the crap and have only Mystic Light\n\nI credit another Redditor for this information but I don't have his username to hand to give him the credit",
      "Got my DC working. Only had to friggin reinstall windows to get the card to be detected in the thing! Unacceptable!",
      "Anybody else remember the great “Fuck MSI, Boycott!” disaster of October 2020 that occurred just a few weeks ago?\n\nMan, people forget real fast don’t they?"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "mid",
    "matched_keywords": [
      "rtx 3070",
      "3070"
    ],
    "title": "Rumor: NVIDIA GeForce RTX 3070 and 3080 Coming Q3 2020 + Specs",
    "selftext": "",
    "comments": [
      "Going to be a long wait for the 3080 ti 😞",
      "Man if that 3080 Ti is real, I'm so in. Price is going to be absurd but that will likely be at least a full 100% performance increase between shader count and architecture improvements over a 2080 Ti. Quadruple the RT cores as well and double the tensors, so RT performance would be dramatically better.\n\nSo I absolutely do not believe that's happening, but a man can dream.",
      "It's going to be a nice upgrade for us on our 1080ti's still though.\n\nGot mine april of 2017 and I'm ready for more frames as games are hitting pretty hard at 1440p ultra.\n\nHad to turn down some stuff just to get RDR2 to do around 70 fps. I'm still too used to doing 100+ and this is too soon for nearing 60!",
      ">The most interesting part is obviously the specs, where a 3070 could be  close in performance to an RTX 2080 Ti. So the shader counts seems hmm,  let's call it far-fetched and too enthusiastic?\n\nWhy would that be far-fetched? the xx70 always matched the performance of the previous generation's xx80Ti card. That is, until Turing. If Nvidia wants to make marginal performance leaps the norm, they will completely erode their competitive lead over AMD. They could afford to be lazy with Turing because AMD was so far behind they weren't a threat, but with RDNA, they can quickly close the gap.",
      "I just bought the 2080s because of Doom. Upgraded all the way from a gtx680.",
      "Hey man, my 3440x1440 120Hz monitor would like to have a word lol",
      "Guru3D is one of the most reputable tech sites. But this is just a rumour from a member of the the community (it's not their own source).",
      "Yup, this is what I'm waiting on. Went from 980ti to 1080ti, but 2080ti just didn't tempt me.",
      "What you're saying is literally what he said, but with a contradictory tone behind the message.\n\nYou're both right, but that's because you were both saying the same thing.",
      "I love all the pessimistic and underestimating posts from people with 20 series cards lol the 20 line was a complete rip off, imagine dropping $1400 for a 35% improvement to performance and early access to tech that is almost useless even now a year and a half later.\n\nThe 30 series is finally going to be on a die shrink, a new process. It's going to show leaps and bounds better performance than the 20 series, the same as the 10 series was over the 9 series. Prepare for another massive improvement in performance, and hopefully with competition from the new consoles and maybe a new series from AMD, we'll see a trend back towards reasonable prices. Can't wait to finally have a real successor to this aging 1080 Ti that I can replace it with.",
      "The 2070 super is still a price increase.\n\nThe 1070 was a $380 GPU in 2016 that was like 2015's $650 GPU but 2GB more VRAM.  The 970 was a $350 GPU in 2014 that was like 2013's $700 GPU but with 1GB (.5GB haha) more VRAM.\n\nSo it took one year for a ~$310 or ~46% drop + improvement in the two generations preceding Turing.  But Turing took 2 years for a $200 or 29% price drop.  And Maxwell used the same node as Kepler so you can't just go \"well there was a node drop that really helped!\" since... even Turing had some node improvement over Pascal.",
      "We definitely need 4K 144Hz monitors for under 1000$ is that is true, 1440p is going to be a joke for a GPU like that xD",
      "5000 corejump from 3070 to 3080 ti? wtf",
      "I'm hoping we see a VRAM bump from the new cards, that 3080 seems like a good successor to my 1080TI but I would like to see double digits VRAM numbers from it, my ultra modded Skyrim uses close to 10GB as it is.",
      "DLSS 2.0 may have a word about that xD",
      "Sitting on my 1070 waiting...",
      "Not with ray tracing enabled!",
      "Thank you. Rabid fanboys seem to forget that the middle range of cards now starts at $300 which is ridiculous.",
      "Yea it seems a bit insane. I get the feeling those numbers will only be seen by titan or higher and the 80ti will have like 6800 cores or something more normal like that.\n\nHopefully it is that crazy cause holy piss man, that's some power right there!",
      "Yep. I can easily make my 2080Ti cry in a lot of games with my 3440x1440 120hz monitor. I'm in no race to go up to a higher resolution yet..."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "mid",
    "matched_keywords": [
      "rtx 3070",
      "3070"
    ],
    "title": "My new build with Ryzen 9 5900X and Gigabyte Aorus Master RTX 3070",
    "selftext": "",
    "comments": [
      "Its crazy how every single fan in that case is backwards\n\nEfit: I saw in another comment op says bottom is intake and top/side are exhaust but.... they don't look that way.",
      "What fans are those ?",
      "But it’s how they are. Google DeepCool MF120GT",
      "Since when is the RTX 3070 a “poor” GPU?",
      "Ah I see still should have more intake than exhaust. Just flip the side fans then to intake. Your cpu will thank you and you'll have less dust in the case.",
      "3070 isn’t a low spec card at all lmao",
      "DeepCool MF120GT",
      "omg youre right thats awesome its messing with my head",
      "I think he means relative to the CPU, which is usually more than $400. ie you could've spent less on the CPU, maybe opting for something like 12400F, 12600KF, 5600X and put the money you saved, from lowering the CPU, into upgrading to a 3080 or 6800XT. Idk what you use your PC for primarily but for gaming a 12600KF/12400F + 3080 combo would be much better than 5900x + 3070. BUT if you use your PC for primarily CPU intensive application workloads like blender, code compiling, edits/renders, compression etc then prioritising CPU makes sense. It's all relative to what the PC is being used for",
      "Bro thank you for supporting and liking my music, thank you as well for liking the build. This new build will help me make even better music",
      "He's gotta be trolling. Less than 2% people own a 3070 according to steam rankings",
      "Great 🙂",
      "This guy is a crackhead LOL. For real. 1440p all day damn near maxed or running exceptional performance. I’m running the same cpu and gpu. I actually downgraded from a 3080 for financial reasons. It’s certainly not leaving it in the dust based on personal experience at all.",
      "I'd flip the bottom and top fans.",
      "Even my house doesn't have that much fans. BTW Cool Build",
      "Lol, first thing I came here to ask too. Those fans are slick. Very distinct look the way the X is illuminated.\n\nBeautiful build, OP.",
      "Stuff",
      "Can the build still be quiet with nine fans and would you recommend those ones?",
      "People are just frustrated, don’t worry lmao",
      "Someone get this for me please 😭😭😭"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "mid",
    "matched_keywords": [
      "rtx 3070",
      "3070"
    ],
    "title": "RTX 4060 or RTX 3070 - which one for my first budget gaming PC?",
    "selftext": "Hello, I have the option to buy a second hand gaming PC quite cheaply and I can choose between RTX 4060 8GB and RTX 3070 8GB for the same price and I would like to know your opinion which one would you choose?  I have been googling a lot however I found a lot of \"buts\", the 3070 seems quite a bit more powerful with like 10-20% more FPS, but the 4060 has the new DLSS3 frame generation pushing its fps all the way to rtx 3080 level, but there is apparently an input lag issue with dlss3, but nvidia reflex seems to solve it? I am quite lost here, if I want to play modern games in QHD resolution with the best quality possible at around 60FPS, does 4060 with DLSS 3 provide better experience than RTX 3070 with DLSS 2? Are there other things to consider? \n\nI will probably buy a 34\" ultrawide QHD monitor, but I havent made my final decision, would you also choose such monitor for best gaming experience if you had $300-400 to spend just for the monitor (plus $600 for the pc so $1000 limit for the whole setup, I really dont think I want to spend $200-300 more for RTX 4060ti or rtx4070 as the FPS with rtx4060 seems high enough for most modern games in QHD)? \n\nThanks a lot for your advice.",
    "comments": [
      "Go with the 3070. The 3070 performs nearly the same as the 4060ti. The 4060 is not powerful enough for a 3440 x 1440 monitor. The 3070 will be able to use DLSS and be just fine. Frame Gen is only acceptable if you are playing a single player game. FSR frame Gen works great with DLSS.",
      "What games can a 3070 not run? Personally the only games I've ever experienced issues with were a handful of VR titles. Everything else ran fine.",
      "I traded my boys 3070 for a 2080ti due to Racket and Clank rift apart. If you didn’t play on low setting or Performance mode upscaling the game was almost unplayable due to the stuttering from a lack of VRAM. Plays fine now with all settings maxed out with DLSS quality.",
      "I don’t know if this helps but I have both 4060 and 3070 Ti. Games that support frame gen (let’s use Diablo 4) vs 3070 ti:\n\nUltra settings (1440p) / Raytracing OFF\nFrame Gen and DLSS (balanced) ON\n\n4060 (85W) 117-148 FPS\n\n3070 Ti (140W) 131-170 FPS (no frame gen support)\n\nOf course, this is paired with a 12700H (for 3070 Ti) versus 13620H (4060)\n\n\nAnother game: Assassin creed Valhalla:\n\nUltra settings / FSR ON\n\n4060 67-75 FPS\n\n3070 Ti 85-112 FPS\n\n\nIn general 30 series will have better raw power but it all depends on the watt variant of the 4060 to make it worth buying over a 3070 let’s say. They both support DLSS except frame generation is only on 40 series.\n\nInput lag is there and when frame gen is on, it feels floaty, almost like you aren’t playing the game during  frame loading? Hard to explain but latency is definitely there and idk feels off at least on diablo 4",
      "In this exact situation. 3070, 3440x1440, use dlss with fsr fg on horizon forbidden west and am very happy with the performance except for when I run out of vram and it starts stuttering and loosing frames. It's never that bad though.",
      "The 4060ti also comes in a 8GB model which performs almost identically to the 3070.",
      "On ultrawide, it hit its limits on call of duty quite quickly so I had to use dlss performance and low settings to hit 120fps and it looked awful.\n\nFor normal games, I had to turn off all ray tracing and enable dlss to hit above 60. It physically can’t run stalker 2 above 5fps if you play at higher resolutions.\n\nIt’s doable if you don’t care for higher refresh rates or ray tracing and you don’t mind using dlss",
      "Not Nvidia's framegen, which is somewhat better. But I agree framegen isn't worth the Nvidia tax alone.",
      "Yep. 4060ti uses 160W. 3070 uses 220W. Some 3070s have a power limit of 250W",
      "You won’t be able to run portal RTX on a 4060. My 4070 super only gets 30fps on it even with upscaling and it’s around 50% more powerful than the 4060 ti.\n\nFor anything less than a 4070, you’re better with amd because 8gb just isn’t enough.",
      "I currently have a AMD 5800x and a 3070, playing at 34\" 1440p. The 3070 can still get *decent* performance and visuals in games with DLSS, but I would not personally recommend it to someone looking for a GPU to last a few years at 1440p because of the VRAM issue, which I've ran into in games like Horizon Forbidden West and others. I wouldn't recommend an 8GB GPU full stop to anyone with a 3440x1440 display honestly, not unless that person was exclusively going to play smaller, less demanding games or old games anyway.\n\nAlso FSR3.1 support, which is needed for FSR FG + DLSS is not widespread still and the FSR3 FG mod, in my experience, is a bit dodgy with frame times in about half the games I've tried it in.",
      "Ye I think. But I think game devs work with 8gb. I've not had a problem yet",
      "2080 ti is a pretty good buy as well only a few percent slower with more vram and about identical used pricing. Been trying to nudge my buddy Into picking one up to upgrade his 580 8gb he games on still.",
      "Also dlss 3",
      "3070 no questions asked, DLSS3 FG is useless when the card has 8gb of vram, check out videos by Daniel owen that show how the lack of vram causes FG to lower your fps that you start with\n\n\nIMO if you can get a 4070 or the 4070 super, go for it, you'll be thankfull for the 12gb of Vram (Hardware unboxed recently tested Stalker 2, all of 8gb cards run at 2 fps due to lack of Vram) and actually usable FG couple of years down the road as an investment, because with the 4060 and at a lesser degree with the 3070, you'll be looking at you next upgrade very very soon (unless you only play light or older games and don't plan to play the latest AAA games of course)",
      "4060 is a terrible 1440p card and so is 3070, grab 6750XT/6800 Nvidia has no good budget cards.",
      "Neither,  7700XT or 7800 at this segment.",
      "3070 all day.",
      "4080 super is more expensive than my total budget, I dont really need that much more performance mainly because I will still keep using Geforce now service in case there is a game where 4080 super is well worth it, i just want to have a home machine for those games that cant be played remotely like the new Portal 2 RTX. When I checked reviews, 4060 seemed to deliver good enough performance in 2K resolution, many games need DLSS but I dont consider that a negative. I feel like we live in an era where even midrange gpus are powerful enough to run any game on high settings, and you need high end gpu only if you really want to max out the graphics with 4k resolution, raytracing or path tracing, no DLSS or only DLSS quality etc. I remember times when even the high end gpus werent enough to run a game on full details with anti-aliasing, mainly around the Crysis 1 release (8800 ultra and then 9800gtx), I remember the most powerful gpu from nvidia had like 40 FPS there and it took 2 generations of new gpus to comfortably have 80-100 FPS with 60 min FPS. And if I have to set the details to medium in a year or 2, so be it, as long as i can still run the game decently at 60 FPS. If not I will consider selling the 4060/3070 for $150-200 (or whatever it will sell for used in 1-2 years) and upgrade to something like 4070 or maybe even 5070.",
      "i see a lot of people recommending amd, but that is currently not an option for me as one of the games I want to play is Portal 1 and 2 with the new sick looking RTX graphics upgrade package mod, and it is not compatible with amd cards unfortunately. But even if I didnt care about Portal, isnt nvidia gpus just straight up better than amd (for the same price) with all \"helpers and improvers\" enabled like DLSS, raytraing, reflex etc? \n\nAMD seems to have good base rasterization performance, but its ray tracing and dlss equivalent technology is crap no? I remember seeing a grap where enabling raytracing loses like 70% of FPS, and their DLSS tech doesnt improve fps as much as nvidia and looks worse no? I play to use every available tech to my advantage, I will definitely have DLSS enabled, probably frame generation as well unless it looks or behaves worse somehow, I definitely want to have raytracing enabled in games as the difference in scene lighting is absolutely magnificent (especially with wet/shiny surfaces, glass, mirrors and water.        \n\nAMD also has 12GB or 16GB of vram, but I have no idea how that translates to games and future performance, 8GB vram seems fine right now, and I assume that if it isnt enough in 2-3 years, I will just play with slightly less detailed textures or I will be forced to lower resolution to fullhd. is 8gb of ram really such a big deal as a lot of people seem to think?"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "mid",
    "matched_keywords": [
      "3070"
    ],
    "title": "Zotac leaks its GeForce RTX 3090 Trinity Holo, RTX 3080 and 3070 also mentioned",
    "selftext": "",
    "comments": [
      "That's a clean fucking card.",
      "That design looks awesome",
      "That actually looks great, cant wait to see the EVGA and MSI variants!",
      "Going to have to put 3 credit cards in sli to be able to buy one 😔",
      "Agreed that is legit something I would want in my case, cudos to zotac for not going overboard in the rgb",
      "My wallet isn’t ready for this but I am",
      "I'm happy with this sleek design. I hated their designs for the previous gens. So gaudy looking with those yellow accents.",
      "Because it cleans out your wallet!",
      "reveal day has FE preorders up usually.",
      "There are new renders of the card on [Videocardz](https://videocardz.com/newz/zotac-geforce-rtx-3090-trinity-pictured).",
      "I  hope it's clean... Its brand new",
      "I cant wait for the Asus Strix Variant of both!",
      "make new post for karma",
      "I think normally the reveal day doesn't have the cards actually available that day. Iirc it's typically a week or two until the cards are first available",
      "But are your credit cards ready?",
      "Man I feel most AIBs needs to tone it down a notch or 3",
      "Oh shit, they went \"all in\" for 3090 seems like. Cannot imagine it being less than $1.5K with that design and backplate, but 4 more days. Hope I am wrong.",
      "Couldn’t care less even if they are 4 slots. SLI and CF are dead. Give us big coolers for cool and quiet and quiet operations!",
      "*Looks pretty slick and*\n\n*Not over the top, can't wait*\n\n*To see what MSI does*\n\n\\- retro808\n\n---\n\n^(I detect haikus. And sometimes, successfully.) ^[Learn&#32;more&#32;about&#32;me.](https://www.reddit.com/r/haikusbot/)\n\n^(Opt out of replies: \"haikusbot opt out\" | Delete my comment: \"haikusbot delete\")",
      "Are they expected to launch on the first as well?"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "mid",
    "matched_keywords": [
      "3070",
      "rtx 3070ti",
      "3070ti"
    ],
    "title": "Is the rtx 3070ti worth getting over the normal 3070?",
    "selftext": "In my country the cheapest 3070 goes for $900 and the 3070ti is a extra $100 at 1k. Is the performance boost worth it? \n\nWould it be better to get a 3080 for 400 more at 1300? \n\nNeed some advise not sure what u want to do. Ideally don’t want to spend more than 1k",
    "comments": [
      "Ask yourself if 10% more performance is worth another $100?",
      "Well in this situation, 10% of the price is $90 so OP would be paying an extra 10% for an extra 10% performance.\n\nEdit: to clarify, I still don't think it's worth it. That 10% will be like 10 or 15 frames at most",
      "Now that's what I'd call price to performance",
      "Bruh, you didn't ask this but I'm going to say it anyway: prices are dropping like a stone right now. Unless you absolutely need it, wait.",
      "The key deciding factor between the two is *heat*. The 3070Ti is essentially an overclocked version of the 3070, it has 3% more CUDA cores, 35% faster vram and 27% higher TDP (220W vs 290W) which combine to give only a 5-7% performance boost. That's a lot of extra power and heat you're generating for a somewhat disappointing performance increase. If you have sufficient cooling and decent ambient room temps, Ti is worth considering. Otherwise go with the 3070.",
      "people are really buying desktop 3070 (ti) to play in 1080p?",
      "Most of the heat is the GDDR6X, as those will need around 60W, but it still is only 8gb. The best card to buy so late in the cycle would be the 3060 Tie, as it’s almost 3070 level but msrp was more attractive",
      "If you consider the price of the whole rig, it's 5% higher price for 10% higher performance. So. Theoretically worth it, from that perspective.",
      "I guess it depends on the country, here in Chile the 3070s used are like 850 bucks and new are like 1100USD or so.\n\nThe 3070Ti surprisingly used it's 900 bucks and new 1100 bucks as well, it has literally the same price as the 3070 for some reason",
      "No.\n\n3060ti, 3070, and 3080 are arguably the best value points for this gen imo",
      "I had a two fan 3070 and upgraded it to a 3 fan 3070 ti. Mostly did it for better cooling and it looked tiny in my large case but the better performance was a bonus. Also at the time a 3080 was unobtanium.",
      "A friend of mine literally said a 3080ti is the perfect 1080p card the other day... People are delusional lol.",
      "It depends what you want to play. If you want to play Cyberpunk 2077 with everything Ultra + Psycho RT + Quality DLSS with no drops under 60, then RTX 3080 Ti is a great 1080p card. :D My RTX 3080 12GB in 1440p can't play CP2077 with Ultra RT without drops under 60. :D\n\nFor serious, people sometimes stupid.",
      "Where there is a will, there is a way!",
      "Cool misaligned architectural comparison. The diff between a ocd 60 Ti to a 3070 is under 5% and was 100 bucks cheaper at msrp. Nobody asked about 2000 series",
      "All I can say is avoid the founders edition ti. I got the 3070ti fe and that bitch is hot. I had to set a custom msi curve to keep the temps below 85, and looking online I am far from the only one with this issue.",
      "So never upgrade.",
      "I've got a founders 3070ti and my peak temp is 77 degrees and that's while playing quake RTX. Normal temps for me are 65-72 under load and 28 idle",
      "Thanks. It is a must to make this argument to justify my 3090 😅",
      "AAA games look like garbage at 1080p. I have a 1080p, 1440p, and 4k monitor. \n\nEach jump is very noticeable despite what people say on Reddit. Once you get used to playing at 1440p/4k and then try 1080p again, it’s comically bad. \n\nWith that being said, games like Valorant and Overwatch at 1080p are fine.\n\nEdit: I uploaded pictures of character models from Witcher 3 at 27” 1080p , 27” 1440p, and 32” 4k to my profile. Please go check them out if you think there’s no difference."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "mid",
    "matched_keywords": [
      "rtx 3070",
      "3070"
    ],
    "title": "Anyone know what version RTX 3070 I have?",
    "selftext": "",
    "comments": [
      "it's from a HP OEM",
      "Thats from a HP Omen..",
      "This is the saddest way to gloat about having a 5090, posting a completely useless picture of it when OP asks a genuine question about an unrelated card. The flair and everything is just icing on the cake.",
      "Put it in and load GPU-Z",
      "That's it - thanks!",
      "Yup that’s an OEM card. HP and Dell produce their own designs. It has the same GPU, just a custom usually cheaper board and cooler. In some instances OEMs made a good or at least respectable card. It depends on which one.",
      "Why is no one stating the obvious that the screws for mounting the cooler on the PCB are missing? The center square should have screws in them to hold down the cooler.",
      "4 critical screws are missing that hold the cooler to the GPU itself.",
      "Crazy how similar OEM models are, I swear I saw the exact same style for Dell",
      "Looks like OP scorched it, or there was a leak from aio. Hence why he asking. (Atleast that’s the only reasonable explanation)",
      "Probably made by the same company",
      "Yep. Hp omen.",
      "Hp omen 3070",
      "it was easy to find out before you ~~stole~~ removed it from a computer.",
      "Dell ones are pretty solid, not pretty but they get the job done.",
      "Dell uses MSI as their oem.  The only thing custom is the bios.  It's got mail markings right next to the PC connector.",
      "Came to say this, I wouldn't run this card without those screws.",
      "Walmart.",
      "It looks exactly like my Dell (OEM) RTX 3070.",
      "HP makes graphics cards?"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "mid",
    "matched_keywords": [
      "rtx 3070",
      "3070",
      "3070 ti"
    ],
    "title": "RTX 3070 Still worth it in 2024?",
    "selftext": "EDIT 2: I've figured out my card is the Asus Tuf gaming 3070 ti, and I am no longer planning on upgrading for now  \n  \nhi, I've had this 3070 for about 4 years and recently upgraded to a 4k monitor, i bought this at the worst time in the market in late 2020, but I've seen videos on Pcs with 4060s and semi decent cpus for only about 700 refurbished, my pc costed about 2,200 CAD, and this was my first so i got a prebuilt, wondering if i should upgrade to a 4060 or should I stay, with my 3070,\n\nASUS TUF Gaming NVIDIA GeForce RTX 3070 OC Edition Graphics Card- PCIe 4.0, 8GB GDDR6, HDMI 2.1, DisplayPort 1.4a, (copied from what i think is my card off the internet, Idk if its an OC edition or a TI)\n\nIntel 10700k I7  \n(idk my motherboard)\n\n16 gb ddr4 ram\n\nI use this rig for gaming, music production, and video editing.\n\nEDIT: Most people have told me to wait for the 50 Series to Upgrade to a new card or for 4090 / 4080 prices to drop, which i will",
    "comments": [
      "4060 is a downgrade. \n\n4060ti is a sidegrade.\n\n4070 is an upgrade.",
      "4060 isn't even an upgrade, lowest upgrade I would target with a 3070 is a 4070 Ti Super (4070S wouldn't be bad but you want 16 GB of VRAM at 4k going forward)",
      "3070 performs better than 4060 unless you involve DLSS frame gen. But then you can just buy Lossless Scaling on steam to add frame gen to a bunch of games.",
      "Thanks! Think i will stick with my current since the card seems to be an uograded version",
      "what are you even ranting about.. 3070 is solid gpu",
      "Just wait for the 5000 series at this point. Not long now.",
      "Not when fsr3 is a thing. 4060 is much slower in raster and not every game has frame generation. Its a downgrade",
      "Oh thats why they were so cheap",
      "4060ti is a straight up downgrade at 4k",
      "I'm still rocking a 3070 and have no issues at 4k 60hz medium-high settings",
      "You would have to upgrade to at least a 4070 ti super (~800) to really have a big jump in performance. I suggest waiting for the 5070 around early next year.",
      "I dont know much about it, thats why i came here for more information",
      "are you sure? when the 4000s were released i could have easily walked into best buy and picked one off the shelf any time i wanted",
      "A 4060 isn't really an upgrade over a 3070, so I wouldn't do it.",
      "you can use the fsr frame gen mod in certain games is you really want to, but I really wouldn't consider dlss frame gen a feature worth \"upgrading\" for.",
      "The 3070 launched in October 2020, so yeah coming up on 4 years ago. The only new generation since then has been 40 series which came out in 2022. The 4070 from that stack actually launched later than the 80/90 launching in April 2023 so it's only just over a year old at this point. So even though your PC is coming up on 4 years old, it's still really modern.  \n\nCheckout the techpowerup page for the 3070 [here](https://www.techpowerup.com/gpu-specs/geforce-rtx-3070.c3674). Scroll down to the relative performance section and you can get a quick estimate to how it stacks up to other cards. The 4060 is only 79% of a 3070, so that would be a downgrade. The 4070, is only about 20% better than a 3070, so not a huge uplift either. If you didn't have a GPU, neither are bad options, but given that you already have the 3070 both seem like bad value. You mentioned in another thread that yours is an OC model or upgraded model, and while sure it might be a few mhz higher than a stock card, those for the most part are marketing gimmicks and can mostly be ignored. A 3070 will perform within 1-3% of any other 3070 on the market. An Overclocked (OC) 3070 is still a 3070, so you won't see any huge gains over the stock performance.  \n\n\n50 series is rumored to debut in the final quarter of this year. It will most likely just be the top tier skus like the 80/90 but the 70 will follow eventually. When that generation drops, it might be worth evaluating again if you want to upgrade.",
      "Yeah Ill be sticking my 3070 atleast till the 50 series",
      "Third party app for $7 that allows upscaling and frame generation in any game that be ran in a window or borderless window. It doesn't have dlss, but does have roughly 6 different upscaling methods built into it you can choose between. I tend to prefer their LS upscaler and frame generation though as it's much better than FSR (which is another option they offer)",
      "I bet this time next year there'll be a 5070.\n\nBut if you really want an upgrade, take the money you were gonna buy a 4060 with, stick it in a savings account, keep saving a bit each month and by the time a 5080 does come out you'll be able to get that instead? Either way I think it's worth it to wait if you have a 3070 already. \n\nIt's what I'm gonna do anyway...",
      "60hz it’s great for single player..\n\nBut 144hz would be noticeable difference those those demanding multi player games like COD, Tarkov, Fortnite, ect"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "mid",
    "matched_keywords": [
      "rtx 3070",
      "3070"
    ],
    "title": "RTX 3070 in 2025 for 1440p?",
    "selftext": "I’m wondering if the 3070 is still a good option for 1440p gaming, I was gonna consider a 5070 when they release but I’m unsure due to cost.",
    "comments": [
      "Depends what games you play tbh",
      "Yeah its still allright. I use a 3070ti for medium to high settings on 1440p with dlss and you can get around 100+ fps in most games.",
      "This is the best comment. Ditto for me as well. 8gb wall comes alive in new games",
      "I have a 3070 but I'm 3440x1440 (ultrawide).\n\nI'm a little higher resolution but I would not recommend any 8GB VRAM GPU looking to play the latest games at 1440p. There have been multiple recently released games where I've ran into VRAM issues, either resulting in stutters or having to play the game at lower texture settings which personally I do notice.\n\nThat being said the new DLSS transformer model and how good DLSS performance looks may help with this.\n\nBut yea my personal suggestion? Wait a bit longer and try and save up a bit more for a 5070 if you're able, or maybe grab a 4070 Super for cheap if possible.",
      "I've hit the 8GB VRAM limit on my 3070 Ti a few times, but if you dial back the settings like texture quality to medium/normal, it should help get you back to reasonable frame rates.  Going forward into the next couple years, I'm expecting the lack of VRAM to become more of an issue.  The pro-8GB crowd will tell me otherwise, but I personally wouldn't buy anything with less than 16 GB VRAM if I were buying new in 2025.",
      "Vram is a major problem I am selling my 3070 build for 1k and going to upgrade to a 50 series card or 4090. Some games sturggle with vram but you should be good even if you get it.",
      "I have a 3070 and until a few months ago was playing on 1440p. For me, it really doesn't feel like it's going to be adequate for 1440p in this year. I've already hit VRAM limits on games like Stalker 2 and had to push visual settings down to medium or low to hit acceptable frame rates.\n\nIf you play online multiplayer games or older titles, it's fine, but I'd go for a 5070 otherwise.",
      "It's an 8GB card...",
      "1080p ultra type settings already use more than 8GB, it's not going to last very much longer.",
      "Works for me. High still in most games (with DLSS), but you can still drop to medium later on if needed.",
      "It'll be okay as long as you don't ever turn ray tracing on.\n\nI have a 3070 and I'm giving my current PC to my wife to build with a 5080 so I can replay RE4 Remake in all it's glory",
      "With dlss sure, im using a 3060ti at 1440p and works really well at high settings.",
      "Heard that, I guess I can wait a few months then for it to release!",
      "Sweet! I was gonna consider running medium to high so.",
      "Most games I play on my 3070 at high settings in 1440p. I'm waiting to see what the 5070ti brings to the table before I commit on upgrading",
      "Yo estoy en la misma, estoy escalando con el lossles Scalling ( o algo así) el del pato, y lo veo buena opción para aguantar a que está generación baje, a ver q hace AMD y presiona la bajada, sino xD tal y como va el tema de frames falsos quizá algún día la 3070 rinda como una 4090, xD como dice Juan de la 5070",
      "I was gonna try and snag a 5070 if I can, but I don’t know if a 3070 would get on in 1440p for the following years.",
      "Sweet!",
      "Definitely do that. The 5070 looks like it'll be a great card and it's not a good move to purchase a mid-range 3000 series card right now.",
      "100%, Tested dllss 4 with Nvidia inspector set to profile J on 30 series and big fps drop + looked really bad on balanced/performance (as expected)."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "mid",
    "matched_keywords": [
      "rtx 3070",
      "3070",
      "3070 ti",
      "rtx 3070 ti"
    ],
    "title": "[Digital foundry] Nvidia GeForce RTX 3070 Ti Review: Not Fast Enough For The Money",
    "selftext": "",
    "comments": [
      "Honestly I’m sure a lot of people will buy it just because of shortages of graphics cards.",
      "So the $100 markup is pretty much only for the market demand and not the performance boost compared to the 3070, got it",
      "At least they were kind of normal with the $100 markup. The $1200 3080 Ti is a fucking joke.",
      "Nah.. people will quickly forget what happened when they release a new gen.",
      "making such claims without the next generation actually releasing fr fr",
      "Except for the 3060 ti",
      "Making more SKUs doesn't help the shortage, it helps their bottom line. TSMC is operating at capacity--they are incapable of producing more silicone. But if Nvidia comes out with a \"brand new\" GPU with a nice markup to take care of different bins and can charge more for it, they sure as hell will.",
      "What would I be playing on a 3060 that would *need* more than 8gb or VRAM?",
      "I feel like nvidia doesn’t need to have so many different cards. They could probably have 4 cards total and that would help with pricing arguments and supply shortages.",
      "Its a bad deal when compared to the 3070 FE, which is $100 cheaper. However the msrp for the cheapest AIB 3070 is now around $600, which is the same price as this 3070 ti FE.\n\nI’m guessing the AIBs will be charging $700-$800 for their 3070 ti models. Now those well be the real ripoffs.",
      "The 6000 series was a letdown. Instead of undercutting Nvidia, they just matched them in price, with worse performance and stock.\n\nWe won't see prices come down until stock improves.",
      "Ti in 30 series are a joke.",
      "Less bandwidth.",
      "The increase in performance from G6X should've been expected. I saw only an average 2-3% reduction in performance dropping memory speeds all the way down as far as it goes on a 3080. Seems like it only contributes 5-6% of the performance from the 14 Gbps. What I don't understand is why they decided to use expensive, limited G6X for an imperceptible amount of performance when cheaper, 16 Gbps G6 would have gotten them nearly all the way there. \n\nWith GDDR6, they could have still raised the prices, gotten more profit, and still have been equally disappointing. Nothing would have changed. Probably could've even gotten away with a less beefy cooler. This does not seem like a product that makes total sense for anyone involved.\n\nAnd of course if it's in stock at a retailer at MSRP, buy it. Still a good deal in these times.",
      "I have 980gtx in sli. You bet your fucking ass I'll buy it",
      "I'm more of an AMD fnboy myself but will flip-flop depending on whichever tech I think will be worth my money. I bought my 3080 to replace my Vega 64 after being let down by Vega's \\~70% of promised technologies unfulfilled. The 3080 has held up to everything Nvidia claimed about it. I have serious doubts about AMD 7000 series; I'm guessing it will only have a 30% uplift.",
      "$500 for 2 extra GBs of VRAM. The best deal in gaming!",
      "Its the entire package that you need to consider.\n\nAs much as I detest nvidia's strategy right now, nothing AMD has, no card, comes close to the overall experience nvidia can offer.\n\nFrom massively superior ray tracing to DLSS 2.0 and all the other stuff like noise cancelling and so on. \n\n40 series nvidia are in theory due in Q4 next year, and even if AMD manage to compete in raw power, they need to perform miracles to also compete on the software front.",
      "That was pointed out earlier. Samsung isn't in a much (if any) better position as far as silicone production goes either, though.",
      "No dude userbenchmark is awful. It cannot be used to draw these types of conclusions. At all. An actual benchmarking software suite like 3dmark, which is what I used, is far more reflective."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "mid",
    "matched_keywords": [
      "rtx 3070",
      "3070",
      "3070 ti",
      "rtx 3070 ti"
    ],
    "title": "RTX 3070 ti fe on Nvidia UK NOW",
    "selftext": "I’m shaking I got one - I actually can’t believe it.",
    "comments": [
      "I had one in my cart, logged into scan, went to pay and then got declined :(",
      "Don't get too excited. Scan have cancelled GPU FE orders before : )",
      "3080ti's popped up *with* a buy button on Scan the other day for me (normally there's just no button as they've gone a second after they go live or whatever) so I added to cart, my card got declined twice (just because it's a £1k+ purchase I need to text the bank YES), but it still managed to go through.\n\nSuper lucky on that one.",
      "Congratulations OP.. can you send it to India? I want to try it out and send it back to you after sometime",
      "Did you cum?",
      "Oh god don’t. I guess I’ll have to see if it arrives 21st June then! 😅",
      "[that's kinda SUS](https://cdn.frankerfacez.com/emoticon/363156/4)",
      "\"we gonna turn this FE into a white edition\"",
      "Absolutely not. Around 10% better performance at 70% higher price",
      "I ordered a 3080 from them a couple weeks ago it was fulfilled no problem. Feels like stock is better now.",
      "Why do you need another?   \n\n\nIts annoying for the right reasons in this supply limit, if there were no stock issues then have at it but its not the case right now.",
      "Not sure if this is a flex but I basically only buy groceries, so a random £1000 purchase triggers a text message to check",
      "Happy for you. RTX 3080 msrp is my dream but i don't really expect to get one. I'll probably get the 4080 if stock problem fixed by the time of next gen.",
      "Lol, , so that’s how Gigabyte makes their Vision OC’s",
      "Nice! Yeah mine was declined, put the wrong code in once and then got it the second time from my bank, might have been why. Maybe I should have tried again!",
      "I have a family of 4 and we like to play games together. I do all tech purchasing.",
      "I know, and I would have gotten the 3080 but I’ve been so sick of waiting I just had to. My laptop is from 2012, and I can’t live that way anymore 😂",
      "Question: if a 3080ti comes up for MSRP, is it worth the extra money over a 3080?",
      "he probably just wants a card probably doesn’t care he had to pay 100 extra",
      "I managed to score a 3070FE from them yesterday, but couldn't pay with Monzo (it kept failing - something about billing address).  Had to switch to credit card and then it worked."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "mid",
    "matched_keywords": [
      "rtx 3070",
      "3070"
    ],
    "title": "My new build with Intel i7 12700KF and RTX 3070 Aorus Master",
    "selftext": "",
    "comments": [
      "Would you like some computer with your fans?\n\nNice build BTW.",
      "Only Fans…..",
      "Lmao",
      "i think those sticks are ddr4 the design changed with ddr5 xpg ram",
      "Looks great. I actually love the ambiance!",
      "Hi, not using DDR5. Specs are: Lian Li O11D, Gigabyte Aorus Elite DDR4, Intel i7 12700KF, 32GB XPG D60G 3600MHz, NZXT Kraken Z73, Gigabyte Aorus Master RTX 3070, 9 DeepCool MF120GT fans, NZXT C850 PSU",
      "Thanks. Well it’s personal preference. I like it, you don’t",
      "You literally wrote lmao in every response. Something must be funny. The socially acceptable thing would then be to either be polite about it or just not answer. Instead you chose to write as if this topic is not to be taken lightly. Odd behavior",
      "Specs please? Are you using DDR5?",
      "It’s a GPU support bracket",
      "Thank you",
      "Exactly, it’s DDR4",
      "My favorite part is the 1 fps. Seems like a solid card!",
      "Clean, classic . Nice stuff.",
      "Very nice \n\nLike the RGB. :)",
      "Fan orientation isn't wrong but curious why you exhaust on the bottom and intake on top since hot air rises, doesn't it seem natural to flip it the other way? Just my two cents :3\n\nEDIT: I'm not familiar with the fans, but is the X facing out exhaust instead of intake? If that's the case then you're all g.",
      "😂",
      "Yes, interestingly, these fans (likely for aesthetics) appear to buck the norm and have reversed the direction of flow in term of the hub.",
      "Roughly the same as your monitor's refresh rate 😄 just takin the piss, my dude. Good looking machine you've got there",
      "I built a PC last year. When I built it, I priced it with and without RGB. The difference was $70 total. Everyone who complains about RGB complains about how expensive it is, but it's really not. I have to look at this thing multiple hours per week, I want to be able to change what color it is on the fly. If I decide I don't want RGB for a while I just turn it off. This way you have options."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "mid",
    "matched_keywords": [
      "rtx 3070",
      "3070"
    ],
    "title": "RTX 3070/5800X build I started back in February with a mix of budget and mid-range/upper end parts",
    "selftext": "",
    "comments": [
      "How’s the 5800x with that cooler ? It can run fairly toasty with my 280mm aio.",
      "Don't daisy chain your gpu cable, pull another separate cable for the other 8 pin connector instead.",
      "By the way, current specs are as follows:\n\n1. MSI GeForce RTX 3070 Ventus 3X\n\n2. AMD Ryzen 7 5800X\n\n3. MSI B550M Pro-VDH WiFi\n\n4. 4x 8GB 3200Mhz G.Skill Trident Z RGB\n\n5. 2x WD Blue 4TB\n\n6. 1TB laptop HDD from an old iMac upgraded to SSD\n\n7. 1TB Samsung 870 Evo\n\n8. Seasonic Focus Gold 750W\n\n9. Thermaltake Versa H18 case\n\n10. Wraith Prism ordered online by itself\n\n11. 250GB 970 Evo nvme paired with one of the 4TB drives using Fuzedrive",
      "90 is the limit. It is underclocking quite a bit. I can’t recommend anything except getting a new cooler. Those just aren’t designed to work with a 5800x.",
      "True story here.  I recently upgraded to a 3080Ti on my system. 850W PSU should be no issue, I thought.  Fucker kept crashing during any game that used my GPU more than 90%.  Come to find out it's because of using the daisy chain PCIe power connector.  Once that was out of the equation, hasn't crashed since.",
      "I'd check your aio fitment/mounting if it's getting as hot as you think? I've got a 5800x paired with an Asus Strix 240mm aio and it runs *cold*",
      "You actually wouldn’t have 2 dangling connectors. You can buy the cables to fit properly. But if you’re not having any issues then it’s not a big deal. This sub gets super worked up over the weirdest shit. \n\n\nMy only honest issue with this build is the wiring management is a nightmare. That’s something you could fix for free and a half a day of fun.",
      "It was originally hitting 90. I fixed that by reducing all the PBO power limits. It was hitting 80ish after that on Cinebench with around 4.5ghz all core boost and 4.85 single. I then replaced my 240mm 110i to a new 115i because I wanted flashy lights. Didn’t expect much of an improvement but now it’s maxing around 70 on Cinebench.",
      "Well, i don't think you always need max 144 fps. Depending on the game 100-120 fps are buttersmooth. Sure, there is a difference between 100 and 144fps visible but it's not that major.\n\nLet's say your 5800x hands you 15-20 fps more in SotTR. It makes a smooth experience a tiny bit smoother.\n\nWhat about graphical more intense games like Metro Exodus Enhanced Edition, Cyberpunk, RDR2,... the 5800x won't hand you that much of a different performance compared to a 5600x or 9900k while a 3080 would definitely do that.\n\nAlso do you play 1080p? The 3070 is more or less overkill for that. Of course you run faster into a cpu bottleneck especially with DLSS which pushes the render resolution quite a bit down.\n\nIf you still have 1080p in the next couple of months you will think about upgrading to 1440p because your gpu is simply too strong for 1080p while 1440p is quite a visual bump. My old RTX 2070 was already more than enough for 1080p if i didn't enable RT. If you upgrade the cpu bottlenecks will get a way smaller problem.",
      "Yeah I wanted a 3080 but back in February where I'm at it was over 50% more expensive than the 3070",
      "Those CPU coolers are fantastic for what they are but honestly you should watch the clock speed and the temps and consider upgrading to something a bit better in the future. Your cpu at default will allow itself to boost faster if it’s got proper cooling.",
      "Easier to upgrade a GPU in 2-3 years vs upgrading a CPU on AM4 which is on it's last gen. \n\nI mean I guess OP could have grabbed a 5600x but I think a 5800x is perfectly reasonable. Besides...he may not have been able to grab a 3070 Ti/6800XT/3080.",
      "My fitment is fine. It doesn’t run hotter than it should. Had to change some settings thought as it was using far too much power originally. Gaming it runs around 60. Cinebench Max’s at 70ish.",
      "I went from a 3700x & RTX3080 to 5800x and my frame times got significantly tighter. I only gained 10-15 fps (at 1440p), in BFV, but it's my final upgrade for my x470 platform for the next 4 years or so.",
      "Your motherboard is letting the CPU use more than TDP. Sadly this is the default setting on many boards.",
      "For me the GPU cable should come up through the bottom. And I’d carefully align each little wire in the bunch as well to make sure they weren’t all poking out in every direction. The twist in the cable makes me wanna pull my eyes out. \n\n\nAnother upgrade would be a fan hub hidden in the back side of the case. But if you were to spend money on anything that CPU cooler needs to go. The 5800x runs hot and that thing is fairly compact. It’s probably also negatively impacting the overall airflow dynamics of the case. Noctua air coolers are cheap and quiet. \n\n\nAll in all though. Solid build. Happy gaming.",
      "The cooler is slightly tilted. Can’t unsee.",
      "Unfortunately it doesn't screw onto this case properly so I bought an aftermarket one (you can see it at the front of the card)",
      "I think its just that for Zen 3 there is a wide range of silicon quality. Some of them runs cool while some runs hot. My 5900X running with Noctua C14S is about 80 under full load. Most people I've seen sits around 70. And no the paste isn't the issue because I've manually spread them, and the screws are as tight as they would go.",
      "Indeed, same with my 3090.  Have no idea why I daisy chained because I usually don't.  I just wasn't thinking.  I figured it out after it started crashing though."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "mid",
    "matched_keywords": [
      "rtx 3070",
      "3070"
    ],
    "title": "NVIDIA GeForce RTX 3070 Founders Edition Review - Disruptive Price-Performance",
    "selftext": "",
    "comments": [
      "Summary = Its pretty much 100% 2080 Ti at 499$\n\nIF Stock is found",
      "Considering the 1070 gave you 980Ti performance for $380 and the 970 gave you 780Ti performance for $330, this isn't very disruptive. This is just the usual performance leap we've come to expect from an xx70 card, but at a new (higher) price.\n\nAnchoring the price of the 2080Ti at $1200 (it's still absurd just typing that) was a genius marketing move by Nvidia. It made all future releases seem like great deals. If the $500 3070 was replacing the $700 2080Ti, this wouldn't be such a great deal anymore.",
      "Ofc is it. 95% of the people don't care about most features except Raytracing and DLSS.\n\nWe also don't know the full feature set of the RDNA2 AMD cards. But we do know they will have Raytracing and rumors are they will have some form of upscaling aswell. \n\nIf your not a blind fanboy you should always look at both camps. See which one has the things that better suit you or has better value and go with it. And if AMD can put out a card that has better performance at the same price of even a bit cheaper then a lott of the people will consider them.\n\nHell a lot of the people will consider them just because Nvidia can't get their stock together.",
      "So its a 2080ti for 500$. Thats great. Now lets see what AMD can offer at this price point tommorow.",
      "> Summary = Its pretty much 100% 2080 Ti at 499$\n\nso they werent lying. huh. this is my card whenever i can get it",
      "It's all overhyped marketing these days, hoping that consumers can't remember what happened 3 years ago.\n\nThe only thing that doesn't seem to get inflated is the actual production volume.",
      "The trick here is that the 3080 is extremely good at cost per frame at $700, but nobody is actually making $700 3080s. Everyone is upselling the \"factory OC\" 3080 at $800, which doesn't do anything notable over the stock card because OC headroom is so low.\n\nWe'll have to see if the 3070 ends up sitting at $500 or $600. That really changes the comparison on value.",
      "the problem is Out of stock.",
      "Its so odd seeing people praising them for matching the 2080 ti performance. Every generations xx70 beat the last gens xx80 ti the only outliner being the last gen rtx 20xx series.",
      "In the world of RTX, DLSS, and a host of other features like Broadcast etc... is price to price comparison shopping really done between AMD and Nvidia?\n\nThese cards have the complete package and I’d wager the software features Nvidia provides are worth a 10-15% price/performance difference just like they were in the 20xx era of midrange cards.",
      "Yeah the performance to price is good but its only good because the  2080ti should have always been 700-800$. its more like a 200$ difference in reality. \n\nTuring was a smaller jump while also being overpriced. Its easy for Nvidia now to claim its got great value again.",
      "Honestly it's pretty amazing how accurately Nvidia nailed the 2080 Ti performance mark.",
      "You may be able to AFFORD it, but, you certainly won’t be able to FIND it.\n\nSOLD OUT.",
      "Hey I was here first get in line.",
      "Then you have to put faith in AMD to have working drivers. I'm extremely hesitant even if price/performance is good.",
      "Absolutely nuts that this wasn't just marketing bullshit. This is such a wildly good card for its price. The 2080 was roughly 10% above the 1080ti with the 2070 roughly 10% below the 1080ti. \n\nIt was decent deal to get the 2070 with an MSRP of $500 over the $700 1080ti. But with the $500 3070 being identical to the $1200 2080ti just shows how terrible of a deal the 2080ti was. \n\nNow it's just a matter of seeing if AMD brings some competition. Even if they are comparable this gen, I would be ecstatic. I already bought a 3080 FE and don't have any intention of buying a new GPU for 4+ years,  but I hope that AMD brings pressure to force innovation.",
      "The era of easy die shrinks is over. Each new process node is more expensive to design and manufacture than the last. If you want to keep seeing the usual performance leap, you should expect to see higher prices to get that performance.",
      "At launch the 2080 was actually almost dead even with the 1080 ti, leaving the 2070 closer to 15% below it.  But if you factor in previous generations it fuckin' sucks.\n\nThe GTX 1070 was 980 ti performance for $380.  The GTX 970 was 780 ti performance for $330.  The GTX 770 was literally just a GTX 680 for $400.  The GTX 670 was slightly better than the GTX 580 for $400.  The GTX 570 was equal to the GTX 480 for $350.  The GTX 470 was better than the GTX 285 for $350.  The GTX 260 was better than the 8800 Ultra / 9800 GTX+ for $400 and was seen as overpriced and quickly lowered significantly.\n\nThe 2070 was the first x70 card to fail at matching the previous generation's top card, *and* it was the first one to cost as much as it did.  To say the 2070 was a decent deal is a joke.",
      "So the XX70 is once again the best value card (the 3080 costs 40% more but is ~20-30% better)?",
      "Not exactly. This time around both cards have different best use cases. Last gen both the 2070 and 2080 were 1440p cards for most people, the difference was that the 2070 was a good 1440p card while the 2080 was a great 1440p card.\n\nThis time around 3070 isn't really a good 4k RT card but it's a fucking great 1440p RT card. Meanwhile the 3080 is a really good 4k RT card.\n\nYou can't just look at the on-paper value, it highly depends on the buyer's situation. If you are going to be gaming at 4k with RT you really should go for the 3080 even if it's not better value price/performance wise than the 3070."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "mid",
    "matched_keywords": [
      "rtx 3070",
      "3070"
    ],
    "title": "Bit the bullet and upgraded to the RTX 3070 from the GTX 1080… couldn’t pass the deal for $649 at Microcenter. The EVGA GTX 1080 served me well since day 1, 6 years ago, and still running strong!",
    "selftext": "",
    "comments": [
      "Good upgrade….\n\nBut highly suggest running two PCIE power cables to the card.",
      "1080 was a great card, I upgraded from that to the 3080 and it's awesome. Your build looks clean too",
      "That 3070 can pull up to 200 watts, a pci-e connector is upto 150w and the pci-e slot itself is upto 75w, so you are \\*technically\\* ok, but its got two pci-e connectors for a reason and thats going to be power spikes.  25w isnt much wiggle room, this obviously doesnt cover any overclocking.",
      "I can probably do that…",
      "my upgrade was the gtx 1060 *3GB* -> rtx 3080 honestly didnt know how bad the 3gb version of the gtx 1060 was at the time",
      "I couldn’t justify spending an extra $600 on the 3080. I got a really good deal on this card. (Considering the prices of GPU’s over the last couple years)",
      "It is still a solid card depending on your needs. It went into my fiancee's build to replace the 1650 Super in there and it runs everything pretty well still at 1440p (with some settings turned down depending on game). \n\nWe've been playing DICE Battlefront 2 and Halo MCC together and it's been running fantastic for her. Paired with my old 8700k as well, still a very solid build.",
      "Yeah I mean I'm not trying to brag too much but I got my card for like 800 bucks on launch day but I still really think the 3070 is a fantastic card",
      "Alright alright… just did it. I don’t wanna turn my computer into a Samsung phone 😳",
      "That 3070 looks at home in there tho",
      "Pfffff amateur! My GTX 660 is still going strong. Just joking man, still waiting to upgrade myself.",
      "You did well, other alternative is 3070 Ti and they all seem to be $750 at the moment.",
      "Although I agree that you should use 2 PCIE cables, I actually used my 3070 with a single PCIE cable for over a year now without any issues. Although I undervolted the card so it never went over 220W.",
      "Your 1080 has been a good Soldier 😎",
      "1060 6GB to 3080 felt pretty insane.",
      "No, one of the guys I work with has a son that really wants a gaming computer… they’re not well off, so with the extra parts I have laying around I’m building him a gaming computer. I pulled 16GB of 3600mhz Ram from my machine, have a decent b450 ASRock MOBO, 1000watt PSU, Ryzen 5 5600g, 24” Samsung monitor and bought him a new case, 1TB M.2, gaming keyboard/mouse and AIO. He’s coming into the office today and he’s going to learn how to build a computer. He’s a good kid just doesn’t have much. Good deed of the year.",
      "When did you buy the AIO?",
      "you know what. 1080 cards were awesome. that whole gen was awesome.",
      "I upgraded from 8700k 1080ti to a 3070 laptop xD (legion 5 pro). And I made a profit",
      "So two separate cables plugged from the psu to the pcie then right? I just upgraded to a 3060 and am wondering if I should do the same"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "mid",
    "matched_keywords": [
      "3070"
    ],
    "title": "I upgraded my GTX 970 to the RTX 2060 today! It’s no 3070, but I got a pretty good deal on it and I’m really excited to play Cyberpunk on my PC! (After and Before photos, upgraded the CPU cooler too!)",
    "selftext": "",
    "comments": [
      "In case you aren’t aware EVGA has a step up program that you can upgrade within the first 90 days of purchase to another GPU. So when the 30 series rolls out you can put in to step up to one if you want to and just pay the difference",
      "Awesome dude, happy for ya!",
      "I have 3 of those 970's in my house - were some of the best bang for the buck cards for years!",
      "That’s good to know! My reasoning for not waiting for a 3000 series card is because my CPU is 5+ years old and I’m sure it will bottleneck even overclocked. (i7-4790k @ 4.5)",
      "Ahh. Back in a day bought 970 just for Witcher 3. Good times.\n\nNow Im getting 3080 for Cyberpunk.",
      "To all the people saying he should wait, what could he buy around 250 that is better than a 2060? A used  5700 or Vega 56? Used 2070 rarely goes for that cheap and by the time 3060 is actually available - to puah prices further down - we will be around Christmas.\nHe needed a GPU now and for that kind of money the deal is good indeed.",
      "Looks good.\n\nThanks to DLSS, I am sure Cyberpunk will run very well on your 2060",
      "FYI that program only applies to certain and not all models.",
      "If you are open to upgrade that resolution (if you got a better card), bottleneck will become less of a problem.\n\nI got an i7 4790 and will get a 3080.",
      "Should’ve waited for sure",
      "Thank you that is exactly my reasoning! Plus I don’t really need a 3000 series and even if I got one I’m afraid it would bottleneck my CPU. I am happy with what I have for 1080p gaming :)",
      "A 4790K won't necessarily bottleneck a 3000 series. It probably would bottleneck a 3080 especially if the game is CPU heavy, but a 3060 would be a good pairing to not bottleneck much if at all.\n\nBut if all you are trying to do is get 1080p 60 fps with good graphics settings, a 2060 for $250 is a really good deal.",
      "Gotta love CDPR!",
      "I'm still gaming on my GeForce 256.  20 years strong baby!",
      "Massive upgrade. You're going to love it!",
      "Honestly still an excellent card, just wanted a little more umph’ for my games.",
      "oh boy, another one of those total annihilation/serious sam gamers boomering it up  \n\n\nhaha that's epic though",
      "That looks absolutely amazing. \n\nAs soon as I can afford it, I need to upgrade my Nvidia 770...",
      "Thank you! 😊",
      "Even without DLSS, I think OP will be able to run CB 1080p on high settings 60fps. I believe that CD Project Red had more than enough time to optimize their game."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "mid",
    "matched_keywords": [
      "rtx 3070",
      "3070"
    ],
    "title": "EVGA GeForce RTX 3070 XC3",
    "selftext": "",
    "comments": [
      "I love how they keep showing just that side and don't show that the backplate on the XC3 is as horrendous as the FTW3 and also has the red accents on the side for no apparent reason",
      "very ugly not worth buying guys lol",
      "[For those who want to see what I'm talking about](http://imgur.com/a/fzUSmZp)",
      "I, for one, am glad that they went over the top with the RGB and the curvy colored aesthetics, because if that keeps at least one person from buying it, then that means that there is one more card that could potentially be in stock for me to buy.",
      "Definitely. If I were them, I would go for FE or other AIBs. Look how gross this is. /s",
      "What's up with the wavy crap? :o",
      "Know this post is a meme, but the backside is pretty bad to be fair, they just don't show it in any of the marketing material so far.",
      "Founder edition cards look better and might perform better as far as thermal and noise this time around.",
      "Hate to break it to you but the XC3 also had the red accent on the back-plate and side.",
      "Ya it does but the outsourced Nvidia support  is much worse. That's the one thing keeping me from just not going for the FE instead of EVGA. Honestly not many would buy EVGA rn if it wasn't for their good reputation for support compared to everyone else.\n\nPlus they might release the 20gb 3080 in a month or two and with EVGA i could just step up (as long as it's within 90 days) .",
      "I really don't mind the design of the cooler on the EVGA cards like everyone else, but man, those fans are the ugliest fans I have ever seen with their little \"E\" protrusions. They look even worse in pictures over renders. I would be very interested in seeing their engineering analyses on those fans - I feel like those features would degrade the performance.",
      "You'd be wrong. I can't say if the effect is that noticeable, but adding things like that produces turbulence and thus lowers noise. That's why car antennas have an spiral pattern around them.",
      "The backplate is on top?",
      "Jesus, can we hire a product design consultancy for once and stop letting the 7 year olds design the coolers? It’s getting old and cringe now. All the second party companies design tacky shit.",
      "Please don't buy it, so I can snap one.",
      "Ugly as shit but I'm buying it for EVGA support and I'm slapping an EK block on it ASAP anyway.",
      "you're high if you think a 3080ti would drop within 90 days of the 3080 release.",
      "No way the new 3080 is gonna come out within 3 months, EVGA would lose a lot by letting people step up that way imo",
      "I'm looking forward to the reviews. I want to know if there are considerable benefits paying extra for the FTW3 when compared to the XC3. Aesthetically speaking I'm leaning towards the XC3.",
      "Why couldn't the 3080 FTW3 look like that? Much cleaner design without that red accent."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "mid",
    "matched_keywords": [
      "rtx 3070",
      "3070",
      "3070 ti",
      "rtx 3070 ti"
    ],
    "title": "Nvidia won’t explain the mysterious absence of its RTX 3070 Ti GPU",
    "selftext": "",
    "comments": [
      "It was a new kind of launch, I present you: GHOST launch.",
      "Take the shortest path possible.  From the TSMC factory to the mining \"factory\".  Maybe in some cases they are right across the street. \n\n&#x200B;\n\nThinking about this, honestly, Nvidia/AMD and their partners could save a killing if they just packaged them like bulk ordered hard drives and didn't do the whole logistical mess of designing fancy boxes, shipping individual cards here and there, etc.",
      "actual paper launch?",
      "I didn't see any go on sale in my country. Not that I would buy them even at MSRP, but there are none to buy anyway.",
      "Anyone else just beyond caring and utterly exhausted by this shit?",
      "Nitpick: These would leave a Samsung fab (and go through others). TSMC is busy with other stuff.",
      "for me is so simple, nvdia just want to sell the profitable 3080ti. nothing else",
      "The point they're making is that normally Nvidia would release a small amount of FE's, but this time they didn't drop a single one. Links didn't appear at all and if you go on eBay there are no 3070Ti FE's anywhere, so it's not like scalpers got to them first.",
      "I am gonna be honest and say I'd rather have more 3070s and 3080s/3080 Ti's on the market if it means the 3070 Ti is nowhere to be found.",
      "Just create GeForce NOW for miners, no need to sell GPUs.",
      "Nvidia may not be the problem.  It might not even be Samsung either.\n\nIt's the companies that actually supply the parts for the video card so the company that prints the boards can assemble them in the factory.  (Also keep in mind that Nvidia doesn't MAKE the card, they only design it then they send it to their partner to silkscreen the PCB and assemble the card after they get the chips, which IIRC is either Palit or another OEM (it's the very same OEM that had released a 12 pin non FE version of the own 3080 or 3070 card awhile back).\n\nSomeone proved this just yesterday by posting the \"date code\" of their GPU die (not on reddit) of their new 3090 FE (purchased June 4th) and the die itself was fabbed four months ago!  And the heatsink 6 months ago (Dec 2020 to be precise) and the card was just released, so it means Nvidia isn't releasing the cards as soon as the chips are created, but are being delayed for some other reason.  The fact that the chip is so much older than the drop of the card in the shop means that Nvidia has enough chips.  Something else is holding the production back.\n\nNotice the difference between the cooler production and the chip production vs the drop.\n\nOriginal post (untranslated):\n\nhttps://www.hardwareluxx.de/community/threads/nvidia-geforce-rtx-3090-faq.1277151/page-566#post-28465006\n\nNotice his other card has a heatsink date of september 25, 2020 (Right after the street date) and GPU date of 45th week of 2020.\n\nSomething to think about.",
      "50% Eth mining limiter, EIP-1559 coming up very soon and the end of Eth mining around end of Q4 2021.\n\nMany folks have done the math and most cards you can get right now will not even pay themselves off before mining ends.\n\nIn the next couple months I really think we will see the GPU situation improve a lot as miners begin selling of large numbers of cards in bulk.",
      "But that only fucks over the environment. With crypto we can screw over the environment, gamers, machine learning experts, the power grid, retailers, etc.",
      "Isn’t this just a real paper launch? They release specs and it’s technically for sale there’s just no stock. People misused the term the first time around.",
      "Better yet, let miners mine in Samsung factory",
      "Just skip **all of the steps** and dump a bunch of crude oil on a nature preserve or national park! lol",
      "Exactly.  I was following the launch all day that day and like many others, I spent hours monitoring Best Buy only for it to instantly go OOS.  I've been following it periodically since then and there still aren't even any reviews on the card.  Many people have been saying that it doesn't look like Best Buy ever got any cards to sell.",
      "Only if they share the die.  The GA102 and GA104 are different sizes all together.",
      "Nvidia could just become a crypto mining company. Cut out the middleman!",
      "Seems like, yeah."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "mid",
    "matched_keywords": [
      "rtx 3070",
      "3070"
    ],
    "title": "[Hardware Unboxed] Radeon RX 6800 vs. GeForce RTX 3070, 40 Game Benchmark: 1080p, 1440p & 4K",
    "selftext": "",
    "comments": [
      "great analysis here - \"Cyberpunk 2077 hits the VRAM limit with RTX on so we recommend buying an RX 6800 which is trash at RTX and doesn't have DLSS\"\n\nalso this whole paragraph\n\n\"DLSS usability is both game and resolution dependent, which makes providing benchmark numbers more difficult. We’ve seen many reviewers who are evaluating DLSS in games like Cyberpunk 2077, doing so with an RTX 3080 or 3090 at 4K. This is by far the best way to showcase the technology. As you lower the resolution, even to 1440p, the image becomes a lot blurrier as DLSS has less data to work with, and at 1080p even in Cyberpunk 2077 the quality DLSS option isn’t great, and in our option noticeably worse than native 1080p.\"\n\nafter watching GN's video on DLSS is a nice laugh",
      "Yeah I mean if you watch is videos, you can kinda tell he's biased towards AMD. \n\nIn games where AMD loses, he defends them by saying things like oh even though it loses, you can still perfectly fine, with smooth gameplay. (Which I don’t disagree)\n\nHe doesn't add those commentary when 3070 loses and only points out 6800 is e.g 20% faster when both are over 200+ frames in 1080p where it doesn’t really matter, by using his logic mentioned earlier.\n\nI’m not a fanboy in either. I am subbed to both NVIDIA and AMD. \n\nFor this price bracket i think 3070 is a clear winner particularly when 6800 AIB prices are well over 600+ and more like $650 USD. He’s using founder edition performance/price which makes AMD look more favorable. If you compare the street price for AVG AIB Models for both, perf/dollar would be a completely  different story.",
      "\"still no DLSS\". I don't know what people are waiting on.  There can not be an equivalent because there's no pipelined hardware for it. If you do it on the general purpose cores, it will be too much performance hit as it takes from your rendering time.",
      "Radeon 6800 11% faster at average in 1440p, but worse ray tracing performance and still no DLSS equivalent from AMD",
      "you can dislike them and still be against Nvidias attempt to censor them",
      "b-but AMD promised!!1",
      "The amd bias is incredible",
      "People are so caught up in this brand war they just don't notice the bias anymore.\n\nI like HUB. I especially love their monitor reviews. It's definitely one of my go-to YT channels for hardware. But Steve *is* biased towards AMD, even if he doesn't notice it himself. Where I really started to notice it was when I was actually looking at GPU reviews from the perspective of a potential buyer for the first time in 4 years.\n\nThere are many small details in how he analyzes the data and what he concludes from it, like what you mention, that aren't immediately obvious but you notice it when you're looking at buying the product and hang over every word. I've said it before here but his 3060 Ti review was particularly offensive - I found that video felt more like praising the 5700XT a year later than reviewing the 3060 Ti.\n\nPersonally I also find his VRAM arguments to be kind of nonsensical and a bit hypocritical considering how he feels about RTX and DLSS.\n\nThey still make great content that I enjoy but yeah, it's there.",
      "So AMD priced the RX 6800 ridiculously. Only 11% faster than the 3070...but your paying a 3080 price",
      "AMD put premium prices despite not being in the position to do so. I think increasing their CPU prices was a smart idea from a business standpoint, but GPUs? No way. Not to mention they have even less stock than nvidia, despite making fun of nvidia in this regard. Doesn't help that outside of the US it's impossible to find one at near MSRP.\n\nAs good as RDNA2 is, it's not looking as good as it did right after its reveal.",
      "AMD Fans really pushing to justify the  price hard.\n\nGarbage feature set and drivers for over $500?\n\nNo thanks. But I guess if  AMD could sell the R7 to loyalists, this one should do well too.",
      "Dude is biased AF lol",
      "Lol does he seriously sat the first paragraph?  No wonder they wanted to cut him off.  I guess I am playing video games wrong since I prioritize visual fidelity and play single player games..\n\nIf cyberpunk is any indication, the ultimate image quality of the future is better served by tech like rt and dlss, not increasing native resolution and texture resolution to higher levels, which just doesn't scale as well. \n\nTraditionally you need 4x more horsepower to play 4k vs 1080.  Not true anymore thanks to RTX tech....",
      "VRAM amount really comes in at 4K ultra type settings looking to hit over 60fps, at which point the 6800 is already out of it's league.\n\nSlapping more VRAM on a lame ass GPU doesnt make it future proof.",
      "They're saying what their audience wants to hear from them.",
      "I have an rtx 3070 playing on 1440p, RT ultra, dlss balanced and let me tell you a fact. That vram number has not gone above 6900 mb even once during the 70+ hours I played cyberpunk.",
      "I feel they need to decide what they want to be, reviewer or influencer.",
      "DLSS Quality at 1080p is better in some places than native and worse in some places, saying that it is \"noticeably worse than native\" is a load of bullshit\n\ndid you like play the game yourself before typing this comment? because with my rig game looks WAY BETTER with RT and DLSS Quality than without RT",
      "He was even arguing with Andrei from AnandTech about how to benchmark cpu. He was saying that SPEC is synthetic benchmark and it is not related to real world performance.\nI think he doesn't even know that SPEC is suite of real world applications.",
      "I literally play DLSS quality at 1080 so I can Max RT. Sharpness on in NVCP. It looks as great as native except for ghosting on the back of my drive. Im no Fanboy AND in Turing. If I had a 3080 I would still play at 1080p with RtX Max but without dlss"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "mid",
    "matched_keywords": [
      "rtx 3070",
      "3070"
    ],
    "title": "Gigabyte RTX 3070 gaming oc thermal paste change",
    "selftext": "Hi all, \n\nI know that there hundreds posts/videos about this but just wanted to share my experience with changing the thermal paste on my gpu so maybe this can be useful for people when it’s needed.\n\nSo, for a long time I was playing at 1080p and the gpu overall temp never passed 65 degrees celsius. I haven’t been able to use my pc for around a year because I move abroad and when I got it back I switched to 1440p and the temps started to rise. \n\nFirst I thought okay this is 1440p performance of this cad but I also knew that it shouldn’t be so I decided to change the thermal paste but keep the thermal pads cus I saw that they are decent usually. \n\nGpu temps before thermal paste change in games:\n\nOverall: Around 80 degrees celsius\nHot spot: Around 105 degrees celsius\n\nAfter thermal paste change in games:\n\nOverall: 65 degrees celsius\nHot spot: 70 degrees celsius\n\nSo thermals went back to normal and I suggest you to do this if you have similar problems and your card doesn’t have warranty and of course if you know what you are doing.\n\nPS: I am using it with uv apllied",
    "comments": [
      "I'd love to do this to mine, but Kinda freaks me out taking a GPU apart lol",
      "PTM7950 tests about 66c in environments where paste tests about 68-70c.\n\nTested on a 4090 FE.",
      "It is usually alot easier then you think but it depends on the card. I just did the same ob my 4080 and i only needed to remove 4 screws in total to do it. My 3080 though needed alot of removal to do but just check videos on youtube. It is extremely difficult to screw it up if you follow a good video 🙂",
      "It is okay for most of cards and processors. You will be fine.",
      "Just did this to my wife’s RX 580, it wasn’t hard but I didn’t particularly love how AMD decided to use 6 different types of screws to hold it together",
      "MY 3080TI was starting to get toasty. Just changed the thermal paste to kryonaut extreme and changed the pads over to the pre-cut kritical set. I went from nearly 80C to maxing out around 65C on both the gpu and vram.",
      "What about honeywell ptm7950 ?",
      "I did new pads and paste on my 3080ti master. Was very simple. I had massive improvements. Hot spot went from 105c to 75c. Paired with undervolt now I never go above 70c",
      "Looks like it has 0.25mm thickness. Is it ok for 4080 super?",
      "What thermal paste is good for GPU? Is mx4 a good one?",
      "Exact same model. Exact same temps and hotspot and similar change lol. It's been such a stark difference.",
      "Oh I know, I was also very anxious but felt like had to do it anyway because temps were reaching to the bad levels.",
      "I used mx-6",
      "Since the release of new DLSS I haven't used it to be honest, since the games I play doesn't support it but I am planning to play the new Indiana Jones game so I will share the result.",
      "Instead of lowering power target, undervolt it and you get the same fps in games and close to default in benchmarks, unlike power limiting.",
      "Well removing the RGB header was difficult and I can't say I wasn't scared :)",
      "Unfortunately I have a 3080 Aorus Master, with the lcd screen. I think it would be pretty difficult but I'll have a look see",
      "Any phase change pad will work, or is it from GPU to GPU different? I have a Aorus 3070 max and would like to change the thermal paste/pad too ☺️",
      "Yeah 8GB memory is really low especially when you are 1440p. Nice to see you got lower temps too.",
      "With undervolting I actually get higher FPS and score with lower temps"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "mid",
    "matched_keywords": [
      "rtx 3070",
      "3070"
    ],
    "title": "Asus RTX 3070 vs 5070Ti size comparison",
    "selftext": "I recently replaced my RTX 3070 with a 5070Ti, and was interested to see that the two cards are almost the same size.\n\nThe top card is the Asus TUF Gaming RTX 3070, measuring 299.9 x 140 x 53.4 mm.\n\nThe bottom card is the Asus Prime RTX 5070Ti, measuring 304 x 126 x 50 mm.\n\nAnd yes, I did remove the plastic before installing the 5070Ti. \n\n\n\n",
    "comments": [
      "5070Ti seems to make good use of space by using slightly larger fans.",
      "I want 24GB or more since I upgrade rarely, still using my 1080. I'm hoping the supers will have more ram.",
      "i want one sooooo bad, but these prices aren't right man.",
      "https://preview.redd.it/td2xgho0m9qe1.jpeg?width=3000&format=pjpg&auto=webp&s=3ef6bb71a0fa60337346700338cc47d23fa3bab7\n\nwent from 3070 Ti TUF to Shipping \"lost\" my MSRP Ventus 5070 ti - so the vendor sent TUF instead as a replacement 😅",
      "it will be a long wait till then man 🥲",
      "Its crazy to think that the cards have gotten so big the prime has an \"sff ready\" designation.",
      "I liked the Prime design and it's cooling efficiency for given dimensions in this generation. Its much more appealing and works cooler than other MSRP-level models.",
      "I was extremely fortunate to get one for MSRP at Microcenter, but I wouldn't have paid more than that.",
      "The old TUF wanted a new TUF as a replacement... 🤣",
      "1 more year hopefully, paying nearly 1k for 16GB is just too bitter a pill to swallow. Thank god I don't play so much lately.",
      "same, I'm currently looking at 5070ti but only if priced at 830$ or less. other than that I'm holding.",
      "Fully stock!",
      "What's crazy is the 5080 uses the same cooler and it stays very cool. Mine doesn't really get above 72\\* and it's in a SFF Case (Phanteks Evolv Shift XT). The 9950x3d in the case and on an AIO holds more heat.",
      "Congrats man! I had a very very similar upgrade. TUF 3070 Ti to Prime 5070 Ti at MSRP. Could not be happier. I miss the metal shroud of the TUF but the build quality of the Prime is excellent too",
      "I wish my 5080 were as big as my 3080ti. At least then I could easily fit my pump res combo normally. 😂",
      "Asus prime is their small form factor cards. I like them cuz my case is narrow",
      "I was expecting some behemoth, but my 5080 is about the same size as my 3080ti.",
      "size seems negligible if not the same, but 9 vs 11 blades.",
      "You made out because supposedly the cooler on the Ventus isn't great.",
      "Do you notice that your prime when going from 0 rpm to over 2000 rpm for a few seconds sometimes when booting up some games? Does it once and goes back to being quiet after."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "mid",
    "matched_keywords": [
      "rtx 3070",
      "3070"
    ],
    "title": "GeForce RTX 3070 Review Megathread",
    "selftext": "# GeForce RTX 3070 reviews are up.\n\n[Image Link - GeForce RTX 3070 Founders Edition](https://preview.redd.it/i7k7cj8d0pv51.png?width=1920&format=png&auto=webp&s=0c8d3056d3a742543fc47f941fc1a8a710a451c6)\n\n# Reminder: Do NOT buy from 3rd Party Marketplace Seller on Ebay/Amazon/Newegg (unless you want to pay more). Assume all the 3rd party sellers are scalping. If it's not being sold by the actual retailer (e.g. Amazon selling on Amazon.com or Newegg selling on Newegg.com) then you should treat the product as sold out and wait.\n\n# Below is the compilation of all the reviews that have been posted so far. I will be updating this continuously throughout the day with the conclusion of each publications and any new review links. This will be sorted alphabetically.\n\n# Written Articles\n\n# Anandtech - TBD\n\n# [Arstechnica](https://arstechnica.com/gaming/2020/10/nvidia-rtx-3070-review-the-499-1440p-graphics-card-to-beat-for-now/)\n\n>Nvidia really couldn't have set these dominoes up any better. Its RTX line of GPUs has separate components to handle the above fancy features—dedicated ray-tracing cores and dedicated \"tensor\" cores to handle ML-assisted computation. The way its ray-tracing cores work lines up neatly with industrywide standards like DXR, which means it's a drop in the programming budget to implement those in ways that will work on competitors' GPUs and on brand-new gaming consoles. And the tensor cores' upscaling methods line up neatly with TAA, a particularly common anti-aliasing standard that Nvidia's DLSS effectively piggybacks off. As of DLSS 2.0, the model does *not* require game-specific coding to work (though developers still have to partner with Nvidia to implement it).  \n>  \n>Thus, as I said in the beginning, your definition of a \"future-proofed\" GPU will likely drive your interest in what the RTX 3070 has to offer for $499. We're about to see even more interesting ray tracing in games—including at least one we're not allowed to talk about yet. You'll have to take our word for it, in terms of how exciting it is to live inside of some games' ray-traced worlds.  \n>  \n>If that's not your bag, due to visual preferences or budgetary reasons, I get it. But it remains to be seen whether a cheaper RTX card can deliver the same future-proofing in the 1080p range or whether AMD will arrive with a perfect amount of budget-minded power and ray tracing—or even a butt-kicker of a card that skips ray tracing altogether in favor of powerful, traditional 3D rendering for a damned good price. For now, in the 1440p range, Nvidia has the clear lead... for at least 24 hours.\n\n# [Babeltechreviews](https://babeltechreviews.com/the-rtx-3070-fe-arrives-at-499/)\n\n>This has been a very enjoyable experience evaluating the new Ampere RTX 3070 versus the seven other cards we tested.  The $499 RTX 3070 FE performed very well performance-wise compared to the RTX 2080 Ti FE – *formerly* the fastest gaming card in the world that released at $1199. The RTX 3070 at $499 is a solid upgrade from the GTX 1080 Ti that originally launched at $699 even though we were [originally hesitant](https://babeltechreviews.com/benchmarking_turing_rtx/) to recommend the upgrade to a RTX 2080 Ti two years ago based on its value to performance.  \n>  \n>If you are a gamer who plays at maxed-out 1440P, you may do yourself a favor by upgrading to a RTX 3070. The RTX 3070 Founders Edition offers good performance value as an upgrade from a GTX 1080 Ti with the additional benefit of being able to handle ray tracing, and it can even meet the demands of 4K gaming with high settings.\n\n# [Digital Foundry Article](https://www.eurogamer.net/articles/digitalfoundry-2020-nvidia-geforce-rtx-3070-review)\n\n# [Digital Foundry Video](https://www.youtube.com/watch?v=ul8F0MmRpmY)\n\n>The RTX 3070 is undoubtedly a terrific graphics card. It delivers performance in line with the RTX 2080 Ti at a very reasonable asking price of $500, lowering the cost of entry to high frame-rate 1440p and stable 4K gaming substantially. Moreover, the Founders Edition card we tested is cool, quiet and equipped with future-looking features, including a single HDMI 2.1 port that matches perfectly to next-gen 4K 120Hz HDR displays.  \n>  \n>With that said, there is an asterisk on those results, with the Founders Edition 2080 Ti we tested with marginally beating the 3070 in some games thanks to the older card's out-of-the-box overclock. Regardless, the 3070 FE's significantly improved power efficiency, HDMI 2.1 port, upgraded RT performance and better-performing cooler make it a better choice than the RTX 2080 Ti Founders Edition even with that performance differential in mind - in a hypothetical situation where you could find both cards for the same price.  \n>  \n>Perhaps more relevant is the comparison with the RTX 3080. Normally we expect to find diminishing returns from higher-tier graphics cards - you might pay 30 per cent more for one hypothetical video card over another, but only get 20 per cent better performance. That's not really the case with the RTX 3070 and 3080, where - at least in some games - you're getting more or less 40 per cent better performance by spending 40 per cent more, so in some sense they're equally good value for 4K gaming. If you're gaming at a lower resolution like 1080p or 1440p, then the margin between the two cards narrows as you're becoming partially constrained by your processor - something we experienced even using the Core i9 10900K, which at present is the fastest gaming CPU on the market. So in some sense the RTX 3080 is the best value high performance card for 4K, and the RTX 3070 is the better value choice for 1440p gaming - especially as its 8GB of VRAM is less likely to be an issue at this resolution.\n\n# [Guru3D](https://www.guru3d.com/articles-pages/geforce-rtx-3070-founder-review,1.html)\n\n>Yes, I can make this short, out of the three RTX 30xx cards released right now, my untarnished favorite is the 3080. The 3090 super-sweet but out of my comfort zone price-wise. However, for most, so is the RTX 3080. And that then makes the RTX 3070 a far better/proper proposition money wise. If NVIDIA can get the stock allocation in order and prices remain/hover at the 500 USD marker, you'll retrieve a crapload of gaming performance for that amount of money. The most straightforward comparison is the mighty GeForce 2080 Ti (read that well *Ti*) performance. A few months ago, that card was (and still is) 1250 USD, you know. Unreachable for the vast majority of us commoner folk.  \n>  \n>So therein is a lot of value to be found. However, my most significant grievance for the 3070 is its 8GB of graphics memory as yes, this still is a proper Ultra HD card. While you'll be fine in Full HD and Wide Quad HD at 8GB for a while, times are changing. We feel framebuffer sizes need to go up for Ultra HD. Then again, if this card had 16GB as opposed to its 8GB of GDDR6, then you could easily add close to a 150 maybe 200 USD premium on top of the 500 USD asking price, as yes graphics memory is very one of the most expensive things in that bill of materials for a manufacturer. With that in mind, a 3080 would then be the more logical choice. With that said and done, I get why NVIDIA opted for 8GB, the reasoning behind 8GB as for most games that will be sufficient and keeps that bill of materials used at that a  level we ll can embrace.\n\n# [Hexus](https://hexus.net/tech/reviews/graphics/146293-nvidia-geforce-rtx-3070-founders-edition-ampere/)\n\n>Nvidia has had an interesting launch experience with GeForce RTX 30-series GPUs based on the all-new Ampere architecture.  \n>  \n>On the one hand, the technology advancements over Turing are sound, construction of the Founders Edition cards is first class, and relative value is surprisingly good given rival AMD has yet to release its next-generation beasts.  \n>  \n>On the other, however, a desperate lack of stock and initial instability has forced Nvidia to apologise to its legion of gaming fans. Lessons have been learned, you would think.  \n>  \n>Delayed by two weeks, this is precisely why the GeForce RTX 3070 Founders Edition launch is so important. Nvidia ought to have had the requisite time to iron out issues that have plagued the other two, more powerful GPUs.  \n>  \n>Priced at $499/£469, the RTX 3070 FE is deserving of serious attention to any gamer who wants superb performance at QHD and more than a stab at 4K gaming with all the bells and whistles turned to 11.  \n>  \n>It's a match for last-gen RTX 2080 Ti FE, which cost over twice as much when released, albeit equipped with extra memory, and offers a solid upgrade from any other 20-series, or older, GPU. The Founders Edition is built beautifully, quiet and cool, and sets an awfully high bar for partners to emulate.  \n>  \n>Bottom line: The GeForce RTX 3070 Founders Edition is a thoroughly decent premium graphics card whose true position in the enthusiast pecking order will only be revealed when rival AMD launches Radeon RX 6000-series in the coming weeks. Interesting times ahead.\n\n# [Hot Hardware](https://hothardware.com/reviews/nvidia-geforce-gtx-3070-ampere-gpu-review)\n\n>When NVIDIA initially announced the GeForce RTX 3070, it made some bold claims regarding performance that got gamers and enthusiasts really excited for the card. 2080 Ti-like performance for about $500 would represent an incredibly strong value in light of the GeForce RTX 20-series’ price structure. And as you saw on the previous pages, [NVIDIA ](https://hothardware.com/tags/nvidia-)delivered. Over and above the strong performance per dollar, however, the GeForce RTX 3070 also has a relatively small form factor, it runs cool and quiet, it’s an easy overclocker (albeit power limited), and it's energy efficient as well. The GeForce RTX 3070 ticks all of the right boxes. The only potential gotcha is the card’s 8GB of memory. For the vast majority of games available today, 8GB should be adequate with maximum image quality, even at high resolutions, but moving forward that 8GB of memory may require some image quality concessions to maintain smooth framerates.  \n>  \n>As it stands today though, the GeForce RTX 3070 is the GPU to buy if you’re in the market for a graphics card in the $500 price range. It offers killer performance per dollar and an unmatched feature set. This one is an easy Editor’s Choice winner.\n\n# [Igor's Lab](https://www.igorslab.de/en/nvidia-geforce-rtx-3070-founders-edition-in-test-ampere-can-also-economic-and-cuddly-small/)\n\n>In general, the GeForce RTX 3070 is an all-around success, because it is faster than a GeForce RTX 2080 Ti, costs less than half the price and has become significantly more efficient. For a final assessment, including that of the market positioning, one will, however, have to wait for the launch of the new Radeon graphics cards. I already wrote that NVIDIA’s feature set ranges from the usual RTX components such as raytracing and DLSS 2.0, to various RTX software (video, voice) for the end user, to the entire studio and workstation applications.  \n>  \n>Especially in the semi-professional areas, AMD is currently rather at a disadvantage and it will have to wait and see what will be launched on 28.10.2020 in addition to the new hardware. So everyone will have to set their own premises and ask themselves what value which feature and use case really has (or not) for them. A review can’t take this decision away from anyone, it’s up to each person to decide for themselves.\n\n# [KitGuru Article](https://www.kitguru.net/components/graphic-cards/dominic-moass/nvidia-rtx-3070-founders-edition-review/)\n\n# [KitGuru Video](https://www.youtube.com/watch?v=5ieU6eV8rh0)\n\n>With the RTX 3070, Nvidia also saw fit to change the Founders Edition design. This card is about 40mm shorter compared to the RTX 3080, and has both its fans on the underside, instead of one on the topside of the card. As the RTX 3070 is significantly less power hungry than the RTX 3080, though, this new cooler is still more than good enough to tame the 220W Ampere GPU.  \n>  \n>Temperatures, for instance, didn’t go above 72C during my testing, which means it is actually slightly cooler-running than the bigger RTX 3080 Founders Edition. Noise output is also very easy on the ears, with the two axial fans spinning at 1700rpm under load. We’d still expect custom cards from the likes of ASUS, MSI and Gigabyte to improve on this performance, but the RTX 3070 Founders Edition is a technically excellent piece of engineering.  \n>  \n>The improvement the Ampere architecture has made to power efficiency is also more evident with the RTX 3070 than we saw from the RTX 3080. Drawing pretty much bang on 220W under load, this GPU offers 16% higher performance per Watt than the RTX 2080 Ti, and it’s even better compared to the RTX 2070, with 27% higher performance per Watt. Again, it’s not close to the jump from Maxwell to Pascal, but it is definitely a step in the right direction.  \n>  \n>Enthusiasts will be glad to hear that we experienced significantly better overclocking results with our RTX 3070 sample. Right now I can only talk about this Founders Edition card, so it’s still not clear whether or not I just got lucky with the silicon lottery, but overclocking this card resulted in performance gains between 9-11%. Compared to the lacklustre overclocking capabilities of the RTX 3080, this is much more positive and means an RTX 3070, when pushed to its limit, should be faster than RTX 2080 Ti in pretty much any scenario.  \n>  \n>In sum, **Nvidia** has delivered an excellent graphics card in the form of its **RTX 3070**. At £469, this GPU delivers unmatched value for 1440p, and even 4K, gamers. It’s about as fast as the RTX 2080 Ti, it is significantly faster than the RTX 2070, while also being more power efficient.\n\n# [Legit Reviews](https://www.legitreviews.com/nvidia-geforce-rtx-3070-founders-edition-review_222986)\n\n>This is the new mid-range graphics card for NVIDIA and it looks like the performance numbers lived up to the hype. The GeForce RTX 3070 really does deliver GeForce RTX 2080 Ti-level performance at jus a fraction of the cost. It also does so while using less power and that helps the card run cooler and quieter. While the GeForce RTX 3070 trades blows with the GeForce RTX 2080 Ti, it completely dominates that other cards in the GeForce RTX 20 series and all the cards in the GeForce GTX 10 series. This makes upgrading much easier if you are looking for a $499 graphics card as you will be getting a massive performance increase while snagging all the latest NVIDIA features. Some might have wanted to see more than 8GB of GDDR6 memory on the GeForce RTX 3070, but that shouldn’t be an issue on current game titles for 1440P gaming. If a game comes out in the future that needs more than 8GB for ultra image quality settings then the solution would be to just change the game settings. Not a huge deal and moving up to the RTX 3080 only gets you 10GB of GDDR6X.\n\n# [OC3D](https://www.overclock3d.net/reviews/gpu_displays/nvidia_rtx_3070_founders_edition_review/1)\n\n>So far our time with the Ampere GPUs has been one of jaws dropped, minds blown and wallets emptied. We hadn't long got used to the RTX 2080 Ti, and its class-leading performance before the RTX 3080 came along and gave you higher framerates than the Turing card and did so at a significantly lower price. The RTX 3090 was jaw-dropping in all sorts of other ways, and more akin to a Bugatti, being both insanely powerful but also not exactly affordable for the majority. If, however, even the RTX 3080 was above your budget, then the RTX 3070 is even better value for money.  \n>  \n>Official replacements for existing models is one of the things that emphasises how quickly the hardware world has moved on. When you feel that there is as much power as you could realistically wish for, a new refined model appears that makes the preceding one look lacklustre by comparison. Nvidia is determined to compare the RTX 3070 Founders Edition with their RTX 2070 Founders Edition, and that's their prerogative. Even a casual glance over our results will show you that in actuality it should be compared to the RTX 2080 Ti, such has been the improved performance Nvidia have extracted from their Ampere GPU when compared to its Turing forebear.  \n>  \n>Our results show something quite interesting too. Admittedly it's a general rule rather than a hard and fast one, but in broad terms, the games that the RTX 2080 Ti bested the RTX 3070 FE (albeit barely) tended to be the older ones, whilst the Ampere card just had the edge in the more recent titles. This is especially true for the games that made full use of the DLSS and Ray Tracing. This makes sense, given the fact that there are the areas that the Ampere is designed around.  \n>  \n>As time goes on and the new Console generations get launched with their Ray-Tracing abilities and faster load times, more PC games will be designed with these technologies in mind.  In time, we expect the performance gap between the older Turing card and newer Ampere cards to widen, especially as Nvidia drivers refine the performance of the newest game releases. Just off the top of our head, we know that games such as Watch Dogs: Legion, COD: Black Ops Cold War and the game that is probably the most hotly anticipated game of all time, Cyberpunk 2077, will make full use of every eye-candy technology they can bring to bear.  \n>  \n>All this means that even if you could find a Turing card for around the same money as the Nvidia RTX 3070 Founders Edition, there is no point to do so. You might as well get the newest architecture with the longest warranty that will be supported by the manufacturer for the longest time. The fact you can get this for such a ridiculously low investment cost is just the icing on the cake. A single 8 pin PCIe power input allows the RTX 3070 FE to be more power-efficient, and the addition of the HDMI 2.1 lets users push higher resolutions at higher refresh rates than the RTX 2080 Ti that it matches in performance.  \n>  \n>If the RTX 3080 was the card that showed how serious Nvidia was in refining their Turing architecture, then the RTX 3070 FE is the card that will sell in huge volumes and yet hasn't been crippled to achieve a low price point. Two months ago the fastest card on the planet cost you well north of a grand. Today you can match that performance for less than half the price. There has never been a better time to be an enthusiastic gamer.\n\n# [PC Perspective](https://pcper.com/2020/10/nvidia-geforce-rtx-3070-founders-edition-review/)\n\n>What we know right now, and by right now I mean October 27, 2020, is that NVIDIA has the GPU to buy at $499 with the RTX 3070 Founders Edition – if you can buy one. Availability – of course – will be a big part of this launch. But what AMD announces on October 28 will be another part of the story, and we only have leaks and rumors on the AMD front at this point.  \n>  \n>No matter what AMD announces, the RTX 3070 Founders Edition we reviewed today is a fantastic product. Beautifully designed, quiet under load, reasonable power draw, and nearly as powerful as the RTX 2080 Ti at less than half the cost. If only every GPU launch was like this.\n\n# [PC World](https://www.pcworld.com/article/3586613/nvidia-geforce-rtx-3070-founders-edition-review-vs-2080-ti.html)\n\n>Take AMD’s potential counterpunch out of the equation, though, and there’s no question that the $500 GeForce RTX 3070 is a fantastic graphics card. It’s remarkably faster than its direct RTX 2070 predecessor, delivers gaming performance effectively on a par with last generation’s $1,200 flagship (and much better creative rendering performance) while drawing less power, and runs very cool without getting too noisy. Nvidia’s Founders Edition design continues to rock my socks aesthetically too. I wish Nvidia included more memory capacity in the RTX 3070 for people wanting to play at 4K resolution, but other than that, there’s not much to complain about. The GeForce RTX 3070 will melt your face for a stunning *$700 less* than you used to have to pay for this level of performance.\n\n# [TechGage](https://techgage.com/article/nvidia-geforce-rtx-3070-rendering-performance/) - Workstation Benchmarks!\n\n>In the end, NVIDIA’s GeForce RTX 3070 performs about where we’d expect it to, based on what we knew of the card before diving in. NVIDIA itself said that the RTX 3070 would match 2080 Ti, and in our gaming tests so far, we’ve found that to be largely the case (although we seem to see Ti pulling ahead more often than the opposite is true.) Again, we’ll have that performance in the days ahead, as we wrap up our testing (which will include 1440p, ultrawide, and 4K test resolutions.)  \n>  \n>It’s become a theme that we kick off a new launch with creator-focused content, but with the RTX 3070, it seems to almost make sense that we start here. Whereas the RTX 3070 will largely match the RTX 2080 Ti in gaming, it’s almost guaranteed to take a clear lead in creator.  \n>  \n>We saw some instances where the 2080 Ti still managed to take the lead, but it was never by very much, and it could be owed in some cases to the larger frame buffer. If you can survive your work with a 8GB frame buffer, then the RTX 3070 is a seriously attractive creation graphics card. As mentioned multiple times earlier, this card costs less than half what the 2080 Ti did, but often beats it in rendering.  \n>  \n>Quite simply, the RTX 3070 offers more performance than a $500 GPU ever has before. If we look as far back as the Pascal-based 1080 Ti, that card scored 189 points in OctaneRender, whereas this RTX 3070 scored 414. In our real-world tests, we generally see the RTX 3070 at least twice as fast as the 1080 Ti, and it still costs less than that card did at its launch a few years ago.  \n>  \n>All three Ampere cards have been interesting or exciting in their own right, but the RTX 3070 sets itself apart due to its more accessible price-point and its performance advantages over the last-gen parts. $500 GPU for $500 GPU, the RTX 3070 is 55% faster than the 2070 SUPER from last-gen, so overall, NVIDIA has quite an alluring product here.\n\n# [Techpowerup](https://www.techpowerup.com/review/nvidia-geforce-rtx-3070-founders-edition/)\n\n>NVIDIA has done it again—their new GeForce RTX 3070 is impressive, not only in terms of performance, but also pricing. Just a few weeks ago, we reviewed the GeForce RTX 3080, which finally makes 4K gaming work perfectly. Today, we have the RTX 3070 Founders Edition, which achieves the same for 1440p gamers. Every single title in our test suite exceeds 60 FPS now, and performance is improved so much that you get RTX 2070 \"RTX Off\" FPS with \"RTX On\". If you choose to enable DLSS with RTX, the RTX performance hit is basically nullified; in that case, and with games that don't support RTX, the GeForce RTX 3070 FE matches last generation's flagship, the RTX 2080 Ti, which retailed at over $1200 not too long ago.  \n>  \n>When averaged over our whole test suite at 1440p resolution, we see the RTX 3070 Founders Edition beat the RTX 2080 Ti by 1%, let's call them equal—still a huge achievement. Against the original GeForce RTX 2070, the performance uplift is around 50%, and the difference to the RTX 2070 Super is 30%. AMD definitely needs something new, the RTX 3070 is 42% faster than the RX 5700 XT, at much more attractive pricing. GeForce RTX 3080 is 23% faster than the RTX 3070, but for this comparison, it's also important to look at 4K, where the difference is 31% because the RTX 3080 is slightly CPU limited at 1440p.  \n>  \n>With those performance numbers, RTX 3070 is the perfect choice for the huge 1440p gamer crowd, but the card also has enough muscle to drive many titles at 4K 60 FPS, especially if you are willing to dial down settings a little bit. The RTX 3070 is also a great choice for 1080p Full HD if you want to drive a high-refresh-rate monitor with 120 or 144 Hz. For just 60 FPS, 1080p it's overkill unless next-gen titles go overboard with their hardware requirements, which is highly unlikely.\n\n# [Techspot](https://www.techspot.com/review/2124-geforce-rtx-3070/)\n\n>Overall, Nvidia's GeForce RTX 3070 is a great high-performance value product. Upcoming competition aside, in today’s market the RTX 3070 is as good as it gets in terms of cost per frame and even performance per watt.  \n>  \n>The RTX 3070 is the new and much more affordable 2080 Ti. In making that comparison, you get 3GB less VRAM, but make up for that with improved power consumption, shaving off about 60 watts. That means it’ll be possible to make more compact graphics cards, or larger models that run cooler and quieter. Oh yea, did we mention this card will run you $500 instead of $1,200?  \n>  \n>Compared to the GPU it is replacing, the GeForce RTX 3070 is nearly 40% faster than the 2070 Super. Now, it's going to be extremely important that Nvidia addresses supply and makes sure those base models hit the MSRP.\n\n# [The FPS Review](https://www.thefpsreview.com/2020/10/27/nvidia-geforce-rtx-3070-founders-edition-review/)\n\n>At the end of the day, there are several things about the GeForce RTX 3070 Founders Edition that we like and see as positive for everyone.  At $499 it is priced the same as the GeForce RTX 2070 FE and RTX 2070 SUPER FE.  This means it is the direct upgrade path, from those last generation video cards.   \n>  \n>As an upgrade path, it has proven to provide 50% or more performance advantage from the last generation at the same price point.  It is so that it now compares on performance to the GeForce RTX 2080 Ti FE of the last generation.  That was a $1200 video card.  In the last generation, you had to pay $1200 for this kind of performance.  Now you can get what was $1200 performance, for $700 less at $499.  You now save, on generation-to-generation, $700 for the same performance.  \n>  \n>It also provides this level of performance at much less power demand.  It also delivers this level of performance in a smaller package size and cooler GPU temperatures.  On generation-to-generation improvements, this is a positive evolution of graphics advancement. Technically, we would have liked to have seen more VRAM.  This seems like the right card to have been the one to carry 10GB of VRAM instead of 8GB in its default configuration.  Then the RTX 3080 could have had 12GB, that would have been a better lineup in our opinion.  \n>  \n>At the more affordable $499 price point, you get an ideal playable gameplay experience at 1440p with everything turned on.  You can maximize graphics settings at 1440p and might even be able to turn on Ray Tracing depending on the game.  If Ray Tracing is ever too demanding, and the game supports DLSS, turning that on at 1440p will solve that easily.  This video card is not really suited for 4K, though it can muster decent performance, ultimately the limitation will be VRAM and performance in newer games.  Now that the RTX 3080 FE has been launched, that’s your 4K card with no compromises.   \n>  \n>The GeForce RTX 3070 Founders Edition earns its place as a proper replacement and upgrade path from the GeForce RTX 2070, and especially for anyone on GeForce GTX 1070 series. Add-in-board partner video cards will be available on October 29th. The GeForce RTX 3070 Founders Edition is the fastest $499 video card to date. It is well put together, and as a custom card from NVIDIA provides excellent thermals, package size, and remains quiet.\n\n# [Tomshardware](https://www.tomshardware.com/news/nvidia-geforce-rtx-3070-founders-edition-review)\n\n>The GeForce RTX 3070 Founders Edition is everything we expected. It's a lower power card with a smaller footprint, and it basically trades blows with the previous generation king of the hill, the RTX 2080 Ti. Two years later, and $500 now potentially gets you the same performance as the old $1,200 GPUs. If there's one constant in the world of GPUs, it's the ever-increasing performance at any given price point. But we're in the midst of a *lot* of GPU stuff, and without seeing what AMD's Big Navi brings to the table, it's impossible to give a final verdict for the RTX 3070.  \n>  \n>The bottom line is that we can't declare a winner right this moment. Nvidia's Ampere RTX 30-series GPUs are potent, and the RTX 3070 brings new levels of performance to the $500 market. We expect to see 30-series parts push down into the $300-$400 range in the coming months as well. AMD's Big Navi is more of a wildcard since we don't quite know what to expect in terms of ray tracing performance or DLSS alternatives. AMD may have as many as four Navi 2x GPUs launching in the next month or two (or three or four), also with prices ranging from perhaps $250 up to $600 or more.  \n>  \n>If you're already set on going with Nvidia and don't want to spend more than $500, you can try to pick up an RTX 3070 on Thursday. If you're willing to spend a bit more money, we'd argue the added VRAM, bandwidth, and performance of the RTX 3080 means it's the better option at $700 — not that you can find RTX 3080 in stock, but you can keep trying. For the undecided, we suggest waiting to see what happens with Big Navi, and of course, those who prefer AMD GPUs will want an RX 6000 regardless of how it stacks up.\n\n# [Computerbase - German](https://www.computerbase.de/2020-10/nvidia-geforce-rtx-3070-test/)\n\n# [HardwareLuxx - German](https://www.hardwareluxx.de/index.php/artikel/hardware/grafikkarten/54456-high-end-fuer-499-euro-nvidia-geforce-rtx-3070-founders-edition-im-test.html)\n\n# [PCGH - German](https://www.pcgameshardware.de/Geforce-RTX-3070-Grafikkarte-276747/Tests/vs-2080-Ti-Release-Benchmark-Review-Preis-1359987/)\n\n# [PCMR Latino America - Spanish](https://www.pcmrace.com/2020/10/27/nvidia-geforce-rtx-3070-founders-edition-review/)\n\n# Video Review\n\n# [Bitwit](https://www.youtube.com/watch?v=imkp8swF840)\n\n# [Digital Foundry Video](https://www.youtube.com/watch?v=ul8F0MmRpmY)\n\n# [Gamers Nexus Video](https://www.youtube.com/watch?v=NbZDERlshbQ)\n\n# [Hardware Canucks](https://www.youtube.com/watch?v=knPHhzEdpeo)\n\n# [Hardware Unboxed](https://www.youtube.com/watch?v=UFAfOqTzc18)\n\n# [JayzTwoCents](https://www.youtube.com/watch?v=rXhTSKjAX3k)\n\n# [KitGuru Video](https://www.youtube.com/watch?v=5ieU6eV8rh0)\n\n# [Linus Tech Tips](https://www.youtube.com/watch?v=3XaOeLPztN4)\n\n# [OC3D](https://www.youtube.com/watch?v=pvXz-85m0V4)\n\n# [Optimum Tech](https://www.youtube.com/watch?v=6AhvNcMRL1s)\n\n# [Paul's Hardware](https://www.youtube.com/watch?v=o_N7S9iEP7U)\n\n# Tech of Tomorrow - TBD\n\n# Tech Yes City - TBD\n\n# [The Tech Chap](https://www.youtube.com/watch?v=2BS0pClYYho)\n\n# [Techtesters](https://www.youtube.com/watch?v=vK6QrnOKGKE)",
    "comments": [
      "One again reminding anyone in a rush to upgrade for cyberpunk 2077 that it got delayed again.\n\nSource:  https://twitter.com/CyberpunkGame/status/1321128432370176002/photo/1 \nI'm too lazy to format on phone",
      "**3080 / 3090 stock situation part 7**",
      "Nice job /u/Nestledrink. This is a fuck load to do, keep it up the good work.",
      "06:00:37\n\n... and it's gone.",
      "i think you're being generous...",
      "Holy shit I was expecting a rick roll",
      "I try not to shitpost in official threads",
      "I’ve lost 99% of my interest in getting a 3070 at release now. \n\nThank you CDPRED for reducing my urgency to upgrade.",
      "So Nvidia hasn't said anything about their store on EU yet?  \nWe're so close to the release and yet no words",
      "About 36 seconds too generous.",
      "I saw people just yesterday saying that the 3070 was a \"terrible\" value for price/performance.\n\nTurns out, that's not true. Just because the 3080 is better in that facet than normal doesn't mean that the 3070 is irrelevant. Great card for 1440p, 100+hz and even 4k60 in plenty of titles. Plus, in games that support DLSS 2.0 going forward, you'll be able to hit basically any standard performance threshold even with RT on.\n\nGreat card to upgrade to for 10-series and even low 20-series owners.",
      "This comment, along with 10 years of comment history, has been overwritten to protest against Reddit's hostile behaviour towards third-party apps and their developers.",
      "Thank you. About 4 hours late (originally targeting noon finish time) but people love scheduling last minute conference call around lunch time apparently.",
      "Starting a month later would actually arguably be better because they will have fixed bugs!",
      "Can't wait to buy this in 2077, just in time for Cyberpunk too!",
      "I'd like to thank AMD for making the 6000 series GPUs reduce people buying the 3070",
      "So are we expecting a 6am PT release on Thursday? I believe thats the time the 2080 dropped.",
      "This comment, along with 10 years of comment history, has been overwritten to protest against Reddit's hostile behaviour towards third-party apps and their developers.",
      "Worth noting that he based it off pure CUDA core count and not real world benchmarks.",
      "As someone who's building his first PC in 15 years, this ...is madness.  At least I understood the demand side of the crypto currency.  I don't understand this launch at all.  Thursday will basically be the last time I try to get a card in 2020.  If it doesn't work out, I'll see you all in 2021 when the first 32\" 4k 144hz IPS monitors start coming out.\n\nIf things are still fucked then, well, I guess I'm waiting till AM5?  Honestly I don't care enough about gaming to go camp out at a microcenter at 11pm the night before.  I'll go read a fucking book."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "mid",
    "matched_keywords": [
      "rtx 3070",
      "3070"
    ],
    "title": "[Hardware Unboxed] Nvidia GeForce RTX 3070 Laptop vs Desktop Benchmarked, The Same GPU (But Not Really)",
    "selftext": "",
    "comments": [
      "This is a problem, but all parties involved need to do more. Nvidia should probably go back to putting an “m” after it. Manufacturers need to publish more on the cooling capacity of their laptops and power limits. Consumers need to research more before buying a computer, or anything for that matter, to see what third party reviews think as marketing is always filled with partial truth and sometimes outright lies. Even with the same exact cpu, performance can vary wildly between devices.",
      "Yeah, when Nvidia dropped the 'm' suffix with Pascal, it made sense, since Pascal was power efficient enough to perform very similar on mobile. Now, not only are the mobile GPUs much slower with no way for the non-tech-savvy to tell, but they also have the 3080 mobile, which is based off of the GA104 (3070) die. Consumers are going to buy 3080 laptops with no idea that what they are actually getting is a glorified 3070. The Ampere mobile lineup naming scheme seems to be designed to mislead buyers.\n\nI do agree that laptop manufacturers and consumers also need to do their part though.",
      "You know except for how they called both of them RTX 3070.\n\n\nImagine if Intel released a laptop CPU called i9 9900K but it was a six core or a quad core.",
      "It should be written though, because not every consumer outside of those who build their own desktops would know.",
      "No but it doesn't change the fact that Nvidia calling this GPU an RTX 3070 when it's slower than the slowest desktop RTX 3070 is simply misleading.\n\nJust call it an RTX 3060 if that's the level of performance it's capable of.\n\nThe fact that they have an RTX 3080 for laptops that doesn't even use the same GPU is even worse. I'm sure there are a lot of non-tech savvy consumers who thought they were getting the RTX 3080 destkop performance because of the identical name.\n\n\nAt least last generation Nvidia used the same GPUs in both the desktop and mobile cards and only lowered the clock speeds.",
      "That makes no sense \n\nSimply being the most powerful mobile GPU doesn't make them entitled to use the 3080 brand \n\nIt's literally a 3070 chip. \n\nIf they even used a 3080 chip and undervolted it you MIGHT give them a pass. But it is a 3070",
      "What happened to putting an M after it. That must have made it too easy.",
      "I got a 3060 laptop and outside of being able to boil an egg on the keyboard, it performs really well. I always thought it was an unwritten rule that if you're getting a gpu laptop, not to expect desktop gpu performance.",
      "Yeah but at least the model name was different even if all they did was an M to the end of the model number.\n\n\nIf Nvidia didn't want to mislead customers they could have just added an M to the end like they did in the past. Then not tech savvy people could at least tell that an RTX 3070M is not the same as an RTX 3070 non-M.",
      "It even makes sense for nvidia to avoid this confusion, so they don't have users on forums etc. complaining that their \"3080\" doesn't perform, influencing others to avoid buying their own desktop 3080's which would perform well. I can understand the want to make buyers think they're getting a full 3080 in a laptop, but it is still the most powerful mobile GPU on the planet, so they don't need to hide the fact that it's a mobile part by muddying their naming scheme.",
      "Prior to the recent few series, they used to put an m after the number do you knew it was different.\n\nWhy do people think HUB are anti-nvidia? GN tends to say similar things and people call him Tech Jesus here.",
      "I agree it’s messed up, and while it doesn’t excuse nvidia, if someone is going to drop $1000+ on a product they should research it. Either that or speak to a knowledgeable friend in the area if they feel they don’t understand. That’s recommended for everything in life, not just PCs. People need to stop trusting the marketing material, then maybe their informed purchases will help drive companies to change.",
      "Sure, so nvidia should take a 750 and call it a 3080 fuck it.\n\nI'll go put a Ferrari logo on my piece of shit car as well. Why not \n\nI'm amazed it's legal or hasn't been challenged",
      "But that rule was broken by Pascal and late stage Maxwell. The 980 GPUs in laptops at the end of Maxwell were full 980 GPUs. Not mobile, not cut down - FULL. \n\nSame thing with Pascal - the first chips launched, before Max Q debuted, were full desktop chips. Maybe 100Mhz difference base clock, but that's easily OC'd or beaten in boost clocks. Hell, the GTX 1070 laptop chip was actually more powerful than the desktop one - exCt same die, 100Mhz slower clock speed, more CUDA cores.\n\nSo it's really a backslide with Turing and more so with Ampere that we're seeing the chips not line up with their desktop parts, when Nvidia made a (rightfully) huge deal about in in 2016 and 2017.",
      "> Consumers need to research more before buying a computer\n\nLike checking the model number of the components, ie 3070?\n\nLooking up the performance of individual parts is super detailed for an average person. They know this and are taking advantage of it. Scummy",
      "If lying is common industry practice in certain industries, should we just allow it?\n\nIf you say \"RTX 3070 performs like this\" and then you release a mobile product and say \"This is also RTX 3070\" then they should probably be similar products.\n\nHere, they released a different, worse product under the same name, hoping that people will buy the worse one thinking it's the same, knowing that some people wouldn't buy it if they knew it was worse. This is basically lying to make more money. We should not encourage companies to lie to consumers to make more money.",
      "> RTX 3070 when it's slower than the slowest desktop RTX 3070 is simply misleading.  \n>  \n>Just call it an RTX 3060 if that's the level of performance it's capable of.\n\nSo... call the 3070 GPU a 3060? That won't get confusing I'm sure.\n\nWhat happens when one OEM has the \"3060\" in a really good chassis with decent airflow and max TGP and you compare it to an identical \"3060\" in a competitors chassis with no airflow and nearly half the TGP?\n\nLaptop GPU performance will *always* be confusing for the average consumer, even amongst the same SKU the performance will vary wildly dependent on the OEMs design.",
      "They dropped the M when they started bragging that the Pascal mobile chips used the same chip as the desktop verson. IMO they should have brought back the M.",
      "I watch almost all of their content and they frequently take a shit on every company. AMD fanboys used to call them Nvidia shills and now it’s the other way around. \n\nThey frequently praise the 30 series cards and have showed them very favourably against RDNA2. Some Nvidia mega fanboys on this sub just can’t handle a single criticism of Nvidia. \n\nPointing out the the laptop 3070 is significantly slower than the desktop one, while also pointing out that Nvidia’s marketing would like you to believe otherwise is something that needs to be pointed out. AMD isn’t even relevant to this video and yet here we are with people like you declaring his AMD bias when it has zero relevance to the topic at hand. \n\nLiterally zero AMD GPUs in this video and here you are talking about horrendous bias towards AMD.",
      "I just won't buy their garbage laptops, and I dont. It's that simple. And I will dissuade others from doing the same.\nPresuming I live longer than AMDs stock shortages I don't really see your point. If they come up with a mature alternative to DLSS I'll buy their products \n\nTheir monopoly in AI has nothing to do with consumer laptops at all\n\nThey now have 2 competitors in the consumer space, with intel GPUs coming at the end of the year"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "mid",
    "matched_keywords": [
      "rtx 3070",
      "3070"
    ],
    "title": "RTX 3070 or RTX 4060 ti",
    "selftext": "Hi there! This is the offer: RTX 3070 Asus Strix OC V2 vs. RTX 4060 ti msi Gaming X 16 gb version. I want to upgrade my GPU. In my nation, each cost 500 euros, and I am curious what you think.",
    "comments": [
      "Used 3070 (cheaper than a 4060ti) and wait for 50 series",
      "None of them, preferably.\n\nThe 3070 is a great card for ~$280 USD on the used market\n\nThe 4060ti is horrible value when the 7700xt, Rx 6800, and 7800xt exist (all for less than $500USD)",
      "By nvidias wisdom DLSS 3 = frame gen.\n\nDLSS 2 is at version 3.7.10\n\nThe RTX 3070 has access to DLSS 2 (3.7.10) and Ray Reconstruction which is part of DLSS 3.5 although apparently DLSS 3.5 is DLSS 2 + Frame Gen (DLSS3) + Ray Reconstruction in a whole package.\n\nNvidia is not doing great at marketing this shit.",
      "The 3070 is better at resolution above 1080p by up to 10%. But with the 4060Ti you get DLSS3. I personally would go for the 4060Ti, I prefer more features and lower power consumption.",
      "Thats not always the case. I would still grab one, it's much cheaper in my country",
      "4060TI 16GB - less power consuprion, less heat, 16GB vram, better encoders, DLSS framegen\n\nI wouldn't buy 8GB gpu for more than 280€.",
      "Considering op is not from the US, AMD GPUs might actually not be a great deal for them. Feels like it's only a good deal in the US and some parts of Europe. Where i live, they're much more expensive and much less popular, most retailers don't sell them.",
      "If you know what to check and getting the card from a seemingly clean guy, it will probably be fine. Most of the  knowledgeable miners know how to take care of their GPU's so they'll treat it better than most gamers.",
      "Get the AMD 7700XT or 6800XT. They're both much, and I mean MUCH better than 4060 ti or 3070.",
      "Let’s put them in “hair”\n\nThe RTX 3070 is a person who grew their hair length journey 3 years ago, it’s healthy and reliable.\n\nThe 4060 Ti is a person who grew their “hair” with that 128 bit bus a year ago and when he complained, he asked jensen to help weave others synthetic hair.",
      "Can you not get a 4070 for around the same price as the 60ti?",
      "Most used 3070s weren't doing mining stuff. The 8 gigabytes wasn't good for mining, and a lot of them are being sold because of the 8 gigabyte limit not being sufficient for newer titles",
      "Pretty sure the vram is necessary for larger projects",
      "4060ti, no doubt. I had two (one still here) and very happy",
      "I also looks at AMD cards I love it but I need to use in blender for 3D Models and RTX to play some gameslook",
      "Exactly. In places where all GPUs are priced higher the difference between Nvidia and AMD GPUs becomes thin.",
      "Depends if you need GPU right now. Mid-range Nvidia GPUs are not expected sooner than Q1 2025.",
      "Oh ok. If you need it for 3D modeling, then Nvidia is the way to go. I'd take the 3070 if it's mostly for modeling, and 4060 ti if you plan to play a lot of games (because of DLSS 3).",
      "Or maybe upgrade the cpu and waiting for 50 series?",
      "Well in my country is like 200 euro difference or maybe 250"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "mid",
    "matched_keywords": [
      "3070"
    ],
    "title": "ZOTAC releases GeForce RTX 3090, 3080, 3070 and 3060 TI PGF OC graphics cards - VideoCardz.com",
    "selftext": "",
    "comments": [
      "China only........",
      "It's like the people commenting here don't even bother reading the article, but that's just Reddit for ya.\n\nChina only model. Triple fan OC models. RTX 3080 has 3 8 pin and argb, 3070 and below have 2 8 pin and no rgb.",
      "makes no difference even if they release worldwide, theres no stock.",
      "Hey, look, more vaporware!",
      "\"Releases\"",
      "Actually Zotac stocks in Asia are quite abundant. 3090 are easy to find.",
      "The look",
      "might throw some high power models out in the rest of the world as well at some point.",
      "??????",
      "More power to the Chinese crypto farms",
      "(copy/paste) \nHad a ton of defective fans on the 3080 Trinity. And their firestorm software is really bad.\nTake a look at the r/ZOTAC subreddit around september",
      "For twice the amount of msrp, kinda insane.",
      "look at all these nice GPUs that won't be in stock.",
      "This gen skip zotac. They got caught in a shit storm because they use the worst quality components in their gpu and they keep failing and crashing.",
      "Nope, the scalping wave is over. 3090 are at MSRP and the Zotac cards are at RRP",
      "I'm in Singapore and they're readily available off the shelf at MSRP. Some are already on second hand markets at 100-200 below MSRP",
      ">I know. I just wanted to trigger some snowflakes ❄ 🤙\n\nSomeone time travelled to 2007 when Ben Shapiro complications were considered peak humour for 13 year olds",
      "Just like all the 3080s that are available in retail!",
      "I’ve had good experiences",
      "My MSI 1080 (gaming x) failed after a week."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "mid",
    "matched_keywords": [
      "3070"
    ],
    "title": "[Techpowerup] NVIDIA PCI-Express Resizable BAR Performance Test - 22 Games, 3 Resolutions, RTX 3090, 3080, 3070, 3060 Ti",
    "selftext": "",
    "comments": [
      "A shame they didn't report on 1% lows which I'd argue is just as important, if not more important for most people. \n\nThrough testing a few games with a 5900x and a 3080 I have seen upto a 12% increase in the minimums although it's generally around 8%.\n\nAlso just for reference my test with Cyberpunk saw nobar give me 51 fps just outside the club and 56-57fps with bar enabled, 4k all highest, rtx all on medium with balanced dlss. I saw roughly a 5fps increase scene for scene elsewhere when loaded into a save, tested multiple times to ensure it was consistent with bar on vs off and got the same results each time.\n\nEdit:\nThere is one page of frame times, it was added a few hours after my comment.",
      "Crazy that Gears 5 gains so much. Why didn't they test RTX?",
      "1-2% improvement on a 3090 @4k is a nice free boost. Now to use that to throw more mods at Skyrim.",
      "I have the frametime data, just didn't think it's relevant. Will chart it up for you after dinner\n\nEdit: frametime charts have been added",
      "Why even test unsupported games if you aren't gonna whitelist them using nvinspector?",
      "Yes, some people in Guru3D figured out how to do it. I am not gonna post how to do it here, because mods are removing all posts mentioning it for whatever reason.",
      "Gears 5 is one of the best optimized PC games of all time. It even has multi-gpu support. Not SLI, true multi-gpu. It's crazy how many options there are too.",
      "Gears 5 is actually a lot more demanding in terms of graphical features, by quite a bit. Although DOOM looks and runs great, they do cut corners in graphical features and some things don't look great when you really study them. Both amazing games though. \n\nDigital Foundry has a great video on Gears 5.",
      "Yeah, there's a few that are 2-3% better, which can be gained with a small OC. It's free performance, so I'll take it.",
      "If you read down a little bit you'll see the frametime charts were only added about an hour ago, so not really your fault.",
      ">AMD wants to sell you the overpriced Ryzen 9 5900X. The much more affordable 5800X is actually the faster processor for gaming due to its CCD design.\n\nUh, what?",
      "Yeah gears 5 seems the only game that has actual noticeable difference. Other are pretty much unnoticeable",
      "No downsides unless some bugs or incompatibility happens. Turn it on for the smooooooth min frames baby",
      "Not sure if I would ever call techpowerup clickbait lmao",
      "Even 5% performance gain for what is essentially just a bios upgrade is a big deal. I'm very happy with the extra performance.",
      "Can games be whitelisted for BAR using NVInspector?",
      "Tests likely done using automated scripts running overnight.",
      "Some of us are still playing without variable refresh rate monitors (I’m on a 4k tv), so frame times really make an impact on how smooth it feels. So thank you for adding the frame time charts!",
      "Wouldn't the 5950X technically be the best for gaming? Not a good value, but it should have the best binned CCDs and clocks.",
      "Doom Eternal ultra settings 1440p on a 3080 can run at 240 fps but my monitor only does 144. Easily the best optimized game."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "mid",
    "matched_keywords": [
      "rtx 3070",
      "3070"
    ],
    "title": "US retailer drops prices on GeForce RTX 30 Founders Edition GPUs, RTX 3080 cheaper than RTX 3070 - VideoCardz.com",
    "selftext": "",
    "comments": [
      "\"Price drop\" implies that they've determined a new price point for future sales.\n\nThis is clearance. They're getting rid of stock and not getting more. I'd expect this to be a signal that nvidia told them they're no longer making 30 series chips. AIBs will probably hang around awhile longer, but the stock that's available is it.\n\nSort of makes sense, given they're getting ready to release a stack of products that exist at the same performance point as the old cards. No point in having both on the shelves. Expect price parity with last gen.",
      "Meanwhile in europe lmao",
      "Damn 420 for a 3080 was a fuckin steal.",
      "They haven’t been in stock for many many months in most areas.",
      "Choose (cant have both) \n\n1) cheap / free healthcare\n\n2) deals on gpu prices",
      "![gif](giphy|ISOckXUybVfQ4)",
      "Here in Europe we can still get the RTX 3060 Ti for 450€ or the RTX 3080 for 800€. lol",
      "Oh, so a 3080 going for less than what a 3070 goes for is normal?\n\nThis is called a clearance sale. Nothing about a 3080 for 420 is normal",
      "&#x200B;\n\n![gif](giphy|kFGxSX8HiOkrOcXCot)",
      "Its insane. In canada 3080’s cost what 4070tis cost. The 3090’s are above the 4080’s price.",
      "~950€ for 3080's if they are in stock here in sweden",
      "Lmao",
      "Except it’s not actually free. Still better than what we have though.",
      "Did anyone have any 3080 stock left?\n\nIsn't this just a clearance to get rid of the last of their remaining 3080s in stock?\n\nNot really a price drop.",
      "Pretty sure Best Buy cleared out their stock yesterday when the sale was announced. \n\nWhatever stock they had leftover went OOS quickly.",
      "$420 for a 3080 is an absolute steal.",
      "Nvidia won. By jacking up the price of 4070ti and 4080, they sold all of the remaining 3000 series GPUs and a boatload of 4090s. AMD sat by and let them do it too rofl.",
      "I gave up years ago, not going to buy anything at those prices",
      "😂😂😂",
      "I have never seen the FE in stock at Best Buy"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "mid",
    "matched_keywords": [
      "rtx 3070",
      "3070"
    ],
    "title": "Guys rtx 3070 or rtx 4060ti wich one should i get the cpu will be ryzen 5 5600x  ",
    "selftext": "Thanks",
    "comments": [
      "People here just don't like the 4060ti. I would personally go for the newer generation card if I could.",
      "3070 has more raw power, but the 4060Ti has more forward facing tech built into it like frame generation and better ray tracing performance which means it has the potential to perform better than the 3070 in ray traced games, but for pure rasterised games the 3070 is the better choice \n\n\nMore vram is definitely better, but more vram doesn't necessarily mean better performance. It basically works the same as having more system memory, you only really see the benefit of having more if you were hitting the limit previously",
      "4060 ti 16 gig?",
      "I know it’s an Nvidia sub, but could a Radeon model perhaps bridge the gap you’re trying to get through better?",
      "Hard disagree.\n\nI have a 3070 and I feel very limited since last year in the textures department. Dropping down even one notch oftens destroys the visuals ( The Last of Us Remaster is the perfect example among many others ).\n\nI wouldn't buy a card below 12GB nowadays as it's the standard now on consoles ( and thus their ports/versions on PC ).",
      "3070 easily. More performance.",
      "As a current 3070 owner, I wouldn't recommend it or the 8 GB 4060 Ti if gaming above 1080p for the foreseeable. Get something with at least 12 GB\n\nThe problem with the 3070 and 8 GB 4060 Ti is they have plenty of raw power, but in newer AAA games they are severely hamstrung by their VRAM capacity\n\nHorizon forbidden west for instance chugs in more populated areas and looking at power usage, its evident the core is being severely underutilised due to it choking on the VRAM limit",
      "4060 ti 16GB or Radeon.",
      "The 4060 ti also has 8 gigs unless you spend 100 bucks more for the 16gb, but for that money you should just get amd",
      "4060 ti 16g (dont buy the 8g version because it will age horribly). 4xxx series can do ai framegen, 3xxx can't",
      "Go for 4060 ti, it has more Vram which could prove usefull in future",
      "I would not buy either, but if i had to probably 4060ti only cause of power consumption. There is no other reason to buy it, because 3070 is slightly faster, but there is like 5%. FG will be irrelevant with fsr 3.1 update. Also there is AV1 encoder support in 40 series if you care about youtube atreaming",
      "I have a 4060ti I just purchased, and I'm overwhelming living the performance from it. I'm not really sure what's better at the end of the day, but a 4060ti is a good choice. If you want to go cheaper, I'd just get a 3070.",
      "DLSS and ray tracing aren’t exclusive to 40 series…only frame gen",
      "Perhaps due to VRAM, are you getting the 16GB version? Realistically a 3070 used is cheaper (where I'm from) so the decision is a no brainer, but on 2nd thought, idk abt ur situation.",
      "4060TI 16gb, no doubt. This is coming from a 3070TI owner.",
      "Yes, if electricity is cheap in the area.",
      "They are almost perfectly equal, so just buy whichever is cheaper.",
      "If you're in this price range take a rx6800 or 7700xt",
      "i currently have 3070 and wouldnt change it for that even if it has more vram. id rather buy a used 4070"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "mid",
    "matched_keywords": [
      "rtx 3070",
      "3070"
    ],
    "title": "PNY RTX 3070 XLR8 heatsink developed mold",
    "selftext": "I’m setting up a new pc. Due to scarcity of 50 series, I decided to salvage an old mining rig. I took a PNY RTX 3070 xlr8 out of it and installed to my new system. The moment I start a game gpu gets on fire and system turns down itself. \nI decided to teardown the gpu and renew the old thermal paste and pads. \nI noticed that a white substance developed between aluminum fins. I tried to scape them with a thin knife but it did not work. I also tried to brushed them with a toothbrush with some isopropyl alcohol. Not helpful either. I checked the internet for replacement fins but I couldnt find any.\n\nMy questions are;\n\n1) is this repairable? If yes, how?\n2) Shall I dispose it, I’m afraid that mold might spread to new system. \n3) Will this mold impact the overall temperature of the gpu?\n\nThank you\n\n",
    "comments": [
      "That's not mold, dude.  \n\nThat's somebody, the previous owner, smoking/vaping around their computer.  \n\nIsopropyl alcohol and very tedious scrubbing with alcohol wipes in-between each blade can solve it.",
      "If it's not scraping off with a knife, it's probably not mold. I'd guess it's oxidation from the humidity.",
      "/r/confidentlyincorrect",
      "Plus how are you supposed to visualize how your airflow works if you don't exhale into your pc?",
      "[https://www.reddit.com/r/nvidia/comments/1j56c2r/bought\\_a\\_evga\\_980\\_ti\\_off\\_ebay\\_and\\_boiled\\_the\\_heat/](https://www.reddit.com/r/nvidia/comments/1j56c2r/bought_a_evga_980_ti_off_ebay_and_boiled_the_heat/)\n\nThis guy just cleaned his like this to be weird but in your case it might not be a bad idea.",
      "Why would mold be on a heat pipe? Theres no water or food for them? Just go game at 60⁰ degrees for a few hours and that will kill anything on it.  Not that anything should be on it. Lol 😆 \n\nThe cure is more gaming. Win win.",
      "Hmmm given the circumstances, this might not be a bad idea at all. Thank you for the feedback",
      "Interesting. His card came from a vape smoker and had caked on staining. This worked for him.",
      "I was a GPU miner and I smoked Marijuana and vaped Marijuana around all 36 of my RX 6700 XT and still cleaned them with ultrasonic cleaner and sold them after repadding/repasting.\n\nA mining rig and smoking are like synonymous, bro.",
      "He hadn't said that when I saw it originally, it looks like he posted that in a comment afterwards. He was just vaguely saying something about \"wanting to erase all traces of the prior owner\" originally.\n\nI guess there was a reason for it, seems like it worked then.",
      "Yup, i find this all the time on old cpu coolers, its just oxidization.",
      "That's just fine dust",
      "so that's what makes the 'green' part of nvidia",
      "Maybe i don't vape hard enough into my pc, I'm trying like 12 hours a day right into the front fans and I've only had to dust it once since 2020 😭 where is my mold?!",
      "Lmao “replacement fins”, this guy",
      "Oxidisation. It's bad.",
      "Spray the sink down with straight concentrated Simple Green to soak that gunk off and rinse with super hot water blasted from a sink nozzle or shower head. Use a bristle brush as needed.",
      "Isopropyl alcohol is enough soak that b*tch in it for a 6 hours or smthn let it dry and ur golden",
      "take the heat sink off soak it in isopropyl then blast it with hot water or steam maybe. reapply all thermal pads and paste properly.",
      "🤣🤣🤣🤣 I know right"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "mid",
    "matched_keywords": [
      "rtx 3070",
      "3070",
      "3070 ti",
      "rtx 3070 ti"
    ],
    "title": "MANLI submits GeForce RTX 3080 Ti, RTX 3070 Ti, RTX 3060 and RTX 3050 to EEC",
    "selftext": "",
    "comments": [
      "Ok, and what exactly is the point of the 3070 now that we are going to have a 3060 Ti, 3070, 3070 Ti and 3080? \n\nJesus Nvidia.",
      "All these base and Ti models are just absurd. Having cards at at $200, $300, $400, $500, $600, $700, $800 just seems ridiculous. WHICH ONE TO BUY NOW? Oh yea still none available :(",
      "And around March/April when your 3080 Ti order still hasn't shipped? Wait for 4080? Wait for \"Bigglier Navi\"?\n\nTime is worth something, the \"usable lifetime\" of a GPU is much lower than the physical life of the hardware itself. If you miss 1/5th of the \"generation\" because you were waiting for a \"better deal\" then you might not have gotten a better deal at all.",
      ">HOLD OFF ON BUYING 3080s now\n\nUnless... you can't afford a 3080Ti?",
      "Lenovo also listed the 12GB 3060, it's real",
      "If you're buying a 3050, don't expect to run ultra nightmare texture on AAA games",
      "No special naming; probably just 3060 with 6G and 12G indicated in some spec icon on the box just like the 3 and 6GB 1060.\n\nIf the 12GB is true, the lineup would be confusing AF. Having a 60 series card with more VRAM than an 80 series lol",
      "A 3050 would likely be around GTX1080 performance, 4GB makes no sense at all.\nIt didn‘t make sense in 2016 and especially not now.",
      "RTX3050 4GB? Really? Unless this chip is slower than 1650 super. Vram is gonna be so bottleneck on this GPU. Most AAA games have no problem chewing 4GB Vram now.",
      "Wait...a 3060 with 12GB of Vram? Did they mean the 3070Ti? What would a 12GB 3060 be called?",
      "I don't think I'll be tempted by the 3080ti unless it gets priced competitively at $899 or less. Which it definitely wont even at MSRP the base models will probably be $999+. This card is still very much not worth it for gaming. It does not have enough power to last long enough until the 20gb of vram is actually needed at 4k. I would have liked a cut down 12gb vram 3090 instead if it meant a cheaper price.",
      "Not like it's going to be cheaper",
      "Oh no they are making money\nRip",
      "Yeah that’s weird and also probably unnecessary. It’s not a 4K card. I’m not sure why you’d want 12GB. A 3070Ti I could see having that much.",
      "What are they going to do? Stuff another 10GB of VRAM and sell it for at least $200 more (probably $300)? That's hardly an \"incredible deal\", especially when you consider that this card will likely be obsolete at the performance expectations of most enthusiasts by the time the VRAM starts being an issue.\n\nI got no problems with alarmists getting a card to give them peace of mind with 20GB of VRAM, but pretending like this is going to be a substantial upgrade that should give pause to 3080 buyers is asinine at best, especially when you know just how poorly the GPU scales with a few more SMs enabled in the 3090.",
      "No need to hold off, they already made sure that no one can buy any.",
      "HAHAHAHAHAHAHAHAHAHAHAHAHAHAHAHA good one man iv not had a laugh like that in ages",
      "RemindMe! 9 months",
      ">10 gb ggdr6x\n\nLike Gamers nexus said Bandwith is more important.",
      "> I’m not sure why you’d want 12GB\n\nbecause 4K/8K texture packs are an easy win for quality even if you are rendering at a lower resolution, and it will probably contribute an extra year or two to the viable lifespan of the card before you have to seriously reduce texture quality.\n\nSeriously, do you *need* it?  No.  Is it *nice to have*?  Sure.  I'd pay $50 more even on this tier of GPU for twice the memory, without hesitation.\n\nI also think that if the 3080 Ti winds up being $999 MSRP, the smarter option is just to suck it up and pay for it, the extra VRAM will give the card 1080 Ti-like longevity compared to the 3080.  I'd take a 3080 Ti FE over an aftermarket 3080 for the extra $150 or whatever."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "mid",
    "matched_keywords": [
      "rtx 3070",
      "3070"
    ],
    "title": "Planning on upgrading from a RTX 3070, what's a good option for the least amount of money?",
    "selftext": "I'm looking to kill 2 birds with 1 stone this black friday buying an upgrade for my graphics card so I can swap my 3070 into my brothers PC and buy a better performing card for myself.   \n  \nThe problem is I don't want to spend too much money and (from what I could gather) I'm scared that my 3070 could perform similarly or even better than some of the \"cheaper\" 4000 options I'm seeing, making it a worthless buy for me\n\nCan anyone recommend me a \"cheaper\" nvidia graphics card that it's 100% an upgrade from the 3070? (I don't mind if it's not by a high margin)\n\nThanks!",
    "comments": [
      "Wait for the next generation early next year",
      "I bit the bullet and got a 4070TiS because I have a 3060 Ti with 8 GB of VRAM but I'm on 1440p and it is struggling.\n\nThe 5000 series does not look hopeful at all, NVIDIA is really letting the greed take over this go around. That and they stopped producing 4000 series, now is the best time to get a card. If you want truly future proof get something with 16GB of VRAM so you can stay ahead of the curve.",
      "The 3070 is comparable to the 4060 Ti, so for your new card to be better than what you have currently, you need to look at least at a 4070 ($500-$550).  Higher up the product stack would be the 4070 Super ($600) and the 4070 Ti Super ($800).",
      "I just upgraded my 3070 to a 4080 super. But I wanted a LARGE upgrade. \n\nThe most sensible and significant upgrade would be the 4070 ti super because it gives like 50% performance uplift, which in turn would last you longer.\n\nThen, a 4070 super would be a good frugal purchase that provides a meaningful increase in performance, though should still last you a good while.\n\nDo not consider a 4060 or 4060 ti. It would be a side-grade. There would be more performance, but not enough to warrant spending the money.\n\nJust go to YouTube and type in \"3070 vs 40xx\" then watch game benchmarks. See for yourself if the fps increase is worth it to you. \n\nThe 4070 ti super bangs, and would last you a much longer time, but it is quite expensive. The 4070 Super is a really good card, costs a good bit less, but wouldn't last QUITE as long. Though should still last you several years and provide a decent but not huge performance uplift.",
      "If you want a noticeable uplift go for the 4070 super, 50% more performance and VRAM without breaking the bank assuming you find a good sale.",
      "If you are dead set on Nvidia 4070 Ti Super\nIf you are open to AMD then a 7900 GRE at minimum.",
      "12GB isn't on its last legs yet when it comes to 1440p, far from it. 4070tiS is a 4K card right now and while it is a good investment for those of us who keep GPUs until they age out most people upgrade consistently and by the time 12GB won't be enough for 1440p they'd have another card already. 6070/7070 imo",
      "That's what I did and I'm happy with the upgrade.\n\nSomeone else suggested a 4060, I think that will be a downgrade and in best case a sidegrade unless you go for the 16GB version then at least you could have use for the extra VRAM.",
      "7900 GRE is comparable to 4070 Super, whilst 7900 XT is comparable to 4070 Ti Super.",
      "Anyone recommending the 4060 or any 8GB card for 1080p nowadays doesn't deserve to have their opinion be taken seriously.",
      "What rando is that? Watch reliable sources of information like Gamers Nexus or Hardware Unboxed. New releases will in fact demolish 8GB cards unless you turn down textures, this has consistently been the case for a while now in games like AW2, DAV, COD6, FFXVI and basically anything that isn't a PC port of a console title.",
      "Nice! thank you for the advice. Some people suggested me to wait for the new 50xx, but wouldn't they be even MORE expensive??",
      "I have a 3070 and this was my thought process. Luckily I had means to getting a new 4080s at $900 before black Friday sales. I am seeing sales for 4070TIS  around $700 now and been thinking about returning the 4080s since the dollar per value is incredible for my upgrade. After seeing the \"leaked\" speculated stats I am still very happy with either purchase.",
      "Since I'm looking to get (probably) a 4080 Super for an upgrade too I'll ask here: which one should I try to get my hands on? Is there a brand to avoid for any kind of problems?",
      "Most games on UE5 right now, even on 1080p are hovering around 8GB. I go to 1440p and I have to drop things down to low/medium and throw on DLSS to get stability with 8 GB. If I got ot 1080p I can almost max things out but not fully. \n\n12GB is the new bare minimum going forward and NVIDIA doesn't care. They are just going to pump and dump the deep pockets with the 90 series.",
      "Yeah I got mine after tax for $834. I went with a Gigabyte model since my MOBO is Gigabyte so I can control everything with the same software.",
      "4060ti should've had 12GB from the start, pointlessly giving it 16GB and then charging as much as for the 6800XT was definitely a decision of all time.",
      "Perfect, thanks!",
      "Intel is expected to release new GPUs next month and AMD and NVidia are expected to release new GPUs in January. So there will be more options if you can wait a few months.",
      "Anything from the 4070 and up will be a noticeable upgrade in all respects. So get whatever you can afford with that as the minimum. Can you afford a 4070 Super? Cool, get that then. Can you afford a 4070Ti Super? Then get that, the 16 GB of VRAM will make it age better (getting a 12 GB card now is the equivalent of getting an 8 GB card in 2020 so keep that in mind)  Etc etc"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "mid",
    "matched_keywords": [
      "rtx 3070",
      "3070"
    ],
    "title": "RTX 3070 FE size comparison vs AIB cards.",
    "selftext": "",
    "comments": [
      "The Asus is a chonker.",
      "so that's where all the 3070s are.",
      "Because Asus reuses the same cooling solution as strix 3080/3090. Probably makes sense since they don't need to develop different cooling solutions for different cards.",
      "The FE is the most viable for itx. It's the only card for my case since the others are too wide.",
      "I’ve seen a few LTT videos now where Linus has said “We have to give this one back.”",
      "Is it bad I'm slightly annoyed at all these tech Youtubers who have cards they're not going to use/going to use for memes e.g. LTT?",
      "Also they allegedly had very little time to develop their cooling solutions so they probably only had time to design a one size fits all cooler.",
      "3070 FE isn't quite as good looking as 3080/90 FE imo, but it's still a brilliant design. I'd have it.\n\n*sadly holds $500*",
      "Not every country even has FEs as an option.\n\nMakes you wonder what's up with that. Why even have FEs if you're not making enough to, well, sell them to everyone. Feels more like a forced scarcity marketing ploy.",
      "And the FE was called ugly. It's a nice piece of engineering even if it doesn't quite keep up with the larger HSFs the AIBs use.",
      "Well, AIB prices have already gone up atleast in EU. Because there are practically no FEs available, only a lucky few will get a 3000 series card at MSRP. \n\nSince Nvidia has the 3080 in their store marked at 739€, everybody talks like it is a \"739€ card\". Although no one can actually have it at that price.",
      "Haven't seen the 80 in person, but I disagree.  The 70 is *stunning* . I'm sad I have to put it in a box. I want to admire it",
      "As someone with an ITX case the lack of pure 2-slot 3070 and 3080 options outside the FE is maddening. I basically don't have any choice.",
      "Hey, I know [that background](https://youtu.be/vK6QrnOKGKE).",
      "For the 3070, Zotac Twin Edge and Gigabyte Eagle are dual slots as well.",
      "They didnt stop making FEs any other year, idk why they would now",
      "Why do people keep saying forced scarcity. If they could sell more they would. They aren't benefiting from limited supply only the scalpers are",
      "No one said they would stop making them",
      "I paid 830€ to get my TUF non OC where I am. The good thing is it came fast(I have it for 3 weeks now) and what's funny is that the price hiked more. It's currently 890€ to get a tuf here.",
      "thats not a STRIX  \nTHATS A THIXX !!  \nbig ol thicc boi"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "mid",
    "matched_keywords": [
      "rtx 3070",
      "3070"
    ],
    "title": "RTX 3070/3080/3090 Brand Comparison - Buy \"Decision\" Aid : I have updated all three files based on some good suggestions and also included a comparison between the 3070/80/90 together with the two Brand/Styles that show up for all three. Thanks for all the comments, suggestions and appreciation!!",
    "selftext": "",
    "comments": [
      "Buy decision: availability.",
      "I wouldn't shop by frame rate differences, between these cards. It's hardly noticeable. Customer service reputation, cost, cooler efficiency, and decibel levels are the only important factors.\n\nAnd I wouldn't worry about stock overclocks, either. Even if you don't want to dedicate a couple hours of testing to OC, GeForce Experience has a built-in OC scanner, now. And you should be setting custom fan curve whether you're overclocking or not.\n\nIMO, it really comes down to customer service reputation and cost.",
      "that's really when you see them side by side that you notice that the 3090 is really a bad choice",
      "[Always has been](https://i.ibb.co/Pxt25qz/dc538a7811ff.png)\n\n^^^this ^^^has ^^^been ^^^an ^^^accessibility ^^^service ^^^from ^^^your ^^^friendly ^^^neighborhood ^^^bot",
      "Always has been",
      "Yeah, l seriously. I just got an Asus Tuf 3070 today... because over the last two months this has been literally the only card of the 3070/3080s I have been able to purchase.",
      "EVGA. I can call them on the phone speak to a real person and set up an RMA on a Saturday.",
      "Yeah, the best to worst difference is only a couple frames... realistically that is pretty meaningless.",
      "Good bot",
      "Yes, that is totally correct. There is a $1000 difference between the two cards and less the an average 10fps difference. So basically, you are paying $100+ dollars for every extra single frame above the 3080 average.",
      "IMO and in no particular order: ASUS, Gigabyte, EVGA\n\nMSI is a company run by weird management and has suffered from weird mishaps for the past few years. Although I liked my MSI Sea Hawk X 1080Ti, I wouldn't recommend them right now.\n\nZotac and PNY have a reputation for cutting corners.",
      "I learned about the thermal pad fix for evga 1080's a few months ago.\n\ngot my card though step up (picked up a 980 with like 2 months and some days before the 1080 was announced, still within enough time), needed the thermal pads. I emailed evga on my 4 year old card and asked like \"do you have recommendations for thermal pads I can buy\" assuming there is no way in hell they would send me them.\n\nthey said \"yea, I think we can get you a kit, we probably don't have any thermal paste though\" and I was like hell yea.\n\ngot it for free (not even shipping cost), it had paste too. now im just hoping to limp it along long enough to get a evga 3080.",
      "In my rush to get his out before the weekend I forgot to fully color code the 3070/3080/3090 comparison. The different color area has no significance. I will correct this and fully color separate next update. Also, I did add the MSI RTX 3080 Suprim X to the 3080 comparison which was newly reviewed by TechPowerUP. Have a good weekend!!",
      "I ended up using the OC Bios across the board on this one",
      "asus for worst customer service",
      "Thank you for taking the time to do these. Super useful.",
      "Looks like MSI really nailed these cards. Both 3080 and 3070 good. I would buy FE or MSI. Price, performance and temp, noise best on those.\n\n&#x200B;\n\nThough i'm enjoying my Asus Strix 2080 OC with Phanteks waterblock. Asus Strix board and vrm's are beefy, max power capability good. Added +90 mhz to core, 1100 mhz to memory, working like a beast for years. Probably faster than 2080S. 2080 benefits a lot from memory oc.",
      "should be sticky, but why do EVGA Ultra went from 31 to 34 db ?\n\nalso FE went from 41 to 36 db ?",
      "How does the final ranking work?",
      "That’s why I did it, I’m definitely feeling it for wanting a 3090, lol"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "mid",
    "matched_keywords": [
      "rtx 3070",
      "3070",
      "3070 ti",
      "rtx 3070 ti"
    ],
    "title": "[HUB] Which Was The Better Buy? Radeon RX 6800 vs. GeForce RTX 3070 Ti: 52 Game Benchmark, 1440p & 4K",
    "selftext": "",
    "comments": [
      "I love my 3080, but I'm really hopeful that AMD's next generation is competitive because I'm sick of giving Nvidia my money. Their business tactics range from shitty to beyond scummy.\n\nEdit: my first card was AMD (480). I went with NV this generation for ray tracing and AI upscaling, which were what I was referring to by \"competitive\". Ik AMD cards win in traditional rasterization but they gotta catch up in other ways.",
      "TLDW:\n\nRX 6800 - 50 games head to head vs RTX 3070Ti\n\n5% faster @ 1440p\n\n3% faster @ 4k\n\n*SAM was enabled for the RX 6800 and Resizable BAR was enabled for the RTX 3070Ti",
      "no. the all around package/features, ray tracing and dlss are way better on nvidias side. so sadly i still need to stick to nvidia.",
      "Ray tracing is not useless. RT is graphics, like any other graphics setting. The point of new gens of GPUs is to improve the graphics",
      "I see 83% here, and 62% on the AMD subreddit \\*shrug*",
      "I agree with the sentiment, but I don't think it's correct to imply AMD was not competitive this generation. There are a couple of things--RT and DLSS--that Nvidia owns, but other than that, AMD holds it own and sometimes wins--especially in 3090 vs 6900 XT gaming performance. If you don't care for RT or DLSS, AMD is a very good option. My bigger issue with AMD, though, is driver stability. Dealing with that should be a very close #2 priority after beefing up performance! I say #3 and #4 for AMD should be improving FSR and Ray Tracing, respectively.",
      "Same. I had to get a 3080 since it was the only real option for 4K gaming this gen.\n\nFSR 2.0 didn't exist in 2020, and even now, DLSS is still better. AMD doesn't have competitive RT performance either.\n\nI'm hoping performance is close with the next series so I actually have a choice as to who I go with.",
      "Inferior ray tracing performance and can't use DLSS.",
      "It does not look as good, I would never want to use it unless DLSS was unavailable. The only thing that is getting close is XeSS, and it's still behind DLSS for now.",
      "By your logic then the dynamic shadows that were firstly used in a successful manner 18 years ago in Doom 3 are useless and a gimmick. I guess we should have stayed with static shadows and 2D sprites...",
      "Nvidia and Intel are both looking into using the Tensor/AI cores for additional innovative applications beyond just upscaling.\n\nAI based research also advances extremely quickly, DLSS and XeSS will at some point look indistinguishable from native res with larger performance uplifts.\n\nFSR will not reach parity until they have AI acceleration hardware. Intel hasn't reached parity for now, even though they've had Nvidia's groundwork laid out since 2018.\n\nAs far as I know AMD makes no substantial investments into AI, still have not said anything about adding dedicated hardware for it. They are so far behind.",
      "Raytracing destroys framerate on AMD cards.  That's why AMD cards are bad.  You've literally bought a bad card and you're trying to make excuses for it.",
      "Wow, non-xt 6800 is faster? I just bought a 3080 12gb, maybe I should have bought a 6800 xt.",
      "Announced, yes, but still 3000 series is not widely available, I doubt that 4000 series will be readily available at a normal price.",
      "RX 6800 was also unique in that it was fast, while being by far the most-energy efficient in terms of frames/watt",
      "True.\n\nI think DLSS won't be a big deal with FSR 2.0 ultimately while yes, I acknowledge that DLSS offers better image quality. It's ray tracing that makes me stay away  from AMD's RDNA 2 high-end options and hesitate to recommend them. The architecture doesn't deal well with heavy RT effects like GI or reflections. Most AAA games are going to utilize ray tracing going forward, and to be always trailing Ampere in this area sucks, even if FSR reaches picture quality parity with DLSS.\n\nRDNA 3 should improve massively in ray tracing compared to NVIDIA tier for tier or they're not gonna sell well unfortunately.",
      "So basically, \"I won't touch AMD unless Nvidia completely fucks up\"",
      "Even if you don't intend to play and/or turn on ray tracing in games, the option is still there for you try it out and see if it's worth it. I wasn't really thrilled about ray tracing 2 years ago, first reason being that there were no games I play that featured it. secondly, I had an RTX 2070 SUPER, it's still a capable GPU, but I'm the 1440p high refresh rate max graphics settings guy and also own an LG 4K 120Hz TV. Once I upgraded to the 3080 Ti, I started to appreciate ray tracing now that there are a bunch of games (Cyperpunk 2077, Spider-Man etc ...) that I play in addition to DLSS in playable frame rates.\n\nRay tracing simply makes NVIDIA RTX 30 series more valuable than Radeon cards, thus, AMD should price their cards accordingly. I'd buy a 6900 XT over a 3070 Ti if they're priced closely and I don't give a crap about RT.",
      "Mad",
      "How is the 3000 series not widely available? There is excess inventory all over the place and they are back to bundling games to entice buyers."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "mid",
    "matched_keywords": [
      "rtx 3070",
      "3070",
      "3070 ti",
      "rtx 3070 ti",
      "3070ti"
    ],
    "title": "Is a Zotac RTX 3070 Ti worth $200??",
    "selftext": "Just looking for opinions?\n\nMainly going to be used for multiplayer FPS games like Hell let loose and PUBG?\n\nI used to have a 3080ti and currently use a 4080s. Never used the 3070ti.\n\nThanks for any input?",
    "comments": [
      "You should be a writer for a tech blog. This is such an eloquent explanation.",
      "So imagine a card with less frames than the 3080ti, that should answer your question.",
      "Yeah, it's a great deal",
      "it’s a good price for the card.",
      "You should be a **adviser** to a writer of a tech blog",
      "That's a great price, i love you zotac gpu. I'd say its worth it. Get great 1080p performance with it. If you dont like it you can resell for profit or a quick flip to break even",
      "Good price for sure, still a pretty decent card",
      "That's a good price but I'm unsure why someone with a better card would wish to downgrade. Trying to sell it the 4080?",
      "In Germany 3070 goes for around 290€ used.... I say 3070ti 200$ is very good price. Make sure it's in good condition?",
      "I sold a 3060 Ti for more than that a month ago",
      "Hell yes",
      "No this is for a cheap rig at my.job when there's nothing to do and the airplanes are out flying",
      "I just sold a 2070 for $200",
      "Depending on use case, absolutely that can be a steal. Only real issue is the 8gb of vram.",
      "Yes, that's a good value for that GPU.",
      "Why would you want a 3070ti if you have a 4080 super?",
      "Rig for work when the airplanes are out flying and I have nothing to do."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "mid",
    "matched_keywords": [
      "rtx 3070",
      "3070"
    ],
    "title": "RTX 3070 Best Buy \"Reserving Item Status\" Info update",
    "selftext": "This should cover it all for Best Buy \"Reserving Item Status\"\n\nI just chatted with BB, \"Reserving Item\" it means there isn't current inventory and they are expecting a shipment at which point they will fulfill the order. The 11/5 date is an estimate. THEY WON'T CANCEL THE ORDER (the 10 day thing is a myth) for any reserving item orders. It is treated like a backorder and they will fulfill it once they have the inventory. I confirmed that reserving item orders will be filled before any new orders will be taken/fulfilled. They are at the mercy of the supplier Nvidia, like other retailers they receive shipments on a weekly/daily basis it is all handled in a software system (OMS/WMS and then pushed to an ERP) with a PO and they are provided with X # of items and an estimated delivery date.\n\nNow with the mess Nvidia is in and the issue with Supply Chains, especially China this could take time. My guess they will push out inventory as soon as it is off the manufacturing line. The good news is the 3070 FE is only through BB which should help the issue as there won't be other retailers that are promised inventory shipments and Nvidia isn't selling the card direct off their site. I can speak to this as I have sold software into manufacturers. Now if you want to know where any manufacturer gets it supply from you can use this [https://www.importyeti.com/](https://www.importyeti.com/) it tracks shipments from and quantity it is a scraping tool. It won't have every supply order but, it is how you can tell where supplies are coming from for Nvidia.[https://www.importyeti.com/search?q=Nvidia%20Santa%20Clara%20Branch](https://www.importyeti.com/search?q=Nvidia%20Santa%20Clara%20Branch)\n\nBB Chat: [https://imgur.com/5Ozbz87](https://imgur.com/5Ozbz87)\n\n This is my set up as of now, the desktop is awaiting [https://imgur.com/drIHSN2](https://imgur.com/drIHSN2) ",
    "comments": [
      "Mine now says \"Getting Ready\" and \"Arriving Thursday\" after saying \"Reserving Item\" for more than 24hours.\n\nEdit: Just got an email that my 3070 shipped!",
      "My order changed from reserving to getting it ready only like 15-20 minutes ago. it was on reserving for more than 24 hours",
      "Still showing reserving item status 7:04 am as of 11/4. I am in the 9:14 am launch confirm camp. I will reach out to BB today and report back.",
      "Lucky. Mine is still reserving item sadly 😢",
      "Good for all the people who's order status is changing. Hmm I got my order completed yesterday at 9:08-9:10 am and it is still in reserving item status.",
      "I’m from Illinois and right now mine is still in “RESERVING ITEM”. Spoke to a customer support representative over the phone today and they said that there is a 90% chance that within the next 24 hours it will change to “GETTING READY”.  So for now I’m still saying really hopeful.\n\nUPDATE 10/30 6PM: Just got an email from Nvidia saying that they had to push my order back to November 20",
      ">THEY WON'T CANCEL THE ORDER (the 10 day thing is a myth) for any reserving item orders.\n\ni have a reserving order\n\ni just got an email that says its been delayed till 20th or sooner due to low stock and also:\n\n\"We will keep your order open and continue to work on getting your item(s) to you until Friday, November 20, 2020. If your item(s) are still not available by this date, we'll cancel the item(s) and notify you via email.\"",
      "I also received the delayed e-mail and will be cancelled after November 20th if they cannot get the item. Ouch.",
      "MY ORDER SHIPPED 9:14 GANG",
      "Fuck Nvidia for all these issues. Fuck eBay for making them worse.",
      "Yes... cause it shipped",
      "Lets hope, my new build is begging me to replace my 2070 Super FE. I just finished the build about 1 1/2 weeks ago. I wish I waited for the 5600X chip it is sick, oh well the 3700x is fast enough for mixed work and gaming. That and I picked up the Asus G14 this week for work with the 2060 max Q and the Ryzen 4900HS it is sweet. It seems they ironed out some of the early issues with BIOS firmware updates. I haven't gamed yet to see if it fixed the heat issues if not I will do the Registry power management fix for it. This is my set up as of now, the desktop is awaiting [https://imgur.com/drIHSN2](https://imgur.com/drIHSN2)",
      "Best Buy is the only place selling the 3070 FE online. According to the 3070 launch thread, Microcenter had some in store too.",
      "Mine just changed to getting it ready as well after almost 30 hours of being reserved!",
      "Are you sure it’s only BB? I bought my FE on day 1 at Microcenter near here",
      "Getting ready and arriving Thursday... DFW area. Bought the gigabyte card",
      "What's the verdict boys I'm still hoping for a miracle I've been keeping a close eye on this post like a hawk actually anyhow I just hope we all get ours tomorrow which is the 5th exactly a week since most of us beat some bots,, I highly doubt it but I'm praying for us pretty interesting how you guys came up with that method of figuring out the different batches and whatnot lol only people like us...???",
      "Here is my theory of what I think happened on launch day. The staggered stock release was based on the expected inventory arrival on staggered dates from Nvidia for the 3070 cards. With a PO (purchase order), x number of items are purchased with a expected arrival date. As we know they pushed the launch date back to try and have more 3070 cards for launch. \n\nThat means they are getting new cards manufactured as fast as they can. I believe Nvidia told BB they would have  expected inventory available on certain dates  based on what they expected to have produced. Hence people getting different expected delivery dates on launch day. It went in chronological order by order confirmation times. They fulfilled orders with stock on hand. So based on them getting inventory at different times, they expected restock b4 11/5 for those of us with that expected delivery date, and it didn't come in as we all know. I haven't heard anyone with a 9:14 order confirmation on launch day move out of reserving item status. Let us hope the 2 BB reps I connected with today are correct about us having updated information tomorrow.",
      "Just got this info via BB chat (my order stills shows reserving item) the rep looked it up here is the deal. 9:14 am launch day confirm crew.\n\nBB Rep from Chat: Good news! I see that the item is packed and ready to go and is queued to be picked up by the carrier. You will see the exact get it by date reflecting in the order details screen as soon as the carrier updates the delivery and you will be able to track your order as well. There is no need to worry as the order will not be cancelled .\n\nChat Log BB Screenshot:[https://imgur.com/9YPlm00](https://imgur.com/9YPlm00)",
      "Chatted with BB said I have a estimate before 11/30\n\n9:14 gang"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "mid",
    "matched_keywords": [
      "rtx 3070",
      "3070"
    ],
    "title": "I have an RTX 3070 and want a 4070 ti super - is this normal?",
    "selftext": "Partially serious question.\n\nI guess I just want more. How do I resist it? Should I?\n\nFor anyone looking to give constructive feedback: I play newer games 1440p with a 13600kf\nPotentially looking to go for VR in the near future.\n\nAlso I have a 635w PSU. The 13600kf is undervolted and usually maxes out at around 70w. Should be safe, right?",
    "comments": [
      "if you have the money go for it.. why not? it's a big improvement over the 3070 and you will make us of its performance @ 1440p.. People will tell you to wait for 50 series.. but nobody knows when they release and what they will cost.",
      "Nonsense, a 3070 it's Even now, After 4 year, a very good GPU for 1440p, save some Money, update that psu and wait for the 5000.",
      "Also the 5000 series is going to be so enthralled with the AI boom. It'll be like crypto again. Go ahead and upgrade while you can.",
      "nvidia rly fucked us over with the 3070 8gb.\n\nmaking us wanting the 4070Ti 16gb even more",
      "I feel you, i have 3080 and I'm quite tempted by 4080 super.. Most people are saying I should wait, until the end of the year/beginning of next for 50 series to release.From other side - Nvidia said there will be limited supply (because they'll mostly focus on their ai pro GPUs that they can sell for 10 times the price) , then for sure there will be scalpers first few months, and then because AMD is dropping out of the high end Nvidia can basically be unchecked on price on the high end. \n\nAll that considered I will not be surprised by another 30% increase in pricing or/and limited supply, so you won't be able to purchase them anywhere near MSRP for the first half a year to a year... \nI really hope I'm wrong though.",
      "Thank you for reminding me what I told myself when buying the 3070! I told myself I'd make it work for a few years at least. And already I am looking at the hotter stuff next door..",
      "Because if u already have a good GPU it has no sense to buy now, wait and save some Money.",
      "If you don't play at 4k, you don't need to upgrade right now. You'd be upgrading and spending a lot of money on FPS numbers and not actual gaming experience.",
      "Next year?? We still only half way through this year and they are saying early 2025. Why are so many people saying wait 8+ months?",
      "Yeah it’s gonna be a 1000 dollar 70 series card that’s gonna be sold out for the first 4 month and if you wanna buy it you will probably have to spend 1400 bucks because bots scalp it",
      "german detected.. no one else talks about energy costs.. besides maybe the danish",
      "Unless its 50%+ performance increase, it isnt worth it. There are both pros and cons to upgrading. 5000 series will probably be heavy priced. On release, most msrp cards will be sold out and youd have to add more or wait a bit more. Suddenly, 6 months turn into waiting game of 8 months+ to get a gpu.",
      "Depends on your mindset and what you want.\n\nPeople tend to fall into two categories, those who buy midrange cards and upgrade every 2-3 years, and those who buy high end cards and ride them out until the performance drops significantly, upgrading every 5-7 years.\n\nOn my older PC I had a 1080ti and daily drove it until my next upgrade, the 4080Super. This thing was keeping ground even with the 30 series GPUs from Nvidia (lower end, of course). Once the 40 series dropped and it was apparent even an OC, balls to the walls 1080ti couldn’t compete with a 4060 at stock, it was clear to me to go for an upgrade. It was about 7 years or so that card lasted me. \n\nThe 3070 is more than an acceptable card for 1440p Ultra. What you need to ask yourself is what you want out of the upgrade. Are you doing it just because the 4070TiS is better and newer and cooler? Because eventually we will be reading a reddit thread from you in a year or so going ‘I have an RTX 4070TiS and want a 5070Ti - is this normal?’\n\nWhat I mean is upgrading just because it’s newer is going to lead to the same kind of buyers remorse that a lot of people get. Always buying a new card without having a specific reason.\n\nOn the flip side, if you’re upgrading because you wanted to go to 4K, or you were noticing you couldn’t maintain 60FPS at 1440p even with lowered settings in games, or there were specific performance issues you noticed, then yes a newer card will play and feel better.\n\nIn my own personal opinion, it’s not the upgrade I would go for. It’s just not enough of a performance improvement for me to upgrade a card I had just purchased. Nobody knows what the future holds, but a 50 series refresh card might come out at a great price point and performance boost, maybe that would be something I’d go for. Like a 5070 Ti Super or 5080 Super. The 5080 and 5090 are going to be scalped to high heavens and I feel like even those cards would lead to regret, because you’ll overpay for cards that will be superseded by their Super and Ti versions months/a year later.\n\nAnyways, that’s just my two cents. A lot of times people ask these questions and they’ve made up their minds and are looking for justifications. Just buy whatever you want, you don’t necessarily need us to say whatever because the card isn’t for us. I wouldn’t do it, but maybe you would and you’ll enjoy it. Maybe you’ll regret it. Impossible for us to know, only you truly know what you want.",
      "Similar position with a 3080ti. Even going to a 4070 I’d see a decrease in power usage and definitely an increase in performance, but I’m not entirely sure it’ll make that big of a difference. \n\nI’m waiting personally, but I also have an i9 9900k too. Honestly, for me it’d be better to upgrade cpu and go to ddr5 ram first. There’s nothing I can’t play and aside from maybe gray zone warfare, there aren’t too many games that I play that really tax my system that hard in its current configuration.\n\nI say wait, get your money’s worth out of the gpu you have and upgrade when there’s a larger benefit  to performance and prices have dropped or stabilized. Especially if you’re not encountering games that won’t run on your current set up. \n\nIm just holding out for a 5080 or 5080s or whatever equivalent nomenclature they use for next gen",
      "Yea right? Might have been a sup optimal purchase decision.\nBut it certainly beats the 2x GTX 970 SLI\n\nAnd ~100w in my most played game @1440p 144fps (dlss) really helps recoup the costs in energy savings",
      "That's a very sensible take. I guess I'll just wait for a few more years (or a big unexpected bonus at work!)",
      "Thanks for the advice!",
      "Sorry typo, it's actually 625w exactly 🫡",
      "Damn you could be an Nvidia salesperson.\nTry and arrest my will to resist temptation! :P",
      "I already do :P"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "mid",
    "matched_keywords": [
      "3070"
    ],
    "title": "Should I go for RTX 3060 12gb or 3070 8gb for editing and stuff ",
    "selftext": "Everyone is saying 3070 is way faster than 3060 but people are also saying you need more Vram for editing and also for good performance in future updates ",
    "comments": [
      "The 3060ti is closer to the 3070 than to the 3060 and it also has 8Gb so it's not actually a good equivalent",
      "This guy is editing not gaming, which I think vram might be important for",
      "If you're already going used? Then also consider the 2080 ti usually goes for about the same amount performs similarly to a 3070 but has a few more GB of vram.",
      "Not RTX 3060, but Puget systems compared the RTX 3070 vs the RTX 3060 Ti: https://www.pugetsystems.com/labs/articles/DaVinci-Resolve-Studio---NVIDIA-GeForce-RTX-3060-Ti-Performance-2021/?utm_campaign=DaVinci%20Resolve&utm_content=154444208&utm_medium=social&utm_source=facebook&hss_channel=fbp-75534321610",
      "better 4060, way faster encoder",
      "This’ll be your answer OP. They run some of the best benchmarks for this.",
      "What if he buy 4060Ti 16GB then?",
      "Why don't I just buy Nvidia server 🫠\n\n\n\nBro price 💀",
      "20, 30, 40. 2080ti is from the generation before the 30 series.",
      "For Adobe premiere I don't know if it matters much.  For Daviinci resolve vram actually matters.\n\n\n\nI could get by doing 4k on a GTX 1080 with resolve 2 years ago.\n\n\n\nWhen I started using more effects and 6k open gate footage and rtx3090 is barely enough, and I'll definitely have to restart resolve to clear out the vram.\n\n\nIm also running an Intel i7 8700k that came out late 2017 so I'm sure that hurts things.",
      "AMD’s cpu’s are borked on naming, but the gpu’s are just RX 5000, 6000, 7000, and soon to be 8000",
      "What? How is RX 5x00, 6x00, 7x00, more difficult than RTX 20xx, 30xx, and 40xx?",
      "For editing... what?  \nIf you edit photos a 4060 is going to be fine.  \nIf you game, a 3070 is much faster.",
      "Go for the RTX 3070 with 8GB of VRAM. While the 3060 has more VRAM (12GB), the 3070 is much faster overall, which is more important for editing, 3D work, and future updates. Unless you're working with huge files like 8K footage, the 3070 will give you better performance and long-term value.",
      "I’d choose the 3070. I had to think about that one for a minute. Much better performance in games, but you’ll have to turn down settings (maybe just textures), vs. with a 3060 using ultra textures and low settings…yeah I’d choose the 3070.",
      "Long term value with 8 GB VRAM? Are you insane?",
      "It's not about the price, I just want to know about how much does \"Vram\" make a difference in editing \nI know 8GB is okay for gaming now",
      "It's expensive because nvidia stoped making 3070 😮‍💨 even second hand is pricey 🫠",
      "This is the first time I am buying a GPU or a PC for that matter so I don't know how much power I need actually so I'll just go with RTX 3060 12 GB\n\nIt's my first time so let's not over spend on think you don't need",
      "You didn’t name any bad ones lol. Those ones all follow the same scheme as previous gens."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "mid",
    "matched_keywords": [
      "rtx 3070",
      "3070"
    ],
    "title": "Need Advice on Upgrading from RTX 3070 for 1080p Gaming",
    "selftext": "Hi everyone,\n\nI'm currently using an RTX 3070 and considering an upgrade. I primarily play games at 1080p and can use DLSS when fps is not enough in native, but I don't plan on using frame generation at all. Here are the options I'm looking at:\n\n1. **Wait for Asus RTX 5070 Ti Prime (690,000 KZT / \\~$1373 USD)**\n   * Cons: High price and need to wait for availability.\n2. **Buy Inno3D RTX 4080 Super iChill X3 (580,000 KZT / \\~$1155 USD + 60-80,000 KZT / \\~$120-160 USD for PSU)**\n   * Cons: Additional cost for PSU, not an Asus.\n3. **Buy Asus 4070 Ti Super Dual (450,000 KZT / \\~$896 USD)**\n   * Cons: Lower performance compared to 4080, but still sufficient for 1080p.\n\nI bought my RTX 3070 during the mining boom (2021 or 2022) for 500,000 KZT (\\~$995 USD). I'm a fan of Asus and prefer their products, but I'm open to suggestions. What do you think is the best option for my needs? Any advice or personal experiences would be greatly appreciated!\n\nThanks in advance!\n\nP.S. i can sell my 3070 for 150,000 KZT (\\~300$) to my friend  \nP.S.S. Running a system with a 7800X3D  \nAlso i am talking about maxed out graphics with RT\\\\Lumen\\\\ETC, and 3070 is not enough for these nowadays.  \nAlso there was a cases when 8GB was not enough and i got a crash with an error bc of that 💀 GhostRunner 2 and Resident Evil 4 Remake for example.",
    "comments": [
      "For 1080p the 3070 is still good",
      "I'd go with 4070super or 4070ti super, but even the super will be more than enough for 1080p\n\n4080super is good enough for really enjoyable 1440p\n\nkeep in mind at 1080p your cpu might get taxed quite a bit more aswell\n\nbut honestly is the 3070 not enough for 1080p?",
      "\\>Not a problem for a 7800X3D i guess.\n\nWith those cards at Full HD, it definitely can be. There will be games that are plain bottlenecked by your CPU, for example Baldurs Gate 3. Sure GPU intensive games like cp2077 aren't as easily bottlenecked, but still in FHD a 4070 ti Super would be plenty powerful. Invest the saved cash into a monitor, there are huge upgrades to get when going to WQHD OLED for visuals and ultimately gamign experience.",
      "Ray tracing performance is still a mess on anything other than the very highest end cards from what I can see, so if you upgrade to another mid range card you'll very quickly hit roadblocks with new games with RTX turned on.\n\nI have a 3070 and play at 2560 x 1440p and with RTX off I can still easily manage high on most games (including RE4 recently) and maxed out on most games older than 3-4 years.\n\nIf you're looking for an upgrade I'd say you'd get more out of upgrading to a 1440p OLED than a new mid-range GPU",
      "I’d stay with what you have, unless you plan to bump to 1440p",
      "The 5070 Ti and 4080 Super TDP are near identical. I don't think you'll need a new PSU for the 4080. And if it's getting too close for you, you can Undervolt both cards easily. In the case of my 5070 Ti my Power consumption under full load get reduced by 40 Watts and the 3DMark Score increased.\n\nIf those prices are the normal prices in your area and the 5070 Ti isn't just that high because of current stock issues, I'd personally go for the 4070 Ti Super. Neither the 4080S and especially the 5070 Ti offer enough of a performance gain to justify such an increase in price imo. Especially considering that at 1080p, many games will be limited by your CPU anyways.",
      "RT and pathtracing are very demanding, there's benchmarks even with a 5090 and all on on native 1080p pushing it to sub 60fps in Cyberpunk for example",
      "Wanting to run everything maxed out, including ray tracing in the latest games while in the market for a mid-range GPU is a losing battle though, you'll be back where you are now in 1-2 years once some shiny new demanding game comes out.\n\nAs I said with RE4 I just turned off RTX (could barely notice the difference tbh) and it was buttery smooth throughout on my 65\" TV, even Cyberpunk I can get a solid 60fps on high without RTX, with DLSS4 I only did a quick test but seems I can now get around 80fps so dropping down to 1080p it'd be over 100fps probably.\n\nIt's up to you of course, I like cranking things up as much as anyone, but I just find the performance hit with RTX isn't worth the slight visual change it gives in most games, there's only a few I've tried where it really adds anything tangible to the experience",
      "\\>There will be games that are plain bottlenecked by your CPU   \nUsually i does not play games like this (bc usually this is a RPG or a RTS XD), but still a good take, forgot about that case.\n\n\\>Invest the saved cash into a monitor  \nI am thinking about upgrading to 1440p for 2-3 years, to be honest. But i guess i will continue to sit on 1080p, because there is no good 1440p 24\" (especially in my country), and personally i dont like anything  that larger than 24\"",
      "Used 3080?",
      "I'm sorry op, upgrading from 3070 these days for 1080p gaming is just silly. Hold on for another 6 months or so and see where the market stands regarding the new gen that just came out.",
      "4070 Super is fine for 1080p, save money for platform upgrades ie. CPU, RAM and MB.",
      "Update for someone who cares...  \nGot the 4070 Ti Super for 940$ and sold the 3070 for 370$. Insane improve tbh.\n\nGAME --- OLD FPS => NEW FPS (1080p, Native, Ultra, RT Ultra)  \nGhost Recon Breakpoint --- 40-60 => 100-120  \nAlan Wake 2 --- 20 => 60  \nSilent Hill 2 --- 40-60 => 80-110  \nHellBlade 2 --- 10-50 (some scenes had drops to 10-20 💀) => 70-85  \nIndiana Jones --- no words(8GB VRAM issue) => 60-80  \nGothic Remake Demo --- 15-30 => 60-80\n\nNot going to lie, this is a much better investment in a PC than upgrading the motherboard, CPU and RAM from the R5 5600 to the R7 7800X3D, which costs almost the same.  \nCheers to everyone who told me to drop the thoughts about 4080S",
      "\\> I don't think you'll need a new PSU for the 4080  \nThe main issue for a new PSU - my PSU have only 2 PCI-E connectors, and the 4080 uses 3 of them.\n\n\\>many games will be limited by your CPU anyways  \n7800X3D on the road, not a problem ha-ha\n\n\\>If those prices are the normal prices in your area and the 5070 Ti isn't just that high  \nNah, that is super high for 5070TI and OK for others. My friend works at a local store and can buy items at the cost price (the price at which the store purchases the items), but the management decided to prohibit buying 50 series GPUs at such a price. If it weren't for this restriction, I would have bought the 5070 Ti for 507,000 KZT (\\~$1000 USD) without hesitation.",
      "I don't know how to explain it well, sorry. So I'll try to show it with images:\n\n[https://imgur.com/a/w5IQwOz](https://imgur.com/a/w5IQwOz)\n\nBasically, the difference between these GPUs shrinks the lower the resolution is. This was tested with a 13900KS which should be slightly below your CPU, so it's certainly not as bad in your case - but it still shows the trend.",
      "Most of the time you can use 2 seperate cables and if it has a daisy you can use that as a third cable. Anyway for 1080p gaming a 4070 ti super is excellent.",
      "IKR, thats why i am not focusing to play on native res",
      "16% performance boost for an additional \\~30% in cost, huh? Seems like a point for a 4070TIS",
      "Ah yeah, 24\"is probably nothing for 1440p or 4k. Pretty much everyone is now on 27\" with 32\"4k getting more and more common.",
      "That's what you have to evaluate for yourself. I personally wouldn't pay it. But currently, 5080 is going for around 500 € more than the 5070 Ti in my country and there's 15 % between these cards. So many people seem to be willing to pay 500 € for just 15 %.\n\nPerformance never scales with price, unfortunately."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "mid",
    "matched_keywords": [
      "rtx 3070",
      "3070"
    ],
    "title": "When to upgrade RTX 3070",
    "selftext": "Hi I have a RTX 3070 and I5-12600k and for last 2-3 years  I am happy about it and I can still play recent games with good performance but when I should upgrade and what should I buy?",
    "comments": [
      "Might be a silly comment but whenever you are personally ready. The GPU market right now is a complete joke and if your setup is doing everything you want it to do with performance you are happy with, no point in upgrading any time soon.",
      "If you're happy with the performance of your system, then there's no reason to upgrade it. You should upgrade when the system you have no longer does what you want it to (drives the framerate, resolution and graphics quality you want).",
      "You should upgrade when YOUR unhappy with its performance. Only then should you be asking what to buy as prices and hardware change constantly",
      "I'm running an i-7 13700k CPU with a z790 motherboard and upgraded ddr5 memory to 32 GB and I'm using my 3080 card",
      "Upgrade when you’re no longer happy with your performance.",
      "Still rocking my 1080 :D  No plans on upgrading",
      "I have the exact same GPU, only thought about changing it when i was playing with AI due to the 8GB VRAM, I think it's pointless to upgrade if you are going to get nothing better in exchange",
      "Actualy when I first bought it I guessed in three or four years there will be massive games and I need to upgrade it very soon but thanks for companys they didnt release anything that I need to buy a new graphic card",
      "Thank you",
      "Thank you",
      "I still play old games that aren't suddenly demanding new hardware.  I recently started playing RDR2 and that made me realize it was time to upgrade."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "mid",
    "matched_keywords": [
      "rtx 3070",
      "3070"
    ],
    "title": "Just bought the Sapphire VGA Radeon RX 9070 XT PULSE 16 GB and ditched my Gigabyte GeForce RTX 3070 8GB! I have waited for NVIDIA long enough...(there is a bit of dust on it don't judge me)",
    "selftext": "",
    "comments": [
      "Nice card!  Good upgrade. I'm gonna do the same from a 1080TI",
      "nice! I got my 9070 (non xt) today to update my 3070, and it's a whole new level",
      "I just upgraded from 3070 to gigabyte 9070 xt today!",
      "That was a legendary card, i am not surprised it lasted you that long!",
      "It barely fits tbh, but thermals are important",
      "And here I am with my simple man's 7th generation i7 laptop with Nvidia 940mx mobile graphics. One giant step for man one giant leap for mankind !",
      "infact 3fans is too long to most ATX cases",
      "I've been concerned doing this swap because it doesn't bench as good for RT. I assume it is an upgrade for you because of the VRam?",
      "Any interest in selling???",
      "It is indeed!",
      "I see many of us were in the 3070, i hope this upgrade will last us 5 more years",
      "I don't care about it honestly, but I fear it's going to become mandatory in gaming. Pretty sure it's required in Indiana Jones.",
      "I hope not because then we will need this AI and Upscale BS always to be on. They are improving but still, we need raw power otherwise lower the prices.",
      "I had double the FPS in 2K res testing Cyberpunk 2077 with and with out RT. They did a good job there too, but of course if you care about it NVIDIA is a better choice with their 5070 and 5070ti, value is horrible tho it costs way more than what it offers."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "mid",
    "matched_keywords": [
      "rtx 3070",
      "3070"
    ],
    "title": "ASUS TUF Gaming NVIDIA GeForce RTX 3070 OC Edition resizable bar",
    "selftext": "as the title says i have a ASUS TUF Gaming NVIDIA GeForce RTX 3070 OC Edition but resizable bar is not enabled. I am not 100% if it would benefit to enable it. Its enabled in bios and pretty sure my mobo and processor supports it.....running a x570 steel legend mobo with a 3700x processor. I talked to another guy that builds pcs and he said it was not worth the risk of bricking the card because i think the card needs a vbios update to enabled it. What do you guys or girls think? thanks!!!",
    "comments": [
      "I had to flash a new vbios on my old evga 3070 xc3. Didn’t have any issues",
      "Update vbios I had to do it for my 3090 tuf oc",
      "I updated my Dell 3070 in order to use resizable bar.",
      "I regularly update my bios. If you know what ur doing, it's totally fine. Apart from enabling it in the bios you also need to download a driver from the gpus manufacturer \n\nhttps://www.asus.com/us/motherboards-components/graphics-cards/tuf-gaming/tuf-rtx3070-o8g-gaming/helpdesk_download?model2Name=TUF-RTX3070-O8G-GAMING\n\nI also have a 3070 tuf, this should help you unlock the re bar",
      "yea it looks like the latest.",
      "it improved my heaven benchmark by 47pts ...thanks!!!",
      "Did it make it also yes to resizable bar inside the Nvidia control panel?",
      "[https://www.asus.com/motherboards-components/graphics-cards/tuf-gaming/tuf-rtx3070-o8g-gaming/helpdesk\\_bios?model2Name=TUF-RTX3070-O8G-GAMING](https://www.asus.com/motherboards-components/graphics-cards/tuf-gaming/tuf-rtx3070-o8g-gaming/helpdesk_bios?model2Name=TUF-RTX3070-O8G-GAMING)\n\nwould you do version 4? thanks",
      "i didnt see any driver besides the standard game ready drivers on the tuf site unless i over looked it..thanks!",
      "yeah in system info says yes!"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "mid",
    "matched_keywords": [
      "rtx 3070",
      "3070"
    ],
    "title": "SUCCESS: Replacement Thermal Paste and Thermal Pads RTX 3070 OC Vision Rev.1",
    "selftext": "Good morning everyone! As per the title, I replaced the thermal paste and thermal pads of my 3070. The card was purchased used, so it had 2/3 years of use. The temperatures were quite high (see photo). Now the temperatures have dropped drastically. On Heavy use, The temperatures do not exceed 90 degrees, and the fans are silent again. I leave you the photos of the temperatures before and after, both during use at full load and not.\n\nProducts I used:\n\n-Thermal Paste: SYY 157\n-Thermal Pads: ARCTIC TP-3 (1.0 mm & 0.5 mm)\n\n\n",
    "comments": [
      "Get ready to replace that paste every 3 months 🥲",
      "I have a 3070, bought a couple of months after release, after 4 years of use, it was hitting 105ºC on the hotspot and shutting down\n\nDid a repaste changed the thermal pads, now its good as new",
      "Good job! Something I would be nervous to do for the first time",
      "Thanks! For me it was the first experience with a GPU, even having previous experience, I must say that I sweated a lot this time😂",
      "In fact, at first I was unsure about what to buy and what to do or not to do. A lot of different guides and methods. For example, many said to also use a 1.5 mm thermal pad, others not.",
      "Its the only reason why I havent changed mine lol. Also got a 3070, but at least my cooler seems to still be doing a pretty good job.",
      "Use Honeywell PTM7950 or Thermal Grizzly PhaseSheet for much longer service intervals.",
      "I just got the courage to build my first PC a month ago, I was so paranoid I would do something dumb and break stuff. I feel like most of this stuff is a lot more intimidating than it should be with how many guides and videos exist",
      "Unfortunately I had a lot of problems, while I was playing it went into protection and suddenly the monitor signal disappeared, I had to restart it every time",
      "Yea i know😩"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "mid",
    "matched_keywords": [
      "rtx 3070",
      "3070",
      "3070 ti",
      "rtx 3070 ti"
    ],
    "title": "Rtx 3070 ti or rx 7800 xt?",
    "selftext": "Im looking for a new gpu and dont know if i should buy the 3070 ti i found for 500 dollars or go look for a 7800 xt.",
    "comments": [
      "3070Ti for $500 is ass",
      "7800 xt and it's not even close. It's not only significantly faster, but it also has more vram. The 3070 ti's 8gb of vram is limiting it these days. It sucks having a GPU only be limited by the company not wanting to spend an extra $20.",
      "7800XT",
      "Oh you are willing to buy a 3070ti for 500? Wow, I thought my 3070ti was worth a lot less. P",
      "Location is limit og",
      "3070ti is worth about $300 but you can get a 3080 for sub $400 (I did like 3 weeks ago at $350) and is closer to the 7800xt in performance \n\nNo idea why this guy is thinking of paying $500 (maybe location?)",
      "fyi...3070ti in my country still sells for 650...and AMD card is non existant in 2nd hand market.\n\n(planning to sell off my 3070ti and add 300 to get 9070 lol)",
      "I Bet that Price would be possible but this is the cheapest used one in the whole country",
      "I got my 3070ti for 300$ in December. Look around fb marketplace",
      "I had a 3070ti and you couldnt even run ray tracing cause its unplayable. I would get the 7800xt",
      "7800xt",
      "This is the cheapest it gets here",
      "This is why it's important to specify location when asking for advice in this subreddit, it's automatically assumed we're talking about the US prices otherwise."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "mid",
    "matched_keywords": [
      "rtx 3070",
      "3070"
    ],
    "title": "RTX 4060  or RTX 3070 ?",
    "selftext": "Which one should I get ? I am upgrading from a 2060RTX   limited budget\n\n2nd hand -  3070 RTX £220\n\nNew -  4060 RTX  £250\n\nI just don't know which card would be better  -  i mainly run DCS / HLL / Squad   any advice most welcome only play in 1080",
    "comments": [
      "The 3070 is the better card. 4060 is just about the same as a 3060, +/- 5% in most case without considering FG. I have a 3070 and it works great with everything, I don't have the desire to ultra every settings so it still works great for me 4 years in.",
      "Who is using a 4060 with a 4K monitor?  It’s going to be VRAM limited in almost any modern game at reasonable settings.  Only 4% of Steam users have a 4K monitor. Around 55% are at 1080p and 20% at 1440p.  4K is just not relevant to 4060 class GPUs, and certainly not one with 8 GB of VRAM.",
      "B580",
      "https://preview.redd.it/vsj4fhgdgsae1.png?width=560&format=pjpg&auto=webp&s=19e414bf28aa0aec1350e874361e184620a181cb\n\nNo 4060 is 15% ahead but loses vram.",
      "Id wait for the 5060ti and see whats up with that one.",
      "I have the 3070 and am looking to upgrade. 8GB of vram just isn’t enough.",
      "it rly isn't, it is great efficient card, especially for some Low Profile builds. Just a bit overpriced.",
      "3070,4060 is the worst nvidia product from recent years.",
      "Just traded my 7900 GRE for 4060 it is killing Fortnite and my streaming for some reason my GRE  kept crashing",
      "The RTX 3070 8GB is the faster GPU in terms of rasterization. The RTX 4060 8GB supports frame generation.  \nLook at Techpowerup's review of the RX 7800 XT (https://www.techpowerup.com/review/amd-radeon-rx-7800-xt/31.html), and the average FPS:   \nAt 1080P:     \nThe RTX 3070 8GB averages 121.3 FPS   \nThe RTX 4060 8GB averages 96 FPS",
      "What is wrong with the 3070? I had one and had no faults. OK, VRAM is low, but 8GB wasn't a huge issue when the 3070 came out. 4060, maybe.",
      "It has literally the same VRAM",
      "He chose the 3070 as the better option and then explained why 4060 isn't good",
      "Ah I'm fucking dumb. My bad lmao",
      "3070 is like 30% faster and will also handle running out of vram a little better seeing it has double the pcie bandwidth",
      "3070 https://gpu.userbenchmark.com/Compare/Nvidia-RTX-4060-vs-Nvidia-RTX-3070/4150vs4083",
      "Where did you get this graphic?",
      "The 16gb version?",
      "techpowerups updated GPU test results",
      "The 12gb version there's no 16gb version only 12&8gb"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "mid",
    "matched_keywords": [
      "rtx 3070",
      "3070"
    ],
    "title": "Is it worth it to upgrade from a RTX 3070 to a RTX 4070 Super or a 4080 Super?",
    "selftext": "I have a Gigabyte GeForce RTX 3070 Vision, when I bought it I played at 1080p which was great at the time, but now I play at 4K 60Hz (CPU: AMD Ryzen 9 5900x / RAM: 64 GB DDR4 3600MHz).\n\nShould I buy a RTX 4070 Super or a 4080 Super or wait for the RTX 5070 or the RTX 5080?",
    "comments": [
      "For 4K, you’ll want a video card with at least 16 GB of VRAM.  So a 4080/5080 based on what you listed.  (I upgraded to a 4070 Ti Super for 4K).",
      "To a 4080 super yes, if you can get a 5080 even better. I went from 3080 to 5080 and i get about if not more than double the frames",
      "4070s is a bit questionable 4k is high resolution even at 60hz, but for 4080 is going to be a big upgrade and you should be able to play 4k in most titles at high settings.\n\n>Should I buy a RTX 4070 Super or a 4080 Super or wait for the RTX 5070 or the RTX 5080?\n\nhow long are you willing to wait for the crazy 50 series market to stabilize? We might be 3 or 4 months away of getting 50 series at acceptable prices.",
      "That’s an optimistic outlook imho. 4080s were still expensive a year out. Now even more. It’s like they’re investment assets.",
      "As a general rule, I wouldn't upgrade unless I can confirm a 50% upgrade in pure rasterization performance and compatibility with my existing hardware at the same price bracket. \n\nA 4070 S will perform better than your 3070, but certainly not at a 50% increase in pure rasterization (no DLSS, DLAA, etc). The 3070 should be fine for most gaming for a while. Save your money.",
      "No, keep your money for the 6XXX",
      "Thing is, 3070 is an 8GB GPU. That’s not really comfortable at the moment, especially at 4K",
      "Isn’t Nvidia still making “next gen” 8gb cards? Also I thought they had some AI texture compression in the works (probably going to only be limited to 5 series, if they want to kick us harder in the balls)",
      "Definitely worth it to a 4080 Super! Not so much 4070 Super, though.",
      "The first thing you should do if this is a gaming first PC is get the 5700x3D (it’s running out of stock quickly). The second thing you should consider is the 5070 Ti when it comes into stock in a few months. This is mostly has to do with the 16gb of vram and better performance it will likely have over the 5070. \n\nHopefully that helps you and regardless of what you choose I hope your upgrade turns out awesome 👍",
      "on a somewhat similar note, I've been thinking about upgrading from a 3070 Ti to a 4070 Ti Super but I'm not really sure which reviews to believe. Is the frame gen and obvious generational gap worth the hassle of an upgrade? Just seems like the 50 series isn't happening now (at least for me any time soon) so looking for a suitable compromise.\n\nLooking to run at 4K with 60 FPS bare minimum but 1440p on the resource monsters like Cyberpunk is ok too since I have both a 4k and a 1440p monitor",
      "4k? 4070 ti super or 4080s or 5070 ti or 5080, depending on your budget. I personally have the 4070 ti super and have no problem to play any game at 4k 60hz with highest settings, dlss quality and frame gen sometimes.",
      "i went from 3070 to 4070S. i have a 4k 60hz stacked over a 3440x1440 144hz. been happy enough at both resolutions. at 1440 p def a great exp.. 4k 60hz its good enough. better than 3070\n\nthe jump has been good vs 3070. a 4080S would be even better. however where i live its twice as much $$ wise for new. also i got a month old 4070S used for 200 AUD less than new. so hard to pass that up\n\ngoing from 3070 to 4070s i now see that its possible to leave RT on more titles. In the past wasnt worth the performance hit and Id only leave it on for minecraft. With RT Dlss + fg = @ High  no issues with cyberpunk @ 1440p over 100+ fps.  even with path tracing on top of those previously mentioned setting on 3440x1440p it was 60fps. Now i wouldnt run it like that cause i want more frames so no PT... however, my 3070 couldnt do that.\n\ndidnt try pt at 4k but i tested various games at 60fps at 4k.  3070 could 4k too, you know this but def way more custom settings vs 4070S\n\nmy 3070 could also become a space heater and this card runs so much cooler.\n\nSure the 16gb is limited and i might have to upgrade sooner...but for the price of a 4080s here... def worth it to me. by the time i need to upgrade nvidia 7070 will be out right.. and ill get a cheap 6070S or ti at half the price of a 6080S",
      "4080",
      "Hello internet should I buy this old tech?",
      "Difference between 3070 and 4070 is huge. Difference between 40 and 50 series card is minimal",
      "New games now list the RTX 4080/S as for 4K 60 FPS, so i think you should get the 4080",
      "3070 has 8GB.  12GB works a lot better (I was playing path traced cyberpunk last night at 4K on a 4070ti, and dark tide, both over 60fps before FG) and would be a good bump.  I have a 4070ti so halfway between the 4070 super and your card.  You can also get them pretty cheap - half the price of a 4080S.  I had a choice - 4070ti for £600 or 4070ti super for £800.  That's not a lot of extra performance an additional £200.",
      "4070ti from a 3060ti.  I could play the last of us on ultra settings because of the 4GB additional vram (3060ti was medium textures only).  Cyberpunk performance, I could easily get over 60fps with RT Overdrive and DLSS ultra performance at 4K (without FG) which looked great.  And on my ultrawide 3440x1440p monitor the performance is obviously better.   I would say that FG definitely does introduce some softness to the image and I would prefer to run a lower version of DLSS than a higher version with FG on.  FG does look good but you turn it on and it's like a software filter has been applied.  You could use more sharpening and it feels very smooth and snappy enough (starting from a 60-80fps base) but it could be sharper.",
      "But given the 50 series is much less of a performance bump, I would guess the demand pressure should relief a bit sooner, because I can't imagine many 40 series owners wanting to upgrade.\n\nIn the end it also depends on how many 50xx they build, Nvidia said they were going to ramp up production, so lets see.\n\nI think is of the interest of Nvidia to push GPU's on the market, because even if AMD is behind, they can still undercut the price and make for a viable alternative."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "mid",
    "matched_keywords": [
      "rtx 3070",
      "3070"
    ],
    "title": "5700 To RTX 3070?",
    "selftext": "Hello people, so I’ve been wondering whether it would be worth it to upgrade my xfx 5700 (normal) to a 3070 for about 180usd in price difference. Would the performance improvement be worth it? For my CPU, I have a R5 3600. I have a TN 144hz FHD and an IPS 100hz FHD, and I plan on buying OLED 2K in 3 years time by the time they drop in price. I feel like I can barely tell the difference in those comparison videos of medium to ultra settings. I play mostly single player games like clair obscur these days but i'm very casual. Maybe the DLSS is worth it?\n\n",
    "comments": [
      "The main advantage for that switch would be dlss and having RT support (even if it wouldn't be usable beyond low settings on newer games).\n\n\nIf the 3070 only costs you 180 that's not too bad, otherwise switching to a newer card that's worthwhile would cost a minimum of $500 to $550 for the 5060ti or 5070.",
      "Roughly 60% performance improvement is pretty solid and worthy. You'll also get dlss transformer model which is game changing really and get to experience ray tracing.",
      "DLSS 4 supported by all rtx GPUs.",
      "So? Is it relevant to what I said?",
      "Oh shit i've read like he is wondering if it is worth upgrading from 3070 to 5070 :))",
      "Lol. It literally says 5700 to 3070 in the title but it happens no worries"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "mid",
    "matched_keywords": [
      "rtx 3070",
      "3070"
    ],
    "title": "Which RTX 3070 to BUY and AVOID! 38 cards compared! Ft. Asus, MSI, EVGA, Gigabyte, Palit, PNY, etc. (O!Technology)",
    "selftext": "",
    "comments": [
      "Wow, MSI really did cut corners in their GPUs (except the SUPRIM), didn't expect they cut even the Gaming X Trio",
      "In the video itself is shown, but as TL:DW, all the MSI cards (except the SUPRIM), are using 45 A DrMos current (which is below all other cards, no exclusions, all others are 50A and Strix is 60A), and VRM current they are the ones with lower limit (405, vs 410 (FE and other cards), 500 (Zotac Twin Edge), and 600+ (SUPRIM X, etc), 700 on Strix), so at the end, lower power limits.\n\nTL:DR the PCB and VRMs are very poor, which shouldn't be the case for the price the Gaming X trio goes. Temps wise is pretty good tho, and performance (without overclock) too; if you want to overclock those cards, they won't reach higher clocks as other cards",
      "Told you folks MSI cards are bunch of garbage. Especially that Ventus shit. Alibaba quality. \n\nBut apparently there's some around here with buyer remorse so it hurts them to accept the truth.",
      "Don't bother. This sub has become an echo chamber of ppl parroting whatever their youtuber of the month quotes.",
      "yeah all coolers perform the same, too\n\nand it's not like some have dual bios or 2 HDMI ports making it worth more, or skimp on transistors/vrms\n\nsuch stupid comment for \"such stupid video\"",
      "I have 3070 Ventus. Runs butter smooth.",
      "Awesome, if this guy keep doing this for every card series.\n\nThe AIB guys gonna have hard time cut corners.\n\nComponent quality also play a major role in reliability as well, regardless you OC or not.",
      "Asus TUF best performance per dollar still\n\nI wonder if we didn't have stock problems, how many would have bought it instead of settling for other worse cards that cost more",
      "Do all/most of these AIBS use the 3070 designs on the 3060ti?",
      "Gaming X and have no issues. No crashes, artifacts or anything. Runs cool and quiet. Not sure what corners they cut but it's built better than my 1080ti Aorus Extreme and that was a tank.",
      "Not everyone is going to be running games at 4k with 10 texture pack mods installed. \n\nAnd by the time 3070 is going to struggle with VRAM limitations, the card will already be beaten in performance by a cheap xx50 card.",
      "Relax man, I'm saying that because MSI is charging premium price when it shouldn't lol, never said the cards were bad.",
      "Had a 3080 Gaming X Trio for a couple of months now, card is quiet and runs under 60°C playing Cyberpunk etc.\n\nCore is about 2040Mhz on average with a small overclock.\n\nNot saying that they haven't cut corners with the plastic backing etc but I'm having zero issues with it and very impressed from a noise and thermal perspective.",
      "Something up your end mine idles 30-35c whilst browsing with fans off and in game under full load max temp is 73c but 90% of its at 65-70c",
      "ah yes, marketing told my ears to block themselves so the cooler sounds quieter.",
      "But it doesn't? Got a 3070 too, ran cyberpunk RT ultra and dlss performance, and it has never maxed out my card's vram, ever. I know dlss helps here, but it's not like you'd ever be able to run the game without it. Cyberpunk does have a memory leak though, maybe that's what you're experiencing?",
      "Dude msi cards have all been marked up recently too. I can't see 3080 x trio at $769 anymore, even on amazon. Scumbags.",
      "No surprise Palit GameRock (OC) tops the list along with Asus Strix, EVGA FTW3. Palit did all the right things with this card. I have the 3080 model of the card and here's [my experience](https://www.reddit.com/r/nvidia/comments/ki9ik0/if_you_could_choose_a_3080_which_would_you_pick/ggs7r6u/?utm_source=reddit&utm_medium=web2x&context=3).\n\ndesktop while doing nothing, lol: [https://imgur.com/a/rmMkZFi](https://imgur.com/a/rmMkZFi)",
      "Why people doing such stupid videos? All cards are in the specs. Some of them that are outside claiming to have 1-2% extra performance in exchange of higher power draw. Essentially it doesn't matter what you buy. Palit apparently sales more video cards than Asus but it is not that common in Europe.",
      "You are one of those... Marketing BS lovers."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "mid",
    "matched_keywords": [
      "rtx 3070",
      "3070"
    ],
    "title": "[VideoCardz] NVIDIA GeForce RTX 3070 has been modded to support 6GB and 12GB memory",
    "selftext": "",
    "comments": [
      "Interesting, I expected a performance reduction due to disabling memory channel, looks like increase in VRAM buffer more than substituted bandwidth reduction, perhaps a small memory overclock will actually do something for 12Gb 3070 and further push its performance.",
      "Makes sense since regardless of what the armchair wannabe computer engineers of this sub think the 4060Ti 16GB addresses its VRAM and has been shown to massively reduce 1% low stutters compared to the 8GB in VRAM limited situations.",
      "For fun, you have to break a memory channel. It's just more seeing what you could do, not what you should do.",
      "The 4060ti 16GB is about $150 too expensive for its level of performance. Especially with the 4070 Super merely $100 more.\n\nIf the 4060ti 16GB dropped to around $350, then it'd be worth that price.",
      "i've seen 16gb mods and it actually works out pretty decently",
      "that's awesome.\n\nhow to get that 12gb mod or is this just research/for fun/showing off?",
      "yeah because you \"just\" need to replace the 1 gb moduls bei 2 gb ones no?",
      "RTFA",
      "pretty much yes",
      "Can I download this mod to my graphics card?",
      "It's not made up, there are plenty of buyers for apps like Blender and Stable Diffusion that buy them. I never said I would, but it's a sensible option for those. 8GB even at the lower tier is not a great way to go.",
      "Probably yes. Also this is not an easy hack, read the article when they first tried to replace the memory modules, they run into stability issues when the card operated on low power mode",
      "I'm not gonna google all this right now but there are plenty of tests showing VRAM bottlenecks for some workloads. However if you idiots are just going to downvote me without discussing what's the point?\n\nHere is one of the first results, showing a 3060 12GB rendering 2.3x faster than a 3070 8GB because it ran out of VRAM on a test:\n\nhttps://youtu.be/TL5JJZS8LqI?si=0zvbBNIALad8GqB_",
      "You're clearly a genius level armchair computer engineer. Please let me know when I can purchase an RTX 4090 8GB.",
      "The worst part is that a 3070 6GB would be very plausible if these were still in production",
      "doesnt work, 4070ti already have 2GB modules and there are no 4GB ones on the market",
      "I see, thanks",
      "People said the same thing about the RTX 3060 and its 12GB of VRAM when it launched, and we saw how that turned out. \n\nI'm fairly confident that the RTX 4060 Ti, being roughly 42% more powerful than the 3060, will see similar benefits from its additional 33% of VRAM.",
      "The point of hating on 4060 ti 16gb is that given how weak it is you will not find many situations in which it needs 16 gb and can reasonably handle.  Sure there are some, but that sku should be one of the most mainstream cards out, not a niche product.",
      "That benchmark doesn't show all the vram stutters.\n\nhttps://www.pcgameshardware.de/Geforce-RTX-4060-Ti-16GB-Grafikkarte-279647/Specials/Test-Review-Preis-Release-8GB-vs-16GB-Specs-Benchmark-1425140/2/\n\nAnd newer games will use more vram, not less."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "mid",
    "matched_keywords": [
      "rtx 3070",
      "3070"
    ],
    "title": "which one should i buy RTX 3070 iChill X4 or IGAME RTX 3070 8GB VRAM ULTRA OC EDITION",
    "selftext": "Hello,\nCan you help me choose a GPU for my first PC? These two GPUs are the ones available to me. Which should I choose?",
    "comments": [
      "The price difference is really small 15 dollars\nso i think im going with the better looking one",
      "Whichever is cheaper.",
      "there is no 3070 12gb vram....",
      "they're saying buying a gpu with 8 gb vram isn't worth it, which is generally true in 2025. I don't know why you specifically must have a 3070. you have multiple options for 16 gb that aren't too costly. there is also b580 at 12 gb if you have a strong cpu",
      "None of these, 8 GB VRAM is barely enough these days. Go get something with atleast 12 GB VRAM."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "mid",
    "matched_keywords": [
      "rtx 3070",
      "3070",
      "3070 ti",
      "rtx 3070 ti"
    ],
    "title": "RTX 3070 Ti Gamerock - mini build for the spouse",
    "selftext": "",
    "comments": [
      "I've added a short video as well on the first image link ([https://imgur.com/a/NZIWBmr](https://imgur.com/a/NZIWBmr))\n\nSpecs:\n\n**GPU**: RTX 3070 TI - Gamerock    \n**CPU**: AMD Ryzen 5800X    \n**PSU**: Corsair SF-750    \n**Case**: Coolermaster Masterbox NR200P Sakura Limited Edition    \n**RAM**: G.Skill Trident Z Royal 16 GB DDR4 3200 MHZ (2x8GB)    \n**CPU** Cooler: ID Cooling PINKFLOW 240    \n**Mobo**: Gigabyte B550I Aorus Pro AX Motherboard\n\n**Update**: I'm not sure where I got the 77C from but the GPU actually runs a lot cooler than I thought. I ran Furmark for about 10 iterations and I got 71C (https://gpuscore.top/furmark/show.php?id=423241)",
      "The semen splattered glass was a nice touch.",
      "why does it look like someone sneezed up a lung all over the side panel?",
      "Isn't AIO in bottom like the worst spot it can be in.",
      "How are the thermals in that little case?\nI’ve got a similar set of specs and I’ve been eyeing that case for a little bit now, I was just worried it would be too hot.",
      "The GPU temps are actually decent, under load about 77c or so max. The CPU temps are a bit on the high side, which prompted me to to set a negative PBO of -15 (I think, I don't recall) on the CPU. They're OK now, but the glass window definitely doesn't help. CPU does hit about 70c-85c under load now depending on what I do.",
      "Good point, I hadn't even noticed that, I'll swap the bottom ones to intake as the case does have standoffs.",
      "NR200P provides a mesh panel too, that significantly helps temps by another 3-5c (the glass panel is the real issue here blocking most of airflow).",
      "How to choke your card 101\n\nGreat looking card but 77 is still a bit much, considering hot spot and vram temp will be higher\n\nSad that people downvoted me for saying a fact about vertical placements.\n\nOh well, that's just reddit.",
      "yup, if the rad is at the bottom all the air is in the pump (highest point in the loop) which can cause premature usage and bad performance since the flow isnt the best.  \n\n\nif u want to keep it like this u can flip it upside down and it would prob run cooler 😂",
      "It's not really used for gaming, I just bought it on a whim because of the looks. But yes, I agree, a case like this is NOT really good for gaming and I don't disagree with it. The GPU can be mounted horizontally and if you take the side panel off it does help drastically with the temps. The glass-tempered panel is the main culprit here.\n\nEdit: Updated main comment at the top with temps (it's 71C, not 77C). I'm not sure why I remembered it as such. Have just tested it in the same condition.",
      "The AIO appears to be installed wrong. The rad is at the bottom of the case so the pump/block will have an air pocket in it and not perform correctly",
      "And if you are already at it, maybe try to mount the radiator at top. If you have it at the bottom, the pump will be the highest point in the loop...so air will collect there and will lead to an early death of the pump.",
      "At least someone’s getting one lol.  Been looking for months for my SO rig but not being available in the states puts a real damper on it. Looks amazing!",
      "looks like someone jizz all over it...",
      "Cooler Master NR200 only supports bottom or side mount for AIO.",
      "You don't really get choices with a case like this though :/",
      "why are people downvoting facts? lol.",
      "https://gpuscore.top/furmark/show.php?id=423241",
      "This - I can't believe how many people aren't realising that there's no way for me to place it on the top or on the front. This case is so small and there's only two places (bottom or side, but side means no vertical GPU and you need a mesh panel). The manufacturer (CM) provides a guide with the only two possible locations as well."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "mid",
    "matched_keywords": [
      "rtx 3070",
      "3070"
    ],
    "title": "Buying a Used Gigabyte GeForce RTX 3070 EAGLE OC 8G (rev. 2.0) in 2025",
    "selftext": "Found this used Gigabyte GeForce RTX 3070 EAGLE OC 8G (rev. 2.0) (GV-N3070EAGLE OC-8GD) for $200 on Facebook Marketplace. Seller seems genuine ( pictures of him and family + account made in 2007)\n\nTho, seems like this specific card model is a cheaper rtx 3070 and has reports of it being noisy + even dying out.\n\nIs this purchase worth it ???",
    "comments": [
      "I have a gigabyte eagle 3060 in an old pc that is perfectly fine, no noticeably loud noises. And I had a 4070ti eagle that I just recently sold which also had no issues and was never noticeably loud. \n\nOnly replaced it because I found a pny 5080 in microcenter for $999 an hour or two before they started raising the prices.",
      "Good price, 8 gb vram is not the best but it will carry on for a few years on 1080p . Don't forget to ask for the stress tests.",
      "I think the trade in value is $230 on Newegg"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "mid",
    "matched_keywords": [
      "rtx 3070",
      "3070"
    ],
    "title": "Should i get an RTX 4060 ti or RTX 3070?",
    "selftext": "you can recommend me different RTXs that are in that price range like 600 or 800$ ",
    "comments": [
      "Honda Accord or Mercedes AMG S63",
      "Honestly at this point get whatever is available. You won’t have much choices, if any",
      "600$ for a 3070? Wow. For that price you should really consider buying from the used market.\nDon't know about the US but 3070s sell for less than 300€ in Europe, can't image them going for much more.\nThe 2080 Ti is older but has the same level of performance and 11GB of VRAM.\nIf you want more than 8GB of VRAM some good picks are 3080 and 3080 Ti, for usually a bit less than 400 and 500 respectively, with about 30 and 40% more performance than a 2080 Ti/3070/4060 Ti.\nFor 550-650 you could get a 4070 or a 4070 super, which are technically worse value, but they have 12GB of VRAM, are newer (so likely with less use, especially the super), more efficient and support frame generation.",
      "I just sold my 3070 for $280.\n\n$600 for a 3070? Hard pass.",
      "It was like 550",
      "I got recommended a 4070 ti super so I'll look at that",
      "All those prices are horrible. How could anyone ever recommend this list.",
      "It's only 15% slower than 4080 so perfect for 1440p",
      "I'll look at Amazon the prices I had were in Amazon the rtx 4060 ti was like 560 and the rtx 3070 was 550",
      "did u buy a gpu yet?? if not then i would wait a lil, i been seeing 5070s going for sale on amazon for retail from $550-$600 (sold & shipped by amazon not resellers). from my experience they sell out after an hour or two of being listed. you just gotta be on the lookout for when they get listed. haven’t seen much restocks on the 9070s tho",
      "To note, these are terrible deals specially the 5070. They're in stock because of the massive markup. If you're patient you can get models like the 880$ MSI Gaming Trio or the 900$ Gigabyte Eagle which is constantly going in stock on Amazon.",
      "4060 Ti or 4070 Ti super"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "mid",
    "matched_keywords": [
      "rtx 3070",
      "3070"
    ],
    "title": "RTX 3070 and 4K gaming",
    "selftext": "Hey guys, I’ve never bought a PC before and I’m about to buy one. But, I was wondering if the RTX 3070 is capable of running 4K games? Or is it best that I get the RTX 3080 if the price is reasonable?\n\nAppreciate all the help in advance!",
    "comments": [
      "I have an RTX3070 with an i7 10700k. I play lot of games in 4K with DLSS like Cyberpunk, Control, Horizon Zero Dawn, Kena, Death Stranding, FS2020, F.I.S.T., all Dishonored, Recent Assassin creed, RDR2, the Witcher 3, etc. Ofc I need to find tune them but it's ok. I agree 8gb VRAM can be short, if you can afford better, do it obviously;)",
      "With DLSS yeah, but at native res not really, because of the lack of vram and it falls a bit short in the performance department.",
      "I have a 3080 Ti and I'm already having trouble with running some games at 4K with max settings and DLSS Quality at 60 FPS. Go for the 40 series, they're a significant improvement.",
      "Not Worth 3080 anymore unless you buy used. Go for 4070 ti.",
      "8gb vram is not enpugh for 4k, besides its too slow for most modern games at 4k max settings.",
      "8 gig is plenty for many but not all 4k games. I had a 2080ti before getting my 4090 and most games I played didn't use more than 8gb at native 4k. Remember that not every single game came out within the last couple years and many people still play those games. I feel some at this sub seem to be oblivious to this fact.",
      "it's pretty much identical to the 2080ti performance wise, but it gets limited by the vram at 4k, only having 8gb",
      "Everybody has a different opinion on this, but generally I'd say people who say ultra settings don't make a difference haven't played many games where they do make a difference. Ray tracing in particular has gotten some very impressive implementations in recent years, and can really enhance a game's visuals above and beyond. \n\nBut setting this aside, people pay for premium cards to get all the frills, no questions asked. I want to be able to set everything to Ultra, play at 60+ FPS and rest assured that I'm getting the absolute best experience possible with no compromises. I thought a 3080 Ti would be enough for a few years, but since it's already starting to lag behind a little I'll probably spring for the 4090 next time.",
      "They're better by themselves, but DLSS3+Reflex also offers a significant FPS boost without any drawbacks, so the effective performance is much better since there's no reason not to use it if it's available.",
      "5600x. Don't think it'd be contributing significantly to the issue at 4K, especially if I'm not getting 60 FPS. \n\nI feel you, Australian prices are actually worse than Canadian ones. A 4080 is going for over 2k AUD here. \n\nI bought an LG C1 and don't regret the purchase at all. Once you experience what an OLED panel has to offer you can't really go back to IPS.",
      "No, you actually get much better lows, slightly higher highs, and much more stable frame times. And in some games you'll get huge uplifts, specially simulators.",
      "I'll second this.  i9 9900kf (same thing as an i7 10700k) and 3070 was enough for my 4k gaming needs at 60hz.  Some games like rdr2 ran at around 55fps average which was fine with vrr.  The 3070 really likes dlss on max performance.  If you're going 4k 120hz, then definitely go 3080 minimum (as I just did a week ago).",
      "3070 and 3080 i would consider as good 2k cards",
      "Max settings are a bit of a meme anyway in a lot of games. Often they just crank up sample counts or resolution with more of a performance hit than justified by the improved visuals.\n\nMedium settings or whatever consoles use are usually the sweet spot where you get the most bang for your buck.",
      "With that mindset you can just get a PS4 and call it a day.",
      "Plague Tale Requiem, Dead Space Remake and Metro Exodus. I know DS is pretty badly optimized and intermittent stutters are to be expected, but the other two are more of a consistent 50. Which is still pretty good, but it makes me roll my eyes at people saying a 4090 is overkill. No GPU is overkill when newer games are asking for ridiculous specs for 4K Ultra, and even if you max out games coming out today, the ones coming out a few years from now will probably make your card work for its money.",
      "Depends on screen size, picture quality, panel type, etc. Went from a 1440p IPS to a 4K OLED and it was a huge jump, not just in visual quality but in reduced eye strain from being further away from my screen.",
      "It is 23 of them already, including the most beautiful and popular ones.",
      "Well it deppends... i own a 3070Ti and right NOW yes, i can play everything 4k 60fps+. But there is a catch. \n\n1- No any kind of RT \n\n2- DLSS Quality (without it's not possible in demanding games). Well it's possible but 35-45 fps.\n\n3- Test every graphic setting in order to determine the most demanding one and turn it down from ultra to high. Sometimes is 1 option, sometimes 2, 3... \n\n&#x200B;\n\nIf you do that...then yes. you can 4k almost ultra 60fps+ for now... Will see in the future. \n\n&#x200B;\n\nRight now i'm playing Dead Space Remake at 4k ultra with dlss quality without RTAO and i'm between 65-75 fps.",
      "If you are willing to tweak the system settings and use DLSS always, It might work, but don't expect magic. But in short, the ultimate 4k card is 4090, the ultimate 1440p card is 4070 Ti"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "mid",
    "matched_keywords": [
      "rtx 3070",
      "3070"
    ],
    "title": "RTX 4060 or RTX 3070 ",
    "selftext": "I'm mainly building a budget system for sym racing and some FPS games. I want to go with the 3070 for pure performance, but I know the 4060 will handle my power levels better (I'm using an old 700w PSU that I don't want to trust fully). I'm going to be playing at 1080p 144hz, so my question is what should I go with. Both are the Zotac white amp ones, if that changes anything. \n\n\n\n  \nPS. According to him, the 3070 is off of FB marketplace but is sealed and brand new.  ",
    "comments": [
      "Intel B580... don't get an 8gb card in current days...",
      "The RTX 3070 8GB is the faster GPU in terms of rasterization. The RTX 4060 8GB supports frame generation.  \nLook at Techpowerup's review of the RX 7800 XT (https://www.techpowerup.com/review/amd-radeon-rx-7800-xt/31.html), and the average FPS:   \nAt 1080P:     \nThe RTX 3070 8GB averages 121.3 FPS   \nThe RTX 4060 8GB averages 96 FPS",
      "3070 is the better GPU, although, you have access to FG with 4060 and lower power draw, but at this point you can buy 4060Ti.\n\nSo i would pick up the 3070 (if your PSU can handle it) and just install FSR3FG mod on games, that use it. Enjoy!",
      "No, FG works like a dream for me. Even the FSR3FG did.\n\nThe RT is more of a gimmick.",
      "Used 3080",
      "6750XT",
      "The intel arc cards that just came out are a good rival to a 4060 and are getting alot of good reviews and they are around 250 I think for the b580.",
      "Be a Chad and get the arc b580",
      "FG with 8gb doesn't work all the time, on any games that already use 8gb of vram without FG, will get lower performance once you turn it on, unless you drop the settings alot to free some vram, \n\n\n3070 is pretty much a 4060 with FG always on, plus you get a way better memory interface, so you get better performance in memory bandwidth hungry games and at 1440p/4k(older titles), so the 3070 is the clear winner hands down",
      "3070 700W should handle it",
      "If rtx 3070 is equal or cheaper than rtx 4060,  go for rtx 3070. Dont worry about frame generation. There is a tool in steam called lossless scaling. Assuming you get 60fps desired games, you can use that tool using lsfg. The only catch is, you will be paying $7 to buy the tool, but its worth it",
      "Wait 1 week if you are willing to use second hand market. Many people might sell their 4070 or 4080 for a 'decent' price with the coming of new gpus",
      "I would pair with a 4060 Ti, better price to performance when looking at it that way",
      "It would be better to shoot for a 4060ti 16gb model",
      "Yup, B580 or 6700XT/7700XT depending on pricing.",
      "if I could find one in my area, I would",
      "4060ti 8GB - $380 mean while the 7700XT for another $20 has 4GB more vram and \\~14% more performance according to techpowerup...\n\nAnd the 16GB variant is even worse, $450 while the 7800XT is $30 more and has \\~38% more performance according to techpowerup...",
      "$450 at the lowest while the 7800XT is $30 more and has \\~38% more performance according to techpowerup...",
      "4060ti 8GB - $380 mean while the 7700XT for another $20 has 4GB more vram and \\~14% more performance according to techpowerup...\n\nAnd the 16GB variant is even worse, $450 while the 7800XT is $30 more and has \\~38% more performance according to techpowerup...",
      "It’s not a gimmick, but FSR framegen and Lossless scaling (on steam) frame gen work on all cards and are just as effective.\n\nI’ve tried them all, and there’s no reason to really buy a 40 series for framegen. You can get modded games that use FSR3 and look just as good. It’s even compatible with basic DLSS"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "mid",
    "matched_keywords": [
      "rtx 3070",
      "3070"
    ],
    "title": "Does the RTX 3070 have 12 pins or 8 pins? I’ve seen pictures of the card with both",
    "selftext": "",
    "comments": [
      "The RTX 3070 will have an 8-pin socket as per Nvidia's specs chart on their website",
      "Nvidia website says 1x 8pin on 3070 and 2x 8pin on 3080 and 3090 (probably to accommodate the included 12 pin adaptor)",
      "Nvidia’s spec page states 1x PCIe 8-pin for the 3070, but it also says 2x PCIe 8-pin for the 3080 and 3090. \n\nIt must be noted that these are listed as “supplementary power connectors\", so this spec only refers to the appropriate ATX connectors that must be adapted, not the actual connector that is on the card itself",
      "To stop the 5G giving your GPU Corona of course!",
      "Digital Foundry showed off the adapter in their video:\n\nhttps://i.imgur.com/DgAePuV.png",
      "Even on their website (the link you just sent) they have a photo of a rtx 3070 with a 8pin and a rtx 2070 with a 12 pin. Weird.. (rtx 3070ti?)",
      "I don't really know why the 3070 would use a 12-pin connector too, unless they were just trying to simplify manufacturing. An 8-pin PCIe power connector can supply 150W, which, in addition to the 75W supplied by the PCIe slot itself, is just enough to handle the 3070 at 220W. Maybe they're going for overhead, though. If either of those are the case, I'd expect the same 2x8-pin -> 12-pin converter as the 3080 and 3090.",
      "All of Nvidia's current images point to a 12-pin connector. I'd expect a 12-pin to 1x 8-pin adapter in the box",
      "[https://www.nvidia.com/en-us/geforce/graphics-cards/30-series/rtx-3070/](https://www.nvidia.com/en-us/geforce/graphics-cards/30-series/rtx-3070/)",
      "My question would be do I drill the hole in the motherboard above or below the card for neater cable management?",
      "It has a dozen molex connectors, all round the sides. Hope that helps!",
      "A single 8 Pin to 12 Pin Adapter would not make any sense though.",
      "Could simply be to solidify the 12-pin as a standard to speed up adoption by PSU manufacturers.",
      "still doesn't explain the stock photo showing both inputs. Confusing hope we get confirmation soon. I have a Strimer Plus on my card so I'd like to know the answer.",
      "All dependent on the board partners...  Too early to call and definitely not across the bar.",
      "true but if you zoom in on the card it changes to an 8 pin. Also their spec sheet lists an 8 Pin as a requirement.",
      "They won't make a single 8 pin to 12 pin adapter for the reason that half of America thinks \"if it fits, it should work\".  nVidia isn't stupid enough to have adapters out there that will \"look\" like they should work with 3080 and 3090, but don't supply enough power.  \n\nIf the card uses a 12 pin, there will be a dual 8 pin adapter just like the one included with the other cards.",
      "that's not what i read...12pin on 3080/90 but not the 70.",
      "No, the photo of the 3070 has a clear 12 pin....",
      "Don't know why you're being downvoted, but you're right. It's really ugly."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "mid",
    "matched_keywords": [
      "3070",
      "3070 ti",
      "3070ti"
    ],
    "title": "Rtx 4060 ti vs 3070 ti",
    "selftext": "Both have similar performance btw 3070 ti is better at raw performance... It doesn't have dlss 3... Do I need dlss 3 or should I just buy 3070ti and fsr3 will work fine?",
    "comments": [
      "doesn't really matter bc neither really has the extra vram for framegen",
      "> It doesn't have dlss 3\n\nYes it does, all RTX cards can do up to DLSS 4 (though not multi frame gen)",
      "3070ti has better raw rasterization performance. Most importantly has 256bit memory interface compared to 132bit(?). 3070ti over 4060ti if you play above 1080p",
      "How much does that cost for you?",
      "a kidney",
      "In that case get a better GPU :)",
      "Used is a gamble",
      "People are pissing on GPU companies and that dropped kidney prices.",
      "Just to clarify OP, the 3070ti can use DLSS 4 upscaling (transformer model). The ONLY limitation you have with dlss is you can't use DLSS frame generation, but you can use all the other features it offers. Unfortunately, if you try to use the transformer model of Ray reconstruction there can be as much as a 25% hit to your performance compared to using the old model, again, specifically for Ray reconstruction. For DLSS 4 upscaling it's only a 3-5% performance hit compared to the older model, but the increases to visual quality more than make up for that",
      "K... Im buying a 3070ti then... Coz I won't even use frame gen",
      "24k(from gameloot)Inr for white colourful igame rtx 3070 ti OC (used btw"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "mid",
    "matched_keywords": [
      "rtx 3070",
      "3070",
      "3070 ti",
      "rtx 3070 ti"
    ],
    "title": "NVIDIA rumored to launch RTX 3090 SUPER, RTX 3070 Ti 16GB and RTX 2060 12GB in January - VideoCardz.com",
    "selftext": "",
    "comments": [
      "Oh wow, more cards for me to look at and get discouraged by when they all say \"OUT OF STOCK\"",
      "i am a little mad that my 3080 only has 10 gb of ram",
      "I really don't understand the point in a 3090 Super. It would literally only be like what... maybe 5 percent faster, if even that. Also, wouldn't Nvidia have to be using perfect dies to make a 3090 Super? I'm thinking that if this card does exist then it might be a Titan instead.",
      "Great, more cards to dilute the market and more cards to fall to scalpers.\n\nIn the end Nvidia will earn them $ at the expense of dignity",
      "Call me when it’s available",
      "Actually is brilliant idea. New best card means whales dumping regular 3090 to get newest and shiniest card for premium price.",
      "Naive. Miners are just going to hop on to the next profitable coin. As soon as etherium switches over to proof of stake, there’s going to be a coin to fill it’s void.\n\nThe only way we’re going to see used mining cards flood the market is if the entire crypto market crashes. Otherwise, there will ALWAYS be a profitable coin to mine",
      "I'm pretty sure the narrative about switching coins is just FUD being spread by veteran miners to trick newbies.  Gives them time to preemptively dump their cards before anyone else.\n\nI guess more likely, it's just miners in denial.",
      "After a full year of \"NVIDIA rumored to launch product\", I literally do not care anymore. Call me when they're released.",
      "Same. This is a big stab in the back by Nvidia.",
      "> Naive. Miners are just going to hop on to the next profitable coin.\n\nIts not that simple. There has to be enough demand for that coin too. \n\nThat being said, they are gearing up to do just that. These guys buy reddit accounts and comments by the thousands to pump crypto and meme stocks.",
      "Depends how much you paid. If rrp, you are still good, if not then yes, can be tricky. Saying as 3080 owner.",
      "Well there is no denying that NVIDIA planned, and could have released a higher capacity 3080, but didn't. Why? Because 3080 Ti & 3090, people like me MIGHT be tempted onto either of those, because I want a bit more than 10GB.\n\nIt's the only thing, other than availability that has stopped me looking at a 3080, it is a great card, but doesn't have a great deal of VRAM.",
      "The fact that people were more than willing to buy the 3090 over the harder to find 3080 shows thirsty people really will spend anything to get a GPU this gen.",
      "I don’t think so.  Here is why.  There is 10x more hash power on Etherium than any other PoW crypto.  The other cryptos market caps and transactions are so small that they are already less profitable than ETH.  Once that hash power moves to alts, difficulty will skyrocket, further lowering profitability dramatically.  It will rapidly hit a point where electricity is more expensive than mining for alts.",
      "I think so too.  Now is probably the best time to dump cards for top dollar in my opinion.",
      "Any chance of a GTX1660Ti with 12GB refresh??? :)\n\n...Or any version GTX1650 with 8GB refresh??? :D\n\nEdit: Fix error spell from GTX660Ti to GTX1660Ti!!! :)",
      "Eh, it's pretty inconsequential. I have a 3080 also, and VRAM hasn't been a problem one single time. By the time it's legitimately an issue we'll be gaming on 5080's or 6080's.",
      "By the time you get new with more ram 4070 will be here. Enjoy in what you have, there’s always better tech coming.",
      "2 extra gigs for only 500$ more."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "mid",
    "matched_keywords": [
      "rtx 3070",
      "3070"
    ],
    "title": "rtx 3070 undervolt",
    "selftext": "i barely know how im supposed to undervolt my 3070 but is this a undervolt and if so, is it too much or too little or is it good?",
    "comments": [
      "Your picture doesn’t really show the clocks on the left.",
      "That’s a 3070 not 4070/5070",
      "That's too low imo. You can go at 950mv to be sure of the stability, and see in what clock you can achieve that\n\nEdit: saw the other screenshot. You can do 950 at 2000ish mhz.",
      "If you are aiming for lower temps at stock (or slightly better) performance try 1860MHz@0.825V.\n\nRan than on mine for years. Temps were ~7°C lower and fan speed around 10% lower (approx values as I have moved on to another GPU).",
      "https://preview.redd.it/6kuhduvl6ove1.png?width=1228&format=png&auto=webp&s=7d7244da10bfdc0e8ce0356025c4eff26e20674d\n\nmb, heres a better one",
      "I think you can try higher clocks at that voltage. Like 100 more.",
      "Oof I don't know why I have so much trouble with this. I'm constantly typing 3080 and 3070ti etc when trying to research the new cards.",
      "You can probably do like 2900 at .9v"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "mid",
    "matched_keywords": [
      "rtx 3070",
      "3070"
    ],
    "title": "Just got an RTX 3070 Eagle oc for about $310",
    "selftext": "As the title just mentioned, I got an RTX 3070 on a reselling website and I was wondering if there was something wrong with the Eagle oc version. On all sites I've seen that the 3070 sells for about $550, so this led me to wonder why if the Eagle oc just wasn't a good version, because to me this was just a steal.",
    "comments": [
      "$310 for a 3070 isn't a steal.",
      "The 3070 is no longer produced so supply of new cards are extremely limited. The original MSRP was $499 but there are now 2 generations of cards that came after it so it is outdated. The $550+ price are retailer holdouts who refuse to drop prices and will that single card in stock forever unless some less uninformed buyer picks it up.\n\n$310 isn't a steal, its pretty much market price and the Eagle OC is one of the lowest end Gigabyte models.",
      "I’ve seen 3080s go for 350",
      "I sold mine nearly a year ago for 250, you’ve been ripped off",
      "I got one for 200",
      "I need to use PyTorch and AMD graphics cards are kind of a hassle at the moment.",
      "310$ isn't really a steal you can find plenty if 3070s on the market for 250-300$",
      "Not even close to a good deal",
      "Is it new or used?\n\nIf you check [completed/sold items on ebay with that name ](https://www.ebay.com/sch/i.html?_nkw=gigabyte+rtx+3070+eagle+oc&_sacat=0&LH_Sold=1&LH_Complete=1&rt=nc&LH_ItemCondition=2000%7C2010%7C3000%7C1500), you'll see what they've been going for.\n\nI don't think this is nearly as bad as some other people will have you believe. If you're happy then that's really all that matters.",
      "Considering the most commonly used cards on Steam are, in order... 3060, 4060mobile, 4060, 1650, 4060ti, 3060ti, 3070.\n\nThey should be ok. Not everyone can afford a 5090.",
      "You definitely wouldn't have been flamed as much if you included that in the post. But like I said, all that matters is whether you're happy about it. Enjoy the card!",
      "How can it be a steal if you can grab a 6800xt easily for $350?",
      "Nah the card doesn’t have enough performance per gigashits and the tetraflips aren’t flipping fast enough good luck playing games in a year buddy",
      "Thanks. But I didn't expect much from Reddit. Used to be a regular Redditor, but most Redditors are just snobs.",
      "It's new and my old gpu is now almost 7 years old now plus I live in Switzerland so you can always expect a 10-20% markup on everything compared to other countries.",
      "It doesn’t have to be the deal of the century—so what? This guy bought a graphics card, probably saved up for it, maybe even dreamed about it for weeks, and was happy enough to share it here. And yet, you all just crushed his excitement in an instant. Do you know how rare it is to genuinely enjoy something these days? What matters is that both the buyer and the seller are happy. Let the man have his moment.\n\nCongrats on your new card, buddy! I hope you enjoy it in good times.",
      "Oh well, it's just money"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "mid",
    "matched_keywords": [
      "rtx 3070",
      "3070"
    ],
    "title": "Is RTX 3070 for $300 a good deal?",
    "selftext": "I currently have GTX 1650. They are some good AMD gpus but I rather stick with NVIDIA. So it's either 6700 or 3070.",
    "comments": [
      "I paid like 700$ for mine mid-Covid madness 😭",
      "Yes. The increase in performance will also be legendary compared to your 1650.",
      "If it’s working, yes.",
      "And that was actually a good deal at the time",
      "I almost bought a 1200 dollar 3080 so many times lol, but then i was patient and waited, and finally bought my 4080 for… 1200 dollars lol",
      "A 4060 is better in the way that it has DLSS3 and way less power consumption. But in games without DLSS3, the 3070 performs way better, did you also test in games without DLSS3 (which sadly are quite a lot)?",
      "Eh I’d look for $260-280 in my region. My $300 3070ti hasn’t sold lol",
      "Isn’t the RTX 3070 better? Should I go for the 4060? I did see it has frame generation and I also wanted to play Portal RTX but I heard there’s better cards I could get.",
      "That would be extra $400 for me. I’m not sure if it’s truly worth it to wait because it’s not like the 3070 doesn’t run at 60fps or more at high or ultra settings on most games. To me it’s between 4060 and 3070 because I want to try CP2077 Path Tracing.",
      "Using 3070 for almost 2 years now, go for it, excellent 1440p and 1080p card.",
      "Yeah a friend of mine paid either a 1000 or 1100 for his 3070 when got it which part of what pushed me to snatch mine up because it was \"only 700\"I probably could've been more patient but I had just upgraded from a 1080p monitor to a 1440p ultrawide and my older gpu was not having it",
      "lol then you plan on not playing a good amount of games?",
      "Nvidia plant comfirmed",
      "Im having a hard time finding a 3080 for $300-$350 on HWS. More like $400 for it.",
      "Idk what it is about my setup (13900k, 6400mhz Corsair Dominator Platinum DDR5, ROG Strix 4090, Z790 Aorus Master) but frame gen introduces substantial frame pacing issues and extreme latency (>100-150ms) in every title I’ve used it in, even with Nvidia Reflex set to “Ultra.” \n\nHave you had a good experience with frame gen?",
      "6700 is only 2 more gb of ram and 3070 is faster. I think I’ll be fine with 3070 for 1080p. I’m not trying to buy a GPU that lasts me 5 years, maybe I’ll upgrade again in 2 years.",
      "It’s easy to get stressed about buying the right card or whatever but honestly once you actually have it you care a lot less. Any new card is gonna play games just fine as long as your expectations are reasonable and you buy the right card for the resolution you want.\n\nAnd all the new gen cards are basically the same price as the “great deals” during the mining craze/pandemic and you woulda had to wait an extra year or two",
      "I’m sure I’m doing something wrong. I’ll toggle vsync in NCP and in-game and see if maybe vsync was getting enabled at the driver level or something, idk.\n\n**EDIT:**  **I was doing something wrong, lmao.  See my edits to the post you replied to.  Thanks for the reinforcement re: my dumbass-ery.  Appreciate you.**",
      "Is that Pounds or USD?",
      "Be pounds dude."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "mid",
    "matched_keywords": [
      "rtx 3070",
      "3070"
    ],
    "title": "[Help] RTX 2000 Ada (16GB VRAM) vs RTX 3070 (8GB): Which should I keep?",
    "selftext": "I have two graphics cards and need to sell one. Looking for advice on which to keep:\n\n**RTX 2000 Ada:**\n\n* 16GB VRAM\n* Lower power consumption\n* Frame generation support\n* AV1 decoding capability\n* Newer architecture\n\n**RTX 3070:**\n\n* About 25% faster performance\n* Completely silent operation\n* 8GB VRAM\n* Uses 4x more power\n* Older architecture\n\nBoth cards would sell for roughly the same price. With the new 5060 also having 8GB VRAM, I'm wondering if 8GB will remain sufficient for games at reasonable quality settings for the next few years.\n\ni keep my cards for a long time, and dont want to upgrade in teh next 3 or 4 years. i play at 1440p.\n\nWhat would you recommend keeping? Which factors would you prioritize?",
    "comments": [
      "> I'm wondering if 8GB will remain sufficient for games at reasonable quality settings for the next few years.\n\nNo, even now, the Oblivian remake, 1080p medium uses 7.7 GB VRAM... ( keep in mind Windows also takes up some VRAM  )\n\nIndiana Jons I think already just runs out of VRAM on 8 GB crads\n\nThose 2 are what I happen to think of right now, there's other **current** games where 8Gb means you're gonna play at 1080p low or medium\n\n9 years ago, the [RX480](https://www.techpowerup.com/gpu-specs/radeon-rx-480.c2848) had 8Gb vram\n\nPS6 is coming in 2027, and is gonna have +16Gb...Ray Tracing needs more VRam... Frame Gen needs more Vram... 8Gb is gonna be a real drag over the next 3-4 years, it's already starting to be now\n\nThe reason Nvidia's sells some low end cards with 8Gb is because they don't really want to sell them \n\nTSMC can only make a limited number of chips for Nvidia, and Nvidia much rather turn most of that capacity into AI cards, and sell them for 20.000-30.000$ each \n\n( instead of \"only\" 500$ for a 5060 or whatever )",
      "to be honest with u, 5060 Ti 16GB is ur best choice, otherwise, all other options below that are subpar, and RTX 2000 Ada is not a gaming card, performance is shit, so u r not getting anything out from the extra vram, so keep the 3070 for now and save some money, then sell it later and get the 5060 Ti",
      "sell both and get 5060 Ti 16GB",
      "in my country, the 5060 ti is more expensive than the two i have combined, so in this scnenario not only i dont get the sale price of one card, i would need to pay.",
      "how much u have to pay over both?",
      "the cheapest one (gigabyte) is about 150 usd over combined sale price (300 each)",
      "Is that how the GPU prices usually are in your area or because 5060Ti is the newest one? What about a 4070?"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "mid",
    "matched_keywords": [
      "rtx 3070",
      "3070"
    ],
    "title": "ROARing RTX GeForce 3070 is very LOUD",
    "selftext": "So, I have an Nvidia GeForce RTX 3070 in an HP 12700 rig with 64 GB. The GPU fan is really LOUD. I really only hear this in DAZ when in iRay preview mode in the Viewport (not actually rendering). However, I am barely able to adjust figure poses and the entire PC lags. Using a software Monitor, I see the following settings: (I have nothing to compare this against and I was wondering if you see anything in these readouts to be concerned about.) **1130 RPM (33%) @ 45°C**",
    "comments": [
      "Well it’s not overheating and 1130 rpm should be really quiet. You likely have a bad fan bearing. Replacement fans aren’t too expensive but you’ll have to partial or fully disassembled your gpu. And if it’s fully disassembled you will need to replace the thermal paste and possibly the thermal pads too.",
      "You barely meet BARELY meets the 8 GB requirement for BASIC 3D work in DAZ, mate. You must upgrade to a 40 series card with 16+ GB of VRAM since the 50 series has a potential ROPs issue and still has somewhat low supply.",
      "I second the comment above, but I would add that you could try using MSI Afterburner to underclock and see if that reduces noise enough for your preference. There will be some performance cost, but it is non-linear.",
      "I guess I'll just have to go back to working in Smooth Shaded view then; there's no way I can afford even a USED 4070 ti!  I wonder why Character Creator 4 is so much more frugal, especially when its models look better??  Any comment on the loudness? But Thanks for the info!",
      "For anyone else reading this, I have had very good luck following these settings to get decent performance:  \n[https://irendering.net/best-iray-settings-for-fast-rendering-in-daz-studio/?fbclid=IwY2xjawJ-QMtleHRuA2FlbQIxMABicmlkETFhSU5kZTZMb1pWbzAwUTZaAR4jAVh9ijepdTN4YKkpYdxCw2LS7ZSJ5z5E-Qln1D1gWoLg9jemDfmd3u3dMg\\_aem\\_LyYWc3VmF0iOagMwTVg1Ag](https://irendering.net/best-iray-settings-for-fast-rendering-in-daz-studio/?fbclid=IwY2xjawJ-QMtleHRuA2FlbQIxMABicmlkETFhSU5kZTZMb1pWbzAwUTZaAR4jAVh9ijepdTN4YKkpYdxCw2LS7ZSJ5z5E-Qln1D1gWoLg9jemDfmd3u3dMg_aem_LyYWc3VmF0iOagMwTVg1Ag)",
      "It, generally, means you’re nearing or hitting the VRAM/frame buffer. For example, my old rig’s 1660 Ti got so bad that it’d become angry just doing mundane stuff.",
      "Wow! And this is just with one, unclad figure! Geez... Okay, thanks!"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "mid",
    "matched_keywords": [
      "rtx 3070",
      "3070"
    ],
    "title": "Just finished building an Aorus RTX 3070 Build with Ryzen 5 5600x ,and Aorus monitor FI27Q , I honestly didn't like the Ac800 tower from Aorus so thinking to change it to a liquid cooler in the nearest future .",
    "selftext": "",
    "comments": [
      "Got a bad news for you buddy. You’ll be using RGBFusion",
      "Yeah it's like the worst piece of software on the market. I don't like the msi bloat center either.\nCan give signalRGB a try.",
      "I fucking hate useless comments like this",
      "Idk the fan cross points into the case and usually is an indicator for the direction the air is flowing to, hence both , your rear case fan and your top fans are pointing in the wrong direction if you ask me",
      "You are right ! 💯 Right thank you so much I have just changed them right now ! Much appreciated and a life saver :)",
      "Btw. Is your rear fan actually an intake rather than exhaust fan? Should check that.",
      "And ? Lol",
      "Right? All hardware will be old eventually. By that logic you should never build a PC in the first place.",
      "Just like the geniuses who were like \"sell your 2080Ti now that it's still valuable, it's going to be obsolete when the 30 series comes out\" or \"why buy now, wait for the 30 series in a few months to finish your build\"... yeah that worked out great",
      "Uh oh... Gigabyte psu detected",
      "MSI center barely functions properly anyway - often the colours are completely incorrect and it’s really clunky even when it does work.\n\nI’ve just replaced it with openRBG and it’s the best one so far.",
      "Just was fancy this particular build nothing much 😃.",
      "I'll wait for it till it drop in the price :) thanks .",
      "Meant to say VAG sorry for that , but definitely they still use different components , couldn't be the same ones , anyway I have aorus PSU will keep an eye and update you here if it blow up or not lol and if it doesn't that proves Aorus use different circuit in their products .",
      "I wouldn’t go liquid cooling on just a 5600X unless you’re really wanting the aesthetics (which is perfectly fine!) but if you do make sure you have enough clearance to do a top rad :)",
      "No worries, enjoy your rig ;)",
      "Congrats on your build. Enjoy it to the fullest. :)",
      "Nevermind the pc that desk is gorgeous",
      "Liquid cooling is a waste of time and space",
      "Nice to hear , will stick for now to what I have for few months , thanks ."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "mid",
    "matched_keywords": [
      "rtx 3070",
      "3070"
    ],
    "title": "Help to choose budget GPU RTX 3070 Palit/Gamerock, RX 6750 XT, RTX 4060",
    "selftext": "Hello, please to make a choice with budget GPU.  \nSo far from google i got that 4060 only good in power efficiency, but loses in raw FPS. But i was wandering if 4060 performance is smother in newer games and there is going to be less problems in future.\n\nMby there is some GPU that i should look into it. Going to take they from local \"ebay\".\n\nRight now im on Ryzen 5600, RX 580 PCI 3.0x16. Im going to upgrade motherboard in future, but right now its not much performance lose compare to PCI 4.0. And im sticking with 1080p monitor in a near future. ",
    "comments": [
      "6750 xt because the vram then 3070. I say this as a 3070 user I wish I went for a 3080 because of the vram. 4060 is just shitty like 15% worse than a 3070.",
      "Thank you"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "mid",
    "matched_keywords": [
      "rtx 3070",
      "3070"
    ],
    "title": "7 years with the Gigabyte G1 GTX 1070, time to upgrade ROG Strix RTX 3070",
    "selftext": "",
    "comments": [
      "You’re getting a nice upgrade but 8gb of vram to 8gb if vram after 7 whole years is going to hinder you in the future.",
      "its not going to last 7 years",
      "I'm using a gtx 1070 8gb too, and yeh why tf would I buy another 8gb card 7-8 years later, hopefully get one of the 50 series with 16gb",
      "If you can swing for a 4070 ti super over the 3070 8gb. I made this mistake a year ago and I upgraded like a week later.",
      "Or even 2 years.",
      "Yeah idk I ended up upgrading to a 4080s because my 3070 had 8gb of vram and I was starting to feel it.",
      "I might do the same, but if the 5080 costs more than £1200, I might just buy a 4080 super",
      "Congrats, you just doubled your performance.",
      "You mean 4 years? Look up the release dates on both gpus",
      "I'm so curious to see the specs and the difference between the 40 and 50 series, only a week to go lol",
      "Why not 40 series? Its going to be cheaper next year",
      "Tbh if you can find a TUF 4070 ti super 16gb has quite less than triple or near double the price of that rog strix 3070, then i’d jump to that 4070 in a heart beat.",
      "Get a 12GB 40XX series instead.\n\nI went from a 1070 to 4070 Ti.",
      "Can't buy a 30xx in the face of 40xx 's far better efficiency.\n\nRethink time.",
      "![gif](giphy|GwvnkalxRdIs36khbb)",
      "ah yes, I HAVE to save all my money to give to Nvidia. all hail Nvidia.",
      "?\n\n7 years have passed. Why on earth would you opt for such a lame upgrade after almost a decade.",
      "Perhaps better financial judgment is required if after 7 years you struggled to save $500.",
      "perhaps people don't have hundreds of dollars to spend like that",
      "7 years to double performance is pathetic."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "mid",
    "matched_keywords": [
      "3070"
    ],
    "title": "Need help - RTX 3060 Ti / 2080 Ti / 3070",
    "selftext": "Upgrading GPU of a 10 year old PC\n\n\n1440p 32” monitor (Buying after GPU)\n\nSystem Model: MS-7821\n\nGraphics Card: GTX 1060 6gb\n\nProcessor: i7-4790K 4.00GHz (8 CPUs)\n\nMemory: 16GB RAM\n\nPSU: ZM700-GV (700W)\n\n\n\nI will be buying a used GPU for future proofing. Aware of CPU bottlenecking and the risk of PSU having deteriorated.\n\nWhere I live\n\n3070 goes for ~$350\n\n3060 Ti goes for ~$280\n\n2080 Ti goes for $250 - $350\n\n\nAccording to benchmarks (using an i9-12900K), these GPUs rank pretty closely. I’m also considering the Radeon RX 6800. \n(https://www.tomshardware.com/reviews/gpu-hierarchy,4388-2.html)\n\n\nAny thoughts or experiences with these options in a similar setup?\n",
    "comments": [
      "U want a future proof gpu but ur considering 8gb vram cards at 1440p?",
      "3070. Look for a 3080 if you could tho, that card is goated. You might find 3070 8gb VRAM limiting when upscaling, but I'd take that over the slower 3060. Compared to the 2080ti, its pro is 3gb more vram, but the 3070 has better rt, power efficiency, and ports (hdmi 2.1/dp 1.4).",
      "I would say 12gb for 1440p would be the minimum to look for",
      "Alot of games depending on what if you're willing to tinker with in graphics settings will allow a 3060 to function at 1440p 60+fps though you are using a 32\" a 3060 might not be able to handle that for 60fps.  \nI was using a 3060 12gb for 1440 on a 27\" and it was running fine but obviously i had to use optimized settings in the more demanding games.  \nI'm not even sure what PSU you're using i can't even find that in the tier list  \n[https://docs.google.com/spreadsheets/d/1akCHL7Vhzk\\_EhrpIGkz8zTEvYfLDcaSpZRB6Xt6JWkc/edit?pli=1&gid=1973454078#gid=1973454078](https://docs.google.com/spreadsheets/d/1akCHL7Vhzk_EhrpIGkz8zTEvYfLDcaSpZRB6Xt6JWkc/edit?pli=1&gid=1973454078#gid=1973454078)  \nmaybe you can take a look here for a suitable psu if you're planning to get a new one.  \nI would definitely recommend a 10+gb vram on a gpu now atleast if you plan to play on 1440p especially since if you plan to full ultra all settings then 8gb won't be enough.  \nDepending on the prices i would recommend looking for the Rtx 4070 super that card price to performance wise use to be very good and with 12gb compared to if you can only get the 10gb on the rtx 3080 is a lot better. The performance is also slightly better and will age better in the long run also the suggested psu is 550w which means you could get away with your older power supply or if you get a new one you could get a 600-650w one instead of a 700-750w one.",
      "Is an RTX 3080 with 10 or 12GB suitable?",
      "It is recommended for a 3080 to be used with a 750W PSU. My 700W is 10 years old so it seems very risky. I guess I could replace it.",
      "Go for 2080 Ti 11GB or 3080 12GB if you can find one cheaper than 3080 Ti",
      "☝️🤓"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "mid",
    "matched_keywords": [
      "rtx 3070",
      "3070"
    ],
    "title": "RTX 2080ti vs RTX 3070",
    "selftext": "At the same price, should i buy 2080ti or 3070 for 1440 on recent game and 2160 for older game, pairing with a ryzen 5 3600x ?",
    "comments": [
      "They're roughly equivalent, but 3070 draws less power, and 2080Ti has more VRAM.",
      "Wondering if you’d be able to find any amd graphics, tend to work better with ryzen processors apparently. Would you be able to find an rx 6800 or rx 6700XT for that price? RX 6800 would have better performance and vram",
      "How much you paying for it?",
      "Whichever is cheaper. The 2080 Ti is technically faster, but by 1-2%, as well as it having more vram, but it doesn’t really matter.",
      "2080Ti, VRAM alone cripples the 3070 on 1080p already.",
      "I sold my 3070 because 8GB of VRAM is not enough anymore.",
      "2080ti as you gonna need more Vram but don't expect the RT to be spectacular.",
      "I prefer the 2080Ti since it is usually cheaper and has extra VRAM. Both perform very similarly.\n\nThat said, if they're the same price then you might appreciate the newer ray tracing cores of the 3070, in RT games it will perform a little better. Downside is the 8GB VRAM of the 3070.",
      "250€",
      "In 4k, the 2080ti perform better than 6700xt (for the same price), and the 6800 is around 300€, not my budget.\nIn 1080p and 1440p, rx 6700 xt perform a bit better than rtx 2080ti",
      "I guess that’s why both 2080ti and 3070 are both at the same price, basically one has better performance the other more ram. To be able to have both my guess would be that you’d need to get a better one. If you could save a little longer or just get some extra money I’d say try to get the rx 6800. Games at 4K majority will require more than 8gb. But if you don’t want to wait or so I’d say go for rtx 2080ti. Although you will be able to play some games at 4k but will need to tick off a few settings most likely",
      "Thank for the response !"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "mid",
    "matched_keywords": [
      "rtx 3070",
      "3070"
    ],
    "title": "Would i be able to go from a RTX 3070 to a 4070?",
    "selftext": "I am not too experienced with PCs but starting to get into PCs more as i’ve had a PC for a while but now playing it a lot more. \n\n\nCPU: Intel i7-11700f\n\nHowever i am wanting to upgrade my GPU. I was trying to look it up and i am unsure if my Power supply ( 700W 80 Plus Gold) would be able to support the 4070 and if it is compatible with my motherboard board (is an Intel B560)  and would fit in my case which is a Mid tower: Rosewill SPECTRA D100\n\nI was wanting to get more VRAM to hopefully help run some fps games smoother at higher frames. \nMy gpu currently has 8 GB GDDR6 video memory",
    "comments": [
      "Your psu will be fine. The case measurements you will have to do yourself(card size will depend on which brand you choose). The gpu works on the motherboard.\n\nJust fyi 3070 to 4070 wont be that much of an upgrade. \n\nIf you really want to upgrade i would go for a 5070 or a 5080, if you have the money of course.",
      "Just so you get an idea the jump from a 3070 to a 4070 is like jumping to a slightly slower 3080. It's nothing crazy so keep that in mind\n\nYour PSU can handle a 4070",
      "I'm running a 5080 with a 750w PSU , you're fine",
      "Upgrading to a 4070 super/ti would be better worth it",
      "Just to add my opinion as I did exactly the same move a couple of years ago.\n\nThey’re worlds apart. Even though specs may not say so. But the advances in frame gen and DLSS meant that for months of struggling with cyberpunk with my 3070, with the 4070 all of a sudden ray tracing and all the advanced effects were able to be used. \n\nIt’s quite a step up. Obviously the 4070 super is the better buy now, dependent on price.",
      "You will need to post a few more specs here;  first, the 700W PSU should work but you need to factor in what CPU you are using and also reference the recommended PSU power level from nVidia's website.  Likely you will be fine but it's worth looking up that recommendation from nVidia and also you should use one of the various online PSU calculators where you put in the GPU and the CPU and a few other things (AIO or fan counts sometimes) and it gives you an estimate for the power needs of the PC and then some headroom above that to arrive at a PSU level.   As for fitting in your case, just measure how much room you have in your current case (likely left to right if the GPU is mounted horizontally) and then when you are looking at 4070 models go to the website for the card maker and it will show the size of the card.  4070s are not gigantic so it should work in your case but it's for sure worth measuring things before you buy a card.",
      "nice! do it man!",
      "At least go for a 4070 super, or try your luck with the 5070",
      "I would wait for the 5070 and 9070/XT before doing so. I wouldn't really say the jump from 3070 -> 4070 is worth it\n\n700W should be fine",
      "No, go for the damn 4070 ti super or the 4070 super depending on pricing.",
      "PSU calculator"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "high",
    "matched_keywords": [
      "rtx 3080",
      "3080",
      "3080 ti",
      "rtx 3080 ti"
    ],
    "title": "RTX 3080 Ti is priced at US$999 to compete with RX 6900 XT, Will Debut in January",
    "selftext": "",
    "comments": [
      "100% agree with this. Keep seeing 3070/3080 posts and never once saw one available anywhere. I want to upgrade my 4 year old 1080 damnit.",
      "Yep, the calendar sets up nicely.  I get to whiff on something each month:\n\n6800XT - November\n\n6900XT - December\n\n3080 Ti - January\n\nCan't wait to not get any of them!",
      "You think ppl that spend $1500 on GPU care about $500? All they care about is \"the fastest\" which 3090 will remain.",
      "I just got a Founders Edition in my Best Buy shopping cart and jumped through all the ridiculous hoops (two clicks to  add to cart, verification code, typing address even though logged in...)\n\n\nAnd then got \"sorry, sold out\". Maybe one day I can add a 3080ti to my shopping cart.",
      "3090 early adopters on suicide watch",
      "Of course. How else will reviewers review them.",
      "Honestly the best thing Nvidia can do to counter AMD is _actually have cards in stock_. Instead they're thinking of adding another SKU to further fragment their production.",
      "Super cool of Nvidia to keep releasing products no one can have lmao",
      "JUST PRODUCE MORE 3080s GODDAMN IT",
      "> 3080ti just need to have high availability!\n\nI too love to daydream.",
      "Google translate\n\nAccording to news from the Taiwan board manufacturer, NVIDIA has confirmed that it will launch the GeForce RTX 3080 Ti in January. The price is estimated to be US$999 against AMD Radeon RX 6900 XT. The GPU specifications are very close to the GeForce RTX 3090, but the memory is frequent. The bandwidth will be reduced from 384bit to 320bit, and the memory capacity will be reduced from 24GB to 20GB GDDR6X. NVIDIA is waiting to see that AMD’s new card cannot be ignored.\n\n \n\nAccording to the information obtained, NVIDIA is planning to launch the \"GeForce RTX 3080 Ti\", which will be positioned between RTX 3090 and RTX 3080. It will use GA102-250-KD-A1 graphics core, PG133-SKU15 PCB design, and built-in The same 10496 CUDA Cores as RTX 3090, but the memory configuration is reduced to 20GB GDDR6X VRAM, 320-bit memory interface. RTX 3080 Ti will have the same TGP as RTX 3080, which is controlled at the level of 320W, and also does not support NVLink.\n\n \n\nIn terms of price, the Taiwan board manufacturer stated that the RTX 3080 Ti is estimated to be priced at USD 999. It has to be said that the price-performance ratio of the \"GeForce RTX 3080 Ti\" is much more attractive than that of the GeForce RTX 3090 at the asking price of US$1,499, which makes AMD Radeon more attractive. The price and memory capacity advantages of the RX 6900 XT have completely disappeared.",
      "Why are they talking about releasing another card when they can't even keep up with their current cards?!",
      "The AIBs will retail them for $1299.  I guarantee it.",
      "I'm honestly kinda pissed with Nvidia. \n\nI have a 3080, so maybe I don't have a \"right\" to be mad, but how/why the hell are they talking about future SKUs and future cards and AMD competition when YOU HAVE NO STOCK OF CURRENT ITEMS. \n\nI get it, I get it, some would say it's the \"same chip, better binned\" or something to that effect, but come on. \n\nyou have millions of customers waiting for 3080s, or even 3070s, and you priced the cards almost predatorily to lure everyone in, and then you can't deliver. \n\neven in THESE comments, you've created a world of disbelief because quite frankly nobody cares about the 3080ti, 3070ti, or whatever other announcement you have in mind until you can deliver the bare minimum you promised 2 months ago.",
      "People will gladly pay $300 more for double VRAM.  The 3080 should have had 16+ GB in the first place but Nvidia never misses an opportunity to grift their customers.",
      "It's a guarantee that 6900XT will not exist in a gaming PC if the mining performance rumors are true. 3080ti just need to have high availability!",
      "Hopefully this is due to a gamer-led psyop against miners to protect 6900XT supplies",
      "F\\*\\*\\* it, just tell me when to go to shop and which card to buy. I'm done with that leaks and paper launches. This is not Mercedes with a-class to s-class launches. It is hardware, launch all cards at the same day once a year!",
      "Same, but with both the FE and the EVGA XC3. Total pain in the ass for no payoff, probably the worst checkout experiences I've ever encountered.",
      "The translation is funny. Overall it's correct, but the debut in January was followed by a question mark that has completely disappeared here."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "high",
    "matched_keywords": [
      "rtx 3080",
      "3080",
      "3080 ti",
      "rtx 3080 ti"
    ],
    "title": "[Gamers Nexus] Waste of Money: NVIDIA RTX 3080 Ti Review & Benchmarks",
    "selftext": "",
    "comments": [
      "71% price increase for at best a 10% gaming performance increase over a non-Ti 3080 sums up this product perfectly. it will only sell because of the current market. in a normal market this product makes 0 sense and if you have $1200 to spend on a GPU, you probably have $1500 to spend on a GPU and would be better off getting a 3090.",
      "Steve is absolutly pissed in the video. And who can blame him. \n\nThis card exists purelly to cash in on the desperate population. Its not here to help games or anything. If Nvidia wanted to help gamers then all these chips would instead be turned into 3080's to increase the suppy of those.",
      "This product just exists to sell the near-perfect GA 102 dies that could not be packaged as 3090s or 3080s. They even gave it the smaller cooler to save money while costing nearly as much. Also I am guessing since the GA 102 is so huge there are tons of such near-perfect GA 102s that Nvidia wants to get off its hands but not at 3080 prices",
      "Nvidia aren't there to help anybody, they are there to milk the shit out of everything and everyone and expecting anything else is just a recipe for disappointment.",
      "Gotta love Steve and the gang, they say it like it is.",
      "In the end the only indicators that matters to Nvidia are how many 3080ti they can sell and how fast it will sell out.",
      "If you just look at the msrp of the founder edition 3080 and 3090s, if availability was not an issue there would be no market for the 3080 ti and that has been apparent since the 3000 series launched. There is not a large enough gap in performance between the 3080 and the 3090 to add another card that splits the difference in a meaningful way.",
      "Not surprised at all with the price. Watch them drop it back to “normal” ($1000 USD) when the market isn’t as fucked as it is right now.",
      "Every single company pretends to care about their customers, it's the oldest trick in the book. It's the same with pride month and rainbow logos - they just keep the appearance and hope to get some good PR with that, no other actions will ever be taken to actually help. \n\nIf any other corporation got into the same privileged position Nvidia and AMD are in right now, they'd milk the crap out of it just the same.\n\nEdit: confirmed my privilege",
      "As Steve mentioned, if Nvidia could have forseen the market conditions that would follow, they would have priced the 3080 higher than the $700 MSRP.  \n\nIt's already pretty evident that Nvidia initially intended the 3080 Ti to be $999, but decided to cash in on the market situation and price it at $1200 instead.",
      "Which means never? By that time next gen will release",
      "All of them, and near instantly.",
      "I feel so damn jammy I've had my 3080 for about 5 months now at a cost of £650. I really feel for you guys out there wanting a new gpu.",
      "Bold of you to assume you get a 3090 for 1500, more like 2500 from retailers",
      "Except that NVidia tries to pretend they do care about the gamer... but yeah I get it, its a corporation, increasing the bottom line is all that matters, and it does feel like they are taking advantage of the situation.",
      "Video games aren't worth this bullshit.  Fuck nvidia.",
      "Aaaaaannnnddd it's sold out in minutes.",
      ">Nvidia aren't there to help anybody\n\nAnyone who genuinely believes that are very naïve in the first place, no tech companies especially multibillion dollar ones that has their first intention to help consumers in the first place, it's all about PR marketing stunt.\n\nAnd yes same does apply to AMD with their FSR enabling Nvidia users. They are more likely doing it because they want their FSR to get adopted as quickly as possible, that's why they want to cover at least 80% of PC gamers who doesn't have RTX GPUs yet.\n\nThey all have the same goals which is to increase market share and make a ton of sales.",
      "I think Linus already said exactly what's going on here. The Ti is an opportunity for Nvidia to package the 3090 without the 24gb of RAM. Making it easier to supply by a lot because Micron the supplier of the ram is also scrounging for silicon.\n\nShould they have just focused on the 3080 or maybe even the 3070 instead,  yeah probably but,  it's basically an excuse for it to exist.",
      "I used the scalper the scalp the scalper"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "high",
    "matched_keywords": [
      "rtx 3080",
      "3080",
      "3080 ti",
      "rtx 3080 ti"
    ],
    "title": "NVIDIA GeForce RTX 3080 Ti to feature cryptocurrency mining limiter - VideoCardz.com",
    "selftext": "",
    "comments": [
      "Inb4 3080s sell for more than 3080tis KEKW",
      "30? How optimistic of you.",
      "Very likely you can literally sell a 3080 and get a high end AIB 3080 Ti for the same price.",
      "People ordering Aorus 3080s now are being told June for delivery in tbe UK so how they can release a card in the meantime is beyond me. Thankful I got a 3090 at RRP as some of the prices I've seen are crazy. OCUK had 10 3090s @£2499.99 last week and they went in 10 minutes.",
      "Not a fan of this approach. I don't really trust nvidia to purposefully nerf a card so it only impacts the one thing they are targeting.",
      "Dude you can sell a 3080 to get a kingpin 3090 rn let alone 3080ti",
      "I wonder if they'll release this in the coming months or wait until E3 / Computex in ~80-100 days.",
      "30? More like 5 seconds",
      "Nay, most gpu miners just use nicehash which just switch algorithms to the most profitable one for mining weird and unknown crypto, nvidia just want to gamers think they are doing something when is not",
      ".5? More like ~~OUT OF STOCK~~",
      "5? More like .5 seconds",
      "They have been doing it for over a decade regarding performance in professional applications vs. Quadro.",
      ">OCUK had 10 3090s @£2499.99 last week and they went in 10 minutes.\n\n\nJesus fucking christ lol, here I was thinking 3090s being *in stock* at $3099AUD (~1720GBP) was bad...",
      "Nice. I'll try to snag one and then sell my 3060Ti for stupid profit to a miner to make up for the cost of this.",
      "You mean:  NVIDIA tries to software lock their RTX 3080 Ti so they will sell more CMP cards.\n\n&#x200B;\n\nIf anyone thinks that the big miners (the ones really soaking up all the new product, let's be honest) will not be able to crack this, they are kidding themselves.  Especially if NVIDIA ups the ante by limiting multiple cards using the same method.",
      "I'm so looking forward to not be able to buy that card either because of supply !",
      "It's a bang for your buck thing. It's like 20% better performance, but for nearly double the MSRP (not that anyone is getting cards at MSRP these days). Miners are grabbing everything they can get their hands on though.",
      "Except the other algorithms aren't as profitable as Ethereum like 99% of the time, and going forward now that the 3060 exists they never will until Ethereum mining just ends. All the people that bought the 3060 are increasing the difficulty of everything else extremely quickly because Ethereum is like 95% of the mining market, so if altcoins get flooded with difficulty they'll make like 1/4th of what they are now when Ethereum ends. The only time other coins make more than Ethereum is when they briefly surge in price so it's pure speculation to mine other coins over Ethereum.\n\nThere could still be a situation where a 3080 Ti is priced similarly on Ebay to a 3080 if both are going for around $2k. Miners could keep the 3080 bid up.\n\nEdit: Hell, the 3080 could at times be selling for more than a 3080 Ti on ebay.",
      "Why are 3080s going for as much as 3090s? Are they better optimized for mining? I thought 3090 was better across the board",
      "And people have been complaining about it for a decade too u:"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "high",
    "matched_keywords": [
      "rtx 3080",
      "3080",
      "3080 ti",
      "rtx 3080 ti"
    ],
    "title": "Missing VRAM thermal pad on Asus RTX 3080 Ti TUF OC",
    "selftext": "",
    "comments": [
      "My RTX 3080 Ti had very high VRAM temperature - Tj almost always 110°C no matter what i tired. So i finally opened it up to find missing thermal pad on four VRAM chips.",
      "Jezus how can this happen on such a high-end card",
      "There are some markings on heat spreader like pad was here for a few seconds, but the VRAM chips are clean. So I assume thermal pad somehow fall before putting heat spreader on PCB.",
      "It's fine after re-padding - max 80°C on VRAM.",
      "And what now…they say it’s your fault cause you opened it?  This is bullshit for consumer protection",
      "What bothers me about all of this is that it seems to affect everyone (no consistency other than the fact anyone could be affected) and the only way I have to confirm whether my pads are present with full coverage is to risk opening the card. I mean sure, my temps are fine, but even there I have heard that replacing good working pads can be a 10C drop on memory temp.",
      "Tough luck man damn",
      "I've added missing pad and changed existing ones - just to be safe. I have also added additional pad as recommended for 3080 TUF (non Ti) and VRAM temps dropped to max 80°C. So I hope it will be good.",
      "Maybe I should do that on my 3090 FTW3, VRAM gets up to 105+",
      "wtf is this Asus",
      "For a pre-scalped card, almost double MSRP, I would expect it to have a decently high QC level before going out. At least not have the gum-stick thermal pads which are complete junk. \n\nLove their motherboards, but honestly their GPUs are way overpriced for what you get.\n\nEdit: To break down what a rip-off their pricing is. Lets say they can't sell lower than the $1,100.00 MSRP on the physical bare reference card (press x to doubt), and they still have to pay the tariffs. So, 25% of 1,100 is $275.00, so $1,375 for the base card. Looking at their custom cooler, there's no way there's more than $50.00 in parts, but lets triple it to cover R&D, so $150.00 for the customer cooler. That should make that card realistically around $1500.00. Still overpriced but maybe it's a bit better than the FE design (press x to doubt).  \n\nBut they are selling this at $2,000.00. There's no way that custom cooler they put on a reference card costs $700.00. Even a top of a line EKWB solid nickel waterblock tops out at $280.00. Completely fucking scalped at the manufacturing level.",
      "It's actually $1899 MSRP for the ASUS TUF. All the AIBs except EVGA have inflated their prices drastically.",
      "Yeah that's scary hot. Watch out for junction temps, probably +10c.",
      "My gigabyte 3090 GPU die temps idled at 50-60c. Memory temps were fine, but I was blown away at the fact that this card which cost me $1750 had this issue straight out of the box. Absolutely unacceptable.\n\nIt seems clear every single GPU partner is rushing out as many of these cards as fast as possible and skimping everything but the most basic of QC. Even if it means an extra 2-6 cards a day right now thats a massive amount of money.",
      "post in the asus pc diy group on fb im sure juan could explain more",
      "Well done fixing it yourself so comprehensively, That extra pad made all the difference for me on the non Ti :)",
      "Tuf luck man damn \n\nFTFY",
      "Theres been a drop in quality control in many card makers recently and its not limited to nvidia gpus. the most hilarious oversight that I have seen was a finger glove from a worker serving as thermal pad",
      "those were faulty components. I actually have a 1080 FTW where the VRM blew up even with the extra thermal pads installed.",
      "Dumbest take ever."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "high",
    "matched_keywords": [
      "rtx 3080",
      "3080",
      "3080 ti",
      "rtx 3080 ti"
    ],
    "title": "RTX 3080 Ti Founders Edition - Price Increase",
    "selftext": "",
    "comments": [
      "Damnnnn, even starting with the FEs now...",
      "Ah yes, a single graphics card the price of an average rig two years ago.",
      "I’m more surprised that the FE cards have held onto their original MSRPs this whole time.",
      "All Nvidia aib cards have been slowly increasing in price, while the fes have stayed the same. This is the first time I've seen a price hike on an fe card... sucks.",
      "$1200 that was a real nice rig two years ago...",
      "I regretted grabbing my 2070S for $500 back in January of '20.\n\nNow I'm just thankful I have a card at all.",
      "They're undercutting the entire market and gaining good PR doing literally nothing for an otherwise unreasonable price hike over previous gens. That's why they held onto their value for an entire year.",
      "They won't, it'll probably get worse",
      "Is there something wrong with the FE? I am very new to all this stuff.",
      "I lamented \"only\" being able to buy a 3070 FE back in Feb, but this shit has just gotten bad. Honestly, I hope this thing lasts a long damn time. FE's getting a price bump on top of an already inflated price is just bad for the people that actually use these. Fuck scalpers, and fuck fulltime miners.",
      "It happened with the 2000-series too. \n\nI got a 2070 Super shortly after they increased by £40-50.",
      "The FE cards are made in Taiwan so no mainland China tariff when sold to companies in USA.\n\nThat's a 25% saving right there.\n\nSame goes for EVGA cards.",
      "Welcome to the world we live in now 🤡",
      "And almost a high end rig two *more* years earlier than that.\n\nMSRP of 1080ti and i7-7700k **together** was ~$1000.",
      "Nvidia and AMD learned people are willing and eager to pay $500 more than a 3080 for a smidge more performance. We're never getting a 3080-level value again. \n\nPeople spoke with their wallets. The next time you see someone with a 3080 Ti, remember. They're to blame for what's to come.",
      "I'm reserved (semi-seriously) that the hobby I grew up with since 1985, the 2060 will be my last new GPU. At best it seems like I'll be dealing with used GPU's whenever a new gen comes out and the last gen prices drop... and that's being hopeful.\n\nEDIT: I will only spend so much as well, anything $800 up I don't even consider. I've never spent more than $400 on a GPU to date.",
      "With international silicon shortages and the US government pumping insane amounts of money into the economy, it is no surprise to see inflation.",
      "Given that they've been pretty much unavailable, it's not like it made any difference whatsoever.",
      "Nvidia has pretty bad customer support compared to maybe evga but otherwise it’s OK. In the past they have made some pretty terrible coolers which is why everybody wanted AIB. \n\nFounders cards aren’t bad this gen, even last gen FE design was okay compared to previous cards.\n\nMost people bought fe cards in the past because they were the first ones to get water blocks",
      "I built a complete 1080 rig for like $1500 and it has served me very well. Can’t believe how crazy the last few years has been. Rip pc gaming for me if things stay at this level for my next upgrade."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "high",
    "matched_keywords": [
      "rtx 3080",
      "3080",
      "3080 ti",
      "rtx 3080 ti"
    ],
    "title": "Finished up my Sleeper PC with an RTX 3080 Ti, i9-13900k, and working floppy drive :)",
    "selftext": "",
    "comments": [
      "Specs:  \n- Intel Core i9-13900k  \n- Nvidia RTX 3080 Ti FE  \n- 64GB of G.Skill DDR5-5200 RAM  \n- MSI Z690i Unify motherboard  \n- NZXT Kraken 120 AIO  \n- lots of Noctua fans.   \nBetter pic of the inside (w/ lots of cable mangement): https://i.imgur.com/ycETKwR.jpeg\n  \nThis was a fun project, as it wasn't as simple as \"throw the parts into the case and pray it works\"... you see, cooling wasn't exactly a great concern for PCs when this case was made. The only place for a fan was in the front, and via the PSU's fan on the top. It took a lot of dremelling, but I was able to add in a few more fans (intake on the bottom, and exhust on the back). All-in-all, I probably spent more time and money juryrigging this compared to buying a new case... but where's the fun in that!~  \n  \nThe i9-13900k is still decently cooled with the AIO, and it benches just below average (still well above the i7-13700k). The 3080 ti on the other hand, has no problems with breathing since it's got the intake pointed right at it. If a 1-2% performance hit is what I have to deal with, so sue me, I like the aesthetic.",
      "Okay… but only because you asked nicely haha\n\nhttps://preview.redd.it/8sh849y27tz91.jpeg?width=3248&format=pjpg&auto=webp&s=9e0a94138b70e9c7fc9e291e807048083f2a8598",
      "Make floppy labels for your favorite games, and have them autoexec a batch file on mount which kicks off the corresponding game in steam.\n\nFor true authenticity, stick a small fog machine behind it and trigger it based on power draw when you invite your friends over. \"Nah man, I just overclocked it a little bit. It's fine!\"",
      "Sleeper lol. You taking this bad boy to LAN parties?",
      "#I no longer allow Reddit to profit from my content - Mass exodus 2023 -- mass edited with https://redact.dev/",
      "Oof! Right in the nostalgia. Good job and sweet sleeper build! What does the rest of your battle station look like?",
      "How’s the airflow",
      "Pretty good, there's intake on the front and bottom, and then the fans on the back and in the PSU act as exhust.",
      "Sadly with a temporary setup rn that I’m embarrassed to show :P",
      "This is so late 90s setup. :)",
      "I’m glad I asked, because that’s a lovely setup you’ve got there! What’s that scanner TV looking thing you got there and how long have you been using split keyboards? How do you like the keeb?",
      "That’s cool. Show it off if you feel comfortable but no pressure. I’m fairly certain no one is gonna think it’s embarrassing:)",
      "Working Floppy Drive but no working Airflow💀",
      "The little TV on the left is a Sony BVM-D9H5U (tiny production monitor), while the big one’s a Sony GDM-FW900 (hi-res editing monitor).  \n  \nAs for the keyboard arrangement, it’s complicated lol. The keyboard I’m using rn, the Kinesis Advantage 360, is the new split model of the old Kinesis Advantage (which I loved!). I’m a huge fan, but the learning curve was a bit rough!",
      "Nah, I have both.",
      "So imagine if OP made this sleeper PC and uses it for actual work in the office and manages to have a game or two as well. One day OP's coworkers are like \"hey, we should get OP a new PC because he spends so much time on it, and have you seen it? The thing is ANCIENT and so frigging loud\". One day OP comes back to the office and his PC is gone, his hearth sinks and his coworkers and boss are like \"surprise!!\" and hand him one of those shit Lenovo Thinkstations like \"hey look, it even has an SD card reader!!\"",
      "Did you have to cut into the bottom for the airflow or remove the bottom?",
      "Windows 11 still has native support for floppy drives, and it acts just like it would back in Windows 9X",
      "Yep, exactly what I did. Those little floppy-to-usb adapters cost about $5 or whatever, and then I got a usb-to-usb-header adapter to plug it into the mobo.  \n  \nhttps://i.imgur.com/ycETKwR.jpeg <- you can sorta see the adapter hanging off in this pic, I routed it through the back of the case and then plugged it into the header right next to the RAM.",
      "You can try undervolting it. Depending on how good the chip is, you can lower the temperature quite a bit without any lose of performance (and potentially getting some extra performance)"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "high",
    "matched_keywords": [
      "rtx 3080",
      "3080",
      "3080 ti",
      "rtx 3080 ti"
    ],
    "title": "NVIDIA GeForce RTX 3080 Ti allegedly appears in HP GPU drivers",
    "selftext": "",
    "comments": [
      "Just waiting for EVGA to open up that step up program!",
      "IDK man 3080ti seems a bit dumb outside of memory. How much faster is 3090 compared to 3080? 15%? Unless the 3080ti is under  $900 it won't make sense in terms of price:performance compared to the rest of the stack which would be disappointing considering the 80 ti cards usually don't have hugely inflated halo prices like the 90's and Titans do.",
      "If it is a 20GB part with ~ 5% performance boost - it would probably match/beat the 6900 xt value proposition at $999",
      "My luck my step up period will have expired by the time it rolls out :(  I only have 21 days left",
      "This is so Nvidia can take the reject 3090s and sell them as 3080Ti's instead. Same thing they always do and probably the exact same thing the 3070 and 3060Ti are.",
      "No regrets.",
      "what even is the point of this card?\n\n3080 already is almost like a 3090 in games except for the few times where it runs out of vram in 4k\n\nis this just a 3080 with extra vram?",
      "Cant even produce enough supply for 3080/70/60Ti, never mind a 3080TI!",
      "Definitely true, but the 6900xt is way out of line in terms of price:performance and a $1000 5% faster 3080ti even with 20gb of memory would be too. IDK I think of the ti cards as the best gaming cards that make sense in terms of price:performance commanding a bit of a premium per frame, but not crazy like 30% more cost for 10% more performance.\n\n&#x200B;\n\nI remember when the OG titan was $999 and it was an insanely expensive ridiculous part. Makes me bit sad seeing regular gaming parts costing that much less than a decade later.\n\n&#x200B;\n\nedit: I know the 2080ti was out to lunch too, but at I hoped that was a one generation thing to capitalize on the new RTX features. Also it was WAY faster than 2080, not just 5-10%.",
      "Oh boy another card there won’t be enough supply of I can’t wait!",
      "Agreed. I figure there's no way the 3080 Ti will be a compelling option given how the 3080 and 3090 are already situated.",
      "People who were getting 3090 were already disregarding value/price concerns to pay for an overpriced product. They should have known what they were getting into.",
      "Ti will be slightly less cut down :)",
      "Getting a card now is going to be the hard part of that equation.",
      "saaame",
      "But the 3080 is already a cut down 3090",
      "Best I can offer is 11.",
      "I'm guessing it's just going to be a 12GB 3090 priced at $999.",
      "I think he is more referring to the fact that there is only a 15~ percent increase in performance between the 3080 and 3090.",
      "16GG-20GB or bust"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "high",
    "matched_keywords": [
      "rtx 3080",
      "3080",
      "3080 ti",
      "rtx 3080 ti"
    ],
    "title": "Meet the People Who Camped Out at Best Buy for Nvidia's RTX 3080 Ti GPU",
    "selftext": "",
    "comments": [
      "\"What's the first game you're going to play on your new 3080 Ti?\"\n\n\"Ebay.\"",
      "These people work so hard to screw people over, imagine how successful they'd be if they got a real job",
      "> While they're probably an outlier, you don't have to be jobless to be a scalper.\n\nYeah, you just have to be a piece of shit.",
      "\"Best Buy employees would later disclose that they would likely only have 64 RTX 3080 Ti units on hand during Thursday’s launch.\"\n\n\n“This is bullshit,” said one customer, who narrowly missed out on receiving the GPU after waiting since 3:40 p.m. Wednesday afternoon. He declined to be interviewed.\"\n\n\nHahahaha",
      "I know someone with 6 figure job in a fortune 500 company who has close to a dozen graphic cards that they're scalping. While they're probably an outlier, you don't have to be jobless to be a scalper.",
      "This article reads like it was about a 3rd world country waiting for COVID vaccinations.  Holy shit.  This is the timeline we're in.  Over muthafucking *graphics cards*.",
      "Basically we handed out $1000 to every person in line that got one.  Stand in line for 12 hours to make a grand is a pretty good return if you ask me.",
      "I thought I was so mart getting up at 5 to get to the bestbuy at 6. 100 people in line by that time.",
      "It is for a lot of them. People scalping these cards on fb marketplace has other listings on their profile scalping things like consoles and sneakers as their job. It's sad.",
      "id agree if i didnt expect 90% of them to be on Ebay for triple the price a few hours later",
      "honestly if they wanna wait in line and get 1 single card then sell it good for them.\n\nIf they use bots to buy 10+ cards online is when I get mad.\n\nWhen scalpers argue they are providing a service it is usually bullshit but in this case camping outside on a thursday is a good enough service to pay people to do it",
      "What more do you expect from a hyper-capitalistic society like the USA?",
      "OOOOOOOOOOOOF but who the fuck would get to be 65th or later in line and possibly think they would get a card? I seen a line of 20 and i was like nah I'm out",
      "Scalper, scalper, miner, miner, scalper, ........way end of line PC Gamer.",
      "I feel somewhat good that actual people bought these cards. Not bots in 1 second.",
      "Imagine if that's the only way you knew how to make money lol",
      "You can literally flip them for double the price immediately. Thats about how much I make working 40 hours a week after tax.",
      "What a RIP",
      "If someone wants to interview a guy who was number 42 in line for a store that had only '41' in stock despite having listed 42 cards on the manifest, I'm your guy. Pretty sure I got fucked by someone in the store that stashed one away for an employee. FML...98 people lined up at the BB I went to.",
      "The amount of cards each store had was leaked online.  He definitely could've counted the people in front of him and checked."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "high",
    "matched_keywords": [
      "rtx 3080",
      "3080",
      "3080 ti",
      "rtx 3080 ti"
    ],
    "title": "Blizzard and Nvidia investigating reports Diablo 4 is killing RTX 3080 Ti GPUs",
    "selftext": "",
    "comments": [
      "How is it even possible for a piece of software to kill a GPU? There are power draw checks and limitations, and temperature sensors that should throttle the card if it gets too hot. Literally how can this happen.",
      "Is it only 3080ti models? Seems odd.",
      "Gigabyte 3080 Ti apparently",
      "> How is it even possible for a piece of software to kill a GPU? \n\n&#x200B;\n\nStarcraft 2 has entered the chat",
      "The game didn’t blow shit up it doesn’t work like that.\n\nAnd there was an entire investigation that exposed it was a faulty component. The game just pushes the card to expose the problem.",
      "In the case of Amazon, their game was killing cards because the game was pushing the card hard enough that a defect on the card caused it to fail. This situation with D4 is probably the same.",
      "That wasn't due to the Amazons New Worlds. The mmo just made an apparent defect with the cards noticeable. Buildzoid covered this. To say Amazon did it is placing blame in the wrong place. https://www.youtube.com/watch?v=4DtUCwTXm9Q",
      "New World also. It was blowing up EVGA 3090’s at launch of the game.",
      "It wasn't. The cards themselves were faulty, any game needing a lot of performance would have done it.",
      "Trolling with their quality designs from \"beyond the grave\"...",
      "I played the early beta and capped my FPS  at 144.  \nNo problems, but I won't be trying my luck further with the open beta.",
      "I have seen others even 4090s crashing in that specific cutscene but they don't brick.\n\n3080Ti seems to just die.\n\nTo be safe, limit frame rate inside nv control panel, not in game.",
      "If you have G-Sync the best practice is to set:\n\nG-Sync: Enabled\n\nV-Sync: On  in Nvidia control panel\n\nV-Sync: Off in games\n\nPreferred Refresh rate: Highest available in Nvidia control panel\n\nWith these settings it will automatically limit your framerate to your refresh rate (it'll be 2 to 4 under actually) and from what I've read it's the best practice from Nvidia for screen tear free + lowest input lag.",
      "I saw few posts about 3080ti dying in beta forums and seems like most of them \"bricked\" during first/2nd cutscene, maybe not all but most. You can't access any settings before watching/skipping cutscene, which lasts for like 4mins. During this time my gpu (3080) was using 360W (gpu is UV to 0.862v/1920mhz) and i was using cap of 141 fps globally set in NVCP. During normal gameplay GPU wasn't really stressed at all, like 150-200w max. So WTF is going on during cutscenes? Some of them, like CGI capped at 30fps,  but \"live\" cutscenes where YOUR character model is present - 350W+ powerdraw 100% gpu use etc, and i bet my gpu would go to 450w without undervolt like there is no tomorrow.\n\nIt seems like blizzard did the same thing as new world, not capping fps in cutscenes (new world didn't capped fps in menu). And this leads to technical flaws like EVGA had, bricking affected GPUs. Of course this is definitely not the main issue, but i bet its one of them.",
      "Gigabyte is ABSOLUTE garbage!  Never buy their stuff. I’m $5k down their top tier rabbit hole and two years in and EVERYTHING is failing.  3080 laptop: dead lcd. Z390 aorus pro-WiFi: stuttering. \n\nNow a Z690 Aorus elite with a 12900k and aorus 4090…. Will see how it holds up.  It consistently misses benchmarks by 10 to 15 percent and has frame drops and stutters across most newer titles.",
      "The 3080ti ftw3 had a more robust pcb componentry than most ampere GPUs. I compared them last night.",
      "Sure, remember New World?",
      "Absolutely not! That's the whole point. When g-sync is enabled, V-sync is no longer acting as V-sync.\n\n&#x200B;\n\n\" However, with G-SYNC enabled, the **“Vertical sync”** option in the control panel no longer acts as V-SYNC, and actually dictates whether, one, the G-SYNC module compensates for frametime variances output by the system (which prevents tearing at all times. G-SYNC + V-SYNC **“Off”** disables this behavior; see [G-SYNC 101: Range](https://blurbusters.com/gsync/gsync101-input-lag-tests-and-settings/2/)), and two, whether G-SYNC falls back on fixed refresh rate V-SYNC behavior; if V-SYNC is “**On,”** G-SYNC will revert to V-SYNC behavior above its range, if V-SYNC is **“Off,”** G-SYNC will disable above its range, and tearing will begin display wide. \"  \n\n\nIt's an extensive topic and I know I got downvoted here on my answers because people simply do not realize that G-Sync is meant to work with V-Sync in the control panel, but not to act as vertical synchronisation.  \n\n\nYou can read extensively about it here: [https://blurbusters.com/gsync/gsync101-input-lag-tests-and-settings/](https://blurbusters.com/gsync/gsync101-input-lag-tests-and-settings/)  \n\n\nIt's a deep dive and has many benchmarks. Overall the long story short is that G-Sync is meant to be used the way I described above and yes the input lag will be minimal compared to no g-sync and v-sync enabled (but not as low as no g-sync and no v-sync of course)",
      "It's very real and possible. For example FurMark can kill GPUs and those warnings are not for show.\n\nThose limits aren't hard limits. There can be a spike in a micro second scale and that could be enough.\n\nMy theory is that the speed of PWM controller can be a factor and uPI controllers (found in the majority of nvidia cards) are not that fast enough when dealing with transients compared with MPS digital controllers (found only on high end AIB models like Strix and Founder's Edition).",
      ":( that's my model...\n\nI was so excited, now I must live in fear"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "high",
    "matched_keywords": [
      "rtx 3080",
      "3080",
      "3080 ti",
      "rtx 3080 ti"
    ],
    "title": "The GeForce RTX 3080 Ti comes later, the RTX 3060 earlier and the GTX 1060 3GB gets a nice successor",
    "selftext": "",
    "comments": [
      "Still waiting for the 3080 to come out.",
      "I'm calling BS on the 12GB 3060 rumour. Why would Nvidia increase production costs on a low mid-range card for no reason? 12GB is completely useless at the resolutions that the 3060 is going to be used at. Cranking up VRAM just cuts into their margins with no competitive benefit.\n\nAlso, why would a 3060 launch with more VRAM than a 3060Ti? They'd just be confusing customers as to what the performance tiers are and potentially cannibalizing 3060Ti sales.",
      "Thought that was just a myth.",
      "3060 more vram than 3080 WeirdChamp",
      "Damn, was looking forward to it in january, but if it means I can have a better memory config on it then sure, ill wait.",
      "That is not for sake of VRAM. \n\nSimply normal 3060 will 192 memory bus, and that means you have 2 possible configurations:\n\n- 1GB x 6 chips (32 bit each) = 6GB and 192 bus\n\n- 2 GB x 6 chips (32 bit each) = 12 GB and 192 bus.\n\nRTX 3070/AMD cards meanwhile has 256 bit memory bus that is why only possible memory configuration is 8GBs or 16GBs.\n\nFor 3080 and 3080 Ti we have 320bit and again 10GB or 20GB.\n\nAnd 3090 is 384bit with 2x 12 = 24GB.",
      "Seriously? 3080 is still no where to be seen except for 1000+. Regular priced ones have huge waiting lists.",
      "More like geforce spot",
      "Like the female orgasm!",
      "NVagina",
      "Where is my 384bit 3080ti with 12GB of memory?  That sounds like the dream.",
      "And the g-spot",
      "AMD did it last gen with the RX 5500 XT 4/8 GB vs the RX 5600 XT 6 GB so it’s not entirely unprecedented in recent times (not counting the 1060 because the 1070 is 8 GB), especially if it is indeed the card that used to be called 3050 Ti.",
      "The 3080ti launch is gonna be just as bad lol. Don’t get your hopes up.",
      "Likely why it's no longer coming in Jan. The hope is production picks back up next year to fulfill sales for the 3080 whilst they work on finessing and manufacturing the ti's. This is purely my own ignorant speculation though.",
      "Nice ..i guess i change my \"not in stock\" 3080 order to a \"not in stock\" 3080ti order.   \n\n\nHow pathetic. They still selling the 3070 for above the price a 3080 should cost, in europe. But at least nividia has a couple of cards in the market..not like paper launch AMD",
      "It's bad, the 6 GB and 12 GB models have different shader counts.  Same BS as the 1060 that annoyed people.  The 6 GB should be called 3050 Ti.",
      "If i remember correctly even the RX 570 had a 8gb version. \n\nThe thing with Nvidia is that they will change the Vram speed between versions and sometime the core count, The 1650 4gb was gddr5 for a year then they released a gddr6 version, They released a 3gb 1050 a while back that was faster than the regular one, The 1060 3gb was less capable than the regular 6gb version but far more powerful than the 1050 ti 4gb. It's confusing.",
      "> The RTX 3050 Ti already planned and circulated, is to be marketed as RTX 3060 6 GB\n\nNot bad",
      "Any News about a 3070TI?"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "high",
    "matched_keywords": [
      "rtx 3080",
      "3080",
      "3080 ti",
      "rtx 3080 ti"
    ],
    "title": "Nvidia Geforce RTX 3080 Ti Render",
    "selftext": "",
    "comments": [
      "Hope you're ready to see that in a bunch of news reports and clickbait thumbnails, cause that looks great",
      "\\*\n\n\\*\\*\\*UPDATE \\*\\*\\* Made some tweaks and uploaded [more renders here.](https://imgur.com/a/p745iaX) Sorry only 4k.\n\nNothing to do on 4th of July on quarantine but kick out some renders ! Makes me Happy !\n\nModeled in Solidworks, imported to C4D, rendered with Redshift 3.0.23.   8k render.\n\nMore 4k renders have been posted above.",
      "Ha. Thanks !",
      "\"I'm going to say this is shit, but I'm not gonna tell you why!\"",
      "Inb4 rtx 3000 release with a standard cooler\n(Well done on your work though!)",
      "looks solid",
      "[Guess where I just came from](https://www.pcgameshardware.de/Nvidia-Ampere-Grafikkarte-276295/News/Ein-weiteres-Renderbild-zeigt-mutmassliches-Kartendesign-1353547/)",
      "It's just a mockup based on very little leaked info. The leaked photos can be one of a half dozen different prototypes. Everything can be different when it's actually released. It's all speculation at this point until or if more leaks appear.",
      "Is that seriously where the power ugs are on the 3xxx series is? RIP sff builds I guess.",
      "Any advantages to using them over the built-in Solidworks rendering?",
      "I agree...  I'm still tweaking the materials. I'll be working on a full set of renders this weekend showing all sides and different angles. This was just one teaser.\n\nI also don't like the fan hub. It looks completely out of place. That will be fixed today also.",
      "That is funny as hell.....   Thanks for picking it up.... Wait till they see the new renders and add them to the news.....",
      "I just really hope it doesn't end up there. I want to upgrade my 980ti, but that wouldn't work with my build.\n\nIf they end up doing that, I'm blaming you for giving them the idea. /s",
      "Looks incredible! Don’t the leaks say that they’re doing a 3080 and a 3090 instead of a titanium version of the card?",
      "Drool, that is a gorgeous render! Ye-GADS do I hate the waiting, August cannot get here soon enough so we can get the details confirmed already!",
      "Thanks to solidworks. *hides*",
      "What happens in August (genuinely don't know). Is there a conference that happens? Or what? Id love for confirmation! I've been putting off my PC build since the start of summer.",
      "Yep! The horrible downside to that fact is that Nvidia claims it's pronounced like \"Tie\" (short for Titanium) instead of \"Tee-Eye\". This is according to Linus from Linus Tech Tips",
      "Rumors from tweaktown that nvidia will announce the new GPUs then release them in September. Nothing official yet though that I’m aware of.",
      "My wettest dream"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "high",
    "matched_keywords": [
      "rtx 3080",
      "3080",
      "3080 ti",
      "rtx 3080 ti"
    ],
    "title": "Defective pads and too hot GDDRX6 memory - silicon alert on the GeForce RTX 3080, RTX 3080 Ti and RTX 3090 | igor´sLAB",
    "selftext": "",
    "comments": [
      "No company is going to RMA a card that's working and not showing any problems.",
      "What to do if you're not willing to open up and change the pads yourself? Can you RMA the card before you notice any issues? My MSI 3080 is from like October 2020",
      "oh boy here we go again with the thermal pads...\n\nMy policy regarding this is just use your gpu, if it works, great, if it doesnt RMA it, but dont go out of your way to possibly void your warranty by replacing pads yourself. If a company skimps for few thermal pads let them know that its going to backfire by RMA'ing  that and dont risk it with our own money. If you replace thermal pads yourself you are not only enabling this type of behavior from manufacturers but you are also risking of losing your own money.",
      "Yes and no.\n\nEVGA offered to RMA their 1080 SC's (iirc) back in the day because they were found to have a weakness that caused them to blow under strain. \n\nSo anybody with that brand of card could get it RMA'd and switched over to the new version if they wanted.",
      "Why are you getting downvoted ?  They don’t have a mining farm it’s just a single 3080 it’s the same as any other person that owns a 3080 they just use it for mining",
      "Zotac specifically made a statement saying that, if you open the stock fan shroud, *for any reason*, you've effectively voided the warranty. A bunch of people in the Zotac sub got mad, a rep came out and said they were going to basically think about it, and I haven't seen anything since.",
      "[redacted]",
      "Yea when you buy a GPU you shouldn’t have to pop it open and replace shit anyway. Also most GPUs come with a decent warranty (3 to sometimes even 4 years if you register the card early enough). So if you have problems or temps drastically increase down the road, just RMA while it’s under warranty",
      "I have been saying these in the past, just change the thermal pads regardless of which manufacturer for 3080/3090 ! Mine was a Zotac 3080 Amp Holo and I drop my VRAM temp by 18 degrees when I changed my thermal pads to Thermalright Odessey thermal pads..\n\nGDDR6X is unbearably hot, my brother's Gigabyte 3080 Vision OC doesn't even have thermal pad on the backplate, performing even worse than mine at stock",
      "Any one with a 3080FE? Hows your temps looking?",
      "Sure, but there's 0 actual enforcement of it. You'd have to sue them to prove your point. Companies take the safe bet that the vast majority of people won't bother.",
      "I replaced all the thermal pads on the front and back of my Gigabyte Aorus 3080 Xtreme, I had to use 4 different thicknesses to do it perfectly. All in all, it dropped the mem temps 28c while gaming and 40c+ while mining eth.\n\nI say 40c+ for mining because at 100MH/s it would instantly hit 110c, so I had to massively underclock to keep the temps safe. After changing the pads my temps were 70c, but as it throttled at 110c, there's no way to tell how high it would have actually gone.",
      "I think most gamers should do the same. I got my 3090 to game, but mining eth in between gaming sessions has paid for the card. I didn't buy it for mining but why not pay for the card.",
      "No issues after strapping an extra fan to it.\n\nhttps://www.amazon.com/photos/shared/oktmaUFpTf23xtN5dx3jwQ.sTQdi38EdRHTFSrkr30-ZI",
      "This is Celsius. Water boils at 100C, junction max temperature is usually between 100C and 115C. After that the silicon breaks down and the product can die.\n\nSensors don't often read the absolute hottest temperatures, and if they are external they could be reading Tcase, there is often a 10-20C increase going from Tcase to Tjunction. And like I said, when juction is that hot bad things can happen.",
      "To be fair to them, full production provides much more data than anything they could do in house.   \nOn the flip side, there could've been pressure from other manufacturers to alter the published specs to reduce concerns, so without access to data we can't really say for sure either way...",
      "A card they also game with as well, at that.",
      "yeah i only understand this mod when your gpu is going to lose warranty period soon, then yeah. Repaste your gpu, blow out the dust and possibly replace thermal pads, but for brand new gpu? nahh",
      "Micron actually adjusted GDDR6x spec several months after cards launched from 105c to 110c. So take that 110c number with a grain of salt.",
      "That's why you get it from MSI USA in California."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "high",
    "matched_keywords": [
      "rtx 3080",
      "3080"
    ],
    "title": "NVIDIA RTX 3070 Ti 16GB and RTX 3080 12GB are postponed - only the RTX 3090 Ti is still on schedule | igor'sLAB",
    "selftext": "",
    "comments": [
      "3090 Ti has got to be the dumbest shit ive ever heard of.",
      "Wait till they release a RTX 3090 Ti Super Max",
      "I’ll never get my hands on a graphics card",
      "Rtx 3090 TiTius P3pp3roniuz.\n\nEdit: thx for the silver :P",
      "Very easy to get… over msrp",
      "Why doesn't the RTX 2060 12GB have a MSRP attached? Have they all gone to bulk purchase miners & scalpers?",
      "It has no msrp so that retailers and AIBs can charge whatever they feel like. The first listings spotted had them at around 600-700 euros",
      "2% performance uplift go brrrr.",
      "It is very possible, likely even. You can't get that much more out of a GA102. We're talking about a small memory clock increase, NO memory bus increase (already maxed out), and a mere TWO SM's being enabled (3090 already has 82/84 possible SM's). \n\nThat's not going to result in much. 2% is probably just about right.\n\nFor reference, 3080 > 3090 is like 7-15%, mostly \\~10%, and the differences there are much more stark:\n\n* 19 vs 19.5GBPS memory speed \n* 320 v 384 bit bus\n* almost a 200GB/s memory bandwidth advantage to the 3090 because of the above two things alone (760 vs 936)\n* 68 vs 82 SM's (10496 v 8704 CUDA cores),\n* similar differences in RT/Tensor cores and the like. \n\nThe only way a '3090 Ti' level card makes any sense imho is if it is called a Titan, and gets a few more workstation features enabled in the driver to justify it's existence lol.",
      "That's literally super fucked if you ask me...",
      "Are 3080’s still impossible to get? I’ve been a bit out of the loop",
      "Rtx 3090 ti noctua edition with a 5 slot cooler",
      "My local stores charge gpu based on 3dmark scores. Every generation of cards is getting more expensive.",
      "I weep with you, brother.",
      "Delayed by Nvidia or Delayed by Scalpers.  \n\nSame shit anyway.",
      "[3090 Ti Super Max launch event ](https://youtu.be/ZBJCgrrQhx4)",
      "Ehi guys, what's about all this hate?\nScalpers will get the majority of this Gpu so chill, nothing will change for we poor normal users.\n\nPs fucking scalpers, I still can't upgrade from my Gtx 980 to  the 20xx or 30xx.\nPorco dio.",
      "Can't wait to not be able to buy these",
      "I'd buy that (if I could)",
      "The 3090 was already pushing this chip really close to its top, there isn't much more to go"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "high",
    "matched_keywords": [
      "rtx 3080",
      "3080",
      "3080 ti",
      "rtx 3080 ti",
      "3080ti"
    ],
    "title": "nVidia GeForce RTX 3080 Ti Performance Summary: 8 reviews & 940 benchmarks compiled",
    "selftext": "- compilation of 8 launch reviews with ~940 gaming benchmarks at the 4K/2160p resolution\n- only benchmarks under real games compiled, not included any 3DMark & Unigine benchmarks\n- geometric mean in all cases\n- stock performance on reference/FE boards, no overclocking\n- only launch reviews with **complete adoption of rBAR & SAM** were evaluated _(check PS2)_\n- standard performance without RayTracing and/or DLSS\n- missing results were interpolated (for a more accurate average) based on the available & former results\n- performance average is weighted in favor of reviews with more benchmarks\n- results were cutted in 2 tables, because as one table it becomes to wide (all results are comparable between the two tables)\n\n&nbsp;\n\n4K Perf.|Tests|6700XT|6800|6800XT|6900XT|2080Ti|3080Ti\n|:--|:--:|:--:|:--:|:--:|:--:|:--:|:--:|\nGen & Mem||RDNA2, 12GB|RDNA2, 16GB|RDNA2, 16GB|RDNA2, 16GB|Turing, 11GB|Ampere, 12GB\n[ComputerBase](https://www.computerbase.de/2021-06/nvidia-geforce-rtx-3080-ti-review-test/)|(17)|60.9%|76.2%|88.6%|96.3%|68.1%|_100%_\n[Golem](https://www.golem.de/news/geforce-rtx-3080-ti-im-test-nvidias-ti-tan-mit-halbem-speicher-2106-156854.html)|(8)|59.4%|77.8%|90.6%|99.7%|-|_100%_\n[Igor's Lab](https://www.igorslab.de/en/nvidia-geforce-rtx-3080-ti-fe-in-test-almost-an-rtx-3090-but-with-halved-memory-expansion-for-gamers/)|(9)|61.7%|75.8%|87.8%|95.2%|-|_100%_\n[Le Comptoir d.H.](https://www.comptoir-hardware.com/articles/cartes-graphiques/44118-test-nvidia-geforce-rtx-3080-ti.html)|(19)|59.2%|75.0%|86.9%|94.1%|68.1%|_100%_\n[PC Games Hardware](https://www.pcgameshardware.de/Geforce-RTX-3080-Ti-Grafikkarte-277501/Tests/Test-Benchmarks-Vergleich-mit-RTX-3090-1372951/)|(20)|-|-|-|93.2%|-|_100%_\n[PC World](https://www.pcworld.com/article/3620654/nvidia-geforce-rtx-3080-ti-review.html)|(11)|-|-|-|91.9%|-|_100%_\n[TechPowerUp](https://www.techpowerup.com/review/nvidia-geforce-rtx-3080-ti-founders-edition/)|(22)|61%|77%|89%|95%|68%|_100%_\n[WCCF Tech](https://wccftech.com/review/nvidia-geforce-rtx-3080-ti-12gb-founders-editions-pure-titanium/)|(8)|-|74.2%|88.3%|95.1%|64.7%|_100%_\n**average 4K performance**||**60.3%**|**75.6%**|**88.1%**|**94.8%**|**68.0%**|**_100%_**\nTDP (TBP/GCP)||230W|250W|300W|300W|260W|350W\n\n&nbsp;\n\n4K Perf.|Tests|3060|3060Ti|3070|3080|3080Ti|3090\n|:--|:--:|:--:|:--:|:--:|:--:|:--:|:--:|\nGen & Mem||Ampere, 12GB|Ampere, 8GB|Ampere, 8GB|Ampere, 10GB|Ampere, 12GB|Ampere, 24GB\n[ComputerBase](https://www.computerbase.de/2021-06/nvidia-geforce-rtx-3080-ti-review-test/)|(17)|44.0%|59.4%|68.8%|90.4%|_100%_|102.3%\n[Golem](https://www.golem.de/news/geforce-rtx-3080-ti-im-test-nvidias-ti-tan-mit-halbem-speicher-2106-156854.html)|(8)|51.7%|-|-|92.2%|_100%_|103.7%\n[Igor's Lab](https://www.igorslab.de/en/nvidia-geforce-rtx-3080-ti-fe-in-test-almost-an-rtx-3090-but-with-halved-memory-expansion-for-gamers/)|(9)|-|59.7%|68.1%|90.3%|_100%_|102.0%\n[Le Comptoir d.H.](https://www.comptoir-hardware.com/articles/cartes-graphiques/44118-test-nvidia-geforce-rtx-3080-ti.html)|(19)|-|59.5%|68.2%|90.0%|_100%_|104.0%\n[PC Games Hardware](https://www.pcgameshardware.de/Geforce-RTX-3080-Ti-Grafikkarte-277501/Tests/Test-Benchmarks-Vergleich-mit-RTX-3090-1372951/)|(20)|-|-|-|90.6%|_100%_|104.8%\n[PC World](https://www.pcworld.com/article/3620654/nvidia-geforce-rtx-3080-ti-review.html)|(11)|-|-|-|90.0%|_100%_|103.8%\n[TechPowerUp](https://www.techpowerup.com/review/nvidia-geforce-rtx-3080-ti-founders-edition/)|(22)|45%|61%|70%|90%|_100%_|101%\n[WCCF Tech](https://wccftech.com/review/nvidia-geforce-rtx-3080-ti-12gb-founders-editions-pure-titanium/)|(8)|-|-|-|89.9%|_100%_|102.6%\n**average 4K performance**||**45.1%**|**59.2%**|**68.2%**|**90.3%**|**_100%_**|**103.0%**\nTDP (GCP)||170W|200W|220W|320W|350W|350W\n\n&nbsp;\n\nAt a glance|GeForce RTX 3080|GeForce RTX 3080 Ti|GeForce RTX 3090\n|:--|:--:|:--:|:--:|\n4K performance|90.3%|_100%_|103.0%\nMemory|10 GB GDDR6X|12 GB GDDR6X|24 GB GDDR6X\n(real) power draw|325W|350W|359W\n(official) MSRP|$699|$1199|$1499\n\n&nbsp;\n\nSource: [3DCenter.org](https://www.3dcenter.org/artikel/launch-analyse-nvidia-geforce-rtx-3080-ti)\n\nPS: Comparison of 3080Ti Cards from Asus, EVGA, MSI, Palit & Zotac [here](https://old.reddit.com/r/nvidia/comments/nuvtdn/comparison_of_3080ti_cards_from_asus_evga_msi/).\n\nPS2 (June 10th): PCWorld's statements about the status of rBAR/SAM were unfortunately misunderstood on my part. After clarification, the status of rBAR/SAM at PCWorld must be changed to \"not active\", although the appropriate hardware was used for this. Unfortunately, there is nothing more to change on the results and evaluations, but the effect of this error on the overall figures should be rather marginal.",
    "comments": [
      "$500 for 10% increase in performance. That has to be the worst deal in history.",
      "Thanks for the tables, but wow, only ~~10%~~11% faster than the 3080 and 3% slower than the 3090, so many cards with so much different prices, but all of them with similar performances lol",
      "Nah, $800 for 13% increase is even worse (3090). But yea, still awful. Lol.",
      "shy wine secretive silky innate shame squash stupendous pocket deer\n\n *This post was mass deleted and anonymized with [Redact](https://redact.dev)*",
      "that 10% is dwindled when you factor in AIB cards too because its all the same fucking chip.",
      "TBH it seems like the value proposition of the 3080 Ti is a marketing issue. If instead the new card was called the 3090 lite, it would seem like a great deal, only 3% less performance but 20% cheaper? OR HELL just call it a 3090 12GB! That's what it pretty much is anyways...",
      ">$500 for 10% increase in performance. That has to be the worst deal in history.\n\nThat is for 4K also. For 1080P and 1440P, that drops to like 4-6%.",
      "I will never understand why people will use the OC argument. If you can OC one, you can OC the other... and theoretically the Ti should have more headroom given it's much higher core count, memory, and bus width.",
      "For anyone doing VR Gaming I can say with absolute certainty that the 3090 is *incredible.*\n\nMy wife and I are very active VR enthusiasts having logged a couple thousand hours with the Valve Index over the last year and a half and play nightly. Our VR rig had an i9-9900KF and 2080 Ti in it prior to snagging a 3090 FTW3 from EVGA on launch (at retail price mind you). Our frame times dropped significantly which was to be expected with just the rasterization increase from that card to the 3090, but where it *really* shined was being able to supersample existing VR titles. Some games that struggled at 100% resolution scaling before at max visuals in-game were now able to be supersampled at 160% with max visuals all from the significant increase in VRAM.\n\nI also use a 3090 K|NGP|N on my desktop gaming PC and the extra VRAM helps there as well with running multiple 4K monitors. So while I agree it definitely doesn't make sense for gaming if you're doing 1440p or even just regular 4K/60 gaming (I do 4K/120 with a PG27UQ monitor), there's definitely some aspects of gaming where the 3090 with the extra VRAM is an absolute game-changer as far as overall experience goes.",
      "Yeah like I’m not here to say the 3080ti is a good value, it’s clearly not.  But comparing OC of one card to stock performance of another makes no sense.",
      "And you can also overlock the 3080ti…",
      "In a world with options, of course the 3080 non-Ti is one of the best choices. \n\nBut considering that most are $1500+ and 3090s are $2000+, I'm happy to have lucked out on a 3080 Ti for \"only\" $1400. And get a 10% boost to feel good about myself thanks to our NVIDIA overlords.",
      "In Poland price delta is minimal... All 3 models for 10000-12000 PLN which translates to roughly $2725- $3275. This includes 23% of VAT, but mostly is due to scalping margin. Normally we used to have MSRP + VAT similar to most EU members...\n\nI will have to live with my 1080Ti until crypto market has a major crash...",
      "It's the same chip but not the same GPU. All 3080s have the same number of SMs and the same memory bandwidth. All 3080tis have the same increased values. AIBs only change the power budget, stock clock speeds and cooling.",
      "A 2080ti for $599, this guy had a 3070 years before everybody else lol",
      "Didn't the 1080ti have a 30% perf difference from the 1080 for only $200 more?\n\nMiss those days.",
      "I’ve always bought the “Titan” class of card every 5 years or so when I upgrade knowing full well I’ll get fucked by the ti card 6 months later… but I have to be honest I feel like I got a good deal this time around… 3090 at £1300 new.. saw a 3070 being sold in a shop used for £1200 yesterday… crazy times",
      "Well for people that should be using the 3090, there is a lot of research and work related activities that can use that 24 GB of VRAM. \n\nThe 3090 shouldn't be bought by gamers... if there were no stock issues...",
      "Thank you. The OC argument is brainless lol",
      "Honestly I’ve said from the start that the 3090 is effectively just a renamed Titan not the 80ti replacement that most tech tubers made it out to be.\n\nThey should have kept it as a Titan and saved 3090 for this card and truly done what the tech tubers though was going on, because it isn’t outrageous, they have just done an appalling job at making sure people understand the product stack."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "high",
    "matched_keywords": [
      "rtx 3080",
      "3080",
      "3080 ti",
      "rtx 3080 ti"
    ],
    "title": "RTX 3080 Ti Launchday Thread",
    "selftext": "**Subreddit Protocol**:\n\n* **Launch Day Megathread** will serve as the hub for discussion regarding various launchday madness. [You can also join our Discord server for discussion!](https://discord.gg/nvidia)\n* Topics that should be in Megathread include:\n   * Successful order\n   * Non successful order\n   * Brick & Mortar store experience\n   * Stock Check\n   * EVGA step up discussion\n   * Any questions regarding orders and availability\n   * Any discussion about how you're mad because you didn't get one\n   * **Literally everything about the launch**\n* **ALL other standalone launch day related posts will be removed.**\n* **Subreddit may go on restricted mode for a number of times during the next 24 hours. This may last a few minutes to a few hours depending on the influx of content.**\n\n# Reference Info:\n\n# [RTX 3080 Ti Review Megathread](https://new.reddit.com/r/nvidia/comments/nqnkbc/geforce_rtx_3080_ti_review_megathread/)\n\n# [US Best Buy Information](https://corporate.bestbuy.com/what-to-know-about-nvidias-geforce-rtx-3080-ti-founders-edition-graphics-card/)\n\n# Remember not to buy from scalpers (fuck em). If you are buying from website that allows 3rd party sellers (e.g. Newegg/Amazon), please make sure you are buying from said retailer. Anything else means you're buying from scalpers. Do not buy from scalpers. Treat the product as out of stock and wait if the official retailers are not selling them.\n\n# This thread will be sorted by NEW for latest information.",
    "comments": [
      "Not enough VRAM to replace the 3090, not enough power to justify the price over the 3080.\n\nThis card sucks.",
      "Well...scalpers got all but 4 or 5 cards at the Fredericksburg, VA location....as of 11pm last night...there we're only 7 or 8 folks in line....and they had an armed security guard maintaining a list in pencil & red pen in a marble comp book....so things started by looking quite promising....then the con started taking shape...\n\n...he allegedly \"controlled the list\" until of course he removed his \"Allied Security\" jacket and firearm....then handed a list to the manager that was in black ink and an orange cover (not the same book)....then all of a sudden cars with 4 or 5 folks...looking well rested and freshly showered showed up and were somehow at the front of the line......fuck Best Buy and Nvidia....its just more of the same with these launches....\n\nAt this point, it's clear how this shit goes",
      "well that was fun, cya guys for the 4080 paper launch",
      "Don’t buy zotac cards guys, they’re pre-scalping that shit",
      "Already on ebay for $2800. Fuck humanity.",
      "Nvidia said “ thanks for the money dummies”",
      "I got a 3080 but I am still watching this entire 3080 Ti fiasco.... it's crazy to think that GPUs buy out instantly for 1200 USD MSRP, even more so that retail pricing at over 2k still sells instantly. I don't think I remember a time when ppl bought a video card for that much money this \"loosely\".\n\nAlso, I know it's mainly because of mining, but isn't the 3080 Ti already a LHR variant? So miners shouldn't buy these like crazy?",
      "My battle is over boys! After countless pre orders and waiting lists for the 3080's with 0 luck I said screw the online and camped out in front of a best buy in costa mesa ca for 22 hours and secured a card! They had 64 FE and I was spot 51 in line. I'm exhausted and had to go straight to work after I made the purchase but it was well worth it.....hopefully.",
      "\"add to cart\" button just vanished when i managed to reload the evga page.  \n\n\nwelp, guess im stuck with the freaking 970 after my 1080 broke... hate every a\\*\\*hole who is responsible for these overpricing sh\\*ts",
      "I love Nvidia's products, but this is a money-grab launch that I absolutely cannot support.  3080s are already impossible to come by, and now they're turning 102 dies that would be used for a 700 MSRP card that's retailing for 1500+ into a 1200 MRSP card that's going to retail for 2000+ guaranteed.\n\nWhy buy this?  It's already absurdly expensive, why drop 12 GB of VRAM and not future proof your card to a much greater extent for an extra 200 bucks?  This is one of the dumber releases that they've had in a long time.  12 GB is enough FOR NOW, and considering that at 4K we're only going to see memory consumption increase, I'd argue this card is hugely RAM starved given the premium you're paying for what should be a top of the line product that should have enough RAM to ensure that it's not an issue for the next 5-6 years.\n\nWhy are all these cards so RAM starved in this generation?  The 1080Ti had 11GB of VRAM literally 6 years ago, and now the 3080Ti has only 1GB more and we're supposed to be cool with that at almost double the MSRP?  Beyond asinine, I literally can't believe people are buying these.\n\nI'll just keep waiting for my MSRP 3070, I suppose.\n\nEdit: Pascal released in 2016, not 2015.  My b.",
      "I’m tapping out. I’m not going to continue to participate in this video card fuckery anymore. I’ve been trying since October to get a 3080 series card and I’m just over it.",
      "This thread is sponsored by the department of redundancy department as it’s the exact same situation as every other launch the past year to the surprise of *checks notes* Nobody!",
      "Waited since 12:45am and lost by 2 people. Someone ahead of me managed to buy 4 and is scalping each for $3000 in parking lot. Fml.",
      "Nvidia sold all 4 of their units 20 minutes before it was released",
      "Saddens me people are buying this.\n\nSay no to Nvidia's bullshit price gauging",
      "#I no longer allow Reddit to profit from my content - Mass exodus 2023 -- mass edited with https://redact.dev/",
      "2500 euro's in the Netherlands for a 3080 ti. What a joke honestly.",
      "vast uppity impossible point somber abundant deserve wine spark escape\n\n *This post was mass deleted and anonymized with [Redact](https://redact.dev)*",
      "Any other year, this card would be dead. But nvidia knows they can charge whatever they want for it, so they went for it. Whether it's $999 or $1199, they'd still sell the same number of cards (i.e. all of them), so why not charge 20% more per unit?",
      "Bought a 3090 for $2000 and had to basically stab my way through the bots on New Egg, knew I would never be able to get a 3080.\n\nSold my 1080TI for $900 which is slightly less than I paid for it 3 years ago. I think it was $950\n\nTotal cost for 3090 $1100.\n\nThe state of gaming at the moment is fucking tragic. Like I literally paid Nvidia double to be able to get Ray tracing and DLSS and passed that additional cost onto some other poor slob who paid full price for a used 3 year old card...\n\nNow they launch this bullshit? Like the gamers nexus review basically mirrored my feelings exactly."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "high",
    "matched_keywords": [
      "rtx 3080",
      "3080",
      "3080 ti",
      "rtx 3080 ti"
    ],
    "title": "Nvidia's GeForce RTX 3080 Ti 20GB GPU Is Real After All",
    "selftext": "",
    "comments": [
      "The hell?  3090 Super and now a 3080 Ti 20 GB?  What is this going to be called?  3080 Ti Super Arcade Edition?",
      "next up rtx 3090 ti 46gb",
      "RTX 3090 Ti Mega 69GB Nice Edition",
      "Super Arcade Championship Edition 2022 😉",
      "I'll stick to the 12GB version with much higher bandwidth thanks.  Why would you buy this and not a 3090?",
      "3080ti Ya Never Gonna Get One Anyway",
      "Nice I hope to see random Redditors finding some in the wild and building rigs with them.",
      "yet another vaporware Release or Overpriced scalperware.",
      "3080 Ti Super Out of Stock Edition",
      "3060 - 12GB\n\n3060ti - **8GB**\n\n3070 - **8GB**\n\n3080 - **10GB**\n\n3080ti - 20GB\n\n3090 - 24GB\n\n&nbsp;\n\nPretty stingy with vram on the 3060ti, 3070 & 3080",
      "Next year: I totally need that 4090ti Cyberpunk 2 Edition",
      "it'll be the \"THROTTLE SUPPLY TO RAISE PRICES\" edition. by fracturing what little silicon they have into a billion skus they can avoid reality till the crash makes them face it. Might as well change their name to Atari. what's that off in the distance, can they hear the radio songs from 1979, just before the video game market crash? :P",
      "When we said we needed more graphics cards, we meant quantity, not editions",
      "Yes  I recently bought a 3080 Ti and I won't be upgrading for a LOOONG time",
      "Why was this even made? Just one could feed 2.5 RTX 3070 Ti GDDR6X. miners will just use 3090 anyway, and what gamer with the right mind will buy this? Its already proven that more VRAM draws more power, leaving less for the core clock boost, this will run worse fps than the normal 3080 ti 12GB, guaranteed.\n\nP.S: Edited for a typo",
      "This is a very odd entry as the 3080 Ti is really a card meant for 1440P and greater, High res benefits greatly from high bandwidth, Lowering bandwidth and bus width just to say \"look our card has an extra 8GB\" is a very odd decision, By the time that over 12GB is required this card will be EOL by a fair few generations.\n\nThis reminds me of those 6GB 780's a few years ago, Completely pointless, By the time anything required over 3GB the card generally didn't have enough proverbial fuel in the tank, This will be no different.",
      "So it's gonna be an \"lhr 3090\". \n\nIf it costs 100 dollar more than the 12 gig 3080ti I may step up.",
      "Why not just step up to the actual halo product?",
      "Nice",
      "And my net income per month should have been $5000"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "high",
    "matched_keywords": [
      "3080"
    ],
    "title": "[Digital Foundry] Nvidia GeForce RTX 5070 Ti vs RTX 4080/3080 Review - Real-World Pricing Is Crucial On This One",
    "selftext": "",
    "comments": [
      "Lol \"perf is fine\" ??? First ever 70 Card that dont even beat 80 Card from previous generation and is only 12-15% faster than predecessor is Fine???? Not to mension insane 900usd price.\n\nThis is by far worst generation ever released and DF still trying spin it for nvidia favor.",
      "It's not fine",
      "For the right price, why the hell not? That's all it comes down to",
      "I think they just mean it's \"fine\" in that it's not bad, out of context. It renders stuff well, without any inherent shortcomings to speak of (e.g. crippled VRAM, memory bandwidth, etc). It's only once you add in the product name (which has value implications), MSRP, and especially real-world price that things become less fine.",
      "I actually like their content , all other creators are bitching about the price (rightfully so), and it gets tiring. DF always focuses on the technical side, and i like that.",
      "\"Perf is fine\" so we're calling 10% fine now?",
      "Even in *current* context it is going to be the best bang for buck for anybody looking to buy a GPU. It's specifically the *historical* context where all these cards are so absurdly priced/placed.",
      "The performance by itself is fine. It's not a bad card in any way just looking at the numbers by itself in a bubble. It's the pricing that's bad.",
      "No ragebait title or thumbnail? No outdated, repetitive, cringe inducing \"jokes\"? No 'fake frames' and other recycled bits to appease the YouTube peanut gallery? An actual reasonable and professional tone that understands that this video will be watched by people even in future where current drama may not apply? Literally unwatchable. 😠",
      "DF had a podcast on 5080 and they weren't kind to it. Alex even agreed with Hardware unboxed on 5080 being 5070",
      "That's why price matters. Value is all that matters to the customer, performance is important but it's all relative. At this price, the card looks like a decent upgrade for someone maybe two of three generations behind",
      "We are in CPU gen to gen performance uplift and they say its fine okay",
      "I ran some calculations (using TPU numbers with RTX30 as a baseline).\n\n\"How many generational uplifts like this would it take to get 2x the performance?\"\n\nThe 5070Ti does not fare particularly well with that.\n\n**(EDITED to add more cards & gens)**\n\nhttps://preview.redd.it/oi9xjqho8bke1.png?width=1067&format=png&auto=webp&s=cebb40c503aa1bd7f3a18bc6d83c9ad5583a569d",
      "at 750 it would be nearly 30% better value in one generation. Better than the 4000 series. Not sure why people keep lying when we all can check the numbers",
      "4070ti super",
      "$750 fine? Yeah since it's close to the $1000 4080S.\n\n$1000 fine? No because it's the same as getting a $1000 4080S or a used one for $800 or less depending on desperation to sell it.",
      "5080 is literally the most efficient card on the market right now and this 5070ti comes in second, the only card that has shown to be worse than the previous gen is the 5090 so not sure what you are talking about.   \nThey could have shown that in the 5090 video where it might actually matter (if you are buying a 5090 are you really worried about frames per jule?) but in these videos? What's the point?",
      "I agree mostly, except this is *almost* a 4080 for 3/4 the price if it stays at MSRP. That's nothing to sniff at even if the value could be a lot better",
      "So what you're saying is you have an issue that Rich acts like an adult?\n\nHe said recently in one of DF Directs that he never gets upset with computer hardware because his life doesn't depend on it. You don't like the graphics card? Simply don't buy it?\n\nThis is the exact reason why I love DF. I don't want constant bitching and moaning.",
      "Think I’ll be good with my 4070 TI Super for a while it seems."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "high",
    "matched_keywords": [
      "rtx 3080",
      "3080",
      "3080 ti",
      "rtx 3080 ti"
    ],
    "title": "Nvidia's RTX 4090 mobile GPU looks seriously quick, 55% faster than RTX 3080 Ti mobile | It's so fast it can match Nvidia's RTX 3090 desktop GPU",
    "selftext": "",
    "comments": [
      "Battery life 13 minutes",
      "In Laptops starting from 4000 dollars.",
      "4090 has crazy performance between 40  to 70% of the card's stock power limit, this architecture is very efficient.",
      "If the duo offers one might be upgrading. Of course assuming this isn't just a one off cherry picked benchmark....",
      "The desktop 4090 runs right cool as well because it takes a significant undervolt without taking a huge performance hit too right? I think I remember someone saying their fans barely run. I won't get fooled into a laptop again but that makes me hopeful for the people that get one.",
      "Weighing in at 20lbs with a hook up for your garden hose for cooling",
      "It probably isn't fake advertising. This gpu isn't going to be in laptops below 3 grand either anyways.",
      "No one is gaming on battery here",
      "Price/Value discussions aside, this is legitimately impressive and cool.",
      "The whole reason nvidia can price their hardware the way they do is because they make insanely good hardware. Completion really is dead",
      "People seem to misunderstand something. 4090 laptop is a sampled AD103. Does not clock as well as 4080 but scales better with power.\n\nSo expect thin and light designs achieving >=rtx 3080 depending on if maxQ or maxP closer to 3090",
      "With the perf/W improvement 4nm and Lovelace has brought, this performance ballpark should be expected, yes.",
      "You're not getting that performance on battery, and it's not what those are for.\n\nYou can game on battery but it will limit the power draw to make it lasts 1.5-2h usually. But again that's not what it's built for.",
      "The whole reason nvidia can price things like they do is because crypto miners came in and turned gpus into a money making tool.\n\n\nAmd isn't any better, copying nvidia and naming their cards a new tier up while increasing prices. 6800xt $650 -> 7900xt $900.",
      "it's for ultra high end gaming & workstation laptops. so battery isn't much an issue",
      "I'm sure your wife will love it",
      "So when can we start seeing some cards based on this architecture that are no longer than 30cm?\n\nDon't feel like making adjustments to my case :)",
      "being good at geekbench doesn't mean this card will be good at everything else. i want more tests. geekbench is a shitty proxy for real in game results.",
      "I undervolted to 975mv@2700mHz (probably can push higher) the performance impact is ridiculously low.  \n\n\nThis is the most efficiently cooled and silent GPU I have ever owned (gainward phantom non-GS).\n\n* max 64°c in Cyberpunk 1440p RT ultra and DLSS quality.\n* max 54°C peak in modern warfare 2...the 0-rpm mode is at <50°C lol.\n\nI'm really happy. I'm using an AP201 micro-atx case with case fans at like 30% it's not like I have a case with 12 140mm fans",
      "And will still thermal throttle"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "high",
    "matched_keywords": [
      "rtx 3080",
      "3080",
      "3080 ti",
      "rtx 3080 ti"
    ],
    "title": "Intel Phantom NUC / RTX 3080 Ti eGPU",
    "selftext": "",
    "comments": [
      "150% of the cost\n\n70% of the performance",
      "That's supposed to take less room?",
      "Double the space, quadruple the heat!",
      "A lot of SFF cases are smaller than that egpu enclosure while containing a whole pc in it, with better upgradability and performance, if the aim is to take less room this is clearly not the way to go.",
      "with a build like that, why not just get a normal PC? costs less, works better and easily upgradable.",
      "If you need to limit youself to one laptop that you also need to use for school/uni/work your options are:\n\n* A chonky powerful gaming laptop with shitty battery life\n* A 'slim' gaming laptop with meh performance, meh battery life and runs super hot\n* A business laptop with TB3/TB4, no dGPU but excellent battery life + an eGPU for gaming at home with an external monitor\n\nAlso on that last point good luck finding a gaming laptop with a 3 year warranty.",
      "There are plenty of use cases for people who use egpus especially people who travel/commute to work. I own an egpu with a beefy card as well. The biggest drawback is the performance loss from the thunderbolt slot vs pcie, but other than that there are plenty of advantages",
      "Lol, that GPU case is almost as big as my entire PC... with a 3080 Tie in it.\n\nThe NUC is awesome, but it's kinda weird to use in combination with an eGPU, unless you travel a lot.",
      "Yes you lose about 20-30% depending on the game/task",
      "Aren’t some bottleneck because of the thunderbolt connection ?",
      "Yea people need to know more about SFF builds. \n\nEspecially the ones who are away from home for more than a day and want something to game on and use for work.... an SFF build for gaming/entertainment and a super cheap laptop specifically for work would do far better than a NUC and eGPU, for a lower price",
      "More like 50%+ for a 3080 Ti",
      "Made this just for you OP: [https://i.imgflip.com/68llhj.jpg](https://i.imgflip.com/68llhj.jpg)\n\nJk I'm just jelly",
      "I mean, you could put the entire PC in that GPU case.",
      "Sadly, this is the truth. You do lose a decent amount of performance from the type c thunderbolt connection. I was considering a similar build 2 years ago when I had my own NUC (which I had bought as an entry point to get back into PC gaming since my last build back in 2002), but after some in depth research I realized that I'd be paying so much more to get the eGPU case + the GPU itself, only to lose a tonne of performance. \n\nI ended up selling my NUC for $1k and decided to build a PC from scratch. I'm very happy with my SFF PC now, as I make no compromises with it.",
      "Lol!",
      "That whole case on the right is solely for the 3080ti? There's another comment stating it has its advantages, please enlighten me.",
      "There are plenty of cases, yeah right.",
      "If OP bought a NUC and an eGPU specifically from the outset, then I agree that is an unorthodox way to go about things and I'm not sure what problem it solves. \n\nHowever, if they already had the NUC, and since then have decided they wanted more graphical go-juice, then the eGPU was a perfectly logical choice IMHO.\n\nThe true advantage of an eGPU is you can bolt more power on to an existing system which otherwise could not be upgraded without replacing it entirely (or it can be upgraded, but not so cheaply). I would've done the same.\n\nThat said, eGPUs are often misconstrued as a solution for space-saving (as most of the commenters in here would attest, it seems). And sure, I believe you could get a smaller eGPU enclosure than this if you really cared about space, but this one was probably cheaper.",
      "isn't the 3080ti severely gimped by the PCI slot and thunderbolt?"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "high",
    "matched_keywords": [
      "rtx 3080",
      "3080",
      "3080 ti",
      "rtx 3080 ti"
    ],
    "title": "Many a swap later, ended up with a RTX 3080 Ti FE!",
    "selftext": "",
    "comments": [
      "Just wondering, why's it in the lower slot?",
      "Go to page 29 of your motherboard manual and you will see that only the top slot is wired to x16.\n\nThe middle slot is x8 and the bottom is x4.",
      "Ah, right you are and I RTFM incorrectly. I'll move it up to the first. Thanks for the help!",
      "Always gotta be careful of what slot you stick it in...",
      "I'd suggest you double check, best case scenario it's running at x8 with the CPU lanes, worse case scenario it's running in x4 chipset lanes.",
      "Cable spaghetti to reach the dongles, amount of cable traffic from one of the grommets and this is a X570 board, it has a few x16 slots.\n\nAdmittedly, ths [X570 Taichi's middle x16 slot is way below the middle](https://www.asrock.com/mb/amd/x570%20taichi/)",
      "Those sre wise words...",
      "( ͡° ͜ʖ ͡°)",
      "What was the first swap?",
      "Back when mythical MSRPs were a thing, 6900 XT Nitro+ @ 1199.99 for a RX 6800 Ref + difference.",
      "You might be holding that 3080ti back having it plugged into the lower slot in your motherboard.   Some. Motherboards have X4 in some slots.   X8 won't be bad as that would be x16 gen 3 and that's perfectly fine",
      "I always enjoy seeing air coolers.",
      "Rip GPU speed lol",
      "[Doublechecked!](https://i.imgur.com/sdAyHgi.png)\n\nManual states Three x16 slots, one GPU runs at x16, two would be x8/x8.",
      "Scythe Fuma II is def a looker!",
      "[Slot changed! Also changed the MoBo LEDs to 255-255-255](https://i.imgur.com/QIugUrs.jpg)",
      "In fact, most people cannot get 3080TI",
      "First slot tho??",
      "And now trade it for a tesla",
      "TIL. Thanks for the pointers, have usually used the first slot every build but to help build appearance due to the FE dongle, thought lower slot would be more clean."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "high",
    "matched_keywords": [
      "3080",
      "3080 ti"
    ],
    "title": "Gigabyte Came Through BIG TIME – 3080 Ti RMA Turns into a 4080 Super!",
    "selftext": "I just wanted to give a huge shoutout to Gigabyte for their amazing warranty service and customer support. My 3080 Ti Vision died recently, and I was honestly dreading the RMA process. You always hear horror stories about long wait times, getting the runaround, or receiving a questionable refurb as a replacement.\n\nBut Gigabyte absolutely delivered. Not only was the RMA process smooth and relatively quick, but instead of just replacing my 3080 Ti, they upgraded me to a 4080 Super Aero! I was blown away—talk about standing behind your products and taking care of customers.\n\nIt’s rare to see companies go above and beyond like this, so I just wanted to give them the credit they deserve. If anyone is on the fence about Gigabyte, their warranty support is top-tier, and I can personally vouch for it.\n\nThanks again, Gigabyte! You’ve earned a loyal customer.",
    "comments": [
      "That's fucking sick! Grats on the upgrade. Probably the best money you've ever spent on a GPU.",
      "I did buy my 3080Ti for $1700 at Best Buy during covid, so this upgrade makes that price more worth it now!",
      "Now that’s how you do a turnaround in support, asus should take notes.",
      "Covid prices were nuts! I had to get a GPU for work, but I would have never paid $1700 for a 3080Ti for just video games.",
      "https://preview.redd.it/6k1v8sgbuwie1.jpeg?width=1290&format=pjpg&auto=webp&s=695315ec511eaeb78cff8316969ab6126ed51974\n\n🔥",
      "https://preview.redd.it/20vvuynqswie1.jpeg?width=828&format=pjpg&auto=webp&s=96f0835f87dec2f12510a215f8ac798824414f12",
      "I had a 3080 Ti Vision that I RMA'd 3x. Each time, it died due to the same reason. The final RMA, they upgraded me to a 3090 Eagle which absolutely killed my aesthetic in my build (since it's all white). I sold the 3090 Eagle for a good chunk of change and I bought an 4080 Aero at release.\n\nIronically enough, the 3090 Eagle died on the new owner about two months in. Fortunately, I was able to help them get that RMA'd.\n\nEDIT: I just thought that I should add that I echo your statement/sentiment regarding their warranty process and policy. They never gave me a hard time through all of the issues and held up their end of the bargain.",
      "Gigabyte is legit with their warranty. I had a Windforce v1 4090 fail and they sent me a brand new Windforce v2 4090.",
      "Solid warranty but damn that is a scary high failure rate.",
      "Meanwhile at gigabyte hq;\nWHO DID THIS GUYS RMA YOURE FIRED",
      "How many shares of Gigabyte stock did you buy before posting this?",
      "Perhaps you are new here but, COVID pricing was combined with Crypto pricing... a 3080 Ti was insanely marked up. I think it capped around $2000",
      "![gif](giphy|3o7TKMxBuO913uWyoU)",
      "I paid 800 CAD for a 6600.. still hurts",
      "so they replaced a broken windforce 4090 with a working windforce 4090, thats kinda the bare minimum for warranty.",
      "What? OP was just giving more context why they paid that much",
      "We’re not all Reddit experts, I just clicked reply on the wrong comment and didn’t feel like rewriting or copy pasting. I assume most people would figure out the context when reading it all. It is pretty funny people think I might be a Gigabyte employee. \n\nWe should call out companies when they do things right and not just when they do things wrong, just like the same applies to people. So much negativity today! Stay positive people!",
      "Yeah, I was nervous after RMA #1 that they were going to pull some crap and screw me over but thankfully they didn't. They kept sending me these BS refurb units that would literally die after like 2-3 months. It was wild.\n\nHistorically, I had always gone with ASUS boards and GPU's but now they've got a customer in me for life.",
      "Least obv gigabyte propaganda",
      "Gigabyte, for all negative posts they get online does have one of the longest GPU warranties at 4 years.  I have had a Gigabyte GPU for my last 3 now, although... it's not really on purpose.  I buy my 90 series cards as soon after release as I can, and they have been what's in stock the last few times.  But I can say I haven't been disappointed, other than my vram temperatures on my 3090, which was based on a poor design rather than anything Gigabyte themselves did."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "high",
    "matched_keywords": [
      "rtx 3080",
      "3080",
      "3080 ti",
      "rtx 3080 ti"
    ],
    "title": "RTX 3080 Ti to a RTX 5080 ?",
    "selftext": "GPUs prices will go sky high, grabbed a Gigabyte 5080 at Microcenter for $1200 can sell my 3080 Ti for $350.\n\nIs this an upgrade that’s worthwhile ?",
    "comments": [
      "You already got the card, you need validation too? lol",
      "No way is 5080 50% improvement in anything over 3080ti… 10 to 15% max. And no, OP, I don’t think it’s worth doing",
      "FG and DLSS 4 are separate though. You're right that multiframe gen is locked to 50 series, but DLSS 4 is compatible with all RTX cards (yes, including 20 and 30 series). Nvidia made the announcement themselves.",
      "without spending $2500/3k+ yes",
      "3080 ti supports dlss4",
      "The only restricted part of DLSS is the frame gen tech. The upscaling is compatible across 3000 series and onwards. I just replaced my 3060 ti but was using DLSS4 upscaling.",
      "I’m afraid you don’t really understand DLSS. Don’t worry, it isn’t your fault. It is NVIDIA who combined wildly different technologies under the same name. The 20, 30, 40 and 50 series absolutely support DLSS 4, including the new Super Resolution and Ray Reconstruction versions. They have big changes from DLSS 3 to 4. It all runs on the older RTX cards although the performance cost is high on the oldest cards.\n\nWhat they don’t all support is the Frame Generation part of it.",
      "Yeah, I sold my 3080 10gb for $400 just last week. Definitely could go higher than that for a 3080 ti",
      "4090 wins against the 5080\n\nit’s the 3’rd best GPU",
      "4090 is better.",
      "This review doesn’t list the 5080 and the 3080 Ti in the same table or graph, but if you look at page two, you’ll see that the 3080 Ti performs between the 4070 and 4070 Super, depending on resolution. (Closer to the 4070 at 1080p and closer to the 4070S at 4K.) \n\nOn page one and using ultra settings, you’ll see that the 5080 is about 70% faster than the 4070S at 4K ((71.1-45.9)/45.9=70%) and about 45% faster than the 4070 at 1080p ((133.9-92.1)/92.1)=45%. I used 50% as sort of an average in my initial comment. \n\nIf you’re going to tell someone they’re wrong, you should have a reference to backup your opinion, wherever possible.",
      "The 30 series supports the transformer model based DLSS scaler and ray reconstruction, it does not support Frame Generation",
      "I am literally using DLSS4 on my 3080fe. It just does not support fg or mfg. But it supports dlss4 transformer models",
      "Multi-frame generation is unique to 50-series. \n\nhttps://www.nvidia.com/en-us/geforce/technologies/dlss/",
      "Yes huge improvement from my 3080ti to 5080 for 4K gaming.",
      "If you play at 4k with max settings, RT and you need hella lot of frames with frame gen - yes. Otherwise, it is not worth the money spent. It is only ~33% faster on average. \nI have 1440p and 3080 Ti and will sit still until 6000 series comes up.",
      "Daniel Owen has a 5080 vs 3080-12gb.  So same memory setup as the ti but slower so will not tell you the same picture but might be helpful.  https://m.youtube.com/watch?v=ptNAHkI82y0\n\nHis ultimate comparison videos are usually pretty detailed, different resolutions and with dlss and without etc. \n\nYou can also search YouTube for 3080ti vs 5080 and may find videos that show a side by side.  The problem is in the past some of them have comments saying the they are not real so just be careful with those and hence why I like Daniel’s videos.\n\n\nThanks",
      "Yes. I did the same mostly for playing flightsim, modding som games, and tinkering in VR. It’s doubled my fps.",
      "Sell me your 3080ti bro?!",
      "Just did the same upgrade and I'm happy with it"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "high",
    "matched_keywords": [
      "rtx 3080",
      "3080",
      "3080 ti",
      "rtx 3080 ti",
      "rtx 3080ti",
      "3080ti"
    ],
    "title": "RTX 3080 Ti vs RTX 4070",
    "selftext": "1. Hello, after months of hunting, I've finally purchased an RTX 3080 Ti (Second hand). It hasn't arrived yet and I believe I am able to return. I saw a deal for an RTX 4070 (Brand New) that makes it similar cost to the 3080 Ti I bought.\n\nIs it worth me just sticking with the rtx 3080ti or return and buy the 4070 ?\n\n\\[Update: I've spent all day reading responses (Much appreciated) and decided to buy the 4070 since it's brand-new, and for me power consumption + warranty seem to give me a better edge atm\n\n3 month update - I do not regret buying the 4070, although I haven't been as active with using it it's made my pc a LOT quieter and I'm not facing any issues so far! ]",
    "comments": [
      "The 4070 is maybe 5 or so percent below the raw performance of a 3080ti, but where it exceeds it, is in Ray Tracing, lower power draw (help keep room temps lower & elec. Bill), & DLSS3 (frame generation).",
      "Yeah from what I read it's a big saver for elec bills in contrast. DLSS3 is fairly new so not supported by many games yet but I guess with time it'll become more apparent how well it performs. \n\nThanks for the feedback!",
      "3080 Ti is slightly better, only cons are bigger consumption and lack of 40 series features. Overall it's a good card, don't return it.",
      "Mostly where you'll need frame generation is newer stuff, not older stuff. That's really where it counts. And when it comes to newer stuff, I bet you 80% of triple-A titles will support it if they are demanding titles. There is already plans to mod it into Starfield if Bethesda doesn't add it. It'll just make the card are much better, because in 4 years the 3080ti might be struggling, but the 4070 will still be fine. Go look at the massive improvements Digital Foundry just showed in the Unreal 5.2 video.\n\nFSR3 should still work on your 3080ti, though. Just no guarantee it'll look any good.",
      "For $600 I don't know if the rtx 3080 ti is a good deal, I recently bought my rtx 3080 ti tuf oc for $400 that was used for mining for 8 months and then it was stored for a few months. It still has 1.5 years of warranty tho.\n\nIt runs nice and quiet at 900mV 1920Mhz, the hotspot is just 6°C over the GPU temp which is pretty great. \n\nOn average the 3080 Ti is 6-10% faster than the 4070 at 1440P (it depends on the game, on cyberpunk 2077 it's around ~18% faster on 1440P High), the 4070 consumes less power tho.\n\nAt 4K on average the 3080 ti is ~15% faster than the 4070.\n\nSo it depends, If the 3080 Ti is in good condition, with good temps and still in warranty it might be better for you to keep it. The 4070 isn't a bad card, it's priced badly that's all.",
      "Bruh \n\nEuropeans exist \n\nI pay between 35-40 cent per kw \n\nPower draw is literally why I chose my card over last gen amd",
      "If you had warranty on the 3080ti, I would tell you to keep it, but having 2 years of security on the 4070 really swings in into favour. DLSS3 is nice to have, but I would rarely use the frame generation tech on it, so power consumption is really the main benefit.  \nThe difference between the cards is tiny, but the 4070 might be the more sensible choice.",
      "That logic is why i recently went with a 4070.  That frame gen will help a lot.  I'll just have to finally upgrade my display to get VRR (which I've been wanting anyway) so I can use frame gen.",
      "You forgot \"better VRAM cooling\" which is also important, I think a lot of 30 series will eventually die because of this. maybe it is better now?",
      "I can't blame you.  I turned frame gen on my 4080 fe for Spiderman Miles Morales, and yeah, I could tell the lag/latency, especially since I play high fps on COD.",
      "- splitting hairs\n\n- 3080 was huge uplift. 4070 is only 200W. Both can easily handle 4K most games. Blindfolded you cant tell.\n\n- performance plateau s every few generations. Both will last you 4+ years, and you can always just sell and upgrade.",
      "even the 30 series will support DLSS 3 - the improved upscaling updates.  \nframe gen is \\*one\\* DLSS 3 feature which is exclusive to the 40 series.  \n\n\nthe 3080ti also has almost DOUBLE the memory bandwidth, which will immensely help some workloads.  \n\n\nif you undervolt it, you can get close to the 40 series's efficiency (I saved 70w on my 3080 even with a slight overclock).  \nthe 40 series doesn't support much undervolting, sadly.",
      "crazy that you have a crystal ball and can see the future, what's next week's lottery numbers?",
      "Ehhh, 4070 is powerful enough to have high framerates already, which makes the generated frames it does not add *that* much latency. I'd personally not return the 3080 TI though, takes too much effort lmao and 3080 TI is already such a good product already too.",
      "I CaN SeE thE faKe FrAmeS\n\nIs the new\n\nI hear the audio connector does not have golden plating\n\nYou probably also believe that you can brake your car in 10ms after sometime jumps onto the road",
      "I agree, I'm from the UK & our electricity bills are already hiked up stupidly. But my usage isn't as heavy these days so that's a trade off",
      "That's what I was thinking, also comes new so looks cleaner haha",
      "4070 has 504 GB/s memory bandwidth vs 912 GB/s. The scaling with resolution is apparent:  \n[https://www.techpowerup.com/review/nvidia-geforce-rtx-4070-founders-edition/32.html](https://www.techpowerup.com/review/nvidia-geforce-rtx-4070-founders-edition/32.html)\n\n3080 Ti vs 4070 relative performance:\n\n1080p - 106%\n\n2k - 111%\n\n4k - 119%",
      "Purchased now! Can't wait to use it :)",
      "Can confirm, undervolting with a slight overclock made my 3080ti half as loud, cut power consumption by 30% when playing intensive games, and performs better than it was at stock. Feels a lot more stable now too.\n\nTook about a day's worth of tinkering with settings in Afterburner, but was well worth it."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "high",
    "matched_keywords": [
      "rtx 3080",
      "3080",
      "3080 ti",
      "rtx 3080 ti"
    ],
    "title": "I'm sitting at best buy to get a RTX 3080 TI, AMA",
    "selftext": "I'm sitting here for 12 hours at best buy, I'm wondering what you guys are thinking.\n\nUpdate: it's 2:39 am and I'm tired, but going to keep pushing untill 7:30 am. Once it's 7:30 I'll post if I get a ticket.\n\nEDIT: it's 7:30 am and I was the first one not to get the card. I was behind the last person that received a ticket. :(\n\n\n46 cards where ticketed,\nI was 47th in line ;(\n\n\nThank you all for the support and the motivation through the way! I unfortunately did not get a card today, but I will not stop until I do. I am thinking of camping out of micro center tonight, I can't stop once started.",
    "comments": [
      "I am also in a line at best buy since about 3pm. Nvidia is scalping my time.",
      "Holy fuck OP RIP. Sorry to hear that update. That sucks...",
      ">EDIT: it's 7:30 am and I was the first one not to get the card. I was >behind the last person that received a ticket. :(\n>\n>46 cards where ticketed, I was 47th in line ;(\n\nF",
      "Well, to be honest, it will still be cheaper than a scalped 3080.",
      "take some pictures of the people lining up so we can food stamp meme nvidia",
      "It's only an extra 10 fps if you already have a 3080. Maybe this guy has a 960ti and now he's getting an extra 100fps.",
      "It's kind of insane to think that out of 956 stores in the United States, only 81 has limited stock.  It's a shame that this generation has ultimately been sold out to miners to yield a profit.",
      "I'm thinking I'm glad I scored an FE 3090 online from Best Buy three months ago for $1349. \n\nThat's what I'm thinking. No lines for me - ever. I don't care if it's the latest iPhone, newest GPU, or Tesla Cybertruck.  Screw it, life's too short.",
      "LMAOOOOO",
      "Actually it is you that chose to wait in line.  Is it really worth the extra 10FPS at 12K VR?",
      "Well, it's both. I have been looking for a 3080 since lanch.",
      "You try that. If it works, you’ll have convinced me.",
      "Yeah, it's painful trying to get one of these cards. During this long adventure with best buy, it's been hard doing everything to attempt to buy one. \n\nI spend 3 or so hours a day now looking and searching for the 3080. I have probably spent over 100 hours looking for these cards since launch. \n\nNow spending over 12 hours sitting outside in the cold to try and get one with the tiny amount of hope remaining. \n\nI just want to get a card to play games. I want gamers to have these cards, and I would wait for other gamers to get theirs. I don't want these cards ending up in the hands of people trying to make a quick $1. \n\nThe no sleep is starting to melt my brain lol :)",
      "Yeah",
      "Yeah, I'm not not waiting anymore, but happy you got a FE3090!",
      "Better than buying a 3080 for $2000, so a 3080 is 60% more expensive for 10% less performance actually.",
      "And how much time have you spent doing that? I spent every Tuesday and Thursday for the last few months trying. Adding up all of those hours I realized how much time I wasted. Instead I just bought a 3090 because fuck it.",
      "Congratulations on 1st!! We are 49th :)",
      "If I get a 3080 ti I’ll sell you my FE 3080 at non scalper prices.",
      "Is the price worth it or are you there out of desperation"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "high",
    "matched_keywords": [
      "rtx 3080",
      "3080"
    ],
    "title": "@KatCorgi: \"The RTX 3080 has about 20% increase compared with RTX 2080 Ti\"",
    "selftext": "https://twitter.com/KkatCorgi/status/1285452946218512384\n\n\"The RTX 3080 has about 20% increase compared with RTX 2080 Ti\"\n\nTo which @kopite7kimi replied:\n\nhttps://twitter.com/kopite7kimi/status/1285454528339259392\n\n\"It's true. Not bad, except of TGP.\"\n\nThe two represent the most reliable leakers for Nvidia lately.\n\n[Nvidia GPU performance/price over years over at /r/hardware](https://www.reddit.com/r/hardware/comments/hva9hx/nvidia_gpus_over_the_years_ampere_included/)\n\n**My personal opinion**:\n\nI would say 20% is really meh and I doubt Ampere will be worth it, especially when considering the major TDP increase.\n\nIf this is accurate, Sasmsung 10nm must suck. I think AMD might be able to give Nvidia a run for its' money here.",
    "comments": [
      "I'll hold any \"not bad\" comments until I see the princing.\n\n20% more for 600-700$? Not bad.\n\n20% more for 1000-1100? Ehm.",
      "For reference here is information about previous releases of Nvidia:\n\nGTX 780 Ti - $699 - (7.11.2013)\n\nGTX 980 - $550 (18.9.2014) - 10%-15% faster than 780 Ti, $150 cheaper, 10 months after the release of 780 Ti\n\nGTX 980 Ti - $650 (1.6.2015) - 70% faster than 780 Ti, $50 cheaper, 18 months after the release of 780 Ti\n\nGTX 1080 - $600 launch (27.5.2016) ,  cut to $500  (1.3.2017) - 25-30% faster than 980 Ti, $150 cheaper, 12 months after the release of 980 Ti\n\nGTX 1080 Ti - $700 (5.3.2017) - ~~43% faster~~ than 980 Ti, $50 more expensive, 21 months after the release of 980 Ti\n\n(EDIT: **[Anandtech](https://www.anandtech.com/show/11180/the-nvidia-geforce-gtx-1080-ti-review/17) puts 1080 Ti at +74% at 4K and +68% at 1440p over the 980 Ti**)\n\nRTX 2080 - $700 (20.9.2018) - 5-8% faster than 1080 Ti, same price, 18 months after the release of 1080 Ti\n\nRTX 2080 Ti - $1000 (27.9.2018) - 30-34% faster than 1080 Ti, $300 more expensive, 18 months after the release of 1080 Ti\n\nRTX 3080 - $??? (9.2020?) - 20% faster than 2080 Ti (?), unknown price, almost 24 months after the release of 2080 Ti\n\nRTX 3080 Ti - $??? (9.2020?) - 30%-40% faster than 2080 Ti (?), unknown price, almost 24 months after the release of 2080 Ti\n\nPerformance figures are from techpowerup.com\n\nGiven the whole 2 years from Turing to Ampere, 20% is hardly impressive. Pricing will decide the fate of these cards. Also, the second time Nvidia left performance on the table by going with an inferior node, like with Turing.",
      "Both the 2080 and 2080S were $700... $600 seems too optimistic. They got the taste of blood in their mouths; I'd be shocked if it was below $800. \n\nTo me it sounds like they want to move the current high end SKUs up and create more segmentation. The 2070S and 2080S replaced the non-S versions, but the non-S versions are still around for 2060 and down. 1650 and 1660 have Ti's as well.",
      "Nvidia afraid of getting Intel-ed.",
      "It all is going  to depend  if RDNA2 can match and surpass the 2080ti.\n\nIt all points out that is going to be yes. Rumored 80+ CU AMD part should on paper surpass and even crush 2080ti, since it has twice the CU count of that of the 5700XT that falls just short of the 2070S. And nVidia is aware of that, otherwise it wouldn't make sense for them to go so hardcore in power consumption, plus it's been a while since they have been forced to come with a 102 x80 part.\n\nAMD's mid end is going to be something like the Xbox chipset, some 50-60 CU part that should be capable of matching at least the 2080S.\n\nIt all makes sense to me. Otherwise nVidia wouldn't be balls out.",
      "Exactly, a 2080Ti beater for circa £600-£800 is great, but if it launches at a like-for-like cost then It's going to be a similar result as when 20** came out after 1080.",
      "Almost no one will pay $1,000 for a 3080. Nvidia would be losing their minds with that.",
      "They also got the taste of horrible sales in their mouth. The pricing of the 20xx series backfired and made their revenue plummet so badly that they had to scramble and basically refresh the entire series mid-generation.",
      "There's no way they price the 3080 above $800. It would simply nullify Ampere from all but the enthusiast crowd in a day and age of consoles that will offer 4K 60 hz and RTX capabilities for a complete package worth $500-600. AMD would eat the market alive.",
      "1080ti was more like 60% faster than 980Ti on average. Even more maybe.",
      "> what if I have infinite money?\n\nThen give us your address so we can come say hi",
      "Umm, I think the 3080 being 20% faster than the 2080ti is pretty damn good....",
      "I know this is all speculation. However, if these pricing and performance rumors have any merit it would be very unfortunate. \n\nCompared to consoles PC pricing would be getting way out of hand. Just awful value for what you are buying. I’m just not sure how people would be able to justify paying these prices.",
      "Says who? The same guys have rumored the 3080 to be at 4300 cuda cores and the 3080ti at 5200cuda cores..\n\nthats a big difference.",
      "Exactly. 24 months into Turing release and GTX 1060 is still ruling Steam hardware survey. 4 years ago Pascal replaced 9 series much, much faster.\n\nIf they continue offering this abysmal value upgrades, AMD will have good opportunity to strike.",
      "heh for a moment I read 3080ti for some reasons and I almost exploded.\n\nwish it was 30%+ but eh still better than rtx 2080 only matching 1080ti for a long time.\n\ndeciding factor will be price as always, though I'm probably going to bite the bullet for 3080ti since I'm in need of a good gpu.",
      "The 1080ti was just too good (and Pascal in general). It had the biggest leap in performance in recent memory.\n\n3080 being +20% over 2080ti is not bad in my opinion... 2080 was within margin of error from 1080ti. This means that 3080ti is gonna be about +50% over 2080ti.\n\nHowever, it's pretty clear NVIDIA has no competition. That's why they allowed themselves to release a new series that had little performance increase but costs more. No card in the Turing series had good value imo. 2060s/2070s too expensive to be mid-range. 2080s just a slightly better 1080ti, and 2080ti not close to justifying its price. All AMD had to offer was a card that can compete with the PREVIOUS flagship, but couldn't even do that because of driver issues.",
      "What kind of phantasy world are people living in lmao, if it's 20% faster at $700 that would be absolutely amazing. Phenomenal. By far the best we can hope for. How is that \"meh\"? The 2080 Ti is ~32% faster than the 2080, so the 3080 by this logic would be 1.32 * 1.2 = ~58% faster than the 2080. At the same price, that would be the largest price to performane jump **ever**, even bigger than the huge outliers that were Maxwell and Pascal. It would be absolutely incredible!\n\nMuch more likely though the 3080 will cost like $859.",
      "Oh wow, never actually looked at their revenue reporting until just now. The impact was immediate, lol. Alright, consider my hope renewed.",
      "set expectations that favor the consumer and be mad when they arent met -- dont do nvidias work for them by telling people to expect to pay more"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "high",
    "matched_keywords": [
      "rtx 3080",
      "3080",
      "3080 ti",
      "rtx 3080 ti"
    ],
    "title": "Best GPU to upgrade from RTX 3080 Ti 12 GB",
    "selftext": "**Dear community,**\n\nI'm considering upgrading my current RTX 3080 Ti, but I'm not sure which GPU would be the best choice.\n\nI mainly use it for gaming (aiming for 4K resolution on a 4K monitor or my TV through a Denon AVR-X2300W receiver), and occasionally for 4K AI video processing.\n\n**My current PC specs:**\n\n* Motherboard: Gigabyte Z690 AORUS Master\n* CPU: Intel Core i7-12700KF (12th Gen)\n* RAM: 64GB DDR5\n* GPU: RTX 3080 Ti 12GB\n\nWhich GPU would you recommend as a worthy upgrade?\n\n",
    "comments": [
      "9070 xt and it isnt even close",
      "5070ti is the best \"value\" from NVIDIA right now. About the same performance as a 4080 super with DLSS4 added. 5080 is marginally better for 200 more (if you can find either at msrp). Supposedly 5080 super and 5070 super are coming next year with more VRAM which might be worth the wait if you can stick with the 3080ti for a bit longer. 16gb VRAM on the 5070ti and 5080 is disappointing and really not a huge improvement over the last series.",
      "The 5070ti is the better choice given USA pricing but it depends on region",
      "What performance are you getting from your 3080Ti in 4K?",
      "5080/90 for 4k depending on game. 90 for AI",
      "3080 ti has dlss4",
      "Okay",
      "Okay",
      "Okay",
      "Not true https://www.techpowerup.com/review/sapphire-radeon-rx-9070-xt-nitro/37.html",
      "something with 16gb of vram at least or it wouldn't be an upgrade",
      "I had a 3080 and got the 9070xt but the Raytracing and Pathtracing performance was lackluster to say the least so I got a 5070ti.\nIf I had a 3080ti I probably would've gotten a 5080 or waited for next generation to justify an upgrade.",
      "To really feel a performance jump from a 3080ti- a 4090/5080/5090.\n\nI’ve had a 1080, 2080ti, 3080ti, and 4090. The performance difference coming from 3080ti to 4090 felt like I skipped a generation.\n\n50 series is nothing but more frame gen so I upgraded my monitor instead to an LG 4k 240hz dual mode. Possibly my best pc upgrade ever lol",
      "I’d go for the 5070 TI or the 9070 XT. I’ve the 9070 XT, tried to troubleshoot it for a week straight and had a lot of issues. So I returned it and got the 5070 TI, no issues ever since. If you’re going for the Oblivion Remastered, I’d recommend Nvidia",
      "Nothing currently, wait for 5xxx refresh...",
      "pretty much only 5090 is an upgrade where you will really feel the difference, i mean you could get 5070Ti but you will only get 30% fps more, so instead of 60 you will have 80, is that a big enough differencefor you? not to mention that for 4K 5070ti is still too slow, you will struggle getting to 60fps a lot on max details and you will have to rely on dlss performance to get you there, and 16gb of vram is also not enough for 4k more and more often, especially if you want to combine path tracing and frame gen (or DLAA).\n\nBut if you dont have the budget for 5090, there are rumours that the next Super series of gpus will have 5080 Super with 24GB vram and 4090 performance, that would be a very good upgrade that would be more affordable, you just have to wait 8-10 months. But current 5070Ti/5080 gpus are really kinda meh, the raw performance upgrade is very weak, it will still be slow in situations where 3080ti is slow. 5070ti/5080 are perfect 1440p cards but for not ideal for 4K.",
      "Ima be 100% honest. Outside of the vram the 3080 Ti  is solid. And the only real upgrade to this would be a 5090 honestly. Cause anything 5080 and below would just feel like a slight upgrade. But if 5090 is just not possible. Then 5080 is the 2nd fastest of course ignoring the 4090 which isn’t sold new anymore.",
      "Thank you all so much for your helpful responses! I really appreciated the different perspectives, and I ended up waiting for the next gen.  \nyou guys really helped me out!",
      "Had the same card, upgraded to 9070xt last week. Nice bump in performance but will only be worth it once I manage to sell my 3080ti. \nThe real upgrade was silence and lower temps.",
      "Thats a terrible upgrade..."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "high",
    "matched_keywords": [
      "rtx 3080",
      "3080"
    ],
    "title": "From RTX 3080 12 GB to RTX 5070 TI 16 GB: it is worth?",
    "selftext": "I want to change my GPU and buy a 5070 TI for playing in 1440p High settings, with RT and a framerate boost with multi frame tech, it is worth or i should wait for SUPER cards or 6000 series?",
    "comments": [
      "Don't listen to any answers here. Gpu upgrades are entirely personal. If you think you need an upgrade, go get one. If it's not worth it yet, don't. Upgrade whenever your pc isn't performing to YOUR standards with YOUR games.",
      "People want a yes or no answer to literally everything nowadays. Search engines and GPT have absolutely cooked society. There’s so much nuance and context that goes into “worth it” lol like c’mon brother",
      "It's about a 50% upgrade in raw performance, plus you get framegen. \n\nAs to whether it's worthwhile, that's subjective. I wouldn't upgrade from my 3080 for less than double performance, personally.",
      "Ok that has nothing to do what what op asked you're just looking for an opportunity to say you have a 4090 lmfao",
      "OP, Listen to this person.\n\nIn reality, the only people who can recommend the card are the ones who have the 5070ti and also play the same games you do. See if you can find YouTube videos of people testing the 5070ti with the games you want to play, and then make a decision.",
      "yes wait 6000 series for the next gpu shortage",
      "I went from a 3080 10GB to. 5080…it wasn’t worth it. Yes it’s a little nicer, but it’s not $1200+ nicer.",
      "I had a 6800XT and moved to a 5070Ti. To be honest, I wish I had waited for 5080 prices to come down. I wanted to hit 60fps with RT in the new GTA enhanced. I get that, but not to the leaps and bounds I thought I would. I probably need a whole platform update, but I was only marginally impressed",
      "I never understood the arguments made in this sub. People called me crazy for buying a 4070 super for a 4k60 card. 90% of my play time is Beamng drive and War Thunder. NATIVE ULTRA RAY TRACING in war thunder gets me 60fps on most maps. Throw on quality dlss and frame lock and the fans don't even turn on.",
      "I went from a Gigabyte gaming oc 3080 10GB to a Gigabyte aorus master 5070TI and it was well worth for me... to be fair, I built a new pc for it but then again, the cpu in my old machine was holding the 5070ti back",
      "Yea but the whole \"leaps and bounds\" thing is almost certainly because of the rest of your PC. \n\nGTA is very light on the GPU, raytracing obviously makes it harder to run, but again my 3080 can do 60fps in 4k with raytracing on, it never drops below 120fps with raytracing off (4k ultra). \n\nWouldn't be surprised if a 5070ti can do 120fps or close to it with raytracing on if the rest of the pc is good.\n\nEDIT: [100+ fps in the city at 4k with everything maxed out including RT.](https://www.youtube.com/watch?v=P1gWczfTXuw) That is with DLSS Quality which imo is foolish not to use. If you play at 1440p or can settle for DLSS balanced at 4k then the 5070ti can easily do 120fps.",
      "That's fair, sadly they are kinda disappointing if you have a 4090. Overclocked 5080 is almost a 4090 but still.",
      "Depends what games you play imo. I’d probably wait though",
      "Up to you bud.  Personally I went from a 3080 ti- 5080 which is a similar jump to what you’re talking about.  I couldn’t be happier. My last card could do 4k60 all day but now I can crank out 4k 144 and it looks just insane",
      "Upgrading from a 3080 10GB to a 5070 Ti. Got the 5070Ti for $830. I can sell my 3080 for quite a bit, so the cost to upgrade is not so bad. My 3080 is still really good, but it’s not cutting it in some titles then I would need to lower graphics settings or use DLSS performance. My main reason is the VRAM because at 1440p I have always had to set the texture setting down 1-2 settings",
      "Personally I have a 3080Ti and will be skipping this generation. The performance increase I would get is simply not worth the money, if staying in the same price class as what I paid for my current card",
      "Honest review of 5070 ti upgraded from 4070 original. The upgrade is and feels nice. It’s not as major as I thought it would be (nvidia drivers underperforming, bugs etc). I play in 3440x1440 and now I can push way more than my 4070. PT and DLSS quality on cyberpunk and wukong do feel way nicer. I can push some more 2k/4k texture mods on cyberpunk and keep 70 fps (with frame gen x2 - I know it’s not ideal because my actual frames is 35-40 but I’m having fun and it feels responsive enough for me). \nHaving said the above DONT buy it for the x3 x4 FG. It’s completely unusable as it stand now at least to my testing. Too many artifacts and glitches. I believe that they will improve it on the future as they did with DLSS during the 40 series but now, 2 weeks with my 5070 ti it is on instant disable. Diablo 4 feels better than my 4070 but even there the x3 x4 MFG is unusable. \n\nTLDR: the upgrade from 4070 to 5070 ti feels nice but don’t buy it for the multi frame generation - not worth it as is currently. Buy a 50 series for the DLSS upgrade and 2x frame generation update from 30 series if you believe you need it.",
      "I would wait for 6000 series\n\nI mean which game RTX 3080 can't handle at 1440p ??? Even the most demanding games, you can still use \"optimized setting\" to improve fps and DLSS quality mode\n\n5070 Ti is big upgrade but 3080 can still run modern games  with no issue.",
      "If you want framegen on your 3080, you can try out DLSS to FSR Framegen mod available at Nexus mods. Basically, enables the DLSS4 Framegen checkbox in games for your 3080. Pair it with DLSS4 swapper so you will benefit from the less blur of DLSS4 as well.\n\nGPU price are atrocious at the moment and I would not support that kind of price imo",
      "I made this upgrade a few weeks back for the same reason. I’ve been happy with the results I’ve gotten so far. If you can find a 5070ti at/near MSRP, pull the trigger"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "high",
    "matched_keywords": [
      "3080",
      "3080 ti"
    ],
    "title": "RTX 3090 or 3080 ti or 4070",
    "selftext": "So there are 3 gpus that are in my area  second hand , 3080 ti evga at 480 euro , 3090 founders edition at 500 euro , and palit /msi 4070  12gb at 480 euro (used, new ones are 650+ euros)\n\nPersonally i leaning towards the 3090 fe because of the massive vram , sometimes i do AI stuff but its like a hobby , mostly gaming at 1080 in competitive games but i do have a 4k tv that i play  single player games on it sometimes with controller.\n\nIm scared that the 3090 pcb might crack but i havent seen / heard FE models do that. Another thing to consider is resell value in few years , which one would hold its value the most.",
    "comments": [
      "The best deal is with the 3090 for sure",
      "3090 if you have a decent power supply",
      "power supply is 1000W platinum so no issues there",
      "There will be no such drop.",
      "3090 is the Best value opion here. As 4070 owner here i'm struggling with some games with 12gb of vram.",
      "I'm also curious as to how you're struggling with 12GB of VRAM. \n\nAs for my experience in 1440p the most I've probably used is around 10GB or 11GB but that's with cyberpunk and with RT on. But then again, the game is too niche and most of the time I barely hit 10GB on most games I play. Mostly the average usage is around 6GB-8GB sometimes 9GB.",
      "3090 with an undervolt. You can cut 150w and lose 5% performance on that gpu",
      "Why are you worried about a 12gb ram gpu when yours is 16gb",
      "Wish this were true but it will not be.\n\n3080 / 3090 still going for high prices etc… it’s nvidia my man",
      "You mention AI... If you are intending to do any LORA training or want to use the full Dev version of Flux, you need 24GB of VRAM.  That leaves the 3090 as your only and best option",
      "3090 is the current Miata of Ai enthusiasts.",
      "I agree that the 3090 is the best value option here and I am probably an outlier with this opinion.  But the 4070 is plenty capable, I am able to play my games max settings with RT off at a pretty decent FPS.  RT isn't worth the price tag of a 4090 or to sacrifice a large fps drop.  Most of these games look great with high settings without RT.  Don't steer people wrong assuming everyone intends playing with all of these features on.",
      "Which games are you talking about? Define how it struggles and how you're measuring Vram usage. What resolution are you using? What CPU do you have?\n\nBecause it sounds like you've pulled this statement out of your ass.",
      "It's worth noting that despite looking very good (especially with RT) cyberpunk has pretty meh texture quality and so VRAM usage is *relatively* low",
      "Cyberpunk is 4 years old though.\n\nTry Alan wake 2 with everything maxed out. 4070ti's were having issues with that to start with as they couldn't handle the game at high Res with path tracing and frame gen. Ironically the extra vram frame gen eats was bumping the game over the 12gb threshold in some cases.",
      "The 4090 most likely would still be over $1500 because the 5080 will still have 16GB VRAM, only when the 5080 Ti 20GB comes out in 2026 then 4090 can drop to $1000",
      "damn thats huge , thanks for the tip will def undervolt as i plan to use it for atleast 5 years",
      "They're all I buy now and they all work great.  Just don't buy from sellers with very little feedback.",
      "Fair enough MJ .. have fun with whichever GPU you decide on! :)",
      "3090"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "high",
    "matched_keywords": [
      "rtx 3080",
      "3080",
      "3080 ti",
      "rtx 3080 ti"
    ],
    "title": "Which RTX 3080 Ti model runs the coolest?",
    "selftext": "Been thinking of getting a 3080 Ti since they are finally in stock now near MSRP in my country and wanted to know specifically which model of 3080 Ti handles temps the best. Any thoughts?",
    "comments": [
      "Watercooled versions",
      "There are \"stock\" watercooled GPUs like the seahawk for example",
      "I would get the cheapest one you can get and undervolt. I mean, just a little but would make a huge difference on temps.\n\nAnd the best part, it doesnt hurt your gpu! Plus you can even let it run stock speeds but lower mV.. you wouldnt lose performance.. and if you did, maybe 0.5% but much better temps and much lower wattagr",
      "You do realize 80c is just fine, right?",
      "I think Asus TUF+Strix, MSI Suprim and Gigabyte Aorus extreme are among the best for air cooled",
      "Ok, let me elaborate, air cooled. I know there are manufacturer watercooled GPUs but considering the state of the market right now, there is little to no availability of those where I live. And if there is one, it is hella expensive.",
      "My FTW3 ran so hot I ended up buying the AIO hybrid kit from EVGA for it.",
      "Honestly, yep.  With high end ampere the silicon lottery matters more than then cooler design imo. Under gaming stress I dropped my 3080ti from 400W to 330W.  Under other tasks (Topaz AI) I dropped from 270W to 170W.  That's a bigger difference in temps than having a better cooler.\n\nObviously the coolest card is winning the silicon lottery with the best cooler, but there's no way to guarantee that.",
      "Asus Strix is King",
      "I don't know which one runs coolest but when buying a new GPU I will always advise to buy EVGA. Their customer service is beyond what any other company offers and makes it much more worthwhile.",
      "what's hot? mine never seems to go above 80C",
      "Sorry, should have been specific. Same temps as you, around 80C. That’s just too hot for me, I wanted something in the high 60s.",
      "EVGA aren't bad either",
      "Awwwwwwwwwww. No shit.",
      "But winter is coming soon and how else am I going to warm up my house.",
      "That was only the 3090, and they found out it was a soldering error that happened to a limited number of batches and they replaced every 3090 card from those batches for free. \n\nEVGA found a problem, solved the problem, and made their customers whole. I say they are a good company.",
      "this is fake news",
      "https://www.youtube.com/watch?v=FqpfYTi43TE",
      "From what I've come across, Strix, Suprim X, FTW3 ULTRA, Aorus Xtreme and Gamerock are the top contenders. TUF OC also has a really good cooler for the price as well. Personally I have the Gamerock OC and the highest memory junction temp i have seen is 82 C at 60% fan speed running Horizon Zero Dawn.\n\nI would get any of those, minus maybe the Aorus since they have had terrible results on their thermal pads, but that may since have been fixed.",
      "It seems that quality control is hit/miss -- regardless of the model.  Seen top of line, and FE editions with terrible/missing thermal pads.\n\nI think whatever model you pick should be fine -- if you replace thermal pads on VRAM (which everyone should do!!)\n\nAnother thing that will impact temps, in general is the bower budget of a particular card.  500 watt cards are going to run \"hotter\" out of the box, bit that shouldn't be the case when wattage is normalized.\n\nAlot of posts about temps are just general \"I get this gaming,\" without talking power consumption or fan speeds .. or even game (rt? DLSS?)\n\nFind the card you can get reasonable $, then just make sure it isn't a total POS.  You should be fine.  GOOD LUCK!"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "high",
    "matched_keywords": [
      "rtx 3080",
      "3080",
      "3080 ti",
      "rtx 3080 ti"
    ],
    "title": "NEW $419 RTX 4070  or USED RTX 3080 ti $500? ",
    "selftext": "Im planning on upgrading just not right, however, I just got a buyer with cash on hand, and I'm selling my Asus Rog Strix 2060 Super.\n\nI used to play in 1080p but upgraded to a 2K monitor, so ofc my 2060 S still rocks but struggles ofc, I considered the 3080, which is more 4K friendly.\n\n  \nI might be even down to consider a 3070 ti tbh since I've seen some for $200-$300 but used ofc.",
    "comments": [
      "Where did you even find that 4070 brand new for just $419, crazy\n\nSeriously though, you should just get the 4070. It may perform worse than the 3080 Ti by 20% but is significantly efficient (draws 200W vs 350W) and has frame gen.",
      "also buying a new comes with a full warranty which has imo significantly value when prices are this high",
      "I say 4070 for the power savings and dlss3. They're both great cards. Can you find a 4070 super for a bit more?",
      "4070 doesn’t beat the 3080 Ti sadly, plus they both have 12GB of VRAM",
      "At 419 the 4070 offers an amazing value proposition, I would honestly say pull the trigger on it before it’s off the shelf. Sure there are faster cards from this generation and the 5000 series is just around the corner. But I seriously doubt they will give you the bang for buck a deal such as this would provide.",
      "Fr. New 4070 is like 600$+",
      "True. That 16 gigs of VRAM will be worth in a few years",
      "I would also pick the RTX 4070 at $419. That's a great deal. The RTX 3080 Ti is slightly stronger but not in any meaningful way. The RTX 4070 has frame generation, and it's newer, so it will be supported longer as well.",
      "It's good for story based games. It's horrible for multi-player but great for single player in many situations.",
      "4070 all day long dude, frame gen is useful and its just going to last longer, run cooler and still give great performance",
      "Amazon has a 4070 super for $30 more. \n\nhttps://a.co/d/4hsoiNp",
      "https://www.techpowerup.com/review/nvidia-geforce-rtx-4070-founders-edition/31.html\n\nNoticeably slower than 3080 ti.",
      "Where are you seeing pre-owned 4070's for $320? I've been scouring eBay and Jawa all week for a GPU and never seen a working 4070 below $400. Plenty of \"as is for parts' listings in the $300 range.",
      "OP is in Honduras so there must be a lot less demand there",
      "I'd go 4070, especially since 3080Ti draws like 200W more for barely any more performance.",
      "save more money and buy the 4070 ti super, your just wasting it buying anything less",
      "Also the 4070 will retain resale value better than the already 3 year old card. Should OP decide to just pawn it off and step up to next-gen in 2025, he might even turn a profit on the 4070.",
      "Yeah. Even if next generation cards were priced much higher, all of the people wanting to upgrade and sell their old card would still force used prices down at least temporarily.",
      "core free card",
      "4070 Super goes for $600+ and Ti for $700+"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "high",
    "matched_keywords": [
      "rtx 3080",
      "3080",
      "3080 ti",
      "rtx 3080 ti"
    ],
    "title": "[US] What to know about NVIDIA’s GeForce RTX 3080 Ti Founders Edition Graphics Card - Best Buy Corporate News and Information",
    "selftext": "",
    "comments": [
      "1 store, downstate in rural country. Lmao gg bb",
      "The only place you can get one in the entire state of Illinois is in Champaign, which is like the 5th or 6th largest metro area, maybe not even? Chicago, Rockford, Bloomington, Peoria, Quad Cities, Springfield, St. Louis areas get nothing.\n\nLMAO\n\nP A P E R L A U N C H",
      "I wonder realistically how many of these they'll get per location. I doubt it'll be anything over 10 per store. **I deleted my edits I have this update**:\n\nRoseville CA 46  \nChampaign IL 46  \nWest Madison WI 46  \nNovi MI 46  \nGainesville FL 54  \nBoca Raton FL 54  \nCanton OH 46  \nVirginia Beach VA 40  \nChesapeake VA 30  \nNewport News VA 21  \nCosta Mesa CA 64  \nDeptford NJ 42  \nChristiana DE 42  \nModesto CA 64  \n\n\n  \nSan Fran CA 64  \nManhattan Midtown 62  \nCary NC 42  \nCedar Park TX 46  \nMerrillville IN 24  \nTuttle Crossing OH 46  \nConcord Mills NC 24  \nWichita KS 46  \nFayetteville NC 42  \nGreenwood IN 46  \nFargo ND 46",
      "79 Best Buy locations listed on that site and it looks like around 50 per store (outside of a few really low numbers).  That is less than 4k cards for all of the US lol",
      "I can smell the tents already",
      "I’m already in line",
      "I can't even entertain the idea of taking off mid day from work just to stand on line for 20 hours.",
      "I can confirm that for my location at least this number is accurate. I asked a best buy employee and they showed me that number on their computer screen",
      "These numbers are pulled from the API. Stores that show ?? are stores that are reporting no stock information. Could mean that they just haven't checked in the shipment as I have seen a few stores change from 0. Hopefully the numbers given by the API are correct. \n\n**Final Update: 8:00AM Central Time**\n\n**15 stores never updated**\n\n**3412 GPUs Total so far**\n\nZip|City|State|Quantity\n:-:|:-:|:-:|:-:\n35242|Birmingham|AL|54\n35806|Huntsville|AL|54\n72758|Rogers|AR|??\n85053|Phoenix|AZ|64\n93312|Bakersfield|CA|64\n92626|Costa Mesa|CA|64\n90064|Los Angeles|CA|58\n95356|Modesto|CA|64\n95678|Roseville|CA|64\n92108|San Diego (Mission Valley)|CA|64\n94103|San Francisco (13th & Harrison Street)|CA|64\n80920|Colorado Springs (Academy Boulevard)|CO|46\n80922|Colorado Springs (First & Main)|CO|??\n80031|Westminster|CO|46\n06385|Waterford|CT|??\n19702|Newark (Christiana)|DE|42\n33498|Boca Raton|FL|54\n33765|Clearwater|FL|54\n32608|Gainesville|FL|54\n33012|Hialeah|FL|54\n34741|Kissimmee|FL|54\n33172|Miami (Doral)|FL|49\n32809|Orlando (Florida Mall)|FL|54\n32504|Pensacola|FL|54\n33710|Saint Petersburg|FL|??\n30909|Augusta|GA|54\n30253|McDonough|GA|??\n52807|Davenport|IA|46\n83709|Boise|ID|64\n61822|Champaign|IL|46\n46142|Greenwood|IN|46\n46410|Merrillville|IN|46\n67206|Wichita|KS|46\n40207|Louisville (St. Matthews)|KY|??\n01040|Holyoke|MA|??\n04106|South Portland|ME|??\n48375|Novi|MI|46\n49002|Portage (Kalamazoo)|MI|46\n55113|Roseville|MN|46\n65804|Springfield (Battlefield)|MO|??\n59102|Billings|MT|58\n27518|Cary|NC|42\n28027|Concord (Concord Mills)|NC|42\n28314|Fayetteville|NC|42\n58103|Fargo|ND|46\n03060|Nashua|NH|62\n08096|Deptford|NJ|42\n87123|Albuquerque|NM|??\n89113|Las Vegas (Southwest Las Vegas)|NV|64\n12203|Albany|NY|??\n10017|New York (Midtown Manhattan)|NY|62\n43016|Dublin (Tuttle Crossing)|OH|46\n44720|North Canton|OH|46\n74133|Tulsa|OK|46\n97220|Portland (Cascade Station)|OR|??\n97301|Salem|OR|64\n97477|Springfield|OR|64\n16509|Erie|PA|??\n29607|Greenville|SC|54\n37923|Knoxville|TN|54\n37129|Murfreesboro|TN|??\n76015|Arlington|TX|46\n78613|Cedar Park|TX|46\n79407|Lubbock|TX|24\n79705|Midland|TX|46\n77380|The Woodlands|TX|??\n84107|Murray|UT|60\n84405|Ogden (Riverdale)|UT|64\n84115|Salt Lake City (South Salt Lake)|UT|52\n23320|Chesapeake|VA|42\n22401|Fredericksburg|VA|42\n23602|Newport News|VA|42\n23462|Virginia Beach|VA|41\n98005|Bellevue|WA|64\n98036|Lynnwood|WA|64\n98125|Seattle (Northgate)|WA|64\n98383|Silverdale|WA|64\n99216|Spokane (Spokane East)|WA|58\n98409|Tacoma|WA|52\n53719|Madison (West Madison)|WI|46\n26501|Morgantown|WV|46",
      "This is disappointing news. I guess supply of these cards are so small that they have to pull a stunt like this to avoid it all being snatched up by bots within minutes. But doing it on an early Thursday morning miles away from most major metro areas doesn't really seem like the best way to handle this either imo. guess I'm sticking with my 900 series card until it's old enough to drink",
      "Pin this on the subreddit so that no one gets one tomorrow lol",
      "I just tried calling the closest one to me to ask this question, and it says they are not taking phone calls at this location at this time. Classic.",
      "Looks like there won't be an online release as per the above link.\n\n> Here’s everything you need to know about RTX 3080 Ti Founders Edition – **available only at select Best Buy stores.**",
      "Couple people in line already at my local store",
      "Gl!",
      "IL? It kind of makes sense as a spot to pick, since it's the home of the UIUC campus. Still sucks, though.",
      "How are you able to find the stock numbers?",
      "You better start sleeping in front of it right now",
      "Yeah, but I'm not trying to resell it like some scumbag scalper - I need a new card for my system, to replace my dying 1080",
      "Closest store is an hour and a half away, and I have to be there in person on a weekday? I have work in the morning. I'm not about to call off work to stand in a line for hours and most likely be told they are all out of vouchers by the time it's my turn. Fuck best buy. At least give people who work for a living a chance to buy one online."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "high",
    "matched_keywords": [
      "3080"
    ],
    "title": "ZOTAC releases GeForce RTX 3090, 3080, 3070 and 3060 TI PGF OC graphics cards - VideoCardz.com",
    "selftext": "",
    "comments": [
      "China only........",
      "It's like the people commenting here don't even bother reading the article, but that's just Reddit for ya.\n\nChina only model. Triple fan OC models. RTX 3080 has 3 8 pin and argb, 3070 and below have 2 8 pin and no rgb.",
      "makes no difference even if they release worldwide, theres no stock.",
      "Hey, look, more vaporware!",
      "\"Releases\"",
      "Actually Zotac stocks in Asia are quite abundant. 3090 are easy to find.",
      "The look",
      "might throw some high power models out in the rest of the world as well at some point.",
      "??????",
      "More power to the Chinese crypto farms",
      "(copy/paste) \nHad a ton of defective fans on the 3080 Trinity. And their firestorm software is really bad.\nTake a look at the r/ZOTAC subreddit around september",
      "Just like all the 3080s that are available in retail!",
      "For twice the amount of msrp, kinda insane.",
      "look at all these nice GPUs that won't be in stock.",
      "I'm in Singapore and they're readily available off the shelf at MSRP. Some are already on second hand markets at 100-200 below MSRP",
      "This gen skip zotac. They got caught in a shit storm because they use the worst quality components in their gpu and they keep failing and crashing.",
      ">I know. I just wanted to trigger some snowflakes ❄ 🤙\n\nSomeone time travelled to 2007 when Ben Shapiro complications were considered peak humour for 13 year olds",
      "My MSI 1080 (gaming x) failed after a week.",
      "Nope, the scalping wave is over. 3090 are at MSRP and the Zotac cards are at RRP",
      "How are Zotac cards in general?"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "high",
    "matched_keywords": [
      "3080"
    ],
    "title": "[Techpowerup] NVIDIA PCI-Express Resizable BAR Performance Test - 22 Games, 3 Resolutions, RTX 3090, 3080, 3070, 3060 Ti",
    "selftext": "",
    "comments": [
      "A shame they didn't report on 1% lows which I'd argue is just as important, if not more important for most people. \n\nThrough testing a few games with a 5900x and a 3080 I have seen upto a 12% increase in the minimums although it's generally around 8%.\n\nAlso just for reference my test with Cyberpunk saw nobar give me 51 fps just outside the club and 56-57fps with bar enabled, 4k all highest, rtx all on medium with balanced dlss. I saw roughly a 5fps increase scene for scene elsewhere when loaded into a save, tested multiple times to ensure it was consistent with bar on vs off and got the same results each time.\n\nEdit:\nThere is one page of frame times, it was added a few hours after my comment.",
      "Crazy that Gears 5 gains so much. Why didn't they test RTX?",
      "1-2% improvement on a 3090 @4k is a nice free boost. Now to use that to throw more mods at Skyrim.",
      "I have the frametime data, just didn't think it's relevant. Will chart it up for you after dinner\n\nEdit: frametime charts have been added",
      "Why even test unsupported games if you aren't gonna whitelist them using nvinspector?",
      "Yes, some people in Guru3D figured out how to do it. I am not gonna post how to do it here, because mods are removing all posts mentioning it for whatever reason.",
      "Gears 5 is one of the best optimized PC games of all time. It even has multi-gpu support. Not SLI, true multi-gpu. It's crazy how many options there are too.",
      "Gears 5 is actually a lot more demanding in terms of graphical features, by quite a bit. Although DOOM looks and runs great, they do cut corners in graphical features and some things don't look great when you really study them. Both amazing games though. \n\nDigital Foundry has a great video on Gears 5.",
      "Yeah, there's a few that are 2-3% better, which can be gained with a small OC. It's free performance, so I'll take it.",
      "If you read down a little bit you'll see the frametime charts were only added about an hour ago, so not really your fault.",
      ">AMD wants to sell you the overpriced Ryzen 9 5900X. The much more affordable 5800X is actually the faster processor for gaming due to its CCD design.\n\nUh, what?",
      "Yeah gears 5 seems the only game that has actual noticeable difference. Other are pretty much unnoticeable",
      "Not sure if I would ever call techpowerup clickbait lmao",
      "No downsides unless some bugs or incompatibility happens. Turn it on for the smooooooth min frames baby",
      "Even 5% performance gain for what is essentially just a bios upgrade is a big deal. I'm very happy with the extra performance.",
      "Can games be whitelisted for BAR using NVInspector?",
      "Some of us are still playing without variable refresh rate monitors (I’m on a 4k tv), so frame times really make an impact on how smooth it feels. So thank you for adding the frame time charts!",
      "Doom Eternal ultra settings 1440p on a 3080 can run at 240 fps but my monitor only does 144. Easily the best optimized game.",
      "Tests likely done using automated scripts running overnight.",
      "Wouldn't the 5950X technically be the best for gaming? Not a good value, but it should have the best binned CCDs and clocks."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "high",
    "matched_keywords": [
      "rtx 3080",
      "3080",
      "3080 ti",
      "rtx 3080 ti"
    ],
    "title": "MANLI submits GeForce RTX 3080 Ti, RTX 3070 Ti, RTX 3060 and RTX 3050 to EEC",
    "selftext": "",
    "comments": [
      "Ok, and what exactly is the point of the 3070 now that we are going to have a 3060 Ti, 3070, 3070 Ti and 3080? \n\nJesus Nvidia.",
      "All these base and Ti models are just absurd. Having cards at at $200, $300, $400, $500, $600, $700, $800 just seems ridiculous. WHICH ONE TO BUY NOW? Oh yea still none available :(",
      ">HOLD OFF ON BUYING 3080s now\n\nUnless... you can't afford a 3080Ti?",
      "And around March/April when your 3080 Ti order still hasn't shipped? Wait for 4080? Wait for \"Bigglier Navi\"?\n\nTime is worth something, the \"usable lifetime\" of a GPU is much lower than the physical life of the hardware itself. If you miss 1/5th of the \"generation\" because you were waiting for a \"better deal\" then you might not have gotten a better deal at all.",
      "Lenovo also listed the 12GB 3060, it's real",
      "If you're buying a 3050, don't expect to run ultra nightmare texture on AAA games",
      "No special naming; probably just 3060 with 6G and 12G indicated in some spec icon on the box just like the 3 and 6GB 1060.\n\nIf the 12GB is true, the lineup would be confusing AF. Having a 60 series card with more VRAM than an 80 series lol",
      "A 3050 would likely be around GTX1080 performance, 4GB makes no sense at all.\nIt didn‘t make sense in 2016 and especially not now.",
      "Wait...a 3060 with 12GB of Vram? Did they mean the 3070Ti? What would a 12GB 3060 be called?",
      "RTX3050 4GB? Really? Unless this chip is slower than 1650 super. Vram is gonna be so bottleneck on this GPU. Most AAA games have no problem chewing 4GB Vram now.",
      "I don't think I'll be tempted by the 3080ti unless it gets priced competitively at $899 or less. Which it definitely wont even at MSRP the base models will probably be $999+. This card is still very much not worth it for gaming. It does not have enough power to last long enough until the 20gb of vram is actually needed at 4k. I would have liked a cut down 12gb vram 3090 instead if it meant a cheaper price.",
      "Not like it's going to be cheaper",
      "Oh no they are making money\nRip",
      "Yeah that’s weird and also probably unnecessary. It’s not a 4K card. I’m not sure why you’d want 12GB. A 3070Ti I could see having that much.",
      "Lmao the high end refresh of cards no one has seen.",
      "What are they going to do? Stuff another 10GB of VRAM and sell it for at least $200 more (probably $300)? That's hardly an \"incredible deal\", especially when you consider that this card will likely be obsolete at the performance expectations of most enthusiasts by the time the VRAM starts being an issue.\n\nI got no problems with alarmists getting a card to give them peace of mind with 20GB of VRAM, but pretending like this is going to be a substantial upgrade that should give pause to 3080 buyers is asinine at best, especially when you know just how poorly the GPU scales with a few more SMs enabled in the 3090.",
      "No need to hold off, they already made sure that no one can buy any.",
      "HAHAHAHAHAHAHAHAHAHAHAHAHAHAHAHA good one man iv not had a laugh like that in ages",
      ">10 gb ggdr6x\n\nLike Gamers nexus said Bandwith is more important.",
      "Well that confirms it. RTX 3080 Ti is launching in January. HOLD OFF ON BUYING 3080s now."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "high",
    "matched_keywords": [
      "rtx 3080",
      "3080",
      "3080 ti",
      "rtx 3080 ti"
    ],
    "title": "GeForce RTX 3080 Ti | The New Gaming Flagship",
    "selftext": "",
    "comments": [
      "Nvidia really needs to get their MSRP straight. [Their giveaway claims the 3080 Ti is worth either $999 or $1099.](https://i.imgur.com/1b3AqoS.png)",
      "At that price, what is the point? If you're already at $1200, you'd be the sort of person that wants the best and for a little extra you get double the vram and a few extra cuda cores with a 3090.\n\nPointless release.",
      "Technically, doesn’t this mean it actually gives less value over 3080 than the 2080 Ti gave over 2080?\n\n2080 Ti vs 2080 = +20-25% more performance and 3GB more VRAM, $400 more expensive FE MSRP\n\n3080 Ti vs 3080 = +10-15% more performance and 2GB more VRAM, $500 more expensive FE MSRP",
      "I do. Already got a buyer lined up for my 3080. Selling it for $600 as it's near-junk status now with only 10GB RAM. Really looking forward to a $1500 AIB 3080 Ti....\n \nWhat a f**king joke.",
      "They are going to sell every single one of these they produce and many will sell in the secondary market above MSRP.",
      "I would but submissions here are still restricted. I've got this archived link in case Nvidia manages to catch the mistake.\n\nhttps://archive.is/s92GN\n\nEDIT: Nvidia has changed it to $1,199 on the site now. Doesn't change the fact that it was planned at $999 at some point.",
      "I think NVIDIA have really missed the mark with the 3080Ti pricing - $1199 is a mistake. I just really dont see who the market is for this card. First of all, the pricing is not competitive with the competition at all, considering the 6900XTs RRP is $999, but more importantly, if someone had $1199 to shell out for a GPU, they would just save a bit longer and buy the $1499 RTX 3090. These cards are going to be going for over $1499 at launch anyway I guess, it just seems Nvidia are taking advantage of the current market to set the RRP way higher than it should be.",
      "This deserves more attention, possibly its own separate post.",
      "Dude they’re drowning in money. They don’t give a fuck. \n\nEven all of us in this sub complaining are still gonna buy their products.",
      "This screams: \"hey everyone is selling at 2x MSRP so we want some of that\"",
      "Not gonna lie, assuming MSRP world existed, I would just add $300 and go for the 3090 instead of the 3080Ti, it's basically double the VRAM for $300, and still better performance.\n\nI guess 3080 (lowest GA-102 die) and 3060Ti (lowest GA-104 die) will be really hard to find still.",
      "The 1200 $ MSRP for 3080TI is a joke imo comparing it to 3080... also don't forget LHR is on top... who mines anyway at 300 if you only get like 58 mh/s lol. Even my almost 4 year old 1080TI is more valuable with 43 mh/s running 180W. \nHonestly, who wants to buy that thing? 3070TI on the other hand looks perfectly fine at 600 $\n\nI was waiting all the time for the 3080TI and i'm honestly very dissapointent. If only i knew, i'd have gone for a 3080 at launch because the MSRP on that thing was perfectly fine around Launch time",
      "The problem is the fact that *technically*, the 3080 can be considered a Ti-class card, since it's on the GPU that's typically reserved for Ti-class cards (XX102, GA102 in this case), and it's sharing that GPU with the 3080 Ti & 3090, just that it has a lower binned version of it compared to the 3080 Ti & 3090, with a relatively small amount of cores disabled (in comparison to other generations).\n\nThat's the entire problem with this generation's top end cards, NVIDIA kinda shot themselves in the foot by putting what's typically the best consumer GPU into the second, now third since the 3080 Ti is a thing, best card. The 2080 & 2080S was on TU104, which was also used for the 2070S, while the 2080 Ti was on TU102. The best consumer GPU was reserved for the single best consumer graphics card, with the other cards following behind using less powerful GPUs, so there was a sizable gap between them.\n\nHowever, this generation, they gave the 3080 the best consumer GPU, which meant that the gap between the 3080 and an eventual 3080 Ti wouldn't be as great, because at most the gap would be a product of the differences in silicon quality and the things NVIDIA did to the GPU due to the silicon quality (such as disabling cores).\n\nThe best they could do is give you a better binned version of the same GPU, with better silicon quality and less cores being disabled, which at best would give you comparable performance to a 3090 (as they don't want to encroach on the 3090's market segment, and if you go beyond a 3090, you're heading into Quadro and Tesla GPU territory), and, lo and behold, the 3080 Ti delivers just that, comparable performance to a 3090.\n*****\nAs for the amount of VRAM, this is the result of a difficult choice they had to make. VRAM is connected to the GPU via the memory bus, and the memory bus has a specific width that determines how much data can move through it at the same time (and in turn the bandwidth available to the GPU). As a result, this also affects how many memory modules can be connected to the GPU, since the more memory modules you connect, the wider the memory bus needs to be.\n\nFrom what I can tell, Micron's GDDR6(X) modules seem to connect to the bus with 32 bits per module, so to figure out how many modules can be connected in total to a memory bus, you just take the memory bus width and divide it by 32. Or, if you want to figure out how wide the memory bus needs to be to fit a number of memory modules, you take the amount of modules you want to use and multiply it by 32. Worth mentioning that Micron's GDDR6(X) modules also seem to come in 1GB- and 2GB-per-module capacities, at least based on all released Ampere cards (we know Micron has 1GB- and 2GB-per-module capacities, as people have hard-modded cards to increase the total VRAM by replacing the existing 1GB modules with new 2GB modules).\n\nSo, lets use this to figure out a few things.\n\nFirst, lets figure out how many modules the 3080 and 3090 both use. We know the 3080 has a 320-bit memory bus, and so if we divide that by 32, we get 10 modules, and since the 3080 has 10GBs of VRAM, it must use 1GB modules. Likewise, we know the 3090 has a 384-bit memory bus, and so if we divide that by 32, we get 12 modules, *however*, since the 3090 has *24GBs* of VRAM, it must use 2GB modules.\n\nNow, lets figure out how large the bus would need to be to support, say, 16GB's of VRAM. If we use 1GB modules, then we'd need 16 modules in total, and so if we multiply that by 32, it would need a *512-bit memory bus*. That's a bit excessive, and 16 modules is a **lot** to manage as the 3090 only has 12 and even it's struggling to keep its 12 modules cool, so maybe lets use 2GB modules. With 2GB modules, we'd need only 8 modules in total, and so if we multiply that by 32, we'd need a *256-bit memory bus*. That's **way** to narrow for a GPU as fast as the 3090's, and will significantly reduce the memory bandwidth available to the GPU, hurting performance in scenarios bound by memory transfers (which happens frequently in graphics).\n\nTherein lies the problem. To support 16GB's of VRAM, we'd need to either use an unreasonable amount of memory modules, making them hard to cool, or we'd need to significantly reduce the width of our memory bus, hurting bandwidth. That's just not acceptable for such a high end card, and so 16GB's of VRAM just isn't going to cut it. Which leaves us with either the 3080's memory configuration, or the 3090's memory configuration.\n\nIf we go the 3080's configuration, we could have 20GB's of VRAM on a 320-bit bus by simply swapping out the 1GB modules for 2GB modules, but this trades bandwidth for capacity. If we go the 3090's configuration, we could have 12GB's of VRAM on a 384-bit bus by simply swapping out the 2GB modules for 1GB modules, but this trades capacity for bandwidth. So, which one would cause a bottleneck more often.\n\nWell, when you actually look into things, bandwidth actually ends up being the biggest bottleneck, especially with a fast GPU that can finish a computation before it needs to wait for the memory subsystem to move some data to and from VRAM.\n\nBandwidth becomes the bottleneck whenever you're reading data from VRAM (ie reading data from a texture, reading data from some buffer, etc), as well as whenever you're writing data to VRAM (ie writing data to a texture, writing data to some buffer, etc), while capacity only really becomes the bottleneck whenever you've ran out of VRAM, which doesn't happen all that often, and is far easier to manage, especially with DirectX 12 or Vulkan which literally allow you to control what is stored in VRAM at a given point in time.\n\nThe 3080 only really sees VRAM being maxed out on a select few titles that *allocate* a ton of VRAM (ie they ask for some VRAM to be owned by them ahead of time, so that they can freely move data in and out of VRAM without needing to ask for more), and the 3090 basically never sees it's VRAM being maxed out at all. Even with the 3080's VRAM being maxed out, games can still allocate less at a given time and just move data in and out of VRAM more often rather than keeping data in VRAM for when it's used next, and there are techniques that are being researched to reduce the amount of VRAM used by games (visibility buffers is a big one for high resolutions).\n\nBecause of this, it just makes no sense to give the 3080 Ti double the 3080's capacity while keeping it on the same bus, especially when you consider that the 3080 Ti has a faster GPU. It makes more sense to give the 3090 half the 3090's capacity as well as the 3090's 384-bit bus, giving it more bandwidth to work with.",
      "imagine thinking loser scalpers, panic buying gamers and low iq miners wont buy it",
      "I assume that comment was made in jest. Pretty much all 3080s will still resell for higher than MSRP. However, the relatively small performance gain at almost double the price just seems like a dumb trade off.",
      "$1200 isn't even the MSRP, that's the FE's MSRP. The average board partner (AIB) card (in a perfect market with no inflated prices) will add at least 15% because it's more expensive for them (they have to buy the chips from NVIDIA). This added cost can be as high as 30% for high-end models and 50% for ultra high-end binned models and limited edition cards. So the complete bill for a 3080 Ti will be:\n\n- $1200 (MSRP)\n\n- $150 (average AIB tax)\n\n- $1000 (shortage tax)\n\n- $200 (Euro tax)\n\nFinal price = 2350 USD for Americans, 2750 for Western Europeans. We'll see in two days, but I'm counting on these prices. This is for an average board partner model. Higher-end models (Strix, Suprim X etc.) will cost more. People in developing countries can add another $1000, lets call that the \"low supply priority tax\".",
      "You guys are completely missing a true tragedy here. Nvidia is slowly \"rebuilding\" higher base price for whole lineup so that the prices of 4000 series won't look that shoking high. In other words waiting it out won't help, the absolute bargain that was 3080 for $700 won't happen again in foreseeable future.",
      "Looks like you were correct",
      "Lmao, I know. I’m not selling anything anytime soon. I quite enjoy using my 3080 for gaming :p",
      "This is straight bullshit, fuck this"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "high",
    "matched_keywords": [
      "rtx 3080",
      "3080",
      "3080 ti",
      "rtx 3080 ti"
    ],
    "title": "Rtx 3080 ti vs rtx 4070 super",
    "selftext": "I have EVGA RTX 3080 TI FTW3 ULTRA, Should I replace it with zotac twin edge rtx 4070 super? And whats the difference between them and which is better? \nOther specs are\nI5 13400\nMsi b760m ddr4\n32gb adata 3200mhz\n1tb nvme \nAseye 6 heat pipes cooler\n1000w fsp hydro g 80+ gold \nCooler master mb500",
    "comments": [
      "Not a worthwhile upgrade, wait till the 6000 series imo",
      "I’ve watched several benchmark comparison videos between the 3080 Ti and 4070S, and they seem to be very close, +/- 5%. The 4070 draws less power and has frame gen, but unless that is a free replacement, I don’t think spending money for roughly the same to marginally better performance is worth it.",
      "Wait for the 5000 series.The 4070 Super performs around the same but draws less power,and has frame gen, so it's certainly not worth it",
      "So I was in the same boat. I figured I'd sell off my 3080ti and get a 4070 Super. Then, I discovered that they're pretty much on par with each other and will trade places depending on the test/graph/scenario. \n\nSelling my 3080 AND my 3080ti was the dumbest PC move I've made. Yes, I had both. Yes, they're both still very sufficient for gaming in 2024, and no - upgrading from 3080/ti to 4070/s/ti is NOT worth the additional cost. \n\nI realized that there was no going back, and I sure as hell wasn't about to replace my \"old\" GPU with the same performance for an extra 200 + tax. I also was not about to drop 2k on a graphics card. At the current place for 3080/ti owners, the only true \"upgrade\" is the 4080. I said screw it, and paid $550 to jump from 3080ti to 4080S. The 4080 super is amazing, but here's the thing. \n\nI was already gaming at 4k, and now I'm gaming at 4k. It was smooth before, and it's smooth now. Everything is maxed out now. Before, I had to take a few things from ultra settings to high, but in terms of noticible difference - the $550 missing from my bank account is more noticeable than anything. \n\nIf you're truly looking at an upgrade rather than a sidegrade, the only thing that makes sense with regard to value for money is truly the 4080 Super.",
      "4070 Super is on par with the 3090 and draws much less power. So yes, it's better than a 3080 Ti with and without Frame Generation which is frame interpolation and not \"Fake Frames\" like how some people tend to downplay. \n\nThe FSR3 Frame Gen will also give your 3080 Ti FPS boost.\n\nHaving said that if you are getting good money for your 3080 and you spend like an extra $200 for the 4070 Super then yes get it and keep it for 3 years or something",
      "Well, the OP asked \"particularly ray tracing and dlss\". In those scenarios there are massive difference. Play a game like Alan Wake 2 and it's instantly clear that there's a performance difference on max ray tracing (path tracing on). I was able to play 4k DLSS ultra performance (720p) with PT on, but the GPU can't handle new gen RT. At the same time, RTX 4070 Super can give way better performance, run 30% lower wattage, and get better frame generation out of the box. \n\nIf the upgrade is cheap (less than $100), I would instantly upgrade. Super easy to sell forward when the new gen GPUs are released and the resale value stays higher for longer + 3 year warranty. My 3080 Ti has lost value insanely fast and have no warranty. If there are any issues, no more repairs and the card just run so high wattage. It would be ok if the GPU had all the features and new cores, but it's a letdown when need to use latest graphical options. I would sell the card, because now it still has ok value on used market and cheap to upgrade.",
      "There is no difference apart from framegen,it's a few fps faster at best",
      "uses ai to make 'fake frames' using technology called frame interpolation (kind of fill in gaps between frames imagine an object on the left in frame 1 and it in the right in frame 2 itll create a frame with it in the middle to make its smoother) that doubles your fps but it introduces more input latency so not good for multiplayer games honestly amds new fsr3 will give you it without having to upgrade you can use dlss to fsr or lukefz mods to add it into some unsupported games already. Some other games have it already and you can try it out, if nvidia reflex is available use it to decrease input latency",
      "I have the same card EVGA RTX 3080 TI FTW3 ULTRA, this is my 3rd RMA change. So fed up thinking of going with Nvidia OEM cards this time",
      "The 3080 Ti sells for more than the 4070 Super costs, so clean your 3080 Ti and sell it and buy the super for cheaper.",
      "For me, my screen would randomly pixelate and go all black. I only had it for a year ish. Thankfully the replacement has had no issues",
      "This is not correct at all. The difference is RT and Tensor gen 3 cores and their performance. The 4070 Super is way more powerful on RT and AI related tasks. This is why I personally wanted to upgrade 3080 Ti to 4080 Super. I would have even changed/upgraded to 4070 Super instantly if it was cheap upgrade (new 3 year warranty, new hardware, no worries, resell value, lower wattage, less heat, etc.). I decided to upgrade 4080S to get way more CUDA, Tensor and RT performance for 4k gaming + 16GB VRAM.\n\nThe raster performance might be similar, but the difference comes clear when playing path tracing titles and things that need the AI workload + DLSS 3. RTX 3080 Ti is a great GPU, but especially RT + Tensor performance is massive. RTX 3080 Ti and 4070S are totally different cards. TDP 350 vs 220W, 8 nm vs 5 nm, gen 2 vs gen 3 cores, L2 cache 6MB vs 48MB, transistors 28B vs 36B, etc.  Real generation leap forward, even tho the GPU raster performance might look about the same.",
      "Thanks, brotha, I am not upgrading yet. I will wait for 50 series, and I will upgrade when i have a budget for upgrading processor also",
      "That’s really well put. A sidegrade. Love that. If you play heavy games like cyberpunk the frame gen might give you a lot more of a boost, but in terms of raw performance you’re right. A small bump like that really isn’t worth it. The frame gen also depends what FPS you had before turning it on. In 1440p I get a roughly 50fps bump with frame gen (90 to 140) but in 4K depending on the settings I can be like 40-50fps and turning on frame gen doesn’t add anything and turns the game into a stuttery, ghosty mess. If I had a 3080ti I’d probably go with a 4090 and nothing less. I came from a 3070 to a 4080 and I’m thrilled, my FPS doubled in 1440p.",
      "I really can't explain it,so hopefully someone who can will be able to.I have been using framegen on my 3080ti(DLSS upscaling with AMD framegen) and I'm not sure if it feels better or not",
      "Quality is quite good unless you observe it through a microscope",
      "For things like path tracing, there are no options for slight changes. It's a lighting overhaul or not. That's a massive difference in visuals, and last gen GPUs don't have proper power to handle this.\n\nPS. I personally loved the path tracing so much on Alan Wake 2 that I rather played the game 4k DLSS ultra performance. Great experience, ok 4k OLED screen, but 4070 Super would have offered me far superior performance. It's not even a close one. The same goes for games like Cyberpunk with all the new DLSS 3.5 features. I get that there are people who are fine by turning off features, but I'm just explaining why these matter so much because I do use them on last gen hardware.\n\n  \nEdit. There's even more AI run features like DLDSR + DLSS. I would have to test these and how it affects the performance on 30xx and 40xx GPUs. DLDSR 2.25x + performance is my default choice for 1440p games and it uses Tensor cores to double scale the image. My bet is that 40xx GPUs have better AI scaling performance with new gen cores. My 3080 Ti just can't handle this when using new features. Not even ultra performance.",
      "Right bro thanks 😊",
      "Honestly I'm waiting on an RMA on my 3080 ti which I've used for light gaming for barely 2 years, and after reading countless stories about other having to RMA their 3080 ti, I'm convinced this card is made to break. This is not company specific either, I've read people with Gigabyte, Asus, MSI, etc who have had problems with their 3080 ti. They are full on replacing mine because it couldn't even be repaired somehow? When it gets returned to me, I'll be selling it on eBay and using the funds to buy a 4070 super or super ti.",
      "Not worth it"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "high",
    "matched_keywords": [
      "rtx 3080",
      "3080",
      "3080 ti",
      "rtx 3080 ti"
    ],
    "title": "Igor's Lab: GeForce RTX 3080 Ti will get a new chip with pre-installed hash brake shortly before launch, the card is already in mass production.",
    "selftext": "",
    "comments": [
      "I would gladly trade my mining-capable 3080 for a mining-gimped 3080 Ti.",
      "And it's gone",
      "Eh I like I have the opportunity to pay back my entire GPU through periodic mining. I think I'ts about half way paid off by now",
      "I don't like these baked in hash brakes because it doesn't do anything to improve availability at all, and it limits what I can do with the card if I manage to get one.",
      "Miners aren't passing on this *at all.* They're merely having it mine anything other than Eth, which is still wildly profitable.\n\nHeck, it's automated if you use Nicehash or Cudo Miner.",
      "Long term this is not good. Short term there may be a slight bump in accessibility for the gamers. But long term this will split their production between mining gpus and gaming gpus. Overall supply of gaming gpus will go down.",
      ">because it doesn't do anything to improve availability at all\n\nSecondhand prices for the 3060 went up about $200 after the mining driver leaked.",
      "Looks like [kopite7kimi](https://twitter.com/kopite7kimi/status/1382618361725472768) was right again (as always).\n\n*edit: shit I made a mistake, the article says \"ready for mass production\", that doesn't necessarily mean it already is in production, my mistake.*",
      "Um, correct me if I'm wrong, but if all the miners pass on the limited number of cards available, the rest of us will have better chances for one, no? And: the miners being out of the equation would mean a more relaxed demand overall, which would be less enticing for scalpers to do their thing, I think.",
      "It will be one way. Gamers won’t be able to use mining gpu for gaming. On the whole gamers lose.",
      "Nicehash is easier but has higher fees. Ethereum seems to be most profitable right now. I just use TRex but there are a few options out there.",
      "Because blanket cutting the compute power in half probably isn't something they want to do.  It'd have to be targeted nerf.",
      "Did you actually watch the video? It was due to poorly maintained thermals. The card throttled like crazy. The silicon performs exactly the same otherwise. I should know, my 1080 Ti is over 4 years old and been mining a plenty, and my game perf is exactly the same as the day I bought it.",
      "Always has been 🔫👨‍🚀",
      "I use nicehash mine when I'm not gaming.",
      "Thats actually brilliant! So nvidia is helping the big mining outfits by doing this. Individuals will be less inclined to solder out the chip, so the big mining outfits have less competition. Its a win for everyone except gamers.",
      "They made plenty, there are more of them in the steam survey than the 2080 Ti  \n [Steam Hardware & Software Survey (steampowered.com)](https://store.steampowered.com/hwsurvey/Steam-Hardware-Software-Survey-Welcome-to-Steam) \n\nAnd that's not counting all the ones in mining rigs without steam.",
      "Its pure marketing. The idea that a company would try to purposefully reduce demand by crippling their products is just unrealistic and just bad business. \n\nNot to mention that miners routinely modify their cards, so if these cards have otherwise good hash performance they'll solder out the chip or find a way to route around it. This is just marketing to make nvidia look good to their more numerable \"consumer\" base while still satisfying their bread and butter clients.",
      "Reports say TSMC won't be able to provide enough chips to cover demand until 2023, so coin crashing or not, the situation is dire ffor the upcoming months.",
      "It was really hated at launch because price ($1500) and only 10% faster than the 3080.\n\nNow it seems a good deal comparing to some 3080s lol"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "high",
    "matched_keywords": [
      "rtx 3080",
      "3080",
      "3080 ti",
      "rtx 3080 ti"
    ],
    "title": "Rx 6800 to a rtx 3080 ti",
    "selftext": "I was on FB marketplace and was making a deal with this guy. Would 150 dollars and my Rx 6800 (not xt) be a fair trade for a 3080 ti.",
    "comments": [
      "Nvidia unfortunately is worse right now past 566.36",
      "Market value wise, yes",
      "Depends on what you want. If RT and DLSS is important then yes. I have the 6800 and I love it. But I don’t use upscaling really and I don’t care about RT. It’s a good deal if you want a 3080ti.",
      "Thanks for the advice, I think I'm gonna take it",
      "What is wrong with them?",
      "I got a 3080 ti and it’s pretty good, if you’re looking at playing ray tracing games it’s okay, but it’s starting to show its age. If you’re not planning on playing ray tracing games then you’ll be good for a couple more years depending on what you play.",
      "Also wanted to chime in, zero driver issues on 3080. No black screens, updated drivers two days ago. Pretty sure that’s just the new stuff. Maybe I’m just lucky",
      "Damn that really sucks, either way a fresh GPU is always fun to mess with.",
      "Also I'm just so tired of amd drivers"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "high",
    "matched_keywords": [
      "rtx 3080",
      "3080",
      "3080 ti",
      "rtx 3080 ti"
    ],
    "title": "i9-12900k + RTX 3080 ti power supply recommendations",
    "selftext": "I'm putting together a build and I am not sure what power supply to get, I'll mostly be using the machine for CAD and 3D rendering meaning mostly a multi core workload and the 12900k can consume up to 400 watts under an all core load, the recommended psu for a 3080 ti is 750 watts but I'm not sure how if that still applies with such a power hungry cpu.",
    "comments": [
      "It's when you overclock your gaming chair when issues arise.",
      "An 850W quality PSU should be fine for that system, but if you plan to upgrade in the future you might want to go 1000W since the trend is increasing CPU/GPU power consumption. Though in 2 generations time ATX12VO PSUs might be the thing to get even for gaming PCs so.... If this was my system I'd actually get a 850W for the cost savings.\n\nThe people recommending 1200-1600w PSUs here must like flushing money down the toilet.",
      "10850K overclocked to 5Ghz and @MSI 3080. 750 watt seasonic gx750. never had an issue.",
      "> 12900k is the least efficient cpu ever made\n\nobjectively untrue, just compare it to an FX 9590 using 360 watts while doing magnitudes less work than a 12900k\n\nFor gaming, there's really no point in going past the PL1 power setting for the 12900k, which is a 125 watt limit.",
      "I'd say 850W or 1kW, gold rated or better would be ideal.",
      "My 11900k & 3080 Ti OC run on 850 bronze with no issues.",
      "A 1000 watt power supply will be perfectly fine for that build, yet depending on your upgrade schedule you might want to move to a slightly higher power supply around 1200 watts if the rumors of Lovelace power consumption is true.  I would personally stick with any Corsair or EVGA power supply.",
      "I'm fully aware of the efficiency curves of PSUs. I'm also aware that the times you are producing peak loads on the CPU and GPU (especially at the same time) are usually few and far between. You'll be outside the optimal efficiency range far less than you seem to think. And even then efficiency drops from like 88% at the most optimal to like 85% at full load, which is not gonna effect your power bill to any meaningful degree.\n\nAnd actually, if you're buying an overkill PSU it's probably *less* efficient when you're idling, which is the thing your PC does more than anything. Ex. [https://www.silverstonetek.com/images/tech/WB10-005/10005-1.jpg](https://www.silverstonetek.com/images/tech/WB10-005/10005-1.jpg)\n\nTo top it off, the price increases for 1200W+ PSUs compared to the more mainstream 750/850Ws are often quite substantial. Not worth it at all. Getting an overkill PSUs **is** flushing your money down the toilet.\n\nAs for noise, I can't remember the last time I heard my proportionally sized PSU. If you're running peak loads your other fans are gonna overpower the relatively quiet PSU fan anyway (thought I guess there is a tiny amount of additional noise added to the total noise).",
      "Of course, I’m pointing out the 12900k isn’t the most inefficient processor ever made. Not by a long shot.",
      "You shouldn't be, unless you have a poor PSU.\n\nGold is not an indicator of quality.",
      "Wow, you pulled out all your credentials and wrote a comment full of huff and puff to counter the *exact opposite point of what I made*. Which is that a PSUs wattage **isn't** indicative of the PSU general quality.\n\nI never said you shouldn't buy a quality PSU (in fact I said the opposite), but that you don't need one rated for excessively high wattage. While your 1000w suggestion is reasonable, a lot of commenters have been suggesting PSUs in the 1200-1600w range with no understanding that wattage is required for this system not any mention of ensuring general quality and effectiveness of the PSU.\n\nThat being said, if there is any correlation between wattage and general quality it is that most of the terrible quality shitboxes tend to be found in the lower range and higher wattage PSUs tend to be of higher quality.\n\nYes a 1000w PSU might be a good idea for futureproofing, which I also recommended in another comment, but an 850w will handle that system just fine as it is. And by the time he upgrades ATX12VO-PSUs might be making their introduction, or he might just sell the whole system PSU included.",
      "I always go with 850W because then I can heat my living room.",
      "Isn't alder lakes architecture brand new, with no similarities to the last many generations?\n\nI get it it's funny to make fun of intel, but what you've just said is untrue.",
      "That...doesn't depend on your PSU though?\n\nThe overall heat exhausted into your room depends on how much power your components are drawing, not on your PSU's max wattage. There might be a *slight* difference on the order of a few watts due to you loading an 850W closer to its max capacity and therefore being less efficient, but it's really nothing to write home about and would be vastly overshadowed by even something like moving down from Platinum to Gold.\n\nA 1000W, 850W, or even a 700W PSU powering a 700W system will heat a room more or less the same, negligible efficiency differences aside.",
      "Psu shouldn’t fail from too much power being requested, the pc would just turn off. Sounds like you had a faulty psu. But yes 850w should be good. Im on a 10900k and 3090 using an old 850w evga g2. Been running fine no issues",
      "12900K consumes much more power than 5950X at full load, but the CPU won't work at full load in gaming. 12900K consumes less power than 5950X in most games actually.\r  \nhttps://www.youtube.com/watch?v=13Mw4GJs-uQ",
      "Least inefficient 16 core CPU? Ok dude make a comment when you know what your talking about.",
      "Does your hoover work?\n\nhairdryer?\n\nIf so, don't worry about it.",
      "Yeah I think he needs to re-read your first comment lmao",
      "12900k is awesome, just like the 5950x. These are chips for a certain audience.\n\nFor me, my heart will always fall for ryzen 7 and I 7. Just what I need for my gaming."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "high",
    "matched_keywords": [
      "rtx 3080",
      "3080"
    ],
    "title": "GeForce RTX 3080 & 3090 rumored TimeSpy benchmarks compared to RTX 2080 & 2080 Ti",
    "selftext": "Comparing the rumored TimeSpy results of Ampere with older Turing results, the GeForce RTX 3080 is +35-36% faster at 3DMark TimeSpy Extreme (GPU) than the GeForce RTX 2080 Ti (FE), as well +74-75% faster than the GeForce RTX 2080 (FE). The GeForce RTX 3090 looks like +53-56% faster than the GeForce RTX 2080 Ti (FE). The performance difference between the two Ampere cards is just +14-15%, which is very much less than between GeForce RTX 2080 & 2080 Ti (+29%).\n\nPlease keep in mind, that these are just rumored benchmarks. As well, count TimeSpy as probably a best-case - so the performance gain at real games is maybe slightly less good.\n\n&nbsp;|Hardware|TimeSpy Extreme (GPU)|Source(s)\n|:--|:--:|:--:|:--:|\n**GeForce RTX 3090**|nVidia Ampere, probably GA102, 82 SM @ 384 Bit GDDR6|**\"almost\" 10000**|[Kopite7kimi](https://twitter.com/kopite7kimi/status/1288811296435998723)\n**GeForce RTX 3080**|nVidia Ampere, probably GA102, 68 SM @ 320 Bit GDDR6|**\"almost\" 8600**|[Kopite7kimi](https://twitter.com/kopite7kimi/status/1289148415293628417)\n**GeForce RTX 2080 Ti FE**|nVidia Turing, TU102, 68 SM @ 352 Bit GDDR6|**Ø 6333**|[HWLuxx](https://www.hardwareluxx.de/index.php/artikel/hardware/grafikkarten/47493-geforce-rtx-2080-ti-von-asus-und-msi-im-test.html?start=7) & [OC3D](https://www.overclock3d.net/reviews/gpu_displays/nvidia_rtx_2080_and_rtx_2080_ti_review/25)\n**GeForce RTX 2080 FE**|nVidia Turing, TU104, 46 SM @ 256 Bit GDDR6|**Ø 4912**|[HWLuxx](https://www.hardwareluxx.de/index.php/artikel/hardware/grafikkarten/47493-geforce-rtx-2080-ti-von-asus-und-msi-im-test.html?start=7) & [OC3D](https://www.overclock3d.net/reviews/gpu_displays/nvidia_rtx_2080_and_rtx_2080_ti_review/25)\n\nSource: [3DCenter.org](https://www.3dcenter.org/news/geruechtekueche-erste-grobe-timespy-werte-zu-geforce-rtx-3080-3090-aufgetaucht)",
    "comments": [
      "If a 3090 gives us 50% over 2080 Ti, then that’s amazing. If it MSRPs for $1200+ then that’s not as amazing.",
      "knowing nvidia they will be expensive",
      "Depends what you call expensive. I would call 700-800 dollars expensive lol",
      "I spent tons of money for PC and I have the money for 2 2080tis but I want to feel smart or not being scammed when buying.\n\nIf these gpus are over the thousand euros again i feel i keep my 1080ti until it doens't work anymore.\n\nthis practice of gpus being so expensive pisses me of so bad even if i can afford that.",
      "Absolute the maximum price i'd paid for a top tiered card.\n\n3080ti and 3090 sounds impressive and all but we cant let nvidia get away from charging us an arm and a leg everytime.\n\nThat being said, if the 3090 has no competition from Amd then nvidia will a justification, good or bad...",
      "And why would that ever happen? This slippery slope fallacy is stupid.",
      "So, is the 3090 going to be the new Ti?\nOr is this the new titan? Because every article gives it another name and I'm completely lost now lol.",
      "Which is insane because if they were already struggling to sell Turing at the pre-Super price, it makes no sense to sell them higher as sales figure will collapse.\n\nThese companies are not stupid.",
      "Actually it doesnt matter how good the new carda are if a 3080 would cost like 1000 and a 3080ti or so 1500+ imo. Same for 3070 and 3060 if the cost much more then last gen...",
      "If Nvidia doesn't screw us, the 3060 should be somewhere around 2080 or even 2080S levels. The 1060 was as fast as the 980 and the 2060 was as fast as the 1080, so I don't see why they won't keep doing it the same way. Pricing is the most important thing though, if the 3060 is <300$ then I might upgrade, if it is around 400$ territory, then I'm switching to AMD. Midrange cards shouldn't cost an arm and a leg, the majority of gamers buy x60 or x70 cards.",
      "[Inflation adjusted price of GTX 8800 was over $1k and that was in 2007 or so](https://hardforum.com/data/attachment-files/2019/12/263966_upload_2019-12-27_21-7-53.png)\n\nNot to mention Titan was $1000 (not inflation adjusted) back in what? 2013?\n\nTitan was spinned off GeForce this gen so something has to fill that and Ti is basically the new Titan.\n\nSo the $1k price range has precedence and looking at the lower sales figure before Super refresh, we're clearly at the limit of what consumer would be paying.\n\nAnything higher, though, is unsustainable for sales and unprecedented.",
      "My speculation is that it might fall in line with what both AMD and Nvidia love to do: insert in-between models further down the line.\n\nFor example they could release 3080 and 3090 first, then next year they add a 3080 Ti (or Super if they want to keep that naming) that is somewhere between the 3080 and 3090. 3080/3090 sells to early adopters, 3080 Ti/Super to those who waited for a better price/performance ratio.\n\nI don't think 3090 will be the equivalent of a Titan, which is the full-fledged chip with low yields. But it could replace the Ti segment as the top tier card until the 4000 series in a few years. Considering the 2080 Ti was significantly faster than 2080/2080S they might want to differentiate the top end consumer card further to make it appear extra special as non-tech enthusiasts are most likely going to be confused by the 2080/2080S/2080 Ti nomenclature as is.",
      "If they are calling it a 3090 it will be expensive, simple as that. No reason to change the name if they aren't raising the price.",
      "the 3090 is unlikely. it's been the rumour every time, never panned out. besides they can't price cards higher, Turing was already too expensive (that's straight from jensen), and we are in an economic downturn with millions out of jobs. prices *will* be lower.",
      "These numbers look pretty good if true, fingers crossed for a decent price!",
      "I dont think you get his point",
      "Because everyone wants big Navi to win. \n\nElse they think the 3080ti will cost 4000 and the 3080 will cost 2000",
      "We always knew Ampere would be better and no news/leaks etc have shown anything different . The halo product will be X faster, but pricing likely will be out of reach for most folks who have mere mortal wallets.\n\nIt's the next tier or 2 down that I'm waiting fervently for, the 2070S/2080S replacements -  I'm just hoping it's not a case of \"Here's the 2080S direct replacement, it's 20% faster but costs 50% more. Enjoy!\"",
      "Actually the 50% better is from Nvidia sources, i.e what Nvidia assumes big Navi could be at best, and what they want to counter to maintain the top tier crown.",
      "2000 $? As far i remember milions people lost job in last weeks, good luck with this price if ps5 will be around 400-700. If you right than Im going to cry in corner"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "high",
    "matched_keywords": [
      "rtx 3080",
      "3080",
      "3080 ti",
      "rtx 3080 ti"
    ],
    "title": "Rumor - RTX 3080 Ti same FP32 count as 3090, 10496 FP32, the same MEM speed and TGP as 3080",
    "selftext": "",
    "comments": [
      "I won't be surprised if this gets priced at $999 to go head to head with the 6900 XT.",
      "and we are again at rtx 2080ti launch price oof",
      "week1: 3080 Ti CONFIRMED!\n\nweek2: 3080 Ti CANCELED!\n\nweek3: 3080 Ti CONFIRMED!\n\nweek4: 3080 Ti CANCELED!",
      "kind of, didn't stop them from marketing it as a \"8k gaming\" card",
      "This would put the 3080ti at roughly the same performance level as the 3090 for gaming. nvidia is in a tough situation now.",
      "\"The GeForce RTX™ 3090 is a big ferocious GPU (BFGPU) with TITAN class performance. It’s powered by Ampere—NVIDIA’s 2nd gen RTX architecture—doubling down on ray tracing and AI performance with enhanced Ray Tracing (RT) Cores, Tensor Cores, and new streaming multiprocessors. Plus, it features a staggering 24 GB of G6X memory, **all to deliver the ultimate gaming experience**.\" \n\n&#x200B;\n\nTaken from the product description on Nvidia's site.",
      "They don’t have many other options to be honest. And they have to price it at no more than $999. Otherwise, what’s the point?",
      "Slap in the face to the people that bought 3080's?  What about the people that bought 3090's lol",
      "Frankly, I'd expect $1,199 again like the 2080 Ti.",
      "Personally I am waiting price and value wars at 3070 Ti level, may get a RX6800/RX6800 or RTX 3070Ti 16GB / 3080 10GB with Game Bundles.   \nThe 3070 is out of the question because of 8GB of VRAM for Ultrawide 1440p.",
      "There would be no point to not get the 3090 at that price point.",
      "There is always an early adopter tax, and any new product is always a slap to the last.  \n\n\nNvidia HAD to respond to the 16GB on all of the upcoming AMD parts, even though that's not available yet people didn't want to invest in 'only' 10GB.",
      "Yeah, if this isn't available until March or so, I will 100% be going with a 6800 XT.",
      "Would be interested in this but what's a realistic turnaround for a product like this, 3 months? 4?  More?  Cant wait that long unless 6800XT/6900XT have the same supply issues as 3080's, which frankly I'm skeptical will be the case.",
      "The 3090 shouldn't exist. It should have just been a 3080 Ti with 20GB VRAM.",
      "> unless 6800XT/6900XT have the same supply issues as 3080\n\ni would be surprised if it hasn't supply issues, maybe initial stock will be bigger than nvidia's but then you'll be stuck waiting for cards on sale for weeks\n\ndemand for gpus right now is way too big for both companies, and the longer 3080s are out of stock the more this affects amd",
      "Its not feasible. 12gb wouldnt be enough to go up against the 6900xt so the only other option was 320 bit bus and either 10 or 20gb and 10 is way too little so the only option was 20gb with 3090 performance to match the 6900xt.",
      "If they release a 20GB 3080 Ti against a 6900XT at that price, then their 3090 will be dead. They won't do it.",
      "Dear Nvidia, I know you can overprice this card and people will still buy it, but please, don't go over $1000.",
      "Rumour - Nvidia to release another card you can't buy"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "high",
    "matched_keywords": [
      "rtx 3080",
      "3080",
      "3080 ti",
      "rtx 3080 ti"
    ],
    "title": "GeForce RTX 3080 Ti Review Megathread",
    "selftext": "# GeForce RTX 3080 Ti reviews are up.\n\n&#x200B;\n\n[Image Link: GeForce RTX 3080 Ti Founders Edition](https://preview.redd.it/7z49errd0v271.jpg?width=2560&format=pjpg&auto=webp&s=1753ed99343e776afbb08bf125f182f9c35eaf48)\n\n# Reminder: Do NOT buy from 3rd Party Marketplace Seller on Ebay/Amazon/Newegg (unless you want to pay more). Assume all the 3rd party sellers are scalping. If it's not being sold by the actual retailer (e.g. Amazon selling on Amazon.com or Newegg selling on Newegg.com) then you should treat the product as sold out and wait.\n\n# Below is the compilation of all the reviews that have been posted so far. I will be updating this continuously throughout the day with the conclusion of each publications and any new review links. This will be sorted alphabetically.\n\n# Written Articles\n\n# [Arstechnica](https://arstechnica.com/gadgets/2021/06/nvidia-rtx-3080-ti-review-3090s-power-for-300-less-theoretically/)\n\n>Within the vacuum of comparisons to other cards and the $1,199 MSRP, the RTX 3080 Ti is a heckuva GPU. It's not the \"wow, that's the right price\" stunner of the 3080's original $699 MSRP, but it's also not the clearly overpriced [$1,199 MSRP originally attached to 2018's RTX 2080 Ti](https://arstechnica.com/gadgets/2018/09/nvidia-rtx-2080-and-2080-ti-review-a-tale-of-two-very-expensive-graphics-cards/). If all of these cards existed at retail at their listed prices, I'd say the 3080 Ti is priced for a certain kind of PC power user without gouging buyers 3090-style, while the 3080 and RX 6800XT make more sense on a power-per-dollar basis. (Will the upcoming 3070 Ti, launching on June 10 for $599, shake *that* $600-700 range up significantly? Stay tuned.)  \n>  \n>If you can safely go to a store at this point in 2021, you *might* have a shot at lining up and buying one this week at MSRP, since brick-and-mortar retailers have more incentive to get you into their doors and limit purchases to one per customer. Recent card launches have seen continued movement in that direction. No retailer benefits from bot exploitation.  \n>  \n>Yet Nvidia has been coy about loudly addressing the reality of GPU availability, and at this point, that sucks. Maybe they're in an uncomfortable position as a publicly traded company and can't admit what a mess GPU sales have become in the past year-plus, and maybe they'd rather dump cards into an unregulated market, watch them all sell out, and report the good news to shareholders. There's also the reality of third-party vendors, who produce the majority of Nvidia GPUs, pricing the 3080 Ti however they see fit. Nvidia declined to offer a list of how its partner vendors were pricing their 3080 Ti models ahead of launch.  \n>  \n>So \"$1,199\" doesn't really mean $1,199. And while I can slap performance benchmarks onto charts and break down the ins and outs of graphical performance, I am not nearly as well positioned to do the same thorough evaluation with the traveling fair funhouse that is the modern GPU economy. If you've made it this far in my review, you're clearly invested in high-end computing and in the dream of ever buying into it at a reasonable price. In that journey, dear reader, I wish you all of the luck.\n\n# [Babeltechreviews](https://babeltechreviews.com/the-rtx-3080-ti-founders-edition-benchmarked-with-25-games/)\n\n>The $1199 RTX 3080 Ti FE performed admirably performance-wise compared to the RTX 3090 which is still the fastest gaming card in the world that released at $1499. Therefore at less than 5% slower, the RTX 3080 Ti is a solid upgrade over the RTX 2080 Ti that also launched at $1199 even though we were [originally hesitant](https://babeltechreviews.com/benchmarking_turing_rtx/) to recommend the upgrade to a RTX 2080 Ti nearly three years ago based on its value to performance.  \n>  \n>If a gaming enthusiast wants a very fast card that almost matches the RTX 3090 FE, it is an excellent card for 4K or 1440P gaming.\n\n# [Digital Foundry Article](https://www.eurogamer.net/articles/digitalfoundry-2021-nvidia-geforce-rtx-3080-ti-review)\n\n# Digital Foundry Video - TBD\n\n>There are few surprises really with the RTX 3080 Ti - it treads the path of prior 'Ti' releases, this time nipping at the heels of an xx90 spec that would have been called a Titan in the last generation. The 3080 Ti loses a few shaders and has only half the RAM, but still boasts broadly equivalent gaming performance overall. And when we say equivalent, we really mean it - the 3090 is between one to three percent faster in our tests than the 3080 Ti, which is not something you're going to notice without pulling the frame-time graphs out. There does appear to be a bit more of a 3090 advantage in ray tracing applications, however.  \n>  \n>It all comes back to the fact that the 3080 is using the exact same chip as the absolute top-end offering, something we've not seen since the GTX 780, 780 Ti and the original Titan back in 2013. That means that the gap between the RTX 3080 and its much dearer siblings is much smaller than it was between the 2080 and 2080 Ti - the circa 25 to 35 percentage point difference is more like nine to 13 percent here. It can even be lower on games with traditionally poor scalability, like Assassin's Creed Odyssey. Meanwhile, the gap in memory allocation has also narrowed - the 3GB increase seen between 10-series and 20-series xx80 cards and their Ti counterparts is now 2GB instead. It's difficult to avoid the conclusion that you're getting the lion's share of the experience with a standard 3080. For content creators working with 4K footage, video memory remains king and the RTX 3090 will remain a mainstay alongside the Titan RTX, but for straight-up gaming the RTX 3080 or RTX 3080 Ti are going to be the better choices.  \n>  \n>Ultimately, what you're left with is a halo product that has more in common with the extreme offerings of old - a relatively small amount of extra performance for a whole lot more money. If this were a sane world where GPUs could be bought at their nominal retail price, it would be fair to say that AMD would still be in the game with the RX 6900XT - the 3080 Ti is on par or faster, but really it's the ray tracing support and DLSS that go some way towards justifying the extra expense. Of course, that logic also makes the original 3080 much better value.  \n>  \n>Let's wrap up by saying this: the RTX 3070 Ti is due in just a week's time, and the specs suggest that it could be much more striking. There's a fair amount of space between the power envelopes of the RTX 3070 and 3080, and a Ti-class tweener card could do some real damage. In the here and now, the RTX 3080 Ti is indeed a gaming flagship and its performance is excellent, but the RTX 3080 does seem to be the sweet spot when looking at all three of the GA102-based video cards.\n\n# [Guru3D](https://www.guru3d.com/articles-pages/geforce-rtx-3080-ti-founder-edition-review,1.html)\n\n>The GeForce RTX 3080 Ti is second to that flagship product, blazingly fast on all fronts, and (based on that USD 1199 MSRP) is the cheaper card to get. The 12GB GD6X memory seems well balanced; we never understood the expensive 24GB on the 3090, to be brutally honest (not that I mind or don't find it awesome). Overall though, this is a small powerhouse. This card can run games at 4K quite easily with raytracing and a DLSS combo; it will serve you well at that resolution. The closest product from the competition would be the Radeon RX 6900 XT. NVIDIA, however, offers faster raytracing performance and offers you the option to put that into 6th gear with DLSS.   \n>  \n>There's no doubt about it, we like the GeForce RTX 3080 Ti, yet we're in a unique situation where chip and components shortages are slaughtering this market due to lack of availability or way too high prices. As such, we'll stick to what we review, the actual hardware, and not so much the delicate situation we're still facing. I think anyone would agree with me; we all would love to own a 3080 Ti. This is a very well-balanced enthusiast-class graphics card. Basically, it's almost a 3090 with half the memory and a few configuration tweaks. I am totally fine with the 12GB memory btw; the 24 GB on the 3090 is impressive but far-fetched and made the product extra expensive. 12GB is a notably well-balanced value in the year 2021. Performance-wise NVIDIA carved out something beautiful. You will be way up there in the highest performance regions, and even at Ultra HD, you can enable Raytracing with the combination of DLSS where applicable. Competition-wise, overall, AMD will still win in the lower resolutions thanks to their massive L3 buffer. However, in more demanding scenarios, NVIDIA takes the lead in rasterized shading performance when the resolution goes up when it comes to brute force muscle power in more demanding scenarios. NVIDIA also has faster Raytracing performance and, of course, the implementation of DLSS that will support that raytracing even further in performance. For raytracing, it's still hard to find Games with raytraced properly reflections, but that's what you should be after, and the numbers will grow in the future. The GeForce RTX 3080 Ti performs well on all fronts, performance, cooling, and acoustics as an overall package of hard- and software. The big question will remain to be availability and pricing. But as a desktop gaming graphics card, the product itself is imposing.\n\n# [Hexus](https://hexus.net/tech/reviews/graphics/147864-nvidia-geforce-rtx-3080-ti-founders-edition/)\n\n>The Nvidia GeForce RTX 3080 Ti graphics card arrives to market at a tumultuous time for the PC components industry. Underscored by severe stock shortages showing no signs of abating alongside price gouging which effectively doubles the cost of entry today, getting your hands on either a Founders Edition or partner card will undoubtedly prove difficult and irksome in equal measure.  \n>  \n>If you do, the latest GeForce rewards the gamer with almost as much performance as the range-topping RTX 3090. There's half the graphics memory - which puts it below AMD's premier solutions - the Founders Edition card uses inferior cooling to the 3090 equivalent, and there's no provision for NV-Link.  \n>  \n>One can successfully argue there's little need for additional models when present stock is in such constraint. An opposite line of thinking describes this introduction as promoting even more choice for the well-heeled PC enthusiast.  \n>  \n>A modestly cheaper version of the RTX 3090 with most of the performance knobs still turned on, the £1,049 GeForce RTX 3080 Ti only makes sense if you can purchase it for the advertised MSRP. We wish you good luck in that endeavor.\n\n# [Hot Hardware](https://hothardware.com/reviews/nvidia-geforce-rtx-3080-ti-review)\n\n>The NVIDIA GeForce RTX 3080 Ti Founders Edition and EVGA GeForce RTX 3080 Ti XC3 Ultra cards we tested put up strong numbers throughout our benchmarks and game tests, that were within a couple of percentage points of each other. If you plan to do any sort of manual tuning, there won't be much (in terms of performance) to separate the various GeForce RTX 3080 Ti cards that are due to the hit the market. Versus competing cards, they both fall into the same slot as well. More often than not, the GeForce RTX 3080 Tis were faster than the [Radeon RX 6900 XT](https://hothardware.com/reviews/amd-radeon-rx-6900-xt-big-navi-review)  \\-- especially when ray tracing was involved -- but the Radeon did score a couple of key victories. Generally speaking though, the GeForce RTX 3080 Ti cards aren't quite as fast as the beastly [GeForce RTX 3090](https://hothardware.com/reviews/nvidia-geforce-rtx-3090-bfgpu-review). The deltas separating the RTX 3080 Tis and 3090, however, are tiny and would not be perceivable in real-world use. For gamers the GeForce RTX 3080 Ti is the clear choice between the two. If you're a creator or professional that can make use of the 3090's additional memory, however, it remains the king of the hill  \n>  \n>Disregarding the current craziness in the GPU market, NVIDIA expects GeForce RTX 3080 Ti cards to be available tomorrow on its website and at various eTailers. The company has set its [MSRP at $1,199](https://amzn.to/2SJSzSF). We don't have official pricing for the custom EVGA GeForce RTX 3080 Ti XC3 Ultra, but it will probably be within a few dollars of NVIDIA's design. At those prices, the GeForce RTX 3080 Ti arrives at the effectively the same price point at the GeForce RTX 2080 Ti, which it expectedly crushes across the board. The RTX 3080 Ti is also a couple of hundred dollars more than the $999 Radeon RX 6900 XT, which is a much tougher battle. And versus the original RTX 3080, the new GeForce RTX 3080 Ti is hundreds of dollars more (at least in terms of its MSRP). Whether or not the premium is justifiable will likely depend on the games you play, and at what resolutions. However, any way you slice it, the GeForce RTX 3080 Ti does have some clear advantages over the current top-end Radeon, the most significant of which is ray tracing performance, and it's clearly faster and has more memory than the original RTX 3080 too. The [GeForce ](https://hothardware.com/tags/geforce-)RTX 3080 Ti also runs cooler and quieter than the competing Radeon offering.  \n>  \n>All told, the GeForce RTX 3080 Ti enters the market at a time when there is much more fierce competition, but it is arguably one of the most powerful gaming GPUs money can buy right now. \n\n# [Igor's Lab](https://www.igorslab.de/en/nvidia-geforce-rtx-3080-ti-fe-in-test-almost-an-rtx-3090-but-with-halved-memory-expansion-for-gamers/)\n\n>The GeForce RTX 3080 Ti is not a gap filler between a GeForce 3080 and the RTX 3090 in the traditional sense, there would also be far too little air between the cards to really get that right. Since they use the same power limit as the GeForce RTX 3090, but allow the card almost 30 watts more for the GPU due to the halved memory expansion, the goal of creating a “replacement” for the RTX 3090 has been solved quite plausibly. If the cooler was more potent, you could have even easily outperformed the RTX 3090 with the same TBP. This is also shown by the custom models, which are often faster than a GeForce RTX 3090 FE. But who likes to cannibalize away their own top-of-the-line model?  \n>  \n>And playing in Ultra HD? In the end, it’s exactly the increase that has always been demanded, for example, when playing in Ultra-HD. This works so well, especially with the help of DLSS (but now not only!) in the appropriate games, that with a 60 Hz monitor you already voluntarily turn on the frame limiter again, which in turn allows the card to act much more sparingly. But the reserves are there, no question. The fact that the RAM with its 12 GB could also become scarce in the future, at the latest in Ultra HD, is also due to many game manufacturers who fill up exactly what can be filled up with data. Which, of course, would not be a blanket excuse and thus the only sticking point. But 12 GB is at least more than only 10 GB, after all.  \n>  \n>In any case, DLSS 2.0 is the remedy, because what NVIDIA has presented with DLSS is almost a kind of miracle weapon, as long as it is implemented properly. Of course, the game manufacturers are also in demand, so NVIDIA is currently igniting the DLSS and DXR turbo and supports more and more games (according to NVIDIA around 130). Incidentally, this also applies to the inflationary use of the demanding ray-tracing features. Less is more and if it’s implemented expediently, then no card needs to gasp for air either. In combination with DLSS and Brain 2.0, the whole package is certainly forward-looking, if you’re into that sort of thing. Dying beautifully can be fun, especially when it’s no longer in slow motion. What AMD will then offer as an open-source DLSS competitor on 22.06.2021 cannot be assessed at present.  \n>  \n>For the quick clickers there is also NVIDIA Reflex. Provided you have an Ampere card, a suitable G-Sync monitor and a game where the feature is integrated into the game. Then you can still minimize the system latencies. We recently had a longer article about this. Reflex Low Latency mode in games like Valorant or Apex Legends is definitely a proposition, but it will have to catch on. And then there are the nasty latencies on the internet, which NVIDIA can’t be held responsible for, but which can ruin your success. Only the sum is always smaller if you at least remove the pile that lies in front of your own door. That often does the trick. See article.  \n>  \n>And does anyone remember the mysterious SKU20 between the GeForce RTX 3080 and RTX 3090, which I had “leaked” almost a year ago ? I later wrote at the launch of the GeForce RTX 3080: “If AMD doesn’t screw up again this time, this SKU20 will surely become the tie-breaker in pixel tennis”. And that’s exactly where the RTX 3080 Ti has positioned itself as a shooting star today. This makes it a RTX 3090 Light with Hash Light and Price Light, and it is best positioned as a counterpart to the Radeon RX 6900XT.  \n>  \n>The board partners will surely upgrade this chip with potent coolers and power limits of 440 watts (like here on an MSI RTX 3080 Ti SUPRIM) will be the electric nail in the coffin for the GeForce RTX 3090 FE as a reference object.\n\n# [KitGuru Article](https://www.kitguru.net/components/graphic-cards/dominic-moass/nvidia-rtx-3080-ti-review-ft-gigabyte-inno3d-palit/)\n\n# [KitGuru Video](https://www.youtube.com/watch?v=M35stg47Vj4)\n\n>All in all, the fact that the RTX 3080 Ti is able to offer what is essentially RTX 3090 levels of performance, but for a £350 discount, may well seem like a positive taken in isolation. The thing I don’t like about the RTX 3080 Ti however, is that is is another GA102 GPU, but this time priced over £1000. Every GA102 die going into the RTX 3080 Ti could have been a more affordable £650 RTX 3080, and I know which I think is the better deal.  \n>  \n>In an ordinary market, with plentiful supply, it wouldn’t be a problem – this situation would simply result in more choice for the consumer. Right now however, it is nigh impossible to get your hands on an RTX 3080, and the addition of another GA102 SKU certainly won’t make that any easier.  \n>  \n>Even if we do take these MSRPs at face value, I do also have to question who this GPU is really for. It seems to be aimed at the customer who wants more performance than the RTX 3080, who is unwilling to spend £1399 on the RTX 3090, but would happily still spend over £1000 for a card which is 10% faster than the RTX 3080.  \n>  \n>Maybe there is some small group of buyers who fit that description, but the way I see it, if you’re already spending over £1000 on a GPU, value for money surely does not matter to you, so you may as well get the best of the best and go for the RTX 3090. If you *do* care about value, then the RTX 3080 Ti looks very poor against the RTX 3080 as it’s 10% faster but 61% more expensive.  \n>  \n>The thing is, the market is in such a state right now that any GPU will sell, regardless of pricing or supposed value. It makes complete business sense from Nvidia’s perspective to do what they are doing. For gamers though, the addition of another GA102 SKU priced at over £1000 is hardly the news we wanted to hear right now.\n\n# [OC3D Article](https://overclock3d.net/reviews/gpu_displays/nvidia_rtx_3080_ti_fe_review/1)\n\n# [OC3D Video](https://www.youtube.com/watch?v=A4uUpNU91RY)\n\n>If there is a downside to the world in 2020 it is that the time seemed to absolutely drag. The launch of the Nvidia Ampere cards and the excitement that surrounded them feels like a lifetime ago. It was September. 8 months. In that 8 months the shelves have been emptier than the pasta and toilet roll aisle of your local supermarket and prices have soared with those people lucky enough to have got their hands on one gouging those who wanted to get hold of one. Even storefronts aren't averse to slightly bumping the price when they have some in stock.  \n>  \n>It might have been eight months then, but most of us still haven't actually got an Ampere card, yet here is the Ti version to render the previous model that nobody could find, obsolete. Or does it? Certainly it makes business sense to gear up for a new product, and in a normal universe we'd have had eight months to enjoy the Ampere card. So we'd be annoyed that it was replaced so quickly, but perhaps begrudgingly accepting that this is the way of the world. Early adopters always have to endure such things. However, nobody is an early adopter because there hasn't been any stock. At least Nvidia won't follow the pattern of the retailers/lucky few and bend the potential buyers over a ... £1049!!! Pardon??  \n>  \n>That's obscene.  \n>  \n>Oh well, let's make the best of it. What does this SIXTY-TWO PERCENT price increase over the regular RTX 3080 buy you? As you saw from the previous two pages you get 18% more hardware under the hood, which we'll get to in a minute, and around 12% extra performance at 4K resolutions. 62% more money for 18% more hardware for 12% more performance is a perfect encapsulation of the theory of diminishing returns.  \n>  \n>Why we aren't as cross about the Nvidia Founders Edition as we are about the partner cards is simply a matter of pricing. This card is very nearly a RTX 3090, but significantly more affordable than that card was at launch. We were expecting this to be around £749 given that the RTX 3080 launched at £649, so to have a number closer to the RTX 2080 Ti launch price is eye-widening to say the least.  \n>  \n>If you're a 4K gamer and didn't manage to get on board the RTX 3090 train during the 4 minutes they were available for purchase, then perhaps the RTX 3080 Ti is going to be just the ticket. If you're not gaming at 4K then there is zero reason to buy this unless you absolutely can't find a regular RTX 3080 anywhere. Or 3070. But if that is the category under which you fall, then basically Nvidia are price gouging you like an eBay scalper.  \n>  \n>All that being said it's approximately RTX 3090 performance for a price somewhere between that and the RTX 3080 Ti. If there is stock around and you've been saving frantically then you won't be disappointed with the end result of your spending, and thus it wins our OC3D Performance Award.\n\n# [PC World](https://www.pcworld.com/article/3620654/nvidia-geforce-rtx-3080-ti-review.html)\n\n>All that said, the GeForce RTX 3080 Ti is essentially a 3090 with half the VRAM for $300 less. That makes it much more compelling for gaming, as the 3090’s 24GB was overkill unless you’re performing content creation. The extra 2GB of capacity over the vanilla RTX 3080 makes this feel like a better option for long-term 4K gaming. AMD’s Radeon RX 6900 XT has 16GB, but of the slower (but still fine) GDDR6 variety.    \n>  \n>I’d personally prefer the GeForce RTX 3080 Ti Founders Edition over the Radeon RX 6900 XT thanks to its faster 4K gaming performance overall. AMD earns a few additional victories at 1440p thanks to its Infinity Cache, and even the 3080 TI's deep arsenal of Nvidia features like DLSS, Broadcast, Reflex, Shadowplay, NVENC, and so on doesn’t render AMD’s Radeon flagship obsolete. If Nvidia priced it at $1,000 (which I think would be a much better MSRP), however, the Radeon rival would be a much harder sell. Pricing it at $1,200 leaves ample room for every high-end card released thus far. There are still reasons to go with the Radeon as well as the RTX 3080 and 3090.  \n>  \n>Bottom line? The GeForce RTX 3080 Ti is a monster GPU worthy of being called a gaming flagship—something the 3090 couldn’t claim thanks to its massive memory buffer, high price, and content creation focus, and something the 3080 couldn’t claim thanks to its somewhat skimpy 10GB of VRAM. The dual-slot Founders Edition design isn’t as impressive as the FE coolers on those other cards, but it still does an admirable job. Unlike its other RTX 30-series cousins, the GeForce RTX 3080 Ti has no weak links (aside from the ugly 12-pin cable adapter and high price).\n\n# [TechGage](https://techgage.com/article/nvidia-geforce-rtx-3080-ti-gaming-performance-at-4k/)\n\n>In our eyes, the RTX 3080 is really the sweet spot in NVIDIA’s Ampere lineup. Ignoring the disastrous scalper market for a moment, $699 for that GPU delivers fantastic performance overall. Despite there being an even higher-end GPU, NVIDIA calls the 3080 Ti its new “flagship”, making us believe even more that the RTX 3090 *probably* should have been a TITAN.  \n>  \n>Ultimately, the RTX 3080 is great for those who want to go with a top-level GPU and are fine not splurging on the two even higher-end options that generally offer 10-15% performance boosts. The RTX 3080 Ti is suited for those who want NVIDIA’s current “flagship” – the card that offers the best Ampere has to offer, without breaking into the territory with GPUs with even more memory (eg: workstation cards). The faster memory bandwidth along with the extra 2GB makes the 3080 Ti a well-rounded top-end creator card.  \n>  \n>To that end, high-end creators will still have lots of reason to pay attention to the RTX 3090, as getting such a massive frame buffer (24GB) on the consumer-level is not going to happen any other way. We suspect most of our readers will be fine with 12GB, and if not, you’re probably already aware of your need for lots of memory.  \n>  \n>NVIDIA has said that availability of the RTX 3080 Ti will begin immediately, and we caught some etailers holding stock ahead of the launch. As the way things go right now, we don’t expect supply will last long, so you have to exercise some patience and exceptional mental fortitude in your forthcoming purchase challenge.  \n>  \n>As covered earlier, we’ll include ultrawide benchmarks with our look at the RTX 3070 Ti at its launch next week. That will come in conjunction with an updated look at rendering performance in a variety of applications (including, hopefully, the soon-to-launch Blender 2.93).\n\n# [Techpowerup](https://www.techpowerup.com/review/nvidia-geforce-rtx-3080-ti-founders-edition/)\n\n>Averaged over our 22-game-strong test suite at 4K resolution, the NVIDIA GeForce RTX 3080 Ti Founders Edition achieves very impressive numbers. It has a 10% lead over the RTX 3080, which means it beats both the Radeon RX 6800 XT and RX 6900 XT, by 11% and 5%, respectively. Another highlight is that NVIDIA's new card is really close to the RTX 3090; the difference is just 1%, impossible to notice subjectively. This also confirms once again that there is no significant difference between 24 GB and 12 GB VRAM, or the gap would be bigger. Against last generation's RTX 2080 Ti, the performance uplift is 47%.  \n>  \n>With those performance numbers, RTX 3080 Ti is the perfect choice for 4K gaming at 60 FPS and above. It's probably the only resolution you should consider for this beast because we've seen some CPU-limited titles even at 1440p—for 1080p, it's definitely overkill. On the other hand, if you have a strong CPU and a 1440p high-refresh-rate monitor, 3080 Ti could be an option. The added performance of the RTX 3080 Ti will also give you more headroom in case future game titles significantly increase their hardware requirements, which seems unlikely considering the new consoles are out and their hardware specifications will define what's possible for the next few years.  \n>  \n>There's no big surprises with raytracing performance; the RTX 3080 Ti is basically 10% faster than RTX 3080 and nearly as fast as RTX 3090. The underlying reason is that there has been no change in the GPU chip or GPU architecture. Still, compared to AMD Radeon RDNA2, NVIDIA's raytracing performance is better. The new game consoles use AMD graphics tech, though, so we'll see how much of that can be helped through optimization, or whether simply less demanding RT implementations are chosen. For example, Resident Evil Village has support for raytracing, but only uses very limited RT effects, which cushions the performance penalty incurred by Radeon cards. I'm sure we'll learn more about it in the coming months if this trend can persist, or whether the only option for serious raytracing will continue to be NVIDIA GeForce.\n\n# [Techspot](https://www.techspot.com/review/2264-geforce-rtx-3080-ti/)\n\n>The 'new' GeForce RTX 3080 Ti is essentially an RTX 3090 with half the VRAM. Normally, this could be considered good news since it's cheaper at $1,200, but actual street pricing remains to be seen.  \n>  \n>Some things have not changed... the RTX 3080 Ti is impressively fast, it’s technically an excellent product, and the extra 2GB of VRAM is welcome. But at $1,200 and with the current stock issues, it’s a poorly-timed release that frankly makes no sense, at least from a gamers perspective, it changes nothing.  \n>  \n>For a refresh, this sort of launch is to be expected, too. But the reason we don't warmly welcome it is that Nvidia hasn’t finished releasing Ampere, with no affordable models on offer. After all, they talk about trying to help gamers with hardware limiters for mining, then turn around and release the RTX 3080 Ti, it’s honestly tone-deaf, but it is what the market dictates as far as demand goes and how they can continue to maximize returns.\n\n# [Tomshardware](https://www.tomshardware.com/news/nvidia-geforce-rtx-3080-ti-review)\n\n>The RTX 3080 Ti isn't awful, but if you're willing to plunk down $1,200 for a graphics card — in theory, because we all know these are going to end up selling for closer to $2,000 or more for the foreseeable future — spending $300 more to double your VRAM and get a better cooler with the RTX 3090 seems like a better plan. Instead of a marginally higher price than the RTX 3080, the MSRP is 70% higher and the RTX 3080 Ti is only about 10–12% faster on average. Plus, as we mentioned above, the Founders Edition cooler can't keep up with the additional GPU cores and GDDR6X memory.  \n>  \n>The RTX 3080 Ti is far more similar to the [RTX 2080 Ti](https://www.tomshardware.com/reviews/nvidia-geforce-rtx-2080-ti-founders-edition,5805.html) than the 1080 Ti — except it's nine months late to the party, which is probably just as well since GPU shortages will likely continue throughout the rest of the year. By the time we're able to stroll into a retail shop or check out of an online store without battling bots and shortages, we might be looking at the next generation Hopper and RDNA3 architectures.  \n>  \n>There's potential for far more promising third party cards, but then we still have the price conundrum. It's been an incredibly bleak year for graphics cards so far. This card was probably originally slated to be a $999 competitor to the RX 6900 XT, but in the current market, Nvidia has bumped the price to reap some of the profits that the AIBs and suppliers have been enjoying. Since everything we'd like to recommend ends up costing twice as much as it \"should,\" and much of the price gouging doesn't end up going to Nvidia (or AMD), this is what we get. If you thought the RTX 3090 was too expensive when it launched at $1,500, be prepared for slightly lower performance, half the VRAM, and higher street prices on the RTX 3080 Ti. Well, higher than the 3090 launch price, at least, since the RTX 3090 now basically sells at [Titan RTX](https://www.tomshardware.com/reviews/nvidia-titan-rtx-deep-learning-gaming-tensor,5971.html) and [Titan V](https://www.tomshardware.com/news/nvidia-titan-v-110-teraflops,36085.html) levels these days.  \n>  \n>Fundamentally, there's nothing wrong with the RTX 3080 Ti on paper. Even the price might be tolerable for those with deeper pockets. But unless we see a dramatic increase in supply — or a massive decrease in demand (which might happen, as mining profitability has dropped quite a bit during the past month) — finding one in stock at a reasonable price will be an exercise in frustration. Anyone still hoping to pick up a 3080 Ti should also opt for a third party card with higher factory clocks and a beefier cooler. We'll be looking at some of those cards in the coming days.\n\n# [Computerbase - German](https://www.computerbase.de/2021-06/nvidia-geforce-rtx-3080-ti-review-test/)\n\n# [HardwareLuxx - German](https://www.hardwareluxx.de/index.php/artikel/hardware/grafikkarten/56236-schnell-und-dennoch-ueberfluessig-vier-modelle-der-geforce-rtx-3080-ti-im-test.html)\n\n# [PCGH - German](https://www.pcgameshardware.de/Geforce-RTX-3080-Ti-Grafikkarte-277501/Tests/Test-Benchmarks-Vergleich-mit-RTX-3090-1372951/)\n\n# [PCMR Latino America - Spanish](https://www.pcmrace.com/2021/06/02/nvidia-geforce-rtx-3080-ti-founders-edition-review/)\n\n# Video Review\n\n# [Bitwit](https://www.youtube.com/watch?v=AFzciLlpjtw)\n\n# Digital Foundry Video - TBD\n\n# [Gamers Nexus Video](https://www.youtube.com/watch?v=Vtkk-_0jrPU)\n\n# [Hardware Canucks](https://www.youtube.com/watch?v=qHqesWMY9OU)\n\n# [Hardware Unboxed](https://www.youtube.com/watch?v=n4_4SKtq_Gs)\n\n# [JayzTwoCents](https://www.youtube.com/watch?v=9p5w_vY6SW8)\n\n# [KitGuru Video](https://www.youtube.com/watch?v=M35stg47Vj4)\n\n# [Linus Tech Tips](https://www.youtube.com/watch?v=A-a-wzQPZfs)\n\n# [OC3D](https://www.youtube.com/watch?v=A4uUpNU91RY)\n\n# [Optimum Tech](https://www.youtube.com/watch?v=a8WNHpK2ocI)\n\n# [Paul's Hardware](https://www.youtube.com/watch?v=1HFOSUAfGUM)\n\n# [Tech Yes City](https://www.youtube.com/watch?v=6c4F_zMqlaE)\n\n# The Tech Chap - TBD\n\n# [Techtesters](https://www.youtube.com/watch?v=6txiadrvdnQ)",
    "comments": [
      "The most overpriced card ever that is going to sell out instantly regardless",
      "This card is the catch 22 card. Gamers either get a bad deal money-wise (for the fantasy MSRP) or gamers don't buy it and the LHR gets 'accidentally' cracked. Either way cha-ching for Nvidia.",
      "To the surprise of nobody, getting **reasonable** cards in the gamers' hands wasn't part of the deal. Nothing like a 2%-per-$100 improved card cannibalizing chips for pending RTX 3080 orders.",
      "I was holding out for the 3080ti, traditionally I had always purchased the ti models in the past (780ti, 1080ti, etc.).  However, with the results from these reviews, I think I will just stick with my 1080ti for another generation and see what the 4000 series puts out.  I just can't justify the $1200 price tag for what you get with this card and 3080s are just too damn scarce right now.  I'm not going to go out of my way to spend $1200, but at the original price point of $1000, I was seriously considering it.  I'm pretty disappointed with Nvidia over this one.",
      "Gamers Nexus actually calculated it at about 1% per $100.  Awful.",
      "I mean the 3090 is right there too.",
      "So as a 3090 owner I am going to really lean on how much I like/enjoy Ray tracing and assume more cores will help.\n\nBut shit none of it matters cause I got my 3090ftw3 for $1900 after tax and in these crazy times I'm somehow fortunate for that.",
      "What are you guys gonna do? Not buy it? LOLOLOLOLOLOL",
      "This is the worst investment in the history of video cards.",
      "There's no need to be spiteful bud. My 1080ti is dying, I'd rather a 3080 over the ti, and I'd rather the 3070ti over it too. But unfortunately, the 3080 is a unicorn and the 3070ti will fly off the shelves just as fast as everything else. The reality is, this 20% markup is going to result in a better chance at getting a card I can use before my current one is actually dead.\n\nI originally didn't want to buy any 30xx series, the performance jump value just wasn't there. And well, you're probably familiar with the used market right now.",
      "Look at all the 3080 buyer's remorse I'm feeling.",
      "thank god im using it for gaming exclusively, on a 1080p panel no less.",
      "hi, Sam from Ars Technica here. (That's \"Ars Technica,\" not \"Arstechnica,\" if OP is still keeping tabs.) the answer to your question is \"yes,\" and I have test results--and Nvidia's comments about ALL future GPUs + mining going forward--in my Ars review, linked above.",
      "You're not in Kansas anymore....",
      "nah, that was the 2080ti",
      "If FSR is decent it may give your 1080ti a pretty decent boost to hold you over until the gpu market is better",
      ">  the performance jump value just wasn't there.\n\nI'm surprised to hear you say this. I upgraded from my 1080 to a 3080 (I was lucky to get the card at MSRP through a BB drop).  I am very happy with the purchase.  The 20xx series was a bad buy over the 10xx, but the performance plus bells and whistles of the 30xx (DLSS, HEVC, and more powerful raytracing hardware) made this a good upgrade, crazy market aside.\n\nI do agree that the 3090 and 3080Ti even at MSRP are not worth it, and neither are any of the cards at scalped prices.",
      "No. Unlike gaming mining doesn't thermal cycle the GPU so the solder balls are stressed less and less prone to cracking. You also undervolt as much as you can when mining for good thermals and low power consumption.",
      "Not happy about the cost/performance ratio per every review but that’s just beating a dead horse at this point. My 980ti crapped out a few days ago so looks like I’ll be camping out at BB tonight with slim hopes of actually grabbing one.",
      "Selling a thing for a high price isn’t “scalping”. What Nvidia is doing is price gouging."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "high",
    "matched_keywords": [
      "rtx 3080",
      "3080"
    ],
    "title": "RTX 3060 ti for $500 or RTX 3080 12GB for $800?",
    "selftext": "Which gpu is the better option when it comes to price/performance (Both cards are msi ventus models BTW)",
    "comments": [
      "just get the 3060 ti then",
      "it depends on your uses\n\nwhich you didn’t provide\n\nso it’s gonna be hard to determine which is good for you",
      "I have a 144hz 1080p monitor, and want to select a card that can make the best use out of it for the next 2-3 years.",
      "Go 3080 if it's available\n\nEveryone disses 1080p gaming but in the end it defeats all cards, so grab the one that'll handle it the longest",
      "3080, you'll be happy you did.",
      "I disagree. For the next two years at 1080p the 3060ti should be enough to do medium or high with Dlss",
      "For 1080p - 60ti is best value GPU on the market no question, but, be aware you are setting yourself up to be on the low end of the spectrum for performance in the coming years.",
      "The Ventus is actually trash. MSI is also absolutely not bottom tier OEM.",
      "Yeah people vastly underestimate what these cards are capable of. I'm playing 1440p high settings on a 3060 in all games",
      "How much does $300 matter to you?  If you make >$50 per hour or so, get the 3080.  If $300 is a lot of money to you, get the 60 Ti.   \n   \nIf you make good money, I’m assuming you’ll upgrade to 1440p in the near future",
      "Rtx 4090 ti",
      "You relating the 3060ti to 1080p and I'm playing my games in 4k with it...........",
      "1080ti in 2017: amazing 4k card\n\n3070 (30% better than the 1080ti) in 2020: amazing 1440p card\n\nfr everyone assumes you only play AAA games on ultra and as such you cant use anything less than a 3080 for 4k",
      "If you have the money. Get the best one you can afford. With GPUs you can't really go wrong with the best one you can afford.",
      "3080 12 gb has no MSRP but theoretically should be more than $100 above the 3080 10 gb (or perhaps just about $100 over, depending on who you ask). The 12 gb is considerably faster and has more vram. $800 is a steal.",
      "Wait wait, $800 USD for a 3080 12 GB is very cheap - which model card is this? What is the retailer?",
      "3080. You can crank everything to max including RT though believe it or not, some games will still have issues (looking at you, WD Legion) and DLSS is generally less useful at 1080p so don't count on that. But $800 is a steal for that card. It sounds like it's in your budget if you're even considering it and the 5800x3d is overkill for the 3060 ti.",
      "Same here. DLSS really is a godsend. And even without, 1440p +80/90 fps High/Ultra is very doable in most games not named Cyberpunk 2077. I can even throw in medium RT in some games as well.",
      "Would buy 3080, my 3060 ti struggle to keep 60 fps, ray tracing max at 1080p when play cyberpunk.",
      "3080 is just a safer bet and that's a great price for it."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "high",
    "matched_keywords": [
      "rtx 3080",
      "3080"
    ],
    "title": "Opinion on RTX 3080 over 4070 Ti for 4K",
    "selftext": "Hey guys, I’m buying a PC, and would like to know whether getting the new 4070 Ti is a good idea, I have the Ryzen 7 5800X3D CPU and a 4K 60Hz monitor. Is it worth it paying more for the 4070Ti over the 3080?",
    "comments": [
      "4070 ti will perform better and it has DLSS 3",
      "4070ti outperforms 3080 in every conceivable way at 4k and under. i will repeat the same thing everyone else has been saying for the daily fucking 3080 vs 4070ti post. if you want a new card go 4070ti, if you cant find a used good condition 3080 for under msrp then go 3080. cant wait for an hour from now when another person makes this exact same fucking post and 17 different people tell him the exact same thing again...",
      "Definitely worth it. The performance will be better but more importantly, you're going to have support for much longer and higher resale value.",
      "plus way better power draw and efficiency overall.",
      "According to the benchmarks in my personal opinion I would say yes it's worth it.",
      "If you did not already have 3080 then go with 4070ti. Better performance, newer card and gonna get tech support for at least 1 generation.",
      "How much is more?",
      "A lot of people are spouting the same overly-simplistic “this card is better at 4K” or “this card is better because it has DLSS3” bullshit that we see in almost every thread on this sub.\n\nWhether or not it’s “worth” paying more for the 4070 Ti over the 3080 is entirely dependent on how much more you’re being asked to pay for the newer card and what titles you play. You can perform this own analysis on your own. Consult benchmarks for representative gaming examples for your own planned use case and figure out if the % increase in fps is better or worse than the % increase in price. Pay particular attention to which games do and do not support DLSS3 and keep and mind that most legacy titles will never receive support for the very feature that allows the 4070 Ti to pull dramatically ahead of its 30 series rivals.\n\nIf you want my biased opinion, it probably doesn’t matter on a 60 hz 4K monitor. A 3080 is more than capable of generating north of 60 FPS at 4k for pretty much every non-DLSS title with ray tracing off. Even with ray tracing on with the exception of maybe cyberpunk or games like it, the 3080 is likely more than adequate. Have you purchased your monitor yet? If not, I would not recommend buying a 60 hz monitor for gaming purposes. You’d be better off with a 1440p 144/165/170 hz display and won’t notice the difference in resolution quality compared to the 4K screen unless your eyes are less than 6” from the screen. (Which is not a great idea in general)\n\nThe timing of the purchase isn’t great either. Given how poorly the 4070 Ti and 4080 have been selling I think it’s fair to assume both will come down in price 9-22% in the next 6 months (my prediction). But if you need a card now, I guess that doesn’t make a difference. I personally probably wouldn’t pay more than a $200 premium for the 4070 Ti so if the price difference is that or lower to 4070Ti. If it’s more than that, a 3080 will be just fine for years to come.",
      "This is the part where you present your counter argument.",
      "Yes, 4070thai can deliver you a smooth 60+ 4k framerate.",
      "I think it's downvoted because its only severe edge cases. You really have to manufacture a scenario where a 3090 beats a 4070Ti in rasterization, let alone a 3080. It's true, but needs like 10 asterisks after it.",
      "1440p lost its appeal the moment DLSS/FSR became common place.\n\n4K DLSS performance runs with the same FPS as 1440p DLSS quality, but it provides much better detail and antialiasing. People don't understand that because benchmarks typically focus on native-to-native perf comparisons. The only downside is that 4K 144hz monitors are much more expensive.",
      "After playing on 60Hz my whole life, I got a 360Hz monitor.  I was looking for a 1080p/240Hz one but the 360Hz one was on sale for $50 more. After playing in the 240-360Hz range for a couple months, going back to  60Hz it feels like a slideshow.  It's insane since I thought 60Hz was smooth before getting a higher refresh rate monitor.",
      "His argument is “try again”",
      "There’s no scenario, given the absurdity of the 3080 still being a 700-800 dollar retail card 2+ years after launch, where you should buy the 3080 over the 4070ti.\n\nThe 4070ti is ~15% faster, has DLSS3 support for delicious fake frames, for roughly the same price. While I’m utterly disgusted with Nvidia’s “we’re the scalper now” pricing, one still shouldn’t buy last-gen, especially given the freakin prices haven’t dropped much.",
      "I *strongly* disagree with all the people telling you to get a 1440p monitor. Given the prevalence of upscaling, a 4K 120Hz display would give you way more flexibility with a wider range of resolution/framerate combinations. 4K DLSS Quality at 100Hz for example is really nice middleground. Less demanding games you could go for the full 120Hz at native res.",
      "Don't listen to people trying desperately to unload their 3080 on you for top dollar. They just want to use your money to upgrade to a 4070ti or 4080 themselves. Buy a new card. It performs better, has exclusive performance boosting features, has less wear and tear, will be supported longer, and comes with a valid warranty.\n\nEdit: if you can find a 3080 that is in good condition for a massive discount, like $300-400, then that would be a better deal. You probably won't find that this generation though.",
      "Thank you for mentioning that.\n\nI feel that many forget the resale value on their hardware. If you're willing to go through the trouble to sell your older hardware, it makes the hobby significantly more affordable.",
      "You’re right I should’ve specified, it’s around 150CAD more",
      "As another 10GB 3080 owner, I agree with this post.\n\nEven targeting 4K120, the 3080 can still do the job in basically all Esports titles. Perfectly achievable in Halo Infinite and Overwatch, from experience.\n\nWith that said, I also want to emphasize on my agreement on not buying a 4K60 monitor. I think that is a waste of money. High refresh 1440P > 4K60 any day."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "high",
    "matched_keywords": [
      "rtx 3080",
      "3080"
    ],
    "title": "RTX 3080 and RTX 4070 Ti",
    "selftext": "I have a RTX 3080 and I can get a 4070 ti for free should I change it ? ( I don’t know much about graphic card I got my first pc 2 days ago lol) \n\nThanks for helping ",
    "comments": [
      "Free is a good price",
      "You should, the 4070 ti is superior than your 3080, and it's free",
      "Well It’s a no brainer, faster and better card + 2 more gb od vram. And you also get frame gen on the 40xx series so yes go for it",
      "Does your 3080 have 10 GB or 12 GB VRAM?",
      "Thank you very much !",
      "4070Ti is slightly better than 3080 and an additional 1 GB VRAM. Since you can get a 4070Ti for free, why not keep both and enjoy multi-GPU perf gains in 3d animation if you're into it or could get into it? You'll need a beefy Power supply for that though and a compatible motherboard. Else a 4070Ti is better",
      "Thanks for your answer ! I just checked again and it’s a msi RTX 4070 ti gaming x slim is there a big difference?",
      "Thanks for your answer! I just checked again and it’s a msi RTX 4070 ti gaming x slim is there a big difference?",
      "It’s a great card, I have the 4070S gaming x slim works like a charm",
      "10 GB",
      "[https://www.techspot.com/review/2643-geforce-rtx-4070-ti-vs-geforce-rtx-3080/](https://www.techspot.com/review/2643-geforce-rtx-4070-ti-vs-geforce-rtx-3080/)\n\nAs demonstrated, the 4070 Ti is better with 12 GB and slightly better perf and more updated architecture and RT cores. Given it's \"free\" for you, it's a no-brainer upgrade"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "high",
    "matched_keywords": [
      "rtx 3080",
      "3080",
      "3080 ti",
      "rtx 3080 ti"
    ],
    "title": "RTX 3080 Ti Air Cooled with Raijintek Morpheus II (Mount mod) and Custom VRAM Coldplate (Copper mod)",
    "selftext": "",
    "comments": [
      "That is proper engineeering 👍🤓",
      "Hey look buddy…",
      "So I've seen posts like [this](https://www.reddit.com/r/nvidia/comments/q5jjk9/is_there_a_thicc_cooler_like_raijintek/), [this](https://www.reddit.com/r/nvidia/comments/imj6q5/3080_series_support_for_morpheus_ii_cooler/), [this](https://www.reddit.com/r/pcmasterrace/comments/kuzoa5/rtx_308090_with_raijintek_morpheus_ii_8057/) and [this](https://www.reddit.com/r/nvidia/comments/j0j4qa/anyone_try_slap_their_morpheus_2_cooler_on_their/) asking if Morpheus is an option for Ampere cooling. I believe I have an answer now.\n\nBasically this is a <$25 mod if you have all the right tools.\n\n\nFunny how I've been ghetto slapping an AIO on my HD7950 and still doing something like this today. Some things never change.\n\nPaging the OPs who asked: u/Yeetirios, u/t1337dude, u/Duckers_Mcquack, and u/Squidmaster7.",
      "Was it difficult to make a hole in the coldplate for the GPU, also did you isolate the little transistors around the GPU with nail polish or something like that? i was very close to having an accident because of that, Liquid metal tends to displace easily compared to thermal paste.",
      "There is a free market no one capitalize. Someone should start producing heatsinks for gpus just like waterblock so we can put Noctua A12 on it and enjoy superb performance and silence.",
      "I don't think so cuz I didn't drill it 😂😂😂 The shop did it for me.\n\nBut I don't see how it's any harder than your average home improvement project. Copper is soft after all.",
      "Oh and for your second part of the question, yes everything within 2 inches of the core, VRAM what have you must be sealed with at least nail polish. Extra measures like electricians tape for the small ones around the core. Then spam thermal paste on top of the tape as a final measure, if you so incline.",
      "I'm an Engineer",
      "I know you \"aggressively undervolted\", but why keep using such a low wattage PSU?",
      "I bought this card in an impulse, assuming I could strip my Morpheus II CE from my Strix 1080 onto this. Turns out it's a little bit more difficult than I thought after several posts circulating around how this is technically possible while nobody has done it yet, but I won't let a fine cooler go to waste.\n\nThe Colorful RTX3080Ti NB-V is just your bog standard 3080Ti AIC reference design. Temps and perf in gaming were fine before modding, but nothing to write home about - Undervolted gives 74°C core/88°C VRAM at full gaming load.\n\n`Mounting system`\n\nAmpere is not aftermarket friendly as their mounting holes are different from last gen, so something has to be done in the mounting arrangement. I find machine shops like [this one](https://www.aliexpress.com/item/1005003095574238.html?spm=a2g0o.productlist.0.0.1cbb61d2ujb1nj&algo_pvid=0fc42fa0-17f5-4863-a189-ffaa50454007&algo_exp_id=0fc42fa0-17f5-4863-a189-ffaa50454007-0&pdp_ext_f=%7B%22sku_id%22%3A%2212000024054440369%22%7D) to help cut out the mounting arms, substituting the [stock ones](https://www.raijintek.com/images/accessory-morpheus2clip.jpg) on a Morpheus with Ampere dimensions. I threaded them with screw taps to install [mounting screws](https://www.aliexpress.com/item/4001072025844.html?spm=a2g0o.productlist.0.0.536f1ade0hK81m&algo_pvid=91553233-f00b-4443-b66f-f5235e3ec6d3&aem_p4p_detail=202110220559147709442038346600016600401&algo_exp_id=91553233-f00b-4443-b66f-f5235e3ec6d3-4&pdp_ext_f=%7B%22sku_id%22%3A%2210000014059762460%22%7D) for the main assembly. **Given the wider lever arms, choosing thick steel plates would help create an even mount on the core and VRAM as the arms don't hog easily under stress**.\n\n`Coldplate`\n\nMeanwhile, to find a good solution for the GDDR6X heat problem that the Morpheus can't solve on its own, the copper mod is in principle the best option on air. A step further than that, I designed a copper coldplate with cut shims facing the VRAMs and thin heatsinks on the opposite side which were then soldered together. Suppliers like [these](https://www.aliexpress.com/item/1005002120776637.html?spm=a2g0o.productlist.0.0.7574220801X8Sp&algo_pvid=b5872e3f-b4d4-451d-ba15-676615837533&algo_exp_id=b5872e3f-b4d4-451d-ba15-676615837533-0&pdp_ext_f=%7B%22sku_id%22%3A%2212000018808788560%22%7D) proved greatly helpful. I also sanded the Morpheus contact face with the plate down to achieve better flatness.\n\n**The coldplate reduces the tolerances with the VRAM to sub 0.2mm which allowed direct thermal paste applications**. I strongly reccomend a viscous paste like [ShinEtsu X-23-7921](https://i.ebayimg.com/images/g/MLIAAOSwOahe3jkJ/s-l400.jpg) to ensure adhesion and safety when handling the bare card.\n\n`Ancillary cooling`\n\nFor the rest of the board, cooling is handled simply with Morpheus II Core Edition's provided heatsinks. Follow the stock heatsink for a clue on where to apply the [mini-sinks](https://www.raijintek.com/images/accessory-heatsinkc.jpg). Since their double sided tape worked 'so well', I changed it for 3M ~~468MP~~ (Edit: I temporarily swapped to 9448A as they stick better. 8815/8810 is next for testing). For the [VRM heatsink](https://www.raijintek.com/images/accessory-vrm-heatsinkbig.jpg), some simple zipties and thermal pads sufficed. **If your Morpheus version is different, YMMV**.\n\n`Insulation (Important)`\n\n**Electrical insulation of the board against copper is key**. You may consider three measures for that: Nail polish, electrician's tape, and thermal paste, applied in that order. While the first two should be obvious, thermal paste is great because it is inherently a gap filler.\n\n`TIM choice`\n\nWith the insulation in place, I thought about the TIM for the VRAM and core. Here I had a dilemma - The same coldplate receives heat from the VRAMs and the core; VRAM has no practical option of treating with LM, and LM to the core can impact VRAM temps in the steady state because of a locally higher thermal conductivity in favour of the core. I went for LM on the core anyways because I don't concern myself with mining.\n\n`Results`\n\nThe results were as I expected - **an equalisation and reduction of temps between core and memory**. It is important to make this distinction because the copper distributes heat around efficiently. Temp reduction comes from elimination of inefficient thermal pathways (pads), more efficient surface contact, and beefier cooler and fans instead. This is now a 4+ slot card, btw.\n\nAt 55% speed with NF-A12x25 fans, **results were a \\~20°C drop in core, and \\~15°C-20°C drop in VRAM**, and much quieter operation. 54°C core/68°C VRAM. The temp decrease actually helped with power consumption as a side benefit to the point where I saved 6-8% leakage power.\n\n`Value`\n\nMaterials-wise, this mod costed me about $25, which, compared to the mark up of better designed brands, is an extreme value. But do consider warranty, and include the cost of fans, the cooler and tools you need to buy yourself if you're thinking about attempting it from scractch.",
      "I have wondered this myself and I think I know why. This post is my speculation, not stating this as fact. \n\nAfter studying a few PCB layouts and being a mechanical engineer with a few years of previous electromechanical experience myself, I believe I understand the reason why it's not a huge thing this generation.\n\n1. A lot of vendors aren't going with a reference board design, although components maybe taken from the reference design, they have optioned for different layouts\n\n2. Due to the difference variations, mounting holes in the 30 series vary from various boards\n\n3. Also due to these variations, gap thicknesses from the cold plate and vram are so varied it's unpredictable. Various people have bought wrong thermal pad thicknesses due to these variations and following the advice of other users. EVGA user sees ASUS user use thermal pads at X thickness, they try it and it is too small or too big\n\n4. Because of these large variations, I believe that aftermarket heatsink makers have determined it's not worth doing because they would have to have various heatsinks produced which would be quite costly. Imagine ordering 100,000 for a reference PCB vs 10x 10,000 to account for 10 different variation of cards. Finally, imagine if you don't sell these, your revenue margin would be pretty low.\n\nTL;DR the 30 series cards vary too much in design, even hole patterns vary. GPU die height to vram height vary also. You can't design a one heatsink fits ALL GPUs this generation like the 9 and 10 series. I don't think companies want to bother nor do they see it profitable.",
      "2 inches is 5.08 cm",
      "That means I solve problems",
      "Uh, wow... Thanks 69 bot?",
      "WOW!!!  It seems you know what you're doing so any comments/suggestions I have are likely rubbish.  But because it is a slow day:\n\nWhat is the overall GPU to Hotspot temp Delta?  My main concern with repadding/waterblock etc is always good mounting pressure.\n\nThoughts on thermal puddy?  Is sold out everywhere right now, but is supposedly even better than pads or paste.  Could drop mem temps further.\n\nNo liquid metal?  I know it's risky but you seem to have the bases covered with nail polish etc.\n\nAny clue what a pleb like me might pay to implement this?  I assume the copper is affordable enough, but when you're having stuff machined... seems out of reach for many.\n\nAbsolutely amazed!!  Those are close to water block temps, without all the hassle.  Great job, thanks for sharing!",
      "Excellent write-up and mod",
      "I completely agree. Even if they have the economies of scale to source everything at say, a fraction of what I paid, it would still be a tough sell with all the variants out there. Anyone that frequent this sub can easily spot differences in the TUF and X Trio models from Nvidia's 'true' reference just by looking at PCB pictures alone.\n\nThe optics is a bit weird when somebody sells you a cooler for $50, and asks another $15 for a compatibility kit, which is essentially just multiple pieces of metal with you having no idea which ones would work until you try.\n\nI think the mod *maybe* has applicability for the cheapest variants of PNY, Zotac, Galax, Gigabyte and EVGA etc. SKUs that don't give a damn to rearrange much of anything under the cooler.",
      "I solve practical problems!",
      "Impressive results. I was expecting worse with what is essentially a gigantic overly wide heatspreader between the die and cooler. Mod well done!",
      "Looks like you used liquid metal on bare copper?\n\nIt is only a matter of time for when you experience it alloying with the copper.\n\nhttps://imgur.com/a/4qbrvDJ\n\nhttps://imgur.com/a/53k7tw5\n\nHad a few microns of this crap on my AIO and it was about a few microns thick. It can be a bitch to clean off. It was on a GPU.\n\nGPU have a much higher electrical field around them than CPUs, so that's why CPU liquid metal people don't see this kinda stuff often, but they still do.\n\nMy question is... **What if you just went with liquid metal with the stock cooler if you were going to put liquid metal already?** The stock cooler was nickel plated right? Liquid metal works better on nickel plating and nickel is closer in electrical potential to liquid metal."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "high",
    "matched_keywords": [
      "3080"
    ],
    "title": "RTX Discussion: 3070 Ti vs 3080 for $400 difference?",
    "selftext": "Hey everyone,\n\nI can’t imagine how many discussions are talking about the difference between cards.  I’m currently looking to build a new PC and am really struggling settling on the right one.\n\nI’m running on at least a 10 year old system with parts probably as old as 12 years.  I haven’t experienced much above 30 FPS on popular titles and am afraid of buying new games from the constraints of my machine.  However, now that I’m looking to upgrade, I’m having trouble deciding which one.\n\nHere are some key points:\n\n-I’m going for 1080p gaming. There’s a possibility in a few months I may look for a 1440p monitor for some games and bounce back and forth, but the majority will be 1080p.\n-the difference between cards, from what I’ve seen, is $400 (a steep price change)\n-my immediate thought is.. I don’t think it would be worth it but.. I’m not sure. I don’t know how 120 FPS looks on a 144 hz monitor compared to 150 FPS\n\nIf it helps, I’m attaching what I believe to be my fully complete build:\n\nhttps://pcpartpicker.com/list/zQyjpH\n\nAny advice or feedback is welcome and I just want to learn.\n\nEdit: Updated part list 3/30/2022",
    "comments": [
      "3070Ti is already overkill for 1080p. A 1440p 144Hz monitor would be a logical next step for you. The 3070Ti will not quite max out 1440p 144Hz, but the 400 dollar difference will get you a decent monitor to make full use of the card. \n\nThe next generation of cards is already on the horizon, and they Will be another big boost in performance. A 3070Ti will feel like a big jump for now, and you can choose from there when you Will feel like you Will need An upgrade. Don't forget that your 3070 Ti can be sold to help fund your next card.",
      "For 1080p go for a 3060 Ti or something.",
      "You shouldn't be playing at 150 FPS on a 144 Hz monitor. That would lead to screen tearing, which is still visible at 144 Hz. You should use G-Sync with VSync and cap a few FPS below 144, for example 140 or 141 FPS. That way you get no screen tearing and minimum lag.\n\nAs for how it looks, it's much better than 60 FPS, but once you're past 100 FPS, you're entering the realm of diminishing returns. You have to be a really good competitive player to notice the difference. I'm saying that as someone who just went from a 144 Hz monitor to a 240 Hz one. Wasn't worth it IMO.\n\nFor 1080p 144 Hz I’d probably get something like a 3060 Ti. It's widely recognized as the best value card of the whole series and should be enough for 1080p. But if you can afford a better card you can actually play at fake 1620p on a 1080p monitor with 2.25x DLDSR, which looks much better than native 1080p.",
      "I ran into this, but from my research as long as you're not generating a profit there are no tax implications, and with declining gpu prices it's unlikely to make money second hand.",
      "G-Sync disengages once past the refresh rate.\n\nVSync is still needed to eliminate screen tearing. Battle(non)sense has a video that clearly demonstrates screen tearing with G-Sync. I don't have a link on my phone, but it's easy to find. Something along the lines of how to get the most of your G-Sync monitor.\n\nVSync eliminates screen tearing, but adds input lag. G-Sync eliminates that input lag.",
      "Unless he wants something that will last longer...",
      "Looks like you are keeping your systems for a long time. If this is the case, you should get the highest GPU that meets your budget. I would also say wait for 40 series cards which are around the corner to get more performance/buck.",
      "Get 3070 ti",
      "I think the 3070ti would be fine for you, the price jump for a 3080 is too extreme based on your needs from what I can tell. [My PC](https://pcpartpicker.com/user/GreenThimble/saved/3PtrrH) is very similar to what you plan on building (3070ti, Ryzen 5800x), albeit with 16gb of RAM but if you want me to benchmark anything for you let me know and I can run some tests depending on whether or not I own the game haha.",
      "I would go for an 850 watt psu, especially if you decide to go with the 3080. Keep in mind, Nvidia is releasing there new Gpu’s later this year.",
      "My 3070 Ti is literally destroying everything I throw at her at 1440p 165Hz",
      "I play on an OC'd 2080 which should be equal or closw to an OC'd 3060ti.\n\nI play at 3440x1440 and play mostly AAA games. I can run 90-100fps in most games at high, some games some ultra, some games a few settings dialled back.\n\n 3060ti's are a lot cheaper than 3070. 3070s and 3070tis seem to be similar price, you don't get much more performance between the 2. 3080 is a big jump, but for current 1080 or 1440 is generally overkill.\n\nBest bang for buck is generally 3060ti, 3080 is double or more for futureproofing which has been generally been shown to be a poor idea with PC parts.",
      "the sweet spot in price to performance is usually the xx60/xx60ti.\n\nbut a 3070ti would be a good choice if u intend to go for 1440p 120+ hz in the future",
      "I remember over 2 years ago when people where saying this about the 30 series... and still can't get them",
      "What's your point? 3060 is enough?",
      "Tbh, best bet if you're trying to avoid the reporting process would probably be to sell in person and on offerup/mercari/craigslist/FB marketplace.\n\nIf you use multiple different channels you can also help to avoid the $600 limit. Meaning make $500 through ebay, $500 through PayPal, $500 through cash app, $500 through venmo. (Understanding you need to use \"Goods & Services\" and pay fees for most of those sales.",
      ">I’m going for 1080p gaming\n\nBoom, go for the 3070 / TI cause unless you are doing competitive shooters at 2560x1440 or 4k 60fps gaming, you are not getting the full value of the card. Why do I say this?  \nCause 400 dollars for 20-25% more horsepower you arent gonna use would seem like a waste AND that 400 could be used for future investment in stocks or a newer generation card.",
      "3060 is for 1080p\n3070 is for 1440p\n3080 is for 4k (but rly its a 1440p on steroids becouse it has only 10g ram)\nYou should go for 3070 IMHO but wait 2 months more and you will buy it much cheaper. The prices are going down as we speak . Forget about ti versions they are designed to money grab.",
      "*their",
      "I've just glanced over your list. \n\nYou have a small headroom (just 50 watts) concerning your power supply. The next gen cards are rumored to be the most power hungry they have ever been. So if you know you are going to want to upgrade down the road, it's best to purchase a power supply that is ready for that. \n\nThe chance that you will want to upgrade the graphics card is quite big, because 4000 series is rumored to be a very big jump again and because the graphics card is easy to upgrade as opposed to the CPU. It's very common to upgrade just the graphics cards every few generations with the same system, before it's worth it to build a new system. \n\nBuying a beefier power supply is not a waste of money imo because when it is not running near 100%, it will run cooler and more quietly, less energy is wasted. Power supplies have efficiency curves and golden ratios that can be calculated using online tools (e.g. I need 600 watts, how big of a power supply should I buy if the power supply runs most efficiently at 55%?)\n\nAlso consider buying Windows 10 and then upgrading to W11 for free, if that's cheaper than buying W11."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "high",
    "matched_keywords": [
      "rtx 3080",
      "3080",
      "3080 ti",
      "rtx 3080 ti"
    ],
    "title": "rtx 3080 ti or rtx 4070 super",
    "selftext": "hello, been wanting to upgrade to a new graphics card\n\nin my case here rtx 3080 ti is 217$ cheaper than the rtx 4070 super (both new)   \n\n\nwhy am i asking this? because i heard that dlss4 transformer model would perform much better on an rtx 4000 series than an rtx 3000 series also new stuff will most likely be added to the rtx 4000 series and not the rtx 3000 series\n\nalso keeping dlss3 in mind if that would be worth it (i currently use afmf or lossless scaling which are both pretty good for me)",
    "comments": [
      "https://preview.redd.it/db8egzusi3ne1.png?width=1646&format=png&auto=webp&s=9ba3ae816ed1b84ee33bc3a7159d0136d56eee0d\n\ndlss 4 SR almost the same for all gpus  \nso if you are gonna be playing cyberpunk with raytracing+ ray reconstruction ur gonna lose +30% performance",
      "30% raw performance? or considering dlss3?",
      "30%   \nusing dlss 4 upscaling + ray reconstruction",
      "30% seems like alot, i will be using RT thats the main reason i am switching from nvidia to amd\n\ni want to crank high-ultra settings with rt ultra in most games (cyberpunk included) obv\n\n  \nwould the 200$+ diff be worth for 30% performance?\n\nbtw in my country 200$ in value is actually like 300-400$ diff",
      "https://preview.redd.it/ly8kwx5gl3ne1.png?width=2560&format=png&auto=webp&s=0b27a1fe9c6fb91abd5afad47f71758727541d9d\n\n1440p + dlss 4 p on 2060 super   \nRt psycho no ray reconstruction  \n90 fps without RT  \n30 fps RT + RR",
      "these are my 4070 Super results below\n\nUSING: transformer model, dlss performance + fg on both below\n\n3440x1440p  (same test below with no RT on 158 FPS)\n\nultra/high, raytracing med, ray reconstruction on = 124 FPS (about 109 fps with RT ultra)\n\n4k\n\nultra/high, raytracing ultra, ray reconstruction on = 98 FPS",
      "hello, what are the temps and what model is ur 4070 s"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "high",
    "matched_keywords": [
      "rtx 3080",
      "3080",
      "3080 ti",
      "rtx 3080 ti"
    ],
    "title": "NVIDIA GeForce RTX 3080 Ti to feature GA102-225 GPU, RTX 3070 Ti gets GA104-400?",
    "selftext": "",
    "comments": [
      "Ah more cards we’ll never get to buy.",
      "If the 3080 Ti is really being announced in the first half of April, we should start getting more leaks soon.  That's a very close launch for a GPU we know nothing about (or if it even exists at all).\n\nAnd the 3070 Ti with those specs, presumably $600 MSRP, is a total joke with the 3080 being so close in price but drastically superior.",
      "Not sure how much better 3070 ti will be with 8gigs of gddr6x vram but cuda core amount looks like dog shit for a \"ti\" imo.  I guess miners love gddr6x ?",
      "I’ve been PC gaming since the 90s. I’ve never seen anything like right now with graphics cards. Absolutely ridiculous situation",
      "Will be anounced on 1st of april, so you can't be sure if they are serious or not :D",
      "They would, memory bandwidth is everything in Ethereum hashing. GDDR6X would probably get the 3070 to ~83 mhash/s.",
      "8GB 3070 Ti....man i hope this will not be true.",
      "Scarcity of GPUs, CPUs, and the most sought-after mobos for those CPUs along with sky-high prices for ram and PSUs. Never seen this before in 20 years of building computers.",
      "> Nvidia can capitalize on that.\n\nThey could just build more 3090s instead. A 12GB 3080Ti needs a fully working memory controller and probably almost as many CUDA cores as a 3090. I can't imagine there are many chips that pass as a 3080Ti that couldn't also pass as a 3090 instead. Unless they are constrained by the GDDR6X memory it makes no sense.",
      "What a wild ride, when the cards came out and the 3080Ti was “around the corner” with 20 GB rumored memory for $1000 I felt a bit of buyers remorse buying my MSRP 3080FE. \n\nOh how times change",
      "8gb on 3070ti you got to be kiddin right? Thats terrible",
      "The way things are going..I hope my 3080 last me a good 10 years..",
      "The 3070 Ti specs are also quite unclear to me... I was hoping for a card with somewhat higher VRAM than the 3070 to be a bit more future-proof, but for 600$ MSRP the card would be too close to the 3080, unless the clock frequency is higher than for the 3070.",
      "There seems to be a small crowd that considers more memory necessary for future proofing. Nvidia can capitalize on that. They can charge more than it’s worth because people think that extra memory is worth more than it is.",
      "Don't worry, the Ti has had a \"release date\" about 5 times now, I'll believe it when NVIDIA tells me otherwise - not videocardz every other day to fish more ad revenue.",
      "It’s the first time in all these decades I’ve just taken an indefinite break from PC building, I’m not even following what’s going on, what’s releasing, because I know most of it is a fairy tale in all practical terms. I *love* following PC hardware developments, it’s been a daily part of my life since age 13. Recently? Barely paying attention to any of it. Hope it gets back to reasonable at some point in the near future",
      "Zero hype for e card that I can't buy.",
      "edited by user using PowerDeleteSuite.",
      "Miners can't wait to buy up all the stock within 0.0001s from launch.",
      "Suggested prices doesn't matter anyway. We will not know its real price until someone checks its hashrate."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "high",
    "matched_keywords": [
      "rtx 3080",
      "3080",
      "3080 ti",
      "rtx 3080 ti"
    ],
    "title": "RTX 3080 Ti Asus Tuf Gaming Thermal Pads Replacement From asus Support source",
    "selftext": "Hello anyone wondering what is the official right size for the Asus rtx 3080 Ti tuf Gaming 12Gb \n\nI got the answer directly from Asus Support ",
    "comments": [
      "nice but why not just use putty",
      "It is very messy and hard to replace.",
      "What is putty ?"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "high",
    "matched_keywords": [
      "rtx 3080",
      "3080",
      "3080 ti",
      "rtx 3080 ti"
    ],
    "title": "Custom-Cut EVGA RTX 3080 Ti XC3 20 W/mK Thermal Pads + 14W/mK CryoFuze Paste Replacement Kit",
    "selftext": "Hey everyone, I just finished building a thermal pad kit for the EVGA 3080 Ti XC3 using high-quality XPC T20 20W/mK pads. \n\nThe kit includes both front and backplate sizes + Cooler Master CryoFuze 14W/mK paste.\n\nAvailable on eBay in case it helps someone avoid the sizing hassle:  \n\n🔗 [https://www.ebay.com/itm/236073798070](https://www.ebay.com/itm/236073798070)",
    "comments": []
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "high",
    "matched_keywords": [
      "rtx 3080",
      "3080"
    ],
    "title": "RTX 3080 10GB OR RTX 4070 Ti",
    "selftext": "help",
    "comments": [
      "If money isn't an issue here then the 4070 Ti of course.",
      "4070 super is easily better fps per dollar compared to the 4070 ti super",
      "As they say on HUB \"It depends\" on the cost, display resolution/refresh/cpu/use case.  Obviously a 4070 Ti is going to be faster and provide 12GB of VRAM compared to 10GB, however if it costs 80% more for 17% better performance is that really worthwhile?",
      "You’re the one that made the choice 3080 or 4070ti…",
      "Used 3080 honestly or just wait for the 5 series. You don't need a 4070ti. My 3080 runs almost anything I need, and it will be traded in for either 5 or 6 series when I upgrade the entire PC. Right now it does all the work and I'm totally fine playing backlog and shitloads of other games.",
      "UB is well known to be biased garbo.",
      "I say just go for a 4070ti if you can afford it. \n\n\nThe 3080 is hard to come by brand new and you would be gambling in the used market.\n\nPrice to performance ratio becomes irrelevant when you can't play the games in the image quality and resolution that you want.",
      "It objectively is. Saying \"no\" won't change that lmao",
      "https://www.tomshardware.com/reviews/best-gpus,4380.html\n\n4070 Super is the best price:performance for now. The downside is the low RAM.",
      "17% According to [Techpowerup](https://www.techpowerup.com/gpu-specs/geforce-rtx-3080.c3621)",
      "Used 3080s can be had for $300-350. It's a way better deal.",
      "Just got the 4070ti Super and it’s a fantastic card. Found the Asus TUF model for $780 on Amazon though it looks like it’s normally around $800.",
      "Look for a 4070S",
      "Likely because the 3080 is significantly cheaper. I got an entire computer with a 3080 in it for $760. (Used, of course.)",
      "4070 ti. Go new",
      "Well ofc. RTX 4070Ti... Is this somekinda trick question?",
      "I have a 3080 10gb, I would trade it for a 4070 Ti. DLSS Framegen, lower power draw, and most importantly is more VRAM.\n\nUnless there is a huge price difference the 4070 Ti is the obvious choice.",
      "4070ti",
      "50 series coming out soon.. probably worth waiting at this point",
      "Honestly, the 40 series seems much better compared to my previous 3080. Ray tracing performance, dlss 3.0 and efficiency as well as thermals are all much better."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "high",
    "matched_keywords": [
      "rtx 3080",
      "3080",
      "3080 ti",
      "rtx 3080 ti"
    ],
    "title": "RTX 3080 Ti = Monster",
    "selftext": "",
    "comments": [
      "Can't wait to to see the $2500CAD price tag at release and not be surprised.",
      "Is this your first graphics card launch? Nvidia never teases anything until the actual event is announced and everything comes from rumors until then; I wouldn't expect anything official until september rolls over (if they indeed launch on september).",
      "That's when I :\na) keep my 1070 and down grade to 1080p monitor or \nb) get a console",
      "They wont make that mistake again :P",
      "Especially the 1080ti",
      "Given sales of their last gen cards weren't great at launch, the economic downturn, and new consoles, it seems unlikely we'll see a significant price hike... But who knows it's Nvidia lol",
      "Every Ti has always been a \"monster\".",
      "It had 11. \nWhich is makes it weird the 3080ti only has +1GB after 3 years.\nI guess they feel its enough?",
      "I’m sure a lot.  $500-$600 for a console vs $700 just for a gpu...it’s gonna be an easy decision for a lot of people most likely.",
      "The 10900K doesn’t run as hot as the 9900K, watch Linus’s video on it.",
      "I hate that everyone is relying on  rumors and leaks while nvidia remains silent on specs and pricing.\n\nAt this point, I'd be ecstatic if we get a tease of an official announcement at least. Even if it's a month from today.",
      "That makes the RTX 3080 Ti the top card from [this leak](https://videocardz.com/newz/rumored-geforce-rtx-3090-and-rtx-3080-specifcations-emerge) rather than the Titan, with slightly faster memory and only 12 GB?\n\n21 TFlop would hopefully put it at least 50% better than the 2080 Ti, which makes that TimeSpy result look a lot like the 3080.",
      "10900K: Am I a joke to you",
      "Fake SKU imo no way they'll do full core count with 12GB for the 3090/Titan. Most leaks by Kopite and Hardware leaks and others show 24GB with the all cores enabled.\n\nEDIT: Amended, no full core count with 12GB.",
      "12GB of vram was way ahead of it's time. Such a great card",
      "And so will the price. Monstrously high.",
      "DLSS 2.0 doesn't mean much if only 5 games adopt it.",
      "That was mid-way through the console life-span though. And with each console generation, they get closer to PCs.",
      "The 2080ti is a monster of price :)",
      "Gotcha. Rumors start getting more and more real the closer we get, but don't expect them to be 100% accurate either, so if you don't want to deal with it, then ignore them until the event date is set."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "high",
    "matched_keywords": [
      "rtx 3080",
      "3080"
    ],
    "title": "[Optimum Tech] RTX 3070 Review vs. RTX 3080, 2080 Ti - $499 4K Gaming",
    "selftext": "",
    "comments": [
      "Hooo boy, this launch is gonna make the 3080 one look smooth, I guarantee it.",
      "TLDR - Essentially the same as a 2080ti. He calls it an excellent value at $500 and notes that at FPS/$ it’s even a slightly better value than the 3080 at 4K.",
      "eh, calling it a 4k card is reasonable but this is really just the 1440p no questions asked card. I would not use this on a 4k setup unless you greatly prefer resolution to fps",
      "I'm expecting these to sell out just as fast if not faster than the 3080s did",
      "Because the 30xx series cards are purely theoretical lol",
      "Maybe off-topic but Optimum Tech is my favorite PC component reviewer by far. No click-baity title or thumbnail. Fantastic production and he gets right to the point.\n\nEdit: grammar",
      "Seems much better to review the 3070 as a 1440/144Hz GPU, can't imagine anyone wanting a massive downgrade to 60Hz to run this at 4K.\n\nEdit: The only 'concern' I saw was the 1% lows in some of the benchmarks, like being significantly below the 2080Ti. This might get better with driver tweaks though.",
      "If they had 500k notifications for the 3080/3090, there will probably be at least a million during the first week.  Lower price = larger market",
      "I believe he said the FPS/$ value is better for the 3070 at 1440. He said something like 4K is where the 3080 stretches it’s legs and becomes worth it",
      "Yep 1440p/144Hz perfection.",
      "Nobody was expecting 3070 to massively outperform the 2080ti. Having it on par is enough to call it a 2080ti killer considering the MSRP.",
      "If you go to 3:46 and you think whatever garbage you just wrote is still correct id suggest new glasses or a new brain.",
      "Looks like an exceptional 1440p card. Awesome time to be a gamer (if you can even get one of these lol)",
      "2080s-> 3070 doesn’t sound like a big upgrade. You should save more for a 3080",
      "Instead of selling out in 0.1 seconds it'll sellout in 0.05.",
      "Ah yes, the Aussie ITX master. This GPU will be one to see in as small as space as possible.",
      "People like eeehhh 2080Ti score is 16768 and the RTX 3070 benchmark score is 16767 that's definitely not an RTX 2080Ti killer.",
      "Hence why you better be f5ing not to make an order but to get into the queue asap.",
      "Yes they have - I was joking. But there are apparently severe supply issues. There is essentially no inventory anywhere and haven’t been for multiple weeks. And in most cases it’s not like stores are getting them and then selling out - stores just aren’t getting them.",
      "Ok you’re actually mentally challenged. Nvm this is a waste of time."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "high",
    "matched_keywords": [
      "rtx 3080",
      "3080",
      "3080 ti",
      "rtx 3080 ti"
    ],
    "title": "NVIDIA GeForce RTX 3080 Ti to launch in January 2021 - VideoCardz.com",
    "selftext": "",
    "comments": [
      "You won't be able to buy it until April",
      "Perfect we can have another card that's available no where.",
      "2077",
      "What year?",
      "Waiting on a graphics card for so long changed my perspective on these things. 10% more performance for 30% more price is just not justifiable to me. I’d rather wait for 3080/6800xt and upgrade those sooner rather than later instead.",
      "Nvidia  has lost their marbles. There is not one positive comment about this  card on the internet, and even if the 3070/3080/3090 weren't so hard to  find, this would still be very pointless. This not necessary to compete  with AMD's offerings and is essentially Nvidia competing with itself, as  they did repeatedly over the last two years already.\n\nThis absolutely will take away capacity to make other cards, which Nvidia already seems to be struggling with.\n\nI  personally felt Nvidia should have held off and launched the 3xxx very  late this year or early next year as it is, they clearly launched it too  soon. And the \"we didn't anticipate the demand\" thing is a crock of  shit.\n\nI'm waiting for them to  release a 3090ti in February now just to piss off the 3090 owners. And  then in March release Super versions of everything. Then release some  2660 cards also in ti and super variants in April.\n\nPare  the damn skus down, make sure the yield is high enough to actually sell  the fucking things, and then put them to market. Nvidia is turning into  Intel, they are so bloated and arrogant that they are making rookie,  amateur mistakes and basically begging AMD to step in and be the \"good  guy\" again and sweep a huge chunk of their market away from them.  Nvidia's market position is way more fragile than they believe it to be  and they just don't care.\n\nSeriously, this is ***mind bogglingly stupid to release in January.*** The existence of this in like, a year, maybe next fall, could possibly make sense. But right now this is just *stupid*.",
      "What’s funny? He’s serious. /s",
      "Ahahah. Thanks for the laugh",
      "Dope cyberpunk might be out by then too",
      "I come from the future CyberPunk 2777 has been delayed.",
      "I wanted a 3090. I wanted a 3080. At this point im going to walk into microcenter and look for all 3 variants. If my only option is the 6900xt then i guess im goin amd...",
      "I see, another one of those Trading Graphics Card.",
      "if I see that the 6900xt is in stock I will go for it. Nvidia has been pretty trash lately with how they are releasing these cards might as well give amd a try.",
      "Bought my card for 699. So can't complain.",
      "I doubt we get a new series by September, unless it's just a refresh. Nvidia usually go 1.5+ years between series. AMD said they will try to go with an annual release cycle moving forward, but I'm not sure how feasible that is. It takes several months for supply to actually start meeting demand. I can't see them killing production on a series just when sales have picked up. For example, let's assume Ampere supply doesn't normalize until February. That would leave just 7 months for sales. My guess is new series in Q1-Q2 2022.",
      "It’ll be overpriced for most games, but still excel at non gaming tasks and games that require more memory more bandwidth",
      "Nice, more SKUs. Just what we need.",
      "There will always be something better and faster. In 3 years when my (non existent as of now) 3080 will be choking, I'll sell that and upgrade to whatever is new then.  Is the 3080 objectively a bad card? No, cus it plays what I want at pleasing frame rates and resolutions. Its fantastic for anything 1440p and pretty good at 4k60 for cinematic games as well, and can easily do over 144 fps in competitive esports titles. When newer games come out that cause this to suffer, I'll think about all this, then. For now, its like counting your chickens before the eggs hatch. They still barely have enough cards to meet demands now, I dont think this will be available to buy before November next year, even if they release it in jan.",
      "Damn if this is true, then EVGA buyers we are lucky. This would be within everyone's step up timeline",
      "Wild to see Nvidia launching another card when their 3080 & 3070 are still impossible to get. \n\nAnyone have any insight into the 6800XT availability? I've been Nvidia my last 3 GPU's, but I've been trying to give Nvidia 1000$ for almost two months and I still don't have a god damned card lol. \n\nWay she goes."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "high",
    "matched_keywords": [
      "rtx 3080",
      "3080",
      "3080 ti",
      "rtx 3080 ti"
    ],
    "title": "A Plague Tale Requiem - RTX 3080 Ti - 4K Ultra DLSS Comparison",
    "selftext": "",
    "comments": [
      "Well it is kinda unfair to compare images without motion. DLSS biggest issue is the motion blurriness and ghosting. \n\nBut yeah when you stop dlss is sooooo good.",
      "Great comparison, but maybe upload those pictures to [https://imgsli.com/](https://imgsli.com/) or [https://slow.pics/](https://slow.pics/), otherwise it's pretty hard to compare them properly.",
      "Very good call! Have done this now - [https://imgsli.com/MTQwMjQ0/0/4](https://imgsli.com/MTQwMjQ0/0/4)\n\nThanks!",
      "quite literally do not see any difference",
      "This game is an absolute masterpiece visually.\n\nI would love to see the fabled RT update. Right now it's already the best looking game I've played this year, with RT it would be just insane (and probably hard to run)\n\nEDIT: Finished the game, it's not just visual it's a masterpiece period. you HAVE to play it (after its prequel Innocence though) of you like narrative heavy games and aren't afraid of rats lol",
      "Never discount the Performance and Ultra Performance modes in new games, it might look better than you expect.",
      "I've found this to be the case as well. Performance mode looks exceptional from a normal viewing distance in some games.",
      "Much better link. I usually pay at DLSS Balanced mode, less shimmering. But, i do play at 1440p 165hz, so not as demanding vs 4k.",
      "Anything above ultra performance seems to look good tbh! Running with Quality as a 60+ experience is good enough for these kinds of games for me\n\nDefinitely much more demanding than innocence which generally stayed at or above 90-100 fps in most areas",
      "Were you getting this fps further into the game? Most bench marks I’ve seen of Requiem have been at the very start of the game.\n\nI have a 3080 and though I was fine but about 40 mins in you reach the city and my fps absolutely tanked, it did so for the next few chapters.",
      "It does more than just a aa pass.\n\nIt imagines pixels and adds those.\n\nExamples in warthunder text on planes actually look better and sharper with dlss.\n\nNioh 2 got some actual reflection bugs fixed with dlss.\n\nWhat you think of is Fsr with taa.\n\nOr nvidia nis + aa.",
      "I'd argue that DLSS Balanced is better than DLSS Quality since 2.40 came out. \n\nWhy? DLSS of all types seems to have a very slight blurring effect on the finest details, even at Quality Mode in 4k. However the blurring effect on fine edges seems to diminish it's increase rate each step down. \n\nDLSS also gives you some motion ghosting effects and fizziness on multiple interweaving moving objects. \n\nIf you are going to implement DLSS Quality for a 15% FPS gain, you also impose these costs. DLSS Balanced gives you slightly more of these effects but with about 30% more FPS and typically fewer memory bandwidth related 1% Lows (due to lower internal rez). \n\nIn mathematical terms, DLSS of all types have multiple fixed costs with some form of logarithmic increase. In the sense that DLSS Quality has 15% more FPS for 15% more negative effects. DLSS Performance 30% more FPS for 25% more negative effects, etc. If we had a DLSS slider of sorts, I believe this would be more easily shown.",
      "Just run it on High instead of Ultra. Pretty good performance bump without significant visual degradation. You can pair that up with DLSS if you want.",
      "Performance throughout the entire game was pretty consistent in my playthrough. Varies quite a bit from scene to scene (sometimes I'd be 60-80 range, other times 100+), but it doesn't get worse later on if that's what you're afraid of.",
      "Why does DLSS influence the AO so much? It's the biggest difference. If it wasn't for that it'd be hard to tell them apart in stills.\n\nIn Ultra Performance it's as if it's disabled entirely.",
      "With u there",
      "Still no RT for now. The game is still stunning to be fair even without",
      "You can fully turn it of, at least on pc",
      "Original picture is too sharp because  game devs intentionally pushes the mip bias in the negative to help countering the blur added by temporal anti aliasing and DLSS\n\nnegative mip bias makes thing grainy and shimmery but it helps with low quality textures.\n\nthis is why thoses screenshots comparaisons are stupid.\n\nIf you want to compare this,  it's needed to force mip bias at 0 at a driver level to have the correct amount of sharpness on non anti aliased scenes.",
      "but it's available, just clamp negative bias and force anisotropic filering in nvidia control panel. (and never use this option with TAA/dlss)"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "high",
    "matched_keywords": [
      "rtx 3080",
      "3080",
      "3080 ti"
    ],
    "title": "GeForce RTX 5080 Review Megathread",
    "selftext": "# GeForce RTX 5080 Founders Edition reviews are up.\n\nhttps://preview.redd.it/0b57tcm6vxfe1.jpg?width=3840&format=pjpg&auto=webp&s=ad230615d607bf9dd8a84e9abf0861c159b5cc42\n\n# Below is the compilation of all the reviews that have been posted so far. I will be updating this continuously throughout the day with the conclusion of each publications and any new review links. This will be sorted alphabetically.\n\n# Written Articles\n\n# [Babeltechreviews](https://babeltechreviews.com/rtx-5080-founders-edition-review/)\n\n>Upgrading to the new RTX 5080 from a 30 series GPU—or for those who simply demand peak performance—presents a clear decision. The price-to-performance ratio of the RTX 5080 is impressive, especially when viewed against the backdrop of NVIDIA’s previous generations or its current competitors. There is a uplift gen-over-gen of around 7-15% on average in raw power, when you consider DLSS 4 and its incredible uplift for max settings its really exciting. DLSS 4 is not perfect, however, and it cannot replace raw power for enthusiasts. The RTX 5080 also carries a higher price tag, albeit lower than the RTX 4080’s MSRP at $200 less. This is much better and the value it offers in enhanced performance, especially with advancements in ray tracing and AI-driven capabilities like DLSS 4, justifies the investment in our opinion.\n\n>We understand the inclination to wait for the more budget-friendly 70 and 80 class GPUs from the Blackwell generation, as these models often strike a balance between cost and performance, catering to the needs of the average gamer. However, for those seeking the pinnacle of current gaming technology, the RTX 5080 is unparalleled in its price range and class. It’s designed to deliver top-tier performance for years to come, making it an investment in future-proofing your gaming or creative setup. Ultimately, the decision to invest in such a high-end GPU depends on your specific needs and budget, but for those who prioritize leading-edge technology, the RTX 5080 is a wonderful new addition to the market.\n\n# [Digital Foundry Article](https://www.eurogamer.net/digitalfoundry-2025-nvidia-geforce-rtx-5080-review)\n\n# [Digital Foundry Video](https://www.youtube.com/watch?v=k7hDtGh0wIo)\n\n>See Stickied Comment\n\n# [eTeknix Article](https://www.eteknix.com/nvidia-geforce-rtx-5080-founders-edition-review/)\n\n# [eTeknix Video](https://www.youtube.com/watch?v=CKhoBBX2h00)\n\n>See Stickied Comment\n\n# [Guru3D](https://www.guru3d.com/review/review-nvidia-geforce-rtx-5080-founders-edition-reference/)\n\n>Depending on the game, performance improvements can vary widely. On average, you can expect a 10 to 25 percent boost in traditional rendering performance coming from a 4080S. The more effective part is NVIDIA's heavy investment in AI, deep learning, and neural shading. When we tested DLSS4 with frame generation enabled at 4x, the performance is simply incredible. However, the pressing question arises: will consumers be ready to invest in AI-assisted rendering? The answer isn’t clear yet, but time will tell. One thing is certain—DLSS4 works wonders. The performance metrics shown are a testament to its power. This GPU is quintessential for gamers using Ultra-Wide HD, Quad HD, or Ultra HD monitors, delivering a great visual experience with framerates to match. But yes, overall from the shading rasterization performance, the card is somewhat lacklustre\n\n>The GeForce RTX 5080 will speak to a lot more people compared to the $1999 costing RTX 5090. However, you'll get far less performance. Compared to the RTX 4080/4080 Super the overall rasterizer performance is a notch faster, but not heaps, and that is today's most disappointing news. NVIDIA invested heavily in the transistor budget for AI, the new generation of products places a strong focus on Raytracing, Neural Shading and of course DLSS4 with MFG (Multi Frame Generation). The combination of these together can easily bring in a fact x3 or x4 (and sometimes faster) result. Whether or not the end user is ready for artificially created frames in this degree we doubt, but as far as NVIDIA is concerned, it's the future. We do hope to see more backwards compatibility with DLSS 4 so that older games will get this new tech included as well. We stated this in the RTX 5090 review already, we wonder if the balance hasn't shifted towards AI assistance a bit too much. For the end-user change and thus a move away from the traditional render engine it will be a tough pill to swallow. The potential is huge though. For example, games like Microsoft Flight Simulator 2024, when combined with 4.0, could achieve over 150+ FPS at Ultra HD. Similarly, Cyberpunk in UHD did \\~180 FPS, that's with raytracing enabled. The recent move towards Ray reconstruction also moved NVIDIA into a new sweet spot. All features and performance combined with new technology like DLSS4 really make the Series 5000 from NVIDIA compelling. Other downsides for today's tested product have to be the high energy consumption and price level. In the end whatever we write, or how we feel about the AI-driven content doesn't matter. It's you guys that make the decisive purchase or not which makes this product series a success. The product is a notch faster than the previous generation if you look at that traditional render engine, however looking just that alone is not enough. With a whole lot of extra AI driver functionality that comes along with it, boosting your game FPS towards very high levels in the highest resolutions is possible with the likes of DLSS4 and MFG. Realistically though an RTX 4000 card with DLSS3.5 and Frame Generation will get you plenty of AI-driven performance as well. The founder card itself is lovely in design, it looks nice and it is reasonably silent. The power usage is somewhat icky. If you're coming from the RTX 3000 series or lower products, then this might be an attractive enough buy, but I think many of you expected to see RTX 4090 performance, or even slightly better. For that, you'll need a premium AIC OC version with a premium price. \n\n# [Hot Hardware](https://hothardware.com/reviews/nvidia-geforce-rtx-5080-blackwell-review)\n\n>Last week’s launch of the [GeForce RTX 5090](https://hothardware.com/reviews/nvidia-geforce-rtx-5090-review), crowned a new king in the gaming GPU market. It’s pricier and consumes more power than its predecessor, but the RTX 5090 was performance leader across the board. The GeForce RTX 5080 is also technically an upgrade over the RTX 4080 in virtually every way, but its power consumption is in the same ball park and its introductory $999 MSRP is actually somewhat lower. That should be a great story, but the GeForce RTX 5080 is only a mild upgrade over its previous-gen namesake for gaming, unless you can turn on all DLSS features with multi-frame generation. It does, however, offer more of a boost with AI and content creation workloads.\n\n>When the GeForce RTX 4080 launched, it [crushed the GeForce RTX 3090](https://hothardware.com/reviews/nvidia-geforce-rtx-4080-gpu-review) with many workloads. That’s not the case with the GeForce RTX 5080, but that was obviously not NVIDIA’s intention. The GB203 GPU powering the card is actually smaller than the AD103 on the RTX 4080, and it is manufactured on the same process node.\n\n>NVIDIA’s focus here was obviously on architectural advancements and AI-powered rendering. When you factor in the capabilities of RTX Neural Rendering and DLSS 4 with multi-frame generation, the RTX 5080 separates itself from previous-gen offerings and offers clearly superior performance and technology. And therein lies the rub. Traditional raster will likely be less of a focus for the industry moving forward. NVIDIA is looking to the [future with Blackwell](https://hothardware.com/reviews/nvidia-rtx-blackwell-architecture-overview), and they're not alone, as both AMD and Intel are on this path as well . As game developers incorporate more of the technologies available in the RTX 50 series, its performance profile relative to previous-gen GPUs will change. Though 75 titles will offer support for DLSS as of tomorrow (if you factor in the DLSS override controls in the NVIDIA app), we suspect revisiting the performance of these cards in a few months may tell a different story. AMD and Intel may also have some fresh competitors in the mix too by then.\n\n>That said, most consumers buy products for what they offer today, and not what they may potentially offer in the future. If you’re considering a card in the GeForce RTX 5080 FE’s price range, it is the current best option on the market. It’s faster and has more advanced features than a GeForce RTX 4080 and also AMD’s current flagship offering. It is not a significant upgrade over the GeForce RTX 40 series for gamers though. For owners of GeForce RTX 30 series cards (or older), however, the GeForce RTX 5080 will offer a massive boost.\n\n# [Igor's Lab](https://www.igorslab.de/en/nvidia-geforce-rtx-5080-founders-edition-im-test-geforce-rtx-4080-ti-mit-blackwell-genen/)\n\n>The RTX 5080 is particularly impressive in Ultra-HD resolutions (3840 x 2160 pixels) with activated ray tracing and patch tracing effects. Thanks to the 10,752 CUDA cores, 336 fifth-generation Tensor cores and support for DLSS 4, the card achieves exceptional frame rates in graphically demanding scenarios. While the RTX 4080 Super lags behind the RTX 5080 in most benchmarks, the new card manages to deliver a smoother frame rate and better stability through the integration of multi-frame generation (MFG). This is certainly advantageous for those who believe they need something like this.\n\n>The improved ray tracing performance, made possible by 84 fourth-generation RT cores, is particularly evident in games such as *Cyberpunk 2077* and *Alan Wake 2*. With ray tracing enabled, the RTX 5080 also benefits from advanced ray reconstruction functionality, ensuring outstanding image quality in even the most demanding scenarios. Despite this impressive performance, some limitations can be recognized: In native 4K with maximum settings, the card may still remain at its performance limit, especially at high frame rates and intensive lighting simulations. Apart from these new features, however, the GeForce RTX 5080 remains a classic sidegrade and can hardly score with significant additional performance. Everyone has to decide for themselves whether they are disappointed by this. For my part, I had actually hoped for 20 percent.\n\n>The thermal design of the RTX 5080 is based on a double-sided flow-through cooling system that directs cool air through the card and efficiently dissipates heated air. During operation, the GPU temperature remains stable even in intensive gaming scenarios, with the card reaching a maximum temperature of just under 76 °C. The memory temperatures benefit from the optimized power supply via separate power rails, which ensure an even power supply. This minimizes thermal fluctuations and ensures that the memory area remains stable even under high loads. Thermal analysis using the Optris PI 640 shows homogeneous heat distribution, with hotspots such as the GPU and voltage converters being effectively cooled.\n\n>The noise development of the RTX 5080 is heavily dependent on the fan speed. When idling and at moderate speeds, the card remains pleasantly quiet, which is due to the low-vibration fan mounting and the aerodynamic optimization of the fan blades. Under load, however, the noise increases noticeably and reaches values of up to 38 dB(A). A characteristic humming at around 200 Hz was detected in the tests, which is caused by resonances of the fans or the voltage converters. This noise is particularly noticeable at certain fan speeds, but is not consistently audible.\n\n# [KitGuru Article](https://www.kitguru.net/components/graphic-cards/dominic-moass/nvidia-rtx-5080-review-efficiency-gains-but-a-performance-letdown/)\n\n# [KitGuru Video](https://www.youtube.com/watch?v=uKIwmW5j6oc)\n\n>Only consider the RTX 5080 if you buy into Nvidia’s AI-fueled vision of the future\n\n>DLSS 4’s Multi Frame Generation feature must be seen (and felt) to be believed. On PCWorld’s Full Nerd podcast, we compared the leap from Single Frame to Multi Frame Generation to the leap from DLSS 1 to DLSS 2. When both technologies first came out, they showed promise but had plenty of rough edges. With DLSS 2, gamers agreed that Nvidia *nailed it*. And while it’s not quite perfect, Multi Frame Generation *nails it*. Once more gamers get their Dorito-stained paws on RTX 50-series cards, and are able to tool around with MFG in 75+ games and apps, I wouldn’t be surprised if all the furor over “fake frames” online dies down quite a bit. It’s a literal game changer.\n\n>But Nvidia is in trouble this generation if the masses *don’t* embrace Multi Frame Generation. Because when it comes to traditional gaming performance, the RTX 5080 is no game changer.\n\n>It’s a pretty damned terrible generational upgrade, actually. Eking out a mere 11 to 15 more render performance than the RTX 4080 Super, at the same price, at a higher power draw, isn’t compelling whatsoever. It can’t come anywhere close to last gen’s 4090. If you don’t like AI-generated frames — maybe you’re sensitive to latency, or you focus on competitive games, or you loathe the idea of AI frames potentially introducing visual glitches — I’d even go so far as to suggest picking up a 4080 Super to get roughly comparable performance for less cash.\n\n>Remember: The [RTX 3080 beat the RTX 2080 by *60 to 80 percent*](https://www.pcworld.com/article/393472/nvidia-geforce-rtx-3080-founders-edition-review.html) when it launched earlier this decade, and it did so for just $700. Then [Nvidia jacked the price of the vanilla RTX 4080](https://www.pcworld.com/article/1379747/nvidia-geforce-rtx-4080-tested-5-things.html) by *$500 dollars* for a 30 percent performance increase, leading to poor sales rectified only by the launch of the 4080 Super at $999. With the RTX 5080 barely outpacing that, the RTX 5080 would have been immensely more compelling at a couple hundred dollars cheaper. Two generations after the RTX 3080, Nvidia has truly devastated the xx80 tier’s value in recent memory. Upgrading from the 3080 to a 5080 will only get you about 40 to 45 percent more performance, for a price tag that’s 42 percent higher. That’s not progress.\n\n>If Nvidia didn’t have MFG in tow, this would’ve been a *scathing* review for the RTX 5080 itself. But boyyyyy does DLSS 4’s new tricks feel great. Multi Frame Generation makes *Star Wars Outlaws*, a notoriously janky game, feel just as good as *Doom 2016*. *Cyberpunk*’s neon Night City feels so much more *alive* when you’re racing around at a buttery-smooth 240Hz+, or over 150fps even with the game’s nuclear RT Overdrive Mode active.\n\n>And that’s the promise Nvidia needs gamers to buy into for the GeForce RTX 5080 — heck, perhaps this entire RTX 50-series generation. Are you willing to embrace “fake frames” and dip your toes into experiences that aren’t currently possible with traditional rendering alone? If so, this GPU provides enough grunt to fuel those adventures in 4K and 1440p alike.\n\n>If not, the RTX 5080 is one of the most disappointing GPU releases in a long time. It’s probably best to save your cash.\n\n>Me? I’m into the vision. But I wish Nvidia imbued the RTX 5080 with more raw rendering firepower, so it could be a decent upgrade even for “fake frame” haters. Nvidia didn’t, alas — so now the RTX 5080’s future hangs in the balance of those 75 DLSS 4 games working correctly at launch.\n\n>If DLSS 4 and Multi Frame Generation perform like a champ when that wider availability hits, it could usher in a new era of smooth, AI-supercharged performance. But if DLSS 4 winds up plagued by visual artifacts or other issues once the floodgates open, it could instead set off an explosion of “fake frames” memes and sign a death warrant for the otherwise ho-hum RTX 5080 — perhaps even the rest of Nvidia’s 50-series lineup.\n\n>The GeForce RTX 5090 can stand alone on its own merits, but the RTX 5080 is all-in on DLSS 4. All that’s left us to see is where the chips fall.\n\n# [LanOC](https://lanoc.org/review/video-cards/9135-nvidia-rtx-5080-founders-edition)\n\n>For performance, it will depend a lot on what your goal is for the card on whether you would say it did well in testing or not. Nvidia markets the card as a 2k or 1440p card and at that resolution and at 1080p it did extremely well, outperforming last generation's flagship RTX 4090. At 4k I would still say it did very well, but on average the RTX 4090 does edge back in ahead of it in our tests. The RTX 5080 has 16GB of memory and a smaller memory interface than the RTX 4090. It does have faster memory which makes up the difference a lot, but that does make a difference at 4k in some tests. That said, if you haven’t experienced DLSS 4 with the improved transformer models making significant improvements in the visual quality and frame generation x4 giving mind blowing performance, I would take that over the 8 extra FPS at 4k. Not only do you see a lot of those improvements even in CPU-limited situations, but you can see 300-500% performance improvements over not using DLSS at all. I didn’t run into as many of the bugs as I saw when testing the RTX 5090, but OpenCL-based workloads were still a problem but Nvidia is aware and working on it.\n\n>At the end of the day though, it always comes down to pricing. The RTX 5080 Founders Edition has an MSRP of $999. That is $200 less than the RTX 4080 launched at but is $300 more than what the RTX 3080 launched at. It’s also half of the price of the new RTX 5090. More importantly, how does it compare to other cards with current pricing? For that, I put the graph above together that takes every card I’ve tested’s Time Spy Extreme GPU Score and divides it by its current price as well as its launch MSRP. For current pricing, it is the lowest available price on PCPartPicker and it is interesting to see how much pricing and card availability has changed from last week when the performance of the RTX 5090 was shown. The RTX 5080 Founders Edition is sitting in the middle of the pack for value right now but there aren’t any cards faster or even near it in performance on the chart. With all of the talk on how it compares with the RTX 4090 for example, the only 4090’s you can currently get are $2598 or more. I wouldn’t call it a value, but if you are looking for high-end 1400p or 4k performance and the RTX 5090 isn’t in your budget this is the clear choice, that is assuming you can find these anywhere near the launch price once they hit stores.\n\n# [OC3D Article](https://overclock3d.net/reviews/gpu_displays/nvidia-rtx-5080-founders-edition-review/)\n\n# [OC3D Video](https://www.youtube.com/watch?v=k-6Dw4qsGhA)\n\n>As we said in our introduction, the Nvidia RTX 5080 Founders Edition is almost famous before it’s appeared. Such is the incredible reputation of its similarly numbered forebears, the expectation is massive. The GTX 280 was launched 17 years ago, and apart from a couple of notable missteps – the red hot GTX 480 for example – they’ve all been stellar. It’s not a coincidence that when Nvidia introduced the RTX series of cards the top model was a RTX 2080 Ti. The name has cachet.\n\n>Clearly the RTX 5090 follows the recent trend where the 90 card is the flagship, money-no-object option. The x080 cards are for those with deep pockets, but not unlimited ones. Or perhaps those for whom gaming is your primary thing and so spending a little more is worthwhile. That’s where the Nvidia RTX 5080 Founders Edition comes in. We’ve yet to see performance figures for the guaranteed massive selling RTX 5070 and RTX 5070Ti models. That leaves us with either seeing how close the Nvidia RTX 5080 can get to the big RTX 5090, or how much better than the Ada Lovelace cards it is.\n\n>If the RTX 5090 was jaw-dropping, the RTX 5080 continues that good work. The next generation of cores which festoon the tiny PCB really put the work in to give you smooth performance. We know that the big ticket item is multi-frame generation, but even in pure rasterised benchmarks the Nvidia RTX 5080 Founders Edition proves a big upgrade on the previous model. If you’re just after the latest and greatest at an enthusiast price point, you can almost stop reading here.\n\n# [PC World Article](https://www.pcworld.com/article/2591060/nvidia-geforce-rtx-5080-review.html)\n\n# [PC World Video](https://www.youtube.com/watch?v=YaZT5OuW6v0)\n\n>DLSS 4’s Multi Frame Generation feature must be seen (and felt) to be believed. On PCWorld’s Full Nerd podcast, we compared the leap from Single Frame to Multi Frame Generation to the leap from DLSS 1 to DLSS 2. When both technologies first came out, they showed promise but had plenty of rough edges. With DLSS 2, gamers agreed that Nvidia *nailed it*. And while it’s not quite perfect, Multi Frame Generation *nails it*. Once more gamers get their Dorito-stained paws on RTX 50-series cards, and are able to tool around with MFG in 75+ games and apps, I wouldn’t be surprised if all the furor over “fake frames” online dies down quite a bit. It’s a literal game changer.\n\n>But Nvidia is in trouble this generation if the masses *don’t* embrace Multi Frame Generation. Because when it comes to traditional gaming performance, the RTX 5080 is no game changer. \n\n>It’s a pretty damned terrible generational upgrade, actually. Eking out a mere 11 to 15 more render performance than the RTX 4080 Super, at the same price, at a higher power draw, isn’t compelling whatsoever. It can’t come anywhere close to last gen’s 4090. If you don’t like AI-generated frames — maybe you’re sensitive to latency, or you focus on competitive games, or you loathe the idea of AI frames potentially introducing visual glitches — I’d even go so far as to suggest picking up a 4080 Super to get roughly comparable performance for less cash.\n\n>If Nvidia didn’t have MFG in tow, this would’ve been a *scathing* review for the RTX 5080 itself. But boyyyyy does DLSS 4’s new tricks feel great. Multi Frame Generation makes *Star Wars Outlaws*, a notoriously janky game, feel just as good as *Doom 2016*. *Cyberpunk*’s neon Night City feels so much more *alive* when you’re racing around at a buttery-smooth 240Hz+, or over 150fps even with the game’s nuclear RT Overdrive Mode active.\n\n>If not, the RTX 5080 is one of the most disappointing GPU releases in a long time despite its prowess. It’s probably best to save your cash unless you’re on a card several generations old and don’t mind spending big for a big performance upgrade.\n\n>If DLSS 4 and Multi Frame Generation perform like a champ when that wider availability hits, it could usher in a new era of smooth, AI-supercharged performance. But if DLSS 4 winds up plagued by visual artifacts or other issues once the floodgates open, it could instead set off an explosion of “fake frames” memes and sign a death warrant for the otherwise ho-hum RTX 5080 — perhaps even the rest of Nvidia’s 50-series lineup.\n\n>The GeForce RTX 5090 can stand alone on its own merits, but the RTX 5080 is all-in on DLSS 4. All that’s left us to see is where the chips fall.\n\n# [Puget Systems (Content Creation Review)](https://www.pugetsystems.com/labs/articles/nvidia-geforce-rtx-5080-content-creation-review/)\n\n>Overall, the RTX 5080 is a solid GPU that provides good performance nearly across the board. However, following [our 5090 review](https://www.pugetsystems.com/labs/articles/nvidia-geforce-rtx-5090-content-creation-review/), we are somewhat disappointed by the relatively small performance uplifts over the RTX 4080 SUPER. In some places, the 5090 seemed to justify the price increase over the 4090 with staggering performance increases. For the 5080, the same price seems to get you basically just the same performance in many workloads.\n\n>In **video editing and motion graphics**, the RTX 5080 is about 5-10% faster than the RTX 4080 SUPER and 20-30% faster than the 3080 Ti. There were some standout areas, such as 3D performance in After Effects, with gains double those. We’re still waiting on finalized DaVinci Resolve results, but we are doubtful the 5080 will be a huge upgrade over a 4080 or 4080 SUPER, except perhaps with LongGOP media. Still, for new-to-PC users or those on even older cards, it offers a solid upgrade.\n\n>In **rendering applications**, the 5080 manages better, with a 10-20% lead over the 4080 SUPER and a 55% to 188% lead over the 3080 Ti. This is definitely a performance jump that may be worth upgrading for even from the 40-series card, and it offers a great value for those using older generation cards. However, there is still the lingering issue of compatibility and performance quirks, so we would recommend buying with caution or holding off for a bit before committing to a 5080 for a rendering system. We are currently [maintaining a list of known issues](https://www.pugetsystems.com/blog/2025/01/27/nvidia-geforce-rtx-50-series-known-software-issues/) in content creation applications that you can check in on to see when these are resolved.\n\n>NVIDIA’s new GeForce RTX 5080 is a great workhorse GPU that provides solid performance across the board and can handle most of the tasks you throw at it. In many workflows, it is only slightly slower than the RTX 5090, so it may end up being one of the better price-to-performance cards of this generation. If you are on a 30-series card or older, it offers a great upgrade, but less so for users on a 40-series card. Especially given the dwindling supply of those previous-generation cards, we expect the RTX 5080 to be an incredibly popular GPU.\n\n# [Techpowerup](https://www.techpowerup.com/review/nvidia-geforce-rtx-5080-founders-edition/)\n\n>At 4K resolution, with pure rasterization, without ray tracing or DLSS, we measured a 14% performance uplift over the RTX 4080 Super, 15% over the RTX 4080 non-Super. This is definitely MUCH less than expected and not nearly as much as what we saw last week from RTX 5090, which beat the RTX 4090 by 35%. Compared to the GeForce RTX 3080, the performance increase is 75%, which means NVIDIA missed the \"twice the performance every second generation\" rule. Last-generation's flagship, the RTX 4090 is 13% faster than the RTX 5080 and the new RTX 5090 flagship is 52% faster, but twice as expensive.\n\n>GeForce RTX 5080 is still faster than AMD Radeon RX 7900 XTX, Team Red's best GPU, by 15% in a pure raster scenario, much more in RT. AMD has confirmed that they are not going for high-end with RDNA 4, and it's expected that the RX 9070 Series will end up somewhere between RX 7900 XT and RX 7900 GRE. This means that AMD's new cards don't pose a threat to the RTX 5080, which might explain why we're not getting bigger performance improvements.\n\n>RTX 5080 is a good card for 4K gaming. With RT or Path Tracing enabled, some titles require that you use DLSS Upscaling / Frame Generation. The card is also great for 1440p gaming, to feed those high-refresh-rate gaming monitors.\n\n>NVIDIA is betting on ray tracing and Blackwell comes with several hardware improvements here. Interestingly, the RTX 5080 runs only 11% faster at RT than RTX 4080 Super—remember, we got +14% in without RT. It looks like this is partly due to the game selection. The games that show the biggest gains in our non-RT test suite do not support RT. Still, compared to AMD's Radeon RX 7900 XTX, the difference is massive—the RTX 5080 is 61% (!) faster than the RX 7900 XTX. On top of that, NVIDIA is introducing several new optimization techniques that game developers can adopt. The most interesting one is Neural Rendering, which is exposed through a Microsoft DirectX API (Cooperative Vectors). This ensures that the feature is universally available for all GPU vendors to implement, so game developers should be highly motivated to pick it up. AMD has confirmed that for RDNA 4 they have put in some extra love for the RT cores, so hopefully they can catch up a bit.\n\n>NVIDIA made a big marketing push to tell everyone how awesome DLSS 4 is, and they are not wrong. First of all, DLSS 4 Multi-Frame-Generation. While DLSS 3 doubled the framerates by generating a single new frame, DLSS 4 can now triple or quadruple the frame count. In our testing this worked very well and delivered the expected FPS rates. Using FG, gaming latency does NOT scale linearly with FPS, but given a base FPS of like 40 or 50, DLSS x4 works great to achieve the smoothness of over 150 FPS, with similar latency than you started out with. Image quality is good, if you know what to look for you can see some halos around the player, but that's nothing you'd notice in actual gameplay.\n\n>Want lower latency? Then turn on DLSS 4 Upscaling, which lowers the render resolution and scales up the native frame. In the past there were a lot of debates whether DLSS upscaling image quality is good enough, some people even claimed \"better than native\"—I strongly disagree with that—I'm one of the people who are allergic to DLSS 3 upscaling, even at \"quality.\" With Blackwell, NVIDIA is introducing a \"Transformer\" upscaling model for DLSS, which is a major improvement over the previous \"CNN\" model. I tested Transformer and I'm in love. The image quality is so good, \"Quality\" looks like native, sometimes better. There is no more flickering or low-res smeared out textures on the horizon. Thin wires are crystal clear, even at sub-4K resolution! You really have to see it for yourself to appreciate it, it's almost like magic. The best thing? DLSS Transformer is available not only on GeForce 50 series, but on all GeForce RTX cards with Tensor Cores! While it comes with a roughly 10% performance hit compared to CNN, I would never go back to CNN. While our press driver was limited to a handful of games with DLSS 4 support, NVIDIA will have around 75 games supporting it on launch, most through NVIDIA App overrides, and many more are individually tested, to ensure best results. NVIDIA is putting extra focus on ensuring that there will be no anti-cheat drama when using the overrides.\n\n>For $1000, there is no reason you should buy RTX 4080 or RTX 4080 Super now. AMD's Radeon RX 7900 XTX is $820, or 18% cheaper, but it's also 15% slower in raster, and 38% slower in RT. NVIDIA is also very strong in software features, the new DLSS Transformer model is a game-changer and DLSS 4 multi-frame-generation is a notable selling point, too. No way I would buy RX 7900 XTX at that price instead of RTX 5080—maybe if AMD drops the price considerably. Also, the way AMD is handling Radeon lately makes me wonder if their discrete GPU brand will still be around in two or three years. The upcoming RDNA 4 lineup will not target the top end of the market, so unless a miracle happens, RX 9070 XT won't be able to compete with RTX 5080, maybe RTX 5070 Ti, which is coming out soon.\n\n>If you already have a high-end GeForce RTX 40 Series card, then there is no reason to upgrade. You're just missing out on multi-frame-generation, the DLSS Transformer model is supported on all older RTX cards, too. On the other hand, if you're coming from GeForce 30, then suddenly you'll get to experience frame generation, which will make a huge difference for your gaming experience.\n\n# [The FPS Review](https://www.thefpsreview.com/2025/01/29/nvidia-geforce-rtx-5080-founders-edition-video-card-review/)\n\n>GeForce RTX 5080 performance makes us go hmmm. That’s an interesting way for us to start this paragraph, but the performance of the GeForce RTX 5080 is indeed all over the place. There are some games where the generational uplift looks exciting, and then there are others that make us scratch our head. It generally gives us a feeling of “hmmm.”\n\n>There are some good cases where the GeForce RTX 5080 is a nice uplift from the previous generation. We did see some 23%+ performance improvements, but those seemed to be outliers, more than the norm. Overall, it has somewhere between a 10%-20% performance uplift depending on the game and settings, Ray Tracing wasn’t that big. This isn’t enough to reach or match the GeForce RTX 4090 in performance. The GeForce RTX 4090 remains the performance leader in this regard. If you thought the GeForce RTX 5080 would be as fast as the GeForce RTX 4090, it isn’t.\n\n>Some of the results we have experienced make sense, after all, the raw specifications of the GeForce RTX 5080 are not that much upgraded from the GeForce RTX 4080 Super. The GeForce RTX 5080 is a GPU that is essentially a GeForce RTX 5090 cut in half, and the price reflects that as well. The GeForce RTX 5080 seems to consume about 17% more power than the GeForce RTX 4080 Super, and we get a performance increase that is close to that, some cases better, some cases worse.\n\n>Overall this means that the GeForce RTX 5080 at times follows a little too closely to the previous generation it is supposed to be supplanting. Often times we are left with a sense of a less-than-desirable gameplay experience improvement that one would expect from a new generation.\n\n>One could even call the GeForce RTX 5080 more akin to a theoretical ‘GeForce RTX 4080 Super Ti” or “GeForce RTX 4080 Super Super”, at least that is what it feels like. Keep in mind that the MSRP is $999, and that IS the same MSRP that the GeForce RTX 4080 Super was as well. Therefore, technically, it is a price for performance improvement, if pricing is at $999. It’s just that… it isn’t that exciting really.\n\n>As the GeForce RTX 4080 Super’s dry up in the market and the GeForce RTX 5080’s replace it, you will be getting a better gameplay experience with the GeForce RTX 5080. At the $999 MSRP, the NVIDIA GeForce RTX 5080 Founders Edition would be a solid upgrade from *prior generations*, such as GeForce RTX 3080 or GeForce RTX 2080 or even earlier.\n\n>If you are moving from an older generation prior to the RTX 40 series, the GeForce RTX 5080 will offer a good substantial upgrade path to modern features and gameplay performance at the $999 MSRP, but if you currently own a GeForce RTX 40 Series, unless you are moving from low-end to high-end, it is not going to be worth the upgrade.\n\n# [Tomshardware](https://www.tomshardware.com/pc-components/gpus/nvidia-geforce-rtx-5080-review)\n\n>Nvidia's RTX 5080 Founders Edition delivers what we were expecting, mostly. We can't help but feel that, like the RTX 5090, these first drivers made available to reviewers aren't fully tuned for the Blackwell architecture yet. In some games, performance looks quite good with reasonable generational improvements. In others, the gains don't materialize — particularly at lower resolutions.\n\n>What is obvious is that the RTX 5080 isn't a massive leap in performance compared to its predecessor — whether that's the 4080 Super we tested or the slightly slower RTX 4080. Nvidia's performance claims depend almost entirely on Multi Frame Generation (MFG), and that's disingenuous at best. Nvidia knows as well as anyone that a game running at 200 FPS with 4X MFG doesn't feel the same as a game rendering at 200 FPS without any form of framegen. Pretending that the resulting \"framerates\" are comparable requires serious mental gymnastics.\n\n>However, it's equally disingenuous to suggest that framegen/MFG are useless or \"fake frames.\" If you play a game running at 30–35 FPS without framegen and then try the same game running at 55–60 FPS with framegen, the latter feels better in my book. It's not anywhere close to twice as fast, but perhaps 20% faster. And if you use 4X MFG running at 105–115 FPS, that might feel another 10–20 percent faster than the 2X framegen result.\n\n>It's really just frame smoothing, but that smoothness interacts with your brain to make the game generally feel better, even if the base input sampling rate decreases slightly.\n\n>As a potential GPU purchase, if they're both priced the same, the RTX 5080 will be better than an RTX 4080 Super. That much is a given. Right now, it doesn't always win, but driver tuning should address any shortcomings. But if you already have a decent GPU, the benefits of the 5080 over the 4080 Super are pretty thin at present. If you didn't see enough in the RTX 4080 Super to entice you to upgrade in early 2024, the extra 10% performance plus new features that the 5080 offers isn't likely to change things.\n\n>If you're in the market for a $1,000 graphics card, and assuming there's enough supply to keep prices down, the RTX 5080 now sits on the podium as the second fastest GPU overall. It's half the price of the 5090, less likely to be continually sold out, and has all the other Blackwell architecture features. It's just nowhere near the potential 30% higher baseline performance we like to see with generational upgrades.\n\n>And if you're able to justify spending a grand on the RTX 5080, it's probably not that much of a stretch to double that for the clearly superior RTX 5090 that's over 50% faster on average — at 4K. The RTX 3090 was only 15% faster than an RTX 3080 four years ago, for double the price. For the well-funded gamer / streamer / AI researcher / etc., the 5090 is the clearly superior option. Which is one more reason we expect it will be hard to come by for quite some time.\n\n# [Computerbase - German](https://www.computerbase.de/artikel/grafikkarten/nvidia-geforce-rtx-5080-test.91176/)\n\n# [HardwareLuxx - German](https://www.hardwareluxx.de/index.php/artikel/hardware/grafikkarten/65395-leistungsplus-nur-ueber-mfg-die-geforce-rtx-5080-founders-edition-im-test.html)\n\n# [PCGH - German](https://www.pcgameshardware.de/Geforce-RTX-5080-Grafikkarte-281030/Tests/Release-Preis-kaufen-Benchmark-Review-vs-4080-Super-1464610/)\n\n# [Elchapuzasinformatico - Spanish](https://elchapuzasinformatico.com/2025/01/nvidia-geforce-rtx-5080-founders-edition-review/)\n\n\\--------------------------------------------\n\n# Video Review\n\n# [Der8auer](https://www.youtube.com/watch?v=IvQwlN1sE0U)\n\n# [Digital Foundry Video](https://www.youtube.com/watch?v=k7hDtGh0wIo)\n\n# [eTeknix Video](https://www.youtube.com/watch?v=CKhoBBX2h00)\n\n# [Gamers Nexus Video](https://www.youtube.com/watch?v=nShh_j4s2YE)\n\n# [Hardware Canucks](https://www.youtube.com/watch?v=JFF7lMvpV-s)\n\n# [Hardware Unboxed](https://www.youtube.com/watch?v=sEu6k-MdZgc)\n\n# [JayzTwoCents](https://www.youtube.com/watch?v=meekBr-ZB1E)\n\n# [KitGuru Video](https://www.youtube.com/watch?v=uKIwmW5j6oc)\n\n# [Level1Techs](https://www.youtube.com/watch?v=ZoE8GQnDwQQ)\n\n# [Linus Tech Tips](https://www.youtube.com/watch?v=Fbg7ChsjmEA)\n\n# [OC3D Video](https://www.youtube.com/watch?v=k-6Dw4qsGhA)\n\n# [Optimum Tech](https://www.youtube.com/watch?v=d7k4XWg-TcA)\n\n# [PC World Video](https://www.youtube.com/watch?v=YaZT5OuW6v0)\n\n# [Techtesters](https://www.youtube.com/watch?v=azD56D4_bFM)\n\n# [Tech Yes City](https://www.youtube.com/watch?v=6NwO1qrkEds)",
    "comments": [
      "> And if you’re able to justify spending a grand on the RTX 5080, it’s probably not that much of a stretch to double that for the clearly superior RTX 5090 that’s over 50% faster on average — at 4K\n\nWhat a stupid take (as expected) from Tomshardware.",
      "Literally the worst generation of GPUs Nvidia has ever released.",
      "RTX 50 8.0%",
      "TLDR; Skip the 5080 if you have a 40 series.",
      "I hope this doomer posting from this sub continues so I can get a 5080 tomorrow. \n\nNot everyone is upgrading from a 4000 series, and this seems like a great upgrade from my 3070ti.",
      "I may as well double it again and run dual 5090s at that point because clearly if im just throwing thousands around like that it's not an issue",
      "RIP my dreams of cheaper used 4090s.",
      "Fairly disappointing coming from a 3080 Ti looking to upgrade.",
      "My takeaway.\n\n\nIf you are on 4000 series, skip. Unless you really want multi frame gen.\n\n\nFor 3000 series, it is up to you. It's up to 50% more frames, some improvements in frame time, and access to frame Gen.\n\nUnder the 3000 series? Much better performance, much better frame times, more features. If you were previously considering the 4000 series, this is a no brainer. Better performance at the same price.\n\nThe 5000 series is being compared to Turing. A lot of the new architecture is focused on neural rendering, but no games use it yet. Like Turing, these cards might age well in 2 years time.\n\nThe small Gen on Gen uplift is why everyone is upset. Neural rendering doesn't exist in games right now. Silver lining is that the 5000 series is the same price as last Gen.\n\n\n\nThere is so much room for a 5080 Ti or Super. The 5090 is getting something like up to 50% more frames over the 5080. Also room for more ram on a 5080 Super/Ti.",
      "This \" launch \" could've been an email",
      "NVIDIA has been trying to make people think this way for years, but this gen doesn’t sell it at all. $1200 -> $1600 made a lot more sense last gen, even if that was also BS",
      "CPU manufs should retaliate by blowing hot air towards the GPU.",
      "Going from a 1070 to a 5080 is a massive upgrade, why would it not be worth it?",
      "See the bright side: There will be less posts about 5080 not beeing in stock.",
      "Gonna keep my 3080 for a while longer, lets see what the next generation has in store.",
      "The 16gb vram aside (which already made it a no-buy for me), the pitiful perf increase and price tag make this a slap in the face from nvidia.\n\nI'll definitely be holding on to my 3080 for another gen it seems.",
      "basically a 4080 Ti Super with multi frame gen \n\nnot a bad card if you're going from 30 series GPUs and below or a 4060, but still a bad card generation to generation wise",
      "TLDR\n\n![gif](giphy|JoePLWxLD7cGc)",
      "Barely 10 per cent improvement ...  there: done.\n\nYou're welcome.",
      "I wasn't expecting much and was still disappointment"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "high",
    "matched_keywords": [
      "rtx 3080",
      "3080",
      "3080 ti"
    ],
    "title": "GeForce RTX 30-Series Ampere Information Megathread",
    "selftext": "# This thread is best viewed on new Reddit due to inline images.\n\n# Addendum: September 16, 2020\n\n[RTX 3080 Review Megathread](https://new.reddit.com/r/nvidia/comments/itw87x/geforce_rtx_3080_review_megathread/)\n\n[GA102 Ampere Architecture Whitepaper](https://www.nvidia.com/en-us/geforce/news/rtx-30-series-ampere-architecture-whitepaper-download/)\n\n# Addendum: September 11, 2020\n\n[Embargo and RTX 3070 Update Thread](https://new.reddit.com/r/nvidia/comments/iqyol5/rtx_3080_founders_edition_review_date_sept_16th/)\n\n>Hey everyone - two updates for you today.  \n>  \n>First, GeForce RTX 3080 Founders Edition reviews (and all related technologies and games) will be on **September 16th at 6 a.m. Pacific Time.**  \n>  \n>Get ready for benchmarks!  \n>  \n>Second, we’re excited to announce that the **GeForce RTX 3070 will be available on October 15th at 6 a.m. Pacific Time**.\n\n# There is no Founders Edition Pre-Order\n\n&#x200B;\n\n[Image Link - GeForce RTX 3080 Founders Edition](https://preview.redd.it/sx6y5lmfflk51.png?width=1920&format=png&auto=webp&s=97732ebf788f1a904cb3c847e3b06f2f608a0424)\n\nPowered by the Ampere architecture, GeForce RTX 30-Series is finally upon us. The goal of this megathread is to provide everyone with the best information possible and consolidate any questions, feedback, and discussion to make it easier for NVIDIA’s community team to review them and bring them to appropriate people at NVIDIA.\n\n# r/NVIDIA GeForce RTX 30-Series Community Q&A\n\n~~We are hosting a community Q&A today where you can post your questions to a panel of 8 NVIDIA product managers.~~ [~~Click here to go to the Q&A thread for more details~~](https://new.reddit.com/r/nvidia/comments/iko4u7/geforce_rtx_30series_community_qa_submit_your/)~~.~~ **Q&A IS OVER!**\n\n[Here's the link to all the answers from our Community Q&A!](https://reddit.com/r/nvidia/comments/ilhao8/nvidia_rtx_30series_you_asked_we_answered/)\n\n# [NVIDIA GeForce RTX 30-Series Keynote Video Link](https://nvda.ws/32MTnHB)\n\n# Ampere Architecture\n\n# [Digital Foundry RTX 3080 Early Look](https://www.youtube.com/watch?v=cWD01yUQdVA)\n\n# [Tomshardware - Nvidia Details RTX 30-Series Core Enhancements](https://www.tomshardware.com/news/nvidia-details-rtx-30-enhancements)\n\n# [Techpowerup - NVIDIA GeForce Ampere Architecture, Board Design, Gaming Tech & Software](https://www.techpowerup.com/review/nvidia-geforce-ampere-architecture-board-design-gaming-tech-software/)\n\n# [Babeltechreview - The NVIDIA 2020 Editor’s Tech Day – Ampere Detailed](https://babeltechreviews.com/the-nvidia-2020-editors-tech-day-ampere-detailed/)\n\n# [HotHardware - NVIDIA GeForce RTX 30-Series: Under The Hood Of Ampere](https://hothardware.com/reviews/nvidia-geforce-rtx-30-series-ampere-details)\n\n# [Gamers Nexus - NVIDIA RTX 3080 Cooler Design: RAM, CPU Cooler, & Case Fan Behavior Discussion](https://www.youtube.com/watch?v=0Y7QhFx6VmI)\n\n# [\\[German\\] HardwareLuxx - Ampere and RTX 30 Series Deep Dive](https://www.hardwareluxx.de/index.php/artikel/hardware/grafikkarten/54038-neue-details-ampere-und-gtx-30-series-deep-dive.html)\n\n# GeForce RTX 30-Series GPU information:\n\n# [Official Spec Sheet Here](https://www.nvidia.com/en-us/geforce/graphics-cards/30-series/compare/)\n\n&#x200B;\n\n||**RTX 3090**|**RTX 3080**|**RTX 3070**|\n|:-|:-|:-|:-|\n|**GPU**|Samsung 8N NVIDIA Custom Process GA102|Samsung 8N NVIDIA Custom Process GA102|Samsung 8N NVIDIA Custom Process GA104|\n|**Transistor**|28 billion|28 billion|17.4 billion|\n|**Die Size**|628.4 mm^(2)|628.4 mm^(2)|392.5 mm^(2)|\n|**Transistor Density**|44.56 MT / mm^(2)|44.56 MT / mm^(2)|44.33 MT / mm^(2)|\n|**GPC**|7|6|6|\n|**TPC**|41|34|23|\n|**SMs**|82|68|46|\n|**TMUs**|328|272|184|\n|**ROPs**|112|96|64|\n|**Boost Clock**|1.7 Ghz|1.71 Ghz|1.73 Ghz|\n|**CUDA Cores**|10496 CUDA Cores|8704 CUDA Cores|5888 CUDA Cores|\n|**Shader FLOPS**|35.6 Shader TFLOPS|29.8 Shader TFLOPS|20.3 Shader TFLOPS|\n|**RT Cores**|82 2nd Gen RT Cores|68 2nd Gen RT Cores|46 2nd Gen RT Cores|\n|**RT FLOPS**|69 RT TFLOPS|58 RT TFLOPS|40 RT TFLOPS|\n|**Tensor Cores**|328 3rd Gen Tensor Cores|272 3rd Gen Tensor Cores|184 3rd Gen Tensor Cores|\n|**Tensor FLOPS**|285 Tensor TFLOPS|238 Tensor TFLOPS|163 Tensor TFLOPS|\n|**Memory Interface**|384-bit|320-bit|256-bit|\n|**Memory Speed**|19.5 Gbps|19 Gbps|14 Gbps|\n|**Memory Bandwidth**|936 GB/s|760 GB/s|448 GB/s|\n|**VRAM Size**|24GB GDDR6X|10GB GDDR6X|8GB GDDR6|\n|**L2 Cache**|6144 KB|5120 KB|4096 KB|\n|**Max TGP**|350W|320W|220W|\n|**PSU Requirement**|750W|750W|650W|\n|**Price**|$1499 MSRP|$699 MSRP|$499 MSRP|\n|**Release Date**|September 24th|September 17th|October 15th|\n\n# Performance Shown:\n\n* RTX 3070\n   * Same performance as RTX 2080 Ti\n* RTX 3080\n   * Up to 2x performance vs previous generation (RT Scenario)\n   * New dual axial flow through thermal design, the GeForce RTX 3080 Founders Edition is up to 3x quieter and keeps the GPU up to 20 degrees Celsius cooler than the RTX 2080.\n* RTX 3090\n   * Most powerful GPU in the world\n   * New dual axial flow through thermal design, the GeForce RTX 3090 is up to 10 times quieter and keeps the GPU up to 30 degrees Celsius cooler than the TITAN RTX design.\n\n# PSU Requirements:\n\n&#x200B;\n\n|**SKU**|**Power Supply Requirements**|\n|:-|:-|\n|GeForce RTX 3090 Founders Edition|750W Required|\n|GeForce RTX 3080 Founders Edition|750W Required|\n|GeForce RTX 3070 Founders Edition|650W Required|\n\n* A lower power rating PSU may work depending on system configuration. Please check with PSU vendor.\n* RTX 3090 and 3080 Founders Edition requires a new type of 12-pin connector (adapter included).\n* **DO NOT attempt to use a single cable to plug in the PSU to the RTX 30-Series**. Need to use two separate modular cables and the adapter shipped with Founders Edition cards.\n* For power connector adapters, NVIDIA recommends you use the 12-pin dongle that already comes with the RTX 30-Series Founders Edition GPU. **However, there will also be excellent modular power cables that connect directly to the system power supply available from other vendors, including Corsair, EVGA, Seasonic, and CableMod. Please contact them for pricing and additional product details**\n* **See Diagram below**\n\n&#x200B;\n\n[Image Link - GeForce RTX 3090 and 3080 Founders Edition Power and Case Requiremen](https://preview.redd.it/zaz57oacflk51.jpg?width=2525&format=pjpg&auto=webp&s=78c93d7a7a7eb33889d897e0776a1f7c369eaa19)\n\n# Other Features and Technologies:\n\n* **NVIDIA Reflex**\n   * NVIDIA Reflex is a new suite of technologies that optimize and measure system latency in competitive games.\n   * It includes:\n      * **NVIDIA Reflex Low-Latency Mode,** a new technology to reduce game and rendering latency by up to 50 percent.  Reflex is being integrated in top competitive games including Apex Legends, Fortnite, Valorant, Call of Duty: Warzone, Call of Duty: Black Ops Cold War, Destiny 2, and more.\n      * **NVIDIA Reflex Latency Analyzer**, which detects clicks coming from the mouse and then measures the time it takes for the resulting pixels (for example, a gun muzzle flash) to change on screen.  Reflex Latency Analyzer is integrated in new 360Hz NVIDIA G-SYNC Esports displays and supported by top esports peripherals from ASUS, Logitech, and Razer, and SteelSeries.\n      * Measuring system latency has previously been extremely difficult to do, requiring over $7,000 in specialized high-speed cameras and equipment.\n* **NVIDIA Broadcast**\n   * New AI-powered Broadcast app\n   * Three key features:\n      * **Noise Removal:** remove background noise from your microphone feed – be it a dog barking or the doorbell ringing. The AI network can even be used on incoming audio feeds to mute that one keyboard-mashing friend who won’t turn on push-to-talk.\n      * **Virtual Background:** remove the background of your webcam feed and replace it with game footage, a replacement image, or even a subtle blur. \n      * **Auto Frame:** zooms in on you and uses AI to track your head movements, keeping you at the center of the action even as you shift from side to side. It’s like having your own cameraperson.\n* **RTX I/O**\n   * A suite of technologies that enable rapid GPU-based loading and game asset decompression, accelerating I/O performance by up to 100x compared to hard drives and traditional storage APIs\n   * When used with Microsoft’s new DirectStorage for Windows API, RTX IO offloads up to dozens of CPU cores’ worth of work to your RTX GPU, improving frame rates, enabling near-instantaneous game loading, and opening the door to a new era of large, incredibly detailed open world games.\n* **NVIDIA Machinima**\n   * Easy to use cloud-based app provides tools to enable gamers’ creativity, for a new generation of high-quality machinima.\n   * Users can take assets from supported games, and use their web camera and AI to create characters, add high-fidelity physics and face and voice animation, and publish film-quality cinematics using the rendering power of their RTX 30 Series GPU\n* **G-Sync Monitors**\n   * Announcing G-Sync 360 Hz Monitors\n* **RTX Games**\n   * Cyberpunk 2077\n      * New 4K Ultra Trailer with RTX\n   * Fortnite\n      * Now adding Ray Tracing, DLSS, and Reflex\n   * Call of Duty: Black Ops Cold War\n      * Now adding Ray Tracing, DLSS, and Reflex\n   * Minecraft RTX\n      * New Ray Traced World and Beta Update\n   * Watch Dogs: Legion\n      * Now adding DLSS in addition to previously announced Ray Tracing\n\n# Links and References\n\n|**Topic**|**Article Link**|**Video Link (If Applicable)**|\n|:-|:-|:-|\n|GeForce RTX 30 Series Graphics Cards: The Ultimate Play|[Click Here](https://nvda.ws/34PDO4L)|[Click Here](https://nvda.ws/2GfLl2B)|\n|The New Pinnacle: 8K HDR Gaming Is Here With The GeForce RTX 3090|[Click Here](https://nvda.ws/2YQiEzH)|[Click Here](https://www.youtube.com/watch?v=BMmebKshF-k)|\n|Introducing NVIDIA Reflex: A Suite of Technologies to Optimize and Measure Latency in Competitive Games|[Click Here](https://nvda.ws/3lyuwzX)|[Click Here](https://nvda.ws/2QHNrKI)|\n|Turn Any Room Into a Home Studio with the New AI-Powered NVIDIA Broadcast App|[Click Here](https://nvda.ws/2QHurvC)|[Click Here](https://nvda.ws/32F9aZ6)|\n|360Hz Monitors|N/A|[Click Here](https://www.youtube.com/watch?v=vAoTsrgfBik)|\n|NVIDIA GIPHY page|[Click Here](https://giphy.com/NVIDIA-GeForce)|N/A|\n|Digital Foundry RTX 3080 Early Look|[Click Here](https://www.eurogamer.net/articles/digitalfoundry-2020-hands-on-with-nvidia-rtx-3080)|[Click Here](https://www.youtube.com/watch?v=cWD01yUQdVA)|\n\n# RTX Games\n\n|**Games**|**Article Link**|**Video Link (If Applicable)**|\n|:-|:-|:-|\n|Cyberpunk 2077 with Ray Tracing and DLSS|[Click Here](https://www.nvidia.com/en-us/geforce/news/cyberpunk-2077-30-series-4k-rtx-on-trailer)|[Click Here](https://www.youtube.com/watch?v=GQKXr9neSNk)|\n|Fortnite with Ray Tracing, DLSS, and Reflex|[Click Here](https://nvda.ws/3jq70Do)|[Click Here](https://nvda.ws/3jwIgcS)|\n|Call of Duty: Black Ops Cold War with Ray Tracing, DLSS, and Reflex|[Click Here](https://www.nvidia.com/en-us/geforce/news/minecraft-with-rtx-creator-worlds-pack-3-free-download)|[Click Here](https://www.youtube.com/watch?v=tZ_IjLt8zDU)|\n|Minecraft RTX New Ray Traced World and Beta Update|[Click Here](https://nvda.ws/3jwIrF4)|[Click Here](https://nvda.ws/2EIazpU)|\n|Watch Dogs: Legion with Ray Tracing and DLSS|[Click Here](https://www.nvidia.com/en-us/geforce/news/watch-dogs-legion-geforce-rtx-dlss-trailer)|[Click Here](https://www.youtube.com/watch?v=ytm2HvLYcmo)|\n\n# Basic Community FAQ\n\n**When is Preorder**\n\nThere is no preorder.\n\n**What are the power requirements for RTX 30 Series Cards?**\n\nRTX 3090 = 750W Required\n\nRTX 3080 = 750W Required\n\nRTX 3070 = 650W Required\n\nLower power rating might work depending on your system config. Please check with your PSU vendor.\n\n**Will we get the 12-pin adapter in the box?**\n\nYes. Adapters will come with Founders Edition GPUs. Please consult the following chart for details.\n\n[Image Link - GeForce RTX 3090 and 3080 Founders Edition Power and Case Requiremen](https://preview.redd.it/zaz57oacflk51.jpg?width=2525&format=pjpg&auto=webp&s=78c93d7a7a7eb33889d897e0776a1f7c369eaa19)\n\n**Do the new RTX 30 Series require PCIE Gen 4? Do they support PCIE Gen 3? Will there be major performance impact for gaming?**\n\nRTX 30 Series support PCIE Gen 4 and backwards compatible with PCIE Gen 3. System performance is impacted by many factors and the impact varies between applications. The impact is typically less than a few percent going from a x16 PCIE 4.0 to x16 PCIE 3.0. CPU selection often has a larger impact on performance.\n\n**Does the RTX 30 Series support SLI?**\n\nOnly RTX 3090 support SLI configuration\n\n**Will I need PCIE Gen 4 for RTX IO?**\n\nPer Tony Tamasi from NVIDIA:\n\n*There is no SSD speed requirement for RTX IO, but obviously, faster SSD’s such as the latest generation of Gen4 NVMe SSD’s will produce better results, meaning faster load times, and the ability for games to stream more data into the world dynamically. Some games may have minimum requirements for SSD performance in the future, but those would be determined by the game developers. RTX IO will accelerate SSD performance regardless of how fast it is, by reducing the CPU load required for I/O, and by enabling GPU-based decompression, allowing game assets to be stored in a compressed format and offloading potentially dozens of CPU cores from doing that work. Compression ratios are typically 2:1, so that would effectively amplify the read performance of any SSD by 2x.*\n\n**Will I get a bottleneck from xxx CPU?**\n\nIf you have any modern multi-core CPU from the last several years, chances are you won't be bottlenecked but it depends on the game and resolution. The higher resolution you play, the less bottleneck you'll experience.\n\n**Compatibility - NVIDIA Reflex, RTX IO, NVIDIA Broadcast**\n\n*NVIDIA Reflex* \\- GeForce GTX 900 Series and higher are supported\n\n*RTX IO* \\- Turing and Ampere GPUs\n\n*NVIDIA Broadcast* \\- Turing (20-Series) and Ampere GPUs\n\n**Will there be 3090 Ti/Super, 3080 Ti/Super, 3070 Ti/Super**\n\nLiterally nobody knows.\n\n**Where will I be able to purchase the card on release date?**\n\nThe same place where you usually buy your computer parts. Founders Edition will also be available at NVIDIA Online Store and Best Buy if you're in the US.\n\n**When can I purchase the card?**\n\n6am PST on release day per NV\\_Tim\n\n**How much are the cards?**\n\n3070 - $499 MSRP\n\n3080 - $699 MSRP\n\n3090 - $1499 MSRP\n\nNo Founders Edition  Premium\n\n**When will the reviews come out?**\n\nSeptember 14th per Hardware Canucks",
    "comments": [
      "The price revelation was insane! I did not expect that at all, AMD will have to do some magic with RDNA 2 if they want to compete.\n\nEDIT: Looks like Digital Foundry already made a [hands-on review.](https://www.youtube.com/watch?v=cWD01yUQdVA)",
      "so no pre order this time, they're just releasing the 17th it seems.",
      "It is so obvious they are not doing this because of supply. They know these things are gonna sell out in minutes. It is gonna be a dog fight for awhile to get one guys.",
      "Remember: Wait for 3rd party benchmarks.\n\nThe claim that the 3070 is \"more powerful than a 2080 Ti\" is *only* with ray tracing and DLSS enabled. A jump in performance with ray tracing on was expected for this generation. We don't know how the new cards stack up against the current gen in non-ray tracing, non-DLSS scenarios. Games have to specifically support both of these features, and many newer AAA games still don't support them. That will change over time of course, but don't buy a 3070 thinking that you're going to get 2080 Ti performance across the board at a fraction of the price, because that's almost certainly not going to be the case.",
      "Didn't expect them to make the 3070 and 3080 cheaper than was rumored, but then again I didn't expect them to make the 3090 *more* expensive than anticipated either. Lmao.. either way I was only planning on buying the 3080 so I guess it's whatever",
      "As mentioned, the 3090 is to replace the Titan branding. So technically it is $800 cheaper than the RTX Titan.",
      "well shit, the 3070 is actually a better value than people expected, while the 3090 is more expensive than expected.\n\nalso if those shader TFLOP numbers are real world full FP performance holy fucking christ this is a massive upgrade beating out pascal.",
      "I mean I am really not sure what people expected? Like we are in the middle of a pandemic and the writing has been on the wall for months that this was going to be the case.",
      "So now we have to be constantly checking for like a month straight and there is still a slim chance you can get one. Terrible.",
      "They announced the 3090 as if it is a successor to the Titan. If that's what it is we're looking at a $1000 price cut from previous gen.",
      "Remember when people said we'd be rioting over the prices?  Peperidge farm remembers...",
      "Still would have been nice to have a preorder even if it takes a month to get in stock. I would like to just have some place in line.",
      "RIP 2080 Ti Resale Value\n\n&#x200B;\n\n\\*Cries\\*",
      "UK Prices\n\nhttps://imgur.com/Y9f6tWt\n\n\n3090 - £1399\n\n\n\n3080 -  £649\n\n\n\n\n\n3070 - £469\n\n\n\n\nScan AIB Cards (thanks u/benzyl-chloride) https://www.scan.co.uk/shop/computer-hardware/gpu-nvidia/all\n\n\nOverclockers AIB Cards https://www.overclockers.co.uk/pc-components/graphics-cards/nvidia",
      "We ARE rioting, just different kind of riot!!!",
      "Not gonna lie I was expecting at least 1000$ for the 3080. This is a pleasant surprise",
      "no, the 3090 was directly compared to the titan if I remember correctly",
      "It’s going to be so hard to grab a card for the 3080 on the 17th..",
      "Just sold mine last night for $850 after hearing the news. Feeling like a genius.",
      "Yeah AMD is gonna be seriously hurting on the GPU side of things this gen unless they pull something really spectacular out of their ass."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "high",
    "matched_keywords": [
      "3080",
      "3080 ti"
    ],
    "title": "My 2070 couldn't hold up, so got my hands on a brand new 3080 Ti FE <3",
    "selftext": "",
    "comments": [
      "Your 2070 couldn't hold up...? Tf are you trying to run? Microsoft Flight Simulator in ultra 8K?",
      "A 2070 couldnt hold up?! Wtf lol",
      "Guessing 4k. Idk why everyone wants to run 4k, but its a thing now. My 2070 runs everything i throw at it with high settings. 🤷‍♂️",
      "And I’m over here with a laptop from 2014 that can barely run terraria lol",
      "This sub has the most mind boggling consumerism I’ve seen in a while",
      "You dont know why anyone would want to run a higher res monitor?\n\nIts incredibly more crisp than a 2k monitor. Going from 24\" 2k to 27\" 4k is 78% more pixel dense. It looks amazing\n\nEdit: some of you are so pathetic, it's amazing how such inconsequential comments get you so riled up. When people have knee jerk reactions to hearing about 'gamers' you're the people they think about.",
      "And I’m over here with a laptop from 2008 that can barely run the os lol",
      "yeah thats what i thought, my friend with a 2060 can play AAA titles on high, perfectly fine, a 2070 is still an amazing card. I have a 2080 Ti and I'm not even thinking about upgrading, just doesn't really seem worth it to me as I play everything maxxed out and still pull over 100 fps on a 34 UW 1440p",
      "Not sure what was wrong with your 2070 but my 1080ti still kicks ass in any game I play.  And byw I play on a LG CX.",
      "i just have a brick. :(",
      "It's a perfectly fine card, this guy's just an idiot",
      "And Im over here with a laptop 1998 that can barely run the BIOS",
      "Makes me feel bad with my 2070 super",
      "Because we want higher res? What lol",
      "And Im over here with a laptop from 1990 that can barely turn on",
      "My 2070 Super paired with my G-sync monitor (1440) eats everything at high-ultra. Plus I'd rather have 144hz over 60hz as an option.",
      "2070 super is still very plenty, Mine runs great with no hitch",
      "weird flex",
      "I will still always take 3440 x 1440 @ 144hz over 4K @ 60hz",
      "r/fuckmotionblur"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "high",
    "matched_keywords": [
      "rtx 3080",
      "3080",
      "3080 ti",
      "rtx 3080 ti"
    ],
    "title": "It’s Time For Ti -- Announcing The GeForce RTX 3080 Ti, Our New Gaming Flagship, And The GeForce RTX 3070 Ti",
    "selftext": "",
    "comments": [
      "The only winners are the people who got 3080 and 3090 on msrp.",
      "Not gonna lie, assuming MSRP world existed, I would just add $300 and go for the 3090 instead of the 3080Ti, it's basically double the VRAM for $300, and still better performance.\n\nI guess 3080 (lowest GA-102 die) and 3060Ti (lowest GA-104 die) will be really hard to find still.",
      "Faster? It's a cut down 3090,lol",
      "The 1200 $ MSRP for 3080TI is a joke imo comparing it to 3080... also don't forget LHR is on top... honestly, who wants to buy that thing? 3070TI on the other hand looks perfectly fine at 600 $\n\nI was waiting all the time for the 3080TI and i'm honestly very dissapointent. If only i knew, i'd have gone for a 3080 at launch because the MSRP on that thing was perfectly fine around Launch time",
      "It's pretty much just a 3070 but with faster vram and a factory overclock. The +4% cuda cores will barely make a difference. The 3080 ti and 3090 are pretty much the same but the 3080 ti has 1/2 the vram.\n\n\nYou can see how they compare here. \n\nhttps://videocardz.com/newz/nvidia-announces-geforce-rtx-3080-ti-at-1199-usd-and-rtx-3070-ti-at-599-usd",
      "The only thing the 3070Ti had to do, was adding some VRAM...",
      "All those points are true but do not back up your original argument of the 3080 ti being faster.\n\nThe 3080 ti FE is 350w just like the 3090 FE. So 50% less GDDD6x and consumes same power. That doesn't support your argument either.\n\nLOL",
      "2080ti didn't have a 2090 to compete with. \n\nIf it weren't for stock issues there are very few arguments to get 3080ti. If the 10GB VRAM on the 3080 worries you, 2GB more won't really do much. For £200 more you might as well get the 3090.",
      "For those gunning for the ti, may the odds be ever in your favor everyone. I'll be seeing you on the battle field in 48 hours.\n\n&#x200B;\n\nQuestion, what is the MSRP for the FTW3 3080 ti?",
      ">Question, what is the MSRP for the FTW3 3080 ti?\n\nQuestion, who cares after the debacle that was the 3080 and 3090 FTW3? Countless posts about dead cards and downright defective power balancing. I've been buying exclusively EVGA for 15+ years and I have zero desire or brand loyalty to make my next purchase an EVGA product after watching that shit show unfold.",
      "The 3070 Ti seems tame right? I expected a little bit more. \n\nI was debating on upgrading then selling my 3070 to people I know who have been trying to get one.",
      "Pretty disappointed with the MSRP pricing for 3080 Ti of $1200.\n\nNot that MSRP matters in 2021 but still.",
      "> How much difference would the G6X even make?\n\n+20 VRAM temp based on what we already know.",
      "How does the 3070ti compare to the standard 3080?",
      "prices were at 1099 but they raised it last minute, on some deeper parts of the website you could see it being 1099",
      "My 1080 just died out of nowhere 3 days ago. Feels like I'm going to have to face the entire world to get a 3070ti with an amazing price point like that :/",
      "What about the 3050? On their website they show [2 laptops for the 3050 and 3050 Ti](https://shop.nvidia.com/en-us/geforce/store/laptop/?page=1&limit=9&locale=en-us&category=LAPTOP&gpu=RTX%203050,RTX%203050%20Ti&category_filter=GPU~0,LAPTOP~0,STUDIO-LAPTOP~0,DESKTOP~0,NVLINKS~0). But Jeff didn't talk about it in the show.   \n\n\nDid I miss something?",
      "Hi.",
      "I guess you should re-read your own comment. Yikes.\n\n>50% LESS GDDR6X. If you have any idea how much power the GDDR6X on these cards consumes, you'll understand why that's a big deal.\n\nIf GDDR6X consumed as much power as you're implying, then cutting it in half with dramatically effect the TDP, and it doesn't, at all. That TDP is to drive the full chip's cuda cores, and the gain to do so is illustrated in the very minimal performance difference between the 3080 and the 3090.  \n\n\nAlso you still havent explained or backed up your original claim of the 3080 ti being faster, with slower clocks and less cuda cores.",
      "Imagine making a 3070 and thinking 8GB is future proof, and then making the Ti version with the same amount of VRAM, lmao"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "high",
    "matched_keywords": [
      "rtx 3080",
      "3080"
    ],
    "title": "Neat Video Benchmark Results: RTX 3080 vs. RTX 2080 Ti (CUDA performance + memory bandwidth + PCIe 4.0 relevance)",
    "selftext": "",
    "comments": [
      "I'd like to know how well the 3080 performs on 1440p, as I'm transitioning to that next.",
      "Yeah, we'll have to wait for reviews since Nvidia seems hell bent on only allowing 4k results to be shown. I am guessing that while the 1440p results will be impressive, they might not have the performance gap at 1440p between the old cards and the 3080 that there is between them at 4k, and that might be why they're only letting out 4k stuff for now. \n\n(be it because of memory bandwidth giving the 3080 a bigger advantage at 4k or maybe CPU's bottlenecking performance a bit at 1440p)",
      "Gaming on the touch bar.",
      "Apparently this article directly comparing the 3080 and the 2080 Ti came out back on September 3rd, but I just saw it this morning and couldn't find it posted here.  It seems they worked directly with NVIDIA to get these results.\n\n**TL;DR, the 3080 looks VERY impressive and they're excited about it:**\n\n> **\"The new RTX 30 Series are set to change the game! RTX 3080 has outperformed the ancestor by 31% with 59.7 FPS working at the same settings while 4K results with default settings are 41% better.\"**\n\nIn terms of Neat Video, these gains are fantastic.  See the table below for previous gen comparisons.\n\n-----\nA quick explanation of what this is, why it's interesting, and more quotes from the article:\n\nNeat Video is the industry standard noise removal tool for video editors, and it's highly dependent on factors like CUDA core performance and memory speed, and more specifically, it uses Single Precision FP32 for all of its calculations.  Because of this I've found it to be a great way in the past to compare the compute performance of different video cards, especially because it has a long history of data and they conveniently provide a super easy benchmark tool that anybody can use called [NeatBench](https://www.neatvideo.com/download/neatbench).  You can also benchmark CPUs with it, and you'll see people like [Puget Systems](https://www.pugetsystems.com/labs/articles/Premiere-Pro-CPU-Roundup-AMD-Ryzen-3rd-Gen-AMD-Threadripper-2-Intel-9th-Gen-Intel-X-series-1535/) use it in their various benchmarking tests for both CPU and GPU.\n\nSnippet from the article regarding memory clock speeds:\n\n> The improvement in internal memory bandwidth seems to have been achieved thanks to increasing memory clock speed from 7000 to 9500 MHz compared to RTX 2080 Ti. Despite the fact that the reduction in bus width from 352 to 320 bits has taken away some of the gains, the resulting memory bandwidth of RTX 3080 is still significantly better than that of its predecessor.\n\nInternal transfer speeds:\n\n> Our direct tests indeed demonstrate a 24% improvement in the internal transfer speed of RTX 3080 compared to RTX 2080 Ti: the actually observed speeds on the test computers were 649,087 MB/s and 521,318 MB/s respectively.\n\nPCIe 4.0 improvements:\n\n> PCI Express 4.0 is twice as fast as PCI Express 3.0 when the same number of lanes is used. Our direct tests confirm that RTX 3080 indeed delivers the expected gains: we have observed 120% and 103% better transfer speeds to and from GPU compared to another system with PCIe 3.0-based RTX 2080 Ti installed.\n\nActual FPS performance numbers comparing the 3080 and the 2080 Ti in terms of how fast it renders:\n\nFrame Size | Temporal Radius | 2080 Ti | 3080 | Difference\n---|---|----|----|----\n1080p | 2 | 45.4 |  59.7 | +31.5%\n1080p | 5 | 36.8 | 48.5 | +31.8%\n4K | 2 | 12.8 | 18.1 | +41.4%\n4K | 5 | 10.2 | 13.5 | +32.4%\n\n(Temporal Radius is how far forwards/backwards it looks to compare frames, and as you can imagine it causes a massive performance hit.)\n\n3.3 frames per second on 4K/5 may not seem like much, but I promise you the differences here can result in literal hours of time saved.\n\nConveniently, [a guy keeps a database of old NeatBench tests results](http://fifonik.com/nv/), and there's [previous articles](https://blog.neatvideo.com/post/hw-nov19) where the Neat Video developer has listed the numbers, so we can pull numbers from other cards to compare these to.  I'm going to use 1080p with a Temporal Radius of 2 since that's the default NeatBench v5 settings:\n\nGPU | FPS\n---|---|----|----|----\nRTX 3080 | 59.7\nRTX 2080 Ti | 45.4\nRadeon VII | 39.7\nRTX 2080 | 35.5\nRadeon RX 5700 XT | 35.1\nRTX 2080 Super | 34.8\nRadeon RX 5700 | 32.9\nRTX 2070 | 32.4\nPro Vega II | 32.8\nRX Vega 64 | 29.4\nGTX 1080 Ti | 28.5\nFury X | 26.8\nRX Vega | 24.9\nGTX 980 Ti | 21.6\nGTX 1070 | 19.7\nRX Vega 56 | 19.3\nRadeon RX 580 | 14.5\n\n(All of these results are from NeatBench v5 after Neat Video was rewritten to be faster.  Any results from NeatBench v4 are sadly not comparable.)\n\nIt only takes like 30 seconds to run, so feel free to perform your own benchmark on your current card using [NeatBench](https://www.neatvideo.com/download/neatbench) to see how the cards in that table compare to yours.  Apparently anybody can add their results to that speed database (top right), so I'm sure they would appreciate it f you uploaded them as well.",
      "I'm hoping to be able to run things much better on my 3440x144 144hz screen. My 2080 has been good but not great for FPS games like warzone.",
      "Isn't the **entire** x570 lineup PCIE 4.0 compliant? I would hazard a guess that users that are looking to buy a card that would be affected by PCIE 3 limitations wouldn't be the same users looking to cheap out on a B550 or cheaper board.",
      "2080 Ti FE TSE score is 6400\n\n3080 FE TSE score is 8500\n\nThat's according to Kopite from back in early August. It appears this leak was very accurate and will probably end up being expected performance stock-to-stock. \n\nThat's 40% theoretically in benchmark and probably closer to 35% in game at 4k over 2080 Ti until drivers are improved. Yeah it isn't 50%, but remember the $699.",
      "Upgrading from a 1070 is going to be glorious, ive been refreshing this sub so many times at work waiting for benchmarks, im a little bit obsessed.",
      "yes correct, cpu bottlenecks more at  lower reolutions\n\n&#x200B;\n\nThe easier job a gpu has , the less it will bottleneck. The less the gpu bottlenecks, the more the cpu will botleneck. This is why cpu benchamrks are more  meaningful and mostly are done on  1080p, while gpu benchmarks at 4k",
      "Benchmarks or not I think I'll notice a \"slight\" difference jumping from 970 to 3080, 1440p gaming",
      "there are way mroe pixels to render for a gpu at 4k than on  1440p.",
      "2600x here. The trick is to just keep turning up settings and DSR until the GPU holds us back again.",
      "Most games are bottlenecked by the GPU (i.e. 3080) limiting frame rate. If a game is limited by CPU (i.e. Ryzen 2600x) you can make the GPU be the bottleneck by increasing graphic settings and resolution.\n\nWas a joke but if you have GPU performance that isn't being used then settings which effect GPU more than CPU (which is typically most graphic settings) may as well be turned up.",
      "Soo pci-e 3.0 vs 4.0 fps difference 1? 2? Or 5fps ?",
      "Man it will be fine. I've been rocking 1080ti for 3440x1440 (1440p ultrawide) and it was pushing over 100fps most games I play \n\n3080 expected to be double the 1080ti so take that as you will",
      "Nvidias benchmarks have been with pcie 3 and there are barely any pcie 4 motherboards on the market anyway",
      "Wrong, all the B550 AND X570 mobos support it, basically PCIE 4.0 are, at least on AMD line up, on the CPU which means all the Zen2 line enables the PCIE 4.0. \n\nThe benchmarks Nvidia been doing has been on an Intel CPU there of the lack of PCIE 4.0 benchmarks (Intel CPUs is behind and currently to my knowledge don’t  have consumer CPUs with PCIE 4.0). \n\nTechnically, PCIE 4.0 could be run on a B450/X470 motherboard (since, again, it’s a CPU thing and AMD 3xxx series supports it) but it’s been disabled/removed in BIOS that’s out for those mobos - which you can see for yourself if you do some research on Gen4 nvme drives and a 3xxx series on YouTube for example.",
      "Bottlenecking doesn't necessarily mean it's bad, a GPU being used 99% and CPU being used 100% would still be called a CPU bottleneck.",
      "Just read some beginner guide and tutorials. You literally can't harm an NVIDIA GPU as the voltage is capped (idiot proof)\n\nAnd your CPU just stay below 1.4v as a maximum for daily voltage and you will be fine.",
      "Retail drivers though could add another 5% on top of that"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "high",
    "matched_keywords": [
      "rtx 3080",
      "3080",
      "3080 ti",
      "rtx 3080 ti"
    ],
    "title": "RTX 3080 or RTX 3080 Ti?",
    "selftext": "I'm planning on getting a PC in the future and I really want an Nvidia RTX 3080 but should I get the 3080 Ti or not? I'm gonna be honest, I've been in the laptop world forever so all this is kinda new to me and I have no idea what the difference between a normal 3080 and a 3080 Ti is.",
    "comments": [
      "Hshshaha..........🤣🤣🤣🤣🤣🤣🤣",
      "Get whichever you can find tbh since both cards prices are inflated currently and their performance differences are minimal. If you can get the FE definitely the 3080 at its original MSRP.",
      "Good luck finding anything RTX that doesn’t require selling both kidneys.\nIt’s not a case of what you’d ‘like’ but what you can get hold of.",
      "Here’s the thing though, there isn’t going to be an ‘official’ restock all the time crypto mining is still lucrative.",
      "Yep, if anything it’s worse now.",
      "Just check benchmarks. 3080 should be fine imo.",
      "They'll have 4080s out by then...",
      "Since this doesn't seem to be a price question: I play with a 3080 at 3440x1440 wide so basically 3k and it's more than enough. Dial some settings down and enjoy 3k 144fps gaming :)",
      "That ‘may’ be the official price but NVidia are smoking crack.\nTry a little google and see if you can find anything for under $2000 that isn’t a scalper or scammer.",
      "It’s still that bad? I haven’t really followed it since the new GPUs came out and I was fortunate to get one through the EVGA Elite program before bots could gobble them up, but it’s not very promising if they’re still short on stock less than a year from the next generation.",
      "As ultrawides have been out for quite a while now, there are plenty of games that take advantage of the extra width and give you more immersion. If you’ve never even tried one, don’t knock them with such confidence.",
      "Fukkk....that's mad. I thought £900 was steep for the gigabyte extreme 3080.  I wanted to get the 3090 version but that was 1600 ...kind of wish I bit the bullet and got that instead now.",
      "> I've been in the laptop world forever so all this is kinda new to me\n\nA 3080 or even 3070 would probably be plenty for you. The 3080 Ti (even the 3080 frankly) is an enthusiast tier GPU for people who are into hardware and don't care too much about price to performance (mid tier gpus are almost always a better value).\n\n> I have no idea what the difference between a normal 3080 and a 3080 Ti is\n\nDespite having the same number, they're actually different parts. The 3080, 3080 Ti, and 3090 all have the same core, but the 3080 Ti and 3080 are both cut down and have less memory and processing units. Ti (titanium) doesn't really mean anything, just consider it a middle ground between two parts, sort of like a 3085 in this instance.",
      "Both are good for non-4K stuff. With Asus ROG RTX 3080ti on 4K, I barely get 60 fps on most 2020-2021 titles with high-ultra settings. So I’ve to go medium with ray tracing off to get a stable gaming experience.",
      "It wasn't a recommendation for an uw monitor but for a 3080. The monitor was mentioned for fps reference. Hope this clears it.",
      "What's your target in terms of resolution?\n\n1440p go definitely for a 3080. The difference to a 3080 ti is only 5-7% on avg. That margin gets less if you enable dlss since the render resolution gets lower.\n\nIn 4k it can be worth it depending if you want to pay that much extra for 10-14% more performance. Imo not worth it. Again this margin gets less with dlss.\n\nSince you come from a laptop. Desktop gpus are way more powerful than mobile gpus. The desktop 3070 is stronger than a 3080 mobile. That's not uncommon. I had a laptop with a 980m years ago. The 980m was between a desktop 960 and 970.",
      "I found an EVGA RTX 3080 ti for $2,099 before taxes from an electronic store in my state and that was a *steal*.",
      "Go look at completed auctions to see what they sold for.",
      "GPU’s have been incredibly difficult to get for about 2 years now. Going on for the third. If you want a card you have to pay atleast 2x msrp.",
      "Joking aside, it's really what you can find. I snagged a 3090 early summer which is the only GPU I was able to get my hands on. Way overpriced and out of my budget range. However, I mined  some ETH with it for a while, just enough to get the back the money making it MRSP."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "high",
    "matched_keywords": [
      "rtx 3080",
      "3080"
    ],
    "title": "Wow, the jump from an RTX 3080 10GB to an RTX 4070 Ti is like playing on a new PC",
    "selftext": "I like to upgrade my GPU roughly once a year, while the one I'm using still holds value on the resale market. My 3080 10GB seemed to be getting creakier, was struggling with 4K/60hz, even though it handled 1440p/144hz well enough with DLSS. I was finding I couldn't use ray tracing on some games, and some others (Dead Space, I'm looking at you) I was having to drop to 1080p to get a decent frame rate. Basically I was having to make too many compromises to get to what I personally class as acceptable. Decided it was time for an upgrade. I couldn't justify the price of a 4080, especially as my TV, which is what I play single player games on, is only 60Hz. Wasn't keen on the 4070, I didn't think I'd get much different than I was getting from the 3080. So decided on the 4070 Ti, mainly as, for one, it was originally going to be a 3080 12GB, and because all the reviews say it trades blows with 3090 and 3090 Ti. I'm, 100% honestly, blown away by it. It's shredded everything I've thrown at it so far. Cyberpunk in psycho mode, no problem. Hogwarts Legacy at ultra RT settings, no problem. These two were pretty much unplayable at 4K for me before. I know I'll get diminishing returns, but as I said, I like to upgrade once a year, rather than use a GPU till it's on its last legs and then pay full whack for a new one. Today has been the first day in ages that I feel like I'm getting the full benefits of being a PC gamer\n\nEdit: Downvoted on an Nvidia sub because I'm happy with an Nvidia purchase? There's some odd ones on Reddit 🤷‍♂️",
    "comments": [
      "I went from 2080 to 4090, which was an Olympic front flip.\n\n3080 to 4070ti is a good increase, but i think maybe by 10%  or 20%  if generous.\n\n\nEdit:  i watched hardwareunboxed.   Ok, now i know 4070ti is very good.  I can say maybe 20-30%  increase easily without dlss3",
      "Are you talking about DLSS3 Frames Generation in your performance increase or do you exclude that?\n\nBecause 3080->4070ti it is not a big jump in terms of raw performance, but RT perf did get a nice lil bump architecturally, and then DLSS3 Frame Generation elevates everything where it applies.\n\nUpgrading often and reselling older GPU while it's still worth something is a sound strategy. +1 for that",
      "4070 Ti is like 16% (4k) -22% (1080p/1440p) faster than the 3080 according to this:\n\n [ASUS GeForce RTX 4070 Ti TUF Review - Average FPS | TechPowerUp](https://www.techpowerup.com/review/asus-geforce-rtx-4070-ti-tuf/31.html)   \n\n\nSo to be honest, the only major difference you will feel is when using FG, or if you play at 60 FPS, then the performance jump will get you there when the 3080 dips to low 50s.",
      "+20% is not that crazy of a jump for $800, you see.\n\nI am not saying it's trash. I am just saying it's not \"Wow, that jump\" reaction worthy.",
      "> 3080 to 4070ti is a good increase, but i think maybe by 10%  or 20%  if generous.\n\nConsidering the games mentioned, the added VRAM may mean the difference is bigger. Once you run out of VRAM, performance tends to take a fairly big hit.",
      "Sorry, it is actually 20-30%. i checked hardwareunboxed comparison just now",
      "I took it to a UK based second hand tech store and got store credit as I was buying the new GPU from there, and they give more money for store credit.\n\nEdit: I could have got more money on ebay, but couldn't be arsed with the hassle. With these I just took it in, they tested and it passed, they gave me a voucher code, I ordered the new one yesterday afternoon, and it arrived this morning",
      "I wouldn’t call a 25% jump very big. Especially due to the price increase",
      "I came here to ask if he was using framegen too lol",
      "As I've said before, for me, it is a huge upgrade. I can play games I couldn't properly before, and that's what's important to me.  Also, I upgrade every year using the money I get for my old GPU to help towards the new GPU. That way, I don't have to watch my gpu get less and less capable, and I don't have to fork out full price for the next card. I do agree about the prices. The cost per frame isn't value for money, especially considering what the 30 series were launched at before it all went to shit. But I also know that this card is going to help pay for my next one in about a year",
      "Someone's got to be conspiring against you because I have no idea why you're being downvoted",
      "I went from a 970 to a 4070 😀",
      "I disagree, I enjoy the shit out of the 4070 Ti with a 120hz 4k oled tv. \n\nYeah I cap starfield and cyberpunk with path tracing at 60fps, but everything else is 120fps native or 120fps with DLSS upscaling. \n\n4070 Ti is a fine 4k card. Yeah 12gb vram isn’t ideal, but 3090/3090 Ti performance is 3090/3090 Ti performance.",
      "It's probably my brother, he seethes when I buy anything new for my PC 🤣",
      "I went from the same card to a 4080 it was night and day ! Good job mate. I wanted to keep the 3080 for a new pc but swapped it out for a 4070. Cool, no noise and less power !\nLong live NVIDIA rtx series. Hell to the haters, DLSS is way better than AMD fsr.",
      "I jumped up from 3090 + 5800X3D to a 4090 + 7800X3D, it was a massive leap for 4k 144Hz gaming and VR gaming. Insane for 60% in a single generation.",
      "I've only used FG on the Cyberpunk benchmark to see what RT Overdrive looks like. I have DLSS on auto on CP and quality on HL. It feels like a huge jump for me. My 3080 wasn't the best (EVGA 3080 XC3 Ultra). It was power limited and was really struggling over the last few months",
      "Thanks, I was thinking the same reason. There's no point in anyone being envious, it only makes them miserable, not me. Jedi Survivor is an incredible game, prob the best I've played so far this year (Ratchet and Clank came close though). I've finally got into Cyberpunk after 4 or 5 times of trying and quitting due to performance problems. The lighting on Overdrive mode is absolutely stunning. Never seen any game look so good. It blows anything I've seen on console out of the water, and is the sort of thing that's the reason I'm a PC gamer in the first place",
      "It happens all the time on this sub.\nThe other day there was someone simply saying \"nice\" to someone's nvidia purchase (had 2 down votes).",
      "Thanks, it's nice to get a positive opinion, lol. Nice upgrade yourself. If my TV was 120Hz, I probably would have done the same, but unfortunately, I'm tied to the one I've got as it's from Sky in the UK, so I am under contract. I'm very happy as is though. My missus will be happy with my PC not sounding like a Dyson in the corner while she's watching TV in the evening too, lol"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "high",
    "matched_keywords": [
      "rtx 3080",
      "3080",
      "3080 ti",
      "rtx 3080 ti"
    ],
    "title": "NVIDIA GeForce RTX 3080 Ti Founders Edition Review",
    "selftext": "",
    "comments": [
      "Absolutly pointless product. \n\n5-10% more performance over the 3080 while being 70% more expensive. \n\nNvidia should have just diverted all of these chips into more 3080's instead.",
      "5 or 11% on average when compared to 3080 for + 500$ more? This is a robbery. How is this card can cost 1200$ is beyond me.",
      "Looks like it was meant to be cheaper but they changed it last minute. Check the prizes listed for the Summer of RTX Sweepstakes:\n\n[Webarchive $999 MSRP](https://web.archive.org/web/20210601060129/https://www.nvidia.com/en-us/geforce/contests/summer-of-rtx/terms-conditions/)\n\n[Live link $1199 MSRP](https://www.nvidia.com/en-us/geforce/contests/summer-of-rtx/terms-conditions/)\n\n999 would've been much more reasonable to me personally but I have no doubt it will still sell like hotcakes at 1200.",
      "Well, it's nvidia's own website for nvidia's sweepstakes with nvidia's product. I'm assuming they worked with the information they had at the time and just corrected it when they changed the msrp last minute, which they did.\n\nEven Steve from Gamers Nexus mentioned in his review today that the 999 was in talks behind the scenes before it released.\n\nMaybe do some research before you start a pathetic pissing contest for a multi billion dollar company.",
      "Ugh 1,200$ at that rate you might aswell just get the 3090 if you can",
      "Agreed. I thought for the price it'll be a heck of a lot better performer than the 3080. It literally doesn't make sense.",
      "Pointless from the perspective of the consumer, not from the perspective of the corporation",
      "Iirc he mentioned they wanted to crush amd at the same pricepoint?",
      "Linus said the same thing after talking with nvidia",
      "Just so you know, expect lines to start forming tonight. Microcenter has lines forming at noon the day before for their cards.",
      "They will sell every single one of these, so it’s not pointless.",
      "Honestly, that's probably why they did it that way. It's so stupid IMO.",
      "Jensen is literally known for deciding on the price of a card right before he goes on stage.",
      "Yes you were desperate enough to pay above MSRP for the card based on your business needs.  Doesn't make my statement wrong, regardless of whether or not you were offended by it.",
      "99c memory temps while gaming, sure that's in-spec, but still really bad, especially compared to some of the partner cards. I bet as with the RTX 3080 and RTX 3090, simply replacing the pads will drop GDDR6X temps by 10-20c.",
      "Stupid and/or desperate people.",
      "I would say my obtaining the 12 cards I'm using to mine at MSRP was a sound decision but you couldn't figure out how to get the ONE card at MSRP so out of desperation you paid over MSRP.  Yes.",
      "But the 3090 isn't a heck of a lot better than a 3080, so the ceiling wasn't very high.",
      "For real. People keep mentioning and comparing MSRP as if that's what you can buy them for",
      "skip"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "high",
    "matched_keywords": [
      "rtx 3080",
      "3080"
    ],
    "title": "[HUB] GeForce RTX 4070 Ti vs GeForce RTX 3080 10GB, 50+ Game Benchmark @ 1440p & 4K",
    "selftext": "",
    "comments": [
      "So the 4070ti basically replaced the 3080 on the new market, more money for more performance \n\nFor most people (Unfortunately) the 4070ti does actually make sense if you're looking to buy a new high end GPU (You can build a well balanced PC with a 4070ti for less than a 4090 costs)\n\nThe problem with the 3080, is most people bought it for far more than the $850 (New and used between 2020 and 2022)\n\nIf you have a 3070/3080, it's worth looking how much it sells for to fund the upgrade to the 4070ti (E.g. my old 3070ti I sold for £40 less than I bought it for new 16 months previously)",
      "Looking to upgrade in a few months and still running my 1080 Ti. I'm so unsure what to get, a used 3080 as a stop-gap for 5xxx or the 4070 Ti, which is a massive performance jump and will last me a long time... but man, buying any of the 4xxx series just feels so bad, the price points are just painful which takes the enjoyment out of the purchase.",
      "I had a 3080 and sold it for a 4070ti as I was able to sell it for the price I bought it and pay just £200 extra to get the 4070ti. \n\nI have 0 regrets. It runs quieter, cooler and draws less power so is more efficient which is often overlooked. DLSS 3 & Frame Generation are fantastic and I've had no issues running it in CP2077 and Hitman.\n\nIf you are buying ***new,*** right now,  the 4070ti offers the best value on NVIDIA's side.\n\nPrices for new 3080 cards are only £100/£50 less than a 4070ti so the 4070ti is much better value and 3090's are obviously more expensive than that.\n\nShould a 4070ti cost £800-£900? **HELL NO!** But in this current climate, we've got limited choice, especially if you're buying your first PC or having to replace an older card.",
      "Unfortunately because it's an $800 70 class GPU",
      "I hate that these reviews (not limited to HUB) don't even mention frame generation, let alone benchmark it. It's ~ 2x performance multiplier and the only feature capable of relieving CPU bottlenecks, which is becoming more common with ppl stuck on AM4 and generally CPUs falling behind GPUs. \n\nIt's not perfect, but let the buyer decide whether the extra latency is \"unplayable\", rather than pretending the feature doesn't exist.",
      "Okay, how about we talk about it's bad value? Something less arbitrary for you",
      "First I need AM5, DDR5 and then MAYBE I'll replace my 2080",
      "Not necessarily\n\nThe thing about inflated new prices is your old card also sells for a premium, especially if it's ampere \n\nI went to the 4070ti from a 3070ti, purely because my 3070ti had basically retained all it's value over the 16 months I used it for",
      "What's the point? Not all games have it nor will have it and it wouldn't measure the gpu performance anyways (as in, 4070ti results wouldn't be comparable to 3080 results).",
      "Man I really didn't want to want a 4070Ti out of principle because we all know it's basically a mid range card labelled and marked up as a lower high end card, but the performance is good and I'd be able to run it comfortably on my EVGA G2 650W PSU... 🤔",
      "The point is that many users will choose to enable it if it's available, so why *not* include it in their testing (alongside native resolution performance testing)? That's how actual people will use these GPUs, and it's one of the biggest features of this generation of GPUs.",
      "Downvoted for terrible upgrade path the most terrible money waste i ever seen",
      "So the moment game requires higher memory bandwith,  4070ti performance tanks. (since it runs somthing like xx60 bandwidth)\n\nThis is a 900-950 euro card that doesn't feel futureproof at all (Eastern EU).  Holy shit.\n\nP.S. and Hogwarts just obliterated them both in 4k due to lack of VRAM.",
      "you are very wrong",
      "I'm still running a 1080ti and love it.",
      "4070 Ti only makes some sense if you’re coming from a 20 series or lower.",
      "Only poor people living off credit cards say that shit.",
      "I'd get a used 3080 12GB.  I've got a 3080 ti and it runs everything I throw at it at high settings.  Hold out for a 5000 series card.",
      "I got two 3080s at launch for msrp, was lucky as hell, panic ordered from multiple etailers here in Norway. But yes, most people paid 2xmsrp for those cards.. Crazy really",
      "Buying a used RTX 3080 for around 500-600$ if you manage to find a trustworthy seller with a solid card is a bargain if you are buying a GPU in europe though. The 4070ti costs like 900-1100+ euros"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "high",
    "matched_keywords": [
      "rtx 3080",
      "3080",
      "3080 ti",
      "rtx 3080 ti"
    ],
    "title": "NVIDIA RTX 3080 Ti Founders Edition Tear-Down: Seeking Differences vs. 3080 FE",
    "selftext": "",
    "comments": [
      "Spoiler: There is no difference between the two cards, architectural wise or cooler wise. The Ti has two more memory chips and two more VRM packages to service those chips.",
      "More disappointment with the thermal pads on the back.",
      "What are you doing, don't you know simping for GPU manufacturers is the rule in these subs. How dare you not worship Huang's schlong?",
      "He makes positive videos, too. He's just trying to make sure people are aware and appropriately angry when companies screw us over by doing shoddy engineering.",
      "uhh, watch the video? Steve clearly explains what nvidia missed out on regarding the back of the card and the thermal pad situation. The fact is, they're kinda just wasting space by not using more thermal pads on a card( well, a cut down version of the same card) that's known for SPITTING HOT FIYA. It's not a MAJOR issue, but it's still something nvidia could do better at when you're buying a 1200$ gpu",
      "What makes it worse from Nvidia in this case is that they purposely hid the VRAM temperatures from sensor programs at the initial release of the 3080/3090, so the Founders Edition cooler got a ton of praise for its space efficient design since it keeps the core temperatures in check. It wasn’t until months later that the HWINFO64 guys made the VRAM temp visible to all users on all ampere cards and then we got to see how cards were hitting over 100 C vram junction temp in gaming and 110 C during mining and scientific compute workloads. So not only did they cheap out on the cooling on their product, they hid the temperatures so people wouldn’t complain about it.",
      "https://www.youtube.com/watch?v=xMcn-npviGA\n\nLiterally 3 days ago, but I guess going to a Youtube page is harder than ignorant complaining.",
      "They should have put the 3090 cooler on it then...",
      "think the difference was $400\n\njust happy to see the price gap was worth it in the end",
      "Huang’s Schlong. *insert Robert Redford nodding gif*",
      "It isn't just a problem for miners. The FE card hits 95-100 C during gaming on VRAM. With the addition of $5 of thermal pads it can max out as high as 85 C. Some of the board partners, like Asus, did a decent job with their pads and always stay under 90 C vram temps during gaming.",
      "Gelid extreme are supposed to be both pretty squishy and good quality. I actually have some for a repad but I haven't opened them up yet.",
      "On average, the RTX 3080 Ti was 12% faster than the RTX 3080 but costs so much more! Seriously, have you not watched any reviews for the 3080 ti? 3080 fe is $699.99 and the 3080 Ti fe is $1199.99. Simply not worth it for the price",
      "it's a good thing they followed that statement with a caveat, would look silly otherwise.",
      "This has come up so many times it’s probably not even worth repeating, but just because Nvidia sets the thermal throttle limit to 110 C doesn’t mean it’s a good idea to allow the vram to run over 95 C for extended periods. Sure it will probably last the length of the warranty period, and to some people, and Nvidia, that’s enough. But a lot of consumers would prefer their card to survive well after the warranty period and allowing temps to sit that high doesn’t align with that goal.",
      "This asshole needs a chill and a pill.",
      "If you want to look at it that way but if you are in the market for a 3090 you are getting the same performance for less money.\n\nYou can use the same argument and has been used for the 3080 compared to 3090 but that did not stop 3090 sales...",
      "So you are calling him negative and then showing where he’s not being negative and is trying to make light of the situation?\n\nGeez are you reading what you are saying",
      "anybody knows a brand of squishy thermal pads? \nI got some Arctic’s but they’re hard as hell in compression",
      "Did you actually watch the video and listen to the completely valid points he made? When negativity (in a review) is called for then its justified and in this case it’s completely justified. Can you honestly say one good thing about the 3080 Ti? Is the price fair? No, is there availability for gamers? No. Is it a huge price increase for little performance increase? Yes"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "high",
    "matched_keywords": [
      "rtx 3080",
      "3080",
      "3080 ti",
      "rtx 3080 ti"
    ],
    "title": "An Impression of Micro Center's Refurbished RTX 3080 Ti FE: Becoming a Good Deal?",
    "selftext": "Hello all,\n\nMicro Center has been selling refurbished 3000 series Founders Edition cards for some time now and while the prices were questionable previously, the prices have started to fall (finally). Here I am writing a <24 hour impression with once such card I bought, a RTX 3080 Ti FE, and the condition of the GPU. The two-slot design of this card makes this particularly enticing for SFFPC builds.\n\nThe GPU was listed as open box for $424.96, \\~$450 after tax. The GPU comes in a nondescript cardboard box with adequate foam padding. Upon inspection in the store (which you are allowed to do on open box items, not for newly packaged items) the GPU was unopened from its antistatic bag and came with a newly packaged Nvidia-branded 12VHPWR adapter. I suspect this was a purchase and return.\n\nhttps://preview.redd.it/9oa4yplq5t2d1.jpg?width=4000&format=pjpg&auto=webp&s=09d38d24eb5b7f62234442871b903c4911b7be95\n\nDuring my inspection of the card I did not see any previous fingerprints, nicks, scratches, or other evidence of damage to the card shroud, suggesting that these are factory refurbished. I also did not observe dust or residue under the GPU heatsink that I have seen with uncleaned used and mined cards. The fans look brand new without signs of use or unevenness when spinning the fan blades. The 12VHPWR connector is clean without burn marks or melted plastic. The only evidence of previous use to these cards is at the PCI-e pins on the card, which do have marks on them. These observations do not exclude the possibility that these were previously mined on but they have at least certainly been given a good clean and treatment. I have not opened up this GPU to determine the condition of the thermal pads or paste.\n\nhttps://preview.redd.it/ovc2wx7s5t2d1.jpg?width=4000&format=pjpg&auto=webp&s=198a785498ecfa7bdfa7df188f59eee14c9f20a3\n\nhttps://preview.redd.it/vvhy59ys5t2d1.jpg?width=4000&format=pjpg&auto=webp&s=3a6159f2fd294729631116b9a2610a4284edbd88\n\nhttps://preview.redd.it/ymy8jrgt5t2d1.jpg?width=4000&format=pjpg&auto=webp&s=2519a0a34e7efbc93589e446e9aa0b45a527745b\n\nUpon stress-testing the GPU stabilizes at 81-82°C, reaching \\~1900 MHz core clock and \\~9500 MHz memory clock while drawing 340W of power. There is some minor coil whine that is drowned out by the GPU fan noise, which is at levels that I would expect from a reference design. Synthetic benchmarks reach levels around the median reported scores for other 3080 Tis, which is reassuring that this particular card has not suffered much degradation (and in line with testing from other sources regarding used GPUs). In my in-game testing with Tetris Effect and Battlefield 4 at 1440p I have not noticed any graphical glitches or defects. Overall performance is what I would expect for a new 3080 Ti FE.\n\nhttps://preview.redd.it/b70sbw8u5t2d1.png?width=1372&format=png&auto=webp&s=e0d0a1656c01c12a7288a12cc29f0a7fdf8b5d06\n\nhttps://preview.redd.it/x5hdt7zu5t2d1.png?width=1024&format=png&auto=webp&s=755c42dbc98638382d71e64da85a912dfa2ae351\n\nThese GPUs come with hassle-free 90-day warranty but can also have 2 or 3 year purchase protection plans where Micro Center will give you the amount in store credit. Whether or not the additional warranty purchase is worth it is up to user discretion. (I personally think that the imminent risk of hardware failure is low given that these cards are past the initial part of the \"bathtub curve.\")\n\nThe other closest competitors in this price point (after open-box discount in my case) and performance are the $400 4060 Ti 8GB, $550 4070 12GB, $600 4070 Super 12GB, and $480 RX 7800 XT 16GB. The pure rasterization performance, higher memory bandwidth on the 3080 Ti, and DLSS2 support are very compelling, especially for 4K gaming. High power draw and thermals is a big downside to these cards--but this is user-dependent, and as someone who doesn't game 24/7, the math doesn't add up in terms of power consumption. For me, at \\~4hr gaming/wk, it would take me 6.5 years for the electricity cost to surpass the price difference between the 3080 Ti and the cheapest but similarly performing 4070 Super, which could be further improved with undervolting. The other downside is the lack of support for frame gen and DLSS3, which also depends on the user as to whether these features are useful.\n\nI believe that the prices of this card will continue to drop given the high inventory in some stores. With further discounts or open-box deals I believe these refurbished GPUs should be given serious consideration for folks looking into FE cards for their build.\n\nEdit: Reddit's being dumb, images re-uploaded.",
    "comments": [
      "At $424 that is an absolutely incredible deal.",
      "That card is still worth 550-600 to a lot of people. Steal.",
      "Nice deal OP!\n\nI run a power modded 3080ti - really the only thing holding the FE is the size of the cooler, it will run hot all the time. They have a ton of OC headroom.\n\nHas been serving me great on a neo 4k for over a year and with free framegen mods, I really am not feeling and FOMO towards the 4000 cards.",
      "I wish but that deal was a pricing error by Newegg and is not valid.",
      "I love my 3080ti FE. I have no reason to upgrade to a 40xx series. I’ll wait for a 50xx or 60xx series. I only play Diablo games anyways lol \n\nOp, excellent review of this gpu.",
      "There was some deals on brand new 4070 super for about $450 in the past week on buildapcsale. I personally would just return and try to grab these.",
      "Considering what we were paying in 2020, it’s dirt cheap.",
      "I got a 4080 from a 3080 and the 40 series is remarkably cooler which is nice for people who live in hot environments. And the performance gain was great.",
      "Well from what I have heard and seen from my GPU it just runs cooler completely it doesn't even get anywhere near as hot as my 3080. My 3080 would get hot to the touch and my 4080 doesn't even feel warm. Both were triple fan units. My 3080 would even heat my room it got so warm which is the main reason I sold it because I couldn't even get inside to change the thermal paste and I wanted something cooler and my 4080 aorus master is the best gou I have ever owned. It has the same cooler and heating the 4090 uses though so it's cooling solution is much better plus the 40 series is just cooler all around.",
      "Love this. Buying used is the move. Feel like this sub, buildapc, and honestly most of Reddit tries to upsell everyone. \n\nWhen the 50 series comes out in very interested in seeing the price of 3080s.",
      "Seems like there’s an anticipatory drop in prices of used cards for the new gen, then a spike when new cards are unavailable. Once supply stabilizes they’ll settle into their 2-gen old price point until it happens again the following generation…hard to think of a 3080 coming in below $300 but it’s probably going to happen fairly soon",
      "That's a steal OP! Enjoy your hard find. Personally I'm looking to upgrade to 5070 next year, but tbh not sure if that's the best idea lol since even my current 3070 is still doing very well at 1440p 60+ fps with the help of DLSS. Got it used for $250 from a miner lol. These used 30 series cards are such good deals.",
      "Pretty solid buy at $425 like you paid - but your conclusion is spot on…better to get a current gen card overall. https://www.techpowerup.com/review/nvidia-geforce-rtx-4080-super-founders-edition/31.html (3080 Ti not shown but lets give it the 3090 numbers - it’s a cut down 3090 but it is close).\n\nThese are $500 - I’d rather spend $100 more to get a brand new with warranty RTX 4070 SUPER. The 90 day warranty is all you get on the 3080 Ti unless you spend considerably more for the MC warranty upgrade.\n\nThe used market for current gen is solid, too. Open box or used / refurbished is a goldmine.\n\nPaid $685 for a RTX 4070 Ti SUPER used and just bought an RTX 4090 for $1300 - all shipped / post tax.",
      "I just bought a 3080 FE from my local MC in Columbus this past weekend and it seemed in very good condition temp wise and hot spot all look good while running occt and fur mark but the memory temps slowly creep to 100c even while gaming and after I UV the card to about .850 mV at 1850mhz the mem temps still rise to 100c. I’m wondering if I got a dud that was used for mining..",
      "About to do the GPU-trade-in on the 3050 I bought from them during the gpu-depression, just gonna go up to a 3060ti and buff it out. I'm only gaming at 1080p but I'm hungry for those last few frames in games like Helldivers 2.",
      "I undervolted mine to 0.825V/1820MHz and it does decrease power consumption to \\~280W under load in games. Temps are about the same but I'm able to run the fans at a lower speed. Nvidia used pretty crappy thermal pads from what I understand on the FE cards so I wouldn't be surprised if that were consistent on these refurbished models.",
      "Really? Better fan? Better thermal displacement?",
      "Both AMD and Nvidia are going to have  lot of cards out on the street when $300 3080 ti / and 6950xts hit the market en mass this holiday."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "high",
    "matched_keywords": [
      "rtx 3080",
      "3080"
    ],
    "title": "New Rtx 4060 Ti 8Gb (465$) vs Used Rtx 3080 (600$) 12Gb for casual gaming at 1440p",
    "selftext": "As it's said in the title, I'm stuck between choosing a New Rtx 4060 Ti or a Used Rtx 3080 since:\n\nThe Rtx 4060 Ti is less power hungry, Has newer Dlss 3.5 with frame generation and ray reconstruction and since more games will be better with the Dlss and will be using them instead of optimizing their games, and the Rtx 4060 Ti is new and cheaper than the Used Rtx 3080, but i don't know if it's good for 1440p and not mentioning the 8Gb of Vram that will Surely backfire, also The 16Gb of vram version of it costs 100$ more for slightly 10% more performance or 5-6 more fps\n\nWhile the Used Rtx 3080 has less technological features, more power hungry and depends on raw performance more and it's better for 1440p But I don't if it will be good for the upcoming games that will be more dependent on Dlss than normal performance.\n\nSo i don't know which one to choose for playing games like Alan wake 2, re4 remake, cp 2077, etc...\n\n\nP.S Before someone tells me \"get this or get that instead\" The Rtx 4070 costs (800$) in my country so it's out of my budget and there are no AMD GPUs available in my country.",
    "comments": [
      "3080 12GB is about 33% faster and has 50% more VRAM. At the pricing you're seeing, it's a perf/$ upgrade and it will last longer at 1440p by about a generation.",
      "3080. The 4060ti isn't powerful enough to utilize those \"new features\" to their fullest potential",
      "If you can spend $600 then get a 4070 super, it’s better than either suggestion.",
      "Fr, 4060ti cant even use FG in Horizon due to vram",
      "They said they can’t in their post",
      "The 4060ti isn't even worth considering unless it's very cheap, so the obvious choice here is the 3080.\n\nRemember, OP is running 1440p, and 8gbs of VRAM is barely enough for that.",
      "3080 for sure. Costing about 22% more, you'll be anywhere 27-33% more performance at 1080. \n\nFG and dlss 3.5 is great and all but consider what games you're playing and which ones utilizes it. There's also mods to enable 30 series.",
      "And plus 4070 super you I’ll bit performance and power efficiency",
      "29% price increase for ~40% more performance and more VRAM, it’s actually better value and will last much longer at 1440p.\n\nThe tradeoffs are no Nvidia frame gen, AV1 encoding or warranty and it’s double the wattage. Still more than worth it IMO, unless those things are highly important to you. Both cards have ray reconstruction btw.",
      "3080 12GB for sure. Pretty big performance difference there, and while it's not quite as good as nvidia's native implementation you can use the fsr3 framegen mod to achieve similar results in any title that supports framegen.",
      "3080 12GB? Those are rare.\nGet it. Much better.\n\n\nWhen it launched, 3080 was a beast. Any game 4K max. \n\n\nToday, Alan Wake2 and CP2077 are the few very demanding games that even 4090 cant max out.",
      "OTOH it's 360w power draw for the 12gb 3080 vs 160w power draw for the 8gb 4060 Ti - more than double.\n\nNot sure what country he is in, but depending on electricity costs, that may make a dramatic difference in overall cost of ownership - especially if you are doing anything 24/7 with it like Folding, mining, AI workloads, etc.",
      "You can always undervolt…",
      "If your buying the 308 for 600 you might be able to find a 4070/4070super for ~600 but if it's between the 2 you picked 3080 for sure.\n\nEdit: didn't read description. Go with the 3080 any day. More vram + performance",
      "If you're worried about power usage, just set an undervolt curve.  My 3080 12GB utilizes between 200-265w depending on the game I play at 3440x1440.",
      "You can use the fsr frame gen mod on the 3080, undervolt it by a significant amount, has more vram, and it is just much much faster.",
      "Real life experience:  \nI bought a rtx 4060 for 560$ to game at 1440p.  (horrible performance).  \nHad to trade it in and get a rtx 3080 ti (used) putting like 300$ on top of it.",
      "I see, thanks for telling me.",
      "No no those mods are terrible and not worth any ones time /s\n\n-Nvidia subreddit",
      ">Today, Alan Wake2 and CP2077 are the few very demanding games that even 4090 cant max out.\n\nAt what framerates? And is that including DLSS and frame-gen?\n\nIn Alan Wake II, at 4K, with DLSS Quality and Frame Generation on, I can max out all the graphical settings and still get about 110 FPS.\n\nI haven't tried without DLSS and frame-gen though."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "high",
    "matched_keywords": [
      "rtx 3080",
      "3080"
    ],
    "title": "NVIDIA RTX 30-Series – You Asked. We Answered",
    "selftext": "Below are the answers to the Q&A Thread we posted yesterday. **All the answers below have also been posted back over in the Q&A thread to respond to the individuals.** The purpose of this thread is to list all the questions that were answered so everyone can see it!\n\n# [NVIDIA has also posted this Q&A Summary Article here](https://www.nvidia.com/en-us/geforce/news/rtx-30-series-community-qa/)\n\nI'm posting on behalf of /u/NV_Tim. Anything below is from him.\n\n# Q&A Answers\n\nWith the announcement of the RTX 30-Series we knew that you had questions.\n\nThe community hosted a Q&A on r/NVIDIA and invited eight of our top NVIDIA subject matter experts to answer questions from the community. While we could not answer all questions, we found the most common ones and our experts responded. Find the questions and answers below.\n\nBe on the lookout for more community Q&As soon as we deep dive on our latest technologies and help to address your common questions.\n\n# RTX 30-Series\n\n**Why only 10 GB of memory for RTX 3080? How was that determined to be a sufficient number, when it is stagnant from the previous generation?**\n\n>***\\[Justin Walker\\]*** *We’re constantly analyzing memory requirements of the latest games and regularly review with game developers to understand their memory needs for current and upcoming games. The goal of 3080 is to give you great performance at up to 4k resolution with all the settings maxed out at the best possible price.*  \n>  \n>*In order to do this, you need a very powerful GPU with high speed memory and enough memory to meet the needs of the games. A few examples - if you look at Shadow of the Tomb Raider, Assassin’s Creed Odyssey, Metro Exodus, Wolfenstein Youngblood, Gears of War 5, Borderlands 3 and Red Dead Redemption 2 running on a 3080 at 4k with Max settings (including any applicable high res texture packs) and RTX On, when the game supports it, you get in the range of 60-100fps and use anywhere from 4GB to 6GB of memory.*  \n>  \n>*Extra memory is always nice to have but it would increase the price of the graphics card, so we need to find the right balance.*\n\n**When the slide says RTX 3070 is equal or faster than 2080 Ti, are we talking about traditional rasterization or DLSS/RT workloads? Very important if you could clear it up, since no traditional rasterization benchmarks were shown, only RT/DLSS supporting games.**\n\n>***\\[Justin Walker\\]*** *We are talking about both. Games that only support traditional rasterization and games that support RTX (RT+DLSS).*\n\n**Does Ampere support HDMI 2.1 with the full 48Gbps bandwidth?**\n\n>***\\[Qi Lin\\]*** *Yes. The NVIDIA Ampere Architecture supports the highest HDMI 2.1 link rate of 12Gbs/lane across all 4 lanes, and supports Display Stream Compression (DSC) to be able to power up to 8K, 60Hz in HDR.*\n\n**Could you elaborate a little on this doubling of CUDA cores? How does it affect the general architectures of the GPCs? How much of a challenge is it to keep all those FP32 units fed? What was done to ensure high occupancy?**\n\n>***\\[Tony Tamasi\\]*** *One of the key design goals for the Ampere 30-series SM was to achieve twice the throughput for FP32 operations compared to the Turing SM. To accomplish this goal, the Ampere SM includes new datapath designs for FP32 and INT32 operations. One datapath in each partition consists of 16 FP32 CUDA Cores capable of executing 16 FP32 operations per clock. Another datapath consists of both 16 FP32 CUDA Cores and 16 INT32 Cores. As a result of this new design, each Ampere SM partition is capable of executing either 32 FP32 operations per clock, or 16 FP32 and 16 INT32 operations per clock. All four SM partitions combined can execute 128 FP32 operations per clock, which is double the FP32 rate of the Turing SM, or 64 FP32 and 64 INT32 operations per clock.*  \n>  \n>*Doubling the processing speed for FP32 improves performance for a number of common graphics and compute operations and algorithms. Modern shader workloads typically have a mixture of FP32 arithmetic instructions such as FFMA, floating point additions (FADD), or floating point multiplications (FMUL), combined with simpler instructions such as integer adds for addressing and fetching data, floating point compare, or min/max for processing results, etc. Performance gains will vary at the shader and application level depending on the mix of instructions. Ray tracing denoising shaders are good examples that might benefit greatly from doubling FP32 throughput.*  \n>  \n>*Doubling math throughput required doubling the data paths supporting it, which is why the Ampere SM also doubled the shared memory and L1 cache performance for the SM. (128 bytes/clock per Ampere SM versus 64 bytes/clock in Turing). Total L1 bandwidth for GeForce RTX 3080 is 219 GB/sec versus 116 GB/sec for GeForce RTX 2080 Super.*  \n>  \n>*Like prior NVIDIA GPUs, Ampere is composed of Graphics Processing Clusters (GPCs), Texture Processing Clusters (TPCs), Streaming Multiprocessors (SMs), Raster Operators (ROPS), and memory controllers.*  \n>  \n>*The GPC is the dominant high-level hardware block with all of the key graphics processing units residing inside the GPC. Each GPC includes a dedicated Raster Engine, and now also includes two ROP partitions (each partition containing eight ROP units), which is a new feature for NVIDIA Ampere Architecture GA10x GPUs. More details on the NVIDIA Ampere architecture can be found in NVIDIA’s Ampere Architecture White Paper, which will be published in the coming days.*\n\n**Any idea if the dual airflow design is going to be messed up for inverted cases? More than previous designs? Seems like it would blow it down on the cpu. But the CPU cooler would still blow it out the case. Maybe it’s not so bad.**\n\n**Second question. 10x quieter than the Titan for the 3090 is more or less quieter than a 2080 Super (Evga ultra fx for example)?**\n\n>***\\[Qi Lin\\]*** *The new flow through cooling design will work great as long as chassis fans are configured to bring fresh air to the GPU, and then move the air that flows through the GPU out of the chassis. It does not matter if the chassis is inverted.*  \n>  \n>*The Founders Edition RTX 3090 is quieter than both the Titan RTX and the Founders Edition RTX 2080 Super. We haven’t tested it against specific partner designs, but I think you’ll be impressed with what you hear… or rather, don’t hear. :-)*\n\n**Will the 30 series cards be supporting 10bit 444 120fps ? Traditionally Nvidia consumer cards have only supported 8bit or 12bit output, and don’t do 10bit. The vast majority of hdr monitors/TVs on the market are 10bit.**\n\n>***\\[Qi Lin\\]*** *The 30 series supports 10bit HDR. In fact, HDMI 2.1 can support up to 8K@60Hz with 12bit HDR, and that covers 10bit HDR displays.*\n\n**What breakthrough in tech let you guys massively jump to the 3xxx line from the 2xxx line? I knew it would be scary, but it's insane to think about how much more efficient and powerful these cards are. Can these cards handle 4k 144hz?**\n\n>***\\[Justin Walker\\]*** *There were major breakthroughs in GPU architecture, process technology and memory technology to name just a few. An RTX 3080 is powerful enough to run certain games maxed out at 4k 144fps - Doom Eternal, Forza 4, Wolfenstein Youngblood to name a few. But others - Red Dead Redemption 2, Control, Borderlands 3 for example are closer to 4k 60fps with maxed out settings.*\n\n**What kind of advancements can we expect from DLSS? Most people were expecting a DLSS 3.0, or, at the very least, something like DLSS 2.1. Are you going to keep improving DLSS and offer support for more games while maintaining the same version?**\n\n>*DLSS SDK 2.1 is out and it includes three updates:*  \n>  \n>\\- *New ultra performance mode for 8K gaming. Delivers 8K gaming on GeForce RTX 3090 with a new 9x scaling option.*  \n>  \n>\\- *VR support. DLSS is now supported for VR titles.*  \n>  \n>*- Dynamic resolution support. The input buffer can change dimensions from frame to frame while the output size remains fixed. If the rendering engine supports dynamic resolution, DLSS can be used to perform the required upscale to the display resolution.*\n\n**How bad would it be to run the 3080 off of a split connector instead of two separate cable. would it be potentially dangerous to the system if I’m not overclocking?**\n\n>*The recommendation is to run two individual cables. There’s a diagram here.* [*https://www.nvidia.com/en-us/geforce/graphics-cards/30-series/rtx-3080/?nvmid=systemcomp*](https://www.nvidia.com/en-us/geforce/graphics-cards/30-series/rtx-3080/?nvmid=systemcomp)\n\n# RTX IO\n\n**Could we see RTX IO coming to machine learning libraries such as Pytorch? This would be great for performance in real-time applications**\n\n>***\\[Tony Tamasi\\]*** *NVIDIA delivered high-speed I/O solutions for a variety of data analytics platforms roughly a year ago with NVIDIA GPU DirectStorage. It provides for high-speed I/O between the GPU and storage, specifically for AI and HPC type applications and workloads. For more information please check out:* [*https://developer.nvidia.com/blog/gpudirect-storage/*](https://developer.nvidia.com/blog/gpudirect-storage/)\n\n**Does RTX IO allow use of SSD space as VRAM? Or am I completely misunderstanding?**\n\n>***\\[Tony Tamasi\\]*** *RTX IO allows reading data from SSD’s at much higher speed than traditional methods, and allows the data to be stored and read in a compressed format by the GPU, for decompression and use by the GPU. It does not allow the SSD to replace frame buffer memory, but  it allows the data from the SSD to get to the GPU, and GPU memory much faster, with much less CPU overhead.*\n\n**Will there be a certain ssd speed requirement for RTX I/O?**\n\n>***\\[Tony Tamasi\\]*** *There is no SSD speed requirement for RTX IO, but obviously, faster SSD’s such as the latest generation of Gen4 NVMe SSD’s will produce better results, meaning faster load times, and the ability for games to stream more data into the world dynamically. Some games may have minimum requirements for SSD performance in the future, but those would be determined by the game developers. RTX IO will accelerate SSD performance regardless of how fast it is, by reducing the CPU load required for I/O, and by enabling GPU-based decompression, allowing game assets to be stored in a compressed format and offloading potentially dozens of CPU cores from doing that work. Compression ratios are typically 2:1, so that would effectively amplify the read performance of any SSD by 2x.*\n\n**Will the new GPUs and RTX IO work on Windows 7/8.1?**\n\n>***\\[Tony Tamasi\\]*** *RTX 30-series GPUs are supported on Windows 7 and Windows 10, RTX IO is supported on Windows 10.*\n\n**I am excited for the RTX I/O feature but I partially don't get how exactly it works? Let's say I have a NVMe SSD, a 3070 and the latest Nvidia drivers, do I just now have to wait for the windows update with the DirectStorage API to drop at some point next year and then I am done or is there more?**\n\n>***\\[Tony Tamasi\\]*** *RTX IO and DirectStorage will require applications to support those features by incorporating the new API’s. Microsoft is targeting a developer preview of DirectStorage for Windows for game developers next year, and NVIDIA RTX gamers will be able to take advantage of RTX IO enhanced games as soon as they become available.*\n\n# RTX Broadcast App\n\n**What is the scope of the \"Nvidia Broadcast\" program? Is it intended to replace current GFE/Shadowplay for local recordings too?**\n\n>***\\[Gerardo Delgado\\]*** *NVIDIA Broadcast is a universal plugin app that enhances your microphone, speakers and camera with AI features such as noise reduction, virtual background, and auto frame. You basically select your devices as input, decide what AI effect to apply to them, and then NVIDIA Broadcast exposes virtual devices in your system that you can use with popular livestream, video chat, or video conference apps.*  \n>  \n>*NVIDIA Broadcast does not record or stream video and is not a replacement for GFE/Shadowplay*\n\n**Will there be any improvements to the RTX encoder in the Ampere series cards, similar to what we saw for the Turing Release? I did see info on the Broadcast software, but I'm thinking more along the lines of improvements in overall image quality at same bitrate.**\n\n>***\\[Jason Paul\\]*** F*or RTX 30 Series, we decided to focus improvements on the video decode side of things and added* [*AV1 decode support*](https://www.nvidia.com/en-us/geforce/news/rtx-30-series-av1-decoding/)*. On the encode side, RTX 30 Series has the same great encoder as our RTX 20 Series GPU. We have also recently updated our NVIDIA Encoder SDK. In the coming months, livestream applications will be updating to this new version of the SDK, unlocking new performance options for streamers.*\n\n**I would like to know more about the new NVENC -- were there any upgrades made to this technology in the 30 series? It seems to be the future of streaming, and for many it's the reason to buy nvidia card rather than any other.**\n\n>***\\[Gerardo Delgado\\]*** *The GeForce RTX 30 Series leverages the same great hardware encoder as the GeForce RTX 20 Series. We have also recently updated our Video Codec SDK to version 10.0. In the coming months, applications will be updating to this new version of the SDK, unlocking new performance options.*\n\n**Regarding AV1 decode, is that supported on 3xxx series cards other than the 3090? In fact can this question and dylan522p question on support level be merged into: What are the encode/decode features of Ampere and do these change based on which 3000 series card is bought?**\n\n>***\\[Gerardo Delgado\\]*** *All of the GeForce RTX 30 Series GPUs that we announced today have the same encoding and decoding capabilities:*  \n>  \n>\\- *They all feature the 7th Gen NVIDIA Encoder (the one that we released with the RTX 20 Series), which will use our newly released Video Codec SDK 10.0. This new SDK will be  integrated in the coming months by the live streaming apps, unlocking new presets with more performance options.*  \n>  \n>*- They all have the new 5th Gen NVIDIA Decoder, which enables AV1 hardware accelerated decode on GPU. AV1 consumes 50% less bandwidth and unlocks up to 8K HDR video playback without a big performance hit on your CPU.*\n\n# NVIDIA Omniverse Machinima\n\n**How active is the developer support for Machinima? As it's cloud based, I'm assuming that the developers/publishers have to be involved for it to really take off (at least indirectly through modding community support or directly with asset access). Alongside this, what is the benefit of having it cloud based, short of purely desktop?**\n\n>***\\[Richard Kerris\\]*** *We are actively working with game developers on support for Omniverse Machinima and will have more details to share along with public beta in October.*  \n>  \n>*Omniverse Machinima can be run locally on a GeForce RTX desktop PC or in the cloud. The benefit of running Omniverse from the cloud is easier real-time collaboration across users.*\n\n# NVIDIA Studio\n\n**Content creator here. Will these cards be compatible with GPU renderers like Octane/Arnold/Redshift/etc from launch? I know with previous generations, a new CUDA version coincided with the launch and made the cards inert for rendering until the 3rd-party software patched it in, but I'm wondering if I will be able to use these on launch day using existing CUDA software.**\n\n>***\\[Stanley Tack\\]*** *A CUDA update will be needed for some renderers. We have been working closely with the major creative apps on these updates and expect the majority (hopefully all!) to be ready on the day these cards hit the shelves.*\n\n# NVIDIA Reflex\n\n**Will Nvidia Reflex be a piece of hardware in new monitors or will it be a software that other nvidia gpus can use?**\n\n>***\\[Seth Schneider\\]*** *NVIDIA Reflex is both. The NVIDIA Reflex Latency Analyzer is a revolutionary new addition to the G-SYNC Processor that enables end to end system latency measurement. Additionally, NVIDIA Reflex SDK is integrated into games and enables a Low Latency mode that can be used by* ***GeForce GTX 900 GPUs and up*** *to reduce system latency. Each of these features can be used independently.*\n\n **Is NVIDIA Reflex just a rebranding of NVIDIA’s Ultra Low Latency mode in the NVIDIA Control Panel?**\n\n>No, NVIDIA Reflex is different. Ultra Low Latency mode is a control panel option, whereas NVIDIA Reflex gets integrated by a game developer directly into the game.  Through native game integration and enhanced algorithms, NVIDIA Reflex is much more effective in optimizing a game’s rendering pipeline for lowest latency.  \n>  \n> See our Reflex article here to learn more: [https://www.nvidia.com/en-us/geforce/news/reflex-low-latency-platform/](https://www.nvidia.com/en-us/geforce/news/reflex-low-latency-platform/) \n\n**The Ultra Low Latency mode supported CS:GO and Rainbow Six:Siege, why doesn’t NVIDIA Reflex?** \n\n>Unlike the NVIDIA Ultra Low Latency mode, NVIDIA Reflex provides an SDK that the developers must integrate. Having our technology directly in the game engine allows us to align game simulation and render work in a way that streamlines latency.  We’ve currently announced support coming for top games including Fortnite, Valorant, Apex Legends, Call of Duty: Black Ops Cold War, Call of Duty: Modern Warfare, Call of Duty: Warzone, and Destiny 2.  We look forward to adding as many titles as possible to our supported title list. \n\n**Does NVIDIA Reflex lower FPS performance to reduce latency?**\n\n>The industry has long optimized for FPS, so much so that there have been massive latency trade-offs made to squeeze out every last 0.5% FPS improvement. NVIDIA Reflex takes a new look at optimizing the rendering pipeline for end to end system latency.  While our research shows that latency is the key metric for aim precision and reaction speed, we understand FPS is still an important metric; so NVIDIA Reflex aims to reduce latency while maintaining  FPS. In the majority of cases, Reflex can achieve latency reduction without any FPS impact.  In a few cases, gamers may see small 0-2% FPS impacts alongside larger latency gains -- a good tradeoff for competitive games.  Of course, Reflex is a setting in-game, so gamers can choose for themselves.  Based on our testing though, we believe you’ll find little reason to ever play with it off. \n\n# PCIE Gen4\n\n**Will customers find a performance degradation on PCIE 3.0?**\n\n>*System performance is impacted by many factors and the impact varies between applications. The impact is typically less than a few percent going from a x16 PCIE 4.0 to x16 PCIE 3.0. CPU selection often has a larger impact on performance.We look forward to new platforms that can fully take advantage of Gen4 capabilities for potential performance increases.*",
    "comments": [
      "Holy shit these are detailed answers. Thanks so much! \n\nI'm still curious about the power requirements for the FE versions vs third parties, but perhaps that's not worth wasting time asking here, and rather waiting for benchmarks. Still, this is fantastic to read.",
      "Thanks ;)",
      "6 AM PST.",
      "Only thing I feel is missing is confirmation for what time the cards go on sale on the specified dates.",
      "No.\n\nSource: years of experience with hardware launches",
      "I'm disappointed but not surprised they didn't pick up any of those launch supply questions but it at least goes a long way in setting my mind at ease about 10gb on the 3080.",
      "Tim, you are a Great man. Keep up the good work :)\n\nYou helped so much people here, I can’t even express how good of an community manager you are. \n\nAll I can do is be happy that you are the manager :D",
      "I don't care about any of this. All I want to know is whether or not there will be enough units to go around.",
      "Will chicks be interested in my 3090 oc'd? :\\",
      "10gb is enough for 4k gaming today. And it's GDDR6X, which means much higher bandwidth and speed.",
      "If you use an air cooler like the noctua nh-d14, won't the front fan of the founders edition blow heat directly into the cooler? How much does it increase cpu temps?",
      "There’s always going to be outliers. Should EVERY card that rolls off the NVIDIA line be designed to handle the 4 games that have a higher ram requirement, or is handling 99.9% of games enough?\n\nIf you are willing to pay a premium they have a card for you, or will soon if they double the ram on the 70/80 offerings in 6 months with a Super edition",
      "1pm UTC",
      "Thank you :) Fixed",
      "Flight simulator has massive CPU bottlenecks so any comparison GPU-wise is going to make 3000 series look bad. Just my two cents.",
      "There is a very large flaw in your criticism. You are not disputing their claim; you are pointing out that it is not *always* a 1.9x improvement in PPW, whereas they claimed there was *up to* a 1.9x improvement in PPW. This is important, because PPW is not linear. This is why undervolting Vega chips could result in significant power reduction without significantly reducing performance, and why a 400w 2080 isn't going to perform 66% better than a 240w 2080. \n\n[This graph](https://images.anandtech.com/doci/16057/Ampere_PPW.jpg) from the reveal shows the source of Nvidia's claim. Ampere chips using just 130~ watts of power will have the same performance as turning chip using 250~. Thus, the 1.9x PPW claim. \n\nThis isn't particularly surprising. Optimal power/performance is typically much lower than the max wattage of the card. They are basically comparing the highest standard spec for Turing (which is going to be the least efficient, other than overclocked cards) with the optimal point on Ampere's curve. \n\nThe 1.9x claim is probably not false, though these benefits are mostly seen outside of where the desktop variants operate. This high efficiency at low powers might be more useful for laptops, though at that point we'll be looking more at how 80w~ on Ampere compares with 80w~ on Turing.\n\nEdit: ~~PFW~~ -> PPW (performance per watt)",
      "He's gone.",
      "Yes it can, they were just saying that pcie 4 will likely be a bit faster, which makes sense as pcie 4 m.2s are faster than gen 3 counterparts.",
      "Thanks! That'll help a ton with speculation. Any chance we can also find out when the review embargo will be lifted or do we just have to wait for that one?",
      "https://www.overclockers.co.uk/news/-pre-order-dates-announced-for-nvidia-3000-series-gpus-with-pricing-on-the-overclockers-website-550.html"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "high",
    "matched_keywords": [
      "rtx 3080",
      "3080",
      "3080 ti",
      "rtx 3080 ti"
    ],
    "title": "I can get a RTX 3080 TI for $800? Should I?",
    "selftext": "I have a GTX 1080 and need a upgrade. I was settled on the 4090, but saw the prize of this and wondered if I should pull the plug?\n\nI play on 1440p 144hz.",
    "comments": [
      "I ordered my 3080ti from Best Buy two days ago for $900 and will have zero regrets, especially after waiting for two years to replace this aging GTX 970 and considering the ongoing uncertainty of the market.  \n\n\nEdit: Changed price from 800 to 900.  Sorry if anyone noticed!",
      "Can't go wrong unless AMD announces (November 3rd) massive performance improvement at a lower price forcing Nvidia to lower their prices.",
      "The 4080 12GB has the same gaming performance as the 3080 Ti. It's not worth it.\n\n[These are Nvidia's own performance comparisons with the 3090 Ti](https://www.reddit.com/r/hardware/comments/xjiafr/the_official_performance_figures_for_rtx_40/?utm_source=share&utm_medium=android_app&utm_name=androidcss&utm_term=1&utm_content=share_button) (80 and 90 Ti are extremely close).",
      "I have my doubts that it will play out so well in the first generation of this technology, but I’m glad to hear the optimistic take.",
      "So tell me how to get 144 fps on a 3080 then in Cyberpunk, rdr2, ac almost any new game you name it. Because I am getting around 100",
      "To be fair you're comparing it to the 4090.. the 4090 is absolutely a beast. Almost the cost of two 3080s though",
      "Of course, there's a lot of global factors. R&D isn't free either. Considering inflation and performance, I don't think the rtx 4090 is a crazy price either. I honestly was expecting closer to $2000 if the performance figures are true.",
      "Absolutely, buy into Nvidia's strategy of clearing 3xxx stock.",
      "I think that's pretty unlikely. My sense is that much of the price increase is on the foundry's end, where AMD is paying the same cost.",
      "Fake frames. Don't be fooled.",
      "TBF you dont really need 144fps on single player games, 80ish if fine. Only need high refresh rates for competitive games.",
      "The thing is AMD can undercut Nvidia, they have the ability to... The new architecture is chiplet based and AMD already has much smaller cores than Nvidia. So their yields are going to be vastly higher than Nvidia with massive GPU cores. Im really curious what Nvidia's yields are They cant be as high as AMD with the die sizes. So AMD can add and subtract as many GPU chiplets as it wants and will have less defective chiplets per wafer. Its going to be the same way as AMD vs Intel. Simply put they can out produce and produce more product for a lower price. Nvidia simply cant drop the price on the 4000 series, they need to sell the 3000 series stock they still have. they do then they destroy what AIBs they have left and ther bottom line will be destroyed. AMD honestly is probably going to obliterate them with this generation, if rumors are true. Nvidia is about to get it world rocked... I would be very very worried if I was Nvidia right now.  \n\n\nThe only thing they really have that is going to help them right now is CUDA and DLSS 3.0 (which is smoke and mirrors) its more or less frame interpolation added to DLSS 2.0. IMHO it should have been called DLSS 2.5, its nothing new...",
      "I miss that excitement to a degree. I haven't skipped a cycle in a long while but when I was younger and had less money, definitely had those gaps and getting upgrades were so amazing. I am skipping this nonsense from NVIDIA though this time around. As for the junction temps, really not a big deal unless you're going to try and push the card. You could undervolt the card to help some with that to avoid taking it apart. Either way, taking them apart isn't that scary (did it 2x with mine). Just be gentle and watch a few tear down videos before you do it. The only really fragile parts to be extra careful with are the RGB and fan connections.",
      "That's crypto scarcity + stimmy check prices, 2022 is not comparable. There's a reason why no one would by a 3080ti for $2k today.. and most people aren't actually complaining about the price/performance of a 4090.. it's the 4080/\"4070\" that aren't good deals",
      "4090 was shown with DLSS 3 and frame interpolation.",
      "Yeah, I can’t complain, either. The 30-series still feels new since so many people couldn’t afford it during the electronics shortage, and the performance is great.",
      "The way Nvidia has priced the 4000 series, it's likely 3000 series stock will be around for a while.\n\ni.e. I'd be surprised if 3080 Ti's weren't still available for $800, or less, months from now\n\nAMD's RX7000 launch event is on the 3rd of November, so it's probably worth waiting for that to see what their price/performance is going to be like.\n\nAlso, even though RTX 4000 series pricing is awful, and they're definitely milking the margins, the 4070 (4080 12GB) is probably the better buy if you're looking around an $800 spend.\n\nI'd definitely wait for benchmarks of the first 3 4000 series cards.",
      "Yea I'm going to skip the 4000 series, with all the negative feedback, I hope the 5000 series will drop in price like how the 3000 series did.",
      "In a similar position got a 1080Ti planned to get a 3080Ti but pricing stupid came out too late I decided to wait for 4080. I'd say wait until benchmarks released for 4090 cause you're already getting up there and saves upgrading next release",
      "I think you should go for it. For $800, its price-to-performance should match the next-gen. We should expect the 4070/4070Ti to match the 3080Ti, and those cards are likely to be priced in the $700-800 range."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "high",
    "matched_keywords": [
      "rtx 3080",
      "3080",
      "3080 ti",
      "rtx 3080 ti"
    ],
    "title": "RTX 3080 Ti, constant cycling between 30fps and 60fps on all games",
    "selftext": "What it says in the title, I've been having this problem mostly with FFXIV but it's starting to happen on other games now. I have fiddled with Vsync as so many people have told me to, turned it on and off, switched it to adaptive, locked framerate at 60, 72, and 144, switched my screen's refresh rate between 60 and 144, and nothing has fixed it. Also tried updating and clean reinstalling the drivers 3 times over.\n\nMy other specs:  \nRazer Blade 17 (Gaming Laptop)  \nMicrosoft Windows 11 Home 10.0.26100 Build 26100  \n12th Gen Intel(R) Core(TM) i9-12900H 2.50 GHz  \nGeForce RTX 3080 Ti Laptop GPU (Razer Blade 17)  \n32GB RAM, DDR5 2500MHz  \nSamsung SSD, 1TB  \nCPU temp 44C, GPU temp 80C (when in game)",
    "comments": []
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "high",
    "matched_keywords": [
      "rtx 3080",
      "3080",
      "3080 ti",
      "rtx 3080 ti"
    ],
    "title": "Should i get a RTX 3080 HOF or a RTX 3080 TI base low end edition?",
    "selftext": "As the title says, both are priced about the same...",
    "comments": [
      "Base low end edition? Never heard of that. The 3080ti is obviously better than the 3080…",
      "The 3080 Ti of course",
      "The TI has more cores.",
      "4070 Super",
      "Base 3080ti and you can shunt/powermod to reach 3090ti level. https://www.3dmark.com/spy/44615687",
      "ti duh it’s better",
      "there was never a oc edition of a gpu that beat a one tier higher gpu.",
      "Thanks everyone, think i'm going with the 3080TI",
      "I think you should wait a few months for the flood of second hand 4090s and get one of those instead"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "high",
    "matched_keywords": [
      "rtx 3080",
      "3080",
      "3080 ti",
      "rtx 3080 ti",
      "3080ti"
    ],
    "title": "Replacement for Rtx 3080 Ti Gainward Phoenix",
    "selftext": "Please can any expect recommend me on what to upgrade to from my 3080Ti. Suggestions are fully welcome. Thank you in advance.",
    "comments": [
      "Wait for the 5000 series to consider your upgrade options. In the meantime enjoy your GPU, it's still a beast.",
      "4080/S or 4090 is your only option for a significant upgrade. Or 7900xtx",
      "4090 is the only alternative but it's too expensive for a 2 year old card. Wait for the 5000 series to come out.\n\nAlso, this thread asked the same question yesterday https://www.reddit.com/r/nvidia/comments/1ex3vlf/upgrading_from_a_3080ti_is_it_worth/",
      "4080/4080 super/4090 are the only reasonable upgrades\n\nIf you dont like these cards/can wait, then wait for 59 series ofc",
      "Let's wait for another shortage and price spike dude",
      "Budget?",
      "4090 is your only option that makes sense rn (67% faster according to techpowerup)",
      "Thank you",
      "Thanks alot, was truelly helpful, will wait for the 5080 or 5090",
      "Will consider, thank you",
      "A few 1000+. I read the other comment and i will wait for 5000",
      "A few 1000+ won't be enough for a 50 card in January"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "high",
    "matched_keywords": [
      "rtx 3080",
      "3080",
      "3080 ti",
      "rtx 3080 ti"
    ],
    "title": "NVIDIA GeForce RTX 3080 Ti Founders Edition pictured",
    "selftext": "",
    "comments": [
      "omg it took them a Ti variant to correct the 8?",
      "Woooow it looks just like every other 30 series Founders edition card!",
      "I didn't think they'd do a FE, but what's more shocking is that it takes the 3080 cooler, and not the 3090.\n\nIts heat output will be much closer to a 3090... Yes it won't have backside memory modules but still.",
      "Should have come with the 3090 FE's cooler to be honest.",
      "Holy fuck. Just saw it",
      "Only early models had an upside down 8. Got mine in January and it’s upright",
      "I checked on mine which I got in april and it's upright too, reading this thread had me sweating.",
      "Yeah my 3080 already plays Minecraft great. I guess ill get a 3080 ti just to put on the shelf.",
      "it was upside down :)",
      "The only surprise there is that it’s using 3080’s cooler rather than 3090’s. I suppose they do need to create some reason for buying a 3090 so it does make sense.",
      "I’m out of the loop, what was off about the previous one?\n\nEdit: I see it now and I can’t unsee it damn",
      "For sure...\nI was really hoping the 80Ti would have the 90 cooler, but maybe in a different shade of grey.",
      "The 3080 FE looks so good but damn if I had that in my pc and saw it now my ocd would kill me",
      "Hmm they say that the cooler is same as base 3080, not sure about possible temps, sure there wont be vram on the back but in theory gpu core should output same amount of heat as 3090, it will be probably alright but i expect worse temps overall than both 3090 or 3080.",
      "As someone with a 3090 FE, I fully agree. That cooler is a beast and can deal with a ton of heat while still being quiet. The 3080 FE cooler is not bad, but extra wattage is going to make it scream.",
      "I assume the existing FE cards won't be LHR but the 3080/3070 Ti will be.",
      "I mean if you can actually get one you can just sell your 3080 after and pretty much get paid to get a 3080 Ti.",
      "They said the FE cards wouldn't have LHR. Which was fine, they can just keep producing the same cards as before.\n\nBut then they release this. So I guess this is an FE card that'll have LHR and only the other old ones won't? (And if they release a 3070Ti FE, presumable it will also have LHR on the FE?)",
      "I hope they are selling these though bestbuy canada. The best FE we got is 3070.",
      "Not the damn power connector though"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "high",
    "matched_keywords": [
      "rtx 3080",
      "3080",
      "3080 ti",
      "rtx 3080 ti"
    ],
    "title": "New Firmware Boosts RTX 3080 Ti Mining Speed By 21 Percent",
    "selftext": "",
    "comments": [
      "This is sure to bring more GPUs to gamers. \n\n/s",
      "And they lose passwords to their wallets",
      "it's funny, the article is based on a reddit discussion and yet, this reddit discussion links the article rather the actual source of the info lol",
      "Lovelace is TSMC 5N which is a more expensive process than Samsung 10nm+++ (8nm), and TSMC increased wafer prices further earlier this year as a result of high demand. Prices for the RTX 40-series will be higher for sure. Also there is significant inflation across Western nations as the bills for the year-long lock downs and money printing are coming due (inflation is 6%+ in the US atm, 5.4% in Europe, both rising). You can forget about those Ampere MSRP's, you will never see that again.",
      "Correct. The 3080 Ti just received a hefty price raise of about 20%. Amen to those who buy a used 3080 Ti. Will probably already been opened a few times, overheated a few more times and had it's firmware raped endlessly.",
      "Dude. Water cooling literally won’t make any difference to room temperature whatsoever versus air cooling. Heat is heat and has to go somewhere.\n\nIf anything watercooling would be even more efficient at extracting heat and make the room even warmer.",
      "China may well do that",
      "It's a good way for people who already have money to get more money.",
      "The real source is in a evga forum and is like 2 or 3 months ago",
      "I would use my 3080 to mine when I'm not playing games but my room would be the opposite of chilling.",
      "We can't do anything fellow users. Guess we can jus see if intel and nvidia claim chip shortage will improve and look foward for. Lovelace(hoping d price isn't fixed acc to new msrp)",
      "Amen",
      "Well no that's why I asked, you still didn't answer the question. Real woke",
      "Honestly my dislike for this mining thing goes way beyond the inconvenience of being unable to purchase a GPU at the moment.\n\nI'm genuinely of the opinion that the world would be better without this wasteful pyramid scheme, in general.\n\nAn ecological disaster in the making and entirely for the sake of an idiotic speculative bubble that doesn't produce any real value for people.",
      "He was talking about using a secondary radiator inside to actually bring the coolant back up to avoid this lol. Shit was wild",
      "Greeeaaat.... that's great...",
      "that was /s for sad, not sarcasm =(",
      "There was a dude in Alaska who put his rad outside lol. Was getting great temps",
      "That's great until the coolant is so cold it causes condensation and drips water on your shit.",
      "Waste electricity to print internet money: Disapproving Drake\n\nWaste electricity for entertainment : Positive Appraisal Drake"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "high",
    "matched_keywords": [
      "3080",
      "rtx3080"
    ],
    "title": "RTX 4070 TiS Upgrade from a 3080 10gb?",
    "selftext": "I'm struggling with a decision right now. I want an upgrade for my PC. I run a RTX3080 with 10 GB and I'm worried that 10 GB are not enough for high FPS gaming in the long run with WQHD resolution. The 4070 TiS seems to be just the right Card for my purpose hence it's 16 GBs.\n\nI have a R7 5800X3D and I think the 4070 TiS would run really good with it.\n\nI'm not a newbie at PC-Building but not an expert either so I'm looking for advice now from you folks.\n\nIs it worth for just the memory upgrade or am I about to do something stupid?\n\nPlease no \"Buy a Radeon then\" comments! Had a AMD Card befor and only had problems with it!",
    "comments": [
      "The only upgrade that's worth it is 4080S/4090 in my opinion from a 3080.",
      "Wait für 5000 series",
      "So wait one year or more for gpu ?\n\nPeople forget that there is not push to Nvidia to release anything stronger than 4090 because AMD gave up on high end so Nvidia has two options now push the release of 5090 to 2025 and release lower tiers even more later or release 5090 in q4 2024 and release lover tier few months later\n\nJust look how good are the sales of 4090 - because there is no gpu close to it so why they would be any rush to release anything stronger",
      "Don't get me wrong. Second hand is a good option in most cases, but when it comes to prices like that, I'm a little to cautious. Also second hand purchases often have no RMA options in case something is wrong with the Item. I appreciate your Idea tho.",
      "Look at it this way: the 4070 Ti Super will only get cheaper. Unless another COVID/Crypto thing happens when you’re looking to upgrade there is never a downside to waiting until your tech isn’t doing its job. If you wait a year the 4070Ti Super will be cheaper because the 5000 series should be out.",
      "I’m going from a 3080 10gb to the 4070TiS because is stronger in almost any scenario, but the main reason is power consumption, less for more, no need for anything else .",
      "I think this rationalization suggests your should hold off.  Save and wait for real upgrade that you can afford.  Upgrading for the sake of upgrading is only good for nvidia.",
      "That is why I suggest ebay so you can pick seller with good rating and there is protection but I do understand it is not for everyone",
      "- IMHO, the only logical upgrade path from the RTX 3080 is the RTX 4080/4080 Super.     \n- For reference, look at the review of the 4070 Ti  Super by techpowerup (https://www.techpowerup.com/review/zotac-geforce-rtx-4070-ti-super-trinity/31.html):   \nAt 1080P:   \nThe RTX 4080 16GB averages 193.8 FPS   \nThe RTX 4070 Ti Super 16GB averages 174.5 FPS    \nThe RTX 4070 Ti 12GB averages 167.6 FPS   \nThe RTX 4070 Super averages 157.6 FPS      \nThe RTX 3080 10GB averages 139.1 FPS      \nAt 1440P:   \nThe RTX 4080 16GB averages 154.1 FPS   \nThe RTX 4070 Ti Super 16GB averages 135.1 FPS    \nThe RTX 4070 Ti 12GB averages 128.2 FPS   \nThe RTX 4070 Super averages 118.6 FPS   \nThe RTX 3080 10GB averages 106.1 FPS   \nLook at the data and make up your mind.",
      "Well 4080 super starts from 1109eur",
      "He has a 3080 that is perfectly capable of playing AAA games at 1440p.",
      "Well second hand is not really my cup of tea. You can get scammed so easily, especially at electronics",
      "\"Problem\" is an overstatement. The 3080 is still very strong. There may be one or two games that struggle at 1440p/max.  But turn the textures down, and these games will be fine.",
      "It looks like you are not really in a rush and do not need a new GPU immediately. I would say wait a bit for the price of 4080 super to come down to near MSRP (Pre-orders often suffer from huge markups).",
      "I'd definitely go for a 4080S. Probably around a 50% improvement. \n\nI had a 3080 10Gb with a 5800x. Due to unfortunate events, I'm now running an rx560 lool.\n\nBut yeah. If I'm spending that much money for 16 gb vram, I'd rather just spend like $50-100 bucks more for the 4080S",
      "My friend drop down your itch if you cant afford minimum a 4080. Use nukem fsr 3.0 mod, and if you cant hold back start upgrading rest to a 7800x3d",
      "Honest question because I am in the same boat, why dont you wait till 5070/5080 ?",
      "Anyone still rocking Ampere, especially high end Ampere like the 3080, should just wait for a 5000 card since we're over halfway through the generation, maybe do a full system upgrade with Zen 5 or whatever-lake. At WQHD you're fine with 10GB outside of really unoptimized games like TLOUP1.",
      "Nah Bro. I had to plan a whole new system for that. My MB is still good to go, no need for an upgrade there.",
      "That's still a whooping 200€ and I'm on a Budget ..."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "high",
    "matched_keywords": [
      "rtx 3080",
      "3080"
    ],
    "title": "RTX 3080 Buyer's Mini Guide: Which 3080 do I get?",
    "selftext": "Was suggested I make this by someone so here it is.\n\n**You want a RTX 3080**, *but you don't know which one to get*. With RTX 3080 stock being almost non existent, the answer here in most cases is.. the one that you can get, unless you don't mind waiting. In all honesty, you're fine getting almost any RTX 3080 as long as you aren't paying anything outrageous for it, because they all perform within a few percent of each other. If there's ANYTHING to take away from this guide, it's that the 3080 has little to no headroom, so there's *verrryy* little difference between most of the partner RTX 3080 cards. Any extra money you spend on a \"better\" model will not go very far, and that's because the 3080 seems to scale *TERRIBLY* with more power than it's already given target TDP. You will have a much louder and power hungry card for only a few fps more if you try to overclock.\n\nLet's pretend these video cards will be in stock soon, and you want to make an informed decision. I'll make a breakdown of what I already know from my too many hours of free time spent googling things. This is by no means a complete guide, but it is close to semi-complete and can be used as a starting point in your search for the 3080 card that best fits your needs. Hopefully with a little more user input, and more information revealed with time I can make this into a more complete guide (I will try to keep updating this as I learn more things).\n\n**The All Rounder**\n\n* *Asus TUF*\n\nIf you wanted a short and sweet tl;dr, the answer is just to get an **Asus TUF**, which is retailing at $699 MSRP. This is the all rounder choice. Great cooler that easily outclasses even more expensive cards, none of the other cards in the same price bracket come close in db normalized cooling results (the quiet bios is kick ass imo). Comes with dual bios, which you wont find in any other card at this MRSP, and also has a higher TDP limit (370w) than pretty much all the other similarly priced 3080 cards. There are better cards than this one (as you'll find out below if you keep reading), but the difference between them and this one is *sooo* small that you're better off saving the difference in money to spend elsewhere.. I think most reviewers will agree with me here. I may add one or two more all rounders here in the future if any come close value wise. PS Current reviews are for the TUF OC model. I believe the only difference is factory overclock (if it is, just get the cheaper one), but I could be wrong, and the difference might be the power limit set by the bios. Hopefully someone can confirm this for us soon. Edit: just confirmed it, the max power limit is the same for both models. Don't bother spending extra for the OC model. \n\n**The slower ones?**\n\n* *MSI Ventus, Zotac Trinity*\n\nSo the slower ones.. aren't really that much slower. Literally like 1-2% slower than FE, be it to a bad cooler design, or purposely gimped by a low power limit. Seriously, you're fine getting whatever card if you can at least get it close to $699. Don't be put off by getting like 0.5-1 fps less. However I will say, that there's no reason to get any of these cards if the TUF is available at it's MSRP price. Currently in this list we have the **MSI Ventus** and **Zotac Trinity**. I believe there are a few cards I've missed, so I will add them to this list as I find them. Who knows, the ones gimped by lower power limits could possibly be worked around with bios flash in the future, but I wouldn't risk voiding warranty just for 1-2% more performance.\n\n**The Compact Cards**\n\n* *Founders Edition, and EVGA XC3*\n* *Honorable mentions: Asus TUF, and PNY XLR8 EPIC-X*\n\nNow here's a category that I think is worth considering important, because there are going to be some of us working with less case space than others. To see a comprehensive spreadsheet detailing the various dimensions of most of the different RTX 3080 models we have available check out the one that  [u/MattVanAndel](https://www.reddit.com/user/MattVanAndel/) has made [here](https://docs.google.com/spreadsheets/d/e/2PACX-1vT-JXCyCCUyrmtnH0hOLZStrE2mljLHConizXGL-ysKDzbH_aCWynoOwWqRtnPEDE0Tp6KIm8xVFfRJ/pubhtml?gid=0&single=true). The king here is by far the **Founders Edition**, nothing comes close in compactness. The smallest partner model is the **EVGA XC3**, however beware that the black edition does not come with a backplate. The **Asus TUF and PNY XLR8 EPIC-X** are also fairly compact relative to their peers, so I've added them as honorable mentions. EDIT: Was brought to my attention that the FE might be a no go for some sandwhich style SFF cases. Keep that in mind if you're building in a SFF case, the FE may not be for you. \n\n**I got money to blow for a few percent more of performance**\n\n* *EVGA FTW3, Asus Strix, Gigabyte Aorus, probably a few others I missed*\n\nJoke title aside, some of these models may be good for better thermal/acoustic balance, letting you game with less noise. I think we will need more reviews to be certain about which models will be best for this, I think I will give this a separate section once we have more info. For now, silent cooling can easily be accomplished with a custom fan profile and negligible performance penalties on most cards already. The EVGA FTW3 has already claimed overclocking records on live stream with gamersnexus. The strix and Aorus will without a doubt have very high power limits as well, and great PCBs. Im not too sure about the Aorus cooler yet, but if the TUF and previous Strix models is any indicator of what the Strix might be I don't think we have to worry about the Strix not being an amazing card. These are currently your best choices for top end partner cards as they have better components on their PCBs, usually better coolers (this can be a hit or a miss), and probably most importantly, higher max power limits with the addition of an extra 8 pin connector. Should you spend extra for any of these cards? Unless you really like how one of these looks (good help your soul if you like the FTW3 for it's looks), or *realllyyy reallllyy* want a few percent extra performance and that *very* tiny bit of extra OC headroom, cause you're a \"hardcore overclocker\", I wouldn't bother paying extra for one of these. I guess there is that third category you could fit too, where you just buy shiny things to make yourself feel better like myself (hence my strix preorder lol). I may have missed a few cards here, but as more cards are released and reviewed I will be able to update this list with my findings.\n\n**Cards with Caveats**\n\n* *MSI Ventus/Trio, EVGA Black Edition*\n\nThese are the weirdo cards. Let me explain. The **EVGA XC3 Black Edition** does ***NOT*** come with a backplate, if that's important to you, skip this card. The **MSI Ventus/Trio** cards come with backplates.. but they are not metal, they're some sort of plastic. Now you know. These might be things to consider when making a purchase. I will add other cards here if I find anymore weirdo cards. Edit: there's been some discussion on the backplates of the msi cards. These are graphene composite, mostly plastic but advertised for the use of graphene to have thermal benefits. Personally I'm skeptical and don't think there's any really benefit to be had over the metal backplates + thermal pads but you guys be the judge. \n\n**In the Middle**\n\n* *Pretty much everything else*\n\nThis is where most cards fit, right in the middle. This includes the TUF, and the Gaming X Trio, but the big difference is, one is cheaper than the other. The Gaming X Trio does *very* slightly better in most benchmarks and overclock a bit better, likely due to the extra 8 pin connector, but its too close to be worth the extra cost, worse thermals and plastic backplate. What *CAN* make it worth it is the warranty. If you like MSI warranty more than Asus warranty, I think this easily makes the Gaming X Trio worth the extra cost. See the section where I discuss warranty below. I think if a vbios flash mod to raise the max power limit ever becomes available for the gaming x trio that it could become the best value \"overclockers\" card since it is the cheapest triple 8 pin model, making it perfect for slapping an aftermarket cooler or waterblock on. I will add more cards to the discussion here as more reviews surface for the other difference models. PS the difference between the \"ultra\" and \"gaming\" EVGA cards seem to only be factory overclock. As far as I'm aware that's the only difference, but one may have a higher max power limit for all I know. Some claim that the factory overclocked versions are binned better, but EVGA themselves had said that there's no difference between the two in binning. Either way, the silicon lottery wont discriminate between the two so I say just go with the cheaper version. The Gigabyte Gaming OC is a great in the middle card I think, it costs a bit more than the TUF, but comes with a year longer warranty and also has a dual bios switch. I still think the TUF is a better choice cause of its cheaper price, but pricing isnt going the same everywhere so this is another card you can consider if it's cheaper. PS some gigabyte and asus cards come with an extra HDMI, if this is something useful to you that's something to consider. The eagle is pretty decent card too. I think I need to split this category into two soon, for the better in the middle cards and just average ones. \n\nEdit: some people seem to think I'm sleeping on the msi x trio. It's a good card but I don't think it's as good as the cards in the higher performance bracket. The main reason being is poor max power limit (only 350w). Everything else about it is good. It runs fairly cool, not the best cooler but it's good, and it  is a very quiet card. Also comes with one of the highest if not highest factory overclock. This makes it a good middle bracket card, but still not as good as the very top end ones which have much higher max power limits. I stand by what I said before, it's a great card that's slightly better than the tuf but at a premium. I've also got word that the power components on the PCB aren't as good as some of the other cards BUT I have not confirmed this myself so take this with a grain of salt. It's still a good card regardless. \n\n**I want a needlessly overkill card that comes installed with a waterblock**\n\n* *EVGA Hydro Copper, MSI Corsair, and Gigabyte Aorus Waterforce*\n\nThese are not available yet, but they are confirmed to be coming ~~soon~~ (who knows when). These typically feature very good PCBs and are paired with a waterblock. I can't tell you which one will be better. I couldn't even tell you which ones were better for previous generations, and I've looked. PS The MSI Corsair is the successor to the MSI Seahawk line, and will believe it or not, feature a Corsair waterblock. I believe there will be some AIO type models coming too. I'll update this portion of the guide when I get more information.\n\n**Cards that will get Waterblocks**\n\n* *Founders Edition, Reference PCB cards, Asus Strix, MSI Ventus and MSI Gaming X Trio, Asus TUF, EVGA XC3, Zotac Trinity*\n\nI don't know too much about what cards will get waterblocks even though I do plan on watercooling a 3080 in a custom loop myself. Figured I should throw what I do know here anyways because it might help someone. The two most obvious ones, **FE** cards, and reference cards, most big block manufacturers will have blocks for both. A lot of you know this already but I should clarify anyways for the uninitiated, but the **FE** cards are ***NOT*** reference PCB, they are a custom nvidia design and will need a different waterblock. As for figuring out which cards have reference designs.. just look up any reference rtx 3080 waterblock and see what cards it supports. EK has confirmed a block for the **Strix**, and Alphacool has confirmed that they are making blocks for **MSI Ventus** and **Gaming x Trio**. Edit: EK has also confirmed upcoming waterblocks for the **Asus TUF** and **EVGA XC3**. The FE blocks will follow shortly after. The zotac trinity will also be getting a block from both ek and bykski. \n\nUpdate: Confirmation on upcoming blocks from u/Eddy-Alphacool\n>We are working right now on blocks for:\n>\n>Asus ROG Strix RTX 3080  \n>Asus TUF RTX 3080\n>\n>Founders Edition 3080  \n>Founders Edition 3090 \n>\n>Gigabyte Eagle RTX 3080  \n>Gigabyte Gaming OC RTX 3080\n>\n>MSI Ventus 3X  RTX 3080  \n>MSI Gaming X Trio RTX 3080  \n>\n>\n>Presale will start in the next 2 weeks. They will be available mid/end october!\n\n**Let's Talk Warranty** (WIP/Very Opinionated/Take with a grain of salt)\n\nThis is without a doubt one of the best ways to choose your video card, even more so for the 3080, where there is very negligible performance difference between most of the different partner models. I don't know which models have longer than standard warranty as I admittedly have not looked into this too far yet, but I do know some cards like the **Gigabyte Gaming OC** come with 4 years of warranty. Most credit cards will offer you extended warranty on purchases made on those cards too. From what I understand Asus has bad RMA customer service (sad considering how great the TUF is). Community consensus seems to be that EVGA has the best customer service and that MSI also has great RMA service for video cards (can confirm this, MSI replaced my broken blower 1080 ti that I bought used with a ventus gp 2080 ti for free, no questions asked or any hassle). There are probably others with bad or good service, and I can't tell you which one will be better. I suggest doing your own research and picking the brand you feel most comfortable with warranty wise.\n\nCredit u/darkpriest\n\n>Just to add, ZOTAC offers 3 + 2 years warranty (total 5 years) for most of the countries except USA.  \n>  \n>Asus has a 3 + 1 year warranty (total 4 years) for some parts of the world.\n\nSince I'm calling this a \"close to semi-complete guide\" discussion and questions aren't only welcome, but encouraged! This guide can be improved a lot more with input from you guys.\n\nEDIT: Adding a bonus piece on power supplies since we get a lot of of is my power supply enough questions here.\n\n**Do I need a new power supply?!?!?!?!?!?!!**\n\nWhat power supply you will need will largely depend on how power hungry the rest of your system is (namely your CPU), but you more than likely don't need anything crazy, trust me on that.  On a tame system with something like a ryzen 3600 all you need is a decent 550w power supply. Focus on getting something that is good quality and reliable over higher wattage, this is more important than getting as many watts as you can. There are tier lists and PSU reviews that can help you find a good power supply. If you have a big power hog like a very heavily overclocked i9-10900k all you need is a *good* 600w or better power supply, and this is very clearly shown [here](https://www.youtube.com/watch?v=Bdohv96uGLw) in optimum tech's video. If you have a lot of peripherals/add-ons or are just a very anxious person you can err on the side of caution and get an extra 50 watts more than you need. Just make sure it's a **GOOD** power supply. If you're wondering why nvidia has grossly exaggerated their recommended power supply specifications it's probably because of how many terrible cheap power supplies there are available, that a lot of uninformed people end up buying. *Source: have built many computers with both crappy cheap high wattage psus and good ones with lower wattages.*\n\nPS Connect your dual 8 pin cards with sperate cables if you can, don't use a single daisy chained one. See the diagram below on how to connect your 3080 to your PSU.\n\nhttps://preview.redd.it/xp4zxywjzeo51.png?width=960&format=png&auto=webp&s=17233e280702a26f458a8265bd5d7d1823e17b8a\n\n*Source: I have too much free time and have been too obsessed with the rtx 3080*",
    "comments": [
      "The only way of picking for people at the moment;\nBuy what you find\n\n\nJoke aside pretty detailed guide, thanks",
      "Also might be worth mentioning that the higher end cards (FTW, Strix, Trio, etc) need 3x 8-pin connectors, whereas the other regular 3080's need just 2x. \n\nNot sure it'll matter in most cases, since most CPUs only need one of those connectors and most PSUs come with 4 total (I think?), but still might cause incompatibilities for some users.",
      "Doesn't seem to be a bad card. I believe that one comes with a dual bios and 4 years warranty, which to me are two huge pluses. I don't think you can go wrong with that one. Only thing to keep in mind is that it's a pretty big card. Be sure you can fit that big beastie in your rig.\n\nEDIT: Not sure about the downvote, but it seems like a decent card, performance is inline with most other cards if not slightly better. There is a review here if you want to check it out: [https://www.overclock3d.net/reviews/gpu\\_displays/gigabyte\\_rtx\\_3080\\_gaming\\_oc\\_10g\\_review/20](https://www.overclock3d.net/reviews/gpu_displays/gigabyte_rtx_3080_gaming_oc_10g_review/20)\n\nI did confirm that it is dual bios and has 4 years warranty. I still stand by what I said, I think these two features alone make it a great card.",
      "It's a pain in the ass if you have or plan to buy custom cables. Most kits come with two 8 pins, not three. Getting that one extra cable isn't always fun.",
      "Find any detailed reviews on the EVGA XC3 series? I have not found temps or sound of those.",
      "thoughts on the gigabyte gaming oc?\n\nthere's a lack of coverage on this card and its the one i have ordered lol\n\nthnx for that wonderful writeup",
      "I'm really interested to see what the Strix can do when they pulled off the TUF. I'm expecting it to beat the FTW3 at this point although even if it does I'll probably still buy the EVGA card just for better customer support.",
      "MSI with the best marketing team in the industry. Able to cut cost on the bill of materials and opted for plastic over metal. Behold \"graphene\" lol",
      "nine pocket quickest person cable innate simplistic retire ask dinosaurs\n\n *This post was mass deleted and anonymized with [Redact](https://redact.dev/home)*",
      "Sounds like I'm getting an ASUS TUF.",
      "It'll be next to impossible to buy and even large retailers like B&H have raised the price [back up to $779.99](https://www.bhphotovideo.com/c/product/1593649-REG/asus_tuf_rtx3080_10g_gaming_tuf_gaming_geforce_rtx.html/?ap=y&smp=y&lsft=BI%3A514) for it. ASUS [originally planned on selling the TUF for that higher price](https://webcache.googleusercontent.com/search?q=cache:GN-06oIMMJ4J:https://store.asus.com/us/item/202009AM150000004+&cd=4&hl=en&ct=clnk&gl=us) but dropped it to $699.99 to match the FE at the last minute, I'm not sure they're going to keep the lower price at this rate since they can't keep anything in stock anyway.\n\nIf you can get it at $699.99 I'd go for it, but at $779.99 the performance differences just aren't there to justify it, all the cards are so close to each other anyway.\n\n&#x200B;\n\nI think that's why this is reviewing so well, it's really a higher end card ASUS suddenly dropped the price for.",
      "You're sleeping on the MSI trio. Graphene backplate is a bonus as its strong and also lets heat dissipate and cool to the touch. Trio also comes in with a built in brace and an included bracket. At the same DBA (sound level) as the TUF they run at the same temps. (hwu review). Out of the box the MSI trio runs 71c full load and is the quietest of all the cards. It also runs 4-6% faster than a FE on most benchmarks, which is one of the fastest if not the fastest out of the box.  MSI has one of the better support systems in the event you do RMA. It also looks premium over the TUF.\n\nTUF is the better buy but only because of the price. But don't sleep on the trio it's the top awarded 3080 aftermarket I can find. Both are exceptional though.",
      "> Also might be worth mentioning that the higher end cards (FTW, Strix, Trio, etc) need 3x 8-pin connectors, whereas the other regular 3080's need just 2x.\n\nDone.\n\n> Not sure it'll matter in most cases, since most CPUs only need one pin and most PSUs come with 4 total (I think?), but still might cause incompatibilities for some users.\n\nNot worth mentioning I think. Most come with 4, and if not will at least have those 8 pin connectors that daisy chain into two. In this case you want to connect one 8 pin/6+2 pin cable to one connector, then use another to connect the other two, this is perfectly fine.\n\nEDIT: See this.",
      "It's one of the \"lower tier\" cards but the difference is so little that you likely wont even notice it in games.. We're talking half an fps difference at 4k, and maybe 1-1.5 fps difference at 1440p. I think people are making it sound worse than it is because there's really not much to differentiate most of these cards. These cards already have so little OC headroom anyways so you really dont benefit that much from having a better card. Even the acoustics arent bad, these msi cards are pretty quiet. They do run a little hot though, and they are pretty power limited, but neither of these things should matter if you dont plan on overclocking.",
      "I think you should make it more obvious that the higher end cards are also lower noise.",
      "It's not 100% graphene, these \"graphene\" backplates that MSI use are closer to plastic than graphene, unless something has changed with this generation. It's supposed to offer thermal benefits, but most reviews have shown that it doesnt really, at least compared to the metal ones we usually see.",
      "doesn't help with custom cables. custom cables usually don't offer the ugly Y-split",
      "Only difference is factory overclock I believe. You'll be fine with either, silicon lottery wont discriminate either model. People claim that there's a binning difference, but EVGA themselves say that neither of them are binned higher than the other. Just dont get the black edition if you want backplate.",
      "Ya he should have added \"Card thats possible to buy\" column, though that doesn't exist.",
      "Just to add, ZOTAC offers 3 + 2 years warranty (total 5 years) for most of the countries except USA.\n\nAsus has a 4 + 1 year warranty (total 4 years) for some parts of the world.\n\nI believe the rest are standard 3 years warranty.\n\nBased on pricing (might vary across the world), the only reason to get ZOTAC is because of its warranty.\n\nEverything else, just get ASUS TUF.\n\n\\*Please note almost all of the reviews are on ASUS TUF OC, while the ones available now are only the ASUS TUF (Non OC) model."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "high",
    "matched_keywords": [
      "rtx 3080",
      "3080",
      "3080 ti",
      "rtx 3080 ti"
    ],
    "title": "NVIDIA quietly remarking GeForce RTX 3080 Ti’s GA102-250 GPUs to GA102-300 for RTX 3090",
    "selftext": "",
    "comments": [
      "Never seen this before.  Bizarre.",
      "The 3080Ti is essentially the same as the 3090 right? Just less VRAM. \n\nIf Nvidia planned to launch the 3080Ti and had started making the chips I can see why they would do this. \n\nWhy sell cores destined for a $1000 SKU when they can use the very same chips for $1400 SKUs?\n\nDemand is still so high and stock so short that 3090s are still selling out and for ridiculous prices. I saw some priced at £2400 and they were all gone in a day.",
      "But where the 3080 at?",
      "Yeah. Same. I wonder why they were binned as a -250 initially. Maybe Nvidia thought there wouldn’t be enough of a market for $1500 cards and made a few -250 parts out of silicon that would have otherwise qualified as a -300?",
      "My 3090 is a SHIT undervolter compared to release cards. I was speculating with a friend that the lack of chip probably meant that chips that usually would go to “worse” SKUs because they are borderline as fuck are going to 3090 just to meet demand.\n\nGuess it’s true ....",
      "Pay more for 5% gains lol, 3080 still where it's at",
      "Thank you, I'm just going to fly to another continent to buy it.",
      "You would think a $1500 card would slow in demand within a few weeks, much less continue to sell out months later. They likely already had forecasts for how many cards of each segment would sell, so by the time 3090 sales collapsed the 3080ti would ship out.\n\nInstead all their cards still sell like they just launched so now they make more cash by continuing the 3090 markup.",
      "Ah I didn't know that. However, my theory could still hold true. \n\nIf the 3080Ti dies are essentially the same as 3090 dies and destined for one or the other SKU depending on quality or functional cores...it could still be the case that these chips were originally intended for 3080Ti BUT all their cores are functional and they bin well enough for 3090. Nvidia assessed the market conditions and repurposed them for 3090s.\n\nEither that or someone just engraved them incorrectly!",
      "1st rumors of 3080Ti were that 3080Ti will be same chip as 3090 just with 20GB of VRAM and less wide memory bus (so slower memory in total).\n\nCurrent rumors about 3080Ti is about as wide memory bus as 3090 but just with 12GB of VRAM and with less cores. So in nutshell more gaming oriented 3090.",
      "Few less cores too iirc",
      "You can buy a 3080 with the $2300 you get from selling your 3090 :)",
      "No, they probably made a bunch of GA102s that they were planning on selling as 3080 Tis, but they decided to unlock the cores and sell them as 3090s instead.",
      "We are never seeing a flagship card under $800 again, trust me.",
      "Good in theory, but with the way the market is, I strongly suspect that the real retail price of the 3080ti will be about that of the 3090 at launch. So those who waited for a more gaming oriented 3090 (cheaper, because 24GB is overkill for gaming) got screwed, because they’re not getting a cheaper alternative.",
      "More like double the launch price of a 3090.\n\nAs for those people you mentioned,  i think the only good thing i got out of all this was a laugh at how many in the 3080 threads (and multiple other forums/sites) were saying that the 10GBs of GDDR6X wasn't enough, and that they would wait for the 20GB version, and many of them were laughing at the potential buyers of the 10GBs 3080 saying that they got ripped off and that this GPU won't have enough VRAM soon.\n\nNow, not only did the plans for a 20GB 3080 got scrapped, not only are we getting a 3080Ti with measly extra 2GBs instead but with a $1000 MSRP slapped onto it, but also no one is even going to be able to buy this thing or even the 10GB model for less than $3K. Bwahahaha what a bunch of fucking idiots.",
      "When you're rich enough to just press a button in a computer to change a specification and still print money... \n\nNow all they need to do is make a box that says 3080 Ti 20 GB, with a large white line crossed out and under it \"3090 24 GB scalper edition\"",
      "Yeah I'm not sure how I feel about my 3090 still. Like obviously it's a beast but I still wish I got a 3080 and saved the $1000. I was on my way to buy a used 3080 off Craigslist for $2400 Canadian. I was about half way to the dudes house with the cash in my pocket and I realized I was being dumb. Went home, wrote a bot, got a 3090 in a few days from the local store for $2440 so it was really only $40 more than I almost paid for a second hand 3080. Initially I was going to resell it for $3500(I was swarmed with offers) and then use that money to offset a 3080 at $2400 but decided fuck it I'm keeping the 3090. That's the only way I can really justify it to myself and it's a bit sad. \n\nFor anyone curious about the script, I targetted a really specific store, I even had it automatically purchasing and the script would purchase the card at minimum 6 seconds and max 9 seconds after it became in stock(really fucking fast). Earlier versions of the script could take anywhere from 1-30 seconds just to notify me and I was being outbotted until I improved it down to 6-9 seconds. Part of the problem too was the site was rate limiting me and when a reached a certain threshold they would redirect my requests to their Facebook page (lol). So I signed up for NordVPN, wrote a side script that would detect if I'm being redirected to Facebook, and if I was, connect to a new VPN to get a new IP. Honestly I am not a web dev or anything but this script is a masterpiece for me. The next day I woke up with a confirmation email in my inbox for a TUF OC 3090 and now I play RDR2 at ultra 4k and I get around 60fps solid\n\nSad the lengths we have to go through. Why are there no captchas in place? Lol",
      "I think you're on the money. They were probably planning on launching a 3080Ti, but the market conditions are such that the 3090 is obviously supply is still well below demand. So might as well shelve the 3080Ti for a bit and sell more 3090s.",
      "Ahhh...you meant the 3080Ti...I thought you meant the FE 3080...many benches out there between that and the FE 3090."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "high",
    "matched_keywords": [
      "3080",
      "3080 ti"
    ],
    "title": "rtx 2080 ti vs 3080 ti or 4080?",
    "selftext": "Am I thinking of getting an EVGA 3080 or just a 4080?",
    "comments": [
      "the question is how much youre willing to pay",
      "Wait for the 4080.  Yes nvidia is dicking everyone down but when it comes down to it the 4080 is \n better.",
      "5080",
      "What do you define as comfortably?  My 3080 can't even play a lot of games on high+ settings at 1440p@144hz.  I don't think a 2080ti would be better in that situation either.  If it is 1080p, then you are golden, or if you just want 60fps.",
      "Everyone that isn’t making money from gaming is casual lol, and most of the pros are still on cards like the 1080ti playing at 1080p.\n\nI see your point though, but if you’re unable or unwilling to compromise on something(graphics, resolution, FPS), Jensen is just going to bend you over. You should really temper the advice you give to other people though, especially when it involves a potentially four figure purchase. Motion sickness isn’t that common, and the vast majority of the world’s population is happily gaming on much, much worse hardware than a 2080ti.",
      "I forgot to add my brother said he would buy my card 2080 ti for 250, and I'm selling my laptop to his wife for 250 too, so that's half.",
      "16g?",
      "What a nice brother you are. 2080Ti for only $250? Damn what a deal",
      "Worst buys in computing history? How do you already make that conclusion?",
      "A 4080 12gb is going to be only a few % faster than a 3080ti, meanwhile the 4080 16gb is going to be up to 30% faster. But the 4080 16gb is also insanely overpriced. \n\nI'd say the 3080ti is still a pretty good pick, it's atleast 35% faster than a 2080ti and has come down in price a lot.",
      "I could do 1200$",
      "Then depending on your monitor, I would either get a 3080ti or wait for the 4080.  If you are trying to get 144+fps, then go with the 4080.",
      "I'm a fan of dlss and Nvidia drivers , so 3080 \n\n6900xt is 10-15% faster in raster.\n\n\nI think go cheaper , I just think dlss will progress better than fsr",
      "That's an insanely good deal for both of them lol",
      "Metro RTX",
      "4080 for 1200$!? Or 6900xt for 700$!? Am I really going to get 100% uplift in performance!? If it’s just 15% that’s some",
      "If you can do 1200 you can do 1600. The 4080 (and \"4080 12gb\") are some of the worst buys in computing history.",
      "I play at 1440P",
      "Ture",
      "Tureing"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "high",
    "matched_keywords": [
      "rtx 3080",
      "3080"
    ],
    "title": "Just built my 2nd PC. RTX 3080 Ready. Have my old 1050 Ti in for now.",
    "selftext": "",
    "comments": [
      "Might want to flip the radiator so the barbs are at the bottom, otherwise you might get some noise issues since you will have air in the hoses.\n\nhttps://youtu.be/BbGomv195sk",
      "Flip the top fans to exhaust, it'll help with the 3080.",
      "Well I was planning on doing that but if I flip the radiator a 3080 won’t fit. It’s a fractal meshify c case and I’ll only have about a 7mm gap between the 3080 and the radiator.",
      "As an alternative, you might try top-mounting it. Might not look quite as stylish but it ~*should* have clearance for the RAM.\n\nSide note: My build is sort of the mini-me version of yours - Meshify C Mini & Kraken x62.",
      "Don’t you always want top fans to exhaust? CAuse heat rises.",
      "Good point",
      "Ryzen 9 3900x, NZXT Kraken X63, Corsair 850w, Corsair LL120 case fans, Aorus X570 elite, Corsair 16gb 3600mhz memory, Samsung 1 tb ssd, Samsung 500gb m.2. Then I’m waiting on a 3080.",
      "The buoyant force caused by rising heat in a PC case is *extremely* overpowered by the airflow due to case fans. It’s absolutely not a factor.\n\nThe reality is that in a standard ATX case even one standard 120mm case fan is enough to double the buoyant force of air in even the most extreme cases. \n\n[heres a great resource explaining this](https://www.pugetsystems.com/labs/articles/Vertical-vs-Horizontal-Case-Cooling-89/page3)\n\nFan location and case layout plays a much, much bigger role in cooling efficiency.",
      "It depends on the pressure differential of your setup. Top fans are not always needed for exhaust, a rear is more than enough if your front fans are intake (as an example).",
      "I have my radiator like this and have zero issues its not  even a definite cause of noise.",
      "1 mm is a tight fucking fit holy shit",
      "What rgb fans are you running",
      "Just finished my RTX 3080 ready build as well with my 660TI keep the PCI warm... Pretty much dead in the water for any newish games until can get my hands on 3080.",
      "I was going to have the same issue with space in the meshify c case, as I've just ordered a 280mm AiO but there is a solution to fit longer video cards in the meshify c case!\n\nTake a look at Bitwits video: https://www.youtube.com/watch?v=O_DXoIhMdj0&feature=youtu.be&t=295\n\nAnd at this guy on PCPartPicker: https://pcpartpicker.com/b/L38MnQ at picture 7. He also describes what he did in the description.\n\nIt is possible to mount the fans just inside the mesh and get 25mm extra clearance for GPU!",
      "I have a Meshify C and mounted my Corsair AIO on top. I had to remove my Corsair RAM to fit the radiator in, and wound up with a few CM of clearance once I put the RAM back in. And the Corsair RGB ram is fairly tall. I'm not sure I would be able to fit the radiator on the front, and have room for a 3080. The specs we have been given are for the Founders edition, and aftermarket coolers could make the card a tad bigger. I'm slightly worried about my front fans being too close as it is, and can't imagine a radiator as well.",
      "Yeah I think I can only fit the FE. All the AIB’s are over 300mm. Although the FE is definitely the best looking gpu of the lot IMO.",
      "Wait my bad, I have 286mm. I know it was 1 mm above the 3080 FE but couldn't remember the actual length. So I'm good just am an idiot",
      "Corsair LL120",
      "Corsair 850w",
      "this is what i thought"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "high",
    "matched_keywords": [
      "rtx 3080",
      "3080"
    ],
    "title": "RTX 3080 10 Gb vs RTX 4060 Ti 16 Gb?",
    "selftext": "1. Game I play such RE4 Remake needs more than 12 Gb VRAM with ray tracing and max settings. Which one do you think will be better choice?\n\n2. What happened if I maxed out all settings which the game says needs more than 12 Gb of VRAM on RTX 3080 with only 10 Gb? Will the game crashed?\n\n3. Will the RTX 4060 Ti more future proof in long terms when more games need more VRAM?\n\nOh I play at 1440p and 4K.\n\nEDIT:\n\nI guess since both card unable to play at max settings and needs compromise, what I really want to know is:\n\nWill stronger card but not enough VRAM give me a better experience vs weaker card but it has enough VRAM?",
    "comments": [
      "vram is only part of the story, core performance matters as much if not more. 3080 will go leaps and bounds farther since the 4060 ti hardly matches a 3060ti/3070 level of performance",
      "Where 3080 12GB? Also the 4060 Ti sucks, the VRAM is not worth it.",
      "Depends, 3080 will get you medium to high on 4K and 2k.. the 4060ti will get you ultra on 1080 \n\nUse purposes 3080 10gb serves you better \n\nI think the sweet spot for you would be to buy a 3080 12gb, 3080ti, or 4070ti at best price\n\nIf you find ANY of those for under $600 absolutely don’t pass it up, most of them go for $700-900 for reference but will fit your needs \n\nBonus for vram future proof 3090 under $800 is a good deal, they sell $800-1100 right now",
      "The 3080 is the better card, 4060ti 16gbs beats the normal one in like 2 games max. I tried maxing out re4 remake rt and everything it says 13gbs vram/10 and a lot of warnings in the menu but nothing actually happens the game just runs normally your vram uses stays under 10gb and you get 100+ fps . Maybe they downsize the textures or something I wouldn't know , didn't notice anything . The 3080 is still the faster card by like a looot even when it runs out of vram compare it to the 3070 or ti to have a closer comparation",
      "This exactly. The 3080 is significantly more powerful. BTW OP I would nix the 4060ti 16gb and make the options a 3080 or a 4070.",
      "VRAM is complicated to explain.\n\nEasy answer. Everybody (99%) has 8GB cards. Games are made for what people have. 10GB 3080 is OK. \n\nToday, I would 100% get 12GB 4070. More than enough.\n\nLook.\n\nThere will always be some weird game and max out setting that spills over 12GB or even 24GB..\n\nits cheaper to turn down 2-3 settings than pay $500 more.",
      "I'd try to save up for a 4070.",
      "4070",
      "Here is a video about the mentioned resolution. The 6800xt is same tier as 3080, but it has 16 gb vram but less raytracing ability. But for comparison it is maybe giving you some important information though.\n\nhttps://youtu.be/p2Kk7GR0lSc\n\nThe 4060zi ia fine for demanding 1080p ultra games. If you look up for 1440p or 4k, definitly its too weak. Anyway the 4060ti for 500$ is a bad buy. Id rather safe up for a 4070 or get a other card at 500$ range",
      "3080 12gb not an option?",
      "that really doesn't work like that. majority of people had 2 gb gtx 660s, 670s, 680s, 760s, 770s back in 2014. all it took a couple ps4 ports that required 3.5 GB+ VRAM in 2015 to push all those people to rush to upgrade. you cannot bend console game developers to your own will by spamming 8 GB cards to the market.\n\n2 GB VRAM became SO problematic that people mass flocked to 900 and 1000 series as soon as possible. Only reason it is not happening is because NVIDIA still keeps releasing 8 GB card midrange cards. but once they release a 350 bucks 12 GB 5060 that performs like a 4070ti (ala 980 to 1060), you can bet most people will jump the ship. and those who do not feel caught up in the FOMO and will eventually jump to the same ship. if not, they will do so to the next ship (rtx 6060) etc.\n\nif somehow NVIDIA keeps on with a 8 GB 5060, I have no idea what would happen the.",
      "![gif](giphy|phGElmSM4P0sg)",
      "The 4060ti is not a good deal and the 308010 gb too. Get a 4070 atleast because the 60 tier card suck if you look anything above 1080p.",
      ">just get the rtx 4060ti👍\n\nPushing that crap hard. How is that working out?",
      "To be fair neither does the 4060ti, though it's RT performance is leaps over the 6700XT",
      "I'm not saying dont buy more VRAM.\n\nI'm saying that nVidia only recently made 12GB and 16GB 4xxx, so it wont be obsolete in a week. Look. It took from 2014 when 1070 8GB released to now, for 8GB to be too little. \n\nUnless some new GDDR8 is invented, I think next 4-5 years we will be stuck on 16GB-24GB-32GB",
      "![gif](giphy|I7I3rKf0HJlCxyJQmC|downsized)",
      "Baaaahahahaha. Wait that’s a serious question?",
      "Just buy a 6700xt.  YW!",
      "Quick reminder that the VRAM calculators are estimates of VRAM usage at peak times in the game and not an indication of overall or even the usage by the game a majority of the time. If you're getting good performance but are over the estimated VRAM then you're generally fine. Paging to system memory or disk will have a performance hit but you'll know when that happens."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "high",
    "matched_keywords": [
      "rtx 3080",
      "3080",
      "3080 ti",
      "rtx 3080 ti"
    ],
    "title": "Gigabyte Confirms Avalanche of 20GB Nvidia RTX 3080 Ti, 12 GB RTX 3060 Cards",
    "selftext": "",
    "comments": [
      "The 1080 Ti is 4 years old, its features should be considered standard at this point, not bells and whistles.  11 GB is not a bell and whistle anymore.\n\nThat is why AMD is launching 16 GB cards (their 3060 equivalent card will be 12 GB probably).  Nvidia also has a 20 GB 3080 Ti in the pipe and potentially a 16 GB 3070 Ti.  The regular 8GB and 10GB models are the odd ones out. It's hard to talk about how much VRAM a card is \"capable\" of handling, but I think we can all agree the 3070 and 3080 can handle more than 8 and 10 GB.  They are gimped in their current state.\n\nThe issue is not that the 3060 has too much VRAM -- the issue is that the rest of the 30 series doesn't have enough.",
      "The 12GB 3060 seems like a gimmick to just compete with lower tier AMD as a selling point? Like it might do 1440p reasonably well but defiantly not 4K and I don’t see why you’d need 12GB of VRAM.",
      "TFW the 3080 you ordered will be outdated before you even receive it",
      "It's not even true, Nvidia had a single uarch that aged miserably (Kepler), they used it twice as the 600 and 700 series vs AMD's 7000 and 200 series.  These 2 generations are what started the myth.\n\nMaxwell and Pascal both aged beautifully, *especially* Pascal, which at this point are some of the best GPUs of all time.  The 1080 Ti in particular is going to be in the history books.\n\nMeanwhile Fury and Vega are crashing and burning, not \"fine wine\" but spoiled milk instead.  Navi isn't really old enough yet to show any signs of aging vs Nvidia.  The 400/500 series isn't showing massive gains against the 10 series, either.  These cards are approaching 5 years old now.",
      "We already knew about this. Goddamn reposts.",
      "Amd gpu doesnt age like a fine wine because of more gddr on board compared to its nvidia counterparts; its because their drivers are crap at the initial release but they managed to fix it with time, bringing the performance to its full potential.",
      "I don't know why people think VRAM has anything to do with display resolution anymore.  A triple buffered 32 bit color 4K framebuffer only uses up 100 MB of VRAM.\n\nIt's about the textures.",
      "Clickbait too. There is no \"avalanche\", it's perfectly normal for AIB's to have many different models of the same SKU, they do this every time.",
      "I hope the Rtx 3060 12 GB is around 250-300. GPUs have gotten unreasonably expensive these days.",
      "Why did the 1080 Ti need 11 GB?  It's probably going to be slower than the 3060.",
      ">I don’t believe that the normal 3060 has the processing power to render enough frames at a high enough resolution on high enough settings to warrant 12GB\n\nJust to be clear, the alternative on a 192-bit bus is 6 GB.  This should really be a discussion about whether \"more than 6 GB\" is useful on the card, not necessarily all 12 GB.  Just like the 3070 may benefit from more than 8 GB, but not all 16.",
      "Because there are people who don't upgrade every year or two?\nThis is the same argument 5 years ago for 1060, get the 3gb, 6gb is excessive. Same for the rx480, 4gb is plenty, 8gb is a waste of money. Today, 6gb is the bare minimum for 1080p and all the idiots who bought into the 3/4 GB cards are left with an obsolete GPU to save $30.\n\nPersonally I would not consider anything below 8gb VRAM a buy today. We have had 8gb cards for below 200usd for many years now, there is no reason a 200+ card in 2020 should have anything less.",
      "> A low tier card is going to struggle to make use of that much vram\n\n4K textures can still be useful even at lower 1080p and 1440p resolutions.  The more resolution a texture has, the closer you can get to an object without it becoming pixelated.  On the flip side, more VRAM also allows for more mip maps of on screen textures to be stored so that quick zoom outs have less stutter steps in quality.  \n\nHeck, this paves the way for 8k textures.\n\nBut do stay on the \"640k is good enough for everyone\" train.",
      "It is, that’s why it makes even less sense. The 1080Ti was a top tier card so I expect the extra bells and whistles. Not so with the 3060",
      "1080ti is wonderful, modded the heck out of witcher 3 this year and it's performed better than the original benchmarks even with the new 9.5GB 4k texture pack.",
      "Nope, I'm pulling it out of Computing history.",
      "> Why do news outlets treat EEC submissions as product confirmations?\n\nClickbait to generate revenue.",
      "> I  don't know why people think VRAM has anything to do with display  resolution anymore.  A triple buffered 32 bit color 4K framebuffer only  uses up 100 MB of VRAM.  \n>  \n>It's about the textures.\n\ni thought about it for a bit, and the only conclusion i could reach is that mipmaps, LOD, etc are all higher on higher res displays, which means more higher resolution images loaded at once compared to looking at the exact same scene at a lower res. i don't know if that's actually it though",
      "“Do stay on the 640k train,” not only hyperbole but a complete fabrication and not based on anything I’ve said. Get lost.",
      "Probably will be 350 or 330 for the 12gig one and 270 for the 6gig one"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "high",
    "matched_keywords": [
      "rtx 3080",
      "3080",
      "3080 ti",
      "rtx 3080 ti"
    ],
    "title": "gigabyte aorus geforce rtx 3080 ti master 12g",
    "selftext": "Picked up this gpu from a friend who used it to mine…when gaming with it reaches temps up to 83c! Not sure if anyone’s having the same temps ? ",
    "comments": []
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "high",
    "matched_keywords": [
      "rtx 3080",
      "3080",
      "3080 ti",
      "rtx 3080 ti"
    ],
    "title": "Just moved up to an RTX 3080 Ti",
    "selftext": "The Asus TUF RTX 3080 Ti OC went on sale at Micro Center a few days ago for under a grand, so I finally made the switch from my old 2070 Super. It definitely runs cooler than my 2070S (about 20 C at load) and several degrees cooler at idle.\n\n\nI like first-person shooters, so can anyone recommend a FPS that takes advantage of the 3080 Ti?",
    "comments": [
      "The same ones that took advantage of your 2070 Super.",
      "Cyberpunk is my recommendation. When I moved up from a 1080 to a 3090, the jump in quality was incredible.",
      "1 Cyberpunk 2077. \n\n2 Far Cry 6. \n\n3 Dying Light 2. \n\n4 Metro Exodus. \n\nFrom a quick Google search of 'most graphically demanding games' \nAlso try Red Dead 2 in first person. It's incredible.\n\nEdit: forgot to mention Destiny 2. It's very pretty imo, and it's free.",
      "Cyberpunk 2077\n\nI made the exact same video card upgrade. Being able to turn on ray tracing and retain good fps was a huge change. The old 2070S just couldn’t take it.",
      "No kidding, like what is the OP even talking about.",
      "No problem. It's an Intel i7 12700K.",
      "I've been out of the FPS arena for a while and was looking for other peoples' opinions of what a few of the best ones were. I probably worded it poorly.",
      "Congrats!\nI have the same card. Hunted for it for quite a while.\n\nFPS is not at its best now.\nYou may wanna try Doom Eternal as guys have already recommended and Resident Evil Village. Necromunda: Hired Gun may also be interesting.\nThough you can finally enjoy 4K at its best.",
      "Metro Exodus but the PC enhanced edition (RT only)",
      "Control for Ray tracing is the BEST use of it in any game I've played.",
      "Thanks. I'll check it out.",
      "If you think developers have bothered to come up with anything new, you are going to be very disappointed.",
      "Doom Eternal",
      "Ghostwire Tokyo to add to other choices mentionned",
      "3840 x 1600, I was planning to get the 3080 ti and then saw a 3090 for only 100 more, with a cooling perfect for my case",
      "Oh man, get yourself a copy of New Vegas. You're in for a treat lol.",
      "Gratz, I ordered my MSI 3090 2 days ago, arrives monday, also upgrading from a 2070 super 😁",
      "The TUF model is just exceptional! It will blitz through all shooters but aim for higher resolutions to really drive the GPU so 1440p and 4k is where this GPU really shines...",
      "Under 1000? Damn, congrats",
      "If Nvidia is still doing the free games promotion you should be able to get Doom Eternal with 2 DLC and also Ghostwire: Tokyo since those were offered with the 3080Ti\n\nEdit: I see in another comment you already got Doom. Make sure you also redeem Ghostwire it's a surprisingly good game, especially when you have all the settings on \"cinematic\""
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "high",
    "matched_keywords": [
      "rtx 3080",
      "3080",
      "3080 ti",
      "rtx 3080 ti"
    ],
    "title": "VideoCardz: \"NVIDIA GeForce RTX 3080 Ti Laptop GPU to feature 16Gbps memory and max TGP of 175W\"",
    "selftext": "",
    "comments": [
      "Laptop is a funny word for small tower with a monitor attached",
      "With proper cooling those would be sick laptops",
      "will never match full potential of the card without proper thermals",
      "Your mom is 300w worth of tgp then",
      "It’s probably the same GA104 chip with faster mem and +10W dynamic TGP. In other words, somewhere around desktop 3070 performance at best. God that naming scheme is trash.",
      "Thermals are definitely key for good gaming laptops, but there are a lot of good gaming laptops nowadays with solid thermals.",
      "Nvidia dropped the max q nomenclature and created a mess for laptop consumers because they can't tell the tgp of the gpus. At least with max q / max p consumers had an idea of how the particular gpu would perform",
      "Scalpers and miners: \"We will watch it's development with great interest.\"",
      "For the love of god, someone come up with a better naming scheme for mobile Intel CPUs and mobile Nvidia GPU. \n\nMax Q annoys the crap out of the engineer in me. The first thing I think of when seeing Q is heat but the max Q GPU are lower power…",
      "Looking at it from a new gamer or pc user point of view TGP and thermal rating means squat to them. For all they know it has a full 3080 in there. They don't know that the card is gonna thermal throttle 3 minutes into any modern game. I guess the marketing team wins this one.",
      "Anything with 175w worth of tgp will be massive.",
      "It's not just thermal throttling, though - the fact remains that a laptop \"3080\" is a far cry from the desktop 3080 and performs on average only around the level of a desktop 3060 ti, and can be significantly worse when it does throttle. That's not obvious from the names, and naming the laptop 3080 the same thing as the desktop variant is confusing and misleading to consumers.\n\nThrow the various TGPs into the mix and it becomes even more of a mess.\n\nNvidia at one point at least had the dignity to append an \"M\" to the end of their mobile GPUs, and people could easily tell that a GTX 680M is *not* the same as a GTX 680. They stopped doing that with the GTX 900 series, and for a good reason; Maxwell was the generation that was so power efficient that a laptop GTX 980 was legitimately the same chip in the same core configuration and similar clock speeds to the desktop GTX 980. \n\nBut as power consumption started going back up with Pascal, then Turing, then Ampere, they *really* should have brought back something to differentiate their desktop and laptop SKUs.",
      "A computer that is portable and suitable to use while traveling",
      ">I have personally never had that expectation.\n\nProbably because you know about the current state of the computer market, or about the thermal and power limitations of laptops. That assumption can't be made for everyone, or even *most* people, shopping for computers.\n\nHell, *I* didn't realize that a laptop 3080 was not the same thing as the desktop 3080 because I'd been out of computers for a few years and the last laptop chips I remember (the 900 series) had parity with the desktop variants.\n\nIf you spoke to some random person off the street and asked them whether a desktop and a laptop 3080 are the same thing, they'd likely guess yes.",
      "Laptops using this GPU must will probably a built-in liquid nitrogen cooling system to cool the beast",
      "It's honestly not hard to figure out which GPU you're looking for. If you're looking for the highest GPU performance possible for a given GPU model line, just a) check GPU TGP rating, and b) check laptop thermal performance.",
      "Nope. Massive would be the 17.3\"+ 10lbs+ behemoths. This is 15.6\" and 7.5lbs.",
      "It fits in a sleeve just fine. I think you're being a bit too presumptive here.",
      "That isn't at all what modern gaming laptops are like but okay. See: the Legion 7/7i, Legion 5/5 Pro, Eluktronics Mech-15 or Max-15, etc...",
      "It's 175W during dynamic boost, 10W over the 165W of the listed laptops. There are no massive laptops this generation so far."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "high",
    "matched_keywords": [
      "rtx 3080",
      "3080"
    ],
    "title": "RTX 3080 Appears in Steam Hardware Survey :November 2020",
    "selftext": "https://store.steampowered.com/hwsurvey/videocard/\n \nRTX 3080 is at **0.23%** \n\nFor context it is same as RX 5700 (0.25%) and RX 5600 XT (0.23%) which were launched more that 1 year ago and more than 5500 XT (0.19%) \n\nOther recent(10 series+) Nvidia cards are far above it\n\n5700 XT,2080,2080 SUPER,2080 TI are all under 1%\n\nAlso important in % **change** RTX 3080 gained third most after RTX 2060 and GTX 1650 which can be found on laptops\n\nRTX 2060 +0.37%\n\nGTX 1650 +0.26%\n\nRTX 3080 +0.23%\n\nJust wanted to post and see how this progresses in next few months",
    "comments": [
      "1060 must have sold gangbusters to still be that high years later.",
      "Considering it was as powerful as the 980 for a fraction of the cost yeah. Just wait a couple years and youll see the 3070 or 3060ti there instead",
      "Considering how rarely Steam polls users systems.. for it to already be pretty much equal terms with rdna 1 which were midrange/budget class (i get it, they might be too expensive for midrange/budget, im sorry but thats what the manufacturers class them as and i'll go with that.) Is pretty insane.",
      "It was super weird for me. I’ve had steam for 7 years and I never had it ask me for a hardware survey. The day after I installed my 3080 it asks me for a hardware survey.",
      "xx60 cards are typically $180-250. 3060ti at $399 USD MSRP is insane, as was the 2060 at $349 before it. Remember when Pascal 1060 at $299 was a huge price increase that we weren't sure the market would bear?\n\nBut people are eating it up that they're getting 2080S performance for that price point, so it will continue to sell well. Besides, as long as every 3070 sells instantly at $499, Nvidia has no reason not to raise prices. (Typically xx70 cards are $399.) One could even argue that not raising prices would be a dereliction of their fiscal responsibility to shareholders.\n\nI suspect Ampere will be like Pascal and have MSRP deflation a year after release.",
      "It might trigger when you switch components. I never had it either unless I upgraded my system (happened twice) \nEdit: seems that it is unrelated!",
      "sorry its already been pre-scalped.",
      "I think people are forgetting how many models of laptops came with 1660 series cards instead of 20xx series.",
      "I am part of those 0.23% woohoo!",
      "1070, 1060 and 1050 Ti are still great cards for most games, just not for playing AAA's at highest graphics settings. Combine that with a long GPU drought (nobody wanted RTX 20 cards).",
      "But muh paper launch /s",
      "Im Pre-ordering the 4080 at this point.",
      "The GTX 1060 will live forever.",
      "I hope this finally kills the paper launch bullshit going around.  The 3080 has a larger install base than lifetime 5600 and almost that of the 5700.  It is 1/4th of the 2080ti already in only a couple months.  Looks like Nvidia wasn't lying.  Demand and supply were both off the charts.\n\nBy comparison the 2080 had 0.21% the first time it showed up in the HW survey.  Can we settle down now and realize that demand is just massive?",
      "I can understand peoples frustration. But nvidias earnings reports and this. Shows that they werent really fking ard when they said \"unprecedented demand\"",
      "Man, my 1070 was still playing AAA games maxed out at 1080p at 80-144 fps when I upgraded to 30 series.\n\n10 series was such a great gen.",
      "Wow, impressive. I’m happy and fortunate enough to be part of that small gang!",
      "1060 gang",
      "1660ti and 2060 laptops are typically the same chassis and usually just a $150 or $200 upgrade option",
      "I’m trying to replace it but I can’t!"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "high",
    "matched_keywords": [
      "rtx 3080",
      "3080",
      "3080 ti",
      "rtx 3080 ti"
    ],
    "title": "Change rtx 3070 for rtx 3080 ti?",
    "selftext": "I bought a Gigabyte Rtx 3070 8GB a few weeks ago and play mostly VR games (sim racing with Acc, AC, PC2, F1 22) and the performance is good but I'd wish I had more sharpness with my Pico 4 headset. Now I have the opportunity to get a MSI RTX 3080 Ti 12GB for 600 euros (I bought the 3070 for 285). I could then sell the rtx 3070 again. \n \nWhat do you think? Would it be worth it?\n\nEdit: thanks everyone for commenting on this post. I decided to stick with the 3070, plan it better for the future and wait for the 5xxx series",
    "comments": [
      "Coming from a 3070 and not liking it, may as well jump to the 4070ti, which is about 3090 performance.",
      "A lot of money for a relatively average improvement IMHO.\nIf you are ok to spend the money now do it.\nOtherwise if you are ok with your setup now, save more money for a more significant improvement.",
      "I’d wait for the 5000 series. \n\nThat’s when I’m planning my next PC. \n\nGoing to go all in on a completely new rig. Will have to wait for 2025 probably, but the 3070 is absolutely fine for what I play until then.",
      "It might not be worth the upgrade for such a minor increase in performance to be honest. I would either save some more money to buy a used current gen GPU, or wait for the 5000 series to release and look for a used high end 4000 series.",
      "That change doesnt make any sense, go for a 4070 instead, you get the same performance plus new, warranty and dlss3, 570€ in my country. But i would wait some more and get a 16gb+ vram card for future friendly 4k gaming.",
      "The 3070 should be enough performance but due to how low the VRAM is you should definitely get the 3080 Ti, it will age better and be more comfortable to use. \n\nIf you want extra performance the 6950 XT is cheaper and offers 16gb, also a good buy.",
      "Seems like a waste unless you wanted a second pc. But 400~ bucks to upgrade 1 tier, assuming you sell the 3070 for 200, sounds like an upgrade you wouldnt notice as much. I say that as someone who upgraded from a 6800xt to 6950xt, performance was about the same. But I got a good gpu for my living room pc so im happy about that",
      "470 euro for 3080ti? Great price!\n\nIf your PSU can handle it, do it!",
      "The 3070 is a good second hand card. 3080 Ti is significant upgrade, but at this point you can just pay a bit more for a latest gen card, or wait for holiday discounts.",
      "No. Not worth it. Like others have said, get at Minimum a 4070ti.",
      "Not budget for that , the rtx 3080 ti for 600euros is the offer I got",
      "5000 series will be even more $$ than now.   It depends what you can save up (or what he can save).   Everyone has bills and sometimes, expenses pop up.   If he has the $$ now and there's a current deal - at least, he would have the use of the upgraded card for a while.   He's financing it partly from the sale of his 3070 and 30 series card value will go down anyway.   I think it's 50-50 - of it being upgrading now vs. saving up and then upgrading.   Imho, you can make cases for doing either one.",
      "Yeah I am going to wait too. I expect a 5090 to be around 2k USD.",
      "Ok I've found another one for 470 euros, how about that?",
      "I got it at the end for 470 euros xd",
      "It's a side grade, wouldn't recommend it.",
      "If you can get a good price for your 3070 then it might be an ok upgrade, but for the full 600 out of pocket its definitely not.",
      "My point is that the 3070 is absolutely fine for now and you’re not getting much in the way of a perf boost for the hassle and money you’d spend to go to 3080.\n\nGoing to 4000 now at least has new features, like DLSS 3.0.\n\nThe 5000 won’t be out for a while. Plenty of time to save. \n\nAlso, I don’t know where you’re getting your crystal ball, but we have no idea on the price of any new, future cards.",
      "Which card?",
      "3080 ti"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "high",
    "matched_keywords": [
      "3080"
    ],
    "title": "My results of undervolting a RTX 5090 Founders Edition",
    "selftext": "Edit 5: It seems like not everyone got same voltage/frequency curve. Mine at stock (after reset) got around 1930mhz at 0.85v. Two people got 1320 at 0.85v and because you cannot put more than 1000mhz+  on a node, it means it will maxed out at 2320mhz 0.85v. (It will probably not even be stable. I have never seen my old 4090/3080 do 1000mhz on a node and not crash. ) Maybe it is just a software bug for you guys. I have no idea honestly.\n\nIn any case you probably need to use more voltage. Let's say 900mV 2500mhz+ and experiment with that.\n\n\\----------------------------------------------------------------------\n\nI finalized my UV profiles. There are 5. 1 to 5 's order is fastest to slowest\n\nAll the settings got 2000mhz overclock on VRAM. All of them are using my fan curve. Stock downclocks really fast below 2.7ghz if I use stock fan curve. To make it fair for stock, it is using my fan curve and memory overclock too.\n\nMy undervolts :\n\n* Stock: 1-1.1V 2.6-2.7ghz\n* UV1: 0.895V 2.810ghz (Second favorite undervolt)\n* UV2: 0.875V 2.722\n* **UV3: 0.85v 2.6ghz (First favorite undervolt)**\n* UV4: 0.825V 2.5ghz\n* UV5: 0.81V 2.2ghz (only use this UV5 for games that are already reaching your refresh rate. I)\n\n\"UV\" is what I set the fan curve to in afterburner curve editor. They still run slower than what I set them to. For example UV4 runs at 2.35 to 2.45ghz and not 2.5ghz\n\n\\--------------------\n\n**Why Steel Nomad?** Because it is the only game/benchmark that actually uses 570-580w on my 5090. Nothing else uses this much power. Furthermore it takes like 1 minute to run every run.\n\nHere Steel Nomad (Full Screen, HDR on, Loop off, Resolution 8k so it says GPU bound)\n\nMeaning of brackets at the ends: Example: 169% means 69% faster than Stock. I am comparing avg fps here. It is rounded up after 2 decimal place:\n\n* Stock getting 38.26 fps while using 575w\n* UV1 getting 40.15fps while using about 560-570w (104,93%)\n* UV2 getting 39.49fps while using about 530-545w (103,21%)\n* UV3 getting 38.12fps while using about 480-490w (99,63%)\n* UV4 getting 37.16fps while using about 390-425w (97,12%)\n* UV5 getting 33.71fps while using about 340-365w (88,11%)\n\nIt is only Steel Nomad though. In Cyberpunk the peak power is much lower. In Robocop I am using maxed settings + DLAA + FG with new dlss model at 4k. 116fps with UV4 and it only uses 300-330w. (116fps is max fps I get so my monitor stays in gsync range.)\n\n\\-----------\n\nWith 0mhz memory overclock and Stock settings my memory temp was getting to 92c. So I am using my manual fan curve. It goes max 80-82c now. Even with the 2000mhz overclock on memory. Memory overclock seems to be stable at 2000mhz and I am getting around 1-1.5fps more with UV3 for example. That is why I put 2000mhz on Stock and UV1 to 5.\n\n\\-------------\n\nMonster Hunter Wilds Benchmark with every setting maxed out (RT High) at 4K, DLAA (forced DLSS Transofrmel Model with latest preset via NVPI), FG off, HDR on (8 for 800nits). Motion blur, DF, vignette off:\n\nMeaning of brackets at the ends: Example: 169% means 69% faster than Stock. I am comparing avg fps here. It is round up after 2 decimal place:\n\n* Stock getting 80,31 fps (Score = 27390) while using about 430w (peak 470w)\n* UV1 getting 80,21 fps (Score = 27408) while using about 330w (99,88%)\n* UV2 getting 76,94 fps (Score = 26261) while using about 300w (95,80%)\n* UV3 getting 75.18fps (Score = 25674) while using about 280w (93,61%)\n* UV4 getting 73.21fps (Score = 24949) while using about 240w (91,16%)\n* UV5 getting 66.07fps (Score = 22517) while using about 200-220w (0,82%)\n\nSummary: I would probably use UV3 all the time and use UV1 in Path Tracing games or the games that I want to run with DLAA. UV5 should only be used when you still got headroom so you get same fps (in my example capped at 116fps) while using a little bit watt. There is literally no reason to lose so much performance for games where you need those extra fps.\n\n\\-----------\n\nAdded extra: Portal RTX (someone asked in comments) (Standing in second room of level 1 just like the pictures below)\n\nUltra Settings in (alt+x mode), DLSS off, FG off, Reflex off (it worsens your performance when your gpu is at 100%), Vsync off, Motion blur and etc. off:\n\nStock: 29 fps 575w 2.55ghz (before dropping ghz it was at 30fps 2.7ghz for a very very short time)\n\nUV1: 30fps 545w 2.7ghz\n\nUV2: 30 fps 512w 2.6ghz\n\nUV3: 30 fps 480w 2.5ghz\n\nUV4: 28fps 430w 2.44ghz\n\nUV5: 26fps 370w 2.18ghz\n\nSame Settings with DLSS Quality and RR on (it looks much more stable because of RR and as sharp as native. I am forcing Transformer Model).\n\nStock: 93 fps 550w 2.73ghz (dropped to 90 fps 2.55ghz really fast after getting hot. Even with my fan curve)\n\nUV1: 93 fps 460w 2.69ghz\n\nUV2: 91 fps 435w 2.6ghz\n\nUV3: 87 fps 400w 2.5ghz\n\nUV4: 85 fps 360w 2.4ghz\n\nUV5: 79 fps 313w 2.19ghz\n\nhttps://preview.redd.it/pzrmrv0imrje1.png?width=3840&format=png&auto=webp&s=dd7da2e4c5645bc253185491dae8f54e0561618a\n\nhttps://preview.redd.it/rqko1u0imrje1.png?width=3840&format=png&auto=webp&s=5808c5732b88d59e21e6c81722443624160bf1b4\n\n\\----------\n\nEdit: Personally I don't see any difference between DLAA and DLSS Quality with new Transformation model. They both look very good. DLAA can look a bit, just a tiny bit sharper but honestly the fps difference isn't worth it. Main reason for me using it in games like Ghostwire Tokyo/Robocop is that it gives me much more stable Ray Tracing effects (no boiling and not noisy). With DLSS Q-Ultra Performance Ray Tracing got lower resolution. Path Tracing with RR in Cyberpunk doesn't have this issue though. Maybe problem is the denoiser and RR fixes such problems? Anyway this has nothing to do with this post but I still wanted to mention it here.\n\nEdit2:\n\nextra information:\n\nI am using Corsair 2x16GB 6000mhz CL30 RAM, B650E-E, 7950x3d and NZXT C1500.\n\nI ran stock for 2 hours on Loop in Steel Nomad (same settings like above). Using 575w. I even checked the voltage of \"GPU PCIe +12V Input Voltage\" and \"GPU 16-pin HVPWR Voltage\" in HWininfo. the difference was like 0.02-0.06v. whch is really normal. I even checked the wires with my fingers. They were warm, yeah but probably around 50-60w max. All of the wires were warm equally => current is distrubted equally (almost equally)\n\nI am using second cable that came with my NZXT C1500. It was new and I didn't bend the cable where it wasn't bended before. I pressed it in and even had to use a minus shape screwdriver on left and right side of the cable's head (not the wires!) to push both sides in completly. I think I should be fine.\n\nEdit 3:\n\nI sent someone on Reddit following video yesterday. IT IS REALLY LOW EFFORT. SO SORRY! 2:45 to 3:30 is where I tell you how to change the graph in MSI Afterburner. At beginning I talk about the interface, Fan Curve. After 3:30 about memory overclock (I didn't have it yesterday), my profiles (old ones), yapping more about more settings (to set MSI Afterburner to start up with Windows + set your undervolt automatically) and etc.\n\n[https://www.youtube.com/watch?v=DPXM4bL\\_R7Y&lc=UgzCX7ZrKWQG-tiJGwV4AaABAg](https://www.youtube.com/watch?v=DPXM4bL_R7Y&lc=UgzCX7ZrKWQG-tiJGwV4AaABAg)\n\nYou have to download MSI Afterbruner 4.6.6 Beta 5 or newer. If I am not mistaken, it is the first version that supports 5000 series.\n\nEdit 4: afte talking to some redditor, it seems like not everyone is going to have the same curve like mine in the video. Maybe I got lucky and got a really good binned 5090?",
    "comments": [
      "Nice work. Undervolting is the new overclocking. The new transformer model is best at elimating garbling on 3D UI text in frame generation,  and reducing boiling on raytracing and pathtracing.",
      "This is great, thank you for putting in this effort, I've been looking for good 5090 undervolting results and you have put together a great version of that.",
      "-100w for same\n\nNvidia engineers manufacturing threats not GPUs",
      "Undervolt success depends on silicon quality. Nvidia/TSMC engineers must have determined that to get sufficient yield of 5090 they need 575w/~1v into the chips. Some people will get unlucky and their card won't be able to undervolt at all. If that doesn't end up being the case, then yes, Nvidia did mess up somehow.\n\nBut it seems that most 5090 we've seen so far can take a pretty aggressive undervolt, so that's good news. They may have sent out the mostly highly binned chips into early cards so that word spreads that they perform great with undervolt, just like we're seeing early 5080 being amazing overclockers. Then they rugpull and the next round of shipments will be a silicon lottery like usual.",
      "I have my 5080 FE undervolted to 2700 MHz at 850 mV, I'm getting sometimes 2-3% better than stock performance while drawing 230 watts.  It's crazy how much extra Nvidia left on the table with these.\n\n  \nI can also do over 3000 MHz at 950 mV.",
      "This will be a nightmare to get 100% stable, so many apps and games that can crash it and be completely stable in others. Played FF7 rebirth for 100H without a crash, played hogwarts legacy maxed out in 4k and it crashed 15 min in.",
      "I made a video yesterday but it is low effort and low quality. Even worse than those low quality memes you find on internet. Just watch first 3 minutes. The rest is yapping. First 3 minutes got yapping in it already.\n\n[https://www.youtube.com/watch?v=DPXM4bL\\_R7Y&lc=UgzCX7ZrKWQG-tiJGwV4AaABAg](https://www.youtube.com/watch?v=DPXM4bL_R7Y&lc=UgzCX7ZrKWQG-tiJGwV4AaABAg)\n\nedit: some of those profiles are still old from yesterday I removed two and added 2 more.",
      "I guess you missed like 50 threads on how much better DLSS 4 is?",
      "How do I undervolt? Msi or something or do I need to take it apart and soldier  something into something?",
      "Congrats :D. I was planing to get a 5080FE but honestly after camping on Nvidia's website for 2 weeks, I finally could grab a 5090 FE last week in Germany.",
      "Bookmarking the crap out of this one",
      "Honestly, I have fonud FF15 Benchmark (it is ancient), Rainbow Six Siege (just run T hunt for 30 minutes), MH Wilds the best games to find bad undervolts. After testing my undervolts for 2-3 days, I am pretty sure they are stable but yeah. Sometimes there is this one game that crashes with undervolts. Metro Exodus Enhanced Edition is a really good example too. I have to test my UV too actually. Hmmm. When I think about it, DLSS Transformer DLAA should look amazing with everything maxed out in that game. I loved the Story.",
      "Better performance with less power draw. Sure it is. These chips are already pushed well past their efficiency curves at stock like a typical overclock anyways. \"Boosting\" is just stock overclocking on a curve. Undervolting solves two issues at once (power and heat) allowing the chip to clock higher.",
      "It's fine. Cable won't melt if you take precautions even if it draws 600w.",
      "Cyberpunk with Ray Reconstruction Transformer model on, if it's stable in that it'll be stable in everything, the game sometimes won't even launch with unstable offsets when that's on.\n\nCyberpunk with cn model was already one of the if not the pickiest one to get stable, but now it's even more picky had to lower profiles depending on voltage by 30-60mhz that were cn stable.",
      "UV4 seems the best to me.\n\nBut hey, thanks for the data.",
      "What can you do to protect yourself besides not using third party cables",
      "100% safe. If the UV is not stable though, your game will crash but that has nothing to do what you said. So don't worry",
      "Just get a good H++ cable, inspect it beforehand to ensure it's indeed high quality (3rd party doesn't matter here).\n\n\nThen connect it and make sure the cable has enough space to breath without applying pressure from the case or from bending that could cause it to move around.\n\n\nFinally, use either an amperage clamp or a thermal camera to confirm power draw is balanced between each of the 6 power delivery cables.\n\n\nThat's it. You can now enjoy the best GPU in the world for the greatest gaming experience for the next 3 years. No, it won't suddenly start making issues, cable don't suddenly disconnect and the resistance per pin would remain pretty much the same even years into the future.\n\n\nIf you're super paranoid just whip out the clamp or camera every time you move the PC (e.g. to clean it outside), and of course each time you reconnect stuff.",
      "My msi trio 5090 just arrived, everything is perfect except that when I turn ON my pc I have a black screen when displaying the desktop (I have to force restart the PC and everything is fine again), I imagine that this is a problem with the Nvidia driver. Then I tried the stock gpu and in time spy 1440p I had 34,000 points in graphic score (something strange uhmm), but in the time spy extreme I have 25,600 (that seems good), well, after seeing that in games it consumes approximately between 450w to 500w I decided to make undervolt, for now everything is stable. UV 1: 2800mhz - 900V 100% power / UV 2: 2880MHZ - 900V 100% power. From 450w to 500w of consumption I was able to lower approximately 100w (if I'm not mistaken), it's quite good, and from 64°C stock I dropped to 54°C incredible, no problem at all for now it's summer in my country, so they are good results. If anyone has other recommendations I'll read them."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "high",
    "matched_keywords": [
      "rtx 3080",
      "3080",
      "3080 ti",
      "rtx 3080 ti"
    ],
    "title": "Gigabyte RTX 3080 Ti Eagle Thermal Pad Upgrade is a MUST!! (pics included)",
    "selftext": "This card out of the box was hitting over 100C on the memory in less than an hour, the highest spike I saw was 106C which seems insane. The case I'm using is the NZXT H1 which isn't known to be great for thermals, but I do have fans mounted on the back and a fully vented front panel so airflow really shouldn't be an issue. \n\n[This was after around an hour of gaming, hitting an average temp on the memory of 99.7C and max of 106C. ](https://preview.redd.it/ry26mnbftqn71.png?width=582&format=png&auto=webp&s=793eb8de108378204604b21bffdfa864b5bc99bf)\n\n[After installing Thermalright pads on the front and back, the temps improved drastically. This is after another hour and now I'm only seeing an average of 81.2 and a max of 86C. ](https://preview.redd.it/ex73pbritqn71.png?width=582&format=png&auto=webp&s=2a45ced9d06636860c67182726c1268dbab9cc28)\n\n[Original pads in the front.](https://preview.redd.it/pce952autqn71.jpg?width=4032&format=pjpg&auto=webp&s=960de1a6a0886f5c6645b2f37fb6e575b853624b)\n\n[Big surprise here and probably the culprit? It seems they only put thermal pads behind some of the VRAM on the backplate. Not sure if this was something they missed during manufacturing?](https://preview.redd.it/ev0u8y0ztqn71.jpg?width=4032&format=pjpg&auto=webp&s=f20eaedd9938246cba35555a9e6a881f71615616)\n\n[New Thermalright pads for the VRAM, left the original pads on the VRMs. ](https://preview.redd.it/x6q76nw8uqn71.jpg?width=4032&format=pjpg&auto=webp&s=d72e58262e443ac83a61c5c1451e5db5d39da7f6)\n\n[Added Thermalright pads on the back of all the VRAM and moved the original pads to the back of the VRMs \\(not sure if it helps but figured why not?\\). ](https://preview.redd.it/hccmhgdouqn71.jpg?width=4032&format=pjpg&auto=webp&s=5f222907b6d48c76a4b70cbe3e1606549ad0c9a7)\n\nFor those who are interested in doing this, you will need 3mm pads for anything on the backplate, 2mm pads for the front on the VRAM, and everything else on the front should be 1mm (however I didn't change these). \n\nHope this helps anyone facing the same issue!",
    "comments": [
      "Why aren't the pads standard with the card? I'd just avoid getting it if I'm going to have to do extra work, considering the price of these cards.",
      "It's a pitty that SAPPHIRE doesn't make Nvidia cards, they are over engineered in the high end.",
      "Still unacceptable. Today's GPU have a hefty markup from manufacturers (besides scalpers, miners and all those, manufacturers don't want to be left out that party either).\n\nIt's just too greedy.",
      ">1 x 85x45x3mm Thermalright Odyssey Thermal Pad (12.8 W/mK) - This is more than enough to cover all the memory chips in the back, I also reused the original pads for the VRMs.  \n>  \n>1 x 85x45x2mm Thermalright Odyssey Thermal Pad (12.8 W/mK) - This is the 2mm pad for the front and there is more than enough in the size mentioned above to cover all the memory chips.\n\nThese are the pads I used which I used, they are of great quality and have high thermal conductivity of 12.8 W/mK.",
      "Realy nice work mate! What brand of new pads use you? Planing to buy themal grizlis but dont know what is the good pad brad.",
      "Thanks for the pics! I've just done the same thing on the same card, using the same pads, resulting in the same temperature drops as you.\n\nThankfully I didn't destroy my card, I was a bit nervous turning it on after the mod.\n\nI would also say that I'll stay away from Gigabyte in the future, however, it was the cheapest card available. If you factor in the cost of the pads, it was still cheaper to buy this card compared to the next available non-Gigabyte card. Now we have a cool running, quiet, fast card. Maybe we can't overclock it as much as other cards, but it's plenty fast even in stock form.",
      "This is a few months old, I know, but I found it on Google and figured I'd add on since this helped me, might help someone else.\n\nI have a Gigabyte 3080TI Vision OC model. My VRAM temps were getting worse over time, and the GPU fans were cranking harder under the same workloads. I'm really comfortable with taking things apart so I decided to try this. People should be aware that if you were to break something doing this it likely wouldn't be covered under warranty. I generally think people should be more comfortable with disassembling and reassembling things, but also in doing so people should be cautious. For me, it took about an hour and a half to do the whole thing, and I was never able to unclip the fan power cables and had to work around them still being attached.\n\nOnce I opened mine up, I saw that the thermal pad layout was exactly the same as the photos here. The pads on the front were oily and I think that after some heavy use the oil was leaking out and they weren't connecting to the VRAM as well as when I first installed the card, explaining the increasing temperatures. I don't know this for a fact, but it seems to make sense to me.\n\nI replaced the VRAM thermal pads on the front with 2mm Thermalright Odyssey Thermal Pads like OP mentions elsewhere in the comments. It took about 4/5 of a package. I used 3mm of the same brand on the back, and used exactly one whole package to replace what was there and more importantly, fully cover the back of the VRAM. I left all other thermal pads in place. I cleaned off and re-applied the GPU die thermal paste.\n\nIt's straight baffling to me that Gigabyte would use thermal pads on the backside of like 3 of the 11 chips. Either they all need it, or none of them need it. Since I have a card with \"overclock\" in the name, I would hope they would all have it, honestly. Really disappointed in the brand over this.\n\nBefore I did this, my VRAM temps would hover around 90C and peaked at 102C. Since doing this, they're hovering in the mid 70's and peaked at 80.  MASSIVE difference. GPU fans instead of being between 80-100%, are sitting around 65-75%. It's a massively audible improvement. So the damn thing runs cooler and does it quieter all while doing the exact same workloads before and after. It's only been a few days so I don't know for a fact that the performance will remain but so far it was entirely worth it.\n\nI will say that both before and after doing this, the GPU die itself maintains a really low temp. The hottest I've seen it get is 70C, and it usually hangs out under 60C. Again, that's the same both before and after installing the new thermal pads. So the die is well cared for by the design of the card. It's just the VRAM that was running away and hard to get control of.",
      "Thanks for this, I also have an RTX 3080 TI Eagle, and the VRAM temps are 100 degrees +\n\nI really don't understand why gigabyte would make a card, then cheap out on a few pennies by not installing the proper cooling pads.",
      "Honestly I'm not sure, but I think it was concluded that Gigabyte was using very inferior thermal pads on a lot of their cards.\n\nI got this card for around $1700 CAD at my local store which was an amazing deal since most of the other 3080 Ti models here in Canada retail for $2000+ CAD. Still worth it even though I had to pay an extra $50 for the thermal pads!",
      "Gigabyte in particular has put out some of the shittiest cards out of all the vendors. Shit cooling, shit manufacturing, their power connectors were fucking coming apart from the board, the cards are thermal trottling at stock.  \n\nJust buy any other brand",
      "To be fair, the eagle is the lowest tier for gigabyte 3080ti.",
      "That is great to hear, glad you were able to achieve similar results.\n\nI find it so odd that manufacturers won't spend a few extra bucks to at least put some decent thermal pads on their higher-end cards, it boggles my mind! The fact that some spots on my card didn't even have any pads also shows how poor their QC process must be.\n\nVery disappointing to see when so much money is being spent!",
      "I haven't mined with this card, but I wouldn't be surprised if it shot straight up to 110C with the original thermal pads. I think Gigabyte eventually did start putting in some better pads (I believe they are grey), but some cards still have these crappy white ones.",
      "Yeah, I really didn't want to open up the card but I also took a peek through the top and noticed some of the pads missing on the back. I would say it is worth doing as the original pads they use are absolute garbage, your temps will improve greatly! \n\nI continued using it and still have not seen the memory spike any higher than 86C, it usually hovers around 82 - 84C at 100% use.",
      "Those temps don't look bad at all! My card was hitting over 100C on the memory which is why I ended up swapping the pads. You should continue to monitor the temps and if they eventually start creeping up and over 100C, then it might be worth doing.",
      "Yeah, it is their lowest tier card but is still one of the highest tier GPUs in the market today. There should be some standards they need to meet and testing done before they leave the factory. \n\nTaking into consideration how much consumers are paying for these cards today, it is ridiculous how they choose to skimp out on some of these important aspects that can cripple the GPU, even if it is their lowest tier (which still costs $1700 CAD!!)",
      "It’s been that way since I’ve bought it I think it was back in November 2021",
      "Noob dude here, what was the thickness of the otiginal thermal pads on yoir card, OP? They likely vary depending on the model, right?\n\nEDIT: nvm, i fucking missed it in the post lol",
      "I believe you are correct, it is related to cheap pads that eventually start leaking that oily substance. I've heard it can get very bad to the point where it leaks down the side of the actual heatsink and gets flung around by the fan!",
      "Agreed, and if anyone says \"but if the card dies faster it meanyou buy another - yeah you might buy another but it wont be from gigabyte right?!!"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "high",
    "matched_keywords": [
      "rtx 3080",
      "3080",
      "3080 ti",
      "rtx 3080 ti",
      "rtx 3080ti",
      "3080ti"
    ],
    "title": "Buy RTX 3080 Ti or wait for RTX 4080 12GB?",
    "selftext": "Hello. Im building gaming PC. My monitor resolution is 27' 1440p 144Hz. Should i buy RTX 3080Ti or wait for RTX 4080 12GB? I was thinking about RTX 4080 16GB but difference in price is big.",
    "comments": [
      "4080 12GB doesn’t have the same chip & performance of the 16GB. Beware.",
      "From what Nvidia has said so far, it appears the difference in performance between the 3080Ti and 4080 12GB is very small, like a 10% improvement in rasterization at best. If it is barely on par with a 3090Ti with RT enabled you can be sure it will be worse with it disabled. They also have the same amount of VRAM (12GB vs 12GB). Overall the price difference is too much to justify buying the 4080 unless you are interested in DLSS 3 frame extrapolation. The 4080 12GB will cost at least 1k, since there is no FE model. At this point either go for a 3080Ti and save your money or try to go for a 4080 16GB, the 12GB is a scam and waste of money. It should have been called 4070.",
      "None of the cards have been tested yet.  Nvidia's graphs show the 4080 12 GB is about 5-10% faster than the 3080 Ti without DLSS 3.0 and raytracing.  So basically if you can find a 3080 Ti for under $800, it's a better value.  If you buy the 4080 12 GB, you're paying for DLSS 3.\n\nYou should buy the 3080 12 GB instead of the Ti anyway, they are considerably cheaper for an insignificant performance difference.",
      "4080 12GB is much better, only get RTX 3080 Ti if it's at least 200-300 cheaper.",
      "if he said that 3080 12gb is == 3080ti,  then  3080 == 3080ti == 3090\n\n3080 = 3090\n\nsee what i did there? xD\n\nFunny thing is, both of u are right. altho 80 ti is much closer to 90, than 80 12gigs is to 80ti.",
      "4080 12gb is just a 4070 that's been renamed. 4080 16gb is the only real 4080.\n\nBest to wait till 4000 series launches and then look at reviews.\n\nIf you can get a 3000 series card or amd 6000 series card for a good deal, they're still plenty powerful.",
      "You're not going to get a solid answer to this. People are either going to circlejerk about the 4080s being a scam and beg for upvotes, or they're going to tell you we have no real idea yet of the performance of the 4000 series, so it's impossible to know if the 3080ti is still worth it at its current pricing when 4000 series gpus are coming soon around that same price range.\n\nWait for 4000 series testing and reviews, I'd say.",
      "The 12GB is actually a 4070...with reduced cores and memory bandwidth.  Look at the price difference, the 16GB is $1600.  You can get a 3080 ti for under $1k...",
      "He knows",
      "Wait for reviews.",
      "The 12gb 4080 is literally a 4070 in disguise trying to fool us all. The 40 series is a \"filler\" generation. I plan to skip it entirely. The best thing about the 40 series is it should finally bring the 30 series cards in line with the prices we expected and never got.",
      "What’s disappointing is that the ~~4070~~ 4080 12GB was exactly the performance and (almost) TDP I wanted. I would’ve bought it on launch for $599, which would’ve been the most I’d have ever spent on a graphics card\n\nNvidia, afraid of pricing their 4000-series cards too low and disrupting their 3000-series cards because they need to sell a bunch they already produced… pushed me to go buy a secondhand-market, used 3000-series card for cheap instead",
      "You are wrong.\n\nDifference between 3080ti and 3080 is not insignificant compared to its difference to 3090.\n\nIf anything, he should buy a 3080ti, cus it basically performs similar to 3090s. It's value for money.",
      "Wait for reviews but you can't go wrong with the 3000 series at these prices.",
      "The 16 GB is $1200",
      "3090 is == 3080ti.  It's 10% faster than 3080.",
      "Wait for 4080 12G. Will be better than 3080 ti.   \n408012G lands at 3090 perf easily if not matching 3090 ti. Also, newer RT cores and all - probably a boost in RT perf too.",
      "Wait.",
      "Imo nvidia is going to struggle once AMD releases, thats if AMD can have enough supply out.  The only card that seems to be pushing is the 4090, the rest seems like their advantage relies in two aspects, ray tracing and dls3, if neither is a big deal for you, get the RTX3080ti, specially if you can get it in a sale.\n\nI feel AMD will have better offering for people that don't care about ray tracing or their games dont support DLS3.0, i think AMD are going to have strong card with better performance, and likely better pricing, still think they wont be able to touch the 4090, but below... imo AMD will have a stronger position, the question is more whether they can supply enough cards to the market.",
      "The “4080 12GB” is really a 4060ti in disguise so they can charge more. Don’t bother with it."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "high",
    "matched_keywords": [
      "3080ti"
    ],
    "title": "EVGA for the win!",
    "selftext": "Recently asked EVGA for an RMA on my 3080ti, and they were like, yup, here you go. There were 29 days left on the 3 year warranty on the old card that crapped the bed. Excited to get back to gaming!",
    "comments": [
      "Their support is what I liked about them the most. I wish they would get back into the GPU space.",
      "When my 1080 Ti died, I went to check their webpage for customer service hours and phone number... they had live customer support at 9:50PM on a Sunday _night._\n\nThey sent a refurb 1080 Ti (that's the policy).. that card was fine for 8 or 9 months, then the _refurb_ went **POOF**.  EVGA didn't have any more refurb in stock, so they sent a brand spanking new 2080 XC  (not gonna lie, I was secretly hoping for 2080 Ti... but fucking hell did they exceeded my expectations!)",
      "Wait are you the guy whose bat shit crazy wife destroyed the 3080ti? I do miss EVGA's awesomeness....🫤",
      "Dude look at his post history he cheated on his wife with a dom lol",
      "Same, I miss them already :(",
      ">Scammers and people that abused their easygoing system ruined it for the rest of us.\n\nNvidia screwing over their board partners ruined it for everyone.",
      "Nah, not me",
      "RIP EVGA. I'm missing their legendary warranty service and step up program.",
      "You'd be surprised at how much of a pain in the ass lots of those companies are. They can fulfill their obligations while making you go through a shit ton of hoops, and then something goes wrong and they just dare you to take it to court, hoping you won't bother or can't afford it. Just look at Intel saying they won't refund their defective CPU line, even though they're obligated in several countries. They'll just wait and see if getting sued is cheaper than a recall.\n\nSystem shouldn't be like this, but it is, sadly.",
      "https://preview.redd.it/hgbiu7bi8igd1.jpeg?width=4032&format=pjpg&auto=webp&s=30d08d462b95bb055bfcd0e30ffa8620184fa488\n\n<3",
      "Years ago when SLI was a thing, I had a pair of EVGA GTX 470's.   One of them died.  I did my due diligence in troubleshooting; switched slots, ran each card individually, swapped PCI-E power cables, etc.  Called up EVGA, explained what was going on, and what I had done, the EVGA guy who was U.S./Canada based,  just said \"well, looks like you've already done the necessary troubleshooting,  We'll RMA that one. I'll have a replacement sent out, just send us the defective one back in box the replacement comes in, a shipping label will be sent to you.  I spent maybe 3-5 minutes on the phone before everything was taken care of.\n\nAbout 3 days later the new card came in.  They had upgraded me to an GTX 570.  Nice, but I was doing SLI.  So I call them up again,  explain what the issue was. They look up my the cards I have registered with them.  And find that yeah, I have another GTX 470 (which was still working fine).  The EVGA guy said they didn't have any GTX 470's to send out as replacement, but if I wanted to swap out my working a GTX 470 for a new GTX 570 for free, they'd be happy to do it.  I of course took that offer, and again, they sent me another GTX 570 and I sent them back a working GTX 470 in exchange.  \n\nJust amazing customer support at every step.",
      "Same, I buy evga everything after my great experiences with them, and their power supplies are also amazing.\n\nI had a gtx 1080 stop working, outside the 2 year warranty of the shop I bought it from, sent a support ticket asking if it's fixable and they asked for serial number and told me according to their data it's 1 month away from 3 years old, which means it's covered by THEIR warranty. They opened an RMA ticket for me and within a week I had a new RTX 2070 replacement as the 1080 wasn't in stock anymore. I live in Finland btw so I was surprised how fast they got it shipped to me.",
      "Was friends with a couple dudes that were their overnight support on weekends, they would just kick back with some beers.  Had a 650 black edition or w.e die on me that I pulled from an waste bin at my job. Took it home to test it, blue and pink squares. Called em up, just had me register the card and all I had to do was pay one way shipping, 33 bucks or something to their place in Tustin or w.e, got back a refurbished that looked new, 770sc, that replaced my 580gtx or wme at the time.",
      "Oh okay still feel bad for the guy.",
      "> There were 29 days left on the 3 year warranty on the old card that crapped the bed. Excited to get back to gaming!\n\nSo.. company fulfills its legal obligation. More news at 11?",
      "EVGA made a statement that GPUs weren't profitable enough for them to continue. Despite how silly that initially sounds, they had higher quality products with more invested into them so they had much smaller profit margins than the competition.",
      "Because unlike the other major major NVIDIA partners in the US market (i.e. ASUS, Gigabyte. and MSI) they didn't have a sufficiently diversified product lineup.  \n\nEVGA's PSU line was its only other significant source of income, while the three other aforementioned competitors all have large-scale motherboard manufacturing.",
      "EVGA sent me a GeForce 8800 GTS in 2008 as a RMA replacement for a 7900 GT. I was the happiest kid in high school.",
      "Step UP was _so_ good. During the Great GPU Drought of 2019, the only good card I could find was 1050 Ti... for abut $400  o.O  Luckily with Step UP, I was able to parlay that into 1080 Ti for another $400 several months later.",
      "I miss EVGA every day, they were the only way I got a 3080 back when it was scalper central in 2020."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "high",
    "matched_keywords": [
      "rtx 3080",
      "3080",
      "3080 ti",
      "rtx 3080 ti"
    ],
    "title": "Considering to buy RTX 3080 Ti, which version is better?",
    "selftext": "Hello guys!\n\nI am currently considering to upgrade my Titan X (Pascal) to RTX 3080 Ti.\n\nI am a bit confused about which version to pick, I have been looking at the ASUS TUF edition for ($975) as it has very good VRM cooling and temps in general, as well as excellent quality.\n\nAny  better version to consider for the price point? Also, I wanted to ask if my CPU (Ryzen 3700x) would handle the card perfectly?\n\n&#x200B;\n\nThanks in advance!",
    "comments": [
      "I have the Std. TUF 3080 and its the coolest and quietest card I've ever had! Looking to buy TUF again next time too.",
      "The 3080ti is literally a waste of sand, you're paying 100 bucks per fps increase over the 3080 and the performance is realistically around 10%. The 3080 is the best deal.\n\nOf course if you have too much money go for it.",
      "Wait",
      "Unless you can get a Strix or a FTW3 then go with the TUF. I love that card and with a proper undervolt it’s hard to beat.",
      "The difference could also be caused by more or less airflow inside the case. I have a Corsair 4000D case with lots of noctua fans. But honestly, the temps I’m getting are what I expected based upon the reviews. So IDK. Maybe you got a bad one? Does it run that hot for all games?\n\nI have mine set to performance mode for the fans. You could have it on the run quiet setting, which makes it hotter.",
      "I have the TUF 3080 10GB (non OC edition). The temp levels are incredible. Very rare to have it go into the high 60s. Insanely quiet. If I undervolt, it performs as good as stock and uses about 240watts. Not sure how that is possible but it is true! TUF all the way I promise you won’t regret it",
      "I have an FTW3 3080 Ti and that card is an absolute beast. Basically every game except Cyberpunk 2077, can run at 4K max graphics settings 60+ FPS.",
      "MSI 3080 Ti Suprim X.",
      "I also have the tuf but i ahave the 3080 Ti it can reach 90 degrees depending on the load for me.",
      "I have the aorus 3080 ti master \nMy first option was the suprim x 3080ti \nJust couldn't find one at the time 😕",
      "Are you mining? If not… that’s way too hot bro. I mean it still works but it’s not average temp bro",
      "The price to performance increase is not worth it….unless you just want it anyway and it makes you happy. In which case, go for it!",
      "They are, I have one",
      "Could also be difference in loads and ehat games we play too. The 3080 ti is closer to the 3090 than a 3080 compoment wise.",
      "Thank you guys for your opinions, I really appreciate it!\n\nI got another deal for the **EVGA 33080 Ti FTW3 Ultra** for **$820.** Should I go for it? or stick with the ASUS TUF edition?",
      "I would get the TUF 3080 12GB. It’s within 5% performance of the 3080ti and only $759 right now. Scroll to bottom for price links. \n\nhttps://pcpartpicker.com/product/qnFbt6/asus-geforce-rtx-3080-12gb-lhr-12-gb-tuf-gaming-oc-video-card-tuf-rtx3080-o12g-gaming",
      "I have the ASUS TUF 3080 Ti and it doesn’t go over 65 degrees and plays any game I throw at it over 100fps 4k max settings",
      "Evga still have crazy sales so I think the 3080 ti FTW3 is the way to go.",
      "I watched this video alot \nGood luck its a big decision \n\n\n\nhttps://youtu.be/aaKXqQ5R7gY",
      "If you have the option of buying one with a built in AIO that would be my vote. It's likely worth the money and it won't be that much more than a typical card. I have an air cooked version and its great but it always feels like you could OC just fine with an AIO."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "high",
    "matched_keywords": [
      "rtx 3080",
      "3080",
      "3080 ti",
      "rtx 3080 ti"
    ],
    "title": "RTX 3080 Ti vs RTX 3090 vs RTX 4070 Ti vs RTX 4070 for max 4K@60 gaming",
    "selftext": "Hey guys, casual gamer here looking to upgrade their GPU to be able to play triple A games at max settings (including or excluding RTX) 4K@60fps\n\nI’ve narrowed down my choices to these GPUs because of their used prices here in the UK.\n\nI’ve found the:\nRTX 3080 Ti going for around £650\nRTX 3090 going for around £750\nRTX 4070 Ti going for around £850\nRTX 4070 going for around £650\n\nI intend to keep whatever GPU I buy for at least 2/3 years since I don’t really play much anymore, so that’s why the 3090 is an option due to it’s VRAM.\n\nI’m stumped on which one to buy, what would you all recommend?\n\nEdit:\nFor further context, the games I have my eyes on would be RDR2, both Spider Man games, God Of War, The Last of Us, Far Cry 6 and Elden Ring to name a few. I’ll also be doing 7th generation (X360/PS3) emulation and while that is also CPU dependent, I thought it’d be worth mentioning.",
    "comments": [
      "Just buy the 4070ti. It’s the fastest and has the best feature set. It also uses about half the power of the 3090.  3 years from now it will resell for more than the others, and you will make back any price difference.",
      "If you are intending a 3-year lifecycle at UK electricity prices of 0.41 USD/KWh, the 3090 is the worst value card on the list, the 4070 is the best, with the 4070 Ti being a close runner-up.\n\nIn some games, especially when RT is concerned, the 4070 is roughly on par in performance with 3090, the 4070 Ti is more in line with the 3090 Ti, but both of the 4000-series consume about half of the power compared to their counterparts. 12GBs of VRAM is exactly half of the 3090's but that doesn't factor into the performance really, nearly all games that have had troubles with VRAM have been fixed now, and 12GBs never really had issues.\n\nFrame Generation on the 4000-series cards also offers a 50-100% boost to framerates regardless of CPU limitations. When is used in conjunction with DLSS, the performance boost is staggering, I've measured an almost 6X increase compared to native 4K with DLSS Performance + Frame Generation in Cyberpunk 2077 with the new Path Tracing mode.\n\nWith many newer games, especially Unreal Engine 4 titles facing non-GPU bottlenecks, the importance of Frame Generation has increased. You cannot really break the 60+ barrier in both Hogwarts Legacy and Jedi Survivor without Frame Generation. With Frame Generation enabled, you can expect a 4K 120 experience with both a 4070 and 4070 Ti in both of these games, with the appropriate DLSS setting, while consuming less then 200W.\n\nTLDR: 4070 is the best value out of the bunch, 4070 Ti is close second, don't get a 3000-series card at all, it's not worth it. With UK electricity prices and a 3-year lifespan, the value of a 3090 is almost half of the 4070's.\n\nhttps://preview.redd.it/j7nnvmurqo3b1.png?width=1182&format=png&auto=webp&s=59fb5953d6d6a6d5fc7827c8f8f3f62926ae5a8c",
      "The Last of Us runs at max settings at 4K with just 8.2GBs of VRAM usage. The devs fixed the stupid VRAM reservation settings (it was reserving 5GBs of VRAM for Windows on my system at launch) and they've fixed the texture compression settings. Even a 3070 Ti with just 8GBs of VRAM can run the game at 3440x1440 maxed out without issue.",
      "Depends on the games YOU play, just saying AAA is almost meaningless,\n\nSome games, the 4070 can play 4k ultra at 60fps.\n\nSome games, not even the 4090 can touch 60fps at 4k ultra.\n\n&#x200B;\n\n[https://www.techpowerup.com/review/nvidia-geforce-rtx-4070-founders-edition/31.html](https://www.techpowerup.com/review/nvidia-geforce-rtx-4070-founders-edition/31.html)\n\nUse this as a guide to find which card is best for you, go to the page for the SPECIFIC games you play, and look at their framerates on cards, you can find which card hits 60+ in all the games you care about. At the prices you mentioned, I like the 3090 for 750.",
      "If you want to maintain 60fps with ray tracing at 4k you’ll need a 4080 (preferably 4090) for sure. \n\nIf you’re ok with turning that off the 4070ti should serve you well. \n\nI wouldn’t even consider the 3080Ti/3090 at this point. DLSS 3 is the real deal and you’ll 100% need it with a 4070ti at 4k for future AAA titles.",
      "What  kind of games do you plan to play?\n\nIf not the heavy vram games that use more than 12gb such as last of us, i'd say 4070ti is your best option here, if you can afford it.",
      "12g memory for 4k max settings is going to be a stretch. Maybe check out the 7900xtx.",
      "I wouldn’t mind switching a few things off because as much as I want to, I can’t see myself spending all that money on a 4080/4090 (upwards of £1600 in the UK) until those GPUs can come down to normal prices again lol",
      ">Over 4 years at average usage (a study I found stated 7.6 hours per week) this adds about 500 USD to the cost of a 4090 for example.\n\nWhat crack pipe study are you reading?\n\n4090 TPD is 450w aka 0.45kw (it doesn't always run that high, especially if not gaming at 4k, but we'll assume it's running 100% power at all times).\n\n0.45kw x 7.6 hours x 52 weeks 177.84 KWh\n\n177.84 KWh x 0.41 USD per KWh = 72.9144 USD per year.\n\nLet's just round and call that 73 USD per year. Or just over 6 dollars per month.\n\nNow consider that a 4070 draws 55% of that power. Are you really going to base your buying decision over a difference in $40 per year? That's less than the cost of dinner for two at a decent chain resturant.",
      "I've just picked up a 4070ti for just under £700. All gone now but there'll be more deals that come along.",
      "Look, you have to set your expectations in check. It is great to want to game at 4K60 as I enjoy that myself, but you have to keep in mind that the hardware required for \"max settings\" is stupidly expensive and not part of your options. At such lofty requirements I would not go any less than a 4080.\n\nNow, based only on the GPUs you posted, the 4070Ti might be the best option. But keep in mind this is not a long term 4K60 max settings.\n\nI would simply advise to get the 4070ti, and dont use max settings. Any other of the options you posted are either lesser performance or the same but with less features.",
      "Current average in the UK is around 0.41 USD per KWh, almost 4X the US average, if I recall correctly. Over 4 years at average usage (a study I found stated 7.6 hours per week) this adds about 250-300 USD to the cost of a 4090 for example. But if you live in Finland, you don't pay for electricity(at least since April), so it varies region by region. That's why electricity cost and average power usage is an important metric in cost calculation.",
      "What about hogwarts? It still uses 14gb at max 4k.",
      "I couldn't justify the cost of the 4080, but if you can afford it, it's a great card.\n\nI think prices are trending downwards because they're not selling well at the current high prices and people's buying power has been eroded by inflation and the cost of living.",
      "Hogwarts seems to reserve at least 80% of the VRAM regardless of need. For me, the game seemingly \"uses\" 20-21 GBs of VRAM, yet my friend with a 3070 Ti (with 8GBs of VRAM) has no problem running the game at 3440x1440.",
      "You don't need 24GBs of VRAM for Hogwarts. 12GBs should be more than enough if my friend can play without issues with just 8GBs. With just DLSS, I'm seeing \\~65-70% GPU usage on my 4090 with RT on, and that results in 60-67 fps at 4K. With a 4070 being roughly 50% of the 4090 in power, I think even the 4070 should be able to achieve 4K \\~50 without Frame Generation, probably 4K 75-80fps with Frame Generation in Hogwarts Legacy.",
      "Do you have a 4K 120Hz Display? Or rather, what kind of display are you planning on playing at?",
      "Solid response my friend!\nThis does sway my thinking to choose the RTX 4070 Ti, only just dreading the prices since it means I gotta save up a bit more lol",
      ">With UK electricity prices\n\nHow bad are UK electricity prices? As an American, I can't imagine electricity costs making a difference in GPU purchasing decisions, even if I was paying 2-4x as much as I currently am for electricity.",
      "Good point on the first part, as for games I’d be playing, it would be Far Cry 6, both of the Spider Mans, The Last of Us, God of War, RDR2 and Elden Ring as a start, I certainly wouldn’t mind dropping settings since the 4000 series is way too overpriced nowadays."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "high",
    "matched_keywords": [
      "rtx 3080",
      "3080",
      "3080 ti",
      "rtx 3080 ti"
    ],
    "title": "GeForce Beyond Megathread - NVIDIA GeForce RTX 40 Series GPUs, DLSS 3, Portal with RTX and more",
    "selftext": "# Addendum 2: Important note on Power Specifications\n\nPlease visit this page for important information on power specifications: [https://www.nvidia.com/en-us/geforce/forums/geforce-graphics-cards/5/501736/geforce-rtx-40-series-power-specifications/](https://www.nvidia.com/en-us/geforce/forums/geforce-graphics-cards/5/501736/geforce-rtx-40-series-power-specifications/)\n\nSome important points listed below\n\n**Do I need to upgrade my PSU for the RTX 40 Series?**\n\nThe RTX 40 Series doesn’t require a new power supply if you already meet the PSU wattage recommendations. The RTX 4090 TGP is 450 W and the minimum recommended PSU is 850 W. The 4080 16GB TGP is 320 W with a minimum recommended power supply of 750W, and the minimum recommended power supply for the 4080 12GB is 700W.\n\n**Do the RTX 40 Series cards require a new type of power connector or a new power cable?**\n\nNo. The RTX 40 Series cards come with power adapters that allow you to use existing power supplies with existing 8-pin PCIe connectors. The RTX 40 Series cards can also use the PCIe Gen5 power connector which allows you to power the graphics card with a single cable.\n\n# Addendum 1: Important note on DLSS 3\n\nDLSS 3 consists of 3 technologies – DLSS Frame Generation, DLSS Super Resolution (a.k.a. DLSS 2), and NVIDIA Reflex.\n\nDLSS Frame Generation uses RTX 40 Series high-speed Optical Flow Accelerator to calculate the motion flow that is used for the AI network, then executes the network on 4th Generation Tensor Cores. Support for previous GPU architectures would require further innovation and optimization for the optical flow algorithm and AI model. \n\nDLSS Super Resolution and NVIDIA Reflex will of course remain supported on prior generation hardware, so current GeForce gamers & creators will benefit from games integrating DLSS 3.  We continue to research and train the AI for DLSS Super Resolution and will provide model updates for all RTX customers as we have been doing since DLSS’s initial release.\n\n|**DLSS 3 Sub-Feature**|**GPU Hardware Support**|\n|:-|:-|\n|DLSS Frame Generation|GeForce RTX 40 Series GPU|\n|DLSS Super Resolution (aka DLSS 2)|GeForce RTX 20/30/40 Series GPU|\n|NVIDIA Reflex|GeForce 900 Series and Newer GPU|\n\n&#x200B;\n\n# This thread is best viewed on new Reddit.\n\n[Image Link - GeForce RTX 4090 Founders Edition](https://preview.redd.it/6orjy4mwi0p91.png?width=3840&format=png&auto=webp&s=f868594edce3c4857dee6028498428dfd55bfd61)\n\n\\#BeyondFast. Powered by the Ada Lovelace architecture, GeForce RTX 40-Series is finally upon us. The goal of this megathread is to provide everyone with the best information possible and consolidate any questions, feedback, and discussion to make it easier for NVIDIA’s community team to review them and bring them to appropriate people at NVIDIA.\n\n# r/NVIDIA GeForce RTX 40-Series Community Q&A\n\nWe are hosting a community Q&A today where you can post your questions to a panel of 7 NVIDIA product managers. [Click here to go to the Q&A thread for more details.](https://new.reddit.com/r/nvidia/comments/xjcr32/geforce_rtx_40series_community_qa_submit_your/)\n\n# r/NVIDIA GeForce Beyond Giveaway\n\nPrize includes GeForce RTX 4080 16GB card, Steam giftcards, and Nvidia swag bags including RTX Keycaps and Mugs. **See pinned comment for details!**\n\n# GeForce RTX 40-Series GPU information:\n\n# [Official Spec Sheet Here](https://www.nvidia.com/en-us/geforce/graphics-cards/compare/?section=compare-specs)\n\n&#x200B;\n\n||**RTX 4090**|**RTX 4080 16GB**|**RTX 4080 12GB**|\n|:-|:-|:-|:-|\n|**GPU**|TSMC 4N AD102|TSMC 4N AD103|TSMC 4N AD104|\n|**Transistor**|76.3 billion|45.9 billion|35.8 billion|\n|**Die Size**|608.5 mm^(2)|378.6 mm^(2)|294.5 mm^(2)|\n|**Transistor Density**|125.5 MT/mm^(2)|121.1 MT/mm^(2)|121.6 MT/mm^(2)|\n|**GPC**|11|7|5|\n|**TPC**|64|38|30|\n|**SMs**|128 SM|76 SM|60 SM|\n|**TMUs**|512|304|240|\n|**ROPs**|176|112|80|\n|**Base Clock**|2.23 Ghz|2.21 Ghz|2.31 Ghz|\n|**Boost Clock**|2.52 Ghz|2.51 Ghz|2.61 Ghz|\n|**CUDA Cores**|16384 CUDA Cores|9728 CUDA Cores|7680 CUDA Cores|\n|**Shader FLOPS**|82.6 Shader TFLOPS|48.7 Shader TFLOPS|40.1 Shader TFLOPS|\n|**RT Cores**|128 3rd Gen RT Cores|76 3rd Gen RT Cores|60 3rd Gen RT Cores|\n|**RT FLOPS**|191 RT TFLOPS|112.7 RT TFLOPS|92.7 RT TFLOPS|\n|**Tensor Cores**|512 4th Gen Tensor Cores|304 4th Gen Tensor Cores|240 4th Gen Tensor Cores|\n|**Tensor FLOPS (FP8)**|660.6/1,321 Tensor TFLOPS|389.9/779.8 Tensor TFLOPS|320.7/641.4 Tensor TFLOPS|\n|**Memory Interface**|384-bit|256-bit|192-bit|\n|**Memory Speed**|21 Gbps|22.4 Gbps|21 Gbps|\n|**Memory Bandwidth**|1,008 GB/s|716.8 GB/s|504 GB/s|\n|**VRAM Size**|24GB GDDR6X|16GB GDDR6X|12GB GDDR6|\n|**L2 Cache**|72MB|64MB|48MB|\n|**Max TGP**|450W|320W|285W|\n|**PSU Requirement**|850W|750W|700W|\n|**Price**|$1599 MSRP|$1199 MSRP|$899 MSRP|\n|**Release Date**|October 12th|November|November|\n\n# Performance Shown (take with grains of salt until actual review):\n\n* RTX 4090\n   * 2x Performance of RTX 3090 Ti\n* RTX 4080 16GB\n   * 2x Performance of RTX 3080 Ti\n* RTX 4080 12GB\n   * \\~3090 Ti performance\n\n# Power Requirements:\n\n&#x200B;\n\n|**SKU**|**Power Supply Requirements**|\n|:-|:-|\n|GeForce RTX 4090 Founders Edition|**850W Required**. 3x PCIe 8-pin cables (adapter in the box) OR 450 W or greater PCIe Gen 5 cable|\n|GeForce RTX 4080 16GB Founders Edition|**750W Required**. 3x PCIe 8-pin cables (adapter in the box) OR 450 W or greater PCIe Gen 5 cable|\n|GeForce RTX 4080 12GB Founders Edition|**700W Required**. 2x PCIe 8-pin cables (adapter in box) OR 300 W or greater PCIe Gen 5 cable|\n\n**See Diagram below**\n\n[Image Link - RTX 4090 and 4080 16GB Founders Edition Power and Case Requirements](https://preview.redd.it/1dph84mvn0p91.png?width=3172&format=png&auto=webp&s=9aacb9dcdfbe1c12db5c8d1d376e5e6892ca071c)\n\n# DLSS 3\n\n* Over 35 Games and Apps adding DLSS 3\n* DLSS 3 is a revolutionary breakthrough in AI-powered graphics that massively boosts performance while maintaining great image quality and responsiveness. Building upon DLSS Super Resolution, DLSS 3 adds Optical Multi Frame Generation to generate entirely new frames and integrates NVIDIA Reflex low latency technology for optimal responsiveness. DLSS 3 is powered by the new fourth-generation Tensor Cores and Optical Flow Accelerator of the GeForce RTX 40 Series graphics cards.\n* Optical Frame Generation boosts performance by reducing the GPU workload, thus increasing performance. Powered by new fourth-generation Tensor Cores and the new Optical Flow Accelerator on GeForce RTX 40 Series GPUs, DLSS 3 analyzes sequential frames and motion data and uses AI to create additional high-quality frames. \n* Ada includes a powerful new 3rd-generation RT Core (Ray Tracing Core) that provides up to 2x the ray-triangle intersection performance of the prior 2nd-generation RT Core used in NVIDIA Ampere architecture GPUs.\n* 4th Generation Tensor Cores accelerate AI features that allow you to apply advanced effects faster, and without requiring advanced editing knowledge. 4th Gen Tensor cores are up to 2x faster vs prior gen, and now they add support for INT8.\n\n# Portal RTX\n\n* **Wishlist on STEAM Now!  - Coming November 2022** [**https://store.steampowered.com/app/2012840/Portal\\_with\\_RTX/**](https://store.steampowered.com/app/2012840/Portal_with_RTX/)\n* **Note: Free DLC for owners of Portal.**\n* NVIDIA Lightspeed Studios has reimagined Valve’s iconic video game *Portal*, regarded as one of the best video games of all time. Advanced graphics features such as full ray tracing and DLSS 3 give the game a striking new look and feel. *Portal with RTX* will be released as free, official downloadable content for the classic platformer with RTX graphics in November, just in time for *Portal*’s 15th anniversary.\n\n# RTX Remix\n\n* **Sign up Now! -** [**https://www.nvidia.com/en-us/geforce/rtx-remix/**](https://www.nvidia.com/en-us/geforce/rtx-remix/)\n* [NVIDIA RTX Remix](https://www.nvidia.com/en-us/geforce/rtx-remix/), a free modding platform built on [NVIDIA Omniverse](https://www.nvidia.com/en-us/omniverse/) that enables modders to quickly create and share #RTXON mods for classic games, each with enhanced materials, full ray tracing, [NVIDIA DLSS 3](https://www.nvidia.com/en-us/geforce/news/dlss3-ai-powered-neural-graphics-innovations), and [NVIDIA Reflex](https://www.nvidia.com/en-us/geforce/technologies/reflex/).\n\n# NVIDIA STUDIO & AV1 Encoder\n\n* The new [GeForce RTX 4090](https://www.nvidia.com/en-us/geforce/graphics-cards/40-series/rtx-4090/) brings a massive boost in performance, third-generation Ray Tracing Cores, fourth-generation Tensor Cores, **dual eighth-generation NVIDIA AV1 Encoders**, and 24GB of Micron G6X memory capable of reaching 1TB/s bandwidth. The GeForce RTX 4090 is up to **2X faster than a GeForce RTX 3090 Ti in 3D rendering, AI, and video exports.**\n* RTX 40-series Ada generation GPUs feature hardware accelerated encoding for the AV1 video codec using the NVIDIA hardware encoder, NVENC. AV1 offers improved visual quality at the same bitrates as H.265/H.264 which is a boon for game streaming. Optionally, users can opt to maintain the same level of visual quality, with reduced bit rates when using AV1, resulting in smaller file sizes and faster video uploads. Ada’s AV1 encoder is 30% more efficient than the H.264 encoder used today for 4K HDR video. \n\n# Reference Links\n\n|**Articles**|**Links**|\n|:-|:-|\n|GeForce RTX 40 Series Graphics Cards: Up To 4X Faster, Powered By 3rd Gen RTX Architecture & NVIDIA DLSS 3|[Link Here](https://www.nvidia.com/en-us/geforce/news/rtx-40-series-graphics-cards-announcements)|\n|NVIDIA DLSS 3: AI-Powered Performance Multiplier Boosts Frame Rates By Up To 4X |[Link Here](https://www.nvidia.com/en-us/geforce/news/dlss3-ai-powered-neural-graphics-innovations/)|\n|Portal with RTX Reimagines Valve’s Classic with Full Ray Tracing, NVIDIA DLSS & NVIDIA Reflex|[Link Here](https://www.nvidia.com/en-us/geforce/news/portal-with-rtx-ray-tracing)|\n|NVIDIA RTX Remix: Create & Share #RTXON Mods For Classic Games|[Link Here](https://www.nvidia.com/en-us/geforce/news/rtx-remix-announcement/)|\n|Over 35 Games And Apps Adding NVIDIA DLSS 3. Plus Portal with RTX, Cyberpunk 2077 New Ray Tracing: Overdrive Mode & More|[Link Here](https://www.nvidia.com/en-us/geforce/news/dlss3-supports-over-35-games-apps)|\n|Step Up To 1440p 360 FPS Competitive Gaming With New GeForce RTX 40 Series Graphics Cards and NVIDIA Reflex|[Link Here](https://www.nvidia.com/en-us/geforce/news/play-competitive-games-with-rtx-40-series-and-reflex)|\n|GeForce RTX 40 Series #BeyondFast Sweepstakes|[Link Here](https://www.nvidia.com/en-us/geforce/news/rtx-40-series-beyondfast-sweepstakes)|\n|Creativity At The Speed of Light: GeForce RTX 40 Series Graphics Cards Unleash Up To 2X Performance In 3D Rendering, AI, and Video Exports For Gamers and Creators|[Link Here](https://www.nvidia.com/en-us/geforce/news/rtx-40-series-and-studio-updates-for-content-creation/)|\n\n&#x200B;\n\n|**Videos**|**Links**|\n|:-|:-|\n|GeForce Beyond: A Special Broadcast at GTC (keynote cutdown)|[Link Here](https://youtu.be/Uo8rs5YfIYY)|\n|GeForce RTX 4090 Beyond Fast|[Link Here](https://youtu.be/fj245xMr-BM)|\n|Portal with RTX World Premiere|[Link Here](https://youtu.be/AZHBl5yWqJk)|\n|NVIDIA Racer RTX The future of graphics powered by GeForce RTX 40 Series|[Link Here](https://youtu.be/AsykNkUMoNU)|\n|Cyberpunk 2077 NVIDIA DLSS 3 & Ray Tracing: Overdrive - Exclusive First-Look|[Link Here](https://youtu.be/spq0jSWRCqI)|\n|Microsoft Flight Simulator NVIDIA DLSS 3 - Exclusive First-Look |[Link Here](https://www.youtube.com/watch?v=cJlo2I7CiD0)|\n|A Plague Tale: Requiem RTX ON - Exclusive First-Look|[Link Here](https://youtu.be/341KyDYjI0U)|\n|JUSTICE Fuyun Court - Path Tracing Showcase Premiere|[Link Here](https://www.youtube.com/watch?v=X9zMxCPqgGI)|\n|RTX. IT’S ON. Ray Tracing & DLSS In Your Favorite Games|[Link Here](https://youtu.be/mqiVYUAonoE)|\n|GeForce Garage - RTX 4090 Build by LiquidHaus|[Link Here](https://youtu.be/H5soCA5SQD0)|\n|Cyberpunk 2077 NVIDIA DLSS 3 Performance Comparison|[Link Here](https://youtu.be/r-hu006p23I)|\n\n&#x200B;",
    "comments": [
      "RTX 4080 *12GB* being called RTX 4080 is misleading and bad naming. It's not same GPU as RTX 4080 *16GB* at all. Names makes it suggest the only difference is the VRAM but it's totally different class of GPU.\n\nYou seriously don't have any other letters or numbers to use?",
      "Selling the rebranded 4070 for $900 is ridiculously anti-consumer.",
      "Pricing is god awful.",
      "Two 4080 versions... Really? This is BS, just call them differently. I hate when companies do this. Just call the better one 4080 TI or 4085. They are NOT the same.",
      "Guess I’ll keep my Rtx 3080 and skip this gen.",
      "DLSS 3....Wait so dlss 3 is just for 40 series of cards?\n\nWTF?",
      "Hahahahhahahahahha, the pricing is ridiculous. What should be a 70 series card for $899.",
      "It's because the 12Gb is really the 4070 as it's AD104, but they don't want to call it that cause it makes it look like the 4070 is more expensive than the 3080 at launch etc.",
      "Not the first time they've done this. \n\nThey know exactly what they're doing.",
      "Amazing technologies were shown, but the prices where I live are inexcusable. No thanks.",
      "Jensen pulling the Apple power move by gatekeeping software features to push sales of new products",
      "1500€ for 4080 in Europe, lmfao.",
      "Like EVGA, we should skip this gen",
      "Yep, there should not be a crippled 12GB version imo. \n\nWhat a great way to artificially move the stack even further out to make everything more expensive.",
      "From what I've read they should have just called the 12GB version the 4070. Maybe they didn't want to say \"The 4070 costs more than the 3080 did at launch?\" I don't know.",
      "Can’t extort the miners anymore so they’re extorting the general consumers instead, lovely",
      "Ouch that price. My 1080ti going to have to keep ticking over a little longer",
      "*cries in 1060 3gb*",
      "Obviously. Were you thinking that it's reasonable to change your gpu every single gen?",
      "Super interested in amd and their reveal now :)"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "high",
    "matched_keywords": [
      "rtx 3080",
      "3080"
    ],
    "title": "RTX 3080 vs. 2080 Ti in 13 VR games!",
    "selftext": "",
    "comments": [
      "I don't play VR, but I always appreciate that there's someone doing this kind of stuff.",
      "This looks very promising for Valve Index owners, as it looks like the RTX 3080 is able to hit 120 FPS pretty consistently in all the games tested except for Subnautica, but Subnautica is just extremely poorly optimized as an older Unity engine game. The Index and Vive Pro have the same resolution IIRC, so the FPS values seen for the Vive Pro results should match up fairly well with the Index. The jump from playing at 90 FPS to 120 FPS is substantial. I got a 2080 Ti myself and these results are pretty much what I wanted from a card replacing the 2080 Ti, a consistent 120 FPS experience.\n\nIf the 3090's gains of 10-15% are the same in VR as they are in pancake mode, then that's still not quite enough to get that last notch up to 144hz consistently, so it's probably not worth the investment there.",
      "The reviewer used Vive Pro. If I remember correctly Vive Pro has the exact same res also for SteamVR 100% compared to Index - so the choice of hmd may be very good, even if it's not the Index. Also SteamVR res 100% for Vive Pro should be very close to Reverb G1/G2 res 100% (I think G2 is like 2-3% higher, because it has close to no super sampling for SteamVR res 100%, while Index and Vive Pro have much super sampling for res 100%).  \nSome benchmarks were performed using higher than SteamVR 100% res - but again I think Vive Pro and Index uses same res also for res 200% etc.",
      "These 15-20% would be enough to get me to 90Hz in ACC, though. Being able to get to 80Hz rock stable with decent graphics now with the 3080.",
      "Fellow ACC brother here. 3090 FE arrives Monday. Praying for 90 FPS. \n\nFirst will go on my Pimax 5K+, but is ultimately intended for my Reverb G2 next month/early November.",
      "I can't wait for Star Wars Squadrons. Whole game in VR. I need a 3080 for the beautifulness.",
      "Please let us know how the 3090 performs! I haven't seen much information on the 3080 vs 3090 for VR.",
      "It's weird that there isn't many review sites that do it. I only know of this one myself. The most I see is just the open vr benchmark on others.",
      "holy shit i'm so excited, i haven't played vr in months because my 1070 can barely hit 90 in tons of the games i want to play. and the 3080 can hold 120 at LEAST??? like that's so crazy!!! now if only i could get one in the uk",
      "It's the same resolution for the Vive Pro and Index, but the Index has a higher rendered FOV which makes a difference, and the G2 is actually has 6% higher 100% render resolution, not sure about rendered FOV on it but likely similar to the Vive Pro.\n\nAlso note that it's only rightly supersampling is when going beyond the 100% render resolution. While the 100% is higher than the screen resolution that's because the rendered image has to be warped to counter the warping of the lenses and get 1:1 pixel mapping in the center of the view, and hence isn't considered supersampling.",
      "This is great, been waiting to see some good VR benchmarks. Honestly the performance looks better than I was expecting. I was originally considering 3090 but I think this solidifies my decision to go 3080, seems like more than enough to drive the Index well.",
      "Oh yes you can my friend. Key is to use the older 2018 build before they updated the unity core and fucked performance to hell and back.",
      "Are you me? DCS is my other primary sim.",
      "I read your comparison of the 3080 and 2080ti, good stuff! And seeing your earlier posts, don't be afraid to take some time off to actually enjoy VR! \n\nI also saw that you recently hired someone to focus on simulation games. Is a DCS benchmark a possibility in the future? I'm interested in seeing how the 3080/3090 performs with unoptimized games. 3090 doesn't seem worth it for most uses, but perhaps it can help reach stable fps in the most demanding VR games.",
      "Nice! Thanks Babletech",
      "Great article. I’m really looking forward to the 3090 comparison",
      "Those elite dangerous results have me fully erect",
      "Hardpoints deployed.",
      "Imagine sneezing during a walk through for a fps comparison and you look on the ground for a few ms and that gives a 100% boost of the avg. Fps",
      "\\>Star Wars Squadrons \n\nOMG VR X-Wing with 2020 graphics. How did I not know this was coming out soon."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "high",
    "matched_keywords": [
      "rtx 3080",
      "3080",
      "3080 ti",
      "rtx 3080 ti",
      "3080ti"
    ],
    "title": "RTX 4080 (12 GB) VS RTX 3080 Ti (16 GB) Laptop for ML Projects",
    "selftext": "I am an incoming college student vaguely interested in machine learning and fluid dynamics. I hope to run software such as Ansys Fluent and perhaps do a few projects where I may need to run small LLMs on device. I can find a RTX 4080 with a 32gb memory and a 13900HX for \\~2,000$ while a 3080ti with a higher VRAM and a 32GB SSD and a 12900HX for only \\~1400. \n\n  \nI am wondering which laptop would serve me better in my tasks. From my research it seems like r/LocalLLaMA  seems to believe that more VRAM is better while r/GamingLaptops  believes that 4080 is much faster. I have never gamed and don't intend to in the future so the frame generation thing doesn't really excite me. ",
    "comments": [
      "With the older 3080M Ti you're getting both more VRAM and faster VRAM bandwidth, which means it will be faster and more capable for CAE and AI workloads.\n\nRTX 40 series unfortunately is 5 years backward progress with memory bus downgrade, making it slower in these workloads. A dumpster fire of a generation - spare the money!",
      "Get the card with the more vram. That should be mostly obvious if you want to run a local model.",
      "I don’t know how important this is but the CUDA comparability score for 4080 is 8.9 vs 8.6 for 3080ti- it seems like the larger cache is really helpful tor cuda acceleration. Should I pay attention to these metrics?",
      "This guy knows what he's talking about^\n\nGo with the 3080Ti 16GB. And the fact it's cheaper too makes it a total slam dunk",
      "Not important at all. It's not even a major version bump.\n\nThe cache helps when the applications repeatedly accessing the same tiny buffers, which to large part or entirely fit in cache. For example the frame buffer in games. But most compute workloads work with large multi-GB buffers, and when 1% if that fits in cache, you get a fraction of a % speedup, negligible. Cache is useless for most compute workloads."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "high",
    "matched_keywords": [
      "rtx 3080",
      "3080",
      "3080 ti",
      "rtx 3080 ti"
    ],
    "title": "Can I connect 12VHPWR to RTX 3080 ti ?",
    "selftext": "Hi,\n\nI got a gifted Asus Loki PSU with 12VHPWR can I use this new connection and plug my Rtx 3080 ti to it or that's only for 40+ series?",
    "comments": [
      "Only new 4000 series and 3000 founders cards",
      "The 3090ti didn’t have pcie connectors, not 12VHPWR standard but you can still power it with the cable: https://reddit.com/r/buildapc/s/qeyZApLAhB",
      "Nvidia called it a “PCIe Gen 5 cable” and included a 3 pcie to 1 adapter. A Tom’s hardware article says it uses 12VHPWR but it doesn’t say that in the marketing material. The 3090ti is the only ampere card with it afaik.",
      "I thought it was backwards compatible with the 3090ti",
      "Could you maybe update this with the correct information? It's most upvoted but all RTX 30 FE cards can use 12VHPWR. They just don't use sense pins, but the connector fits just fine. I use 12VHPWR with my 3090 FE. It doesn't even have to be a ti GPU, just FE.",
      "ok, thanks. it's just  **12VHPWR**  fits perfectly into my 3080 Ti ports. that's basically why I'm asking",
      "I was wrong\n\nIt turns out FE 3000 cards support it",
      "it looks like: Can I screw a light bulb into a power outlet?\n\nobviously the answer is: 'need a proper dapater'",
      "Can I connect it to my 3070Ti? It’s not founders edition.",
      "You can use 12VHPWR cables with RTX 30 FE cards. I'm using one right now with my 3090 FE.",
      "no, you can't it will ruin your voltage controller and break the GPU - that's what happened with mine. \n\nhad to buy 4080 ;(",
      "Fixed",
      "It killed yput 3080?",
      "yes",
      "Oh I've never heard about this before",
      "It’s compatible with the 3-series FE cards",
      "Using it with my 3080 FE",
      "Yeah I use 12VHPWR with a 3090 FE. I don't have the ti version. Like you said, it's any RTX 30 FE card that can use 12VHWPR.\n\nThe only difference between RTX 30 and 40 series is the 30 series doesn't use sense pins, but the connector fits regardless.",
      "hey, do you use a 16 pin to 8 x2 or 16pin to 16pin ? Because i'll use a 3080 founder temporary for my new build and i see only 16 to 8x2 ref for 3000 fe and 16 to 16 are labeled as only 4000 compatible",
      "I use the 12VHPWR cable that came with my PSU, which is Corsair RM850x Shift. So it's not really 2x 8-pins on the PSU side iirc, Corsair's Type 5 PCIe cables are 6-pin on the PSU side. So that would be 16-pin to 2x 6-pin, but yeah that'd essentially be equivalent to 2x 8-pin. There are some PSUs that use the same 16-pin connector on both sides but it'd work for the 3000 FE cards with 12VHPWR connectors since the device-side connector is the same regardless of the PSU-side."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "high",
    "matched_keywords": [
      "rtx 3080",
      "3080",
      "3080 ti",
      "rtx 3080 ti"
    ],
    "title": "Torn between RTX 3080 Ti and RTX 4070",
    "selftext": "I have been mulling over this question for quite a while now and can't come to a conclusion. Both the 3080 Ti and 4070 cost the same in my country(Both are new and not used). I will be using the GPU for machine learning and gaming. I could only list the following advantages of these GPUs. Which GPU should I go for?\n\n\nPros of RTX 3080 Ti:\n\n28.1 GPixel/s higher pixel rate\n\n4.95 TFLOPS higher floating-point performance\n\n77.4 GTexel/s higher texture rate\n\n4352 more shading units\n\n136 more texture mapping units (TMUs)\n\n48 more render output units (ROPs)\n\n408.2GB/s more memory bandwidth\n\n192 bit wider memory bus width\n\n\n\nPros of RTX 4070:\n\n550MHz faster GPU clock speed\n\n810MHz faster GPU turbo speed\n\n125MHz faster memory clock speed\n\n2000MHz higher effective memory clock speed\n\n150W lower TDP\n\n7500 million more transistors\n\n3nm smaller semiconductor size",
    "comments": [
      "You somehow managed to list a whole bunch of \"pros\" for the 4070 that are all completely irrelevant. Who cares about clock speeds and transistor counts? It's performance in your games and workloads that matters. Consult benchmarks, not the specs.",
      "4070. Frame gen combined with DLSS is like magic",
      "4070.\n\nFake frames are still more frames.",
      "Yeah FG is the tie-breaker, do you want that or not? The only other thing is the 40x0 series is elegantly efficient (less heat and energy) vs the 30x0 series.",
      "get the newer one",
      "Don't look at the specs but the benchmarks.",
      "If they're the *same price* and you don't care about FG then I'd go for 3080Ti. Just curious maybe you meant 4070Ti because that's more in line with 3080Ti price.",
      "I meant the 4070 only. There's a massive sale ongoing in my country which has reduced the prices of RTX 3080 Ti by a massive 72%.",
      "100% depending on whether you like frame gen. I don’t think frame gen is the best right now, so I’d personally say the 3080 TI. You could bank on them getting better. I like raw performance much better, I still only like extra software as a bonus. I don’t like the idea that if Nvidia messes up a software update I could lose frames I need to enjoy a game.",
      "4070",
      "4070. Just got mine. Beast of a card!",
      "Your budget. What’s going to get you the performance you want now and fit with your next upgrade?",
      "Lol.  This isnt a comparison.  3080ti is objectively better at every measure by a significant margin.\n\nThe only thing you get is new frame gen with a 4070.  Ans thats a big ‘if’ atm with only some games supporting it.",
      "Look at their stats for games you play at your resolution. Look at machine learning benchmarks. Decide which of those factors is more important and buy the better of the two cards.\n\n\nI have a 4070. It's pretty good. Very quiet, low power draw and heat. 3080ti will be stronger. You could likely find one used for even less.",
      "3080 ti. Faster in games and a lot more Cuda cores for deep learning.",
      "used 3080s are going for like 350 on ebay there the best cost/performance you can get",
      "The 3080 Ti is from Colorful BattleAX and the 4070 is from Zotac. Are these good brands? Both are new and priced at US$650 in my country.",
      "The 3080ti is your best bet. They go for stupid cheap used, and it’s significantly faster in raster. Not terribly sure abt rt tho"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "high",
    "matched_keywords": [
      "rtx 3080",
      "3080",
      "3080 ti",
      "rtx 3080 ti"
    ],
    "title": "[Optimum Tech] Good Luck – Nvidia RTX 3080 Ti Review",
    "selftext": "",
    "comments": [
      "3080 SE for Scalper Edition",
      "They should have called it a 3080 Super lol",
      "Yeah, that card is a disappointment. The MSRP is at least 200 too high -- not that you can even dream of getting it for less than 2-3x that. All that for 15% improvement on the 3080. Which you also can't get for anything less than 2500 (and rising).\n\nIt's a disgrace.",
      "The 3080 Tie",
      "The 2080 Ti was 21%~~ better than the 2080 (at 1440p) with 3gb extra VRAM\n\n3080 Ti is 7-8% better than the 3080 (at 1440p) with 2gb extra VRAM\n\nI think that combined with the 3080 Ti taking potential dies away from the 3080 is why people are so frustrated",
      "Or the 3080 Marginal",
      "Seriously though how solid is this guy's channel, his reviews are always informative, non biased, and no bs. Really enjoy OT's videos and recently followed his video on curve optimization when undervolting zen 3.",
      "Further product segmentation is certainly not going help with those 3080s that you currently can't get, because now they have less reason to make the product with a lower profit margin.",
      "You can’t get those either.",
      "3090Lite lol at least the price is more in line with that one",
      "Because this launch is splitting silicon supply instead of restocking the products that already existed, and desperately needed restocking. It's a tone deaf approach to the current market. The price is irrelevant,  to me at least.",
      "3080 weebitbetterforalotmoremoney",
      "My 2080ti ftw3u was a beast. 2100+ all day on an ek waterblock.",
      "Neither does mine... im aftermarket air. What do you have now?",
      "That's completely expected though, considering the difference between a 3080 and 3090 was a fairly slim margin to begin with.",
      "It wouldn't exceed 60 degrees either. I miss it.",
      "RTX 3080 Pre-scalped",
      "It's priced exactly like the 2080TI was. lol I legitimately don't understand how people are shocked or upset by this. **Of course** it's a terrible price/performance ratio. It's a totally unnecessary card to begin with! lol",
      "People saying this are so confusing to me.  Do you know what scalping is otherwise known as?  Arbitrage.  Aka, understanding there is a difference between the price people are willing to pay, and what the price of a good is.\n\nNvidia matching that price more closely (and even then it's off by at least 2x it seems) is not scalping.  It's called common fucking sense.",
      "This!"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "high",
    "matched_keywords": [
      "rtx 3080",
      "3080",
      "3080 ti",
      "rtx 3080 ti"
    ],
    "title": "EVGA's Elite membership could be your best bet to bag an RTX 3080 Ti in the first 24 hours",
    "selftext": "",
    "comments": [
      "I have no eligible evga products to register. Have less than 100 posts on the forums, not enough twitch e-points. Ripperonis cappuchino.",
      "USA only it seems",
      "Of course it is. The rest of us don’t get shit with EVGA because we ain’t American. Americans moaning about no GPUs at MSRP is hilarious considering they get them at MSRP in their local MC meanwhile we get fucked.",
      "Quelle surprise.",
      "This is a new program that just launched today, you have to sign up for it on EVGA's site.",
      "I wonder how long it would take to rack up those Twitch points.  You could always just leave the stream running in the background.  The other alternative is to go find a cheap mouse or backup PSU somewhere and buy one.\n\n100 forum posts, maybe.  That's a lot of spam.",
      "I actually found an old 560ti that my brother had and registered it. Need to find 1 more product lulz.",
      "I'm willing to bet that a non-trivial percentage of people who would order from their web site will sign up for this so all it really means is that you'll be able to order a 3080 Ti in late 2021 instead of mid 2022.",
      "wish they would bring it down under",
      "Not really...to get an alternate account to elite status, you'd have to make a few expensive purchases or have 100 non spam forum posts per account. They also only allow one per household.",
      "the barriers to entry are pretty significant. you can only get one product entry per notification per account. so you need to hit like 4 check marks to hit Elite status on an already associate account. \n\nthat's like 200 bucks and a bunch of paperwork per entry. yeah they'll still get one or two or something but this really nukes botting and scalping significantly compared to previous measures being used.",
      "That's probably how I got a 3080 so fast. I have 2 products registered with them and I think I got the first email to purchase a 3080 back in January. I joined the list in Sept. I missed several emails to buy one then just sent them an email saying that I missed my turn and they sent me a link right away to purchase one.",
      "Thanks for reminding me, Been a EM for about 4yrs, 🥃",
      "If I were in the market for one I'd be down but yeah... Looking for 2 3060Ti's currently... a 2060 KO is currently in the step-up program since Dec for a 3060 Ti (for my daughter) and have been semi-actively looking for any sort of 3060 Ti (For my son (1660)... \n\nIf I tried I'd actually snag it but yeah, I suppose since they all have cards there is no rush at the moment..",
      "In case no one noticed, right now they only have a handful of products listed as \"Elite Exclusives\" - like the Kingpin card.\n\nMy guess is, they will release 4 3080 Ti SKUs and only one will be reserved for Elite members at first.",
      "100 posts isn't too hard if you make sure to be on-topic and not spammy, and take advantage of the off-topic section. You got a few days. I don't think the 3080 ti will come out for atleast a week so if you make a few posts a day you'll get there.\n\nI remember doing this in September when I thought being an EVGA elite member would be key to getting a 3080 (I was wrong but still got in)",
      "EVGA is so much better in the US in every way ):",
      "Bought a gaming laptop from them in 2017... Does not qualify. Fucking ouch.\n\nEDIT: I sent them some polite feedback like \"hey guys it would be cool if us old laptop owners qualified\" and they put me on Elite. Very cool. EVGA service has always exceeded my expectations.",
      "I did this exact thing and noticed I had bought a 650 Plat PSU on amazon also in 2017. Did some digging and also found the box. Registered it and was able to fill out the form for Elite status.\n\n&#x200B;\n\nThanks, I wouldnt of even thought of this without seeing this post. Maybe I can snag a 3080ti",
      "Yeah I know, just saying. Seems like they did me a favor before this program."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "top",
    "matched_keywords": [
      "3090",
      "rtx 3090"
    ],
    "title": "RTX 3090 vs. 3080 vs. 3070",
    "selftext": "",
    "comments": [
      "Ive always been told width is more important than length, but you need a little bit of both for maximum efficiency.",
      "Everyone is rightfully talking the length of the 3090, but it's fucking wide too. Length just barely fits in the Meshify Fractal C, but idk about that width...",
      "**G**iant **P**enis **U**nit",
      "We still talking about GPUs?",
      "Damn the 3070 is dwarfed by the 3090 and even the 3080.",
      "I have a felling 3090 cooler will cool as good as any high end AiB cooler and look 10x better on the way.\n\nLook at that size compared to 3080 and it has to cool only extra 30w compared to 3080, looks like a beastly cooler!",
      "Yes, definitely",
      "If there was ever a card that deserved the name \"Titan\" it's 3090.",
      "I have a feeling that if 3090 doesn't come with a bracket its going to break alot of motherboards.",
      "BFGPU",
      "I have no use whatsoever for the 3090 on a 60hz TV but I desperately want one of the bad boys.",
      "Why is there a piece of plastic on the 'blow through' part of the 3090? Shipping protection?",
      "It actually is small. Small is relative. For example, in comparision to the Reichstag, the RTX 3090 is small.",
      "Big floppy",
      "Having three actual PCIe brackets will be better for support, versus a lot of AIB cards that only use 2 brackets but are 2.7-2.9 slots anyway.\n\nThe full length metal frame should also help with drooping at the end of the cards.",
      "RTX 3090 乇乂ㄒ尺卂 ㄒ卄丨匚匚 edition",
      "Certainly looks removable",
      "Where's that OP at that tried to claim the 3090 is actually a small card? LOL.\n\nEdit: [https://www.reddit.com/r/nvidia/comments/inp88v/3000\\_series\\_are\\_not\\_big\\_3070fe\\_is\\_just\\_really/?utm\\_source=share&utm\\_medium=web2x&context=3](https://www.reddit.com/r/nvidia/comments/inp88v/3000_series_are_not_big_3070fe_is_just_really/?utm_source=share&utm_medium=web2x&context=3)",
      "Well at 4K 60hz it still makes sense for running demanding games at the highest settings. I game on a 65 inch OLED and I’m picking up a 3090.",
      "That's why I find a lot of the 2.x \"slot\" cards stupid. Just use 3 PCIe brackets FFS."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "top",
    "matched_keywords": [
      "3090",
      "rtx 3090"
    ],
    "title": "NVIDIA GeForce RTX 3090 and GeForce RTX 3080 specifications leaked - VideoCardz.com",
    "selftext": "",
    "comments": [
      "\"Alright, 1080ti. Looks like another tour.\"",
      "3070 with 8GB is kick to my nuts",
      "As a 1080Ti owner for 3.5 years now i realy hate these options. I want to upgrade for Cyberpunk 2077\n\nI sure af wont do a VRAM downgrade, so 3080 and 3070 are out. The 3090 will be 1500€+ here in germany, so i wont do that either, i already skipped the 2080Ti because i dont do 4 digit cards.\n\n3080 20GB TBA, so i guess they come in 2021\n\nIts like Nvidia wants people like me to get big Navi in november instead one of their cards.",
      "Meanwhile theres people still trying to sell a gtx 1080 ti for 700 dollars. I also see people trying to sell their 2080 ti's for more than they actually paid for them. This crap makes no sense.",
      "I think everyones getting a bit caught up in the difference between the Vram on the 90 and the 80. Looking at those specs, there really arent a lot of things that gamers will do to max out the 10GB (potentially in certain circumstances but i would imagine few and far between) Nvidia really cant launch the 3080 with 20GB (10 or 20 is only option at 320 bus i believe) as its just gonna be way too close to the 3090. Looking at the size of the 3090 it seems to me like Nvidia know the performance difference between these two cards isnt actually going to be that great so they shoved the VRAM up massively, stuck a massive cooler on it and threw a load more electricity through it in the hope to justify the price tag. I think the 3080 may surprise people here and will be the better buy, even if i dont agree with the prices of any of them. If it turns out the 10GB isnt enough can probably sell in 2-3 months for a 20GB AIB and lose £50-£100",
      "8GB again for the 70 series.\n\nOn top of that, non-X GDDR6 :/",
      "memory config a bit underwhelming on the 80, 70 :( probably see \"super\" variants next year with more memory perhaps.",
      "It not having GDDR6X memory surprises me the most to be honest.",
      "I can already see \"Should I wait for 20 GB 3080 or buy 3090 now.\" post flooding this sub lol.",
      "The 3080 being sold with 10GB of VRAM, the 3070 with 8GB ***AND*** without GDDR6X memory just makes the divide between the 3070/ 3080 and the 3090 ridiculous.",
      "They're playing us like a damned fiddle.",
      "8gb is plenty for old gen games. Next gen games will use much more VRAM. Can't wait to set my textures settings to medium on a brand new 700-800$ GPU. Awesome.",
      "That or AIBs will have models with 20GB but will probably cost $100-200 more than base model.\n\nEDIT: It will be best to carry some restraint going into the Nvidia announcement. Don't panic buy if you are not happy with the VRAM amount. Wait and see what the AIBs do.",
      "I get the feeling the 20GB variant of the 3080 will cost you 1k at the minimum.",
      "Calling it now, they be gimping that card so they can release a Super Variant with 12GB, 500mhz boost and GDDR6X in about a year down the line.",
      "This 1080 has been a fine investment. I was too late to the cheap Ti party, but this chip will remain usable at 1440p 144Hz for a while yet.",
      "7nm?? Holy did they really bamboozle us again lmaooo",
      "Buy 3090 now, get mad that 20 GB 3080 comes out.",
      "Yea, I usually got 260, 660, etc. 60s. I got a 1070 and liked it. I was hoping for a 3070 but yes, the jump from 3070 to 3080/3090 is almost like a whole gen.",
      "Yup, I don’t think anyone falls for that? I’ve seen 1080tis for €350-400 used now here and meanwhile some try to sell their 1070 for €280 and 1070ti for €350 lmao"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "top",
    "matched_keywords": [
      "3090"
    ],
    "title": "Finished 3090 build.",
    "selftext": "",
    "comments": [
      "My dream is to get to this level of disposable income.",
      "I just budget accordingly for my \"mental health\". This is the result of that.",
      "I suspect that many aspirational Ampere owners wouldn't describe the process of trying to purchase one as good for their mental health, but I'm happy for you!\n\nI really like the non-tech stuff (aside from the awesome screensaver) - the way you have the plants dropping down and sprouting up is really cool.",
      "The nanoleaf's probably cost more than my entire PC",
      "Thanks!\n\n**SPECS:**\n\n* AMD Ryzen 3900XT @ 4.6hz CCX0/1 // 4475 CCX2/3\n* Asus Crosshair VIII Hero\n* ASUS RTX 3090 Strix @ 2100mhz\n* 32GB DDR4 3200hz CL14\n* Corsair 680x\n* Corsair QL120mm x6\n* Corsair RM850x\n* NZXT Kraken Z63\n* LG CX 48\" OLED\n* HiFiman Sundara\n* JDS Labs Element II\n* Logitech G Pro Wireless\n* Logitech G915 Keyboard\n* Samsung Galaxy Z Fold 2",
      "I think I got them on sale for $130ish.",
      "Heh, good point!\n\nWhat a mess that was.",
      "Depends how many grams he's sold...",
      "YMMV with that one. For \"competitive games\" like CSGO and League, I can play them without issue, its super immersive. You definitely have to move your eyes quickly to get minimap information on a 48\", but on the same token, I find I can flick to the head easier, since well..the target I'm moving to is much visually larger.\n\n I'm also 33 and not by any means a pro gamer.  I play games for fun. The colors, response time, and sheer size of the LG CX 48\" makes everything feel insanely immersive. The size also allows you to run 100% scaling at 4k and get tons of real-estate without things being illegible to read. \n\nTL;DR - If you're a hardcore competitive LoL/CSGO player, and thats all you do. I'd probably sway you more towards the likes of a Samsung G7. If you're an all around gamer, and still enjoy league and CSGO, LG CX all the way. Once you go OLED, you can't use anything else.",
      "That's a very wide range of money.",
      "Just snagged a 3090, currently stuffed in my uni accommodation self isolating with a county lockdown for my first year of my PhD. That was the final straw to spending so much money.",
      "What a mess that *is*. I'm still waiting on my 3080 1 month after placing an order!",
      "Congrats dude! On both the 3090 and pursuing a PhD, best of luck with both!",
      "Same here, anyone with a middle class income can afford this stuff if they budget. Eating out, alcohol, and or smoking is an easy way to hold you back from all kinds of awesome purchases.",
      "Ahh, a pretty decent price",
      "Radeon 6800xt enters the chat",
      "I can check later, it's from [wallhaven.cc](https://wallhaven.cc)\n\n&#x200B;\n\nI usually just go there, set a parameter for 4k, turn on the weeb filter and type like \"mountain\"",
      "Do you play any multiplayer games with KB+M? Feel like a 48\" screen would be tough to play on for something like League of Legends.",
      ">Eating out, alcohol, and or smoking\n\nwhoa man, we live in a society.",
      "Will do, I actually ordered and cancelled the CX 3 times (no joke).\n\nFinally decided to try it for myself and pull the trigger. After 10minutes on my desk, I 130% made the right decision."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "top",
    "matched_keywords": [
      "3090"
    ],
    "title": "Size comparison of the 3090 TUF vs 4090 TUF",
    "selftext": "",
    "comments": [
      "What in the.",
      "Funniest part being: PCB shorter on the 4090!",
      "That literally would not fit in my case",
      "It better with that hockey rink cooler.",
      "It makes the 3090 look *small*. And the TUF 3090 is definitely not small.",
      "I mean yes, but also you’re looking at the enthusiast top-of-the-line here.\n  \nIt’s like complaining a Lamborghini gets poor gas mileage and is too low to the ground to have an optimal experience at a McDonalds drive through window.\n  \nThe purpose of these cards is uncompromising performance first, everything else second.",
      "Couple more years and GPUs will be integrated into a PC case, then you just put and plug all other components into it.",
      "now do one comparing it to a 1080TI... cries in to my SFF case",
      "Perfect for water-cooling.",
      "You vs the guy she tells you not to worry about",
      "I feel like we should maybe slow down on making things more powerful and maybe start making things more efficient. These cards are ever increasing in size and power draw, eventually most people won’t even be able to use them. Perhaps we should try to make them smaller and more efficient so that they can, I don’t know, be usable by most people?",
      "That is literally longer than my case",
      "But now my room is 60C.",
      "The case IS the heatsink.",
      "Wow, this is just ridiculous now. I thought we were actually going to start seeing some smaller cards after seeing the 30 series FE cards naked. And now this comes along....No thanks - wonder how big the actual PCB is relatively small so if you end up water cooling it not an issue. Wonder if the hyrid cards will share this gloated size or not.",
      "Premium cooling solution on a premium card just to fit it into a regular ATX case",
      "So even if I wanted to buy one I wouldn't be able to fit it in my case :|",
      "But you can vertically mount your house on it. Think outside the box.",
      "I was surprised to see that my EVGA 1080 was almost as big as my Asus 3080.",
      "That is a brilliant analogy 👏 👌"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "top",
    "matched_keywords": [
      "3090"
    ],
    "title": "Upgraded after 10+ years, PC was ready for 5090 but to avoid fire hazard, got an used 3090 instead!",
    "selftext": "",
    "comments": [
      "Evga 3090 with red lips is time ticking bomb. Check if your is rev 0.1. Ton of problems with those cards. You can check forums. Evga replaced those cards for free to rev 1.0. Hope your work just fine.\n\nhttps://youtu.be/2atYJ1laG0s?feature=shared",
      "Better for your wallet too",
      "Is that an EVGA card? Approved!",
      "It is! An \"EVGA XC3 GAMING GeForce RTX 3090\".",
      "Going with a used 3090 instead of the 5090 you wanted because it is less of a fire hazard is a very terminally online take.",
      "That’s literally 2x times less performance than the 5090.\n\nI hope you where aiming for the 5090 because you where just upgrading for the best available without actually needing it, and not because you actually needed it for your gaming situation (4k heavy raytracing gaming for example) and because of no availability you decided well let’s get the next best thing I can find, because brother, there are like 6 GPUs in between a 3090 and a 5090 if not more, 2 absolutely different and incomparable performance tiers.\n\nEdit: don’t get me wrong, the 3090 is a great card.\nBut it’s almost on par with a 4070 super.\n\nIf that suits your needs, great, you just saved a lot of money on unnecessary extra performance.",
      "Thanks, but it's not an FTW3 card but an XC3 (revision A1), or does this version have a problem as well?",
      "red lips always lie",
      "Except that 3090 prices have almost doubled in the last year.",
      "brave of you to assume EVGA realistically exists.",
      "for fucks sake this is how I find out 5yr later",
      "RIP EVGA gpu department, gone but never forgotten",
      "But they're... so alluring... *smooch*",
      "[Performance wise? i mean its only a handful of % off. 30 series to 40 series was a considerable jump.](https://www.techpowerup.com/gpu-specs/geforce-rtx-4070-super.c4186)",
      "I would have chosen a used 4080, Ampere cards are locked out of new features like framegen. And the new dlss transformer model performs significantly worse on them too in some scenarios.",
      "This makes no sense whatsoever. 3090/3090 Ti have heat issues and massive power spikes. The performance per Watt is not good. This particular card can pull over 500W, with transient spikes close to or even over 600W. Unfortunately, TechPowerUp doesn't have the transient spikes chart for this card, but I remember reading about it.\n\nGamersNexus test: \n\nhttps://youtu.be/wnRyyCsuHFQ?si=eF3LiIPXlDq6h-6d&t=996\n\nTPU source:\n\nhttps://www.techpowerup.com/review/evga-geforce-rtx-3090-ftw3-ultra/29.html\n\nTPU source:\n\nhttps://www.techpowerup.com/review/evga-geforce-rtx-3090-ftw3-ultra/33.html\n\nAlso, if you had the money for a 5090, why wouldn't you just buy a 4080 Super or a used 4090, then. None of it makes any sense.",
      "Used 4080s going for $900+",
      "They are 5% away on raw perro with the 4070 super even being faster in some titles, what’s so wild about the claim?\n\nDo some fact checking before spouting nonsense",
      "I dont know about XC3. I suggest you to dig up evga forum. I know these cards just died in HALO and New World game. Later in diablo 4.",
      "It is 100% a design flaw, the connector has no way to load/current balance. While 8 pin connectors were split between each connector, ONLY the 3090 has the 12 pin split into 3 separate groups on the board. This means if any one group of 3 starts drawing excess current, the card can shut down immediately. Since the 4090, the entire 12 pin connector goes directly through only one feedback resistor. This means technically, 5 out of 6 12V wires could be separated, and the card would request 600W as normal through ONE 18 gauge wire. \n\nThis is on top of the fact that the 12V-2x6 connector only has a 10% safety margin (600W nominal 660W peak) vs a 90% safety margin (150W vs [288W](https://help.corsair.com/hc/en-us/articles/10700487373197-PSU-How-to-Avoid-Current-Overload-Connector-Issues)) with the PCIe 8 pin connector.\n\nIt is 100% a design flaw, and there are multiple videos on the topic that dive into more depth than I do."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "top",
    "matched_keywords": [
      "3090"
    ],
    "title": "Best Buy cancels my 3090 order from Jan 22nd from lack of stock... 12 hours after a restock",
    "selftext": "",
    "comments": [
      "It found out you are not a bot and canceled the transaction.  This is being seen more and more.",
      "They have a policy where they cancel backorders if they can't fulfill them in 2 weeks, but they had multiple opportunities to fulfill it and it shouldn't have been considered a backorder because i made the order when it was in-stock.",
      "It’s now somewhere in China mining crypto.",
      "Fucking disgusting.",
      "Hey we don't know that.\n\nIt could be in any country mining crypto.",
      "This is not good",
      "Amazon canceled our order from bacm in December 7 last month",
      "Join the club. BB has cancelled 2x 3080s and a ps5 order due to over selling stock.\n\nLuckily I was able to buy a 3080 elsewhere, but I'm still hunting for a ps5\n\nEdit - here's proof https://imgur.com/7D6NHBQ",
      "It's a combo of covid and also raw material shortages. Even the auto industry is dealing with this.  \n\nNow factor in Chinese new year and everything being closed for weeks and it is going to get a lot worse before it gets better.",
      "This is the bit I don't get. Why is nobody offering queues?\n\nI'm British for fuck's sake, stop making me chase disappearing order buttons and just let me get in a fucking queue.",
      "Canada has patience",
      "Seems like placing an order on a gpu is just entering a lottery in this stage of the shortages.",
      "Goodbye little soldier, he in China now",
      "I feel like that 2 week thing should be a question asked to the purchaser. If someone is willing to wait more than 2 weeks and the product is still being produced in a factory somewhere it should be full filled if the customer is cool with waiting.",
      "Damn this is sad honestly, I planned my first pc build and have all my parts ready except the gpu. I chose the worst year to build a pc",
      "This is good for bitcoin",
      "Can confirm",
      "Was it always this hard to get gpus? Or is it hard now cauce COVID?",
      "It's a meme about everything good and bad happening in the world is good for bitcoin.",
      "*Ethereum, bitcoin is mostly mined with asic's these days."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "top",
    "matched_keywords": [
      "3090"
    ],
    "title": "3090 vs 1080ti",
    "selftext": "",
    "comments": [
      "Those poor pcie slots",
      "6 foot vs 5'11",
      "Funniest thing I seen in awhile.\n\nGives new meaning to **BangBus**.  \n\n\n**EDIT**: Thank you for Gold! First time I ever got gold. You popped my **Gold**en Cherry.",
      "That is not going to fit in my case",
      "reference 1080 ti for reference",
      "you vs the guy she told you not to worry about",
      "Nothing a dremel can't fix",
      "Nothing a dremel can't fix",
      "That's a big girthy bastard",
      "And the actual board isn't much bigger than a 1080ti. The size increase is purely from the cooler.",
      "Step one. Buy a 3D printer.\nStep two, download a Goku spirit bomb model.\nStep 3, scale to perfectly hold up your mighty beast of a GPU.\nStep 4, drown in pussy.",
      "They don't call it \"reference\" for nothing",
      "Thicc Boi.\n\nwhich is one reason why 3090 FE is kinda unusable for most cases (that, and the bad power cable placement). Happy that some AIB manufacturers have kept the designs more sane.",
      "Since the weight is now distributed over 3 brackets with the pcie bracket screwed into three retention holes, but it doesn't weigh 3 times as much as a single slot card it potentially puts less strain.",
      "Lolmygod",
      "Take my upvote and beat it.",
      "Its about time they stopped focusing on form factor and started focusing on raw power",
      "You did this wrong. Step 3 is always Profit",
      "Vertical mounting won't work well with this cooling design.",
      "Just like that new song on the radio says, WAP?  (Wet Ass Pcie) by RTX Card-EB?\n\n\"I want you to park that big 3090.  Right in this little slot!\""
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "top",
    "matched_keywords": [
      "3090",
      "rtx 3090"
    ],
    "title": "GeForce RTX 5090 Review Megathread",
    "selftext": "# GeForce RTX 5090 Founders Edition reviews are up.\n\nhttps://preview.redd.it/3568lwrnwqee1.jpg?width=3840&format=pjpg&auto=webp&s=30ca4f255f94899838a70ab1168949437d3e03fd\n\n# Below is the compilation of all the reviews that have been posted so far. I will be updating this continuously throughout the day with the conclusion of each publications and any new review links. This will be sorted alphabetically.\n\n# Written Articles\n\n# [Babeltechreviews](https://babeltechreviews.com/nvidia-geforce-rtx-5090-founders-edition-review/)\n\n>For the Blackwell RTX 50 series launch, NVIDIA strategically chose to introduce their flagship model first, launching the GeForce RTX 5090 ahead of other models to set a high benchmark in performance. Following this release, other models like the RTX 5080 and RTX 5070 are set to be launched, all of which we assume will also be impressive with DLSS 4 and their new design. The RTX 5090 remains the pinnacle in terms of raw power and capabilities and is in a class of its own, alongside its high price tag.\n\n>The NVIDIA GeForce RTX 5090 Founders Edition’s powerful performance make it an essential upgrade for enthusiasts and professionals aiming to push the limits of what’s possible in their digital environments. Purists will not enjoy DLSS 4 and will want a much larger raw performance jump, but for those that do the performance uplift will make you drop your jaw just like it did to ours. We remember titles like Hogwarts Legacy having performance issues at launch and with DLSS 4 enabled we saw incredibly high gains of 301.6 AI generated FPS performance difference over its raw power. Nothing can replace proper optimization but expanding the capabilities of a game to perform in such large amounts is amazing.\n\n# [Digital Foundry Article](https://www.eurogamer.net/digitalfoundry-2025-nvidia-geforce-rtx-5090-review)\n\n# [Digital Foundry Video](https://www.youtube.com/watch?v=Dk3fECI-fmw)\n\n>Going into this review, it was clear that there was some trepidation that the RTX 5090 wouldn't offer enough of a performance advantage over its predecessor when it comes to raw frame-rates, ie without the multi frame generation tech that Nvidia leaned heavily on in its pre-release marketing. These are justifiable concerns - after all, there's no die shrink to accompany this generation of processors, and pushing more power can only get you so far.\n\n>Thankfully - for those that want to justify upgrading to a $2000+ graphics card - the beefier design and faster GDDR7 memory do deliver sizeable gains over the outgoing 4090 flagship, measured at around 31 percent on average at 4K. The differentials are understandably smaller when you look at lower resolutions - just 17 percent at 1080p, though anyone considering the 5090 is probably unlikely to be rocking a 1080p display. Nvidia, Intel, AMD and Sony have all spoken about the slowing progress in terms of silicon price to performance, and we can see why all four companies are now [looking to machine learning](https://www.eurogamer.net/digitalfoundry-2024-sony-ps5-pro-tech-interview-with-mark-cerny-and-mike-fitzgerald) technologies to shore up generational advancements.\n\n>Speaking of which, DLSS 4's multi frame generation is an effective tool for pushing frame-rates - though arguably not *performance* to higher levels. On the RTX 5090, it's best used along similarly high-end 4K 144Hz+ monitors, so it's no surprise that Nvidia and its partners ensured that reviewers had access to 4K 240Hz screens for their testing. If you're lucky enough to be in that situation, you can use MFG to essentially max out your monitor's refresh rate, with a choice of 1x, 2x or 3x frame generation.\n\n>There's of course a trade-off in terms of latency, but it's smaller than you might think - and once you've already enabled frame generation, knocking it up an extra level has only a small impact on thos latency figures. For example, in [Cyberpunk 2077](https://www.eurogamer.net/games/cyberpunk-2077) with RT Overdrive (path tracing), we saw frame-rates go with 94.5fps with DLSS upscaling to 286fps when adding 4x multi frame generation, a \\~3x multiplier at the cost of \\~9ms of added latency (26ms vs 35ms). If you have a 4K 240Hz monitor, that might be a trade worth taking - and of course, you're more than free to ignore frame generation and knock back other settings instead to get performance to a level you're happy with.\n\n# [Guru3D](https://www.guru3d.com/review/review-nvidia-geforce-rtx-5090-reference-edition/)\n\n>The RTX 5090 features an advanced rendering engine that pushes past previous limits with the help of its  21,760 CUDA cores. This means smoother and faster gameplay with more realistic environments, creating an immersive experience. The RTX 50 series introduced a new generation of Ray tracing and Tensor cores. These aren’t just numbers on a spec sheet – they represent a leap in efficiency and power. Located close to the shader engine, these cores work tirelessly to deliver distinctive outputs. Even though Tensor cores can be tricky to measure, their impact is unmistakable, especially when paired with DLSS3.5 and new DLSS4 with MFG  technology that delivers impressive results. The GeForce RTX 5090 is not just an enthusiast-class card; it's a versatile powerhouse. Whether playing games at 2K (2560x1440) or better yet, game at 4K (3840x2160), it offers superlative performance at every resolution. This makes it an outstanding choice for gamers who seek both quality and speed, transporting them into new realms of interactive entertainment\n\n>Depending on the game title this value can greatly differ! However, on average you're looking at 25% maybe 30% more traditional rendering performance. The thing is though, NVIDIA has invested a lot of the transistor budget into AI, Deeplearning and Neural shading. We've presented the numbers with DLSS4 and when you enable frame generation mode at 4x, the performance is astounding. The reality is that we are reaching physical limits where traditional methods of increasing performance are becoming harder than ever. Chips would have to grow even larger, power consumption would skyrocket, and costs would soar. Imagine a future where every attempt to push technology further leads to larger, more power-hungry chips that become increasingly expensive. As we encounter these boundaries, think creatively and seek new solutions. Instead of following a path that leads to dead ends, this challenge invites us to innovate and discover groundbreaking ideas such as DLSS4 and MFG.\n\n>If you factor out pricing and energy consumption, it's gonna be hard to not be impressed with the GeForce RTX 5090. The card drips and oozes performance and it all packs into a two-slot form factor. On the traditional shader rasterizer part, it's still a good notch faster than RTX 4090, however, if you are savvy with technologies like DLSS4 offers, the sky is the limit. We do hope to see more backwards compatibility with DLSS 4 so that older games will get this new tech included as well. DLSS4 is not perfect though, yes butter smooth, but in Alan Wake 2 for example the scene rendered was fantastic but we; see birds flying over in the sky leaving a weird hale trail. The scene was otherwise very nice though.  The Blackwell GPU architecture of the 5090 demonstrates proficient performance. It boasts about 1.25 to sometimes 1.50 times the raw shader performance compared to its predecessor, along with enhanced Raytracing and Tensor core capabilities.\n\n# [Hot Hardware](https://hothardware.com/reviews/nvidia-geforce-rtx-5090-review)\n\n>NVIDIA's GeForce RTX 5090 is the fastest, most powerful, and feature-rich consumer GPU in the world as of today, period. There’s no other way to put it. The NVIDIA GeForce RTX 5090 Founders Edition card itself is also a refined piece of hardware. To design a card that offers significantly more performance than an RTX 4090, at much higher power levels, in a roughly 33% smaller form factor is no small feat of engineering. The card also looks great in our opinion. On its own, the GeForce RTX 5090 is currently unmatched in the consumer GPU market – nothing can touch it in terms of performance, with virtually any workload – AI, content creation, gaming, you name it.\n\n>It's not all sunshine and rainbows, though. In many cases, the GeForce RTX 5090 offered nearly double the performance of its predecessor (RTX 3090) when it debuted, at lower power, while using the exact same settings and workloads. If you compare the GeForce RTX 5090 to the RTX 4090 at like settings, however, the RTX 5090 is “only” about 25% - 40% faster and consumes more power. The RTX 5090’s $1,999 MSRP is also significantly higher than the 4090’s $1,599 price tag. Considering the Ada and [Blackwell GPUs](https://hothardware.com/reviews/nvidia-rtx-blackwell-architecture-overview) at play here are manufactured on the same TSMC process node, NVIDIA was still able to move the needle considerably, but the GeForce RTX 5090 doesn’t represent the same kind of monumental leap the RTX 4090 did when it launched, if you disregard its new rendering technologies at least.\n\n>You can’t disregard those new capabilities, though. Neural Rendering, DLSS 4 with multi-frame generation, the updated media engine, and all that additional memory and memory bandwidth all have to be taken into consideration. When playing a game that can leverage Blackwell’s new features, the GeForce RTX 5090 can indeed be more than twice as fast as [the RTX 4090](https://hothardware.com/reviews/nvidia-geforce-rtx-4090-gpu-review).\n\n>The use of frame generation has spurred much discussion since its introduction, and we understand the concerns regarding input latency and potential visual artifacts that come from using frame-gen. But the fact remains, using AI and machine learning to boost game and graphics performance in the most effective and efficient way forward at this time. Moving to more advanced manufacturing process nodes doesn’t offer the kind of power, performance and area benefits it once did, so boosting performance must ultimately come mostly from architectural and feature updates. And everyone in the PC graphics game is turning to AI. We specifically asked about the importance of traditional rasterization moving forward and were told development is still happening, and it will remain necessary for “ground truth” rendering to train the models, but ultimately AI will be generating more and more frames in the future.\n\n# [Igor's Lab](https://www.igorslab.de/en/nvidia-geforce-rtx-5090-founders-edition-review-the-600-watt-powerhouse-in-gaming-and-lab-tests/)\n\n>The GeForce RTX 5090 delivered impressive results in practical tests. The card achieved significantly higher frame rates in Full HD, WQHD and Ultra HD compared to the RTX 4090, especially with DLSS and ray tracing support enabled. The multi-frame generation enables consistent frame pacing and reduces noticeable latency, which is particularly beneficial in fast and dynamic gaming scenarios. The improvements in patch tracing and ray tracing ensure a more realistic representation of complex scenes. Games such as Cyberpunk 2077 and Alan Wake 2 visibly benefit from the technological advances and show that the Blackwell architecture has the potential to smoothly display the most demanding graphic effects.\n\n>The image quality achieved by the Transformer models in DLSS 4 is another important aspect. Where previously a clear trade-off had to be made between performance and quality, DLSS 4 combines both in an impressive way. Most notably, the new Performance setting offers almost the same visual quality as previous Quality modes. This is achieved through advanced AI-powered models that capture both local details and global relationships to produce a near-native image representation. The smooth and detailed rendering at significantly higher frame rates shows that DLSS 4 is an essential part of the RTX 5090, further underlining its performance. There will be a detailed practical test on this from our monitor professional Fritz Hunter.\n\n>In my opinion, the GeForce RTX 5090 is an impressive graphics card that shows just how far GPU technology has come. The new features in particular, such as DLSS 4 and Transformer-supported image optimization, set new standards. The performance of this card is simply breathtaking, be it in games in Ultra HD with active patch tracing or in demanding AI-supported applications. It is remarkable how NVIDIA has managed to find the balance between graphical excellence and innovative technologies. Another outstanding aspect is the ability of DLSS 4 to achieve an image quality that is almost indistinguishable from native resolutions, while at the same time increasing performance. The change from “Quality” to “Performance” as a standard option is like a revolution in the way we perceive image enhancement. The smooth display, combined with an incredible level of detail, takes the gaming experience to a new level.\n\n# [KitGuru Article](https://www.kitguru.net/components/graphic-cards/dominic-moass/nvidia-rtx-5090-review-ray-tracing-dlss-4-and-raw-power-explored/)\n\n# [KitGuru Video](https://www.youtube.com/watch?v=8wEXrZSnsRM)\n\n>Much was made of the performance ahead of launch, people were breaking out rulers and [pixel counting Nvidia's bar charts](https://www.reddit.com/r/nvidia/comments/1hvvrqj/50_vs_40_series_nvidia_benchmark_exact_numbers/), but after thorough testing today we can confirm native rendering performance has increased in the ballpark of 30% over the RTX 4090 when testing at 4K. That makes the RTX 5090 64% faster on average compared to AMD's current consumer flagship, the RX 7900 XTX, while it's also a 71% uplift over the RTX 4080 Super. Ray tracing also scales similarly, given we saw the exact same 29% margin over the RTX 4090 in the eight RT titles we tested.\n\n>Those are the sort of performance increases you can expect at 4K, but the uplift does get progressively smaller as resolution decreases. Versus the RTX 4090, for instance, we saw smaller gains of 22% at 1440p and 18% at 1080p. Now, I don't expect many people will be gaming at native 1080p on an RTX 5090, but it's worth bearing that in mind if you'd typically game with DLSS Super Resolution. After all, using its performance mode at 4K utilises a 1080p internal render resolution. Clearly this is a card designed for 4K – and perhaps even above – but that performance scaling at lower resolutions could be something to bear in mind.\n\n>Of course, whether or not you are impressed by those generational gains depends entirely on your perspective – an extra 30% over the 4090 could sound great, or it could be a disappointment. The main thing from my perspective as a reviewer is to give you, the reader, as much information as possible to allow you to make an informed decision, and I think I have done that today.\n\n>Gamers do get the extra value add of DLSS 4, specifically Multi Frame Generation (MFG), which is a new feature exclusive to the RTX 50-series. I spent a fair bit of time testing MFG as part of this review and I think if you already got on with Frame Generation on the RX 40-series, you'll probably find a lot to like with MFG. It's been particularly useful in enabling 4K/240Hz gaming experiences that wouldn't otherwise be possible – such as high frame rate path tracing in Cyberpunk 2077 – and with the growing [4K OLED monitor segment](https://www.kitguru.net/components/matthew-wilson/ces-2025-leo-gets-a-closer-look-at-new-msi-oled-monitors-dual-system-case-and-more/), that's certainly good news.\n\n>However, it's definitely not a perfect technology as the discerning gamer will still notice some fizzling or shimmering that isn't otherwise there, while latency scaling is still backwards compared to what we've come to expect – in the sense that latency actually *increases* as frame rate increases with MFG, rather than latency decreasing. That means some will find it problematic as the *feel* doesn't always match up to the visual fluidity of the increased frame rate.\n\n>It is great to see Nvidia is improving other aspects of DLSS, though, with its new Transformer-based models of Super Resolution and Ray Reconstruction. Not only do these improve things like ghosting and overall level of detail compared to the previous Convolutional Neural Network (CNN) model, but this upgrade actually applies to *all* RTX GPUs, right the way back to the 20-series. There's even a possibility that Multi Frame Gen [might come to older cards](https://www.kitguru.net/gaming/joao-silva/nvidia-multi-frame-generation-could-come-to-rtx-30-series-gpus/) given that Nvidia hasn't explicitly ruled it out, but personally I'd be surprised to see that happen given it currently acts as an incentive to upgrade to the latest and greatest.\n\n>We can't end this review without a discussion of Nvidia's Founders Edition design, either. This is a *highly* impressive feat of engineering, considering it's a mere dual-slot thickness yet it is able to comfortably tame 575W of power. We saw the GPU settling at 72C during a thirty-minute 4K stress test, while the VRAM hit 88C, which is slightly warmer but still well within safe limits. I love to see the innovation in this department, as when pretty much every AIB partner is slapping quad-slot coolers onto their 5090s, this is a refreshing step back to a time when GPUs didn't cover the entire bottom-half of your motherboard.\n\n# [LanOC](https://lanoc.org/review/video-cards/9132-nvidia-rtx-5090-founders-edition)\n\n>Performance for the new generation of cards in my testing had the RTX 5090 outperforming the RTX 4090 by around 32% which is right in line with the increase in CUDA cores for the card. There were some tests which saw an even bigger increase and the RTX 5090 was at the top of the chart across the board in every applicable test. What was even more impressive to me was the improvements with DLSS 4, the performance difference that it can make is sometimes shocking, but on top of that Nvidia has improved the smoothness and picture quality. At the end of the day, there wasn’t anything that I threw at the RTX 5090 that slowed it down, but if you do run into something that it can’t handle DLSS 4 is going to fix you right up. I did see some bugs in my DLSS testing, mostly when trying down resolutions, but I suspect some of those will be smoothed out once the updates are released. The biggest issue I ran into performance-wise was that a few of our benchmarks just wouldn’t run at all and they were all OpenCL. Nvidia is aware and is working to get support for those tests.\n\n>The big increase in performance without any change in manufacturing size does have the RTX 5090 having a significantly higher power consumption. I saw it pulling up to 648 watts at peak, combine that with today's highest-end CPUs and we are swinging back to needing high-wattage power supplies. Speaking of power, the power connection has been improved in a whole list of ways including moving from the original 12VHPWR connection to the changed design that is called 12V-2-6. It looks the same and all of the power supplies will still connect. But they have changed the pin heights to get a better connection and the sense pins are shorter and are more likely to catch when the plug isn’t connected all the way. On top of that Nvidia’s card design has recessed the connection down into the card and angled it to reduce any strain on the connection. They have also included a much nicer power adapter as well. All of that power does mean there is more heat but the double blow-through design handled it surprisingly well running similarly in temperatures to the RTX 4090 Founders Edition even with a thinner card design and a lot more wattage going through.\n\n# [OC3D Article](https://overclock3d.net/reviews/gpu_displays/nvidia-rtx-5090-founders-edition-review/)\n\n# [OC3D Video](https://www.youtube.com/watch?v=4oDxME5APa8)\n\n>Speaking of DLSS 4, that comes with the big ticket item in the Blackwell release, Multi Frame Generation. By refining the algorithm, and giving the card newer generations of hardware, the RTX 5090 can now generate three extra frames from a single frame rendered. As you could see from our results in Alan Wake II, Cyberpunk 2077 and Star Wars Outlaws, the effect is considerable. Cyberpunk 2077, with an open world, neon soaked, usually wet and thus reflective environment is about as good as games can look. Turn on path-tracing and it’s nearly real life. That path-tracing has a massive performance cost though. On the RTX 4090 you get 133 FPS @ 4K without it, 40 FPS with it.\n\n>Even turning DLSS and Frame Gen on doesn’t recoup all that, maxing out at 104. Click through the Multi Frame Gen settings on the RTX 5090 though and that number hits 241 FPS. With, and we cannot state this enough, NO loss in visual fidelity. That’s Cyberpunk at 4K with pathed ray-tracing turned on and a frame rate you’d require a very expensive monitor (4K@240Hz!) to appreciate fully. When CD Projekt Red’s Magnum Opus first appeared you could get smoother frame rates from a flipbook.\n\n>All of which returns us to the way we’ve tested how we have. Because in regular mode, with DLSS turned on and, at most, a single frame generated as is currently the way, the RTX 5090 is another big step forwards on the best of the current cards. Anything which can stomp on a RTX 4090 is crazy good. That the RTX 5090 Founders Edition can do that, and then has much further to go with the benefits of MFG, makes any claims about it being a purely software-based improvement look as ill-informed as they do.\n\n>Already that’s more than enough to make the Nvidia RTX 5090 Founders Edition a Day One recommendation to anyone serious about their gaming. We haven’t even mentioned the crazy low latencies – and thus higher KD ratio – of the upgraded Reflex 2 technology. Or RTX Neural Faces that can convert a 2D picture into a 3D character. We’ve not discussed, because it’s embryonic, the potential of the AI powered NPCs with the Nvidia Ace technology. Or the extra broadcast features, faster encoding and decoding, and all the AI calculation benefits having this much power at your disposal can bring.\n\n>Simply put, the Nvidia RTX 5090 has coalesced all the current thinking on AI, performance, sharpness, and generative content into a single card that blows the doors off anything on the market. It’s the future, today.\n\n# [PC Perspective](https://pcper.com/2025/01/nvidia-geforce-rtx-5090-founders-edition-review/)\n\n>Well, NVIDIA has topped NVIDIA. Once again, and with zero competition at the high end, GeForce reigns supreme. And while raster performance has risen, DLSS 4 is the star of the show with the RTX 50 Series, now supporting up to ***four*** generated frames per rendered frame (!) if you dare. Yes, the price for NVIDIA’s flagship has risen again, from $1599 to $1999 this generation, but those who want the fastest graphics card in the world will surely buy it anyway.\n\n# [PC World Article](https://www.pcworld.com/article/2585806/nvidia-geforce-rtx-5090-review.html)\n\n# [PC World Video](https://www.youtube.com/watch?v=_J5wDq2ba2E)\n\n>The GeForce RTX 4090 stood unopposed as the ultimate gaming GPU since the moment it launched. No longer. The new Blackwell generation uses the same underlying TSMC 4N process technology as the RTX 40-series, so Nvidia couldn’t squeeze easy improvements there. Instead, the company overhauled the RTX 5090’s instruction pipeline, endowed it with 33 percent more CUDA cores, and pushed it to a staggering 575W TGP, up from the 4090’s 450W. Blackwell also introduced a new generation of RT and AI cores.\n\n>Add it all up and the RTX 5090 is an unparalleled gaming beast — though the effects hit different depending on whether or not you’re using RTX features like ray tracing and DLSS.\n\n>In games that *don’t* use ray tracing or DLSS, simply brute force graphics rendering, the RTX 5090 isn’t much more than a mild generational performance upgrade. It runs an average of 27 percent faster in those games — but the splits swing wildly depending on the game: *Cyberpunk 2077* is 50 percent faster, *Shadow of the Tomb Raider* is 32 percent faster, and *Rainbox Six Siege* is 28 percent faster, but *Assassin’s Creed Valhalla* and *Call of Duty: Black Ops 6* only pick up 15 and 12 percent more performance, respectively.\n\n>Much like DLSS, DLSS 2, and DLSS 3 before it, the [new DLSS 4 generation](https://go.skimresources.com/?id=111346X1569483&xs=1&url=https://www.nvidia.com/en-us/geforce/news/dlss4-multi-frame-generation-ai-innovations/&xcust=2-1-2585806-1-0-0-0-0&sref=https://www.pcworld.com/article/2585806/nvidia-geforce-rtx-5090-review.html) is an absolute game-changer. Nvidia’s boundary-pushing AI tech continues to look better, run faster, and now *feel* smoother. It’s insane.\n\n>Nvidia made two monumental changes to DLSS to coincide with the RTX 50-series release. First, all DLSS games will be switching to a new “Transformer” model from the older “Convolutional Neural Network” behind the scenes, on all RTX GPUs going back to the 20-series.\n\n>More crucially for the RTX 5090 (and future 50-series offerings), DLSS 4 adds a new Multi Frame Generation technology, building upon the success of [DLSS 3 Frame Gen](https://www.pcworld.com/article/1662185/what-is-dlss-3-nvidia-geforce-rtx-ai-feature-explained.html). While DLSS 3 uses tensor cores to insert a single AI-generated frame between GPU-rendered frames, supercharging performance, MFG inserts *three* AI frames between each GPU-rendered frame (which itself may only be rendering an image at quarter resolution, then using DLSS Super Resolution to upscale that to fit your screen).\n\n>Bottom line: DLSS 4 is a stunning upgrade you *must* play around with to fully appreciate its benefits. It’s literally a game-changer, once again — though we’ll have to see if it feels *this* sublime on lower-end Nvidia cards like the more affordable RTX 5070.\n\n>In a vacuum, the RTX 5090 delivers around a 30 percent average boost in gaming performance over the RTX 4090. That’s a solid generational improvement, but one we’ve seen throughout history delivered at the same price point as the older, slower outgoing hardware. Nvidia asking for an extra $500 on top seems garish and overblown from that perspective.\n\n>While I wouldn’t recommend upgrading to this over the RTX 4090 for gaming (unless you’re giddy to try DLSS 4), it’s a definite upgrade option for the RTX 3090 and anything older. The 4090 was 55 to 83 percent faster than the 3090 in games, and the 5090 is about 30 percent faster than *that*, with gobs more memory.\n\n>At the end of the day, nobody needs a $2,000 graphics card to play games. But if you *want* one and don’t mind the sticker price, this is easily the most powerful, capable graphics card ever released. The GeForce RTX 5090 is a performance monster supercharged by DLSS 4’s see-it-to-believe it magic.\n\n# [Puget Systems (Content Creation Review)](https://www.pugetsystems.com/labs/articles/nvidia-geforce-rtx-5090-content-creation-review/)\n\n>Overall, the RTX 5090 is a beast of a card. Drawing 575 W, with 32 GB VRAM and a $2000 price tag (at least), it is overkill for many use cases. However, it excels at GPU-heavy workloads like rendering and provides solid performance improvements over the last-gen 4090 in many applications. There are some issues with software compatibility that need to be worked out, but historically, NVIDIA has been great about ensuring its products are properly supported throughout the software ecosystem.\n\n>For **video editing and motion graphics**, the RTX 5090 performs well, with 10-20% improvements across the board. In particular sub-tests, where the workload is primarily GPU bound, we see up to 35% performance advantages over the previous-generation 4090. However, the area we are most excited about is actually the enhanced codec support for the NVENC/NVDEC engines. In DaVinci Resolve, the H.265 4:2:2 10-bit processing was more than twice as fast as software decoding and exceeded even what we see from Intel Quick Sync. Even if the 5090 is more than a workload requires, we are excited to see what this means for upcoming 50-series cards.\n\n>In **rendering applications**, real-time and offline, the 5090 pushes its lead over previous-generation cards even further. It is 17% faster than the 4090 in our Unreal Engine benchmark while also offering more VRAM for heavy scenes. Offline renderers, such as V-Ray and Blender, score 38% and 35% higher than 4090, respectively. This more than justifies the $2,000 MSRP, especially factoring in the added VRAM. The lack of support for some of our normally-tested rendering engines is non-ideal, but we are hopeful NVIDIA will address that issue shortly.\n\n>NVIDIA’s new GeForce RTX 5090 is a monster of a GPU, delivering best-in-class performance alongside a rich feature set. However, it comes along with a huge price tag of $2,000 MSRP; ad likely higher for most buyers, as AIB cards will be a good bit more expensive than that. It also requires that your computer can support that much power draw and heat. If you need the most powerful consumer GPU ever made, this is it. Otherwise, we are excited by what this promises for the rest of the 50-series of GPUs and look forward to testing those in the near future.\n\n# [Techpowerup](https://www.techpowerup.com/review/nvidia-geforce-rtx-5090-founders-edition/)\n\n>At 4K resolution, with pure rasterization, without ray tracing or DLSS, we measured a 35% performance uplift over the RTX 4090. While this is certainly impressive, it is considerably less than what we got from RTX 3090 Ti to RTX 4090 (+51%). NVIDIA still achieves their \"twice the performance every second generation\" rule: the RTX 5090 is twice as fast as the RTX 3090 Ti. There really isn't much on the market that RTX 5090 can be compared to, it's 75% faster than AMD's flagship the RX 7900 XTX. AMD has confirmed that they are not going for high-end with RDNA 4, and it's expected that the RX 9070 Series will end up somewhere between RX 7900 XT and RX 7900 GRE. This means that RTX 5090 is at least twice as fast as AMD's fastest next-generation card. Compared to the second-fastest Ada card, the RTX 4080 Super, the performance increase is 72%--wow!\n\n>There really is no question, RTX 5090 is the card you want for 4K gaming at maximum settings with all RT eye candy enabled. I guess you could run the card at 1440p at insanely high FPS, but considering that DLSS 4 will give you those FPS even at 4K, the only reason why you would want to do that is if you really want the lowest latency with the highest FPS.\n\n>Want lower latency? Then turn on DLSS 4 Upscaling, which lowers the render resolution and scales up the native frame. In the past there were a lot of debates where DLSS upscaling image quality is good enough, some people even claimed \"better than native\"--I strongly disagree with that--I'm one of the people who are allergic to DLSS 3 upscaling, even at \"quality.\" With Blackwell, NVIDIA is introducing a \"Transformers\" upscaling model for DLSS, which is a major improvement over the previous \"CNN\" model. I tested Transformers and I'm in love. The image quality is so good, \"Quality\" looks like native, sometimes better. There is no more flickering or low-res smeared out textures on the horizon. Thin wires are crystal clear, even at sub-4K resolution! You really have to see it for yourself to appreciate it, it's almost like magic. The best thing? DLSS Transformers is available not only on GeForce 50, but on all GeForce RTX cards with Tensor Cores! While it comes with a roughly 10% performance hit compared to CNN, I would never go back to CNN. While our press driver was limited to a handful of games with DLSS 4 support, NVIDIA will have around 75 games supporting it on launch, most through NVIDIA App overrides, and many more are individually tested, to ensure best results. NVIDIA is putting extra focus on ensuring that there will be no anti-cheat drama when using the overrides.\n\n# [The FPS Review](https://www.thefpsreview.com/2025/01/23/nvidia-geforce-rtx-5090-founders-edition-video-card-review/)\n\n>There is a lot to unpack in regards to the NVIDIA GeForce RTX 5090, and GeForce RTX 50 series from NVIDIA. A lot of technologies have been debuted, and there are a lot of features to test that we simply cannot do in one single review. In today’s review, we focused on the gameplay performance aspect of the GeForce RTX 5090.\n\n>We focused on the GeForce RTX 5090 performance, so subsequent reviews will focus on the rest of the family, and we’ll have to see how they fit into the overall opinion of the RTX 50 series family this generation. For now, we can look at the GeForce RTX 5090 as the flagship of the RTX 50 series, and what it offers for the gameplay experience at a steep price of $1,999, a 25% price bump over the previous generation GeForce RTX 4090.\n\n>If we look back at the average performance gains we saw in just regular raster performance, we experienced performance that ranged from 19%-48%, but there were a lot of common performance gains in the 30-33% range. We did have some outliers that were lower, and some higher, depending on the game and settings. We generally saw gains in the 30% region with Ray Tracing enabled, where scenarios were more GPU-bound.\n\n>We think one problem that is being encountered is that the NVIDIA GeForce RTX 5090 is becoming CPU-bound in a lot of games. The data tells us that perhaps even our AMD Ryzen 7 9800X3D is holding back the potential of the GeForce RTX 5090. Therefore, as newer, faster CPU generations are released, the GeForce RTX 5090’s performance advantage may increase over time. The GeForce RTX 5090 has powerful specifications, but the performance advantage we are currently seeing seems shy of what should be expected with those specifications. It may very well be the case that it is being held back, and it has more potential with better-optimized games or faster CPUs. Time will tell on that one.\n\n>As it stands right now, you should always buy based on the current level of performance, not what might happen. Therefore, at this time you are seeing about a 33% gameplay performance advantage average, but with a 25% price increase, making the price-to-performance value very narrow. The facts are, that the GeForce RTX 5090 has no competition, it does offer the best gameplay performance you can get on the desktop.\n\n# [Tomshardware](https://www.tomshardware.com/pc-components/gpus/nvidia-geforce-rtx-5090-review)\n\n>The RTX 5090 is a lot like this initial review: It's a bit of a messy situation — a work in progress. We're not done testing, and Nvidia isn't done either. Certain games and apps need updates and/or driver work. Nvidia usually does pretty good with drivers, but new architectures can change requirements in somewhat unexpected ways, and Nvidia needs to continue to work on tuning and optimizing its drivers. We're also sure Nvidia doesn't need us to tell it that.\n\n>Gaming performance is very much about running 4K and maxed out settings. If you only have a 1440p or 1080p display, you're better off saving your pennies and upgrading you monitor — and probably the rest of your PC as well! — before spending a couple grand on a gaming GPU.\n\n>Unless you're also interested in non-gaming applications and tasks, particularly AI workloads. If that's what you're after, the RTX 5090 could be a perfect fit.\n\n>The RTX 5090 is the sort of GPU that every gamer would love to have, but few can actually afford. If we're right and the AI industry starts picking up 5090 cards, prices could end up being even higher. Even if you have the spare change and can find one in stock (next week), it still feels like drivers and software could use a bit more time baking before they're fully ready.\n\n>Due to time constraints, we haven't been able to fully test everything we want to look at with the RTX 5090. We'll be investigating the other areas in the coming days, and we'll update the text, charts, and the score as appropriate. For now, the score stands as it is until our tests are complete.\n\n# [Computerbase - German](https://www.computerbase.de/artikel/grafikkarten/nvidia-geforce-rtx-5090-test.91081/)\n\n# [HardwareLuxx - German](https://www.hardwareluxx.de/index.php/artikel/hardware/grafikkarten/65361-die-geforce-rtx-5090-founders-edition-im-test.html)\n\n# [PCGH - German](https://www.pcgameshardware.de/Geforce-RTX-5090-Grafikkarte-281029/Tests/Reviews-Benchmarks-Vergleich-RTX-4090-1463971/)\n\n# [Elchapuzasinformatico - Spanish](https://elchapuzasinformatico.com/2025/01/nvidia-geforce-rtx-5090-founders-edition-review/)\n\n\\--------------------------------------------\n\n# Video Review\n\n# [Der8auer](https://www.youtube.com/watch?v=La4EdRPT_Mg)\n\n# [Digital Foundry Video](https://www.youtube.com/watch?v=Dk3fECI-fmw)\n\n# [Gamers Nexus Video](https://www.youtube.com/watch?v=VWSlOC_jiLQ)\n\n# [Hardware Canucks](https://www.youtube.com/watch?v=5TJk_P2A0Iw)\n\n# [Hardware Unboxed](https://www.youtube.com/watch?v=eA5lFiP3mrs)\n\n# [JayzTwoCents](https://www.youtube.com/watch?v=ulUZ7bf_MXI)\n\n# [KitGuru Video](https://www.youtube.com/watch?v=8wEXrZSnsRM)\n\n# [Level1Techs](https://www.youtube.com/watch?v=nryZwnVYpns)\n\n# [Linus Tech Tips](https://www.youtube.com/watch?v=Q82tQJyJwgk)\n\n# [OC3D Video](https://www.youtube.com/watch?v=4oDxME5APa8)\n\n# [Optimum Tech](https://www.youtube.com/watch?v=5YJNFREQHiw)\n\n# [PC World Video](https://www.youtube.com/watch?v=_J5wDq2ba2E)\n\n# [Techtesters](https://www.youtube.com/watch?v=srQHBeWnQzw)\n\n# [Tech Notice (Creators Benchmark)](https://www.youtube.com/watch?v=Ah0JxguHdp4)\n\n# [Tech Yes City](https://www.youtube.com/watch?v=Lv-lMrKiwyk=)",
    "comments": [
      "I am whelmed.",
      "As someone with a 30 series gpu that never expected to upgrade after only 1 gen and left potential 40 series buyers alone in 2022 and didn't judge their potential upgrades, id like to express that 4090 owners that ponder upgrading after 1 gen and then when they realize it's not worth it for them BUT their ego can't handle that there's a better gpu available, start make posts saying they're glad they won't be upgrading are annoying as fuck. We get it, you want the best at all times but now that you don't want to dish out the money for a smaller relative upgrade you want to shit on a product that would be a much bigger upgrade for everyone else that doesn't look to upgrade every generation.",
      "RTX 4090 Ti indeed",
      "https://preview.redd.it/uk4qaluuiree1.png?width=845&format=png&auto=webp&s=7139c38c5162a46e822fac34e9298fa6b4a4d8ec\n\nFeels accurate",
      "+25% cost for +25% the performance and +50% the pooooowwwweeerrrrrr",
      "In summary, 30% average uplift in 4K. Old games or UE5 games don't get any significant uplift so there is only a couple of examples in the gray zone like TLoU or Cyberpunk that experience a worthwhile \\~50% uplift.\n\nFor anyone on the 4090 there isn't any point to upgrading right now, besides a few exceptions there aren't enough games demanding enough to utilize the card's full potential so you'll only waste money trying to get it for scalped/paper launch prices.",
      "I like how everyone here is wondering if they should upgrade their 3090 or 4090. I am just trying to decide if I should upgrade my 1080.",
      "https://preview.redd.it/0s0q58ntzsee1.png?width=1018&format=png&auto=webp&s=4cd9ce969154258d47b6f511c7b3e28d9ee695d8\n\nYou're going to have to go water or you need a gargantuan case with half a dozen fans if you want to pair the 5090 with big air.",
      "Terrible coil whine. My number one takeaway",
      "It's a 4090TI good if moving from 3090, lower spec 40 series or older cards, pointless for 4090 owners.",
      "We need real world testing!  wtf uses 1600 PSUs and open cases?\n\nPut the damn thing in a case (fractal north, lancool 7, etc) and then tell me noise, temps, wattage.",
      "Damn, the FE is loud and hot according Techpowerup, might need to look at AIBs for this ! Always felt like two slots was pushing it with 600W GPU.",
      "So 100%+ increase over a 3090 at 4K. I’m in.",
      "Yes, very sorry you will have to “keep your 4080”",
      "Well it was near, the 1080Ti was 27% faster than the 1080\n\nThough the 5090 is faster than that vs the 4090",
      "Are there any reviews for VR for the 5090 out there yet?  I haven't been able to find any.",
      "Everywhere else is saying around 75c and quiet fans, be curious to see why Techpowerup is getting different results. For a dual-slot cooler dissipating up to 600w that's insanely good. Obviously the coil whine is bad though...",
      "Own a 4080/4090 (not worth it) - as expected tbh, who upgrades every generation of iPhone? (but I'm old)\n\nOwn a 3090 or older - you will see a performance bump for the price. And hopefully after 4+ years since your last purchase, your finances have recoverd enough to be in a possition to asses if you want to spend to upgrade. \\[Hopefully for another 4 years to allow one's finances to recover\\]",
      "0.1% lows beating the 4090 average fps is crazy work\n\nFrom GN in some games",
      "One of the things that always bothered me about some sites is when they say “we are using the medium preset with medium ray tracing”. wtf…with a $2000 card you are testing medium? Turn everything on and let’s see.\n\nAlso I only perused the various articles but I want to see this compared to the 4090 with and without framegen. A lot of sites don’t seem to offer thorough results. They may do a CP2077 test but it’s one single chart. That game alone should be at least 3 charts at every resolution. Raster,  DLSS, frame gen."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "top",
    "matched_keywords": [
      "rtx3090",
      "rtx3090 ti"
    ],
    "title": "Sold my RTX3090 Ti FTW3; hello RTX4090…",
    "selftext": "I replaced this with RTX 4090 (see second pic and mind the dust), and was surprised to see this go quickly on the ‘bay. Wanted a quick sale and let this go for about 70% of the average second hand value. \n\nI’ve got 3x more desktops with GTX1080s, two are EVGA FTW3 and another is an Asus OCed version - from which I think I’ll let one more go (EVGA).\n\nI ran a few benchmarks on this RTX4090 card and it wasn’t too shabby. Need to get DCS setup hopefully tomorrow.",
    "comments": [
      "That 4090 in that case looks like if someone had a Ferrari but lived in a tent.",
      "bro had to remove the front case fans xd\nmaybe invest in a bigger case?",
      "This is the most expensive, most jank setup I've seen in a long time",
      "RIP EVGA",
      "Real😭💀",
      "Lived in a tent with a pile of dust that was never cleaned))",
      "“Airflow? What’s air flow?”",
      "Im not joking, you need some better case. Maybe something from phanteks",
      "Don’t worry, that 4090 will blow all that dust out of the case /s",
      "https://preview.redd.it/64byw9bqb6md1.jpeg?width=1600&format=pjpg&auto=webp&s=6fd638e9c1b951c97be89983dff3eabcce9defe2\n\nMy rigs are to the left at the moment. Let me share a snap soon. It’s totally 🤦‍♂️",
      "I hope 5090 comes soon",
      "You have money for engine but not for rest of the car parts and garage",
      "do you light candles as substitute for rgb?",
      "Haha yes I did. It’s a big Corsair case that’s EATX compatible and I almost couldn’t fit the card in. Its size is just insane.",
      "Nice but considering the 5000 series is around the corner I'm gonna be waiting to upgrade my 3090.",
      "juggle sparkle wide command nine handle start bear many sense\n\n *This post was mass deleted and anonymized with [Redact](https://redact.dev/home)*",
      "I mean I see the issue. 💀 You need an X3D processor dog.",
      "i had a friend like this. engineer, couldn't write for shit, house was a fucking mess, but if you were able to take your eyes off the 1950s decor and trash everywhere, you'd see the 10s of thousands of dollars worth of computers and AV equipment hidden in plain sight. dude just didn't care for frivolities, as he put it, only what was practical.",
      "4090 ‘not too shabby’… it’s the fasted GPU you can buy. 🤣",
      "i9-7920X?\n\nMaan, your CPU is the bottleneck here."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "top",
    "matched_keywords": [
      "3090"
    ],
    "title": "4 Nvidia 3090 FE / AMD Ryzen 5950x / MSI X570 Godlike for molecular dynamics simulations.",
    "selftext": "",
    "comments": [
      "I'm not jealous that you were able to buy 4 of them. Nope not one bit.....",
      "We buy a lot of GPUs so we go through a distributor to guarantee stock. Even then, this year has been incredibly tough and we've seen MSRP's move upwards.",
      "If he/she has enough money to do all that, paying resale prices isn’t exactly out of reach here",
      "> I’ve been trying to get one\n\nversus\n\n> We buy a lot of GPUs so we go through a distributor to guarantee stock",
      "Much cheaper. Similar GPU with less memory than a quadro.\n\nIf you don't need more memory than the GTX offers, you probably don't need a quadro. There are some aps that got specific drivers for quadro only I think. But you will only have any business with those in the same scenario as you would want a quadro.... something like editing 3D movies at Hollywood quality....",
      "This is awesome. Is there a benefit to using the 3090s over something like quadros?",
      "Is this your \"Science the shit outta things\" build? :D",
      "We utilize these for molecular dynamics simulations. They run for days so if you have a lot of simulations you need a lot of GPUs.",
      "I'm quite happy this rig is for research and not just another crypto miner. Cheers.",
      "There is no Quadro so far with performance of 3090. So if you don't need a quadro driver optimalizations or 48GB of VRAM like quadro rtx 8000, 3090 will be both cheaper and faster.",
      "That's not a cheap case, that's a server rack. And racks, along with rack towers and rack mounts are _not_ cheap lol. That 'dinky $5 case' probably costs more like _~$200~_ $330 and at least that's not even factoring in the cost of fans and the water-cooling...\n\nEdit: added more accurate pricing, information supplied from a comment under mine.",
      "That’s a rack mount case which is why it looks like that. All the fans on the front and the slide on the right hand side give it away",
      "Trust me, people buying GPUs for science are not the reason you're having a hard time getting a card. We bought less cards this generation than we did last generation for the same reasons you're having a hard time getting cards.",
      "gpu me harder... i .. said harder!",
      "I did some molecular simulations in college, I probably have a gif of one saved somewhere if you wanna see- it’s just water molecules interacting with each other. And maybe a dye molecule.\n\nEdit: here’s a photo...\n\nhttps://imgur.com/gallery/XtLt32N\n\nI’ll try to find the gif later",
      "ASI",
      "The Quadro branding was discontinued, the card they launched was simply called the RTX A6000. It uses the full GA102 chip, but with GDDR6 memory instead of GDDR6X because the latter doesn't have 2GB memory modules yet. You need 2GB modules or you won't have enough pads on the PCB for all the modules. Lower tier versions based on the other GeForce dies are expected to be announced in the coming months.",
      "Check out Blackout PC.  They have reps at most GPU companies and they get their own percentage of stock.  This is how I got my 3090 and a 3080 for a buddy. (also my 5800x)",
      "Upvote for the word “schlommed”",
      "I like that you guys spent thousands and thousands on the most sought after hardware and crammed it into the rinkiest, dinkiest $5 case.\n\nParticularly the titanic radiator just schlommed into wherever it fits at the front."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "top",
    "matched_keywords": [
      "3090"
    ],
    "title": "Just upgraded to 3090 and now I’m officially ready for December 10th!",
    "selftext": "",
    "comments": [
      "Nice mate.\n\nWhat monitor?\n\nWhat rgb game pad for the desk?\n\n&#x200B;\n\nCheers",
      "Still using a 1080 and I'm officially ready for December 10th!",
      "Don't know about the monitor, but pad is most likely Razer Goliathus Chroma Extended (razer logo is kinda readable in the last pic)",
      "Cheers!   \nThe bottom is Alienware aw3418dw and top is  ACER KG271 \n\nMousepad is an Razer Goliathus Chroma Extended",
      "Can someone explain to me why c2077 is just widely accepted as going to be a good game?? People have been praising it for months and I just have never seen something like it for any game before. Many streamers I watch say they’re gonna play it and are excited but never explain why?? (Or when).",
      "The concept is amazing. The studio has made two great games already (Witcher 2 and 3), and they pumped a ton of money into this one. It feels reminiscent to games I loved like gta5 and the Witcher 3, but with more depth, more modern gameplay and a setting I much prefer.\n\nIt might be awful, but I doubt it will be. Quite frankly, I think it will be one of the best games of all time.",
      "3gb is... gonna be a little rough",
      "I got a 2060 super I should be ready too.",
      "''oh that looks like a nice monitor.....copy....paste in google. Holy moley''\n\n1000 pounds.",
      "I failed and it arrived today. I'm a happy bean.",
      "Keep in kind this model came out in 2018 and has since been replaced by a 2020 model. Stock of the 2018 model is so low that the price is absurd on most sites. Amazon for instance is currently selling it for $1227... but I bought it from Amazon in summer of 2019 for $700.",
      "me with a 1060 3gb hoping to run it smoothly :(",
      "I almost brought a 3090 FE few days ago, I had to resist the temptation 😷",
      "Mentions 2 and 3, leaves out 1....",
      "Keep in mind it’s a world wide release on pc, 12 am GMT. It’s coming out at 7 pm EST Dec 9th. 4pm if you live on the west coast (PST)",
      "1) Hype  \n2) CD Projekt Red\n\nThere's a feedback loop between them.\n\nThe Witcher 3 \\*really was\\* an innovation in terms of RPG implementations. The combat and loot was passable, but the writing and the world were so good they elevated the standards for the genre.\n\nMost companies will never reach CDPR standards, but CDPR might, again.\n\nAnimations in CP2077 look \\*janky\\*. Gunplay looks \\*eh\\*. But CDPR's world-building seems on point, and it's this big crazy vibrant world.",
      "It's almost time to jump into cyberspace! OUTSTANDING setup btw",
      "The day Michael V Kalaphates acceded to the throne of the Byzantine Empire in 1041, of course!",
      "You speak with a lot of conviction, but I don't think you know what you're talking about.",
      "How can you say we don't know how the gameplay is when there's literally hours of it online?"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "top",
    "matched_keywords": [
      "3090",
      "rtx 3090"
    ],
    "title": "My build based around RTX 3090, hope you like it!",
    "selftext": "",
    "comments": [
      "That thing must be huge, because the 3090 looks small :o",
      "Well, you obviously don't have a cat!",
      "Haha yeah, quite :D",
      "I would never have cats as pets, they’re too unpredictable and chaotic for my taste :)\n\nDogs are great though",
      "You never owned a cat then. Cats are pretty predictable if you know how they think.",
      "Yeah cats are extremely predictable. For example I can predict exactly when my cat is about to shit on the floor because I can faintly here the garbage truck 3 blocks away, or which surface he’s about to get on to knock shit off of when he wants attention depending on the time of the day.",
      "You mean the black circle? It’s a metal panel with colored glass on the sides, nothing complex but aesthetically very pleasing, since I’m obsessed with black :D",
      "It's an optical illusion. The 3090 makes everything look small.",
      "What’s behind all that? I’m kinda curious :P\nAnd by the way, really cool!",
      "wow, now thats one small ITX mobo. I think thats the smallest sized MOBO i have seen so far.",
      "And don't have dust.\n\nAlso, very nice build! 😉",
      "Very nice work!\n\nA couple of nits: The orange PCI-E cable riser connector is a bit jarring where the black and silver color scheme is concerned and you need to pull your I/O panel shield’s protective film stickers.   ;-)",
      "Valid point, I’m just not a cat person :D",
      "You can see both sides of the circle, 5th image is what the behind looks like",
      "This. I was a total dog person, no cats, cats yuck! Then I adopted a cat that started loving me because I fed it once. Turns out I’m an animal person rather than a dog person.",
      "Careful reddit will attack you for not being obsessed with cats lol",
      "I mean, what do you have behind the circle(for example cable management, etc). Im also obsessed with the color black, or the color combination Black and Gold!!!",
      "This. I mean, there's some size variation in MOBOs, but they're still pretty close since they have to fit their standardized mounts.",
      "Oh no, the hivemind will consume me!",
      "CPU: Intel Core i9-10900k\n\nCooler: Asus ROG STRIX LC 360 RGB\n\nMotherboard: Asus ROG Maximus XII Hero\n\nGraphics Card: Nvidia RTX 3090 Founders Edition\n\nMemory: G.Skill Trident Z RGB 32 GB (4 x 8 GB) DDR4-3200 CL16"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "top",
    "matched_keywords": [
      "3090"
    ],
    "title": "Too many pretty builds, meet Under-Deskius, ft 3090",
    "selftext": "",
    "comments": [
      "This thing is a fucking war crime.",
      "That looks like it was put together by someone who has multiple piss jugs strung about their room.",
      "The more you look, the worse it gets",
      "Oh yes, the classic zip tied fan to cool VRMs",
      "What do you think the fluid in the loop is?",
      "Gatorade Frost Glacier Cherry",
      "Took either time and effort or extra money to get sleeved cables and a comb and then just shits all over everything else. The huge manate.\n\nChrist didn't even see the fan zip tied to the tube 🥺",
      "Wtf is going on here?",
      "Hey all! All your comments are hilarious and made my day. It is a war crime and I love it haha. If any of you are curious I'll give you a rundown of all the JANK!\n\nThis build was once beautiful, but now it's Frankenstein's monster! For dead silence I put it under my desk, it has 2 360mm radiators, and an optimized fan setup I tested thoroughly (6 exhaust, 3 intake. Negative pressure I know but it performed notably better when souly watercooling my 5700xt, even th\nhen the ddr6 pumped a lot of heat out and the AMD backplate had no thermal pads, never bought an EK one). One of the radiator has different spinning fan speeds ( a different fan in the middle too ha!) to avoid harmonizing sounds, like what the mac pro does. The rest of the fans are standard maglevs which were going for reeeally cheap in 2 packs at PLE (Aussie PC store). All fans spin super slow like 600 - 800 RPM, and the last gpu in there (5700XT) was watercooled. The res is a bay res on its side coz pump res combos are a damn rip off and that with a pump mount was cheaper, and fit well in my old silverstone huge aluminium case I forgst the name of lol. Now it sits on a bit of rubber to absorb vibrations. My Z370 board is meh, hence the fan for more airflow over the VRMS but the 8700k is delided with liquid metal, I've had it rock solid with a mild OC (4.7Ghz, 1.21V) for a good two years now! For all the triggered folk do not panic, I'm going to re do the loop with black rubber tubing and clean it all up when I get a waterblock for the 3090, but for the record as jank as it is it's rock solid stable and is cleaned regularly, I had a show case build, I got bored and started experimenting haha.\n\nPS the middle tubes are ziptied together to pull one up as it was hitting the fan on the 3090 that thing is HUGE!\n\nMuch love reddit!",
      "i feel bad for that 3090...",
      "World leaders have been put on trial for less",
      "This is sacrilege.",
      "One of us! One of us!\n\nSeriously tho, I built PCs when I was a kid in the 90s. things like \"GPU\" and \"watch your temps\" were non-existent - does it boot? Yay! \n\nThen I didn't play PC for ages, and built one some 4 years ago to try VR. So I went for ATX, big black nondescript case, non-existent cable management, and the thing worked fine, so yknow, I didn't think about the aestethical part. \n\nThen I subbed to PCMR, and have now a glass-pane case with impeccable cable management :D",
      "An angel just lost its wings.",
      "Give it to me, I'll put it in a loving home",
      "But.... it doesn’t take a professional. Just someone with more pride and work ethic than a 9 year old being told to clean his room on Saturday morning while he’s watching cartoons. Only difference is when the kid shoves everything under his bed, he doesn’t show pictures to fellow room cleaning enthusiasts.",
      "Quite nice to see a build that doesn't look like it was done by a professional although I fear this is too far in the other direction",
      "function over form any day from me",
      "The Verge wants to know your location",
      "agreed thoroughly.... its pretty cancerous, between those sloppy soft tubes and the amount of sheer neglect to wire tuck everything... i almost want to just delete the internet."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "top",
    "matched_keywords": [
      "3090",
      "rtx 3090"
    ],
    "title": "Gamers Nexus - NVIDIA RTX 3090 Founders Edition Review: How to Nuke Your Launch",
    "selftext": "",
    "comments": [
      "What a brutal review! And all of it well deserved. Nvidia did not need to hype this card for 8k gaming.",
      "That's why I trust GN over other youtube reviewers. \"8K gaming card\", yeah only with DLSS and Nvidia handpicked titles. Pretty sure 3080, hell even 2080Ti is capable of \"8K\" with DLSS and toning down the settings to medium.\n\nThis should've been marketed as a professional card. Not a gaming card. It's at best 15% faster than 3080 at 4K, but costs more than twice over the 3080. An utterly pointless \"Gaming Card\". But I'm sure there are few Jeff Bezos out there who'd buy this ridiculous card for \"Gaming\".",
      "Except it's not really that either.  Watch the LTT 3090 review.  TLDW: When inquired NVIDIA told LTT that the \"3090 is not a Titan-class product and thus will not be receiving our Titan-specific driver optimizations.\" This response when Linus inquired as to why last-gen's RTX Titan was OUTPERFORMING THE 3090 in specific professional workloads.",
      "Just gonna copy my comment from the hardware sub:\n\nOnly a few minutes in and this is really brutal. Mostly about how this shouldn't have been marketed as a gaming card and how he disagrees with NVIDA marketing. They claimed 8K gaming so that is what he tested it as and well... I would just watch the video.\n\nThese gaming benchmarks are just awful for price/performance. If you only game, don't get this card. If you're worried about future proofing with more VRAM get a 3080 and upgrade sooner. It will be better and you might even save money in the long run. If you have the money to do whatever you want, I guess go for it. But if you were someone who wanted a 3080 but didn't get it on launch and thinking of stretching your budget for this, don't.",
      "I think he’s seeing fans be so upset over the way lathe launches are being handled and so he basically isn’t thrilled with their current behavior. Professional but possibly critical for good reason.",
      "DOOM ETERNAL TAMAGOTCHI EDITION LETS GO",
      "Tech Jesus saving me money.  Glad it was impossible to buy, woulda been salty.",
      "Shoutout to these guys https://i.imgur.com/CUmnTMF.jpg",
      "I loved how he kept taking the \"bribes\"",
      "If you were seriously thinking about buying the 3090 for gaming you have more money than sense anyway.",
      "Except the LTT 3090 Review showed the RTX Titan (last-gen) performing BETTER than the 3090 is certain scenarios.  They asked NVIDIA about it and NVIDIA responded that \"Titan cards receive specific driver optimizations.  The 3090 is not a Titan-class card and will not be receiving those driver optimizations.\"\n\nReally shitty thing to do to people who are purchasing this card for professional workloads and expecting the Titan-like performance optimizations.....\n\n**EDIT W/ TIME-STAMPED LINK FOR THOSE CALLING ME OUT:**\n\n[https://youtu.be/YjcxrfEVhc8?t=588](https://youtu.be/YjcxrfEVhc8?t=588)",
      "What did we learn today?\n\n\n\n\n\nWait for benchmarks, always.",
      "No that's his cousin, Beve Sturke.",
      "The thing people need to keep in mind is that the 3080 / 3090 only have a clear advandage in floating point compute. (not sure about half precision).\n\nDouble precision float and integer performance is not much faster than the 2080ti, so it is not surprising that performance is underwhelming in specific suites.",
      "You aren't wrong, I'm fortunate to have gotten to a place where 1500 or 700 it impacts my life the same.  I've never had the top-of-the-line anything in my life, and was just gonna spoil myself.",
      "No, less.  The reason is if you sell a 3080 and buy a 4080, you sell for $400-$500.  So the net cost of the 3080 is conservatively $400.  \n\nAssume the same for the 4080.  So over 4 years you spent $800.\n\nIf you sell a 4090 after 4 years you might get $300-$500.  So it costs you $1000-$1200.\n\nIt's because bigger gpus depreciate more over time because the gpus that Nvidia will later release that match them are so much cheaper.",
      "Well it all confirms the leaks we had for the past week and a half; it's 10-15% faster than the 3080 in most things at 4k with it dropping to only ~10% at 1440p and being useless at 1080p.\n\nAlso a TLDW 8k gaming is a joke with most games not even getting 30 fps with a ton of games not even supporting it anyways.\n\nI still feel once drivers mature they'll gain some performance and this is justified by all the reports of the drivers crashing their 3080s like crazy.\n\nOnce drivers and windows updates mature I feel the 3k series will really take off but the 3090 is not worth it for gaming unless you got cash to burn...",
      "totally sucked into nvidia's marketing.",
      "Imagine spending money on the 4000 series when the 5000 series is right around the corner...",
      "Did anyone really expect this card to actually run many games well at native 8K? Or be significantly faster than the 3080 for that matter? The specs were released already... you could've gotten most of these results with a basic calculator."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "top",
    "matched_keywords": [
      "3090",
      "rtx 3090"
    ],
    "title": "Amazon's New World is bricking RTX 3090 graphics cards",
    "selftext": "",
    "comments": [
      "I thought GPUs had many safeguards built in to safeguard from such situations? I would be tempted to place blame on manufacturer rather than the game developer, as software shouldn’t be capable of causing hardware failure if sufficient driver/VBIOS protections are in place.",
      "Imagine buying a +$1500 top-end card and having a game frying it. I don’t care if they fix the issue, that’s going to be a huge PR bluster to recover from\n\nEDIT: please stop commenting that it’s not the game’s problem/fault. I know that. I was trying to say that even if the developers work with Nvidia to solve the problem, gpus worth over $1500 being bricked is going to leave a bad taste",
      "NVIDIA Display drivers => Manage 3D settings => Global Settings => \"**Max Frame Rate**\"\n\nTill the issue is fixed a reasonable FPS cap could be used with the NVIDIA drivers to prevent hardware damage.\n\nI got in a few games 9000+ fps in loadingscreens/menus with the 3090 FE and I started to use the global cap, because game settings are not reliable.",
      "You’re correct unless the game is deploying type of malware that hijacks the video driver for the gpu then it shouldn’t be possible. More likely is that there’s some flaw in the bios that the game happens to be tripping over so the flaw fault would lie with Nvidia really.",
      "They do, something has to be seriously wrong with the VBIOS/drivers that was not caught before. No properly made card will just blow up from a \"poorly made\" game or anything.",
      "This game is so hot right now.",
      "Software \"frying\" GPUs\n\nNot even furmark can do that unless there is something wrong with the GPU or it's been designed/engineered poorly (or the user has been fucking with the hardware).\n\nBut software is never at fault.",
      "The article says it's specifically happening to EVGA 3090s a lot, it's quite possible it's something EVGA did and not Nvidia's fault. Then again I'm guessing a large percent of people playing this game and who have 3090s in general are using EVGA cards so it could just be bias because of that.",
      "If it's a voltage spike make sure to undervolt as well. I've played for 6hrs yesterday without issues on my 3090 FTW3. Although I'm scared shitless to play now I think I should be safe with a fps cap and undervolt.",
      "Oh boy another line of faulty EVGA hardware, at least without fireworks this time.",
      "Imagine having a 1500 dollar card and not using a free/gsync monitor\n\nEdit: He edited his post above me, completely changing how people may see this response as defending the defective cards, I'm not at all.\n\nThey said something along the lines of imagine paying for a a 1500 dollar card and not expecting the game to run at 500 FPS",
      "Unless the thermal sensors has gone bad, nvidia card thermal throttle heavily when overheat.",
      "The early EVGA FTW3 models were dying left and right. This game is just finding the ones that hadn't fried already.",
      "Perfect, I have a shit bin 3090 FE that won't do +800MHZ on mem. If this game can brick my 3090 FE, I'll have a valid reason to get it RMA.",
      "https://www.reddit.com/r/newworldgame/comments/oobi56/did_the_new_world_beta_brick_your_gpu/\n\nSeems like it's mostly limited to evga ftw3 3090s and their cards mostly die in the menu screen.",
      "Booooooy I can't wait for the gamers nexus video on this",
      "Imagine paying $1500, more realistically ~$3000, and being forced to limit fps and enable fucking vsync to avoid risking the card frying itself though\n\nedit: Lots of freesync/gsync talk which is fine, but that shouldn't be a requirement for your top-end card not to go up in flames. Also unlocked fps is still beneficial for input lag, but not so much for this game I guess",
      "It is pretty tough to fry a modern GPU due to overheating, they shut down the PC before smoking.",
      "EVGA’s 3000 FTW have been one clusterfuck after another since release.\n\nDefinitely won’t be getting an EVGA 4000 series until 4-6 months after release to see if any reports of DOA keep piling up.",
      "Nvidia? I mean, if the GPU cant safeguard against this, something is messed up"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "top",
    "matched_keywords": [
      "3090",
      "rtx 3090"
    ],
    "title": "Several EVGA RTX 3090 FTW3 Ultras and a couple MSI RTX 3090 Suprim Xs Duluth Microcenter",
    "selftext": "",
    "comments": [
      "I feel like there are way more 3090s then 3080s... probably because most don’t want to spend 1800 bucks on a gpu lol",
      "Bingo the microcenter I work you could easily get a 3090 if you come in decently early but the others no",
      "I live in duluth mn... got excited then realized we don't have a microcenter here",
      "What days do MicroCenter usually restocks the nvidia GPU's ?",
      "I feel like EVGA is the only AIB that’s been able to keep spitting out cards.",
      "My local (Chicago) Microcenter said they usually get shipments Tuesday, Wednesday, and Saturday",
      "Probably should have specified GA lol. Sorry man.",
      "I feel like the play is, they make a bunch of 3090's and when there isn't any 3080's people just spring for the 3090 instead.\n\nThere's been too many posts of people doing this to convince me otherwise lol.\n\nEdit: Guys I'm not saying this is happening I'm just tin foil hatting a little good golly gosh",
      "the state or the country that borders russia",
      "The people at my MicroCenter (yonkers) told me the same days. Damn I'm off on Thursdays and Sundays. Anyways, I'll just take a day off to get my 3080ti.",
      "Is this in georgia?",
      "Yeah but then you have a Zotac",
      "Yeah I see these sitting and think they would have sold had they been 3080s and not 3090s.",
      "u/CSharpSauce You're confusing VRAM reserve utilization with VRAM actual use. There's a difference. Unfortunately using most of the DRO's that give statistics while playing games will show max reserved utilized VRAM. It's not what is being actually used. It's a tad on the confusing side but most 4k \"quality\" AAA titles don't use but around 3-5GB of VRAM. This is the way most graphic architecture are programmed. It will reserve a large portion of the GPU VRAM for instantaneous usage but it's not 100% being used at any point. More  efficient programming would fix this issue but I wouldn't worry about texture resolution or graphic fidelity on 10GB VRAM any time soon. \\*\\*VR VRAM utilize would start encroaching on that limitation though with 10GB. Fortunately, with DLSS 2.0 (hopefully DLSS 3.0 soon) and AMD's DLSS solution we won't have to worry much about VRAM limitations for several years.",
      "Same man.  I have an EVGA myself lol.",
      "I just visited my local Micro Center yesterday to pick up a few parts and their graphics card stock was non existent, even older gen AMD and Nvidia cards were out of stock. It was insane I have never seen their shelves that bare.",
      "Man how the fuck does Duluth have a Microcenter and the 5th largest city in the US, that I live in, doesn't.",
      "Yes it is",
      "I managed to snag a 3070 from Amazon and of all the stock drop notifications I get a vast majority of them are EVGA. I’m coming back to pc building after 15 years and this is an easy way to build brand loyalty.",
      "If we're being honest, I think a big chunk of the 3090 market is going to dry up when you can actually lay hands on a 3080 reliably.  As someone with more money than sense and a lack of patience and a 3090 in my rig, I'd have gone another way given the option.  I don't think I'm alone.\n\nThat said, I'm really enjoying the Suprim.  It's nice."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "top",
    "matched_keywords": [
      "3090"
    ],
    "title": "Built this in June and used my trusty old 1080, patiently waited for the 3000 series. Managed to get this Gigabyte Vision 3090 last week and my life is now complete.❄️",
    "selftext": "",
    "comments": [
      "Of course!\n\nCase: Lian Li O11 (original I know)  \nRam: Corsair Dominator  \nGraphics: Gigabyte RTX 3090 Vision  \nMotherboard: Asus Prime x570  \nCPU: AMD Ryzen 3950x  \nFans: Corsair LL120 & QL120  \nAIO: Asus Strix",
      "Time for a 5950x 😂",
      "Mind posting a specs list?",
      "This PC will be perfect for scrolling Reddit!!",
      "A thing of beauty!",
      "Why thank you! Yeah actually getting less work done by frequently looking at the beast.",
      "How did you snag the GPU?? F5 gang in the US? What website? I've been trying for the better part of a month to no avail.  \n\n\nEdit: thanks y'all. Will keep at it. Big Navi looking tasty too so I'm on the fence.",
      "So buy right?",
      "15% extra performance for 220% more money. Do the maths.",
      "Or looking at porn.",
      "It seems some of these cards have been easier to get over here in Europe. No need to spam F5 when you could just walk to the store and grab one. \n\nNo such luck anymore though. Now they seem to be sold out everywhere. And the 3070s stocks lasted longer than 3080/3090.",
      "Your pc is a stormtrooper on Hoth",
      "Or both at the same time",
      "Oof I was able to grab a 5900x this morning. So excited for it to arrive.",
      "Looks like a spaceship!! I have the same case and MOBO too!",
      "That has to be the noisiest thing in the entire world",
      "Yeah this is purely a work computer for 3D. Just wanted to join in on the fun of making it pretty also.  \n\nMain reason I got the 3090 over 3080 is the VRAM. 10gb isn’t enough for a lot of my projects.",
      "I want that vision in a 3080 so bad....",
      "Yeah when it’s time to render anything, headphones on ;)",
      "Nono i mean why is my pc so chaos... ur cable wiring is amazing. My englis is trash sorry for that"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "top",
    "matched_keywords": [
      "3090"
    ],
    "title": "The Myth, the legend, Finally got my hands on the fabled 3090 FE",
    "selftext": "",
    "comments": [
      "Just in time to fix that error message",
      "There’s so many things going on in this picture it’s hilarious. Is that a mousepad on top of a larger mousepad? I don’t mind rainbow puke but... what is that color scheme in the pc? Why do you just have an application error on the screen? Is that an ash tray, you smoke next to your PC? Anyways nice job getting the 3090.",
      "Hahahaha, correct the game crashed just in time when the FedEx rang the bell!!!",
      "*whispers*\n\nThey are watching you.",
      "Tbh that's exactly the colour scheme I expect of someone who owns a Thermaltake Level 20. Probably got inspired by [this](https://youtu.be/ZQe4_wTKO_4) video",
      "Whaa? If you stopped smoking you should throw that shit into a lava pit and let it burn for eternity. Don't wanna get back on the addiction",
      "That’s a THX crash. Razer and their shitty THX Spatial in Synapse. Really good sound if you can get the fucking thing to actually stay working 100% which it doesn’t.",
      "Razer and their shitty ~~THX Spatial in~~ Synapse .\n\nfixed.",
      "No the PC just like, felt the presence of the 3090 approaching.",
      "OLED gang rise up",
      "Colour of custom water cooling pc is insane bro ...\nEnjoy with your RTX 3090fe 😢\nMe here with my 1050ti lokking for 30series but i can't find any of the gpu in the market. #sedlife 😭",
      "Double mousepads gives 100+ extra horsepower.",
      "Razer ~~and their~~ shitty ~~THX Spatial in Synapse~~.\n\nWorks for me",
      "Everybody has their own rgb taste, don’t rip him for that...",
      "Nah, you actually can find these out there in the wild. It’s the 3080 FEs that are the unicorns.",
      "Thanks for the compliment,  I change it all the time based on my mood or game I'm playing.  I wish you good luck coping the GPU you want.",
      "I love how they kept throwing money at that fat bitch",
      "Picture of a box. Wow 👏",
      "A $1000 case?!",
      "I get that error on MW and BOCW sometimes and its literally the most annoying thing ever. Makes me question PC gaming sometimes but I know its just activision buggy optimization."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "top",
    "matched_keywords": [
      "3090",
      "rtx 3090"
    ],
    "title": "The Gigabyte AORUS RTX 3090 XTREME Is HUGE!",
    "selftext": "",
    "comments": [
      "I’m more shocked that you got RGB Fusion to work long enough to set the gif",
      "Maybe you just have a small banana.",
      "Well, let's see your banana then big boi",
      "I-i-im scared.",
      "Lol the LED reaction gif",
      "Don't be shy now",
      "Promise you won't laugh, ok?\n\n https://imgur.com/gallery/EBaCC6J",
      "B-but.. It's, got a weird bend to it.",
      "Mia Khalifa approved",
      "Check my post [above](https://www.reddit.com/r/nvidia/comments/ni3w3y/the_gigabyte_aorus_rtx_3090_xtreme_is_huge/gz0ljgu?utm_source=share&utm_medium=web2x&context=3) on how to get it working.",
      "3090 and a stock CPU cooler...?",
      "( ͡° ͜ʖ ͡°)",
      "My babysitter",
      "Yes, the [AMD Wraith Prism](https://www.amd.com/en/technologies/cpu-cooler-solution) runs only 5° degrees warmer than the [Noctua NH-U12S-SE-AM4](https://noctua.at/en/nh-u12s-se-am4) tower cooler which is a $70 aftermarket cooler. - [SOURCE](https://www.youtube.com/watch?v=0JRY0Ri2VoM&t=598s) by JayTwoCents at 10:12\n\nEventually I will upgrade the cooling but it work's great for now.",
      "There is medication for that... :)",
      "its also loud as fuck.",
      "She's a popular speaker of your lord Jesus Christ.",
      "It like is loud, just like Mia",
      "* Download the new and updated BIOS version F2 dated 3/29/2021 [HERE](https://www.gigabyte.com/Graphics-Card/GV-N3090AORUS-X-24GD/support#support-dl-bios)\n* Unzip the file \"N3090AX\\_F2.zip\" and copy the two folders \"N3090AXA.F2\" and “N3090AXL.F2” into your AppData Local Temp Folder here “C:\\\\Users\\\\YOURUSERNAMEHERE\\\\AppData\\\\Local\\\\Temp” another way to that folder is to click on your start button and then type in “%temp%” without the quotes.\n* Make sure the BIOS Switch is on the OC position (To the left) [PIC](https://i.imgur.com/oTFaO3Q.png)\n* Boot into your computer and right click on N3090AXL.F2.exe to run as administrator\n* After the successful prompt, restart your computer and check in the AORUS Engine program if the VBIOS version shows that it has been updated to BIOS version F2.\n* Power off your computer and switch the BIOS switch onto the Silent position (To the right) [PIC](https://i.imgur.com/oTFaO3Q.png)\n* Boot into your computer and right click on “N3090AXA.F2.exe” to run as administrator\n* After the successful prompt, restart your computer and check in the AORUS Engine program if the VBIOS version shows that it has been updated to BIOS version F2.\n* 9. Now both OC and Silent BIOS have been updated to BIOS version F2.\n\nAfter updating both of your BIOS modes to BIOS version F2 dated 3/29/2021, your lcd screen will work.",
      "Thanks I'll try that out with the bios for my 3080 Extreme.\n\nOne question though, I only need to install the most recent bios correct?"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "top",
    "matched_keywords": [
      "3090"
    ],
    "title": "I bought a 3090 FE at MSRP and didn't immediately put it on eBay. Am I alone?!",
    "selftext": "",
    "comments": [
      "Managed to grab one at scan, turning up to the party an hour late! Was surprised I got one and was shipped the next day.It's a real nice card and looks sick in your build!",
      "This is my studio PC that I use for animation and design, plus a bit of sim racing in VR. Recently upgraded my 1080ti FTW3 to this brick.\n\nSpecs:\n\n* Asus WS X299 PRO Motherboard\n* 128gb Corsair Vengeance LPX 2666 RAM\n* Intel i7 9800x running at 4.7GHz on all cores, thanks to...\n* ...Alphacool Eisbaer LT360 AIO w/ 3x Corsair ML Series ML120 Pro Fans\n* Nvidia RTX3090 FE\n* Corsair RM850x PSU\n* Various M2 and SATA SSDs\n* Fractal Design R6 Case\n\n/////////////\n\nEDIT:\n\nWas not expecting this kind of response! Thanks folks!\n\nTo answer some of the main questions:\n\n\\- I need the RAM because After Effects.\n\n\\- The card is a huge step up from my 1080ti, but that is still a great card, don't get me wrong.\n\n\\- temps are good\n\n\\- For rendering I use Cycles in Blender, C4D's built in renderers, Adobe Media Encoder. I am considering a move to Redshift or Arnold. TBH most of my animation work to date has been 2d motion graphics so this has only recently become a consideration.\n\n\\- I run a professional studio and have about 15 years in the industry, so while this is a high end rig, it pays for itself in time savings. The difference in render time and smoothness of workflow, particularly in After Effects is worth the price of admission for my use case. The contents of this box is literally my livelihood. I am not rich!\n\n\\- I have noticed a big performance bump with ACC in VR. That is pretty much the only game I play or have time to play. I used to do a lot more gaming.\n\n\\- I bought the card from Scan in the UK, using PartAlert on Twitter to notify me of stock availability. I turned on desktop notifications and moved quickly when the notification came in.\n\n\\- I would be lying if I said I wasn't tempted to flip the card. I mean who wouldn't be? But ultimately I wanted the card in my machine working for me now, rather than maybe getting a card sometime in the future, possibly long after that extra £1k has been spent on shit I don't need. Plus, I don't want to contribute to scalping. Easy money usually means someone else is getting fucked over and that doesn't sit right with me.\n\n\\- No mining for me. I do have a small crypto portfolio (ADA and ETH, in case anyone is wondering), but I can't stand the damn noise when mining and it takes my machine out of action. HODLing is a much easier and cheaper way to make money with crypto for me.",
      "you deserve multiple high fives",
      "That’s where I got mine as well. I tried to get a 3080 early on at overclockers but fuck them.",
      "Nope I bought a FE 3090 and kept it. Love it.",
      "I love the Asus WS boards, they just look amazing!",
      "I did the same and I'm 95% happy with my purchase. The RAM runs hot so I'm upgrading my cheap case fans to some Noctua 140 mm units to get more air with less noise.\n\nDropping $1500 hurt less when I was able to sell my EVGA 2070 Super Black (i.e. basic, not overclocked) GPU on Ebay for, wait for it, **$790**. These are insane times right now!\n\nReally didn't need the 3090 but I also upgraded to a G-Sync 34\" 3440x1440 monitor and I like high frame rates with lots of eye candy. The 2070S couldn't do Cyberpunk justice!",
      "How does the card perform, I have the same 1080ti as you, I know it would be a big jump in performance but should I wait for the 4000 series?\n\nCause if I'm gonna wait, I'm going to get the 3090 successor at whatever  price it maybe.",
      "Me but with a 3070",
      "Still want a 3080 FE because the theoretical price to performance makes the 3090 FE a stupid choice.\n\nBut the 3090 FE I have is real and in my case. Hard to compete with actual card when the rest is theoretical. Still trying to get a 3080 but it's impossible.",
      "Well u can wait, but I doubt the 4000 series will have much better stocks. If u can get a 3090 at msrp go for it, might be ur only chance",
      "People are selling 3090s for a good $800 over MSRP on ebay. It’s nuts.",
      "What’s even dumber is people are actually buying them",
      "I have money to buy one off eBay too but I would never support that bullshit. Fuck scalpers",
      "I got one from scan when the dropped back in Jan - been a happy camper since :D\n\nminus the pcie gen 4 / usb / x570 stuff but i just run it in gen 3 and don't see a difference.\n\nThe card looks tight!!!",
      "holy crap. I just sold my 2080 blower for $650 on reddit and thought that was a steal! Bought it for $440 zotac refurb lmao \n\njust grab a 1030 2gb from microcenter, all they had it stock",
      "Same here! Sometimes I stumble upon 3090 FEs on eBay selling for 3000 euros and I tell my wife: \"look! it *was* a sensible investment, I would double the capital if I resold it!\" And she's like: \"yes but you're not gonna resell it aren't you?\" And I, hugging the pc case:\"what do you mean resell it? Why would I do something so horrible?\".",
      "They just have money.",
      "4000 is also likely over a year out as well.",
      "Ummm you’re wrong? 3090s resell for over double MSRP"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "top",
    "matched_keywords": [
      "3090"
    ],
    "title": "3090 went up on Newegg this morning on a random F5",
    "selftext": "",
    "comments": [
      "That adapter is just e-waste that will end up in landfill. They're basically giving you their rubbish to sort out yourself. Pointless.",
      "it really is. obnoxious as hell.",
      "When you need to connect your 2004 monitor to your 2020 bleeding edge gpu",
      "free garbage that comes with the card.",
      "Lol why do you need vga output?",
      "I got a 25m eathernet cable as a newegg free gift so sometimes they are actually useful",
      "Actually my mom is needing an HDMI to VGA dongle this weekend as she's taking her laptop on an extended camper stay and is hooking her laptop to an old crap monitor they have in the house lol",
      "I like to imagine that there is some maniac out there that spent $1,500 on a graphics card but is still using a 1024x768 VGA monitor from 20 years ago, getting 700 FPS in all of their games.\n\nEdit: and they aren’t even just running a CRT because it has motion and color that we have still yet to reproduce with our best gaming monitors — it is a shitty first gen 15” LCD monitor, with the worst color accuracy, ghosting, and light bleed you have ever seen.",
      "And 30 mins later it is still available...",
      "3090s are easy",
      "I got one of those too with my 3080. Such a bizarre gift.",
      "It's cringe that they do that hah",
      "I got a 10m HDMI AND a 10m optical cable bundle one.  Super high quality braided steel too.",
      "Actually the 3090 was free, but the dongle was $1500.",
      "I guess ideally they would have it as a checkable option",
      "I didn’t see the „free item“ and thought he bought a 3090 to power a VGA monitor.",
      "i'm always late to the party.",
      "I was about to remark that you must be a brave man to add the 3090, and then actually take the time to add an adapter to your cart before checking out before I realized it was free junk XD\n\nYou are not a brave person. Just an incredibly, wildly lucky one :D",
      "keep checking, I do feel there are more supplies of 3090. I'm not a crazy F5-er and got lucky but also I think more supplies. You want a 3090?",
      "Ask the OP if he will ship to you"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "top",
    "matched_keywords": [
      "3090",
      "rtx 3090"
    ],
    "title": "GeForce RTX 5080 Review Megathread",
    "selftext": "# GeForce RTX 5080 Founders Edition reviews are up.\n\nhttps://preview.redd.it/0b57tcm6vxfe1.jpg?width=3840&format=pjpg&auto=webp&s=ad230615d607bf9dd8a84e9abf0861c159b5cc42\n\n# Below is the compilation of all the reviews that have been posted so far. I will be updating this continuously throughout the day with the conclusion of each publications and any new review links. This will be sorted alphabetically.\n\n# Written Articles\n\n# [Babeltechreviews](https://babeltechreviews.com/rtx-5080-founders-edition-review/)\n\n>Upgrading to the new RTX 5080 from a 30 series GPU—or for those who simply demand peak performance—presents a clear decision. The price-to-performance ratio of the RTX 5080 is impressive, especially when viewed against the backdrop of NVIDIA’s previous generations or its current competitors. There is a uplift gen-over-gen of around 7-15% on average in raw power, when you consider DLSS 4 and its incredible uplift for max settings its really exciting. DLSS 4 is not perfect, however, and it cannot replace raw power for enthusiasts. The RTX 5080 also carries a higher price tag, albeit lower than the RTX 4080’s MSRP at $200 less. This is much better and the value it offers in enhanced performance, especially with advancements in ray tracing and AI-driven capabilities like DLSS 4, justifies the investment in our opinion.\n\n>We understand the inclination to wait for the more budget-friendly 70 and 80 class GPUs from the Blackwell generation, as these models often strike a balance between cost and performance, catering to the needs of the average gamer. However, for those seeking the pinnacle of current gaming technology, the RTX 5080 is unparalleled in its price range and class. It’s designed to deliver top-tier performance for years to come, making it an investment in future-proofing your gaming or creative setup. Ultimately, the decision to invest in such a high-end GPU depends on your specific needs and budget, but for those who prioritize leading-edge technology, the RTX 5080 is a wonderful new addition to the market.\n\n# [Digital Foundry Article](https://www.eurogamer.net/digitalfoundry-2025-nvidia-geforce-rtx-5080-review)\n\n# [Digital Foundry Video](https://www.youtube.com/watch?v=k7hDtGh0wIo)\n\n>See Stickied Comment\n\n# [eTeknix Article](https://www.eteknix.com/nvidia-geforce-rtx-5080-founders-edition-review/)\n\n# [eTeknix Video](https://www.youtube.com/watch?v=CKhoBBX2h00)\n\n>See Stickied Comment\n\n# [Guru3D](https://www.guru3d.com/review/review-nvidia-geforce-rtx-5080-founders-edition-reference/)\n\n>Depending on the game, performance improvements can vary widely. On average, you can expect a 10 to 25 percent boost in traditional rendering performance coming from a 4080S. The more effective part is NVIDIA's heavy investment in AI, deep learning, and neural shading. When we tested DLSS4 with frame generation enabled at 4x, the performance is simply incredible. However, the pressing question arises: will consumers be ready to invest in AI-assisted rendering? The answer isn’t clear yet, but time will tell. One thing is certain—DLSS4 works wonders. The performance metrics shown are a testament to its power. This GPU is quintessential for gamers using Ultra-Wide HD, Quad HD, or Ultra HD monitors, delivering a great visual experience with framerates to match. But yes, overall from the shading rasterization performance, the card is somewhat lacklustre\n\n>The GeForce RTX 5080 will speak to a lot more people compared to the $1999 costing RTX 5090. However, you'll get far less performance. Compared to the RTX 4080/4080 Super the overall rasterizer performance is a notch faster, but not heaps, and that is today's most disappointing news. NVIDIA invested heavily in the transistor budget for AI, the new generation of products places a strong focus on Raytracing, Neural Shading and of course DLSS4 with MFG (Multi Frame Generation). The combination of these together can easily bring in a fact x3 or x4 (and sometimes faster) result. Whether or not the end user is ready for artificially created frames in this degree we doubt, but as far as NVIDIA is concerned, it's the future. We do hope to see more backwards compatibility with DLSS 4 so that older games will get this new tech included as well. We stated this in the RTX 5090 review already, we wonder if the balance hasn't shifted towards AI assistance a bit too much. For the end-user change and thus a move away from the traditional render engine it will be a tough pill to swallow. The potential is huge though. For example, games like Microsoft Flight Simulator 2024, when combined with 4.0, could achieve over 150+ FPS at Ultra HD. Similarly, Cyberpunk in UHD did \\~180 FPS, that's with raytracing enabled. The recent move towards Ray reconstruction also moved NVIDIA into a new sweet spot. All features and performance combined with new technology like DLSS4 really make the Series 5000 from NVIDIA compelling. Other downsides for today's tested product have to be the high energy consumption and price level. In the end whatever we write, or how we feel about the AI-driven content doesn't matter. It's you guys that make the decisive purchase or not which makes this product series a success. The product is a notch faster than the previous generation if you look at that traditional render engine, however looking just that alone is not enough. With a whole lot of extra AI driver functionality that comes along with it, boosting your game FPS towards very high levels in the highest resolutions is possible with the likes of DLSS4 and MFG. Realistically though an RTX 4000 card with DLSS3.5 and Frame Generation will get you plenty of AI-driven performance as well. The founder card itself is lovely in design, it looks nice and it is reasonably silent. The power usage is somewhat icky. If you're coming from the RTX 3000 series or lower products, then this might be an attractive enough buy, but I think many of you expected to see RTX 4090 performance, or even slightly better. For that, you'll need a premium AIC OC version with a premium price. \n\n# [Hot Hardware](https://hothardware.com/reviews/nvidia-geforce-rtx-5080-blackwell-review)\n\n>Last week’s launch of the [GeForce RTX 5090](https://hothardware.com/reviews/nvidia-geforce-rtx-5090-review), crowned a new king in the gaming GPU market. It’s pricier and consumes more power than its predecessor, but the RTX 5090 was performance leader across the board. The GeForce RTX 5080 is also technically an upgrade over the RTX 4080 in virtually every way, but its power consumption is in the same ball park and its introductory $999 MSRP is actually somewhat lower. That should be a great story, but the GeForce RTX 5080 is only a mild upgrade over its previous-gen namesake for gaming, unless you can turn on all DLSS features with multi-frame generation. It does, however, offer more of a boost with AI and content creation workloads.\n\n>When the GeForce RTX 4080 launched, it [crushed the GeForce RTX 3090](https://hothardware.com/reviews/nvidia-geforce-rtx-4080-gpu-review) with many workloads. That’s not the case with the GeForce RTX 5080, but that was obviously not NVIDIA’s intention. The GB203 GPU powering the card is actually smaller than the AD103 on the RTX 4080, and it is manufactured on the same process node.\n\n>NVIDIA’s focus here was obviously on architectural advancements and AI-powered rendering. When you factor in the capabilities of RTX Neural Rendering and DLSS 4 with multi-frame generation, the RTX 5080 separates itself from previous-gen offerings and offers clearly superior performance and technology. And therein lies the rub. Traditional raster will likely be less of a focus for the industry moving forward. NVIDIA is looking to the [future with Blackwell](https://hothardware.com/reviews/nvidia-rtx-blackwell-architecture-overview), and they're not alone, as both AMD and Intel are on this path as well . As game developers incorporate more of the technologies available in the RTX 50 series, its performance profile relative to previous-gen GPUs will change. Though 75 titles will offer support for DLSS as of tomorrow (if you factor in the DLSS override controls in the NVIDIA app), we suspect revisiting the performance of these cards in a few months may tell a different story. AMD and Intel may also have some fresh competitors in the mix too by then.\n\n>That said, most consumers buy products for what they offer today, and not what they may potentially offer in the future. If you’re considering a card in the GeForce RTX 5080 FE’s price range, it is the current best option on the market. It’s faster and has more advanced features than a GeForce RTX 4080 and also AMD’s current flagship offering. It is not a significant upgrade over the GeForce RTX 40 series for gamers though. For owners of GeForce RTX 30 series cards (or older), however, the GeForce RTX 5080 will offer a massive boost.\n\n# [Igor's Lab](https://www.igorslab.de/en/nvidia-geforce-rtx-5080-founders-edition-im-test-geforce-rtx-4080-ti-mit-blackwell-genen/)\n\n>The RTX 5080 is particularly impressive in Ultra-HD resolutions (3840 x 2160 pixels) with activated ray tracing and patch tracing effects. Thanks to the 10,752 CUDA cores, 336 fifth-generation Tensor cores and support for DLSS 4, the card achieves exceptional frame rates in graphically demanding scenarios. While the RTX 4080 Super lags behind the RTX 5080 in most benchmarks, the new card manages to deliver a smoother frame rate and better stability through the integration of multi-frame generation (MFG). This is certainly advantageous for those who believe they need something like this.\n\n>The improved ray tracing performance, made possible by 84 fourth-generation RT cores, is particularly evident in games such as *Cyberpunk 2077* and *Alan Wake 2*. With ray tracing enabled, the RTX 5080 also benefits from advanced ray reconstruction functionality, ensuring outstanding image quality in even the most demanding scenarios. Despite this impressive performance, some limitations can be recognized: In native 4K with maximum settings, the card may still remain at its performance limit, especially at high frame rates and intensive lighting simulations. Apart from these new features, however, the GeForce RTX 5080 remains a classic sidegrade and can hardly score with significant additional performance. Everyone has to decide for themselves whether they are disappointed by this. For my part, I had actually hoped for 20 percent.\n\n>The thermal design of the RTX 5080 is based on a double-sided flow-through cooling system that directs cool air through the card and efficiently dissipates heated air. During operation, the GPU temperature remains stable even in intensive gaming scenarios, with the card reaching a maximum temperature of just under 76 °C. The memory temperatures benefit from the optimized power supply via separate power rails, which ensure an even power supply. This minimizes thermal fluctuations and ensures that the memory area remains stable even under high loads. Thermal analysis using the Optris PI 640 shows homogeneous heat distribution, with hotspots such as the GPU and voltage converters being effectively cooled.\n\n>The noise development of the RTX 5080 is heavily dependent on the fan speed. When idling and at moderate speeds, the card remains pleasantly quiet, which is due to the low-vibration fan mounting and the aerodynamic optimization of the fan blades. Under load, however, the noise increases noticeably and reaches values of up to 38 dB(A). A characteristic humming at around 200 Hz was detected in the tests, which is caused by resonances of the fans or the voltage converters. This noise is particularly noticeable at certain fan speeds, but is not consistently audible.\n\n# [KitGuru Article](https://www.kitguru.net/components/graphic-cards/dominic-moass/nvidia-rtx-5080-review-efficiency-gains-but-a-performance-letdown/)\n\n# [KitGuru Video](https://www.youtube.com/watch?v=uKIwmW5j6oc)\n\n>Only consider the RTX 5080 if you buy into Nvidia’s AI-fueled vision of the future\n\n>DLSS 4’s Multi Frame Generation feature must be seen (and felt) to be believed. On PCWorld’s Full Nerd podcast, we compared the leap from Single Frame to Multi Frame Generation to the leap from DLSS 1 to DLSS 2. When both technologies first came out, they showed promise but had plenty of rough edges. With DLSS 2, gamers agreed that Nvidia *nailed it*. And while it’s not quite perfect, Multi Frame Generation *nails it*. Once more gamers get their Dorito-stained paws on RTX 50-series cards, and are able to tool around with MFG in 75+ games and apps, I wouldn’t be surprised if all the furor over “fake frames” online dies down quite a bit. It’s a literal game changer.\n\n>But Nvidia is in trouble this generation if the masses *don’t* embrace Multi Frame Generation. Because when it comes to traditional gaming performance, the RTX 5080 is no game changer.\n\n>It’s a pretty damned terrible generational upgrade, actually. Eking out a mere 11 to 15 more render performance than the RTX 4080 Super, at the same price, at a higher power draw, isn’t compelling whatsoever. It can’t come anywhere close to last gen’s 4090. If you don’t like AI-generated frames — maybe you’re sensitive to latency, or you focus on competitive games, or you loathe the idea of AI frames potentially introducing visual glitches — I’d even go so far as to suggest picking up a 4080 Super to get roughly comparable performance for less cash.\n\n>Remember: The [RTX 3080 beat the RTX 2080 by *60 to 80 percent*](https://www.pcworld.com/article/393472/nvidia-geforce-rtx-3080-founders-edition-review.html) when it launched earlier this decade, and it did so for just $700. Then [Nvidia jacked the price of the vanilla RTX 4080](https://www.pcworld.com/article/1379747/nvidia-geforce-rtx-4080-tested-5-things.html) by *$500 dollars* for a 30 percent performance increase, leading to poor sales rectified only by the launch of the 4080 Super at $999. With the RTX 5080 barely outpacing that, the RTX 5080 would have been immensely more compelling at a couple hundred dollars cheaper. Two generations after the RTX 3080, Nvidia has truly devastated the xx80 tier’s value in recent memory. Upgrading from the 3080 to a 5080 will only get you about 40 to 45 percent more performance, for a price tag that’s 42 percent higher. That’s not progress.\n\n>If Nvidia didn’t have MFG in tow, this would’ve been a *scathing* review for the RTX 5080 itself. But boyyyyy does DLSS 4’s new tricks feel great. Multi Frame Generation makes *Star Wars Outlaws*, a notoriously janky game, feel just as good as *Doom 2016*. *Cyberpunk*’s neon Night City feels so much more *alive* when you’re racing around at a buttery-smooth 240Hz+, or over 150fps even with the game’s nuclear RT Overdrive Mode active.\n\n>And that’s the promise Nvidia needs gamers to buy into for the GeForce RTX 5080 — heck, perhaps this entire RTX 50-series generation. Are you willing to embrace “fake frames” and dip your toes into experiences that aren’t currently possible with traditional rendering alone? If so, this GPU provides enough grunt to fuel those adventures in 4K and 1440p alike.\n\n>If not, the RTX 5080 is one of the most disappointing GPU releases in a long time. It’s probably best to save your cash.\n\n>Me? I’m into the vision. But I wish Nvidia imbued the RTX 5080 with more raw rendering firepower, so it could be a decent upgrade even for “fake frame” haters. Nvidia didn’t, alas — so now the RTX 5080’s future hangs in the balance of those 75 DLSS 4 games working correctly at launch.\n\n>If DLSS 4 and Multi Frame Generation perform like a champ when that wider availability hits, it could usher in a new era of smooth, AI-supercharged performance. But if DLSS 4 winds up plagued by visual artifacts or other issues once the floodgates open, it could instead set off an explosion of “fake frames” memes and sign a death warrant for the otherwise ho-hum RTX 5080 — perhaps even the rest of Nvidia’s 50-series lineup.\n\n>The GeForce RTX 5090 can stand alone on its own merits, but the RTX 5080 is all-in on DLSS 4. All that’s left us to see is where the chips fall.\n\n# [LanOC](https://lanoc.org/review/video-cards/9135-nvidia-rtx-5080-founders-edition)\n\n>For performance, it will depend a lot on what your goal is for the card on whether you would say it did well in testing or not. Nvidia markets the card as a 2k or 1440p card and at that resolution and at 1080p it did extremely well, outperforming last generation's flagship RTX 4090. At 4k I would still say it did very well, but on average the RTX 4090 does edge back in ahead of it in our tests. The RTX 5080 has 16GB of memory and a smaller memory interface than the RTX 4090. It does have faster memory which makes up the difference a lot, but that does make a difference at 4k in some tests. That said, if you haven’t experienced DLSS 4 with the improved transformer models making significant improvements in the visual quality and frame generation x4 giving mind blowing performance, I would take that over the 8 extra FPS at 4k. Not only do you see a lot of those improvements even in CPU-limited situations, but you can see 300-500% performance improvements over not using DLSS at all. I didn’t run into as many of the bugs as I saw when testing the RTX 5090, but OpenCL-based workloads were still a problem but Nvidia is aware and working on it.\n\n>At the end of the day though, it always comes down to pricing. The RTX 5080 Founders Edition has an MSRP of $999. That is $200 less than the RTX 4080 launched at but is $300 more than what the RTX 3080 launched at. It’s also half of the price of the new RTX 5090. More importantly, how does it compare to other cards with current pricing? For that, I put the graph above together that takes every card I’ve tested’s Time Spy Extreme GPU Score and divides it by its current price as well as its launch MSRP. For current pricing, it is the lowest available price on PCPartPicker and it is interesting to see how much pricing and card availability has changed from last week when the performance of the RTX 5090 was shown. The RTX 5080 Founders Edition is sitting in the middle of the pack for value right now but there aren’t any cards faster or even near it in performance on the chart. With all of the talk on how it compares with the RTX 4090 for example, the only 4090’s you can currently get are $2598 or more. I wouldn’t call it a value, but if you are looking for high-end 1400p or 4k performance and the RTX 5090 isn’t in your budget this is the clear choice, that is assuming you can find these anywhere near the launch price once they hit stores.\n\n# [OC3D Article](https://overclock3d.net/reviews/gpu_displays/nvidia-rtx-5080-founders-edition-review/)\n\n# [OC3D Video](https://www.youtube.com/watch?v=k-6Dw4qsGhA)\n\n>As we said in our introduction, the Nvidia RTX 5080 Founders Edition is almost famous before it’s appeared. Such is the incredible reputation of its similarly numbered forebears, the expectation is massive. The GTX 280 was launched 17 years ago, and apart from a couple of notable missteps – the red hot GTX 480 for example – they’ve all been stellar. It’s not a coincidence that when Nvidia introduced the RTX series of cards the top model was a RTX 2080 Ti. The name has cachet.\n\n>Clearly the RTX 5090 follows the recent trend where the 90 card is the flagship, money-no-object option. The x080 cards are for those with deep pockets, but not unlimited ones. Or perhaps those for whom gaming is your primary thing and so spending a little more is worthwhile. That’s where the Nvidia RTX 5080 Founders Edition comes in. We’ve yet to see performance figures for the guaranteed massive selling RTX 5070 and RTX 5070Ti models. That leaves us with either seeing how close the Nvidia RTX 5080 can get to the big RTX 5090, or how much better than the Ada Lovelace cards it is.\n\n>If the RTX 5090 was jaw-dropping, the RTX 5080 continues that good work. The next generation of cores which festoon the tiny PCB really put the work in to give you smooth performance. We know that the big ticket item is multi-frame generation, but even in pure rasterised benchmarks the Nvidia RTX 5080 Founders Edition proves a big upgrade on the previous model. If you’re just after the latest and greatest at an enthusiast price point, you can almost stop reading here.\n\n# [PC World Article](https://www.pcworld.com/article/2591060/nvidia-geforce-rtx-5080-review.html)\n\n# [PC World Video](https://www.youtube.com/watch?v=YaZT5OuW6v0)\n\n>DLSS 4’s Multi Frame Generation feature must be seen (and felt) to be believed. On PCWorld’s Full Nerd podcast, we compared the leap from Single Frame to Multi Frame Generation to the leap from DLSS 1 to DLSS 2. When both technologies first came out, they showed promise but had plenty of rough edges. With DLSS 2, gamers agreed that Nvidia *nailed it*. And while it’s not quite perfect, Multi Frame Generation *nails it*. Once more gamers get their Dorito-stained paws on RTX 50-series cards, and are able to tool around with MFG in 75+ games and apps, I wouldn’t be surprised if all the furor over “fake frames” online dies down quite a bit. It’s a literal game changer.\n\n>But Nvidia is in trouble this generation if the masses *don’t* embrace Multi Frame Generation. Because when it comes to traditional gaming performance, the RTX 5080 is no game changer. \n\n>It’s a pretty damned terrible generational upgrade, actually. Eking out a mere 11 to 15 more render performance than the RTX 4080 Super, at the same price, at a higher power draw, isn’t compelling whatsoever. It can’t come anywhere close to last gen’s 4090. If you don’t like AI-generated frames — maybe you’re sensitive to latency, or you focus on competitive games, or you loathe the idea of AI frames potentially introducing visual glitches — I’d even go so far as to suggest picking up a 4080 Super to get roughly comparable performance for less cash.\n\n>If Nvidia didn’t have MFG in tow, this would’ve been a *scathing* review for the RTX 5080 itself. But boyyyyy does DLSS 4’s new tricks feel great. Multi Frame Generation makes *Star Wars Outlaws*, a notoriously janky game, feel just as good as *Doom 2016*. *Cyberpunk*’s neon Night City feels so much more *alive* when you’re racing around at a buttery-smooth 240Hz+, or over 150fps even with the game’s nuclear RT Overdrive Mode active.\n\n>If not, the RTX 5080 is one of the most disappointing GPU releases in a long time despite its prowess. It’s probably best to save your cash unless you’re on a card several generations old and don’t mind spending big for a big performance upgrade.\n\n>If DLSS 4 and Multi Frame Generation perform like a champ when that wider availability hits, it could usher in a new era of smooth, AI-supercharged performance. But if DLSS 4 winds up plagued by visual artifacts or other issues once the floodgates open, it could instead set off an explosion of “fake frames” memes and sign a death warrant for the otherwise ho-hum RTX 5080 — perhaps even the rest of Nvidia’s 50-series lineup.\n\n>The GeForce RTX 5090 can stand alone on its own merits, but the RTX 5080 is all-in on DLSS 4. All that’s left us to see is where the chips fall.\n\n# [Puget Systems (Content Creation Review)](https://www.pugetsystems.com/labs/articles/nvidia-geforce-rtx-5080-content-creation-review/)\n\n>Overall, the RTX 5080 is a solid GPU that provides good performance nearly across the board. However, following [our 5090 review](https://www.pugetsystems.com/labs/articles/nvidia-geforce-rtx-5090-content-creation-review/), we are somewhat disappointed by the relatively small performance uplifts over the RTX 4080 SUPER. In some places, the 5090 seemed to justify the price increase over the 4090 with staggering performance increases. For the 5080, the same price seems to get you basically just the same performance in many workloads.\n\n>In **video editing and motion graphics**, the RTX 5080 is about 5-10% faster than the RTX 4080 SUPER and 20-30% faster than the 3080 Ti. There were some standout areas, such as 3D performance in After Effects, with gains double those. We’re still waiting on finalized DaVinci Resolve results, but we are doubtful the 5080 will be a huge upgrade over a 4080 or 4080 SUPER, except perhaps with LongGOP media. Still, for new-to-PC users or those on even older cards, it offers a solid upgrade.\n\n>In **rendering applications**, the 5080 manages better, with a 10-20% lead over the 4080 SUPER and a 55% to 188% lead over the 3080 Ti. This is definitely a performance jump that may be worth upgrading for even from the 40-series card, and it offers a great value for those using older generation cards. However, there is still the lingering issue of compatibility and performance quirks, so we would recommend buying with caution or holding off for a bit before committing to a 5080 for a rendering system. We are currently [maintaining a list of known issues](https://www.pugetsystems.com/blog/2025/01/27/nvidia-geforce-rtx-50-series-known-software-issues/) in content creation applications that you can check in on to see when these are resolved.\n\n>NVIDIA’s new GeForce RTX 5080 is a great workhorse GPU that provides solid performance across the board and can handle most of the tasks you throw at it. In many workflows, it is only slightly slower than the RTX 5090, so it may end up being one of the better price-to-performance cards of this generation. If you are on a 30-series card or older, it offers a great upgrade, but less so for users on a 40-series card. Especially given the dwindling supply of those previous-generation cards, we expect the RTX 5080 to be an incredibly popular GPU.\n\n# [Techpowerup](https://www.techpowerup.com/review/nvidia-geforce-rtx-5080-founders-edition/)\n\n>At 4K resolution, with pure rasterization, without ray tracing or DLSS, we measured a 14% performance uplift over the RTX 4080 Super, 15% over the RTX 4080 non-Super. This is definitely MUCH less than expected and not nearly as much as what we saw last week from RTX 5090, which beat the RTX 4090 by 35%. Compared to the GeForce RTX 3080, the performance increase is 75%, which means NVIDIA missed the \"twice the performance every second generation\" rule. Last-generation's flagship, the RTX 4090 is 13% faster than the RTX 5080 and the new RTX 5090 flagship is 52% faster, but twice as expensive.\n\n>GeForce RTX 5080 is still faster than AMD Radeon RX 7900 XTX, Team Red's best GPU, by 15% in a pure raster scenario, much more in RT. AMD has confirmed that they are not going for high-end with RDNA 4, and it's expected that the RX 9070 Series will end up somewhere between RX 7900 XT and RX 7900 GRE. This means that AMD's new cards don't pose a threat to the RTX 5080, which might explain why we're not getting bigger performance improvements.\n\n>RTX 5080 is a good card for 4K gaming. With RT or Path Tracing enabled, some titles require that you use DLSS Upscaling / Frame Generation. The card is also great for 1440p gaming, to feed those high-refresh-rate gaming monitors.\n\n>NVIDIA is betting on ray tracing and Blackwell comes with several hardware improvements here. Interestingly, the RTX 5080 runs only 11% faster at RT than RTX 4080 Super—remember, we got +14% in without RT. It looks like this is partly due to the game selection. The games that show the biggest gains in our non-RT test suite do not support RT. Still, compared to AMD's Radeon RX 7900 XTX, the difference is massive—the RTX 5080 is 61% (!) faster than the RX 7900 XTX. On top of that, NVIDIA is introducing several new optimization techniques that game developers can adopt. The most interesting one is Neural Rendering, which is exposed through a Microsoft DirectX API (Cooperative Vectors). This ensures that the feature is universally available for all GPU vendors to implement, so game developers should be highly motivated to pick it up. AMD has confirmed that for RDNA 4 they have put in some extra love for the RT cores, so hopefully they can catch up a bit.\n\n>NVIDIA made a big marketing push to tell everyone how awesome DLSS 4 is, and they are not wrong. First of all, DLSS 4 Multi-Frame-Generation. While DLSS 3 doubled the framerates by generating a single new frame, DLSS 4 can now triple or quadruple the frame count. In our testing this worked very well and delivered the expected FPS rates. Using FG, gaming latency does NOT scale linearly with FPS, but given a base FPS of like 40 or 50, DLSS x4 works great to achieve the smoothness of over 150 FPS, with similar latency than you started out with. Image quality is good, if you know what to look for you can see some halos around the player, but that's nothing you'd notice in actual gameplay.\n\n>Want lower latency? Then turn on DLSS 4 Upscaling, which lowers the render resolution and scales up the native frame. In the past there were a lot of debates whether DLSS upscaling image quality is good enough, some people even claimed \"better than native\"—I strongly disagree with that—I'm one of the people who are allergic to DLSS 3 upscaling, even at \"quality.\" With Blackwell, NVIDIA is introducing a \"Transformer\" upscaling model for DLSS, which is a major improvement over the previous \"CNN\" model. I tested Transformer and I'm in love. The image quality is so good, \"Quality\" looks like native, sometimes better. There is no more flickering or low-res smeared out textures on the horizon. Thin wires are crystal clear, even at sub-4K resolution! You really have to see it for yourself to appreciate it, it's almost like magic. The best thing? DLSS Transformer is available not only on GeForce 50 series, but on all GeForce RTX cards with Tensor Cores! While it comes with a roughly 10% performance hit compared to CNN, I would never go back to CNN. While our press driver was limited to a handful of games with DLSS 4 support, NVIDIA will have around 75 games supporting it on launch, most through NVIDIA App overrides, and many more are individually tested, to ensure best results. NVIDIA is putting extra focus on ensuring that there will be no anti-cheat drama when using the overrides.\n\n>For $1000, there is no reason you should buy RTX 4080 or RTX 4080 Super now. AMD's Radeon RX 7900 XTX is $820, or 18% cheaper, but it's also 15% slower in raster, and 38% slower in RT. NVIDIA is also very strong in software features, the new DLSS Transformer model is a game-changer and DLSS 4 multi-frame-generation is a notable selling point, too. No way I would buy RX 7900 XTX at that price instead of RTX 5080—maybe if AMD drops the price considerably. Also, the way AMD is handling Radeon lately makes me wonder if their discrete GPU brand will still be around in two or three years. The upcoming RDNA 4 lineup will not target the top end of the market, so unless a miracle happens, RX 9070 XT won't be able to compete with RTX 5080, maybe RTX 5070 Ti, which is coming out soon.\n\n>If you already have a high-end GeForce RTX 40 Series card, then there is no reason to upgrade. You're just missing out on multi-frame-generation, the DLSS Transformer model is supported on all older RTX cards, too. On the other hand, if you're coming from GeForce 30, then suddenly you'll get to experience frame generation, which will make a huge difference for your gaming experience.\n\n# [The FPS Review](https://www.thefpsreview.com/2025/01/29/nvidia-geforce-rtx-5080-founders-edition-video-card-review/)\n\n>GeForce RTX 5080 performance makes us go hmmm. That’s an interesting way for us to start this paragraph, but the performance of the GeForce RTX 5080 is indeed all over the place. There are some games where the generational uplift looks exciting, and then there are others that make us scratch our head. It generally gives us a feeling of “hmmm.”\n\n>There are some good cases where the GeForce RTX 5080 is a nice uplift from the previous generation. We did see some 23%+ performance improvements, but those seemed to be outliers, more than the norm. Overall, it has somewhere between a 10%-20% performance uplift depending on the game and settings, Ray Tracing wasn’t that big. This isn’t enough to reach or match the GeForce RTX 4090 in performance. The GeForce RTX 4090 remains the performance leader in this regard. If you thought the GeForce RTX 5080 would be as fast as the GeForce RTX 4090, it isn’t.\n\n>Some of the results we have experienced make sense, after all, the raw specifications of the GeForce RTX 5080 are not that much upgraded from the GeForce RTX 4080 Super. The GeForce RTX 5080 is a GPU that is essentially a GeForce RTX 5090 cut in half, and the price reflects that as well. The GeForce RTX 5080 seems to consume about 17% more power than the GeForce RTX 4080 Super, and we get a performance increase that is close to that, some cases better, some cases worse.\n\n>Overall this means that the GeForce RTX 5080 at times follows a little too closely to the previous generation it is supposed to be supplanting. Often times we are left with a sense of a less-than-desirable gameplay experience improvement that one would expect from a new generation.\n\n>One could even call the GeForce RTX 5080 more akin to a theoretical ‘GeForce RTX 4080 Super Ti” or “GeForce RTX 4080 Super Super”, at least that is what it feels like. Keep in mind that the MSRP is $999, and that IS the same MSRP that the GeForce RTX 4080 Super was as well. Therefore, technically, it is a price for performance improvement, if pricing is at $999. It’s just that… it isn’t that exciting really.\n\n>As the GeForce RTX 4080 Super’s dry up in the market and the GeForce RTX 5080’s replace it, you will be getting a better gameplay experience with the GeForce RTX 5080. At the $999 MSRP, the NVIDIA GeForce RTX 5080 Founders Edition would be a solid upgrade from *prior generations*, such as GeForce RTX 3080 or GeForce RTX 2080 or even earlier.\n\n>If you are moving from an older generation prior to the RTX 40 series, the GeForce RTX 5080 will offer a good substantial upgrade path to modern features and gameplay performance at the $999 MSRP, but if you currently own a GeForce RTX 40 Series, unless you are moving from low-end to high-end, it is not going to be worth the upgrade.\n\n# [Tomshardware](https://www.tomshardware.com/pc-components/gpus/nvidia-geforce-rtx-5080-review)\n\n>Nvidia's RTX 5080 Founders Edition delivers what we were expecting, mostly. We can't help but feel that, like the RTX 5090, these first drivers made available to reviewers aren't fully tuned for the Blackwell architecture yet. In some games, performance looks quite good with reasonable generational improvements. In others, the gains don't materialize — particularly at lower resolutions.\n\n>What is obvious is that the RTX 5080 isn't a massive leap in performance compared to its predecessor — whether that's the 4080 Super we tested or the slightly slower RTX 4080. Nvidia's performance claims depend almost entirely on Multi Frame Generation (MFG), and that's disingenuous at best. Nvidia knows as well as anyone that a game running at 200 FPS with 4X MFG doesn't feel the same as a game rendering at 200 FPS without any form of framegen. Pretending that the resulting \"framerates\" are comparable requires serious mental gymnastics.\n\n>However, it's equally disingenuous to suggest that framegen/MFG are useless or \"fake frames.\" If you play a game running at 30–35 FPS without framegen and then try the same game running at 55–60 FPS with framegen, the latter feels better in my book. It's not anywhere close to twice as fast, but perhaps 20% faster. And if you use 4X MFG running at 105–115 FPS, that might feel another 10–20 percent faster than the 2X framegen result.\n\n>It's really just frame smoothing, but that smoothness interacts with your brain to make the game generally feel better, even if the base input sampling rate decreases slightly.\n\n>As a potential GPU purchase, if they're both priced the same, the RTX 5080 will be better than an RTX 4080 Super. That much is a given. Right now, it doesn't always win, but driver tuning should address any shortcomings. But if you already have a decent GPU, the benefits of the 5080 over the 4080 Super are pretty thin at present. If you didn't see enough in the RTX 4080 Super to entice you to upgrade in early 2024, the extra 10% performance plus new features that the 5080 offers isn't likely to change things.\n\n>If you're in the market for a $1,000 graphics card, and assuming there's enough supply to keep prices down, the RTX 5080 now sits on the podium as the second fastest GPU overall. It's half the price of the 5090, less likely to be continually sold out, and has all the other Blackwell architecture features. It's just nowhere near the potential 30% higher baseline performance we like to see with generational upgrades.\n\n>And if you're able to justify spending a grand on the RTX 5080, it's probably not that much of a stretch to double that for the clearly superior RTX 5090 that's over 50% faster on average — at 4K. The RTX 3090 was only 15% faster than an RTX 3080 four years ago, for double the price. For the well-funded gamer / streamer / AI researcher / etc., the 5090 is the clearly superior option. Which is one more reason we expect it will be hard to come by for quite some time.\n\n# [Computerbase - German](https://www.computerbase.de/artikel/grafikkarten/nvidia-geforce-rtx-5080-test.91176/)\n\n# [HardwareLuxx - German](https://www.hardwareluxx.de/index.php/artikel/hardware/grafikkarten/65395-leistungsplus-nur-ueber-mfg-die-geforce-rtx-5080-founders-edition-im-test.html)\n\n# [PCGH - German](https://www.pcgameshardware.de/Geforce-RTX-5080-Grafikkarte-281030/Tests/Release-Preis-kaufen-Benchmark-Review-vs-4080-Super-1464610/)\n\n# [Elchapuzasinformatico - Spanish](https://elchapuzasinformatico.com/2025/01/nvidia-geforce-rtx-5080-founders-edition-review/)\n\n\\--------------------------------------------\n\n# Video Review\n\n# [Der8auer](https://www.youtube.com/watch?v=IvQwlN1sE0U)\n\n# [Digital Foundry Video](https://www.youtube.com/watch?v=k7hDtGh0wIo)\n\n# [eTeknix Video](https://www.youtube.com/watch?v=CKhoBBX2h00)\n\n# [Gamers Nexus Video](https://www.youtube.com/watch?v=nShh_j4s2YE)\n\n# [Hardware Canucks](https://www.youtube.com/watch?v=JFF7lMvpV-s)\n\n# [Hardware Unboxed](https://www.youtube.com/watch?v=sEu6k-MdZgc)\n\n# [JayzTwoCents](https://www.youtube.com/watch?v=meekBr-ZB1E)\n\n# [KitGuru Video](https://www.youtube.com/watch?v=uKIwmW5j6oc)\n\n# [Level1Techs](https://www.youtube.com/watch?v=ZoE8GQnDwQQ)\n\n# [Linus Tech Tips](https://www.youtube.com/watch?v=Fbg7ChsjmEA)\n\n# [OC3D Video](https://www.youtube.com/watch?v=k-6Dw4qsGhA)\n\n# [Optimum Tech](https://www.youtube.com/watch?v=d7k4XWg-TcA)\n\n# [PC World Video](https://www.youtube.com/watch?v=YaZT5OuW6v0)\n\n# [Techtesters](https://www.youtube.com/watch?v=azD56D4_bFM)\n\n# [Tech Yes City](https://www.youtube.com/watch?v=6NwO1qrkEds)",
    "comments": [
      "> And if you’re able to justify spending a grand on the RTX 5080, it’s probably not that much of a stretch to double that for the clearly superior RTX 5090 that’s over 50% faster on average — at 4K\n\nWhat a stupid take (as expected) from Tomshardware.",
      "Literally the worst generation of GPUs Nvidia has ever released.",
      "RTX 50 8.0%",
      "TLDR; Skip the 5080 if you have a 40 series.",
      "I hope this doomer posting from this sub continues so I can get a 5080 tomorrow. \n\nNot everyone is upgrading from a 4000 series, and this seems like a great upgrade from my 3070ti.",
      "I may as well double it again and run dual 5090s at that point because clearly if im just throwing thousands around like that it's not an issue",
      "RIP my dreams of cheaper used 4090s.",
      "Fairly disappointing coming from a 3080 Ti looking to upgrade.",
      "My takeaway.\n\n\nIf you are on 4000 series, skip. Unless you really want multi frame gen.\n\n\nFor 3000 series, it is up to you. It's up to 50% more frames, some improvements in frame time, and access to frame Gen.\n\nUnder the 3000 series? Much better performance, much better frame times, more features. If you were previously considering the 4000 series, this is a no brainer. Better performance at the same price.\n\nThe 5000 series is being compared to Turing. A lot of the new architecture is focused on neural rendering, but no games use it yet. Like Turing, these cards might age well in 2 years time.\n\nThe small Gen on Gen uplift is why everyone is upset. Neural rendering doesn't exist in games right now. Silver lining is that the 5000 series is the same price as last Gen.\n\n\n\nThere is so much room for a 5080 Ti or Super. The 5090 is getting something like up to 50% more frames over the 5080. Also room for more ram on a 5080 Super/Ti.",
      "This \" launch \" could've been an email",
      "NVIDIA has been trying to make people think this way for years, but this gen doesn’t sell it at all. $1200 -> $1600 made a lot more sense last gen, even if that was also BS",
      "CPU manufs should retaliate by blowing hot air towards the GPU.",
      "See the bright side: There will be less posts about 5080 not beeing in stock.",
      "Going from a 1070 to a 5080 is a massive upgrade, why would it not be worth it?",
      "basically a 4080 Ti Super with multi frame gen \n\nnot a bad card if you're going from 30 series GPUs and below or a 4060, but still a bad card generation to generation wise",
      "Gonna keep my 3080 for a while longer, lets see what the next generation has in store.",
      "TLDR\n\n![gif](giphy|JoePLWxLD7cGc)",
      "The 16gb vram aside (which already made it a no-buy for me), the pitiful perf increase and price tag make this a slap in the face from nvidia.\n\nI'll definitely be holding on to my 3080 for another gen it seems.",
      "I thought my 4090 purchase was insane at launch. It might actually turn out one of the best in a few more years.\n\n5xxx series is the least impressive launch since GTX 700 series!",
      "I wasn't expecting much and was still disappointment"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "top",
    "matched_keywords": [
      "3090"
    ],
    "title": "Snagged this absolute unit of a graphics card- 3090 Kingpin",
    "selftext": "",
    "comments": [
      "I like Evga but I won’t by a kingpin edition ever. I bought the 1080ti kingpin edition and I had to turn it in every 6 months for warranty replacement. It was junk. Good luck it was my only bad card series I bought in 25 years. Evga warranty replacement is 2nd to none anyways.",
      "Mixed bag for me. I bought their 980 Hybrid cooler and it failed after a few months.\n\nBought the 1080ti Hybrid cooler and it's still working in my second computer.",
      "Ha! Chonker!",
      "The double 360 AIO rads was always a super satisfying idea to me...enjoy that monster!",
      "It hit 460w under load while running furmark, no need to pay for my heating bill lmao",
      "500 extra watts for a 50 mhz clock boost",
      "time to dump that 1000w bios on it.",
      "Always has been....",
      "What is it with those people uh ?  In every 3090 thread, there's one, telling you all about the facts and \"objectivity\", completely oblivious to the fact that this is a hobbyist forum and we're a bunch of enthusiasts.",
      "I borrowed my friends 980 Ti hybrid and it burned up on me. I sold him my 1080 Ti and it's still going solid.",
      "Can’t wait for the tankies to tell you how you should have spent your money!",
      "On top the tube is going up on the left.\nThe CPU is the one in the back",
      "Jealousy. Pure and simple.",
      "🌏🧑‍🚀🔫👩‍🚀",
      "3840x1080, I snagged a deal on a 49\" samsung monitor lol",
      "Its more of a collectors item. Its not much better than the 3090 FTW3 but its more of the cool factor lol. Or if you're an extreme overclocker that wants to OC with ln2",
      "And this gens KingPin is not as good as 2080ti KPE. Chips are not binned and stock PR scores aren't any better than say ftw3",
      "Y u p",
      "Wait.... where is your GPU radiator mounted?",
      "TIL: African kids eat fps"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "top",
    "matched_keywords": [
      "3090",
      "rtx 3090"
    ],
    "title": "RTX 3090 Gigabyte Gaming OC Build",
    "selftext": "",
    "comments": [
      "Its a nice build but I never understood how having super bright blinking lights right at peripheral isn't super annoying/distracting.",
      "Sexy, what cables are those?",
      "Thank you! Lian Li STRIMMER PLUS cables, you can get em on Newegg.",
      "Ya I bought a ton of LL120s and the O11 Dynamic case, spend a fortune pimping out my build and then had RGB all over for about 30mins until I set it to just colour cycle slowly because I can't handle flashing lights all over next to me. It also glares onto other surfaces like the edge of the monitor which is even more distracting.",
      "Its actually facing away from me, the monitor is on the other side. I just like making flashy builds for fun, it looks really nice to me.",
      "TRON Legacy!",
      "Do these cables work with fully modular 1000watt evga ?!?!?!?!?!?!!!!!!!!",
      "There were some crashing issues during gaming, however under-clocking slightly does seem to have fixed the problem. Hopefully a new driver will fix the issues later on!",
      "That's why I'm still rocking a case without a window, no need to worry about the looks of the components (EVGA 3080 for example).",
      "That was actually a big inspiration for my overall color scheme! That and cyberpunk theming.",
      "Don't plug them directly on the PSU. They're just cable extensions. In case you didn't know that.",
      "Same, especially if your pc is on the table, near the monitor.",
      "Personal preference is all that matters friend!",
      "I don't agree with that. My PC still looks good, but having a bunch of colours flashing is over the top imo. Being able to set my keyboard and computer to any colour I want is actually great, it's no different than getting tired of a certain phone case or imagine being able to have your car be red for a few months, then immediately make it just black or any colour you want.\n\nI usually keep mine on red or white depending on mood and if I'm playing a certain game like Civ VI, I set the colour to be the main colour of who I'm playing, it's great. The best part is I can just turn it off too and my case still looks awesome.",
      "Light show for mr lizard",
      "Love the build! What kind of RGB fans are those?",
      "I walk up to it everyday to turn it on and the room isnt just limited to that corner. I have my girlfriends desk on the side, and my bearded dragon in there. Also we play VR in there, so ya I see it quite a lot and am moving around the room often.",
      "Honest question, dont you get irritated or distracted by those flashing lights on cables? i personally dont mind rgb but i set them all up so the effects are very slow and smooth.",
      "Imagine getting this mad about someone's own use of time and money with their hobby lol",
      "He sounds like the type to still participate in PC vs. Consoles debates in the YouTube comment section."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "top",
    "matched_keywords": [
      "3090",
      "rtx 3090"
    ],
    "title": "GeForce RTX 30-Series Ampere Information Megathread",
    "selftext": "# This thread is best viewed on new Reddit due to inline images.\n\n# Addendum: September 16, 2020\n\n[RTX 3080 Review Megathread](https://new.reddit.com/r/nvidia/comments/itw87x/geforce_rtx_3080_review_megathread/)\n\n[GA102 Ampere Architecture Whitepaper](https://www.nvidia.com/en-us/geforce/news/rtx-30-series-ampere-architecture-whitepaper-download/)\n\n# Addendum: September 11, 2020\n\n[Embargo and RTX 3070 Update Thread](https://new.reddit.com/r/nvidia/comments/iqyol5/rtx_3080_founders_edition_review_date_sept_16th/)\n\n>Hey everyone - two updates for you today.  \n>  \n>First, GeForce RTX 3080 Founders Edition reviews (and all related technologies and games) will be on **September 16th at 6 a.m. Pacific Time.**  \n>  \n>Get ready for benchmarks!  \n>  \n>Second, we’re excited to announce that the **GeForce RTX 3070 will be available on October 15th at 6 a.m. Pacific Time**.\n\n# There is no Founders Edition Pre-Order\n\n&#x200B;\n\n[Image Link - GeForce RTX 3080 Founders Edition](https://preview.redd.it/sx6y5lmfflk51.png?width=1920&format=png&auto=webp&s=97732ebf788f1a904cb3c847e3b06f2f608a0424)\n\nPowered by the Ampere architecture, GeForce RTX 30-Series is finally upon us. The goal of this megathread is to provide everyone with the best information possible and consolidate any questions, feedback, and discussion to make it easier for NVIDIA’s community team to review them and bring them to appropriate people at NVIDIA.\n\n# r/NVIDIA GeForce RTX 30-Series Community Q&A\n\n~~We are hosting a community Q&A today where you can post your questions to a panel of 8 NVIDIA product managers.~~ [~~Click here to go to the Q&A thread for more details~~](https://new.reddit.com/r/nvidia/comments/iko4u7/geforce_rtx_30series_community_qa_submit_your/)~~.~~ **Q&A IS OVER!**\n\n[Here's the link to all the answers from our Community Q&A!](https://reddit.com/r/nvidia/comments/ilhao8/nvidia_rtx_30series_you_asked_we_answered/)\n\n# [NVIDIA GeForce RTX 30-Series Keynote Video Link](https://nvda.ws/32MTnHB)\n\n# Ampere Architecture\n\n# [Digital Foundry RTX 3080 Early Look](https://www.youtube.com/watch?v=cWD01yUQdVA)\n\n# [Tomshardware - Nvidia Details RTX 30-Series Core Enhancements](https://www.tomshardware.com/news/nvidia-details-rtx-30-enhancements)\n\n# [Techpowerup - NVIDIA GeForce Ampere Architecture, Board Design, Gaming Tech & Software](https://www.techpowerup.com/review/nvidia-geforce-ampere-architecture-board-design-gaming-tech-software/)\n\n# [Babeltechreview - The NVIDIA 2020 Editor’s Tech Day – Ampere Detailed](https://babeltechreviews.com/the-nvidia-2020-editors-tech-day-ampere-detailed/)\n\n# [HotHardware - NVIDIA GeForce RTX 30-Series: Under The Hood Of Ampere](https://hothardware.com/reviews/nvidia-geforce-rtx-30-series-ampere-details)\n\n# [Gamers Nexus - NVIDIA RTX 3080 Cooler Design: RAM, CPU Cooler, & Case Fan Behavior Discussion](https://www.youtube.com/watch?v=0Y7QhFx6VmI)\n\n# [\\[German\\] HardwareLuxx - Ampere and RTX 30 Series Deep Dive](https://www.hardwareluxx.de/index.php/artikel/hardware/grafikkarten/54038-neue-details-ampere-und-gtx-30-series-deep-dive.html)\n\n# GeForce RTX 30-Series GPU information:\n\n# [Official Spec Sheet Here](https://www.nvidia.com/en-us/geforce/graphics-cards/30-series/compare/)\n\n&#x200B;\n\n||**RTX 3090**|**RTX 3080**|**RTX 3070**|\n|:-|:-|:-|:-|\n|**GPU**|Samsung 8N NVIDIA Custom Process GA102|Samsung 8N NVIDIA Custom Process GA102|Samsung 8N NVIDIA Custom Process GA104|\n|**Transistor**|28 billion|28 billion|17.4 billion|\n|**Die Size**|628.4 mm^(2)|628.4 mm^(2)|392.5 mm^(2)|\n|**Transistor Density**|44.56 MT / mm^(2)|44.56 MT / mm^(2)|44.33 MT / mm^(2)|\n|**GPC**|7|6|6|\n|**TPC**|41|34|23|\n|**SMs**|82|68|46|\n|**TMUs**|328|272|184|\n|**ROPs**|112|96|64|\n|**Boost Clock**|1.7 Ghz|1.71 Ghz|1.73 Ghz|\n|**CUDA Cores**|10496 CUDA Cores|8704 CUDA Cores|5888 CUDA Cores|\n|**Shader FLOPS**|35.6 Shader TFLOPS|29.8 Shader TFLOPS|20.3 Shader TFLOPS|\n|**RT Cores**|82 2nd Gen RT Cores|68 2nd Gen RT Cores|46 2nd Gen RT Cores|\n|**RT FLOPS**|69 RT TFLOPS|58 RT TFLOPS|40 RT TFLOPS|\n|**Tensor Cores**|328 3rd Gen Tensor Cores|272 3rd Gen Tensor Cores|184 3rd Gen Tensor Cores|\n|**Tensor FLOPS**|285 Tensor TFLOPS|238 Tensor TFLOPS|163 Tensor TFLOPS|\n|**Memory Interface**|384-bit|320-bit|256-bit|\n|**Memory Speed**|19.5 Gbps|19 Gbps|14 Gbps|\n|**Memory Bandwidth**|936 GB/s|760 GB/s|448 GB/s|\n|**VRAM Size**|24GB GDDR6X|10GB GDDR6X|8GB GDDR6|\n|**L2 Cache**|6144 KB|5120 KB|4096 KB|\n|**Max TGP**|350W|320W|220W|\n|**PSU Requirement**|750W|750W|650W|\n|**Price**|$1499 MSRP|$699 MSRP|$499 MSRP|\n|**Release Date**|September 24th|September 17th|October 15th|\n\n# Performance Shown:\n\n* RTX 3070\n   * Same performance as RTX 2080 Ti\n* RTX 3080\n   * Up to 2x performance vs previous generation (RT Scenario)\n   * New dual axial flow through thermal design, the GeForce RTX 3080 Founders Edition is up to 3x quieter and keeps the GPU up to 20 degrees Celsius cooler than the RTX 2080.\n* RTX 3090\n   * Most powerful GPU in the world\n   * New dual axial flow through thermal design, the GeForce RTX 3090 is up to 10 times quieter and keeps the GPU up to 30 degrees Celsius cooler than the TITAN RTX design.\n\n# PSU Requirements:\n\n&#x200B;\n\n|**SKU**|**Power Supply Requirements**|\n|:-|:-|\n|GeForce RTX 3090 Founders Edition|750W Required|\n|GeForce RTX 3080 Founders Edition|750W Required|\n|GeForce RTX 3070 Founders Edition|650W Required|\n\n* A lower power rating PSU may work depending on system configuration. Please check with PSU vendor.\n* RTX 3090 and 3080 Founders Edition requires a new type of 12-pin connector (adapter included).\n* **DO NOT attempt to use a single cable to plug in the PSU to the RTX 30-Series**. Need to use two separate modular cables and the adapter shipped with Founders Edition cards.\n* For power connector adapters, NVIDIA recommends you use the 12-pin dongle that already comes with the RTX 30-Series Founders Edition GPU. **However, there will also be excellent modular power cables that connect directly to the system power supply available from other vendors, including Corsair, EVGA, Seasonic, and CableMod. Please contact them for pricing and additional product details**\n* **See Diagram below**\n\n&#x200B;\n\n[Image Link - GeForce RTX 3090 and 3080 Founders Edition Power and Case Requiremen](https://preview.redd.it/zaz57oacflk51.jpg?width=2525&format=pjpg&auto=webp&s=78c93d7a7a7eb33889d897e0776a1f7c369eaa19)\n\n# Other Features and Technologies:\n\n* **NVIDIA Reflex**\n   * NVIDIA Reflex is a new suite of technologies that optimize and measure system latency in competitive games.\n   * It includes:\n      * **NVIDIA Reflex Low-Latency Mode,** a new technology to reduce game and rendering latency by up to 50 percent.  Reflex is being integrated in top competitive games including Apex Legends, Fortnite, Valorant, Call of Duty: Warzone, Call of Duty: Black Ops Cold War, Destiny 2, and more.\n      * **NVIDIA Reflex Latency Analyzer**, which detects clicks coming from the mouse and then measures the time it takes for the resulting pixels (for example, a gun muzzle flash) to change on screen.  Reflex Latency Analyzer is integrated in new 360Hz NVIDIA G-SYNC Esports displays and supported by top esports peripherals from ASUS, Logitech, and Razer, and SteelSeries.\n      * Measuring system latency has previously been extremely difficult to do, requiring over $7,000 in specialized high-speed cameras and equipment.\n* **NVIDIA Broadcast**\n   * New AI-powered Broadcast app\n   * Three key features:\n      * **Noise Removal:** remove background noise from your microphone feed – be it a dog barking or the doorbell ringing. The AI network can even be used on incoming audio feeds to mute that one keyboard-mashing friend who won’t turn on push-to-talk.\n      * **Virtual Background:** remove the background of your webcam feed and replace it with game footage, a replacement image, or even a subtle blur. \n      * **Auto Frame:** zooms in on you and uses AI to track your head movements, keeping you at the center of the action even as you shift from side to side. It’s like having your own cameraperson.\n* **RTX I/O**\n   * A suite of technologies that enable rapid GPU-based loading and game asset decompression, accelerating I/O performance by up to 100x compared to hard drives and traditional storage APIs\n   * When used with Microsoft’s new DirectStorage for Windows API, RTX IO offloads up to dozens of CPU cores’ worth of work to your RTX GPU, improving frame rates, enabling near-instantaneous game loading, and opening the door to a new era of large, incredibly detailed open world games.\n* **NVIDIA Machinima**\n   * Easy to use cloud-based app provides tools to enable gamers’ creativity, for a new generation of high-quality machinima.\n   * Users can take assets from supported games, and use their web camera and AI to create characters, add high-fidelity physics and face and voice animation, and publish film-quality cinematics using the rendering power of their RTX 30 Series GPU\n* **G-Sync Monitors**\n   * Announcing G-Sync 360 Hz Monitors\n* **RTX Games**\n   * Cyberpunk 2077\n      * New 4K Ultra Trailer with RTX\n   * Fortnite\n      * Now adding Ray Tracing, DLSS, and Reflex\n   * Call of Duty: Black Ops Cold War\n      * Now adding Ray Tracing, DLSS, and Reflex\n   * Minecraft RTX\n      * New Ray Traced World and Beta Update\n   * Watch Dogs: Legion\n      * Now adding DLSS in addition to previously announced Ray Tracing\n\n# Links and References\n\n|**Topic**|**Article Link**|**Video Link (If Applicable)**|\n|:-|:-|:-|\n|GeForce RTX 30 Series Graphics Cards: The Ultimate Play|[Click Here](https://nvda.ws/34PDO4L)|[Click Here](https://nvda.ws/2GfLl2B)|\n|The New Pinnacle: 8K HDR Gaming Is Here With The GeForce RTX 3090|[Click Here](https://nvda.ws/2YQiEzH)|[Click Here](https://www.youtube.com/watch?v=BMmebKshF-k)|\n|Introducing NVIDIA Reflex: A Suite of Technologies to Optimize and Measure Latency in Competitive Games|[Click Here](https://nvda.ws/3lyuwzX)|[Click Here](https://nvda.ws/2QHNrKI)|\n|Turn Any Room Into a Home Studio with the New AI-Powered NVIDIA Broadcast App|[Click Here](https://nvda.ws/2QHurvC)|[Click Here](https://nvda.ws/32F9aZ6)|\n|360Hz Monitors|N/A|[Click Here](https://www.youtube.com/watch?v=vAoTsrgfBik)|\n|NVIDIA GIPHY page|[Click Here](https://giphy.com/NVIDIA-GeForce)|N/A|\n|Digital Foundry RTX 3080 Early Look|[Click Here](https://www.eurogamer.net/articles/digitalfoundry-2020-hands-on-with-nvidia-rtx-3080)|[Click Here](https://www.youtube.com/watch?v=cWD01yUQdVA)|\n\n# RTX Games\n\n|**Games**|**Article Link**|**Video Link (If Applicable)**|\n|:-|:-|:-|\n|Cyberpunk 2077 with Ray Tracing and DLSS|[Click Here](https://www.nvidia.com/en-us/geforce/news/cyberpunk-2077-30-series-4k-rtx-on-trailer)|[Click Here](https://www.youtube.com/watch?v=GQKXr9neSNk)|\n|Fortnite with Ray Tracing, DLSS, and Reflex|[Click Here](https://nvda.ws/3jq70Do)|[Click Here](https://nvda.ws/3jwIgcS)|\n|Call of Duty: Black Ops Cold War with Ray Tracing, DLSS, and Reflex|[Click Here](https://www.nvidia.com/en-us/geforce/news/minecraft-with-rtx-creator-worlds-pack-3-free-download)|[Click Here](https://www.youtube.com/watch?v=tZ_IjLt8zDU)|\n|Minecraft RTX New Ray Traced World and Beta Update|[Click Here](https://nvda.ws/3jwIrF4)|[Click Here](https://nvda.ws/2EIazpU)|\n|Watch Dogs: Legion with Ray Tracing and DLSS|[Click Here](https://www.nvidia.com/en-us/geforce/news/watch-dogs-legion-geforce-rtx-dlss-trailer)|[Click Here](https://www.youtube.com/watch?v=ytm2HvLYcmo)|\n\n# Basic Community FAQ\n\n**When is Preorder**\n\nThere is no preorder.\n\n**What are the power requirements for RTX 30 Series Cards?**\n\nRTX 3090 = 750W Required\n\nRTX 3080 = 750W Required\n\nRTX 3070 = 650W Required\n\nLower power rating might work depending on your system config. Please check with your PSU vendor.\n\n**Will we get the 12-pin adapter in the box?**\n\nYes. Adapters will come with Founders Edition GPUs. Please consult the following chart for details.\n\n[Image Link - GeForce RTX 3090 and 3080 Founders Edition Power and Case Requiremen](https://preview.redd.it/zaz57oacflk51.jpg?width=2525&format=pjpg&auto=webp&s=78c93d7a7a7eb33889d897e0776a1f7c369eaa19)\n\n**Do the new RTX 30 Series require PCIE Gen 4? Do they support PCIE Gen 3? Will there be major performance impact for gaming?**\n\nRTX 30 Series support PCIE Gen 4 and backwards compatible with PCIE Gen 3. System performance is impacted by many factors and the impact varies between applications. The impact is typically less than a few percent going from a x16 PCIE 4.0 to x16 PCIE 3.0. CPU selection often has a larger impact on performance.\n\n**Does the RTX 30 Series support SLI?**\n\nOnly RTX 3090 support SLI configuration\n\n**Will I need PCIE Gen 4 for RTX IO?**\n\nPer Tony Tamasi from NVIDIA:\n\n*There is no SSD speed requirement for RTX IO, but obviously, faster SSD’s such as the latest generation of Gen4 NVMe SSD’s will produce better results, meaning faster load times, and the ability for games to stream more data into the world dynamically. Some games may have minimum requirements for SSD performance in the future, but those would be determined by the game developers. RTX IO will accelerate SSD performance regardless of how fast it is, by reducing the CPU load required for I/O, and by enabling GPU-based decompression, allowing game assets to be stored in a compressed format and offloading potentially dozens of CPU cores from doing that work. Compression ratios are typically 2:1, so that would effectively amplify the read performance of any SSD by 2x.*\n\n**Will I get a bottleneck from xxx CPU?**\n\nIf you have any modern multi-core CPU from the last several years, chances are you won't be bottlenecked but it depends on the game and resolution. The higher resolution you play, the less bottleneck you'll experience.\n\n**Compatibility - NVIDIA Reflex, RTX IO, NVIDIA Broadcast**\n\n*NVIDIA Reflex* \\- GeForce GTX 900 Series and higher are supported\n\n*RTX IO* \\- Turing and Ampere GPUs\n\n*NVIDIA Broadcast* \\- Turing (20-Series) and Ampere GPUs\n\n**Will there be 3090 Ti/Super, 3080 Ti/Super, 3070 Ti/Super**\n\nLiterally nobody knows.\n\n**Where will I be able to purchase the card on release date?**\n\nThe same place where you usually buy your computer parts. Founders Edition will also be available at NVIDIA Online Store and Best Buy if you're in the US.\n\n**When can I purchase the card?**\n\n6am PST on release day per NV\\_Tim\n\n**How much are the cards?**\n\n3070 - $499 MSRP\n\n3080 - $699 MSRP\n\n3090 - $1499 MSRP\n\nNo Founders Edition  Premium\n\n**When will the reviews come out?**\n\nSeptember 14th per Hardware Canucks",
    "comments": [
      "The price revelation was insane! I did not expect that at all, AMD will have to do some magic with RDNA 2 if they want to compete.\n\nEDIT: Looks like Digital Foundry already made a [hands-on review.](https://www.youtube.com/watch?v=cWD01yUQdVA)",
      "so no pre order this time, they're just releasing the 17th it seems.",
      "It is so obvious they are not doing this because of supply. They know these things are gonna sell out in minutes. It is gonna be a dog fight for awhile to get one guys.",
      "Didn't expect them to make the 3070 and 3080 cheaper than was rumored, but then again I didn't expect them to make the 3090 *more* expensive than anticipated either. Lmao.. either way I was only planning on buying the 3080 so I guess it's whatever",
      "Remember: Wait for 3rd party benchmarks.\n\nThe claim that the 3070 is \"more powerful than a 2080 Ti\" is *only* with ray tracing and DLSS enabled. A jump in performance with ray tracing on was expected for this generation. We don't know how the new cards stack up against the current gen in non-ray tracing, non-DLSS scenarios. Games have to specifically support both of these features, and many newer AAA games still don't support them. That will change over time of course, but don't buy a 3070 thinking that you're going to get 2080 Ti performance across the board at a fraction of the price, because that's almost certainly not going to be the case.",
      "As mentioned, the 3090 is to replace the Titan branding. So technically it is $800 cheaper than the RTX Titan.",
      "well shit, the 3070 is actually a better value than people expected, while the 3090 is more expensive than expected.\n\nalso if those shader TFLOP numbers are real world full FP performance holy fucking christ this is a massive upgrade beating out pascal.",
      "So now we have to be constantly checking for like a month straight and there is still a slim chance you can get one. Terrible.",
      "They announced the 3090 as if it is a successor to the Titan. If that's what it is we're looking at a $1000 price cut from previous gen.",
      "I mean I am really not sure what people expected? Like we are in the middle of a pandemic and the writing has been on the wall for months that this was going to be the case.",
      "Remember when people said we'd be rioting over the prices?  Peperidge farm remembers...",
      "Still would have been nice to have a preorder even if it takes a month to get in stock. I would like to just have some place in line.",
      "RIP 2080 Ti Resale Value\n\n&#x200B;\n\n\\*Cries\\*",
      "UK Prices\n\nhttps://imgur.com/Y9f6tWt\n\n\n3090 - £1399\n\n\n\n3080 -  £649\n\n\n\n\n\n3070 - £469\n\n\n\n\nScan AIB Cards (thanks u/benzyl-chloride) https://www.scan.co.uk/shop/computer-hardware/gpu-nvidia/all\n\n\nOverclockers AIB Cards https://www.overclockers.co.uk/pc-components/graphics-cards/nvidia",
      "Not gonna lie I was expecting at least 1000$ for the 3080. This is a pleasant surprise",
      "We ARE rioting, just different kind of riot!!!",
      "no, the 3090 was directly compared to the titan if I remember correctly",
      "It’s going to be so hard to grab a card for the 3080 on the 17th..",
      "Just sold mine last night for $850 after hearing the news. Feeling like a genius.",
      "$499 for an equivalent of a 2080 Ti? Dude wtf. If this translates well to the European market that would be completely nuts."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "top",
    "matched_keywords": [
      "3090"
    ],
    "title": "My completed \"please no more upgrades for 3 years\" build. STRIX 3090 + Ryzen 5950x",
    "selftext": "",
    "comments": [
      "I can easily extend this for 10 years, just swapping the vga every 4 or so.....",
      "3 years? you can use that build till it dies homie",
      "RTX 4050ti beats 3090\n\nAyy lmao",
      "4050 Ti beats 3090 at just USD 300\n\n1 month of no available stock later - 4050 Ti costs USD 1500, because BTC hits a new all-time high of 420,069 dollars",
      "I haven't upgraded mine for at least 14 years yet this guy saying 3 years smh",
      "People selling their 3090 for $280 since  performance is roughly the same as 4050ti....",
      "As someone who plays warzone every night and had a 3900x until 2 weeks ago, this is incorrect",
      "sorry, what? sources?",
      "Op is obvy trying to humblebrag. I used a 780 for 7 or 8 years. 3080 will be fine for a long time bud.",
      "9 years here. I got a rtx 3060 last week.\n\nNone of the \"its barely better than a 2080 super\" means anything to me because nobody is selling 2080 supers, and I was using a gtx 660.",
      "Oh no my perfectly functional build has died upon the 4xxx series release.\n\n(I actually expense my GPUs as independent contractor costs, please dont kill me with downvotes)",
      "Ah yes, the half-life 2 killer.",
      "for 3 years? i bought a 3080 and i thought i was good for at least 10 years",
      "NZXT Kraken liquid cooler that's expensive as fuck, but also looks cool as fuck.",
      "Who buys 3900X or 5950X (or Ryzen 9 / i9 in general) for purely gaming?\n\nThat's just retarded imo, a 6 or 8 core CPU would provide almost exactly the same FPS. Not even taking in account that people buying these CPUs are often pairing them with top tier GPUs like the 3090 and play in 4K when CPU literally doesn't matter lol.",
      "What cpu cover is that?",
      "oh boohoo, little baby can't get 200 fos",
      "Amd athlon x2 64\nGeforce 8400 (i think)\n3 gb ram\n\nThese are the only stuff i know about my pc\nAlso a HP case",
      "Yes I need this 3090 for... consulting",
      "4K is the priority, what else? 5950x is gReAT aT lOw sEttIngs, who the fuck plays at low setting with 3090 and with no 4k high refresh rate screen. and wdym 3900x is outdated, get a load of this guy"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "top",
    "matched_keywords": [
      "3090"
    ],
    "title": "I was in line at MC for a 3080, came out with a 3090 (Asus TUF Gaming OC version)",
    "selftext": "",
    "comments": [
      "Nvidia is laughing all the way to the bank regarding 3090s.  If there had been a normal supply of other cards, the 3090 would have barely sold.  Not knocking you OP, we gotta do what we gotta do.  Your 3090 will probably be worth over MSRP for a year, so no biggie.",
      "Lmao I had a similar experience yesterday. Drop by MC to get a USB c cable for android. Lucked out and got the last 3080. With excitement forgot to buy the cable... Oh well.",
      "I wouldn't buy this if the guy in front of me bought the last 3080. However, I don't regret this purchase at all. The card runs smoothly, and temp always stay below 65c",
      "Just download more vram ?",
      "At least a 3090 will hold for much longer with the extra vram over a 3080, so have fun with it !",
      "Lol, oh well indeed in that case",
      "I bought mine for $1,599 plus tax",
      "$1839.99 + tax is rough.  I'm glad I'm not a hardcore gamer.  Having other hobbies is already expensive enough for me.",
      "Doesn't help with my gtx 1060 3gb :((( trying to get a new card in eastern europe is impossible atm, at least for a good price. The official stores that had cards in stock were selling a rtx 3060 ti for 700$+, rtx 3090 for 2300$+. So yeah you can call them official scalpers.",
      "That looks awesome, where did you find the gpu backplate cover?\nWhat is it called? \nThx",
      "Because the guy in front of me bought the last 3080, so I had no option. I didn't want to play the F5 game or waiting anymore.",
      "24 Gigs of ram on a 1500-1800$ + incredible performance is a much needed improvement for someone who could have used a Titan.\n\nSo for certain customers, it's a good deal.\n\nT. 3d Artist",
      "There's a company here in the US called blackout PC parts. Official nvidia partner. They charge 300+ over msrp for cards they bundle with 400 w psus. Like a 1100 3080 with a 450 w bronze psu. Wtf",
      "I wouldn't say much longer, as by the time more than 10gb is \"really needed\", you'd probably have to turn down setting to get good FPS anyhow, thus freeing up VRAM and keeping it under 10gb. In other words, by the time anyone needs over 20b for gaming, these GPUs will not be nearly powerful enough.\n\nI do think it will last a bit longer though, and maybe will lead to a little less tweaking of settings in a few years.",
      "Bundle \"deals\" lol",
      "I bought it from V1 Tech. Mine is Nvidia Claw Spectrum White RGB",
      "That seems closer to msrp, but rediculous for a normal person.  I guess my local microcenter website has a different price.\n\n  I remember back in the day when got an ATI 9800 pro for $369 and thought that was expensive.",
      "Yeah but from a gaming perspective 1500 dollars can get you a decent setup if everything was selling for mrsp",
      "Exactly lmao. What the fuck am I supposed to do with a $400 Chinese psu",
      "> What the fuck am I supposed to do with a $400 Chinese psu\n\nIt's scalping. The other part is worthless, but then they can't be accused of scalping since the extra price is not for the GPU but for the shitty PSU."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "top",
    "matched_keywords": [
      "3090",
      "rtx 3090"
    ],
    "title": "NVIDIA RTX 4070 Ti is 5% faster than RTX 3090 Ti in leaked OctaneBench test",
    "selftext": "",
    "comments": [
      "The retailers in Canada are selling the 3090 TI for $2599.99, the cheapest today is $2050\n\nThe 4080 is $1699.99 in the same store.\n\nThere's something very strange and very wrong with this picture, previous gens cards prices are barely moving. $600+ for a 3060? Get fucked.",
      "Yep.\n\n\nAlso, when the 4090 is the best price for performance option, we have a problem.",
      "Cards DOA if it's 899, ah who am I kidding there will be a smorgasbord of people posting \"Just upgraded from a 30X0!\" builds",
      "If you own a 30x0 card, I'm begging you to not buy this generation unless the prices actually come down from last gen. Please don't further enable Nvidias shit pricing",
      "Honestly, these kinds of posts are so bizarre to me. Are we supposed to cheer a random person that they've spent money? Do they want us to be envious? Jealous? Why do people need to post every pointless bit of their lives online. Sorry for rant :(",
      "Wat you don't wanna see my 4090 seat belt buckled to my 99 Honda Civic?",
      "Octane performance is always faster than game performance, as its not held by CPU and other stuff. In a way, it reflects true computing performance of the GPU better than games, but obviously, if you care only about games, awesome Octane numbers wont help you.\n\nI presume 4070Ti scores about 720 points then - since vanilla 3090 is cca 650. Not bad. 3090 would still be better choice, if priced similarly, cause 24GB of vram.",
      "Bro seriously?!? You could have easily gotten $100+ more for that card.",
      "So the 4080 is 35% faster than 3090 Ti in this benchmark, but according to reviews it's roughly 25% faster in games.\n\nSo in non-DLSS 3 games the 4070 Ti will more than likely compete with the 3080 Ti/3090 rather than the 3090 Ti.",
      "I just sold my old 3060 for $250....",
      "I think the scenarios where 24 gigs of vram are useful are fair bit more niche than frame generation plus better ray tracing performance.",
      "depends where you are? I see some new 3060ti going for 400 in USA. can't say I know anyone that would dish out 350 for a 3060",
      "Nvidia is really just gonna give us 1 to 1 price to performance increase this generation........ \n\nWelp hopefully the 4070ti flops like the 4080 too so we can get price drops next year",
      "Yeah I don't get anything that is happening now. You can’t find any cards in stores except for 3060 and 3060ti and those are ridiculous expensive still for some reason and nobody wants them for those prices. They said after mining that there would no longer be gpu shortages yet it’s as bad now or worse than it was a year ago. I want a 4090 and have only been able to find a 4080 which just isn’t cutting the mustard and is going back soon. Still no luck 3-4 months later after launch finding one and even 4080s fly off the shelves in the states. Once the 3000 series glut was gone they said we’d start seeing 4090s but those have been gone for a month or more now and still ain’t shit on the shelves.",
      "Oh I won’t. Consoles are the target for most games anyways. 30x0 will be fine until ps6",
      "So basically you can get that performance with an overclocked 3090 and also have double the vram",
      "Scalpers/ex-miners need to cut their losses and move on. There is no excuse for any 3000-series card, in any configuration, selling for more than a 4070ti, yet if you look online, you routinely find people doing just that, likely trying to scam unsuspecting victims. It's despicable.",
      "not everywhere, in Spain (like in many other countries) you can buy a 1390€ 4080, but the cheapest 4090 would be 2000€, 43% more expensive for around 40% more performance, if you're lucky, actually most 4090s are priced 2100€+",
      "If Nvidia can charge $1200 for the 4080 and people in this sub are showing it off in their build, in *this* sub after swearing it's an awful price point, what makes you think 4070 TI will cost just $700?",
      "Generally speaking, flagship products don't offer the best price to performance. That's usually for midrange products"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "30",
    "tier": "top",
    "matched_keywords": [
      "3090",
      "rtx 3090"
    ],
    "title": "RTX 3080 Launchday Thread - Part 2",
    "selftext": "# Part 3 here: [https://new.reddit.com/r/nvidia/comments/iywmsa/rtx\\_3080\\_3090\\_launchday\\_thread\\_part\\_3/](https://new.reddit.com/r/nvidia/comments/iywmsa/rtx_3080_3090_launchday_thread_part_3/)\n\n# Latest Update - September 21, 2020 @ 12:15pm Eastern\n\n# Update from NVIDIA - [Link Here](https://new.reddit.com/r/nvidia/comments/ix3aes/update_from_nvidia_geforce_rtx_3080_launch_what/)\n\nToo long to quote. Please visit link above.\n\n&#x200B;\n\n# Manuel from NVIDIA - [Link Here](https://www.reddit.com/r/nvidia/comments/iuut2l/rtx_3080_launchday_thread_part_2/g5ouzuc/)\n\n>I can't comment for our partners but we will have more cards next week. Users who previously signed up to be notified but did not get a chance to place an order will receive an email when the store has been updated with additional GeForce RTX 3080 graphics cards.\n\n# Manuel from NVIDIA - [Link Here](https://www.nvidia.com/en-us/geforce/forums/geforce-graphics-cards/5/398210/how-does-doing-everything-humanly-possible-to-stop/2827218/)\n\n>We are not ignoring the Captcha request. I have passed on the feedback from the community regarding Captcha to the team that manages the NVIDIA Store.\n\n# Update from NVIDIA - [Link Here](https://www.nvidia.com/en-us/geforce/forums/geforce-graphics-cards/5/398186/rtx-3080-nvidia-store-availability/)\n\n>This morning we saw unprecedented demand for the GeForce RTX 3080 at global retailers, including the NVIDIA online store. At 6 a.m. pacific we attempted to push the NVIDIA store live. Despite preparation, the NVIDIA store was inundated with traffic and encountered an error. We were able to resolve the issues and sales began registering normally.  \n>  \n>To stop bots and scalpers on the NVIDIA store, we’re doing everything humanly possible, including manually reviewing orders, to get these cards in the hands of legitimate customers.  \n>  \n>Over 50 major global retailers had inventory at 6 a.m. pacific. Our NVIDIA team and partners are shipping more RTX 3080 cards every day to retailers.  \n>  \n>We apologize to our customers for this morning's experience.\n\n&#x200B;\n\n# Personal Message from r/NVIDIA\n\nHi guys, I don't know where to start but I think an apology is a good start. I'd like to apologize for the state of the subreddit today. I can't stress enough that today's measure was the last resort. I've gone through 3 launches with this community and each have its challenges and share of issues but what happened today was truly unprecedented and never in a million years I could imagine what happened. There was just no way for us to keep up with everything without the measures we took. This is not ideal so again, I'm sorry.\n\nAs someone who's looking forward to purchase RTX 3090 next week myself, today's event really concerned me and I can definitely sympathize with y'all. I really hope NVIDIA gets their shit together before next week.\n\nThat said, I'd like to outline the path we're taking to restore the subreddit:\n\n1. The old \"RTX 3080 Launchday Thread\" will be locked and redirected to this one. That thread has over 35k comments and it's overdue for a new one\n2. This thread will be the new hub for discussion regarding various launchday madness.\n3. All launchday related discussion (posts and comments) must be contained here. Anything else will be removed.I will be sure to forward this and the previous thread to NVIDIA.\n4. Newly posted threads on /new will be unlocked with the understanding that the comments will be on topic. **PLEASE DO NOT POST LAUNCHDAY RELATED COMMENTS ON THOSE THREADS. ESPECIALLY THE DRIVER POST.**\n5. Subreddit posting will be restored soon after. This is contingent on the regular threads unrelated to launch are **not being spammed with launchday comments**.\n\n**Lastly, any updates from NVIDIA will be added to this thread. Please keep an eye on this thread.**\n\nP.S. Subreddit posting has been enabled since last night (Thank you for keeping the comments on topic). Also, please watch [this video from Gamers Nexus for some perspective about the launch](https://youtu.be/qHogHMvZscM)\n\n**If you’re interested in Founders Edition or partner RTX 3080 cards from various etailers, this can be done via NVIDIA site** [**here**](https://www.nvidia.com/en-us/geforce/graphics-cards/30-series/rtx-3080/) **and click \"See all buying options.\" when it's available to purchase.**\n\n**Best Buy Online in the US** will also carry RTX 3080 Founders Edition. Local store may have some stocks in the US but no guarantee.\n\n**Subreddit Protocol**:\n\n* **Launch Day Megathread** will serve as the hub for discussion regarding various launchday madness. [You can also join our Discord server for discussion!](https://discord.gg/nvidia)\n* Topics that should be in Megathread include:\n   * Successful order\n   * Non successful order\n   * Brick & Mortar store experience\n   * Stock Check\n   * EVGA step up discussion\n   * Any questions regarding orders and availability\n   * Any discussion about how you're mad because you didn't get one\n   * **Literally everything about the launch**\n* **ALL other standalone launch day related posts will be removed.**\n* **There will not be any Megathread for the third party card reviews**. They can and should be posted individually.\n* **Subreddit may go on restricted mode for a number of times during the next 24 hours. This may last a few minutes to a few hours depending on the influx of content.**\n\n**Reference Info:**\n\n[RTX 3080 Review Megathread](https://new.reddit.com/r/nvidia/comments/itw87x/geforce_rtx_3080_review_megathread/)\n\n[RTX 30-Series Information Megathread](https://new.reddit.com/r/nvidia/comments/iko4ir/geforce_rtx_30series_ampere_information_megathread/)\n\n# Remember not to buy from scalpers (fuck em). If you are buying from website that allows 3rd party sellers (e.g. Newegg/Amazon), please make sure you are buying from said retailer. Anything else means you're buying from scalpers. Do not buy from scalpers. Treat the product as out of stock and wait if the official retailers are not selling them.",
    "comments": [
      "We so pissed off we gone into part 2 bois",
      "Fuck I waited outside at Walgreens and they had no idea what I was talking about.",
      "I’m not mad that I didn’t get the card, I’m mad that I didn’t even get a CHANCE to get the card",
      "Well guys, I was one of those idiots who stood in line all night at Microcenter. I arrived at 11 pm and was around 19th in line. 2 people bailed around 0030 so I’m 17th. 3 am rolls around and we have about 25 deep. Alarm goes off at the location and so the cops and the microcenter manager shows up. He gives everyone his most recent update which is that this location will have 12 cards. He also updates what stock it will be which is apparently MSI ventus and ASUS Tuf. 4 more people leave so I’m lucky #13. I asked the manager, is there any point in me or the guys behind me sticking around? He was like probably not, I would go home and sleep. At this point, I’m like fuck it, I will roll the damn dice. I’m here after all. Most the line behind me takes off. An hour later, the line continues to grow regardless of the information that was bestowed upon us. 8 am rolls around and they’re passing out vouchers. The information was correct. I’m lucky #13 and no voucher. I’m crushed. The manager tells me to put my name and number down on a list and maybe there’s a slight chance they get more in that day. They’ll call me if that happens. Done deal, I’m #1 on this damn pity list. I go home annoyed with myself and the entire situation and pass the fuck out. Wake up to a call 2 hours later. Not only did they get at least one more card in for me, but it’s the EVGA Ultra. Bottom line: Never give up, never surrender.",
      "\" We were able to resolve the issues and sales began registering normally. \" \n\nMY AAAAAAAAASS.",
      "So ironic that the proclaimed 'leader in AI' can't put a simple captcha on their second biggest launch day of the year.",
      "For all of you who don’t typically participate in high demand “hype” drops like this: welcome to the show. This is what it’s like - it’s literal cancer. Bots are taking over completely. Real humans have a better shot at the powerball lottery than securing a “hype” drop manually. \n\nThe people who purchased these cards are most likely completely unfamiliar and uninvolved with PC gaming or PC’s in general, and only purchased because of the resale value. Look it up, a group of botters purchased hundreds of cards just to resell. One person in specific purchased over 45 cards for himself to resell. I imagine it’s just another group of losers trying to make a quick buck without leaving their mom’s home and working an actual job. What you imagine these freaks like, is probably the way they truly are.\n\nDo not support the resellers. The only way they make their money is if we buy them. If we don’t, they’ll have to eat the thousands of dollars they spent, lower their prices, or somehow return them to NVIDIA to be relisted for retail.\n\nEverybody stay strong. I can’t stress this enough. It’s beyond important that nobody purchases from any of these resellers. If they see sales, others will follow and jack up the prices. If the resale value plummets, or sales aren’t booming, the likelihood of the restocks being botted drop tremendously. Our goal is to purchase directly from retailers at retail price. I don’t care if you find a card $200 over retail. Do. Not. Purchase. It creates a resale market for these cards, which promotes botting, backdooring, scalping, etc. If the resale market dies, the retail market will rise. It’s the only way to combat this. I want one of these beasts in my PC just as bad as the other guy, and we’ll get there - but not like this. I’ll say it again, do not purchase from resellers. Please.\n\nEDIT: Thank you so much for the gold kind stranger",
      "I went to microcenter here in Dallas right after the shit show, an employee told me they only had 18 cards. The first guy in line apparently wanted to buy all 18 of them. Of course, they only allow one per person, but this asshole didn't give a fuck. \n\nThese dickweeds are willing to do this shit IRL, they have no respect for the game!",
      "The least nvidia could do is stop acting like they didn’t see this coming, “unprecedented demand”, give me a fucking break",
      "fuck scalpers all the homies hate scalpers",
      "Shoutout to all my people who also need this card for a brand new build.\n\nLooks like we gotta hold out and wait.",
      "Yeah, so updating the drivers on my graphics card nearly requires launching and signing into their client app, which every time requires me to Prove I'm a Human, while I am _seated at my computer_ by playing pick the traffic lights. But the payment page for the most hyped hardware release in years eXperieEnceD UnPrECEDented dEmaND with zero countermeasures.",
      "i love it when mods make a megathread and lock the sub so none of this criticism can hit r/all",
      "Well, I saved money for nine months, followed the card rumors all summer, watched the reveal, waited patiently for weeks as I strategically planned this day, and it was all ruined due to corporate incompetence and greed. \n\nFuck scalpers, fuck nvidia, and fuck these retailers. I'm exhausted, I'm going to bed.",
      "This thread is honestly like therapy for me.",
      "Exactly. It’s like we were all lined up for a race waiting for the gun shot and then the person with the gun just turns to us all and says it’s over without ever firing.",
      "Amazon USA is the biggest puzzle of 2020, everyone else worldwide started selling/getting soldout expect the biggest online store Amazon being silent/Not selling still",
      "Really starting to think bartering my grandmother’s insulin for this launch was a mistake. Gonna miss you, mee-maw :(",
      "Guys check Nvidia reps message, no new FE on Nvidia site until Monday at the earliest. [https://www.reddit.com/r/nvidia/comments/iuut2l/rtx\\_3080\\_launchday\\_thread\\_part\\_2/g5ouzuc/](https://www.reddit.com/r/nvidia/comments/iuut2l/rtx_3080_launchday_thread_part_2/g5ouzuc/)",
      "Day one poll results:   Want to help me see how much damage was caused by bots? Take the poll here: [**https://www.strawpoll.me/20958772/r**](https://www.strawpoll.me/20958772/r) \n\n3,830 people have taken my straw poll so far (with bot protection enabled), only 2% bought the FE 3080 accounting for 74 people and only 6% bought an AIB 3080 accounting for 212 people. That's just ridiculous, but wait it gets worse. 18% of people got the buy button but it didn't work accounting for 689 people (including me), 23% of people got the buy button but it was sold out when they went to check out, accounting for 901 people, and last but certainly not least is 51% of people didn't even get a buy button, accounting for 1,961 people. Now that is just insane only 8% of people even got to buy a 3080 out of 3,830 people."
    ]
  }
]