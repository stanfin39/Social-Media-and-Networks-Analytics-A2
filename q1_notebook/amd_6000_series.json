[
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6500xt"
    ],
    "title": "6500xt hits 17 FPS in Far Cry 6",
    "selftext": "",
    "comments": [
      "I mean, it's a pretty good upgrade. If you're upgrading from a GT 710.",
      "the human eye can't see more than 10 fps or 4gb ram",
      "I don't understand the decision-making process behind this graphics card. Amd has not only shot themselves in both knees, but also in ours.",
      "AMD's answer to the 1030 DDR4 edition",
      "$200, huh?",
      "I disagree.\n\nSome models of the GT 710 support 3 display outs, the 6500 XT only seems to support 2.",
      "Literally 499‚Ç¨ in the Netherlands...\n\nI'm fucking dying üòÇüòÇüòÇ\n\nEdit: there's a 399‚Ç¨ model in stock today! What an amazing bargain!!!!",
      "It's 360 Euros, I found the Sapphire model in stock in eastern Europe.",
      "This card can't be any more degrading huh?",
      "I really don't know why they only put 4 lanes and a 64 bit bus. It would have actually been an ok/decent card with even just 8 lanes. Everything else I would've forgiven if not for the 4 lanes.",
      "3080 12GB is faster than 3080 Ti and 3090? Lol",
      "Nvm guys, I found one for 400 euros... it's unbelieveable.",
      "This is a 6200xt in a sane world",
      "1030 D4 launched at $70 back then",
      "It's because the die is tiny.  Navi24 is only 107mm^2 vs 232mm^2 for Navi 23.  That's less than half.\n\nCheckout the annotated Navi 23 die shot (32 CUs), draw an imaginary line down the middle and you'll see why L3 cache and PCI lanes were cut in half:\n\nhttps://pbs.twimg.com/media/E20kNTuX0AMwsKg?format=jpg&name=large\n\nThis would have been a great low cost (<$150) GPU to market alongside Ryzen 6000 APUs (PCIe 4.0, built in HW encoders), however those are only coming to laptops this quarter.\n\nFor desktop they *should* have targeted a slightly larger die size to accommodate 8x PCI lanes, the encoders, and maybe 32mb of L3 cache.  Then it would have been worth the asking price (in this market).\n\nEdit: Navi14 annotated die shot for comparison:\n\nhttps://pbs.twimg.com/media/EPJshhYXsAUAfYI?format=jpg&name=large\n\nNavi 14 (AMD smallest GPU die last gen) is 47% bigger than Navi 24.  Navi 24 is the first to use the 6N process (18% higher density).",
      "it doesn't really matter, the human eye can't see more than pcie 3.0 anyway",
      "ive been laughing at this for 5 minutes straight",
      "The gtx 1650 super also has 4 GB the bigger issue is the pcie bandwidth. To quote gamers nexus you can sacrifice memory amount or bandwidth but never both",
      "They really should have sold this as 6300 XT at $150. It‚Äôs still pricy, but I bet people would be a lot less upset.",
      "[There are actually people who defend this shitty product](https://www.youtube.com/watch?v=ICnz6E7vux0)"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6500xt"
    ],
    "title": "AMD‚Äôs $199 Radeon RX 6500XT officially gets ‚Ç¨300/324 MSRP from ASUS [Videocardz.com]",
    "selftext": "",
    "comments": [
      "AMD: $200\n\nAIBs: $300\n\nScalpers: $400\n\nConsumers:\n\n‚¢Ä‚£†‚£æ‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚†Ä‚†Ä‚†Ä‚†Ä‚£†‚£§‚£∂‚£∂  \n‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚†Ä‚†Ä‚†Ä‚¢∞‚£ø‚£ø‚£ø‚£ø  \n‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ß‚£Ä‚£Ä‚£æ‚£ø‚£ø‚£ø‚£ø  \n‚£ø‚£ø‚£ø‚£ø‚£ø‚°è‚†â‚†õ‚¢ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚°ø‚£ø  \n‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚†Ä‚†Ä‚†Ä‚†à‚†õ‚¢ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚†ø‚†õ‚†â‚†Å‚†Ä‚£ø  \n‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ß‚°Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†ô‚†ø‚†ø‚†ø‚†ª‚†ø‚†ø‚†ü‚†ø‚†õ‚†â‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚£∏‚£ø  \n‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£∑‚£Ñ‚†Ä‚°Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚¢Ä‚£¥‚£ø‚£ø  \n‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚†è‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚††‚£¥‚£ø‚£ø‚£ø‚£ø  \n‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚°ü‚†Ä‚†Ä‚¢∞‚£π‚°Ü‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚£≠‚£∑‚†Ä‚†Ä‚†Ä‚†∏‚£ø‚£ø‚£ø‚£ø  \n‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚†É‚†Ä‚†Ä‚†à‚†â‚†Ä‚†Ä‚†§‚†Ñ‚†Ä‚†Ä‚†Ä‚†â‚†Å‚†Ä‚†Ä‚†Ä‚†Ä‚¢ø‚£ø‚£ø‚£ø  \n‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚¢æ‚£ø‚£∑‚†Ä‚†Ä‚†Ä‚†Ä‚°†‚†§‚¢Ñ‚†Ä‚†Ä‚†Ä‚††‚£ø‚£ø‚£∑‚†Ä‚¢∏‚£ø‚£ø‚£ø  \n‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚°Ä‚†â‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚¢Ñ‚†Ä‚¢Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†â‚†â‚†Å‚†Ä‚†Ä‚£ø‚£ø‚£ø  \n‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ß‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†à‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚¢π‚£ø‚£ø  \n‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚†É‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚¢∏‚£ø‚£ø",
      "Honestly not surprised",
      "Its time to re-paste my RX580 for long run......",
      "This is an insultingly bad price for a very weak card. Even in an inflated market I'd rather pay more to get more. I truly feel for anyone that 'needs' a video card right now, any video card.",
      "#RX580gang\n\nBtw the thermal pad size is 0.5mm right? And what paste do you recommend",
      "Gamers have been appalled from the onset. Ain't shit changed. Everyone gets on Reddit and bitches about the prices then snags the first available card and posts \"Finally got one at MSRP\". MSRP is $2,000 so it don't mean shit these days.",
      "The problem is that you won't be able to upgrade the graphics card in the future.  You won't be able to upgrade to... to... haha...\n\nWho am I kidding?  Welcome to 2026.  Everyone is mining Cryptoethercoin.  It's $2,500 for an RTX 5050 Super Ti 24 GB Edition.  HashBlockMiner has a 93% unlock rate on LHR v4.  Consoles are being scalped for $1,200 and people are now mining with their Teslas.  AMD just released the RX 7100 for $400 with 1 GB of VRAM.  Slogan: \"Miner-Proof!  Perfect for 720p gaming!\" ^with ^FSR ^enabled  \n\nScrew it.  Laptop life ain't bad, mate.",
      "I guess Hardware Unboxed was pretty spot on: [https://youtu.be/jhtpUByiuIA?t=357](https://youtu.be/jhtpUByiuIA?t=357)",
      "Manufacturers and vendors have been absolute cunts. One of the biggest vendors in germany has 30 different RX cards in stock and hundreds, if not thousands sold, but they still don't budge in regards to price. No vendor wants to make the first step. They much rather comfortably scam you. This goes on for weeks. chip shortage my ass",
      "Yeah, why would they price it at $199 if they can sell it at $300? It's not like there are any alternatives. As long as mining+ship shortages is keeping all the GPUs pricing high, they can get away with it.",
      "This 4GB piece of e-waste is useless to the miners. Doesn‚Äôt seem useful to the gamers either...  Judging by the lackluster performance of the 6600/XT, this thing will barely beat a 6-year old GTX 1070, which at least has 8GB memory and is useful for mining. 6500XT is a $400-$500 display output.",
      "300‚Ç¨ to play 1080p medium/low settings? Just buy an Xbox Series S at that point, those are fairly easy to find.",
      "and where are all those  who kept saying  \"this card will at least be MSRP\" \"We should be glad AMD cut it down so much\" \"they made it bad so we could get it at msrp\" clowns\n\nThis is a surprise to no one, a garbage card at a garbage price.",
      "I sell a lot of PCs in my area, and a local kid heard about me from a friend who bought a PC from me. He reached out looking to spend no more than $500 on a PC. I somehow managed to snag a 980 Ti Founder's for $175 from a Facebook group, and built the PC around that with a 4790K, Z97 motherboard, 16GB RAM, 1TB SSD, 1TB HDD, nice case with lots of RGB. I even made money on it. I hope he knows how good of a deal he got in the current market lol",
      "Prices will drop when people quit buying. \n\nAnd with gamers appalled by the price and  poor mining performance that might happen...",
      "i dont think we will ever be able to upgrade anymore. this might be the end of pc gaming for many folks that cant take out 1k out of their wallets for a fucking gpu alone",
      "I believe so. I fixed a friends 580 by using the thermal pads from an asus motherboard m.2 thermal pads\n\nMx4 or attic silver 5 are my recs",
      ">attic silver\n\nWhy yes I still have tubes of thermal paste from the late 90s",
      "My friends all laughed when I bought a new  RTX 2080Ti for 800 euro a month before RTX30XX launched. Shop was trying to dump old stock expecting it to become unsellable. I bet they regret that now!\n\nMy 2 pc now sport a 2080Ti and 1080Ti and with current prices I'll be using both for a long time.\n\nI refuse to fund scalpers and now the AIBs have started acting like scalpers too. At this point I wont buy their overpriced products either.\n\nAMD seems to be the only one half decent in their own online shop. When supply gets to normal I'll buy directly from them and the AIBs can suck something of mine.",
      "THE 1070 IS ALREADY 6 YEARS OLD??\n\nWow do times go by quickly"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "rx6600"
    ],
    "title": "Upgraded from Rx580 to Rx6600 after 6 years of usage; I love these budget graphic cards",
    "selftext": "",
    "comments": [
      "The Rx6600 is Rx580's true spiritual successor. \n\nTruly the best budget card you can buy in the current market, where good budget cards are in extinction.",
      "And it was an upgrade from what she had.  ![gif](emote|free_emotes_pack|grin)",
      "I just did something similar.  Went from a RX 480 to a 6600XT that I bought off of Marketplace.  Gave the 480 to my daughter to replace a potato she had in her PC.",
      "6650xt can be had for about 210 as well.",
      "It's about 6020 of a difference.",
      "Sure man, let's just build 7800X3D/4090 builds for everyone.\n\nOh your 10 year old sibling/kid wants to play Roblox on a 1080p 60hz display? You need at least a 4070Ti Super for that. \n\nYou want just a basic PC that can browse the web and play extremely light games? Sorry man you need 16 cores and at least a 7800XT.\n\nThe 2nd PC you see in my flair is what I made for my younger brother who's 10. For what he plays that RX 6600 is overkill. You heard me right, that card is overkill.\n\nRX 480 is still a viable GPU as long as you don't do much with your system. If you just wanna browse the web and play really easy to run games like most kids do it is still plenty of power.\n\nHeck I have an old R9 290 laying around here and I could comfortably play through the whole story of CP2077 at 1080p low preset on that thing.\n\nYour comment is pure elitism and as someone who grew up scraping together hardware just to play what  games I could I hate it a lot.",
      "I don‚Äôt think anyone would argue it‚Äôs a good GPU, but it‚Äôs fine man.\n\nIf you‚Äôre not playing BM:Wukong or God of War etc‚Ä¶ you can definitely get away with a 580/480, especially if it‚Äôs the 8gb‚Ä¶ and definitely use FSR.\n\nWatched a JayzTwoCents video recently where he used a 980 and ran cyberpunk. With medium-high settings and FSR 2.0 quality @ 1080p, he was getting ~70 fps. A 580/480 can probably get 60 frames depending on CPU and settings man. And if you‚Äôre only playing Esports titles and games like Minecraft, terraria? Defo good enough.\n\nA lot of people still use the 1060 6gb‚Ä¶ the 580/480 is better than or very similar to that.\n\nEdit: guy above me edited his comment, adding the (not considering esports titles) after my comment was made.",
      "I just went from a 1060 6gb to a 6600, life is good",
      "In Europe you usually pay 250+ compared to the 190‚Ç¨ to 210‚Ç¨ for an 6600.",
      "What everybody should be buying! Capable, inexpensive, and power efficient!",
      "Dude, i use a handheld pc with a 780m as its gpu, which is way worse than a 480. 480 is still a damn good gpu for the price\n\nAnd before you say \"ah but you only play esports game\"  no i dont. I play games like cyberpunk, doom eternal, elden ring, forza horizon 4/5, ghost of tsushima, and satisfactory (ue5 title) and run at a very playable 50+ fps\n\n480 is still good but might not be up to your \"120fps is only just playable\" standards",
      "Yeah man, I agree, he and his daughter are what‚Äôs wrong with PC gaming! I just talked to CD Projekt Red devs and they said they‚Äôre cancelling 4k textures and ray tracing in Witcher 4. \n\nAll because Perpetual98‚Äôs daughter still uses an RX480, I can‚Äôt begin to express how upset I am!!!",
      "Spiritual successor that unfortunately took 2 years to actually get to a price point where it can be said spiritual successor",
      "Wat fucking elitism. Polaris cards like the 480/580 and even 470/570 are still capable to run most recent games even on low medium settings you dont need to play at ultra 4k settings and raytracing to enjoy a game.",
      "using 6600 now, served me well. Will only upgrade when when I can get double performance for good price($3-400 USD)",
      "i recently got RX 6600 XT nitro+ for 170 eur from ebay. The jump from my old MSI RX 480 is immense. The card is so damn silent under load.",
      "Famous potatoes",
      "lol went from 1660 to rx6600 yesterday too !  it's such a huge jump for me",
      "Budget cards? They cost twice as much of what they are worth these days.",
      "I was looking into this card last night and saw people were able to get this card down to 50w on the core while losing only about 15% performance from stock. Absolute craziness in terms of efficiency"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6600xt",
      "6600"
    ],
    "title": "Deeply regret buying a 6600xt. The card have a lot of issues that no reviewer talks about",
    "selftext": "There is not a single stable driver for this card at the moment, all of them comes with issues like freezing, restarting, black screens, etc. All of the issues are related to windows power saving mode.\n\nWhenever your display goes into power saving mode (When the \"no signal\" message appears on display, after some time of inactivity), you will have some issue.\n\nThe only workaround atm is to set the \"Turn off display after\" in windows power settings to \"Never\".  \n\n\nI'm SHOCKED about how many people have this problem and AMD doesn't even recognize as a known problem in the last driver patch notes (21.9.2)  \n[https://community.amd.com/t5/graphics/problem-with-my-rx-6600-xt-nitro-and-it-s-weird-behavior/m-p/489727](https://community.amd.com/t5/graphics/problem-with-my-rx-6600-xt-nitro-and-it-s-weird-behavior/m-p/489727)\n\n[https://community.amd.com/t5/graphics/amd-radeon-6600xt-restart-pc-when-screen-timeout-is-turned-on/m-p/485223#M78484](https://community.amd.com/t5/graphics/amd-radeon-6600xt-restart-pc-when-screen-timeout-is-turned-on/m-p/485223#M78484)\n\n[https://community.amd.com/t5/graphics/rx-6600xt-rebooting-pc-after-display-goes-into-power-saving-mode/m-p/490282#M79535](https://community.amd.com/t5/graphics/rx-6600xt-rebooting-pc-after-display-goes-into-power-saving-mode/m-p/490282#M79535)  \n[://www.reddit.com/r/AMDHelp/comments/p5aa4w/pc\\_freezes\\_after\\_sleep\\_mode\\_with\\_rx\\_6600\\_xt/](https://www.reddit.com/r/AMDHelp/comments/p5aa4w/pc_freezes_after_sleep_mode_with_rx_6600_xt/)  \n\n\nI hope that AMD are already working on a fix for these issues...\n\nSpecs:\n\nCPU: R7 3700x\n\nMB: Asrock b450m Steel Legend\n\nRAM:16gb (8x2) XPG D41 Spectrix\n\nPSU: XPG CORE REACTOR 750W\n\nGPU: POWERCOLOR RED DEVIL 6600XT (21.8.2 WHQL Driver)\n\nEverything stock, including RAM.\n\nEDIT: I \"fixed\" the issue by disabling ULPS. However, i need to choose what function my pc needs the most: If i disable ULPS, the screen can turn off and be in idle mode for days just fine, BUT, if i do that, everytime that i suspend the computer, it comes back with a Driver Timeout message displayed by AMD Software.",
    "comments": [
      "RX5600xt launch experience",
      "Recently bought MSI 6600 xt gaming x, been working flawlessly with a qled tv since I got it.\nEven when the TV turns off/power saving mode and turns it works without a hitch or restarts.\n\nSorry you are having issues with yours.\n\nAnd probably why reviewers dont mention it is because they might not experience it?",
      "The 5700xt too.\n\nSource: used to own one",
      "I was looking for this comment. Man that card had serious driver issues",
      "I'm strongly suspecting some PCIe4.0 compatibility issue. Some B450 \"beta\" bioses accidentally enable PCIe 4.0 on the primary x16 slot which can cause major issues since the most B450 boards are 4 layer PCB without proper signaling for PCIe 4.0. Given that 6600 XT is a gen 4 GPU it'll force PCIe 4.0 if it's available. \n\nTry checking which PCIe version is used by the gpu using gpu-z. Try also checking the bios and see force PCIe 3.0",
      "I have a S. Nitro 5700XT since their launch day and didn't have a single driver issue, some games weren't working like Fortnite which was fixed out quickly and also had the same bugs as others like Guildwars 2 but other DX9 games working fine, really weird experience for a lot of people :/ Even faulty powerbrick extensions caused peoples GPUs to act up.",
      "Oh my god, I HAD THIS EXACT ISSUE! Drove me absolutely mad for a few weeks.\n\nReturned the card, no fault found. How I fixed it? I switched it over from the x570/3600 to an intel 11600k system. Not a single problem since.\n\nPlease tell which exact mobo + CPU you have?",
      "Bought my 6600 XT at lauch day. No issues, working perfectly with all drivers. Updated to 21.9.2 yesterday still no issues.",
      "When making such a post, you should elaborate a lot more on your setup: what are your system specs? Was the system stable prior to installing the new GPU? If it's a new build, what PSU and memory kit do you have? Have you ensured a fresh, clean installation of Windows? Cables? Have your tried different cables or tested with an alternate GPU to confirm whether the issue persists?  \n  \nJust crying about a problem and providing no context is seriously lame and shouldn't be allowed.",
      "yeah i think this scenario probably won't happen to a lot of reviews since they'll be using the card a bunch as they run through their benchmarks, so they probably will rarely, if ever, get to the point where their system idles long enough to go into power saving.",
      "I have two 6600XTs (My PC and my wife's) and zero issues to complain about. I use driver 21.8.2 for both systems. They run all games throw at them with rock solid stability, not a single crash, black screen or anything of the sort whatsoever. Before these 6600XTs, I had 3 Nvidia cards in a row and I can say that they feel as stable as Nvidia cards. Maybe overclocking, undervolting and tweaking in general I would give an edge to Nvidia. But for general play, I think AMD has done a hell of a job to achieve this level of stability that I am experiencing.\n\n\nAs for people who regret buying a 6600XT, the solution is simple: ebay it. You might even make a small profit.",
      "Well if your problems go away when u disable screen sleep, maybe the problems are Windows related.",
      "Yeah, it is kinda weird how some people have had 0 issues since launch, while others experience so many bugs. In my case, the entire system would crash and reset randomly under load and some games didn't launch at all (e.g. Hitman). Hopefully AMD will resolve the issues with the current gen quickly enough.",
      "Some other user here told me to force pcie3 on bios, i did that and pc is idling for 1 and a half hour, so far so good.. usually it would take less than 15 minutes to restart when monitor turned off.",
      "You say that, but I got a 3080 a few months after launch and it too had wake/sleep issues and also had some bug where it would freeze up loading a webpage randomly.  It all got fixed with a month or two after a number of updates, but still Nvidia isn't perfect either.",
      "I got a red devil 5700xt near launch, and was a nonstop poster on here as well as r/amdhelp As a sysadmin, I was sure that it was a \"me\" issue, and couldn't concede that I spent $450+ on a card that was essentially broken from the factory. It would blackscreen and restart my computer multiple times a day, and many posters would say that my 750w platinum rated PSU was the issue (lol). Along with countless other \"fixes\", OS wipes, drivers with DDU, etc.\n\nSo what did I do? I bought the highest rated power supply I could find at microcenter, wiped my OS, and it still failed. Fine. Maybe my motherboard has issues with the card. I built a second computer out of older parts and that power supply and guess what, it still failed. At this point, I have tried multiple hw configs, drivers, and countless OS wipes. At one point, an AMD employee recruited me to a dev discord and sent me new drivers and tools to record the issue. This went on for a few months but no beta driver helped me. To note, so many people on the two subs were having these exact issues - this was not an isolated issue.\n\nAbout 3 months later, I RMA the card to powercolor, who after 2 weeks, they find 0 issues with it. I get it back, furious, so I forgo ever putting it back into a system, and sell it at a good price with an obvious caution \"had issues with it, but Powercolor says there is nothing wrong with it\".\n\nI buy a 2070 super and have had 0 issues. No reboots, no black screens, no crashes, artifacts, anything ever. It's been about 6 months since then. I sincerely hope the person who bought that card has had 0 issues with it. I still love AMD as a company, but the entire experience left a terrible taste in my mouth because nobody took blame for it.\n\n&#x200B;\n\nedit: I now realize that I haven't posted since swapped cards, I still have the 5700xt as my flair lol.",
      "I have reference 6700 XT, running latest drivers, and absolutely 0 issues with 2 screens running different resolutions at different refresh rates. I had more issues with my GTX 1080 (mostly DOOM Eternal crashing), but 6700 XT has been smooth sailing.",
      "Both LTT and Hardware Unboxed mention this about PCIe4.0 x8.  \n\n\nHardware Canucks did a review of the PCIe4.0 vs 3.0 with x8:  \nhttps://www.youtube.com/watch?v=86pRe\\_GeT1I&t=361s   \nBut its bad that AMD or vendors doesnt mention this in specs/on box.  \nNot easy to catch up with demand and shortage of substrates to combat prices.",
      "It seems to be related to how ryzen cpus manage idle voltages.\nHowever, i don't think that my CPU is the problem, i tested my GPU in my gf setup and the same thing happens. Also, my old rx 570 runs fine.\n\nI have a r7 3700x + asrock b450m steel legend.",
      "Every single driver released since May is completely unable to properly render Motion Smoothing for ANYONE, an essential effect in some highly demanding VR games. And only after months they made the card even usable for that purpose, due to an occasional stutter causing nausea in all games. So yeah, they're clueless like that. As a VR user, I also deeply regret buying the card at launch."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6600xt"
    ],
    "title": "I recently bought a 6600xt but I seemed to have gotten a bonus item",
    "selftext": "",
    "comments": [
      "Cats do  not improve GPU thermals, no matter what they tell you.",
      "Finally, a GPU worth the inflated price!",
      "Mannn, they lied to me Qwq",
      "It was absolutely worth it",
      "Definately Furmark",
      "This card is really gonna purrrr.",
      "Extra Purrformance :3",
      "May contain cat.",
      "Was a joke because the GPU \"included\" a cat. But it depends on price.",
      "Which games do you play, and at what resolution and framerate? I have the exact same XFX Merc 308 card as you and I love it!",
      "What‚Äôs the hash rate of that cat?",
      "Graphics Cards come with cats now? No wonder they are so expensive.",
      "Dumb (but) Lovable Cat",
      "lol, nice pro-AMD cat!",
      "Looks like a DLC :D",
      "3 furballs/hour",
      "Go tell someone who cares. Try buying a used 5700xt for the price of a new 6600xt. You can‚Äôt because the the 5700xt is a good mining card. You act like it‚Äôs AMD‚Äôs fault the silicon shortage makes everything to expensive. It‚Äôs no different from a 3060 being no better than a 2070 and no cheaper. It‚Äôs normal for a new GPU to be basically equal to a model one tier higher but one gen older. The 3060, 2070 and 1080 are all basically equal.",
      "It's actually a thunderbird.",
      "Nvidia may work better in GPU rendering depending on what software you want to use. Look at compatibility lists for every software you need to see what's best.",
      "Is it? Deciding rn between a 6600/XT, a 2060/super or a 3060. Not only for gaming, but for 3d rendering too"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6500xt",
      "6600"
    ],
    "title": "RX 6500XT/6600 concept, done in blender. I had a lot of fun making this.",
    "selftext": "",
    "comments": [
      "Wireless GPU",
      "It turned out crap so I didn't add it in.  \n\n\nEdit: I made the PCIE connector and a proper I/O shield here  \n [https://imgur.com/a/1v5HxYv](https://imgur.com/a/1v5HxYv)",
      "Just connect it via sata",
      "I hear Molex is boppin‚Äô",
      "Bro, when was the last time you built a PC? SATA is dead. Shit is way too slow. Use Firewire.",
      "Criticism: You didn't add pcb, the io bracket looks it's 2 slot tall but has 3 fingers. \n\nReference: https://www.ekwb.com/shop/ek-fc7970-dcii-i-o-bracket",
      "yes.\n\nedit: I fixed it and added a PCIE thing  [https://imgur.com/a/1v5HxYv](https://imgur.com/a/1v5HxYv)",
      "Ahhh yeeees, misaligned molex connectors. That's my fetish.",
      "Imagine this, but even shorter and with a larger fan. That'd be amazing.",
      "Ahh so I'm not the only one remembering the R9 Nano",
      "Na. I‚Äôll just connect it via the hd audio header",
      "Sorry, this is going to connect via PS/2",
      "Nah, not enough bandwidth, stuff it into a ZIP drive",
      "dont forget the RX 5300",
      "Not bad, i think this would be a nice addition to some small case / Prebuild's.",
      "One day it shall be released (come on amd a good 250 bucks card to replace my 4gb rx 570)",
      "I think it seems like it since he didn't add a pcie connector",
      "That's not how this works, clearly gpu is connected through Infinity architecture",
      "i think this calls for an XLR connection",
      "AGP is pretty good too"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6500xt"
    ],
    "title": "PSA: RX 6500XT official release date is tomorrow. (1/19/22) Please dont support scalping!!",
    "selftext": "AMD have given an MSRP on this card and promised a few things--\n\n1.) $199 MSRP (actual available price targeted)\n\n2.) Large available quantity at launch.  Lisa Su:\n\n>We‚Äôre positioning the launch such that‚Äîand I know, you guys always say, ‚ÄôWell, yeah, they‚Äôre just saying that‚Äô‚Äîbut we really are positioning the launch at a $199 price point. It is sort of affordable to the mainstream. You know, we intend to have a lot of product out there.\n\n3.) Its no good for mining and according to AMD, that was an intentional part of the design.\n\nNumber 3 above is key.  If this is true (and it will be tested, I can assure you), then miners wont be buying truckloads of them-- they shouldnt actually be buying any at all.  Again, this means that anyone selling these tomorrow at above MSRP are outright scalping /scalpers.  In normal times, this is a $160 card, at best.  Its gimped in mem capacity, gimped in hardware video codecs, gimped in PCIe lanes/bandwidth.  Consider that if you are thinking of caving in and paying more than $200.  Dont do it.\n\nIf you purchase one of these cards for anything more than a penny over $200 USD, you are supporting  and encouraging scalping, period.  This should not be able to be blamed on miners. Do not pay more than that at Amazon, Newegg, Best Buy, Microcenter, etc, and for DAMNED SURE do not pay more than that on Ebay or some hardware swap forum.\n\nShow some backbone and say no to scalping once and for all.  Make the scalpers who purchased multiple cards with the intent of flipping them sell for a loss.  Send a message to the AIBs that its not OK to upcharge 50% of what a product should cost just because they slap a \"superclocked\" or \"OC edition\" label on it. If the community doesnt unite and take a stand against this BS it will never stop.\n\n&#x200B;\n\n**\\*\\*EDIT:  There are already some people trying to justify higher prices by saying that \"Oh, the AIB versions will have a bigger cooler, etc, so they will be more expensive.\"  BULLSHIT.  AIB cards are the only ones that are being sold and Lisa's comments about targeted street price of $200 already take this into account.  That means that AMD has sold these GPUs to AIBs at a low enough price that $200 should cover everything else they need to produce the card and still make a profit.  Dont fall for that BS.  This is a tiny die, on a tiny card, with a tiny amount of memory.  It doesnt need a  triple fan Arctic Frozr cooler or some exotic liquid cooling shit on it, dont be that gullible.**",
    "comments": [
      "Honestly? Dont support this gpu either.",
      "My dude, we don't live in a fantasy land where we can flip a switch and stop everyone from buying grapic cards.\nThey're sold for 2,3x the MSRP not because of the people supporting scalping and corporate greed,but due to the fact that people are willing to pay 1600 for 6900xt, 1500 for 6800xt, 1200 for 3070 ,and those are AIB prices caused by tarrifs, TSMC raising prices, AMD/Nvidia rising prices.\n\nWe might disagree all we want, but it is what it is, unless we have an enormous surplus in GPU supply prices are not coming back to \"normal\".",
      "> ETH going to PoS in June\n\nIsn't this the 4th time they have set a date to go to PoS lol",
      "How about you wait for reviews of the card cause you know, there are so many red flags on it?",
      "Dont need a review to understand its not worth more than MSRP.",
      "Really depends what you're coming from.  For some, they might be able to sell a multi-year old card near breakeven and get a brand new card that performs slightly better and at much lower energy, new warranty, and not have to worry about the old one crapping out and being stuck with nothing.\n\nNo it's not an amazing card everyone should be jumping out to buy, but might be a godsend for someone desperate.",
      "Almost anyone that buys this has been duped by AMD.",
      "There is no \"if\" about number 3 because there is only a 4gb version and cryptos such as eth needs more than that to even run never mind run well.",
      "Said multi year old card likely runs in a pcie 3.0 system which means this garbage when put inside it will run in pcie 3.0x4.",
      "It's not even worth it's MSRP imo.",
      "The 4x pci-e lanes will destroy this card for anyone not on pciE4.\n\nWhich the people in this budget range probably aren‚Äôt rocking newest Intel or AMD platforms‚Ä¶",
      "This post is filled with good intentions I'm sure, but really it's cringe as fuck.",
      "Sigh. I'd prefer they'd just put some \"fresh\" RX580's or 590's out instead. :(",
      "They're gonna be sold for higher than MSRP. Scalping is profitable so you're on some copium if you think the price people will sell this at isn't going to be at least 50% more than MSRP, regardless of how lackluster it is.",
      "There's too many desperate gamers willing to burn money for it.",
      "We'll see tomorrow.  Im sure you are right as Techpowerup said this is the first time in like 13 years that AMD has not sent them a sample prior to launch date.  Probably for the exacts reasons you are worried about.",
      "While the message *may* be good, it shows a real disconnect as to how supply and demand operates in a free market, and also gives off the impression you think you can influence anything with a simple Reddit post that got 175 likes.\nSmells a little desperate to me as well, but idk maybe I'm just reading too much into it at that point.",
      "People should also note here, this card is not worth MSRP, let alone above it, it has been gimped in too many ways, (Not to prevent mining, so they can cut costs producing it and increase the margin on it), AMD saying its to prevent mining is a PR stunt, nothing more (Unless someone fancies telling me how gimping the PCIE lanes and memory bus also help 'prevent mining' when the 4gb vram is already in place)\n\n&#x200B;\n\nIf you are a gamer on a budget (Which realisitcally if you're looking at this card, you are), don't bother, get a current generation console. These are easier to buy than GPUs, are more powerful than this GPU, and will cost less (Comparing total system cost).\n\n&#x200B;\n\nThe point of the PC platform is to give a premium experience over consoles for a premium price, this card represents a premium price for a worse experience \n\nYou aren't really getting the freedom of framerate and resolution here, even settings tweaks really, and you're below the XSX/PS5 performance tier so what's the point in buying it more than those systems cost",
      "Supposedly somewhere around RX 580-ish.",
      "Even MSRP seems like too much honestly. Unless they can get it to run at full speed at PCI-E 3.0 x4 and is meaningfully faster than the 5500 XT, this card is going to be terrible at 200, but with how messed up the market it, I'm sure it will sold out even at 400."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6400"
    ],
    "title": "Upgraded froman i5 6400 w/1050 ti to r5 3600 with a 2070 super",
    "selftext": "",
    "comments": [
      "How are you liking the Tomahawk?\n\nJust got mine running last night.",
      "The CPU upgrade alone should be monumental. Can't wait to upgrade from this ancient 4c to a 3600. I may finally see more than 30% GPU usage.",
      "yeah i bought the max verison",
      "I would have purchased that if I had known it had a 32mb bios chip.\n\nEdit: Max is not available in the US so it won't be an option.",
      "Fit more CPU microcode instructions and training tables. It allows the board to maintain compatibility al the way with Ryzen 1000 - Ryzen 3000 and beyond. However if you don't need / care for compatibility with old chips it\n\nI personally believe 16mb won't ve a problem if you are only dealing with Ryzen 3000 +",
      "That's quite an upgrade",
      "What's the advantage of higher chipset memory? What's the difference between a 16mb chipset memory VS 32mb",
      "Why was I downvoted for asking where?",
      "exactly",
      "How's the artic cooler? I'm planning a similar build but waiting for rx5700 AIB models to come out. Did you try the stock AMD cooler?",
      "That is one THICCC card",
      "I replaced my 7600K with a 3600. The 0.1% lows went more stable and higher. I get higher FPS in games and my cpu doesn't stay at 100% most of the time now.",
      "The 3470 has held me back in pretty much every game and application. Even BF3 stutters like mad and I can't break 90 FPS no matter what settings I run at. Got a similar framerate with my R9 285 which is significantly less performing. Ran fairly well with intermittent stutters but near 130 FPS with my old FX 8320. Userbenchmark test says it's performing as expected one minute and no where near expectations the next minute.",
      "Is that really an issue",
      "Where? Max isn't available in the US",
      "Cuz Reddit.",
      ">I personally believe 16mb won't ve a problem if you are only dealing with Ryzen 3000 +\n\nRight, it really only effects the bios user experience",
      "Im from slovenia",
      "Userbenchmark is not really a reliable source is it?",
      "Old flair, I have 3600 now on tamahawk non max. Difference between the two is chipset memory."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6600"
    ],
    "title": "Then and Now: Hardware Unboxed on RX 6600",
    "selftext": "",
    "comments": [
      "Things change and I'm glad that they can change their opinions based on new info!",
      "Well tbf to them, these videos are from different timepoints which you're omitting to put forward your narrative (And their review title is true, that is what the 6600 is) and I don't think you actually watched either of the videos\n\nThey say to buy it if you have no choice and need to buy a GPU, because it was the cheapest current generation GPU at the time of review (But in a normal market it's a joke and just an uninspiring product in general)\n\nThe second video is basically saying to buy it over the 6500xt/3050 because it has better 'value' than either of those cards, but again aren't actually recommending buy it\n\nat the time of the review, it was shit, and tbh it still is a bad GPU from an objective sense, and at the time of reviewing all reviewers don't know what the street pricing will be \n\nBut in the context of this market it is the best card from a price;performance perspective, that's not exactly saying much though when people are buying a 6600 for the price my 6800 cost",
      "I mean... it *can* be a really expensive 5600XT with really shit ray tracing *and* still be the best value GPU on the market.\n\nThe two aren't mutually exclusive...",
      "$$$",
      "It's almost like pricing changes, also watch the content. We said the success of the RX 6600 will heavily depend on pricing :S",
      "Exactly. It‚Äôs not like they said ‚Äúthis card is the worst price to performance card‚Äù on launch and then said ‚Äúthis card is the best value card‚Äù a few months later. Though with the current GPU landscape, even those statements wouldn‚Äôt be too unbelievable.",
      "Initial reviews always go off of MSRP. Which makes their price/performance conclusions practically useless.",
      "The 6500XT is freaking terrible, which would make the 6600/XT the best value.  The 6700XT is $900.",
      "Why would he have manipulated numbers to say the FX line sucked when the FX line objectively sucked?",
      "Their change in opinion has more to do w/ the lower tier cards (and their pricing) that have come out since then.  The 3050 is a decent card that is wildly over-priced while the 6500 XT is a complete shit show.  As of now, that makes the 6600 the \"cheapest\" card that's worth a damn.  If the 6500 XT wasn't so gimped or the 3050 was priced accordingly, this would be a completely different conversation.  \n\n\nWelcome to 2022, where \"best value\" basically means \"this purchase will dick you over the ***least ...*** but it will still give you the D.\"  Fingers crossed that Intel releases a reasonably priced budget card.",
      "You mean his opinions on the CPU line that all sane people think was garbage?",
      "The 6600xt is the only thing available at \"acceptable prices\" were I live since it goes for 5700xt prices. Its the only thing which I could recommend to one of my friends. Both the 3060 and 3060ti cost a lot more. The market changes and so most the perspective of reviewers. \n\nI would like to get a high end GPU for 350CHF (like my r9 fury), but it will take a lot of time for that to happen.",
      "As many have already pointed out in the comments, the thumbnails aren't mutually exclusive so you're making yourself look quite foolish here. Significant adjustments in retail pricing aside, the RX 6600 is still an expensive 5600 XT with shitty ray tracing performance, while the second thumbnail is now correct, dropping to $450 US makes it the best value GPU in the current market.\n\nUpon release the RX 6600 didn't look impressive, pricing didn't sound as though it was going to be remotely interesting and it wasn't, so what did you want the thumbnail to say? \"The probably crap value RX 6600 is here?\"",
      "What new info exactly? \nWhat has changed in the last three months?",
      "That's cause that's CPU is the biggest turd sandwitch in the world i remember it losing to a dual core 5ghz pentium lol in so many games.",
      "That's pretty funny coming from the guy choosing to avoid decades of people thinking the FX CPUs are garbage.\n\nGot a good deal on that copium?",
      "Objectively it is a poor value card (except the 75W pcie limit niche) \n\n\nWas out performed and was more expensive than the RX570 8GB but because it's basically the only \"cheap\" Nvidia card in the market (minus the super variant) and was in a shit ton of laptops and OEM systems it's nearly top dog in the hardware survey",
      "Except the 6600 and 6600 XT were both called bad value cards at launch by most reviewers, so them being bad cards as a result was indeed part of most of the launch reviews of those GPUs. It's only more recently that reviewers who shit on the 6600 XT are having second thoughts about it.",
      "But they don't recommend buying the 6600 in either video, they say in the second to buy it instead of a 6500xt/3050 if you have no choice, and they do say in their review to buy it if you have no choice\n\nBut that's it's a not a good buy, which it wasn't, just because it's gone up in price since launch does not mean the launch price was a 'good' buy, they don't praise it's value, they just say it's less shit value than the 3050 and 6500xt\n\nYou've basically done what they did, clickbait the clickbait to generate traffic",
      "I owned the FX 8350 and traded it in for a I3 haswell at the time every single game i had performed night and day better and that was just a placeholder until i got a 4790K at the time.\n\n&#x200B;\n\nFX 8350 was and will always be a POS CPU\n\nIPC and latency on the bulldozer line of CPU's were so terrible and it barely improved with Piledriver\n\n&#x200B;\n\nI actually even remember dolphin emulator performing faster on my 1100T at 3.9Ghz vs my 8350 which could only do 4.5 with the SAME cooling"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6600xt"
    ],
    "title": "Pricing stickers on 6600xt purchase yesterday for $400",
    "selftext": "",
    "comments": [
      "Not surprising unfortunately",
      "So it's not AMD that scalps but retailers.",
      "You take the cheapest gpu sticker and stick it on a 3080Ti box\n\nProfit\n\nEdit: DONT TRY THIS AT HOME",
      "There was [another thread](/r/Amd/comments/p39mi2/the_largest_dutch_tech_news_site_is_claiming_that/) that said AIBs basically paid rebates to retailers so the first batch of cards would be MSRP. \n\nIMO this is just a trick so that launch date reviews will position the card at $400 in price vs performance charts. So congratulations to everyone who got a 6600XT at MSRP, coz it's gonna be a quick price hike to $700 after initial stock is sold out.",
      "Do you mean your 5700xt? 6600xt is such a pointless upgrade for you unless ray tracing is really important ? It's barely any better you are best of keeping it for the next set of cards from AMD and NVidia.\n\nKeep that 5700xt going!",
      "You can't try at home, you need to try at store...",
      "Most you'd actually get is a dirty look from the employee before looking up the real price in the POS.",
      "I feel like they could turn that into a handful of crimes. Theft, defacing private property, attempting to defraud a company, damage to private property.... They could smack you with a whole list of things if they felt so inclined.",
      "bro i bought a 5700xt last december at MSRP, feeling pretty happy with my purchase rn",
      "Looks like the 5700xt is in for the long ride üò≠",
      "First, I am glad I got mine yesterday at $400. Micro Center had plenty available near MSRP, even had cards left at the end of the day. \n\nHowever, there is no guarantee this will continue to be the case in terms of both quantity and pricing. In fact, the pattern from the 3060 and 6700xt launches were that they had cards near MSRP on launch day but almost only expensive ones later on. Given that even the 6700xt is selling for $800+ from most board partners, I would not be shocked at 6600xt going above $600-650. \n\nWith all the reviewers‚Äô complaints about the $379 MSRP, they forget that getting this card actually at $379 is an absolute bargain in this market, and probably only likely to happen on launch day. The correct advise to their audience should have been to get one at MSRP on launch day if at all possible and just sell your RX580 or GTX 1060.",
      "I scored a powercolor 5700 red dragon open box for $280 in March of 2020. My timing was incredible.\n\nReceipt screenshot: https://i.imgur.com/ZbQ3zme.jpg",
      "> unless ray tracing\n\nI thought all reviews show how RT in AMD cards is completely out of the battle vs nvidia (for now)? So if RT is a thing for you, wouldn't you get a novideo? (Unless you're really anti nvidia)",
      "you can't blame everything on scalpers when we are watching, in real time, how everyone in the chain loads their pockets like peddling heroin is out of fashion now\n\nAMD has been flaunting how their profit margin has been ballooning since RDNA1/5700XT and they've been feeling their excess cash enough to do stock buybacks in a year of massive social upheaval and global economy dropping into massive recession\n\nAMD and NVidia realized they're in position to shake everyone who wants a GPU down and they aren't gonna stop until their junk stops selling, everyone else along the seller chain gets to have a lick\n\nthis is \\[current stage\\] capitalism in action and it's only gonna get more common as competition ever weakens",
      "You ruined my life. Where are the kids, kevin? WHERE ARE THE KIDS?!!!!",
      "Probably, and the board partners also taking as much profit as possible. I don‚Äôt blame them‚Äî why let eBay sellers make the profit.",
      "But the fact is you CAN get this card NOW for msrp.\n\nYou can't get 3060 or ti for anywhere near msrp.",
      "Try to find a miner over in r/minerswap who wants a 5700xt.... I did a flat swap for my 5700xt and got a 6700xt :)",
      "Im already starting to regret i didnt buy it.",
      "It is like saying you should have bought gold in 2007, if you are in the need of a card, check the present, inform yourself on the future and try to make the most out of it."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6600"
    ],
    "title": "Me and my dad just built this pc, any thoughts? Specs: Ryzen 7 5800X, 32 GB DDR4 RAM, PowerColor Red Devil Radeon RX 6600 XT",
    "selftext": "",
    "comments": [
      "Looks good man. I would suggest not daisy chaining the PSU to the graphics card. Run two separate cables to both of the 8pins.",
      "6600 XT probably won't draw enough power for it to be an issue, however, best practices are two separate dedicated cables.",
      "Great specs very nice PC.",
      "he's saying urs is shit",
      "This is the correct answer. Using 2 separate cables is the better practice and what I always do. However, the 6600 XT Thermal Design Power (TDP) is 160W. I can't imagine the AIB card using more than 225W excluding a few spikes, which a single PCIe power cable and the motherboard can safely supply (Motherboard provides 75W and single cable has a TDP rating of 150W). I personally would be comfortable daisy chaining this setup if I had to. Probably would slightly undervolt to be safe.",
      "That makes me feel better about my cable management",
      "Why are you using a 120mm AIO for 5800?. You could get a 240mm and mount it on top.\n\n120mm AIO, in my opinion, is only to be used when you're building a SFF build. Your 5800X *might* run a bit hot on that.",
      "Ok, thanks!",
      "Cable management is dissapointing (I don't care it's misspelled.)",
      "Thank you so much!",
      "You want a pic from a better angle? It‚Äôs not that bad. And if you still think it is, then I‚Äôm sorry. Me and my dad tried our best.",
      "Oh ok, thanks!",
      "It's not the capability of the PSU for the reasoning, it is how much power is coming from the cord to the GPU.",
      "Nice setup! Great CPU, decent graphics card, and plenty of RAM. üëç",
      "It‚Äôs how I was raised, thanks so much for the compliment!",
      "They should be included with your psu",
      "I‚Äôd do some cable management. Get the excess length bundled up in the backside of the case, behind the motherboard. Other than that, nice first build!",
      "Your dad's great.\n\nMy thoughts. I'd downgrade the cpu and ram to get a much better gpu. But if you're utlizing those 8 cores and 32gb ram with your workload then fair enough.",
      "I'm not sure the $130 you could save doing that would really result in much of a GPU upgrade, sadly.  =/",
      "PSU wouldn't come with daisy connectors if there was any reasonable chance that the power draw at maximum on both connections would cause a shutdown or melt the cables.\n\nThere's plenty of evidence showing daisy connectors are no risk at all to 3080/3090 power usage. There may be some GPU performance impact depending on the connector but it's so small you won't notice it anyway.\n\nEdit: for my own anecdote, I'm running a reference 6900XT and a corsair RM 850x that comes with daisy chain connectors. The wire from the PSU to the first connector is much higher gauge than the chained connector.\n\nI have no performance difference using either 2 separate 8-pin or a single daisy chain. The heat in the wire measured 1 degree higher which is not much and within error of the indirect thermometer I was using.\n\nSo it really depends on the PSU and again, I doubt any PSU maker would risk the liability of not having more than adequate daisy connectors."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6500xt"
    ],
    "title": "RX 6500XT doesn't have H264 Encoding, What does this mean for an average gamer/streamer like me?",
    "selftext": "",
    "comments": [
      "It means you will need to get a Nvidia card.",
      "basically mean you'll have to rely on cpu encoding, which is often recommended anyway in AMD lower end cards.",
      "This is the most realistic answer since OP never eluded to streaming using the CPU.",
      "someone with a 6500xt may not have a powerful enough cpu for decent quality recording **without loosing performance** though. This is where the hw can be great even if the quality is somewhat lacking, not having to loose FPS while recording is a godsend and why i don't use X264 for real time encoding (OBS).",
      "It depends, AMD's H264 encoder is kinda bad specially at a low bitrate, but their HEVC encoder is very good, so if you're recording gameplay it's better to use hardware encoding (GPU), but if you're streaming it's better to use software encoding (CPU).",
      "Basically since RTX launched, the nvenc on those cards can get reaaally close to x264 medium",
      "Don't buy it.  It's a downgrade from the RX480 / RX580 / RX 5500XT.  Get an RX 6600, RX 6600XT, RTX 3060, RTX 3060Ti, buy a used card, or wait for an RTX 3050.  AMD keeps shitting on the $200 market and has done so for the past few generations; no Vega model, RX 5500XT, and now the RX 6500.   It's sad when a 5-6 year old card outperforms a brand new offering that should blow it out of the water.",
      "It's *losing not loosing.",
      "You use software CPU encoding or Quick Sync Video if you have Intel integrated graphics. Other than that, a spare GPU just for that task (preferably Nvidia).",
      "or a good CPU.",
      "Well good news!  Your flair says you already have a 6700XT so really it won't affect you, just like 99.95% of commenters shitting on it that will never own one any way, this isn't aimed at ANY OF US it's just to get more cards out the door in shitty bottom barrel prebuilts, and NOBODY buying one of those is seriously contemplating \"streaming\".",
      "The issue is, if someone is buying a '$200\" GPU they likely have a really old, slow performing CPU. People aren't going to pair these with a modern Zen 3 or 12th gen CPU, but likely a 5+ year old budget one.\n\nSo it absolutely becomes an issue.",
      "But how does the performance get loose? Do you need a screwdriver or socket wrench to tighten it?",
      "Isn't part of the whole argument to buy 6-8 core Ryzen CPU's is to stream while gaming at the same time?  When did it become a big deal to use your GPU to encode, anyway, I always that was the inferior method...",
      "In the real world, your audience doesn‚Äôt care and will watch completely garbage video if your audio and content are tight.",
      "It means Radeon ReLive won't work and it's a huge dealbreaker for me.",
      "More than likely, imagine gaming and recording at high bitrates on a 4x interface lmao, i still cannot believe AMD made a X4 gpu, even for mobile i find it odd.",
      "The explanation I have seen is that both the x4 interface and the lack of hardware encoding is because it's a notebook GPU repurposed for desktop. Notebooks don't need a hardware encoder on the GPU because the iGPU already have one, and they use PCI-E x4.",
      "> But don't be surprised when this actually out performs the RX 590/GTX 1660.\n\nNot sure if you're being sarcastic",
      "I just need a gpu to play modern games at 1080p with decent frame rates. I don't stream or record anything and don't care to ever have the ability to. Does this fit the bill?"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6600"
    ],
    "title": "[HUB] Nvidia Gets OWNED: GeForce RTX 3050 vs Radeon RX 6600, 50 Game Benchmark",
    "selftext": "",
    "comments": [
      "I've owned a 3050, 5600XT, 6600 and 6600XT \n\n\nThe 3050 really doesn't have a place, it's noticeably slower than even a 5600XT, draws more power than a 6600XT, DLSS can't work it's full magic at 1080p and at higher resolutions the card doesn't have enough GO to make use of it \n\n\n\nIf it was a 170-200 GPU then sure but it's closer to 300 in a lot of cases",
      "I don‚Äôt understand how 3050 prices have stayed so elevated as everything else drops, the cheapest on Newegg is $330. That‚Äôs arguably even worse value than a $200 6500XT.\n\nMeanwhile the friend I just helped build is very satisfied with his $250 6600.",
      "the 6600 & 6600XT are pretty much the default choice for 1080p gaming right now, unless you can get a 3060Ti for around the same price as the former two cards.",
      "If you did the numbers at the MSRP, it's literally just a faster 6500xt. 20-30% faster for about 25% increased price. And that was *if* you could get it at Nvidia's MSRP, which we all know is a joke\n\nMeanwhile the 3060 and 6600 were practically 2 times more powerful for 50% increase in price. 3050 is genuinely a worthless card",
      "3060Ti could've been the people's card for this gen if not for fucking miners.",
      "I have a 3050. It lives in my unraid server and it transcodes plex and does some rendering work. It replaced a 1060 6gb with a net influx of 50 bucks in cash. So effectively a free upgrade.\n\n&#x200B;\n\nAMD didn't have anything that I could do this with. All their cards at that price range don't have proper encoders. OpenCL is also a joke and no proper rendering software really supports AMD over CUDA.\n\nThat's the realistic niche for this card. It's unfortunate AMD doesn't have much to compete with it.",
      "Yep the only thing new we learn from this video is that AMD card prices keep tanking even below MSRP and somehow 3050 prices still above MSRP. About the performance part from the moment they come out from all the review we already knew that 6600 1 tier above and closer to the 3060/3060Ti/6600xt (hence the name) than the 3050.",
      "Never underestimate that Nvidia mojo. People refuse outright to buy AMD GPUs. In my shop we get people all the time who refuse them. Almost afraid of them. Beats anything I've ever seen. The last Nvidia I bought was a 7800gt. I've had an hd4650, HD7770,R9390, Vega 56 and now 6750xt...I've never had anything but good experiences. I don't get it.",
      "Sadly HWU didnt mentioned that Nvidia silently replaces 3050 dies with 20% slower ones.\n\n\nI guess Nvidia plans to sell idiots the old 3050 as a 3050Ti lmao.",
      "I wouldn't say it's worthless, but it's probably worth about $150. It 'SHOULD' be a replacement for the 1650 Super in Nvidias product stack with similar performance but with RTX and DLSS features added (despite how fairly useless they may be in most games on this card, there are some low-demand games that will still work well with DLSS at 1080p like esports titles). \n\nBut at $300 it's ridiculous",
      "Mining is dead and nvidia cards still overly overpriced. RTX 3050 is 330‚Ç¨ for the most basic model, which is just absolutely nuts when you can buy RX 6600 for 300‚Ç¨. RTX 3060Ti is also pricy as hell here + it's quite power hungry for what it is which will start matter soon with skyrocketing electricity prices in Europe (which were already like double the US prices).",
      "Yeah, AMD would never do that! Radeon RX580 2048SP was OEM only! /s   \n\nIt is not only Nvidia, every company does this. Call them out and don't buy bad products.",
      "No company is your friend.",
      "The 3050 is pointless even compared to Nvidia's own RTX 3060 which costs just about 60$ more but offers 4gb more VRAM and about 35% higher performance.",
      "I'll just head to the comments and grab my popcorn, waiting for the more rabid elements of the Nvidia subreddit to brigade the video.\n\nIn other news, he's right. Objectively there is absolutely no reason to buy a 3050 that I can think of. Like, none.",
      ">I don‚Äôt understand how 3050 prices have stayed so elevated as everything else drops\n\nI would guess that AIB's sold them to retailers for higher costs, and now since the crypto crash and with demand dropping out hard, retailers are hoping to not have to discount cards below what they paid for them, seeing if they can get some suckers to clear out what they have now.",
      "I think any fanboy forgets that, be it Nv, Intel, AMD, Sony, Microsoft, Tesla, Nintendo... You name it.",
      "Sure buddy, why have the prices crashed in the last 2 months?",
      "I've flip flopped between both brands since the OG Radeon and GeForce 2. Never regretted a purchase either way. The only card I ever had issue with was a 7900 GT, that luckily I bought from EVGA, so it was a quick and easy RMA.\n\nI don't get the diehard siding with one brand over another. Each gen, I read reviews and chose the best bang for my budget. Sometimes its AMD and sometimes it is Nvidia.",
      "Isn't that just in prebuilts? Still very scummy, but not something the majority of people on a reddit like this are effected by."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6600xt"
    ],
    "title": "Upgraded my GTX 1080 to a 6600xt",
    "selftext": "",
    "comments": [
      "There is a lot to unpack here wow.",
      "1080 -> 6600xt?\nCable management???\n500watt no-name PSU?!?\nOptical drive (nice)\nWeird case",
      "doesnt much seems like an upgrade .",
      "AHHHHHHHHH! Please clean up your cables, have some decency.",
      "OTOH its so refreshing to see an actual normal everyday build pic instead of some RGB ONLY 240mm FANS PORNOGRAPHY that is your standard battle station build here. \n\nThe cables\n\nThe CPU cooler\n\nASrock 6600XT\n\nRust HDD\n\nSome sort of Optical Drive\n\nMissing brackets\n\nCase Speaker just... doing its thing\n\nI feel like I can just keep going. \n\nIts case photography IN THE RAW",
      "Replacing a card for a 20% performance boost is usually not really worth it. It is an upgrade, but not a very noticeable one.",
      "Brother, this man has 5w speaker sitting on PSU, what cable management you are looking for ![gif](emote|free_emotes_pack|laughing)",
      "[https://www.gpucheck.com/compare/amd-radeon-rx-6600-xt-vs-nvidia-geforce-gtx-1080/intel-core-i9-10900k-vs-intel-core-i7-6700k-4-00ghz](https://www.gpucheck.com/compare/amd-radeon-rx-6600-xt-vs-nvidia-geforce-gtx-1080/intel-core-i9-10900k-vs-intel-core-i7-6700k-4-00ghz) Big enough of a difference, the 6600-XT is comparable to a 1080 Ti.\n\nOne should never really expect colossal gains over going from a x80 GPU to a x60 GPU unless it's a massive time gap like you're going from a GTX 980 Ti to an RTX 3060.",
      "Brother your cables",
      "Yep, this is why people need to be really careful when you get someone ranting about how AMD's drivers need fixing or how their cards blackscreen or other such stuff.\n\nWhen you've worked in a PC shop you see the absolute horror of some people's DIY builds...",
      "I'm not sure he has a lot of spots to hide cables, that's a very cheap case",
      "Depends on how much you can get for your old card. I sold my Vega 56 for ~500‚Ç¨ a couple months ago (probably to a miner) and replaced it with a RX6600 for 380‚Ç¨. It's slightly faster and I got money out of it.",
      "More of these. The every day cable managed rgb this and that builds are boring. Reminds me of my PCs",
      "1080 -> 1080Ti is not a big difference, definitely not worth 300$.",
      "It still looks like theres a punchout on the rught sidepanel to stuff them into. Not neat, not easy but it d look much better",
      "I like it, reminds me of my own builds. I dont give a shit about cable management either, I just plug shit it and use opaque cases so no one can see it. Problem solved! I mean, mines not quite THIS chaotic...but this is art.",
      "Ahh the good old days when cases had solid sides and you didnt care what the inside looked like..until it got a tad warm in there.  \nJust do us all 1 favour, even if you have no inkling to redo the cables...flip the power supply over so it is sitting properly with fan down.  \nThank you",
      "Bro is that even an upgrade? Isn't it like the same?",
      "Word. I have a 4090 and instead of using a GPU support stick I jammed a piece of cardboard between the 4090 fan casing and the drive bays below. Works like a charm zero sagging. \n\nPeople get so hung up in aesthetics they forget that as long as air can flow and cables are not hanging in your coolers, the build will be fine.\n\nI see my pc as my millennium falcon. Tied together with ducktape but outruns imperial cruisers with RGB.",
      "Intel box cooler?"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6600"
    ],
    "title": "2022 Glow up. Finally left my FX 6300. Now running R5 5600X and ASUS RX 6600. Full Spec below!",
    "selftext": "",
    "comments": [
      "Old build - CPU: AMD FX 6300 OC to 4.7GHz RAM: 24GB of DDR 3 at 1866MHz Mobo: Gigabyte 970A-DS3P FX rev 2.1 GPU: Sapphire Nitro+ OC RX 480 4GB Storage: 1TB WD Blue HDD. 240GB Crucial SSD PSU: Corsair CX550M CPU Cooler: Arctic Freezer 7X Case: XPG Starker\n\nNew build - CPU: AMD Ryzen 5600X RAM: 16GB XPG D60G @ 3200MHz Mobo: ROG Strix B550-A GPU: ASUS Dual RX 6600(non XT) Storage: 1TB Silicon Power NVMe M.2 / 240GB Crucial SSD PSU: Rosewill SMG650 CPU Cooler: TH360 ARGB Snow Edition AIO Case: XPG Starker Case Fans: GIM KB-23 ARGB fans",
      "You definitely got the parts right for the best value out of a current mid range gaming rig. Good job!",
      "Beautiful build! I would be weary of the Thermaltake Aio though. They are known for super early failure. Unless they fixed their idiocy..",
      "From what I‚Äôve researched before buying it seems they have improved. Time will tell but so far I‚Äôm very impressed with how it performs. \n\nWith an overclock applied of 4.75GHz running intel burn test at its max the hottest it got was 83.3 degrees. Hopefully the AIO doesn‚Äôt let me down.",
      "Yeah initial performance wasn't their issue. It was the fact that they had multiple types of metals which caused galvanic corrosion and blockage. So yeah time will tell. Gl!",
      "That battle station will become dusty station after 3 months. Do not put on the floor directly.",
      "Paid $599 CAD",
      "If you learn to clean your space daily you won‚Äôt have that issue. Not to mention my place is air purified so not a whole lot of dust to begin with üòÇ",
      "Congrats on the upgrade, friend.",
      "beautiful build, i really liked my white build but you made this absolutely stunning. one of my favorite pc‚Äôs i‚Äôve seen by far.",
      "Is this case any dustproof? Do your floor absorb vibrations? These two questions keeps me from my pc sitting on the floor",
      "This mostly applies to carpet. I've had my rig on my floor ever since I built it over a year ago and it has barely built up any dust inside it. I also clean my room regularly as well.",
      "Don't over think it, just clean your room regularly and you won't have issues with dust",
      "2 counter points. Firstly, it won't fit flipped even if he wanted too. Secondly, the top of the loop is not the cpu block it's the radiator. Still not ideal of course as it still interferes with the flow but really it's not a big deal. Best way would be to top mount, assuming it can fit.",
      "Still with my old trustee FX 8370e at 4.6 ghz and my rx470 waiting for the prices to go down xD",
      "I would mount the radiator on top, so the pump\nis on a lower level as the radiator.\ntwo benefits: the air in the system stays in the radiator, so the pump will be less ‚Äûloud‚Äú, and you have more cooling capacity.",
      "Under full load the GPU struggles to get over 60 degrees",
      "Asus dual is a very good gpu, the cooler is over build.\n\nSame apply for gigabyte windforce.\n\nI can't comment on other aib.",
      "Parts are being sold on EBay",
      "I did! I must have forgot to put in my list of the new build. My bad, it‚Äôs in there though"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6500xt"
    ],
    "title": "As a casual tech enthusiast, the 6500xt launch has been absolutely fascinating",
    "selftext": "I've learned so much about gpu design from this launch!\n\n* The complicated relationship between memory bandwidth and onboard memory.  How do memory clocks and ram influence things?\n\n* The interaction between pci lanes and pci version.\n\n* The design differences between desktop and laptop silicon.  \n\n* How a tiny chip can boost super high and still sip power.  It made me think about the cost-efficiency tradeoff between that and a slab of silicon.  \n\n* That laptop chips don't tend to have as much pci bandwidth as desktops, or something.\n\n* How laptop silicon leverages features from a laptop APU.  \n\n* That game performance can be significantly impacted by exactly how/where they pull assets from memory.\n\nThe techtubers are roasting it, and i'm eating it up because it reveals so many interesting things i didn't realize i didn't know.  It's a weird gpu and it's fascinating.\n\nSo thanks amd, i guess.  Idk about the card, but the release has been awesome.",
    "comments": [
      "Great to see you've taken the glass half full side. :)\n\n> How a tiny chip can boost super high and still sip power.\n\nAlthough interesting, I think it's worth pointing out that a larger chip running at lower clocks can take less power for the same performance than a small chip running at higher clocks.",
      "Also interesting how the HD 7730 had video encoding in 2013, and that was a 60 dollar card. Meanwhile a 2021 GPU doesn't have encoding or decoding.",
      "I think the problem with this comment is that you didn't mention how larger chips have a higher defective to functional dies ratio per wafer than smaller chips, rendering them more expensive, also you failed to mention that running this chip ant high power could potentially reduce its lifespan as it was made to be efficient at lower voltages and clocks, pushing it this high certainly requires relatively high voltages than what it was designed for, which could lead to chip degradation and failure. Given all that I'd say that it seldom balances out, as a larger die with more cores would give the same performance at a lower voltage compared to this laptop die which is being pushed beyond its efficiency sweet spot. Now while higher voltage doesn't always mean lesser lifespan, it does usually mean less power consumed, which is always nice, if we assume that both dies would pull the same amount of current to achieve their targeted performance.",
      "Many of the techtubers are roasting it because they understand what is *possible* with current technology but seem to have little idea what current market conditions will actually *allow*.\n\nLinus put it well during a recent budget PC build using the 6500XT (the first budget PC build using new parts they've been able to do in a long while). He said \"it only adds a small amount to a total system build but offers 2x+ performance over integrated graphics\". It's a crap GPU but from that standpoint it is filling an important market segment.\n\nBrad Chacos at PC World also [has a handle on the situation](https://www.pcworld.com/article/606950/what-the-internet-got-wrong-about-amds-controversial-radeon-rx-6500-xt.html).\n\nSome are complaining that it's not as compelling as $200 GPUs of the past, which is true. It is horribly crippled. But it is crucial to remember that every single component on the card is in short supply or overpriced, even the copper used in the PCB traces is up substantially. Shipping is up substantially. Inflation is up. The design costs for a 6nm part are massive. TSMC has also raised their prices. \n\nI cannot see how it could cost any less.\n\nThe best price NVIDIA can do is $250 on their RTX3050. That is less compromised but it's also more expensive. And we'll have to see in time how availability and markups work out.",
      "Finally a post that sees reality for what it is, and has a purpose to exist",
      "To clarify, the 6500XT does have video decoding, they just removed the AV1 codex decoder which none of the older cards (RTX 20X0, Radeon 5X00 and older) had anyways.",
      "AKA, analyzing and discussing technology rather than simply criticizing even if it is justified. At a certain point, it is beating a dead horse even if the object in question indeed is horse poo.",
      "i still have a 380x and i cannot find 6500xt near its msrp price in Greece .... lowest is 399 euros from the official distributor in the country \"plaisio\"\n\nyes i am willing to give 200 for this \"low end\" card.",
      "Intel literally sells $40 12th gen Celeron CPUs with Xe IGPs that do encoding and have quicksync and can do 4 video outputs (if the motherboard has the connectors). \n\nObviously the performance is not even remotely the same, but it's also a $40 CPU with an IGP that has basic features the 6500xt doesn't.\n\nNo excuse for AMD to launch such a shitty gimped mobile GPU on desktop.",
      "In a laptop the accelerated video encode would be handled by the APU.  Navi 24 was meant for laptop, that‚Äôs why they skipped video encoding.",
      "Um this is from March 2021, we‚Äôre now in January 2022. Hardly recent, nothing wrong with admitting you‚Äôre at fault when called out instead of doubling down and challenging.\n\nEdit: for anyone curious before the user deleted they cited an article about lack of water in Taiwan from March 2021 over a local‚Äôs perspective on the improved situation, saying even though you may live somewhere it doesn‚Äôt make you an expert.",
      "Always thought it was super interesting how a 3070 mobile and 3080 mobile could use the same power but the 3080 would be faster. Or a 3070 could be faster if it had a higher power budget. \n\nSide note, but this finally clicked for me how Apple was able to push performance (per watt) on their M1 Max by making a HUGE chip on a very small node and optimizing for efficiency. 5900HX has 10 Billion transistors and a 3080 mobile has 17 Billion. M1 Max has 57 Billion, or double those two combined. They must have clocked that thing so far down the efficiency curve, and when they needed more performance they made the chip bigger rather than increasing clock apeeds. \n\nEdit: spelling and missed a word.",
      "Water is not becoming a problem in Taiwan. There was a dry spell with less than normal rainfall a while ago, but not any more. \n\nSource: I live in Taiwan.",
      "I agree, there is way too much whining for a thing most people dont even use, or did every gamer become a streamer in the past years?\n\nEdit: to add to this, im not saying this card is good, but just pointing out that people just like to whine for the sake of it.",
      "Taiwan semiconductor manufacturing company puts their fabs in Taiwan...",
      "Ya, that was under drought conditions. Those restrictions were lifted when the rains returned.",
      "Nice to see someone being realistic about this. Where I live 6500XT has managed to fill a huge gap in the GPU market. The only \"budget\" options that one can actually buy are 1050Ti for 230‚Ç¨, 1650 for 270‚Ç¨, 6500XT for 370‚Ç¨ and 1660S for 530‚Ç¨. 6500XT sits right between 1650 and 1660S in terms of both price and performance, so I don't really understand the outrage.\n\n3050 is going be \"better\", but I'm also expecting it to be priced above 500‚Ç¨ here. Assuming that it's even in stock.\n\nOf course I wouldn't buy a GPU at the moment, but if someone absolutely needs a GPU right now, 6500XT is not a bad option.",
      "Supported Rendering Format:\nHDMI‚Ñ¢ 4K Support Yes,\n4K H264 Decode Yes,\n4K H264 Encode No,\nH265/HEVC Decode Yes,\nH265/HEVC Encode No,\nAV1 Decode No\n\nIts a efficient gpu but coming with only 4GB VRAM and the poor performance over older PCIex Gen... just no, its not built for todays gaming \n\nI'd rather have a rx590 or oc a rx580 with a decent cooling solution like a sapphire nitro",
      "This is kinda what i was talking about with the OP.  It's not an expensive thing at all, but it's conspicuously missing.  That's interesting!  We'd never see these stupid compromises in a normal market.",
      "More expensive process, more complex encoding...\n\nAnyway, NVIDIA led the way with the GeForce 1030 and its derivatives (MX mobile GPUs). They were extremely successful, which suggested to AMD that an entry level GPU doesn't need encoding.\n\nI think that the fact that Navi 24 ended up as a $200 desktop GPU wasn't part of the original design."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6600"
    ],
    "title": "AMD announces Radeon RX 6600 with 1792 cores and 8GB memory for 329 USD",
    "selftext": "",
    "comments": [
      "Already at 490‚Ç¨ in Portugal lmao",
      "I had a chance to get a 5600xt for 239‚Ç¨ or a 5700 for 270‚Ç¨ back in mid 2020 and i thought to myself nah the performance upgrade isn't worth it over my RX 580. I'l just wait a for the next generation of GPU's.\n\nAnd now here we are a year and a half later and AMD has released another RX 5600XT/5700 GPU that costs more the old ones at MSRP and double that on the scalped market...",
      "AMD in 2016: Get the RX480 for the ultimate 1080p experience for just 200$\n\nAMD 5 years later: Get the RX 6600 for the ultimate 1080p experience for just... 330$\n\nMan GPU price is just crazy these day",
      "Here in France the main online stores are selling between 520 (pulse) and 580 (hellbound), one store even has one listed for 650 (asrock challenger) lol",
      "Same MSRP as the 12GB RTX 3060. It better end up being faster or else it'll be down on memory, speed and raytracing. At this rate we really are going to get another $200 card with RX 580 performance for the 4th time...",
      "Portugal is amazing, we have 1st world prices on everything and 2nd world wages",
      "they sell used 5700xt here for 800$. yep. used.",
      "\"$330\" ü§£ü§£ü§£ü§£ü§£ü§£ü§£ü§£",
      "The 6600 XT was cheaper at 490‚Ç¨ at launch lmao",
      "Bought my 6800XT and sold my Nitro+ 5700XT on eBay. Auction went up to $1150. I set the price floor at $300 which I‚Äôd have been happy to get and it kept climbing. I don‚Äôt feel bad about it, I didn‚Äôt start off asking for $1000+ like a lot of eBay listings.",
      "Those RX 480's used to be $110-140 for a long time. RX 470/570 new were even under $100 with rebates.",
      "The only thing the RX 6600 beats the RTX 3060 on is power consumption. That's literally it.",
      "More than that. I sold mine for $1150",
      "Every single model at microcenter is $450+. Some even $500.\n\nNot even worth it to consider at that point. Terrible card and terrible value",
      "If this thing is a $500 card, I wonder how much longer I can afford to be a pc gamer.",
      "Laughs in India, worse than 1st world prices with taxes and 3rd world wages.",
      "> RX 580 performance for the 4th time...\n\nRX 480 performance for the 5th time... *",
      "Crazy idea: a gpu that doesn‚Äôt cost 300+ and maybe doesn‚Äôt draw 3-digit watts\n\nThere‚Äôs a reason the 750Ti sold so well. Ffs give us a sub 200$ card",
      "its the same price as the 6600 xt was at launch, these cards are a joke in terms of value.",
      ">  we really are going to get another $200 card with RX 580 performance for the 4th time...\n\nWell yeah, we can't just give the poors a luxury product at a fair price. We have to milk them dry.\n\nSUPPLY AND DEMAND, BABBBBYYYYY\n\nGOTTA PUMP THOSE NUMBERS UP."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "rx6600"
    ],
    "title": "XFX RX6600 arrived today - I am so happy",
    "selftext": "",
    "comments": [
      "A year ago I wanted to build my first PC - right during the GPU crisis. So I build a system with a Ryzen 5600G as a stopgap solution. An honestly the AMD integrated graphics served me extremely well. But as GPU prices are dropping in Germany I pulled the trigger on a 6600 for 277‚Ç¨ (Mindfactory). And this thing - even though it is mid-tier - is a beast. It pulls FPS close to my friends 1080ti.",
      "Perception on this card has changed a lot. It was poo pooed on launch but now that crypto has crashed it's being praised as the best overall value for this gen.",
      "Yeah I agree with you. I think it‚Äôs 2 factors: The MSRP was ever so slightly too high (330, should have been 299) and there was a general negative vibe in the reviewer community at that time",
      "I just got a RX6600 too a few days ago (same XFX model).\n\nI have a Ryzen 5 2400G and it bottlenecks heavily that poor RX6600 because of its poor PCIe controller... I'll need to upgrade that too :(",
      "We should never forget how hyped the 3060 got by reviewers while being actually shit woth no improvement over last Gen entry level cards.",
      "Here is the [RX6600XT PCIe3 vs PCI4](https://www.youtube.com/watch?v=OXWK1WlqoBU), the only game with more than a frame difference was Forza at about +10%, this is also the model above his GPU.\n\nEven on the [6900XT](https://www.youtube.com/watch?v=jthy_hYJn5k) it's next to nothing, I wouldn't buy any new hardware just for PCIe4 at the RX6600 level of GPU. The difference may improve more as Resizable Bar support improves, but even for now a good PCIe3 NVMe isn't much different for increased frames.\n\nPCIe Gen4 is being implemented now for increased storage speed, GPU's weren't at a bottleneck yet on PCIe3. Its only been an issue with newer x4 lane cards like the RX6400, which was more AMD using PCIe4's double the bandwidth to get away with releasing an x4 card.",
      "And let's not forget the 3050 hype train and the positive reviews on day 1 when there were still no stock in stores and therefore no pricing.\n\nA day later no reviewer bothered to revisit their conclusions based on the new pricing which was almost 2x the MSRP in some cases.",
      "I have an rx 6600 too. Insane GPU, have some fun with it man!",
      "its just because paying 5-600 for this was ludicrous. but at a sub 300 price point its seriously amazing. and it has lots of haters that speak many lies about it.   \n\n\njust max out the power limit for EZ maxed out 100+fps 1080p gaming xD",
      "Nice",
      "> Perception on this card has changed a lot. \n\nThat's because reviewers really love to give Nvidia the benefit of the doubt. rx6600 had a realistic MSRP for the market conditions at the time, while Nvidia used fake MSRPs which you couldn't get the competing cards for.\n\nAnd all the reviewers sided with Nvidia and praised their fake MSRP prices while trashing AMD's more realistic prices.\n\nrx6600 didn't change, it was always an excellent card, even when the prices were inflated you couldn't buy anything better for the price.",
      "It‚Äôs a mixed bag. I read a lot of reviews. Apparently, some of their 3-fan designs still suck - but the budget 2 fan design has good reviews for simplicity and thermal performance.",
      "Yeah I think 3050 reviews were significantly more deceptive as 3060 came out in earlier in the mining craze",
      "My friend has a 6600, really good value card !",
      "I picked up a sapphire pulse 6600 on sale for 260ish usd. I‚Äôve been using it in my low wattage machine for a little while now and I‚Äôm astounded by how beefy that little card is. I‚Äôve got it running faster than my old rx5700 and it uses around 120 watts after a little tinkering. Awesome card, great choice! My overkill primary build is almost exclusively a work machine now.\n\nEdit: The card OP is using is available for 259usd on BestBuy.",
      "It seems like that GPU is very popular, I was actually gonna purchase that today.",
      "The case is a Kolink International Citadel Mesh Micro-ATX. The tower cooler is a bequiet! Dark Rock 4 Slim",
      "I hear memory OCing helps alleviate the issue a bit. I recently picked up an RX 6600 as well (Powercolor Hellhound) and am using it with a R5 1600AF on a B450 board, so PCIe 3, and it only seems to bottleneck as far as I‚Äôm aware when the memory gets full. \n\nI have no PCIe 4 systems to test on though and any PCIe 4 system would probably have a beefier CPU so it wouldn‚Äôt be an accurate test. \n\nI seem to pretty regularly fill up the memory running things at 4K High, but I‚Äôm surprised by how well the card handles it. 40-60fps depending on the game, and with FSR/RSR scaling on my 32‚Äù monitor, scaling up from 1440p looks pretty great and will get me a locked 60 in most titles",
      "Is xfx good now? Because the rx4-500 series was so fucked up, and since then I didn't dare to buy xfx.",
      "Can you tell the name of the Case and CPU heatsink models?"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6400",
      "6500xt"
    ],
    "title": "AMD Radeon RX 6500XT and RX 6400 entry-level RDNA2 cards allegedly listed with 4GB GDDR6 memory - VideoCardz.com",
    "selftext": "",
    "comments": [
      "This is $99-$119 class GPU. Interesting to see how greedy AMD will be this time around",
      "Come on Low profile.",
      "As long as the 6400 is better than a 1050TI I can see this working, a lot of people want to upgrade from the 1030s they were stuck with for 2 years or so since everything went to shit (either they build their first pc and thought that would be a temp solution or their main GPU died).\n\nThat is as long as AMD doesn't decide to call this a \"consumer friendly\" $350 card or whatever.",
      "Calling 229 for 6500XT and 149 for 6400",
      ">Calling 229 for 6500XT\n\nFinally, a rx480 replacement. /s",
      "279 for 6500XT  \n199 for 6400   \n\n\nI doubt there will ever be sub $149 AMD card ever again as it would most likely be in an APU form onwards.",
      "The only thing that could make these cards interesting is having no power connector...",
      "> That is as long as AMD doesn't decide to call this a \"consumer friendly\" $350 card or whatever.\n\nMSRP: $350\n\nCurrent market price: $600\n\nCyber Monday/Black Friday deal: ~~$800~~ ‚ÜòÔ∏è‚ÜòÔ∏è‚ÜòÔ∏è $650",
      "If the 6600 was \"best for 1080\" what will these be? Best for SVGA? 100% better than the Amstrad CPC?\n\nHave we entered the era of \"creative uses of sand\"?",
      "Great, another 580 that will likely not beat again! Good job AMD! I love the stagnation! What a shitshow of a generation for both parties.",
      "Low profile and single slot are two separate things.",
      "The 580 will likely stomp this card.",
      "\"Best for entry-level-esports-games-since-we-stopped-manufacturing-all-other-budget-options\"",
      "At this point my performance per dollar recommendation is early GCN cards.  My old 270X is still alive and kicking in my friend's machine, and aside from only having 2 gigs of vram it otherwise performs in the 1050ti bracket.  \n\n\nA quick scroll through auctions ending soon on ebay suggests $100-150 will get you into 4 gig 380's and 290's.  Not the most energy-efficient by any means, but beats the hell out of an APU or paying $300 for a 1050ti.",
      "Best for someone who just wants a GPU to drive more displays.",
      "Finally oh my god, i buy my RX570 2018 for 110 and since then there no GPU taht match RX570 Price performance",
      "Making a weak GPU is fine as long as the price is reasonable.",
      "Welcome to the new normal :(",
      "RX6400 is most likely made just for that.",
      "Sounds too low for the 6400."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6600"
    ],
    "title": "[HUB] 2016 Flagship vs. 2022 Budget GPU, GeForce GTX 1080 vs. Radeon RX 6600",
    "selftext": "",
    "comments": [
      "Pascal is just too expensive on the used market to be a worthy consideration these days.\n\nFor the EU market. A second hand 1080 will set you back 250-350‚Ç¨ depending on the model. And a new 6600 will set you back around 280-350‚Ç¨ again depending on the model.\n\nAnd thats not even mentioning the lack of any real driver optimization these days for Pascal.",
      "6600 20% faster at 1080p, 13% faster at 1440p on the average of games he tested.\n\nSome games had the 1080 as being equal to the 6600, some games were 70% faster.",
      "...Pascal was released 6 years ago??",
      "6 years to save $330 and gain 20% more performance.",
      "Yes, released on may 2016, bought my GTX 1070 on September 2016. Still a nice performer at 1080p.",
      "TL/DW?",
      "Just shows how little GPUs have progressed. It is no wonder that even today the top 3 GPUs on Steam hardware survey are still non 2000/3000 GPUs. The rtx tax and lack of meaningful raster performance improvement per dollar means there is little reason to upgrade for most people.",
      "The 1080 launched at $700. $600 AIB models launched later, and it dropped to $500 when the 1080 Ti launched.",
      "Damn, here in the US I even see 1080ti cards go for like $250 or even less sometimes (got mine for $300 at the beginning of June)",
      "I saw windforce 1080 (I think it was even Ti version, the one with 3 fans) for 225‚Ç¨.",
      "Just to put this in prospective Nvidia didn't have anything worth upgrading from Pascal for around 4 years and part of it was Turing not delivering what users wanted.",
      "What impresses me the most is in the 51 games tested, there wasn't a single case where the RX6600 was 5% or more slower than the 1080 in 1080p resolution.\n\nI think that is evidence to say the RX6600 is a very solid release by AMD. Ofcourse at 1440p you can start to see some weaknesses but AMD has advertized this card as a 1080p thing from the very beginning, so I don't fault them for that. Yes, for 250-300 bucks this is the budget option that Nvidia doesn't have an answer to.",
      "At 1080p, the 6600 almost universally beats out the 1080 by about 25%.\n\nHowever, about 1/4 of games tested at 1440p actually ran the same or slower using the 6600.  The other 3/4 of the games are about 20% faster, on average.",
      "AIB models launched like 2 weeks after FE. I think it's correct to say the 1080 launched at $600 where you could get two weeks early access for $100 more. It was just Nvidia trying to make an extra buck.",
      "\"Budget\".",
      "You talking about the 1060 that went for $250 at least?\n\nI also got a $300 deal for a 1080 in 2018. Does that represent the general market or just the specific card from that specific seller in those specific circumstances?\n\nIt's a rhetorical question if that wasn't obvious.",
      "I can find 1080 for 200‚Ç¨ or less on a dedicated forum (where people are less likely to overprice)",
      "https://youtu.be/djeL6qUTDTo?t=655",
      "The 6600 in my country is priced very much with in what a 1060 6GB was back in its day, so include inflation and the 6600 is pretty damn good.",
      "It was. The 1080 Ti launched in 2017, about 10 months(!) after the 1080."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6600"
    ],
    "title": "JUST GOT MY RX 6600",
    "selftext": "",
    "comments": [
      "Solid choice! May It serve you long and well",
      "Welcome to the club, my guy <3",
      "1.5 years ago I bought a 6600 XT, serve well. I don't wanna upgrade it yet, still enough for 1080p gaming. \n\nEnjoy mate. :)",
      "heck, i use my 6600XT for 1440p and i'm doing just fine too.",
      "I got my rx 6600 2 days ago. But my psu doesn't have the power connectors to connect to the gpu, so I had to order a new psu. I'm still waiting for it to arrive üôÉ",
      "Yeah, for upcoming AAA games it's probably not gonna age well, since they're 50% more demanding for just like 10% better graphics.\n\nBut anyway, i'm just fine with playing on mixed/optimized settings on my games, so it works well for me. Besides, the amount of modern games that i can run on ultra/high with a locked 75fps is impressive.\n\nBut in the end of the day, AAA games just aren't my thing really, i run a few demanding games and emulators here and there (which run pretty well even on 1440p) but lately i've just been appreciating some indie and older games. I live in a third world country and i don't feel like wasting three minimum wages on a GPU that gives me some overrated ray tracing on mediocre games.",
      "Adrenaline allows +- %20 pwr. Given that the default is 100, I would turn it up to 120.\n\nI left fans on auto and kept zero rpm enabled. In Windows the card will remain cool and the fans stop entirely below 45c. General temp is 30-35C.\n\nWorks well. I have the xfx.\n\nStill on 23.11.*",
      "CONGRATS",
      "132W card with 3 fans =  overclocking potential  üòã",
      "6600's power efficiency is pretty crazy. At stock it's like ~100 watts for pretty solid performance.",
      "IT'S GREAT",
      "RT right now isn't really worth the performance hit in most games, even on RTX GPUs. I think the only real issue with the 6600 and the XT/6650 are that they only have 8gb VRAM. It should be fine for 1080p right now but would probably kill it's longevity.",
      "Undervolt until it either loses stability or performance goes down. That's the sweet spot. Amd uses the same voltage for each model of gpu to ensure they can reach the guaranteed performance. However, that is usually more than needed, and more voltage than necessary will increase temps. Undervolting, if you have headroom, will lower temps and allow you to maintain higher boosts.",
      "GPU looks good, enjoy!",
      "Congrats!!!! What a great card.",
      "In games it doesn't even draw that much power",
      "It's the current \"RX 580 / GTX 1060\", best price/performance ratio and you do not have to deal with high power use, temps, noise (and if you do, just undervolt+overclock lol).\nGood choice!",
      "Congrats. It is the outstanding bang-for-the-buck card of the last couple of years.",
      "ye it shares the same cooler as the 6700xt so 100w+ of heat headroom",
      "I Don't know overclocking sadly"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6500xt"
    ],
    "title": "Happy with my 6500XT so far",
    "selftext": "Bought it for my i3 12100 build for a bit over msrp and it is delivering good performance @ 1080p. Compared to the UHD730 that I was using, I am getting roughly 7-10x more frames. \n\nFor the price I paid, the other options would be 5 year old GPUs that offer the same or lower performance‚Ä¶\n\nI understand the frustration with the product and its limitations, but perhaps the hate towards the 6500XT is a bit overblown. For me, it definitely has a reason to exist in the current market conditions.",
    "comments": [
      "The i3 12100 is probably the most realistic/best CPU for this GPU since it has PCI-E 4 but is still relatively low budget. What motherboard do you have?",
      "So you built this machine to do light gaming  and basic computing tasks that your BEAST computer can already do. The logic makes no sense but more power to you.",
      "Kinda sad that the (market)price and performance is comparable to the R9 290X from like 2013/2014. But thats the GPU market today. Everything is inflated.",
      "Asrock B660-HDV. Got it for 110 Euros. My goal for this system was to get the cheapest new parts possible for light gaming and basic computing needs. I have another build with a 3080Ti for more hardcore stuff.",
      "Unless of course this second computer is in a different location?",
      "It's quite simple, it's an entry card at non entry price. Then again miners have been f****g the whole planet for over 2 years.",
      "I'd prefer the warranty over extra performance in some games, especially on a 6500xt budget. If a used card dies and you don't have the cash to replace it you're kinda stuffed",
      "Tbh if I was building a new budget system from scratch a 12100 and 6500xt is probably the way I'd go",
      "Without HEVC encode, I wouldn't recommend the 6500xt for media stations",
      "The hate isnt overblown but there will almost always be someone who believes they got their monies worth. Your previous card and the market the way it is ya good option for a bump without going to the used market. But the same time you mention 5 year old cards with similar performance. Alot of the hate stems from those 5 year old cards having more features and capabilities than the 6500xt and some were cheaper when they launched. The 6500xt is almost a regression. Not trying to put you down or anything cus for you was a good option, just laying some facts.",
      "maybe its for a family member?",
      "It's not about inflation here. Supply-side bottlenecks and crypto scum are bigger factors.",
      "R9 290X TDP is 290 watts, RX 6500 XT TDP is 107 watts.",
      "Life in general is inflated.",
      "OP has a 12100 with UHD graphics. Use Quicksync?\nThis might actually be one of the only system configs that makes sense with this card.",
      "What people cant have Media stations now?",
      "GPU prices from *entry* to high end makes little sense these days. Entry/mid range cards cost as much as higher end cards did a few years back.",
      "People who say they‚Äôd rather go used are probably the ones who got said cards",
      "entry level is APU level now.  There is no entry-level GPU anymore.",
      "Should I upgrade? I have a GTX770 and I don‚Äôt think it‚Äôll last me another year. 6500xt doesn‚Äôt sound too bad for $200 bucks. That should get me by hopefully until market fixes itself.\n\nEdit: I just ordered the 6500xt. I thank this sub for all the good information."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6400"
    ],
    "title": "AMD Radeon RX 6400 Benchmarks: 30% Slower Than the RX 6500 XT",
    "selftext": "",
    "comments": [
      "The only explanation is this: they reached too far with technology. We have to go back to the old ways before it's too late.",
      "do we really need any more gpus in the same perf bracket as gtx 780ti/970/290/290x/rx470?",
      "It‚Äôs literally an OEM only product that is like gt1030 tier. Why wouldn‚Äôt it have low performance, when it‚Äôs literally a low performance and low price product?",
      "If they're priced accordingly, sure.",
      "like 50‚Ç¨?",
      "Because the \"low price\" is terrible compared to even years-old products now.",
      "I understand the strong feelings behind the 500xt and now 400 but these gpus help anchor prices in the low end which does affect all gpu prices. This can only help.",
      "Yes.",
      "What's up with the whining?  This is card (53W) offers GTX 970 (160W) performance for a third of the power!!!  Yeah, pricing's bound to be bad, but pricing is bad everywhere.",
      "This.\n\nIIRC, people were complaining that they just wanted something, ANYTHING to finish their builds. Enter the 6500XT, and the 6400.\n\nWould anyone who wanted \"The Ultimate 1080p Battlestation\" go for these cards? No, obviously not. \n\nBut that's because they're not for the Ultimate 1080p Battlestation, they're for getting your Ryzen rig out of the door and into your hot little hands, for a price that is in the general ball-park of halfway-sensible.",
      "Lmao Nvidia's selling 1030's for 3-4x that....\n\nI saw 4gb 580's like mine going for like \\~60$ before the launch of rtx 3000 series while the leaks were hot like pancakes.\n\nOh how the mighty have fallen, someone bought a 4 gig 580 for 500 euro on one of the local re-sale sites.....\n\nMost of them are selling for \\~350, but that's still ***what I paid for it almost 4 years ago***.",
      "It's probably great for people who are using low-end prebuilts which only have \\~250-watt PSUs.",
      "3 months from now AMD announces the RX 6300 XT which somehow has negative performance and actually takes graphics away  from your games.",
      "I would think \"hey, at least it may have more VRAM\", but\n\n* The 6400 has 4GB. (It is more than the 3GB of the 780Ti)\n* The GTX 970 has \"4\"GB as well (3.5GB fast vs 0.5GB slow)\n* R9 290 and 290X had 4GB as well, but Sapphire did their things in the past and some 290X 8GB exist.\n* R9 390 has 8 GB VRAM.\n* RX 470 has 8 GB VRAM model as well.\n\nAnd all of the above have hardware encoders (R9 390 and before using NimeZ drivers), and you can kinda use high res textures at 1080p on the 290X 8GB, 390 and 470 8GB.\n\nSo the real advantage for the 6400 I guess it would be power consumption (53W) vs 150W (970), 120W (RX 470), and the really heating rooms 300W+ (290/290X/390)",
      "Why not just supply an APU at that point. Be waaay cheaper for low performance.",
      "While true, some businesses/schools need entry-level cards for hooking up additional displays to already-existing machines. They eat this stuff up, as it‚Äôs cheaper than a Quadro and gets the job done. For a completely new build though, would definitely be better to go with an APU in terms of cost and footprint.",
      "But its a raytraced 2 fps!",
      "Also these are 6nm, so they aren't taking production capacity from 7nm Navi2 products.\n\nEach 6400/6500 sold is one less consumer trying to grab the next product up the chain (freeing up more higher end GPUs for enthusiasts).\n\nSure the price is not optimal, but these GPUs are doing their part in getting the market back to normal.\n\nKeep in mind Best Buy has GT 1030's (in stock) for $115 to $150!",
      "Yeah, and a 6800 is over 2 times its MSRP so what's your point? Either MSRP is bad, or MSRP is good and literally no one can get it for that",
      "At 2 fps"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6600xt"
    ],
    "title": "Just got the 6600XT and the Radeon software is saying I'm only using 30-40W while playing Tomb Raider. That can't be right, right?",
    "selftext": "",
    "comments": [
      "1080p 60fps that probably right",
      "GPU utilization at 62% tells the story.  That card is not being pushed.",
      "That‚Äôs probably why, Tomb Raider isn‚Äôt going to stress out a GPU like that too much",
      "Are you capped at 60 fps?",
      "it's also at just 1100 MHz, which means lower power state, and even at that state only 62% of GPU time is used.",
      "This is correct.  Gpu is idling and saving power because it's capping at 60fps. Why frame capping or vsync is good for many games that don't need unlimited fps.",
      "Yeah",
      "That seems to be the consensus. I just switched from a 390 where I'm used to hitting 80c in Tomb Raider. A difference of -30c is baffling to me. Guess I'm not used to all the advances in the new cards. Cheers!",
      "Looks about right , your gpu util is only 60% so not even pushing the card. Plus 6600xt is a low wattage card.",
      "Time to swap back",
      "3 options:\n- Leave as-is, everything is fine\n- Up quality settings to utilize GPU more\n- Get a higher resolution and/or refresh rate monitor to utilize GPU more",
      "Thats one of the uses for vsync",
      "160W TDP doesn‚Äôt mean 160W in games at all times.",
      "We've come a long way that's for sure",
      "Lol no wonder then",
      "It's because the framerate is locked to 60fps, so the card and cpu doesn't need to push more.",
      "Correct me if I‚Äôm wrong, but high clock with low usages is not bad. \n\nHeat depends on load not clock. \n\nLook at CPU‚Äòs. When you overclock your i9 to 5Ghz it‚Äôs not running at 90 Degrees all the time. \n\nAnd the clock is always more stable with low usage. Like you can boot with 5.2 into Windows but Prime is only stable with 5.\n\nI myself cap my FPS to stay in G-Sync range. \nNever had any problems. And GPU Temps are way lower.",
      "Look at the FPS number to see the whole story. OP has vsync on or has manually capped the FPS to 60. Unlock that cap, OP, and your GPU will stretch its legs.",
      "Well that answers your question. If you had the frame rate uncapped, then it would use more power to render more frames.",
      "Tip: 60 is divisible by 120 but not by 144, so if you're going to play at 60 fps you're better off setting that 144hz monitor to 120hz so 60 fps look smooth on it instead if stuttery. Nothing can be done about the resolution though, if it were 2160p you could use Integer Scaling to get 1080p at the same quality of a 1080p monitor, but 1440 isn't an integer number of 1080.\n\nRSR would be perfect for this though, but I doubt the 390 is going to get it. Maybe with modded drivers."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6600xt"
    ],
    "title": "r/AMD wouldn't let me post here when it was relevant so here it is, my almost sleeper build. 6600xt and 5600x. My first proper build and took me 3 weeks to save up",
    "selftext": "",
    "comments": [
      "i see an optical drive... i like you already.",
      "Lmao thank you",
      "How in the fuck did you get a 6600xt?",
      "Luck really, here we're so used to there being a shortage and Radeon isn't that big of a name so Radeon are 2/3 the price of their Nvidia counterparts",
      "The fact that You're using euros means they won't ship. It's called umart and it's Aussie based. My 6600xt cost $849AUD which is 536.26 euros but if you have a friend in aus it'll be cheaper to buy it here and ship it than but it there",
      "Optical drive master race",
      "No one talked about Obama Delphine. I'm disappointed.",
      "I have one too! It's just not mounted in the front of my case, no bay for it, made a bracket and mounted it inside my case. That means I have to open the side panel to change discs, but it's a hinged glass panel so that's easy enough lol",
      "totally not me who thought that it was a printer üò∂",
      "Awesome case, nice build.\n\nThat Multiscore result seems a bit low for a 5600X, should be in the 11k neighborhood.\n\nWhat cooler you got on?",
      "Sleepers are supposed to look less impressive than they actually are. This build doesn't look less impressive than it actually is: it's a humongous case with RGB, it's just not a mini tower with a glass panel like most other builds you see on here.",
      "Im saving up for a pc my while life and am still not halfway done.",
      "Stock cooler",
      "Jesus, can you link me the shop you got it from? Maybe they ship to my country too. Over here the avg 6600xt is around 700 euros",
      "Damn, too bad. Well Nvidia did say that they expect the shortage to really start clearing up second half of 2022, I'll have to wait for that or maybe rtx 4000 series to come out for a price drop.",
      "Ye, good luck with that man",
      "To be honest, for most of use case scenarios it'll be quite alright.\nBesides, it looks like you've got decent airflow in the case which is also really important, so it should be all good.\nEnjoy your build and rock on.",
      "Trust me, my mates have called it everything from a printer to a microwave man, its honestly the best part about the case is its unique design",
      "Ye, I prolly shouldn't have added how long it took me cuz it sounds like humble bragging without context, the context is it was more hours than I should be legally getting, tax free cuz it's a short stint at an adult rate in construction (pays more on average (",
      "I thought I was the only one in the world still using one.\n\nEssential for doing blu-ray rips."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6600xt"
    ],
    "title": "6600xt Before and After Liquid Metal. -8c Hot Spot/Junction Temp",
    "selftext": "",
    "comments": [
      "You applied it to your CPU too?",
      "My guess, he let it run for much longer on the first screen. His numbers might not mean much.",
      "This is a good lesson of why we run multiple trials for good data samples",
      "Looks like the cpu in the first image is doing a lot more work than in the second. The graph shows it as does the temp. That‚Äôs quite a bit extra heat in the case in the first image and can definitely affect results. Of course a LM application should see lower temps regardless so nothing to really see here but not really a scientific process conducted here either.",
      "I thought about that too, but it takes literally seconds for your CPU to reach at least 80% of max temp during load, unless you have a very large cooler. He might just have run another program on the second pic.\n\nBut your theory could be correct as well. I'd just expect a higher CPU temp even for shorter benches.",
      "No idea why. Had the same background apps running. Just a spike I'd guess.\n\nEDIT: looking at that chart it looks like it was running something for at least a minute while taking that shot. Honestly don't know. Maybe Windows updates, or something else. But I don't think it effected GPU temps at all. The VRAM load is the same and they are both at 99% GPU load. Either way I'm not removing the LM to retest lol.",
      "You can run LM safely on a GPU if you know how to apply it correctly.\n\nI have ran and still do Thermal Grizzly Condactonout on all my Ryzen CPU's and Gpus, for years now perfectly fine.\n\nObviously it's not for everyone.",
      "I didn't say it took a few seconds to reach peak temp. I said you'll reach at least 80% of peak temp in a few seconds during load. For me it takes literally about 5 seconds to reach 85c on my CPU, it maxes out at 88C no matter how long I push it. It does however downclock about 100MHz after a while and stays that clock forever. But I have a weak cooler with exceptional fans, but they're loud as hell. With a larger cooler and weaker fans it'd take a bit longer to reach peak temperatures. The hotter the cooler/CPU gets the faster it'll disperse heat.\n\nNow I mainly reach 90% of my max temp in seconds due to PBO and a small cooler. But even using an I3 with a Noctua DH-15 will definitely net you 80% of peak temp after 30~ seconds stressing it.",
      "For sure, I ran Liquid metal on my Radeon VII for the whole time I owned it.  It made a big difference, but yeah just be careful.",
      "So, not worth it then?",
      "I don't get why graphics card manufacturers have to cheap out on paste so much. I'd be more than happy to pay another $10 for them to use a quality paste like MX-4 or NT-H1 for temperature reductions.\n\nEdit: 2.1k fan speed?! What did XFX do with the 6600 XT xD.",
      "Fun Fact - Sony uses liquid metal on the PS5.",
      "That's not exactly helping their argument though, since Sony went to a LOT of trouble to ensure it never leaked and wouldn't oxidise either. [link](https://www.reddit.com/r/PS5/comments/j7b732/sony_liquid_metal_degradation_solution/)",
      "There are lots of guides on LM - never use it with aluminum, nickel plated is best but it can work with copper as well in my experience with Thermal Grizzly Condactounaut. As it is not as reactive as some other brands.\n\nFor ex. - I've had it on a Noctua nh-d14 for 1.5years with the same exact temps. (on a Ryzen 2600)\n\nJust apply the correct amount properly. You can also install a small barrier of foam etc. around the cpu if you are paranoid of it leaking out. I never have and it has never 'leaked' for me anywhere.\n\n\nThe least reactive and most stable is Thermal Grizzly Condactonout.\n\n\nThat is all I've been using for last 5 years on all my cpu/gpus. 10/10 would recommend.",
      "I've got that card and 2k RPM doesn't sound bad at all, even considering you can only achieve that kind of fan speed with an overclock. Nice and quiet.",
      "Liquid metal can short circuit components, handle with care.",
      "Probably not. Runs cool enough already. I figured maybe lower temps would cause it to automatically boost higher, but not too a consistently measurable amount from what I can tell.",
      "My friend. The fucking graphs.",
      "It takes a bit of a while to actually hit peak temperatures. Usually takes my gpu and cpu about 20-30 minutes to hit an actual max temperature that's stabilized.\n\nThe first 5 minutes of your benchmarks mean jack shit because the cpu is still cold and going up in temps. It's kind of like putting a glass of cold water with ice in a room that's hot, obviously isn't gonna change much in a couple minutes.",
      "Same thing happens with my 5600x under Dark Rock 4. It hits peak temp ussualy 10sec after starting a MT test and holds that for a long time. It is called temp equilibrium, it's normal behavior. For some ppl it takes much longer because it all depends on what kind of cooler you have and how much air does your case push...\n\nAnyway, i do not recommend using liquid metal unless you (anyone) really knows what you are doing. LM can react with the aluminum in the cooler and you can easily end up with a dead Gpu... IMO, it is better/safer to use a high quality thermal paste like Thermal Grizzly..."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6600"
    ],
    "title": "[Gamers Nexus] Insultingly Bad Value: AMD RX 6600 $330 GPU Review & Benchmarks (XFX SWFT)",
    "selftext": "",
    "comments": [
      "In Spain this card is 650‚Ç¨ ($750). With its performance, this is a 150-200‚Ç¨ card sold for 650‚Ç¨.",
      "*Laughs in rx 580 golden sample*",
      "They are trying to get us all used with the bumped up prices. It‚Äôs a horrible tactic and very bad for the industry and the consumer",
      "Just like a rebranded 5700 but cost moreüòÖ",
      "Nvidia releases an overpriced product.\n\nAMD: \"hold my beer\"\n\nThe only good thing about it is the power usage, although if u underclock the 3060 it would probably be on par.",
      "Unless we get rid of mining, there is no hope for a fairly priced product. Let's face it.",
      "Ok that price is a little concerning... I paid $330 for a 5600XT (Power Color Red Dragon) in 2020.",
      "Have you looked at recent 5700 prices?\n\nIf you can get the 6600 for 330, it would be close to half the cost of a 5700.",
      "They're saying that \"the new ETH is coming VERY soon\" since 2018 lol",
      "Because it, on the long run, will reduce the upgrade frequency of their customers, reducing their profits. And it will push more people towards consoles, where profits are minimal.",
      "Since miners will buy cards at higher prices, why should AMD or Nvidia give a shit about anything else? It's not like there are dozens of competitors taking away their PC clientele.",
      "I paid 250 for mine at launch. Sold it for enough to buy a 3060 ti. Sold that for enough to get a 3070. Sold that for enough to get a 3080...\nPeople are crazy. \nI wasn't even trying. ü§∑",
      "290 ^choo ^choo ^choo",
      "Remember when 330usd was mid-range with decent performance? Papa Pepperidge remembers",
      "You mean less/same raster perfomance, less VRAM and less features?",
      "This is insulting. AMD hit a new low.",
      "Ya gotta be real about this. They're pricing for the current market and when the market returns to normal we'd be close to the rumored rdna3 navi33\n\nWhy'd amd price it low and let the scalpers and retailers make off with the margins from price gouging? They'd rather price gouge the scalpers themselves lol",
      "My rx 580 8gb runs out of muscle before it runs out of vram 99% of the time.",
      "My 390 died yesterday. However I'm buying a used 1080ti from a work colleague. The current gpu market sucks.",
      "Obviously nobody want to address the elephant in the room but the 5700XT also mines like a child cracked up on Mt Dew playing Minecraft at 2:00am in comparison.  Not a miner here but just figured I would add that to the discussion 5700XT > 6600."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "rx6600"
    ],
    "title": "Amd quick build for a neighbors daughter 5600‚Ä¶. Rx6600 all eBay parts under $600",
    "selftext": "",
    "comments": [
      "5600 6 core processor  rx6000 gpu MSI B550M PRO-VDH WIFI 16 gb of ram t-force 2600‚Ä¶ 256gb NVME 120gb SSD 1TB hard drive 600watt psu case and lighting set up and monitor not bad",
      "it‚Äôll work just fine for a kids gaming rig",
      "Bro spent half the budget on RGB",
      "If possible move that top right exhaust to the back so that it doesn't eject the air before the cooler can take it through the fins\n\nI think I have the same case - is it the ancient Corsair one with the thick side panels",
      "Kids dig rgb",
      "If I was your neighbours daughter I would be happy. Ram can be upgraded down the line... Verry good build for the budget.",
      "Have had both the 5600x and 5600g and never felt that the stock cooler was bad. If you are gaming and nothing else it shouldn‚Äôt be a problem.",
      "It‚Äôs closed lol just tested before cable management",
      "I feel like a 5600 is ‚Äúcheaped out‚Äù. Its the absolute best bang for buck period, great choice imo",
      "should have cheaped out on the ram and gotten a closed case",
      "I actually ordered an extra fan for the rear it‚Äôs just not here yet‚Ä¶. Fan kit I got used for $14 with led strips ‚Ä¶. 6.99 for one extra fanüôÑ oh well",
      "They were ripped out of laptops getting tossed",
      "2600MT/s for ryzen?",
      "Power color fighter",
      "only change would be add a cooler, otherwise this looks amazing great work",
      "The stock cooler sucks.\n\nSource: 5600X, 5600G owner.",
      "sorry im just stupid and didnt notice",
      "> hdr\n\nHigh Dynamic Range, [this will explain it better than I can at 8AM with no coffee.](https://en.wikipedia.org/wiki/High_dynamic_range#Display)",
      "Of course he did, that's the most important part!",
      "hdr???"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6400",
      "6500xt"
    ],
    "title": "AMD Radeon RX 6500XT coming mid-January 2022, RX 6400 in March - VideoCardz.com",
    "selftext": "",
    "comments": [
      "Im waiting for a 3010 that‚Äôs just a rebranded 610. Sold for 299$",
      "on Nvidia side: RTX 3050ti 6/12GB, RTX 3050 8GB",
      "Yeah but with 12GB of VRAM",
      "It's a mechanical hard drive.",
      "Plot twist: it's ddr2",
      "Eh, the whole RNDA2 lineup apart from the 6800xt is uncompetitvely priced against Nvidia this generation\n\nI say this as a 6800 and now 3070ti owner, RDNA2 is uncompetitvely priced at MSRP (it's price matched on rasterisation performance), and in the actual retail market they're marked up higher than Nvidia with the exception of the 6600/6600xt\n\nAt MSRP, the cards to get are the 3060ti/3070/6800xt/3080\n\nThe 6700xt/3070ti/6800 are not ideal but not actually that and at MSRP, just worse compared to the good ones \n\nAnd I do want to stress, the MSRP of the above cards aren't even that good, they just look good up against Turing, which was a notoriously shit value generation\n\nEdit - Just thought I'd add to this, in my experience for anyone looking for an MSRP card, look for the 3070ti FE, it and the 3080ti FE are the easiest cards to get at MSRP (I do not recommend the 3080ti FE), admittedly still not easy",
      "In normal times, these would be great $100-150 options for new builders.",
      "Good talk",
      "It blows my mind that this generation going to be over a year and a half old, at least, before we get the entire product stack launched from either team. \n\nWhat a cursed gen, Jesus...",
      "I wouldn't worry about mining.  There are alt coins and actually there are some miners that allow you to mine ETH with 4GB cards. It is Ethash4G.  However, the 6500XT will be a $1/day at best.  Even if an OEM came out with an 8GB model, it is gonna do half what a 6600XT can do, which will barely put it over $1/day atm mining ETH. \n\nWhat is gonna happen is these will be in a combination of short supply, OEM markup, and the AMD branded cards will be scalped to OEM markup prices.  \n\nThe only way prices won't get inflated is if AMD can crank out so much stock that it would be impossible for any retailer to sell out. People using bots will find they ordered hundreds if not thousands of them causing these people to freak out and cancel all their orders.  No line would be long enough to sell out at brick and mortar even if the MSRP for it's performance is actually a really good deal.",
      "Care to elaborate?",
      "> Well AMD will get what they deserve with selling 128/64bit stagnation overpriced cards.\n\nBy \"what they deserve\" do you mean \"sell every piece of product they could put on the shelves?\". Because that's what would happen. \n\nPeople talk here like AMD has to be competitive with Nvidia in this generation to sell cards.",
      "Tape drive.",
      "I can't believe people still think this. It was supposed to happen this month, and it had already been pushed back multiple times.",
      "Who cares what AMD sets the MSRP at though?\n\nMSRP's don't matter at all for the consumer within a month after launch during normal times, and don't matter at all at the moment.\n\nit seems people are under the impression that MSRP's are set in stone or something. Actual prices will change depending on market forces. it doesn't matter what AMD sets the MSRP too, they'll end up at he price the market is willing to pay anyway. \n\nAll that chances with a higher MSRP is more money for AMD instead of scalpers and exploitive retailers.",
      "Well AMD will get what they deserve with selling 128/64bit stagnation overpriced cards.\n\nI think most consumers will remember all this behaviour from AMD since MOST AMD users always was Price to Perfomance users.\n\nAMD shareholders and fanboys are welcome to downvote me.",
      "Yet not everyone lives in the US, near Microcenter or stays 24/7 to snap something.\n\nIf I went last year on Newegg/Amazon at 2 PM in a Thursday, how many MSRP cards could I get?",
      "Stone tablet.",
      "Yeah, if only I could believe whatever MSRP they list is actually going to be what the price is. Instead of a massively inflated version of it.",
      "Cave painting."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6400"
    ],
    "title": "AMD launches Radeon RX 6400 low-power RDNA2 graphics card at 159 USD - VideoCardz.com",
    "selftext": "",
    "comments": [
      "i dont know why 2022 GPU without Encoding capability is feel like backward to 2009",
      "Guys i think they meant $59 USD.",
      "Never understimate how far people would go to defend trash from a company they like.\n\nBack in 2019 you could buy an RX 580 or 570 with full encoding capabilties, full PCIE bandwidth and 8GB or VRAM for the same price. Hell you could get used versions for around 100$.",
      "Wait til the \"nobody other than the streamers need video encoding\" crew figure out normal people screen share in zoom or other services sometimes and their dual core isn't enough for it.",
      "Seems to be pretty much equivalent to the gtx 1650 3 years later for the same price. Granted, there's been inflation and while the silicon shortage is better but still a thing. So I'm not too upset by the positioning and pricing of this product, it's about inline with what I expect.\n\n\nWhat sucks is it has the same PCIe bandwidth issues as the 6500xt and no video encoding. I get that the 6500xt was a last minute laptop card turned desktop but AMD has had more time to prepare for this card. Without these problems it would have been an acceptable card given the current market conditions.",
      "If priced at sub 100$, it would be an interesting replacement for the crappy gt730 that still flood the lower end market.\n\nNot sure how the pcie x4 will fare at this performance level. Thinking of my sandy bridge htpc, with pcie 2.0\n\n\nPS. Just saw [this](https://www.techpowerup.com/review/amd-radeon-rx-6500-xt-pci-express-scaling/29.html) 6500xt scaling review. Holy fk, 66% performance with pcie 2.0.",
      "GT 1030 does NOT has NVENC of any kind.",
      "> Im sorry but I‚Äôm pretty sure a gt1030 can capture its own clips in nvidia‚Äôs drivers\n\nUpvotes for being wrong, huh? GT 1030 can't make use of GeForce Experience in any capacity, so it has no recording capabilities without an external tool.",
      "Some people don't need encoding though. Not everyone is a streamer. As long as you have decoding 70% of people would be fine 99% of the time.\n\nAnd CPU encoding can handle stuff in a pinch, say 720p discord screen share or whatever.",
      "No it isn‚Äôt. \n\nIt also has less pcie bandwidth, vram, and no encoder.",
      "Hate to break it to you...but it's not 2019 anymore.",
      "AMD using a laptop GPU to fill a gap in desktop product stack.\n\nNot a bad product if retail pricing comes down a bit.\n\nI expect Intel to make a splash in the low end soon, which will shake things up.",
      "There is no good (or even acceptable) way of doing it which wouldn't be slower than CPU while also awful for quality.\n\nSource: I was an XviD developer back in the day and looked into using GPUs for *something*. It's just the wrong tool. And modern codecs are even more complicated in the GPGPU-is-the-wrong-tool direction.\n\nModern video cards wouldn't have completely separate encoding/decoding cores if they could avoid it.",
      "This isn't a 6500xt and this article has benchmarks showing it's roughly equivalent to a 1650. And depending on the bandwidth you can get performance substantially lower than a 1650.",
      "Im sorry but I‚Äôm pretty sure a gt1030 can capture its own clips in nvidia‚Äôs drivers (edit: as pointed ou, this is false, it does not have nvenc) and I know rx5xx cards can too. There is no reason for  the rx6400 and 6500 to not have an encoder. This is not the worst value in the current market but the moment the prices finally come down, these cards turn into e-waste, with the only use for the 6400 being retrofitting older systems with a gtx 1650 alternative from amd, but even then the PCIe x4 limitation will be a problem since‚Ä¶ well older systems don‚Äôt have PCIe gen4, and if you‚Äôre buying a system with PCIe gen 4, your integrated graphics won‚Äôt be much slower",
      "Very much this!\n\nMost people do not seem to understand where transcoding resources are required.\n\nFor people that get it, this forces them to go Intel. Quicksync is great and is widely supported, so pairing one of these only for gaming on a budget isn't a terrible option.",
      "tf you could buy a rx 570 years back for this price... is this piece of trash at least better than rx 570?",
      "Sure they can, but encoders take up space on the silicon die and thus have cost and power consumption. Given that this is a low-end laptop part being re-packaged for desktops, it's understandable why they eliminated it originally (laptops are obviously highly sensitive to power consumption and pricing).\n\nAnd again, lots of people would never use it, especially so for those who would be purchasing a 1030 or 6400. And if they needed it in case of a screen share, that's what the CPU is for.",
      "Another shit GPU at a shit price.",
      "Never said this was a good value, just pointed out that the lack of an encoder is hardly an issue for the target audience.\n\nI don't even have an amd product at the moment, not exactly a \"fan\"."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6600"
    ],
    "title": "AMD Radeon RX 6600 XT Review: Worse Than Expected, But Can It Be Saved?",
    "selftext": "",
    "comments": [
      "Let me get this right: due to the 6600 XT featuring PCI-E 8x rather than 16x, it will **perform worse** on PCI-E 3.0 systems - say, motherboards like B450 and X470, for instance?",
      "Yeah, Doom Eternal in particular was absolutely brutal in the performance drop.",
      "Overpriced by at least $100.",
      "> It even manages to lose out to the 5700 non-XT in Doom Eternal. Embarrassing.\n\n[Meanwhile AMD marketing](https://techgage.com/viewimg/?img=https://techgage.com/wp-content/uploads/2021/08/AMD-Radeon-RX-6600-XT-Generational-Performance-Uplift.jpg)",
      "Just a reminder this is supposed to be a 1080p card priced at almost 400 dollars and will 100% be priced higher than that on the actual market. Nobody should be paying 400+ for a card that's made for 1080p gaming in 2021. That's just a joke",
      "AMD are not your friend.",
      "Like others have said, in Doom Eternal the performance drop was so great that it was outperformed by an Rx 5600 XT.",
      "thats the most favorable review of this card showing only 10% difference at 1080p. Other reviews show 15% and over 20% at 1440p. This shouldnt have been priced more than the actual 3060 non Ti",
      "In normal times this is a $250 card at best.",
      "Congratulations AMD for bringing us RDNA1 performance for RDNA1 prices. \n\nScamdeon just lost all their price-perfomance reputation that they was building for years.",
      "128bit bus and 8 PCIE lanes at price of $380 msrp in 2021 üòÇ - fucking shitshow is that? It's specs for office crap like GT 1030. AMD became so disgusting. Personally - wouldn't buy this crap even at msrp. If the market wasn't in such state - it would be far more beneficial to get used 5700XT, especially for people on PCIE 3.0",
      "As GN Steve rightly said, material costs and other overheads don't qualify as a valid excuse when you're announcing record profits. And they are. Nvidia and AMD are creaming major profits.\n\nLet this generation be considered proof that any ideas that AMD were somehow consumer friendly was total nonsense. The second they got to within spitting distance of Nvidia's performance (a charitable assessment of their performance) they abandoned competitive pricing.\n\nAnyone who doesn't need a workstation computer or who isn't rich should forget PC gaming imho. Console killers are a thing of the past. $300-400 'budget GPUs' are the meta.",
      "That's because this is a $250 product parading as a $400 product. The MSRP for 3060ti was set sensibly before AMD and NVidia said \"fuck it, MSRP doesn't matter\". So now we have cards like this one, the 6700xt, 3070ti, (and to a lesser degree) 3060 with terrible MSRP.\n\nThese are going to go for above $500 anyway. MSRP just decides how much of that goes to the manufacturer.",
      "They are, so will 6600XT's in just few weeks. Especially when there is exactly zero reference models at MSRP. The strix is officially a 550 dollar card. It wont even be lower than that because its official price, there is not a single card released at MSRP.",
      "Everything about this screams \"$200 card\". I even think the PCIE x8 lanes were a last minute decision to save costs just because they can nowadays.\n\nOf course, with demand outstripping supply and shipping costs and raw materials costs being what they are, if this is actually available at MSRP, it will be the best deal of the year.",
      "That ray tracing performance is insanely bad compared to the 3060 ti. The 3060 ti was regularly 100+ percent faster not even including DLSS in a lot of cases dang",
      "Lol. Just yesterday people were applauding AMD on here for charging a premium for their products. The duality of r/AMD users üôà",
      "I would not have complained if this was a $300 card.  \n\nWhile not the $200 dream point many want, $300 isn't miles off what the better 580's and 1060's used to go for.  So it wouldn't be an amazing price, but I think at least acceptable.",
      "amd is banking on shortage to make their card look more palatable lol",
      "So I paid $400 for a 5700xt with a little more performance and then AMD themselves launch another newer gen card for $379 which will never even be sold at 379??? What are they doing lmfao"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6600"
    ],
    "title": "Performance summary: Radeon RX 6600 XT vs Radeon RX 5700 XT at 1080p, 1440p, and 4K",
    "selftext": "",
    "comments": [
      "$400 for a 1080p card.",
      "AMD should have given it 64mb of Infinity Cache. While it wouldn't prevent the large performance hit at 4K, it might have been enough to advertise it as a 1440p card instead of 1080p.",
      "Thanks, I hate it.",
      "Reminder this GPU is roughly the same size as Navi 10/5700XT. \n\nThis is a complete fucking dud of a product and the asking price is an insult.",
      "I'm sure they left enough space for an RX 6700 to fit in between the two XT cards.",
      "5700xt was prolly a gem of card. People who bought it in 2019 made an excellent choice.",
      "Well, its crap. \nThis is to expensive even at msrp. \nThe whole generation is simply #skip\nNo hope for mid range gaming. At this stage a console is the solution. PCMR isn't for people that factor money into equation.",
      "I‚Äôm seeing a lot of acrimony and bullshit going around about AMD‚Äôs marketing and 1440p, etc. here‚Ä¶\n\nI ran a 5700 XT until this year with a 1440p/144 Hz monitor, and it ran every title I threw at it on high settings at 1440p just fine.",
      ">5700xt was prolly a gem of card.\n\nIt wasn't even that great, it just had a big lead on Nvidia in terms of process technology.  It was still surprisingly inefficient and only looked good thanks to Turing being so crap.\n\nIt was still a 251mm¬≤ GPU being sold for $400+.  Nothing to celebrate at all.",
      "Wait till you see how much an rx580 costs",
      ">> 5700xt was prolly a gem of card.\n\n> It was still a 251mm¬≤ GPU being sold for $400+. Nothing to celebrate at all.\n\n[Barely 2x the performance of the RX 480, for 2x the price, after 3 years](/r/Amd/comments/g7ky62/unpopular_opinion_navi_is_an_overpriced_midrange/); that's just sad.",
      "That's more than I got it for new in 2017.",
      "Probably the infinity cache hit rate\n\nhttps://imgur.com/QfSB3bU",
      "I know I am on the AMD subreddit, but man, the RTX 3060ti is a better value. When the hell did Nvidia do that?\n(on paper, at least,because the chip shortage and inflated prices are still here)",
      "#I no longer allow Reddit to profit from my content - Mass exodus 2023 -- mass edited with https://redact.dev/",
      "I thought the 6700xt was advertised as the 1440p card though.",
      "Not capable enough for them to advertise it as a 1440p card I suppose",
      "Because that will kill the 6700 XT? Especially that the 6700XT is already in a bad spot, it's priced 80$ more than the 3060Ti for very little performance gain.",
      "Except in real life I can get a 6700xt much cheaper than a 3060ti",
      "It‚Äôs worse than the 5700xt at the same exact price point. Two(?) years down the line. \n\nHow is that not a dud"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6600"
    ],
    "title": "The AMD RX 6600 is currently going for 17‚Ç¨ bellow MSRP in my country",
    "selftext": "",
    "comments": [
      "This price is with 24% VAT",
      "At some point the basic power color model was being sold for around 280‚Ç¨. Which is still way too much for a tiny little 1080p card with 8gb of vram. For me this card is worth at most 250 at this point.",
      "Œ¶Œ†Œë = VAT",
      "VAT is included in listed prices in all of the EU though, isn't it? Unless it's different for Greece.",
      "I think that the messege was more of a note for people from US, so they don't think it's super overpriced, but just slightly overpriced",
      "Value added Tax.... In all products",
      "Calling it a tiny little 1080p card is underselling it. I play at 1440p at high settings and high FPS. It's a mid-range champion.",
      "I thought the same three years ago. 5700X, this card is 300‚Ç¨. I wait for 260‚Ç¨. Then it was 700‚Ç¨ and I bought a refurbished PS4 with a couple of games instead.\n\nThere is little chance that the 6600 will be dropping to any thing meaningful, not with this market and inflation. I bought one in a 'sale' for 280‚Ç¨ because it will never reach the 'real value' next years.",
      "Even with VAT included. This is a really bad deal atm. Paying MSRP for 18 monthes old technology isn't that smart. If you can wait, then do it until  the new generation GPUs to be released to see the prices go down even further.",
      "Ah now I get it",
      "What is VAT?",
      "I disagree with you. I think GPU prices are going to drop a lot. Because of \n\n1. Low demand caused by a bad economy. \n2. Overproduction, Nvidia has tried to postpone the production. But TSMC refused.\n3. Mining equipment change - I remember Ethereum won't be mined with GPU in the near future",
      "Skroutz the goat fr. Nearly as much as I paid for my rx 5700 XT",
      "Well my budget is 350, so as long as it doesn't go above that, I'll gladly buy it",
      "The 8GB PowerColor Radeon RX 6600 Fighter is like 275 EUR for weeks now. Where is the news?",
      "Its about in line performance wise at a GTX 1080. Which even today will do 1440p as low-mid. \n\nConsidering $300-$350 its a pretty decent card. \n\nBut considering price to where it lands on the current generations stack. Its not a value for your money till around $270-290\n\nCosidering the 6500xt is an MSRP of $200.",
      "I know, I just saw the price being bellow msrp so I decided to post about it",
      "Œ¶Œ†Œë",
      "<300‚Ç¨ in GER atm",
      "They are extremely good I have the XFX 6600 and it games very well in 3440x1440 2k ultra wide on a 10th gen i5"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6400"
    ],
    "title": "Leak confirms custom Radeon RX 6400 graphics card are indeed coming - VideoCardz.com",
    "selftext": "",
    "comments": [
      "...god this thing is just gonna be a bloody display adaptor given how anemic the 6500XT was...",
      "At this stage they could release a lump of coal with a HDMI and displayport and it would sell",
      "At least it'll probably be so slow it won't have the 6500Xt's issue of choking in a PCIe Gen 3 slot (unless it has only two Gen 4 lanes or something)",
      "Basically HD graphics for those without APU.",
      "Depending on the benchmark/metric the 6500xt is 3-3.8x the performance of the Vega 8 on the Ryzen 5000 APUs or the GT 1030 DDR5.\n\nThe 6400 has the same memory bandwidth but 3/4 the CU's and a 15% lower clock.  **At worst it would still be** ~~2.25-2.9x~~ **1.9x-2.45x the performance of the 5000 iGPUs/GT 1030.**\n\nThe 6500xt is about 2.1x the performance of the 1050ti.  So the 6400 would be at worst ~~1.5x~~1.3x the 1050ti.\n\nConsidering people have been buying 1030's and 1050's for ridiculous prices (seen $130-$150 for the 1030), the 6400 (at an expected $150) isn't a terrible proposition.\n\nCould it be cheaper?  Sure.  Will it?  In time.  Is it a good GPU for playing newer AAA games? Oh hell no.  But it does quite well with a lot of games at 1080p and med to low settings.  Several times better than an iGPU for sure.\n\nEdit: the 6400 does have a 15% slower clock speed so adjust the numbers above accordingly.  So the 6400 becomes 1.9x to 2.45x  the performance of the Vega 8/GT1030.\n\nIt's still an upgrade for those on an iGPU for those that want to play older games or games with modest GPU requirements.\n\nEdit2: Best visualized with this relative GPU performance chart.  A Redditor added lines for the minimum and recommended GPUs for Elden Ring.   Note where the 6500xt falls:\n\nhttps://i.redd.it/h8p5sk3o30i81.png",
      "AMD wanted to create a card that wouldn't be throttled by all the PCIe x1 slots that everybody has but almost nobody has a use for.",
      "We need something greener... coal is bad.  How about soft Peat moss.",
      "Bring back AGP for this turd.",
      "Imo the 6500XT was perceived as terrible mainly because of the x4 connector. It's about as fast as a GTX1650 Super at PCIe4 and around a regular GTX1650/RX570 at PCIe3. And here I can get it new for just a little cheaper than a 1650. Not a great deal, but everything else (new) looks like a worse deal. So it's actually kind of an ok card imo. In this shitty climate at least, if things get better, it's also gonna fall in price.\n\nI'd guess a 6400 would be somewhere around a 1050/1050ti. Even if it's slower than that, I still wouldn't call it a display adaptor. That's reserved for the GT710",
      "Yup it'll choke just by looking at it",
      "id like one of these for my file server just for basic vulkan opencl support",
      "Not true - the GT 1030 *also* dropped the hardware video encoders, similar to the RX 6400 and RX 6500 XT. It is also limited to 4 PCIe lanes - and only PCIe 3.0, at that.\n\nLike these AMD cards, the GT 1030 is effectively a laptop gpu put onto a desktop card. (In laptops, it's perhaps better known as the \"MX150\")",
      "The problem with that is that one of its biggest markets is people trying to eek one last upgrade cycle out of a machine with a GTX760/960 and almost every one of those people is on a PCIE3 board.  \"Can afford B550/X570/Z690\" has a very narrow crossover market with \"Can't afford 6600+\"",
      "It's the same chip as the 6500xt just cut down on CUs.  So 4x PCIe lanes and the same L3 cache, memory, and memory bandwidth.\n\nWith 3/4ths the CUs and lower clock speed it only needs 53w.  So this card will likely only need power from the PCIe ~~adapter~~ interface.",
      "Why not? People aren't buying generations, they're buying cards. If there's currently nothing on the market to fill a price point and the 6400 will fill it, then great. If the price isn't right, then not great.\n\nIt's kind of sad that prices, even now that they've gone down, aren't great, but I think it makes no sense to judge a card based on what's been available in the past. All you're doing is lamenting the current market, that's not a problem with the card.",
      "A 750 ti replacement with 750 ti performance",
      "So basically the equivalent of a GT 1030 now",
      "So much negativity in here. God forbid there are options. Also, I don't understand why everyone here complaining it's going to be weaksauce... I mean, yea...no shit. It's a god damn ultra low tier card. But if you don't like it then the card isn't designed for your needs. There are 7 more cards tiered above this one.\n\nI'm confused as to what the issue here is.",
      "At $750!",
      "It's not, just cheaper... but that's okay, we need a 750ti replacement."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6500xt"
    ],
    "title": "Today's launch of the 6500xt further cements the RX 580 as one of the greatest gpus of all time.",
    "selftext": "If you purchased a RX580 now 5 years ago for around 200 USD then you should be throughly pleased with the value that you received. Few other GPUs have delivered as much price to performance, and this kind of longevity. \n\nThe RX 580 is a hall of fame worthy GPU. \n\nWhat other GPUs would you elect to the GPU hall of fame based upon price to performance + longevity? \n\nThe 1080 Ti comes to mind for me, but I'm sure this AMD crowd will be able to name many more.",
    "comments": [
      "All the 10 series cards were really good. Th 580 was also great.\n\nGood times",
      "The problem is that the RX580 launched at the beginning of another crypto bubble and it wasn't available for $200 until late 2018. I mean, some people got it for that price, like some people managed to get cards this generation for MSRP, but those were the exception.",
      "I'm still using my 480 and that thing is still holding strong and kicking ass. Absolutely worth every penny.",
      "> cements the RX 580 as one of the greatest **midrange AMD's** gpus of all time\n\nFTFY.\n\nGTX 1060 cost roughly the same, had a similar performance yet it's a much more efficient and thus quieter card. And to this date it's been the most popular GPU ever released/produced: https://store.steampowered.com/hwsurvey/videocard/",
      "IMO, the HD7970 was the greatest gpu AMD made. It had an incredibly long lifespan, and it's still capable even today. The issue is really just driver support anymore. That was a top of the line GPU in 2012 and they continued to rebadge it for a few more generations IIRC",
      "I bought mine in February 2017 for $186 and sold it two weeks ago for $375. That thing performed on par with the S&P 500!",
      "No doubt the 1060 is in the hall of fame.",
      "I got my 480 (8GB) for 239EUR in release week (founders edition fromm saphire) and sold it couple of weeks later and purchased a 1060 with about 80EUR surplus.\n\n480 = 580 - 5% Performance",
      "R9 290",
      "everyone was angry at Raja for only shipping mid-range cards with polaris. all these years later and AMD ships a gpu that barely holds up against it. CPU industry got back on track but GPUs have just been going straight into the toilet since the polaris/pascal days.",
      "The 580 was not the top end of AMD. It was a rebranded 480, which was slower than previous AMD GPUs (easiest to name being the Fury/Fury X).\n\nThe RX 580 was never positioned as a top end card. AMD completely abandoned the high end until the release of Vega. It was always a GTX 1060 competitor.",
      "When I got my RX 570. The 580 I could find for as low as $160-$175 after MIR.  My RX 570 I got for $115 and I believe I got it near its lowest point.",
      "RTX 2060 and 5700 XT were still very impressive. I reckon they'll be remembered well\n\n1660 Super was also a great 1080p card too.",
      "RX 580 might only be the greatest hall of fame worthy GPU because its successors just have been overpriced garbage. This is a bad thing, not a positive thing.\n\nEither way I think this was the RX 470/480 not the 570/580 personally.",
      "Let's be honest, navi lineup was quite good. 5600xt, 5700 and 5700xt have aged extremely well despite all driver issues they initially suffered from.\n\n5500xt however was a disappointment",
      "These are the gpus that were pretty damn awesome for it's time and provided a relatively long term solution newest to oldest:\n\n&#x200B;\n\n1: RX 570/580/470/480\n\n2: R9 380/380x 4GB.. though the R9 285 2gb was still solid\n\n3: HD7870\n\n4: HD 5770\n\n5: 4850/4870/3850/3870\n\n6: HD2600xt\n\n7: Literally ANY Radeon 9500-9800 non pro, but arguably even the pro were too.\n\n8: 8500LE",
      "Why not rx480 by the way? Basically same card but released earlier. Price? Clocks?",
      "My list:\n\nGeforce2 GTS 32MB\n\nRadeon 9700 Pro\n\nGeforce4 4200\n\nRadeon X800 XL\n\nGeforce 8800GT\n\nRadeon 4870\n\nRadeon 6950\n\nGeforce 970\n\nRadeon 7970\n\nGeforce 1080 Ti\n\nRadeon Vega56\n\nRadeon 5700XT\n\n*Forgot the Radeon 6950.",
      "I just hope people bought the 6GB variant and not the 3GB one.\n\nhttps://youtu.be/ySmMb4X7qbA",
      "1060, 1080 Ti, and RX 580 seem to be THE GPUs of that generation."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6600xt"
    ],
    "title": "The fact that the 6600XT will not be available on AMD Direct Buy ends many people‚Äôs chances at getting a card at MSRP",
    "selftext": "During this global chip shortage, OEM‚Äôs and retailers in the EU have been forced to mark up their GPU prices leading to buying at retail not being an option because of how ridiculous the prices are. (For example my local store is selling their cheapest RTX 3060 at 699‚Ç¨). In the midst of this, AMD Direct Buy has been a way to get cards at actual MSRP, even if the website is flawed and it may take a while, everyone I know that has tried to get a card, has gotten one, even if they had to try for 2-3 months. Here comes the 6600xt, a card that I finally can afford and that isn‚Äôt overkill for my type of gaming. And I find out that any small chance I had at getting this card at MSRP is gone because it does not have a ‚Äúfounders edition‚Äù or reference version that is sold on AMD Direct Buy, so I‚Äôll keep rocking my R9 380 until RDNA3 I guess. I‚Äôm sorry if you read this, I just needed to vent a little.",
    "comments": [
      "Many people won't be able to buy this gpu period.\nThe manufacturing will be bleak at best.\nThis is going to lead to poor allocation.\nIf by chance you see one in the wild, you had better snag it if you want it.",
      "> so I‚Äôll keep rocking my R9 380 until RDNA3 I guess.\n\nHaha he thinks they‚Äôll be any stock of rdna3 cards when they drop. \n\n\nThis shortage is gonna last a lot longer than they want to admit.",
      "> I think Nvidia has out done them on the goodwill\n\nUnfortunate but goodwill ain't gonna sell cards. Pricing low is something you do when there's massive silicon supply and when there's low demand for gpu. Nvidia overcharged with turing and the result is a 80% market share. The gpu market's sayin that people buy cards based on performance leadership marketing and not price\n\nGoodwill ain't a thing in business, the prices are all strategic and goodwill's somethin people say only when they want more for themselves\n\n1. Are the people ranting about 6600xt's price appreciating the \"goodwill\" of 6900xt costing $500 less than the 3090? Probably not \n\n2. If amd's next gen products are shit tier and they'd ask fans for some \"goodwill\" to buy their products would people do it? Probably not \n\nIt's cut throat business where it's every man for himself, consumers or corporations all the same",
      "Well, to be fair, i think that rdna 3 will be massively overpriced aswell. If stock is being sold out mostly now for as much as 100 to 150% msrp.. Why wouldn't they be able to ask for that next round?   \n\n\nI am curious though about rdna 3.. I mean, graphics already look amazing. What would that be in the future? 4k 165hz+  8k 60fps? Huge improvements on raytracing? What technology is next?",
      "GPU's are just stupid now, almost $400 MSRP for a 1080p card when you can get a series x game pass machine for $500,  that can do 4k 60 with compromises.  \n\nWhat's the point in DIY for average gamers at this point, valve could just bring  out another unlocked console with ps5/Xbox like specs with access to everything and that would be a killshot for most of this market.",
      "This is so disappointing to me. As much as I love AMD, I think Nvidia has out done them on the goodwill torwards gamers front. Nvidia released limited hash cards and EVGA has a wait list. Nobody on AMDs side can say this. At least not to my knowledge.",
      "I like day dreaming, what can I say?",
      ">\tI mean, graphics already look amazing.\n\n\nCompared to the past, sure. Compared to the endgame of photorealistic without severely limited draw distance? We‚Äôre not close.",
      "We have different incomes in different countries. For example my month income after taxes is 200$ approximately. And no, this \"issue\" cannot be \"addressed\" in any significant way.",
      "EVGA having waitlist is their decisions not nvidias right? so more like props to EVGA and shame on other aibs",
      "I am so glad AMD hasn't put artifical limits on what their GPUs are allowed to run like Nvidia has. Thanks to their open source Linux drivers, they probably couldn't either, which is good.",
      "Not quite becoming less demanding on hardware, but I think that once GPUs are good enough to raster 4k at high refresh rate then they can start dedicating more hardware to RT and ML features since the other side of the problem is basically \"solved\".",
      "Is the lower hash rate cards really accomplishing that much though?  Seemed more like a marketing gimmick than anything.  Especially with ethereum trying to move to a model that doesn't involve proof of work anyways.",
      "There were some discussions regarding the current gen's wafer allocation.  Obviously this is speculation so don't take it as if it was taken from an official statement.   RDNA2 for PC's is speculated to receive the least amount of wafer allocations, the bulk going to consoles and Zen 3 as its currently the money maker.   My point being is that I'm extremely hopeful that when 5nm products come around that its less of an issue and that RDNA3 gets a more aggressive push as Radeon has really come a long way, and apparently wafer capacity will match 7nm without consoles cannibalizing the wafer capacity.",
      "I think native rendering 4k high refresh rate is the new goalpost. After that idk. Maybe just thinks like raytracing becoming less and less demanding on hardware",
      "nVidia introducing LHR only hurts the market further. With mining boom, there is more demand than supply until the prices get to current crazy price levels. But limiting cards to either mining (no display outputs) or gaming (LHR) means you can not shift the cards between those markets, so have to produce enough for both, further increasing demand.",
      "Yeah, I don't think that account is real at all.",
      "Bye Bye PC gaming.",
      "Crypto to the moon again, be prepared we are going back to May market pricing...",
      "Really you think the overpriced 3080ti was good willed? Lol if you want to get a card in 2021 without paying 200% MSRP you pretty much have to go AMD. Demand for nvidia cards is way too high right now unfortunately"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6600"
    ],
    "title": "MXM form factor RX 6600 teardown",
    "selftext": "",
    "comments": [
      "Cool stuff. \n\nNot related MXM modules or anything, but there are quite a few 6600M desktop cards being sold at AliExpress for a while now, and for $200 or less. Looks good, at least based on reviews.",
      "Man I love this, I wish MXM was more accessible",
      "Got my hands on an MXM form factor RX 6600 and tore it down yesterday.\n\nWhat a lovely compact design using Micron GDDR6 (4x 16Gb modules), OnSemi power stages/voltage controllers, and high quality capacitors. Notes:\n\n- There are two NCP81022 4+1 voltage controllers with 10 phases in total (7 for VCore and 3 for GDDR6/SoC?)\n- Each phase is handled by an integrated OnSemi 55A power stage\n- VBios is set to 75W TDP, but I was able to push it past 130W with MorePowerTool and survive Furmark stress indefinitely. With the tiny heatsink, it matches my Desktop RX 6600 performance which has a 3X larger heatsink and two fans.\n- Curiously, there is no fan header on the board. Instead, the fan plugs into a host controller board on the other side of the MXM interface.\n- Manufacturer is Hightech (HIS)\n\nSo MXM is not dead yet....",
      "Where?  Wow thats nuts!  Surely configured for edp and not lvds?",
      "Why is this not marked nsfw? This is easily porn",
      "Quad DP with this VBIOS but surely configurable for anything. All connected via a host controller board ;)\n\nManufactured by Hightech (HIS)",
      "ok i'm going to check this out it looks like the 6600m is faster than 1070m and i'm seeing a parity in the desktop gpus as well. this could be half the cost to upgrad a form a 980m to a 1070m and faster and have better linux support.",
      "Its for a Thunderbolt eGPU. But I think there are higher-end models intended for some sort of Server or ETHmining application.",
      "It's not MXM, that's why I said it's not related. It's a 6600M chip on a pcb made for 6600s and XTs. Sorry if I made you think they were MXM modules.",
      "ƒ∞s it a laptop?",
      "Honestly, I thought that it was dead for years now, dropped before MXM3",
      "Interesting, ive been wondering which modern cards would get MXM treatments. I've heard of but not yet seen Ampere MXM cards in Clevo and Eurocomm documentation and im glad to see RX 6000 is getting the same treatment. I wonder if any 5600m MXM or other RDNA 1 MXM cards exist",
      "Nah, the government and some workstations still take this standard. Companies like Dell/Alienware used them up until 2014, clevo I believe still use a modified version of it that can be supplied their own power.\n\nPNY still designs GPUs for this form factor! It‚Äôs rare but you can find RTX 2060s and RTX 3000/4000/5000.\n\nI‚Äôm looking to get a GTX 1070 MXM in the next couple of months for my Alienware 17. Such a cool concept; too bad people want thin and light BGA crap",
      "I missed MXM",
      "According to this post, yes. Though I do wonder if the MXM fingers on this card support PCIe 4, since the latest MXM 3.1 spec explicitly supports PCIe 3 x 16 lanes.",
      "Oh the Turing Quadro, I see.\n\nI was gonna say that you shouldn't link webpages from the future cause that's an easy way to get your time traveler's license revoked..",
      "I didn't know mxm was still a thing for laptop gpus.\nLast time I remember hearing about mom was in 07. That was when I was trying to fix an Alienware for my at then boss.",
      "\"RTX3000\" exists in MXM but I'm not sure if its Turing or Ampere as the naming for Quadro and server applications is weird. Regardless its super low TDP.",
      "it sure looks like an MXM connector, whats the difference?\n\nEDIT: as to say that PCB looks like it would fit in my laptop with little issue.",
      "RTX 5000 is a GPU that‚Äôs already out. You‚Äôre getting it confused with the series, which is not what I was referring too."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6600xt",
      "6600"
    ],
    "title": "My experience going from 5700 XT > 6800 > 6600 XT",
    "selftext": "So I had the reference 5700 XT since launch for about 18 months. It served me ok, but the card would get so hot / loud (even tried an aftermark cooler) that I had to use it at about 90% of its clocks with some undervolting. Also had issues with HDMI audio that never got fixed (hw issue apparently). So while satisfied, I was eager to upgrade to RDNA2.\n\nThen the 6800 launched here in NZ for a reasonable price, I was even able to get it on \"special\". Powercolor Fighter, boy, this is the best GPU I've ever had. No RGB BS, ultra quiet, such a performer. With some undervolting (as my HTPC case isn't great), card used about 160-180W and you couldn't hear it. The \"useless\" 16GB of memory have seen up to 15GB used!!! when playing at 4k plus AA. Seriously, highly recommend.\n\nNow, I haven't been playing for months and such amazing card being idle was a discomfort to me. Decided to see for how much they were going - miners and all - and was surprised with what I saw. Long story short, sold it for \\~25% more than what I paid 7 months ago.\n\nOf course I had checked what was available - plenty of 6600 XT here for the same price 5700 XT were sold 2 years ago - so I grabbed one right away. XFX Speedster QUIK 308, screw RGB.\n\nComparison with 6800\n\n\\> testing here at 1080/1440p and it has between 65 and 75% of the 6800's performance, while costing 53% of that 6800's sale price. I'm happy. Noise wise, with overclocking and no undervolting (2750@1150mv and 2200+fast timings), it's maybe a notch above the awesome 6800 Fighter, but still a great and quiet card.\n\nComparison with 5700XT\n\nAs stated above, due to case constraints, the 6600XT is about 20-25% faster and MUCH quieter. The HDMI audio issue was fixed in the 6000 gen so there's that too.\n\n&#x200B;\n\nFor overall desktop use and Youtube/Media Player Classic, this card is amazing. Fans always idle, uses so little power to play even 4k videos, just perfect.\n\nVery happy with my awesome HTPC card + single player gaming here and there.\n\n\\>>> Is it worth the upgrade from a 5700XT?\n\nYes, as 5700XT are going for crazy prices (mining) you may get a 6600XT for $0 or even make a profit",
    "comments": [
      "I've had my RX 5700 XT since November 2019, and despite some driver issues early on, it's worked pretty much perfectly for me. I admit I don't game a lot anymore though. I'm afraid to sell it in case I can't find anything to replace it with.",
      "I thought it is going to be something negative since most people post about problems.",
      "I've never felt such a strong connection to a card before. From 6200 OC, to 9800GT, to GTX 460, RX380, RX480, (5700XT here) and with the 3070 now. 5700XT was such a good card for the price. Definitely felt bad letting it go for ~$950 after my buddy snagged an extra 3070.",
      "Great to hear your experience with those 3 cards!",
      "nah it has been great on me, nothing to complain :)  \n\"oh but it's soooo expensive\", well, here in NZ a high end 6600 XT is going for \\~70 USD less than an entry level 3060 non TI",
      "hell you can get a 6700 xt with how much 5700 xts are selling for. That's what I did",
      "Considering it was twice as expensive as 480 and twice as fast, I wouldn't consider it a good card for the price, it only looked good compared to the equally overpriced Turing.",
      "What is the HDMI audio issue you are referring to?",
      "So true. The 6700XT is a \"mediocre\" card according to everyone, but I fucking love mine. It's a beast for 1080p 165hz and does everything I need it to.",
      "Upgrades for free are the best upgrades",
      "I think we live in a buy now think later market. Of course unless you‚Äôre buying something from zotac that is borderline scalper prices",
      "This is awesome.",
      "There was nothing to be impressed about when you had twice the performance for twice the money 3 years after 480.\n\nWhen I upgraded my 270X to 580, I got double the performance for almost the same money - but well, I guess those days are over, especially since people are pleased with anything right now.\n\nOh, and we're discussing about periods where GPUs **weren't** money printers, now it's a different story altogether + COVID, inflation and all that.",
      "since when a \"3070 with 12GB of memory\" is mediocre? these people",
      "In NZ they are just that much cheaper, and I'm also a long date AMD fan. I had heard that other 5000 series models (5500,5600,5700 nonXT) didn't have the issue so I was confident on the 6000 series.",
      "Yeah, I have a 5700 and haven't noticed any issues with HDMI audio on the rare occasions I use it.",
      "5700XT has some audio drops through HDMI, like a second long drop every few minutes. Not sure if it's only triggered with some specifics devices (Sony and Yamaha here), but if you research you'll see a lot of people talking about this particular issue. Fixed on 6000 gen (5700 non xt was ok I think)",
      "Really depends on what 5700XT you have tho, I own gigabyte 5700xt aorus and not only it is super quiet and with low temps, but it also basically run 2020MHz 24/7\n\nNot to say 6600xt is not great if you can swap for free (not possible where I live and most place's), but it‚Äôs not that simple conclusion and also depends on what exactly are the two cards in question. Mine is basically a lot faster vs reference that was a lot faster vs how you ran yours + no issues like hdmi audio and 4 years warranty - won‚Äôt swap it for just any 6600xt and ofc - I will not swap it for 6600xt at all as this will be not any upgrade performance wise (potentially it will be overall a downgrade). Would swap for 6800xt or up, but I am planning to wait for the next gen.",
      "May I ask why did you decide to stick with AMD GPU despite the issues you had with the 5700xt ?\n\nIn the end it paid off, but still out of curiosity.",
      "Do you have a link to these issues being actually acknowledged or documented?\n\n\nI had ZERO issues with my reference card while using HDMI audio to a Denon receiver also a Sharp TV."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6600"
    ],
    "title": "AMD Starfield bundle starts on July 11th, will include Ryzen 7000 CPUs and Radeon RX 6600+ GPUs. - VideoCardz.com",
    "selftext": "",
    "comments": [
      "so if I buy starfield I get a ryzen 7000 and a radeon rx 6600 for free? \n\nnice.",
      "I wouldn't trust Amazon to honor the promotion even if they listed it, they never honored the 7900XTX \"The Last of Us\" bundle when I purchased a XTX earlier this year.",
      "That's exactly what the article title says, so lets go with yes!\n\n&#x200B;\n\nI'll take 10 please.",
      "So HUB makes one video taking sides with the consumer and calling out anit consumer practices, and all of a sudde they're the bad guys now?\n\nWell I personally don't like siding with a corporation so I will \"whine and complain\" if that's what having principles makes you.",
      "They still owe me a copy of Company of Heroes 3 I was supposed to get for my 5800X3D I got months ago",
      ">Okay boys, let's hear it. Let's hear the complaints and the whining about why this is bad. I hear Hardware Unboxed already has a video in the works on this topic.\n\nVery mature. Why are you getting so emotional over your beloved company getting called out for having committed to a very anti-consumer move possibly for years now?\n\nThe argument has nothing to do with game codes that are bundled alongside hardware. At no point was this issue with AMD's sponsorships about the actual games being some extra freebies that you get with your hardware. Clearly, that's not the problem here.",
      "I mean, I wish could use DLSS in this game.\n\nRIP\n\nit looks way better than FSR to me",
      "LOL the same day I bought a 7800X3D and never got Jedi Survivor either üòÇ",
      "Yeah but it's epic games store",
      "If I knew it would be that early, I would wait out instead of getting RE4.",
      "I'm 99.999999999999999999999% sure that people **don't** have a problem with games being bundled alongside hardware purchases.\n\nBut sure, pretend like that's what people have been complaining about, if lying to yourself makes you feel better.",
      "That would be evil",
      "At least a rx6600, they might even throw in a Rx 7900xtx if you're lucky.",
      "You have to register your product with the company offering the promotion. It's not Amazon giving away the game.",
      "Retail price for the game, in Taiwan dollars. Because that's the source.",
      "Won't it be harder to mod? I get that you'd be saving money on Gamepass but for a Bethesda game you'd want it on Steam surely",
      "We don't know for sure but going by the last game the steam version is the one you want for modding.",
      "Hmm the bundle will only be available on Newegg, Amazon...? Or does it apply even when I buy from a local retailer?",
      "game is already on gamepass day 1 anyway",
      "This is bad because I should have waited before getting my 7800X3D."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6600"
    ],
    "title": "Sold a 5-year-old 1080ti for $220, bought a used XFX RX 6600 XT Speedster QUICK 308 Black for $150, this sidegrade makes me happy with power consumption and noise (virtually silent even at max load)",
    "selftext": "",
    "comments": [
      "people see \"NVIDIA 1080 Ti used\" for sale and they will throw their wallets at you. \ngood bucks to be made by switching...",
      "All hail XFX and their Qick cards, such high quality construction.\n\n\nEDIT, auto correct to Quick, the naming is really not the best",
      "Yep, the card is 5 years old already.",
      "But a good card, though! The 1080Ti still holds serious chops in many aspects! \n\nSo, what kind of games are you looking forward to playing with this newly redefined rig? :)",
      "Personally I prefer the Swoft to the Qaick.",
      ">But a good card, though! The 1080Ti still holds serious chops in many aspects!\n\nDefinitely. But it's just old and could be failing anytime soon. So, time to say goodbye.\n\n>So, what kind of games are you looking forward to playing with this newly redefined rig? :)\n\nJust CS:GO on my new 1440p 165 Hz ultrawide and some not too demanding RPG games in general. The 6600XT is just right.",
      "I got 150W max power on stress test. Not only power difference, but noise as well since this is a more efficient card, and then there's the price.",
      "The performance is similar to the 1080ti: faster in some games, slower in some games, but overall it's the same. For power consumption and noise, it's huge upgrade in this department.",
      "so how's performance? is it the same/better/significantly better? I got no clue and I think about switching myself from 1070 to either 6600xt or 6700",
      "Swft<Core<Qick<Merc<Zero for RX6000",
      "Remember when the budget cards were awesome, and 200 bucks, and the top tier enthusiast cards were 500? and were a fraction of the PC build cost, and not a multiple of it?\n\nSigh.. good ol days..",
      "Played Divinity Original Sin 2 yet, maybe? Deserves a playthrough if you're kinda into DnD :)",
      "cooperations are simply not your friend, you really need to learn that. so there is no reason to treat them like that. no madness involved at all, that would be kinda shizophrenic since companies are not only not your friend, they also are not persons to have feelings towards - of what sort ever.",
      "How does the naming scheme for XFX cards work?\n\nLike, I know with Asus that ROG STRIX is their higher end stuff, with TUF below that, and usually a TURBO model that is a reference card with a blower cooler.\n\nAnd I recently learned about Sapphire, with their Nitro+ and Toxic models at the top of the range, with the Pulse etc being below those.\n\nI've seen XFX have cards like the MERC, SWFT and QICK, with different numbers attached too. What's that all about?",
      "Don't think people buying this kind of performance are often above 1080p, and the 1080 Ti is still quite powerful to his day (was a match for the 5700XT/RTX 2070, which aren't any slower than the 6600XT). It's probably losing steam in DX12 games but still, it's no slouch. ?ot sure why one would buy one at this price though",
      "Actually above 1080p is where the 1080ti claws back some ground. It's kinda hard to find good comparisons since the 1080ti is pretty old now, but Hardware Unboxed did a revisit a few months ago comparing it to a 3060 and 5700xt. \n\nWhen compared to the 3060 the 1080ti was 3% faster at 1080p but 5% faster at 1440p. When compared to the 5700xt the 1080ti was 3% slower at 1080p but equal at 1440p.\n\nI would imagine the same would hold true when compared to a 6600xt, probably due to the 6600xt's anemic memory setup.\n\nI think the 1080ti's memory config is really helping it's longevity. The 1080ti has 11GB GDDR5X on a 352bit bus which is good for 484.4 GB/s. Meanwhile the 6600xt is 8GB GDDR6 on a 128bit bus, good for only 256GB/s",
      "Agreed, my 1080ti is still going strong at 3440x1440 hoping to upgrade eventually with 7000 series assuming prices are reasonable, but not actually in any hurry to upgrade as I can still run most games on medium/high at 100+ fps (except bf2042 lol). On most older games (which is what I normally play, games like BFV, BF1, Destiny 2, Dayz) you can max out all settings and still easily hit 144+",
      "Which is bizarre because those cards are going to require some maintenance and are seriously showing their age at resolutions above 1080p",
      "Heh, even in games like Star Citizen, the 1080Ti is still a champ. The only exception being when you turn cloud settings to... Well, \"on\". \n\nOther than that, you only need a Schwarzenegger-CPU, then you're fine (I'm drooling over the 5800X3D, heh). \n\nWell, and preferably more than 16GB of RAM. \n\nWell, and you definitely need to have the game on an SSD. \n\nWell, and the page file of your OS on an SSD too. \n\nAnd THEN you're fine... Well, as fine as anyone can be.\n\nSo yeah, I'm glad plenty of games exist that are being continually optimized for older GPUs :) \n\n(In a sense, that's true for Star Citizen as well, as they basically based their performance target around the 1060 6GB card. Pre-cloud tech, anyway.)",
      "Not yet, but surely in my list, along with Pillar of Eternity and Trine series. Hopefully I can play these games at 144 fps with APU in the future."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6600xt"
    ],
    "title": "Small upgrade - 2600 + 1070 Ti to 5600 + 6600XT!! And still rocking a B350 board.",
    "selftext": "Managed to get a 6600XT for ~$190 USD from a miner and a 5600 for ~$140 USD. I sold my old parts so not much money spent!\n\nSpecs:\nRyzen 5 5600\nGigabyte Ab350m gaming 3 mATX motherboard\nScythe Fuma 2 Cooler\n16gb DDR4-3200 Trident Z RGB\nSeasonic Core GX650 PSU\nSama IM01 Case\n1TB NVMe, 2TB HDD and 1TB SATA SSD for games\n2x Arctic P12 Slim PST Case Fans",
    "comments": [
      "No such thing as overkill when it comes to air/water cooling. It means you can either run quieter, cooler, both and means your CPU goes through lower temperature differences thus preserving the life of it.",
      "5900x and 6700xt on a B450 board here, runs great!",
      "For a 65w cpu, that cooler is a bit overkill imo, but those 2 fans do create additional airflow. Its a neat build. Good job.",
      "Yeah, I went 5900x over the 5800x3D for the cores for vms and such. Bought the cpu before the gpu here. Impulse bought the 5900x to replace my 2600x when the prices first dropped, so it was paired with a RX 580 4gb for awhile. (Surprisingly, the 5900x got a tiny bit for performance out of the rx 580 that was noticeable in some games, like being able to up graphics settings).\n\nAs for the 6700xt‚Ä¶‚Ä¶I was originally looking at a 6800 non-xt, then settled with the 6700xt cause I only have a 2560x1080p ultrawide monitor. Also the price was right when I got it, got mine for $420 while the 6750xt was still in the $500 range and 6800 non-xt was in the $550s at the time",
      "How much did you sell the 2600 for? I just got a 5600 as well. Enjoy your new upgrades!",
      "Just curious, why did you get a 5900x if you \"only\" have a 6700 XT. Did you just need more cores for CPU workloads?",
      "Yep. But if peak temps stay below 80s, its a smooth sailing. I've had a 1600x running in 75-80c always under load in office pc, never had any issues until now. Though silicon lottery might also be in play.",
      "Upgraded a friends MSI B350 Tomahawk + 1600x system to a 5800x using the same motherboard. Quite amazing we can do that!",
      "No, I'm not. I'm just curious. Not sure why you had to come at me like that but I can see why you did.",
      "Isn't AM4 bloody amazing?\n\nI've been from...\n\nGTX1080 with a Ryzen 1700\nThe. A 3700X\nThen recently I upgrade to  5800X3D and RTX 4080.\n\nWhat a platform I have like 185+ % increase to CPU performance on the same damn socket!!\n\nASUS crosshair 6 hero board here :)",
      "I did the same upgrade and I sold my 2600 on eBay in July for $75 without the cooler. If you‚Äôre doing eBay put the 2600 in and make sure to select ‚Äúcompleted/sold‚Äù auctions to see how much it really sells for.",
      "Ngl I bought it cause it looks cool, but its also real quiet even on load",
      "Mostly gaming and VR. I mod a lot of games like Rimworld and Skyrim, which is quite straining for single threaded CPU performance so the upgrade is pretty nice",
      "That last bit is grade a pure BS but yes quieter is better.",
      "Downvote. Temperature changes is what damages the silicon.",
      "One percent lows should be better, as well.  Also depends on the game.  30% could mean difference between playable and unplayable.",
      "Well scientifically you are right (it'll probably be way more than 10ks) , but what I'm saying is cpu are designed to handle such swings for upto 5 years. And as i mentioned, silicon lottery affects the failure rate to. And on 5600, everything other than its stock cooler is great( that thing was shit)",
      ">just benchmarks great \n\nWhat lol.\n\n5800x3D wipes the floor with every other 5000 series CPU in gaming, and I haven't heard of a single person saying they were disappointed by it's gaming performance.",
      "Same board upgraded 1600 to 5500, 1070ti to 7900xtx",
      "It will after bios update"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6400",
      "6500xt"
    ],
    "title": "AMD Radeon RX 6500XT and RX 6400 to be the first 6nm graphics cards - VideoCardz.com",
    "selftext": "",
    "comments": [
      "Exactly. The only one sub-75W GPU \"available\" will be in OEM hands.",
      "That 6400 sounds great. 53W low profile is certainly something I'd consider buying if it was available. Hopefully it won't be OEM-only forever.",
      "What, does Airbus manufacture GPUs now? Whose card is that?",
      "How's it a waste?\n\nIt's literally the opposite on a newer wafer with lower yields.\n\nIf your wafer will have an estimate of 20 defects and you make 20 big chips out of it chances are more than half will be defective and a 50% yield.\n\nIf you make 400 chips and you have the same defect ratio then you get 380ish good chips. 95% yield.\n\nThat's why they're producing the small ones first.\n\nAlso, budget market (sub 300$) hasnt seen any major revolution since what, 2016 Polaris? We're in 2022 and if I spend 200$ today I won't even get 580 performance.",
      "A380 is shaping up to be quite a market killer at this point.\n\nThe name still sounds ridiculous by the way.",
      "A fan-less passive 6400 GPU!? now that's talking!!! :)",
      "I cant wait for a small formfactor card that isn't the gt710.",
      "RX 480 for $200 is still a good deal 5 years later. smh",
      "Intel",
      ">A380\n\nNo way I'm fitting this in my case!",
      "pipecleaner cards to push the way for bigger badder faster cards",
      "For desktops it will certainly be better than currently available APUs by a significant margin. Rembrandt's 12 CU RDNA 2 is expected to be GeForce 1050 Ti level or so. That's a lot faster than any current iGPU. The 6400 is likely to be somewhat faster.",
      "As if you were going to be able to buy them for less than a million dollars if they went retail.",
      "Bet it sounds like a jet.",
      "Interested to see how it would stack up against my 570. Though if 6600s were a decent price, I'd already have one.\n\nAlas, matters are as they are, and 6600s are rare, snapped up by greedy miners, or selling for a King's ransom.\n\nStill, I can dream of a future where a Mid-tier 1080p card runs cool, quiet, and above all, Efficient.",
      "The best value card I ever bought was a used RX460-4GB just before things went north last year for AU$80 (US$60), with its 75w no extra power. Played REre2/3 at 1080p/60 on High with Capcoms early equivalent of FSR.\n\nI would be interested in another mITX 75W card if it wasn't so profitable to only do cards that everyone wants for mining.",
      "50W are 50W, irrespective of nm process.\n\nLess RAM and lower TDP does of course mean the non-GPU part of the board should be simpler indeed.",
      "Does it really matter if they are not available or affordable?",
      "A380 should be official GPU for Microsoft Flight Simulator.",
      ">Ah, yes. The budget gamer arrives. Tell me, how much have you mattered to AMD or NVIDIA? They know you‚Äôre so irrelevant that they‚Äôve neglected the budget segment altogether. NVIDIA will be using TSMC 5 nm for their next GPUs. Can‚Äôt wait to buy an RTX 4090 to keep destroying budget gamers in every game. Everyone knows frames win games.\n\nQuoting your dumb reactions in case you sober up and feel like an ass.  /u/lizardpeter"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6600"
    ],
    "title": "The RX 6700 (non XT) got real cheap ... for those looking for RX 6600 XTs look no further!",
    "selftext": "",
    "comments": [
      "I envy US pricing and... don't get it.\n\nMid/low range GPUs are promised in summer.\n\nWhat is going to replace RDNA2 GPUs once current inventory is sold out???",
      "Damn, I bought my 6600xt for $600. More than the rest of my pc.",
      "They'll keep making rDNA 2 alongside rDNA3 to keep utilizing their 7nm capacities",
      "Those non xt 6700 cards are cheaper than 6600xt/6650xt in my country so they're no brainer here. More vram, proper x16 interface and more power.",
      "The RX 6600XT got phased out.\n\nNavi 23 is now:\n\n* RX 6600 - $189\n* RX 6650XT - $259",
      "Nah, this time Canada got the best deals\n\nThey got 6750 XT reference model from AMD direct store for $293 USD. I was one of them üòÉ",
      "According to TechPowerUp's database and [this guy's review](https://www.youtube.com/watch?v=6FkQdAViLIs) (cross-checking with his data because TPU didn't actually have a review of the 6700).\n\nThe 6700 is around 6% to 13% faster than 6600XT. The 6600XT itself is [7% to 20% faster](https://www.techpowerup.com/review/msi-radeon-rx-6600-xt-gaming-x/28.html) than the 5700 non-XT and \\~6% faster than the 5700XT (depending on resolution).\n\nThat means that the 6700 is around \\~36% faster than the 5700 non-XT, that's a significant margin.",
      "I didn't even know AMD released a non XT 6700.",
      "I paid $1200 for a new 3070 TI at the peak of prices, now AMD has the 6900 XT on sale for $629. I knew prices would come down, I just never expected it ti be that fast",
      "Or....Ebay, 6700XT for $310 shipped. used of course.",
      "Ever so slightly faster and two extra vram! Not a bad deal at all.",
      "I mean you can, but you end up with the GTX 970",
      "US pricing is a hell of a thing...",
      "Still waiting for 6600 XT for under 200 or 6700 under 300 (‚Ç¨). Thats what these cards should cost. The current lineup is trash, with the 6500 XT being actually worse than a 2016 card for the same price.\n\nUsed marked prices are sick, they for example demand 150+ for a Vega 56.",
      "the 320 price is in dollars, I see also ‚Ç¨380. You can't compare prices in different markets.",
      "That's unreal. I paid about the same for my 580.",
      "It was a pricing error that was only up for a short bit, site was down by the time I tried to buy one",
      "I got a used 6700xt that still has warranty until 12/2024 for 185$",
      "How does the SWFT309 say ‚Ç¨320 for you and for me it's 380?\n\nI'll also disregard that you have free shipping too.  \n\nEDIT: Misread the currency",
      "Canada =  Little USA"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6600"
    ],
    "title": "Are these temps normal on an RX 6600 XT running Heaven Benchmark, the Tjunction temp will go up to 85c while the normal temps stays below 61c.",
    "selftext": "",
    "comments": [
      "I would say yes considering my 6900XT got to 94¬∞C Junction real quick.",
      "Doesn't AMD specify that junction temp up to 110¬∞C is fine/even normal? Or was that just the 5000 cards?",
      "[\"Operating at up to 110C Junction Temperature during typical gaming usage is expected and within spec.\"](https://community.amd.com/t5/gaming/amd-radeon-community-update-more-control-over-gpu-power-and/ba-p/418629)\n\nThey said that about the 5k cards but I guess it's still applicable here, as I've seen pretty high temps from 6k cards aswell.\n\nAs long as they don't reach throttling territory it shouldn't really matter. The cards shut off as they get too hot anyway.",
      "Same. I don‚Äôt worry unless 95+",
      "At TPU they have data for a few models. Hotspot/Junction temps go from 80¬∞ to 98¬∞: https://www.techpowerup.com/review/asrock-radeon-rx-6600-xt-phantom-gaming-d/32.html",
      "The junction temp is the hottest part of the die. If you're coming from an Nvidia card they keep that number hidden by default (probably so they don't have to deal with people freaking out about it), but you can expose it with 3rd party monitoring programs and the behavior is exactly the same as AMD with the junction temp anywhere from 10 to 20 degrees higher.",
      "Tjunct temp is supposed to be higher than core temp so 80c is really good. personally i would let it run at 90c+ for lower fan speed tho",
      "Water",
      "I am so happy with my 6800 Merc319. Even under full load the Tjunc never exceeds 75¬∞ C",
      "Well within tolerances.\n\nIt won‚Äôt kill itself either.",
      "Isn't that rpm loud af?",
      "Sounds like you need to up your clock",
      "I know this is an obvious thing but you could try to lower the rpm to have it like at 25% at 69¬∞ and then 35% for 79¬∞ and like 55 or 54% for 90¬∞ and it should still be able to cool it down unless you are trying to run games at highest on 4k that is ofcourse. Otherwise i think with the config i have you should have an solid rpm below 2000 or so under full load and temperature waging near 80¬∞ junction temp and 60¬∞ somewhere for normal temp.",
      "No problem. Try to use Unigine Superposition or the 3D Mark suite though. They are a bit more modern than Heaven, which is ancient at this point.",
      "My 5700xt used to go to 112¬∞C before watercooling. Normal though. AMD says limit at 120¬∞C or smth (at least for mine). I'd imagine the other RX series cards now are built similarly",
      "thanks for the info.",
      "Yes sir it is.",
      "For junction? Yeah totally. That chip gets hot.",
      ">AMD says that up till 110 degrees it's fine but we all know it really isn't \n\nAnd what evidence do you have to say this? Presumably AMD's official statements are based on their own knowledge of how they've engineered it as well as their own testing data, which we're not privy to. Meanwhile, anything arbitrary we as consumers can say such as \"90C is safe\" or \"80C is too high\" (and I've heard both of those in the same thread before) come from nothing more scientific than our own personal *comfort levels* with various temps. Much of that is based on historical conventions that don't apply anymore (after all, at one point a 50C CPU was considered hot).\n\nIt's just like the old R9-290X debacle, where AMD officially stated they were designed to be run at 95C, and everyone freaked out because they were convinced that 95C would kill it in a matter of weeks. Lo and behold, I have an R9-290 that's been run on the stock cooler at 95C under full load still alive and kicking today, 8 years later.\n\nI won't say no to cooler temps when they're available. But in the absence of conflicting data, I'd be inclined to trust any manufacturer's official statement.",
      "For the temperature? Any good monitoring utility with a temperature chart (not just a number) will visibly show when it's leveled off. I'm not sure about Radeon Software, but MSI Afterburner and GPU-Z both have charts.\n\nIf you're talking about overclocking stability, that's a different story. I try to run through all of Time Spy, Fire Strike, and Port Royal stress tests, then 12-24 hours of Superposition."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6600"
    ],
    "title": "So about those 6600 XT prices...",
    "selftext": "",
    "comments": [
      "Sapphire Pulse can be had for ¬£380 here in the UK, has been in stock since release.",
      "Just don't buy it. Problem solved.",
      "Genuinely amazes me how they've held up, or overclockers just took in the entire European shipment of cards",
      "Hey, it's free market. When my ancestors wanna buy GPUs at MSRP, they made USSR.",
      "In my country they did land at around the MSRP in the first days after the launch.",
      ">$560\n\nI'm not sure if you can consider yourself lucky :)",
      "Still significantly cheaper than the 3060 in my country.",
      "I got downvoted into oblivion and people thought this would land around the msrp lmao",
      "Feels more like the latter (to an extent at least - more likely OCUK got a strangely large supply of them if nothing else) because the Pulse has always been a super popular card, would be extremely odd for it to barely be selling (especially given the price) when other models are selling out as expected.",
      "Because it was near MSRP in many countries outside of the US.",
      "I'm just as amazed that oc aren't bumping the pricing up on them like everybody else. We both know that oc is selling a boat load of them and they love to pump up the pricing, I'm wondering if there was a deal made where they could have a boat load of stock but had to keep it at a pricing sapphire wanted",
      "#I respect you for saying that.\n\nIf you don‚Äôt want cards over MSRP then stop spending more than MSRP.\n\nAnd cards we want aren‚Äôt ever at MSRP anyways, they‚Äôre usually higher by $100(+/-).",
      "Yes you could also use an AMD APU in the meantime. And less gaming and more learning (e.g. videos) is good for the career. ;-)",
      "Overclockers isn't selling them to anyone outside of the UK anyway",
      "In Norway the prices are more or less MSRP, but still not worth it!",
      "So much complaining MSRP, and didn't grab MSRP cards at launch day when had a chance.  \nAnd here is the real street price, so keep waiting folks.",
      "That by itself is a miracle",
      "Price fixing is where different parties agree not to sell lower than an agreed price so they aren't fighting against each other and ends up worse for the consumer. Setting a maximum price that a card can be sold for is a completely different matter and is actually good for consumers. I'd take bets that this is what has happened with overclockers this time around, they usually aren't shy of bumping up the price if they think their customers will pay it, I bought a MBA Sapphire 6800 at release and overclockers were charging about ¬£50 over the MSRP for it at the time.\n\n&#x200B;\n\nEdit: I spoke too soon, the Sapphire Pulse has gone up by ¬£15 today, cheapest now is the PowerColor Fighter at ¬£390.",
      "I got mine for ¬£330 including VAT (Net of VAT it is ¬£275 which is $380).\n\nThey were actually available for MSRP for a short while and in the UK they are still cheaper than 3060's",
      "I would never consider Amazon prices to be a real judgement of the current state of the market. GPUs have always been overpriced there, and have the most egregious examples of price gouging."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6600"
    ],
    "title": "RX 7600 review roundup demonstrates disappointing performance/price vs RX 6600 despite RDNA 3 GPU performing 27% better",
    "selftext": "",
    "comments": [
      "The RDNA2 is clearance stock, great while it lasts but will dry up\n\nClassic Radeon, it's a poor buy at $270, but will be fantastic at $200-250 in 6 months when it's been forgotten about",
      "If the two only positive/best things that can be said about your GPU is that you'll stop producing the other better ones to increase margins, and that it'll come crashing down in price soon enough... Well, you're probably AMD. Then again there's nothing positive to say about Nvidia's except the 4090 is a huge leap... When's intel dropping some new hotties?\n\nAnyone in this price tier should either grab a 6700 10 GB while they still exist, or go used. I got a 6700 xt for 220 with 2 years warranty left a couple days ago. And sales tax here is 15% so even more savings there. Receipt price is 1265 from the scalpocalypse... Oof.",
      "I think it‚Äôs aimed at new buyers on a budget or people who skipped a gen or two who are also on a budget.",
      "This. I know it's a poor gen on gen upgrade, it's quite a boring GPU for guys like us but if you already own a 6600/xt/50xt you don't really need an upgrade. \n\nNew people building PCs in a few months will appreciate the 7600. People still on a RX 580 or GTX 1060 who finally decide to upgrade, it's good for them.",
      "I doubt you will ever find a card to buy, with that expectation.",
      "27% faster than the 6600 is a decent gen-on-gen upgrade, *especially* for this market segment.",
      "it's not (just) about margins, it's about getting rid of old stock",
      "4060ti was dunked on by majority of reviewers. What",
      "In the used market he very easily can",
      "It's 100‚Ç¨ more my man, I'm not spending that money.\n\nEDIT: proof, before I get any shit for this. https://amzn.eu/d/fs9LMWP",
      "The used market has its own drawbacks.\n\nDue to AMD's aggressive new pricing, I don't find used RDNA2 cards to be worth it tbh. The price is slightly lower than new, but you still have to pay sales tax and likely much more for shipping.\n\nFor example, after shipping the *cheapest* BIN 6600 on eBay is 160, when you can get a brand new one with a game and free shipping for 180.\n\nHWS is an option, but imo any legitimately good deal gets purchased so quickly that you pretty much have to F5 to actually get anything. And Facebook Marketplace is complete fucking garbage frankly and a huge PITA in my experience.\n\nYou could buy a gen older used, but that has its own clear disadvantages too.",
      "I honestly think that the 7600 is an impressive step forward for a card that performs quite a bit better than the 6600 and 6600xt. \n\nFor the price you are paying for, along with more modernized core architecture, its a good buy. And as per always, AMD normally makes their cards very competitive as time goes on with better drivers altogwther.",
      "Reviewers yes, we'll see what consumers think.",
      "After seeing the 7600's price/performance I just bit the bullet and bought an RX 6600 for 206‚Ç¨  \n\n\nWill keep it for as long as I can, next purchase will probably be with an entirely new build.",
      "The more you buy, the more you saveüòé",
      "Production of those cards stopped a while ago lol. It's being phased out now hence the bargain bin prices for remaining stock. Not really a fair comparison.\n\nCompare it to the $400 4060Ti instead.",
      "Usually new gen offers better value than old gen even if it's on its way out. At least if it's interesting. To get better value on a 2080 ti than a 3070, you had to buy used. 980 ti was also terrible value when 1080 ti was launching same for 780 and 980, etc. Otherwise why launch it? Just keep giving us rdna 2 if it's better value. It's not like there's new tech even on offer. Like how is your launch supposed to be exciting if all it's making me wanna do is buy your older stuff?\n\nAnd what's worse is 6650 xt's have been available around this price for like 6-12 months. So who's this card for? Anyone who wanted this type of performance at this type of price could've had it for the last year and been gaming away. It would've been substantially better value, if you buy it now it's more of a giving in \"ughhhh fine\" than exciting.",
      "under $200 is where this card will shine, 8GB above 200 is just a stupid purchase.",
      "I'm not denying that, but it's clear that RDNA2 is going to sell out soon enough that the reviews will age like milk.\n\nI just don't like the idea of thrashing an AMD product solely because they cut prices on older products. Pragmatically, AMD is going to see that feedback, and we'll end up with either of these:\n\n1. They ignore it\n\n2. They artificially hold pricing high like Nvidia did. Then, when they launch the 8600 for the same price, it'll look like a good deal.\n\nI'd rather have the current situation than the 6650 XT being 330+ dollars so the 7600 looks better.",
      ">It's not our position to bitch verbally about new products being worse\n\nWhos position is it then if not the customers? The dudes working at AMD? TSMC?\n\nAnd yeah, for the past 25-30 years we have expected and gotten 20% increase in perf each generation for same price cards. \n\n\"When the 6000 series is gone you have no other choice...\"\n\nYes we do. Buy used or don't buy at all.  Which is exactly what consumers are doing right now."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6600"
    ],
    "title": "AMD Radeon RX 6600 XT with 2048 cores and 8GB G6 memory officially launches on August 11th - VideoCardz.com",
    "selftext": "",
    "comments": [
      "This MSRP is just a very bad joke.",
      ">This MSRP is just a very bad joke.\n\nThey just pretty much rereleased the 5700XT with poor Ray Tracing support.",
      "380$ lol. Rather spend the 20$ (when comparing msrp) and get the 3060 ti.",
      "40% faster, 39% more expensive.  1% savings passed on to gamers.  Thank you progress. Thank you.",
      "$379, fuck that lmao",
      "Even the 6700xt isnt good at msrp compared to its siblings. It has 20 less CUs compared to the 6800 but clocked way higher to lessen the gap  (which leaves no oc headroom and if you oc the other cards the gap widens), even then is still 30% weaker than 6800 at stock clocks in Doom with RT ([https://www.reddit.com/r/Amd/comments/obo98s/doom\\_eternal\\_4k\\_raytracing\\_benchmark/](https://www.reddit.com/r/Amd/comments/obo98s/doom_eternal_4k_raytracing_benchmark/))\n\nHas less Vram and way worse cooler (by 10 degrees according to Techpowerup ). \n\nFor 100$ more you get 30% uplift (by far the biggest jump for 100$), 4gb more VRam and way better cooler (which many people already pay for to get better AIBs)\n\n6700xt should have been 400$.",
      "1080p card in 2021.. 379$\n\nLOLLL",
      "This person curb stomping the 6700 value proposition.",
      "I expect AMD to adjust MSRP when this shortage is over. rather pay +20 for 3060ti or stick with 3060 for 50 savings + dlss.",
      ">**Nvidia settles price-fixing lawsuit**\nOut-of-court deal cut with plaintiffs  \nTony Smith Tue 30 Sep 2008 // 08:06 UTC  \nNvidia has settled a class action lawsuit that alleges it conspired with AMD to fix graphics chip prices.  \nThe proposed settlement, outlined in the company's latest filing with the US Securities and Exchange Commission (SEC), offers initial plaintiffs $112,500 and a further $1.7m to all the others who subsequently signed up when the lawsuit attained class-action status.\n\nhttps://www.theregister.com/2008/09/30/nvidia_settles_lawsuit/\n\nI hope none of this is currently happening again",
      "Yup. I'd rather wait for 6700xt at a good price. Probably not this year...",
      "On retailers is going to be much higher. MSRP doesn't mean anything since January.",
      "Hey hey now. Our cult leader Lisa needs her margins.",
      "AMD themselves are even positioning it closer to the 3060 than the 3060 Ti yet the MSRP is closer to the 3060 Ti.\n\nIn a world where MSRP was normal for everything, I don‚Äôt really see the advantage of getting this over a 3060 Ti or 3060. \n\nOf course, right now it‚Äôs practically impossible to get a 3060 for MSRP, even if you joined the EVGA queue soon after launch and nearly impossible for the 3060 Ti. I‚Äôm sure this won‚Äôt be much different though especially since this won‚Äôt have a model sold by AMD directly.",
      "Imagine making the 3060 and 3060ti look like good value.",
      "Yeah, with the RDNA II cards, I find it suspicious with the MSRP pricing.\n\n$379 RX 6600 XT\n\n$479 RX 6700 XT\n\n$579 RX 6800\n\n$649 RX 6800 XT\n\n$999 RX 6900 XT\n\nFrom the RX 6600 XT to RX 6800 XT, the $100 difference seems to be bait to lure people, who can afford it, up the stack. In real world pricing, the price difference makes it weirder. For example, ASUS RX 6700 XT ROG STRIX ($929.99) vs. XFX RX 6800 XT MERC319 ($1499.99) looks disgustingly debatable (both in-stock regularly at Newegg). At 61% higher price, the 6800 XT has 55% more silicon, 50% more VRAM, 33% more memory bandwidth, and 80% more CUs as well as solid 4K gaming performance.\n\nEven the RX 6800s are popping up in-stock on Newegg, the MSI Gaming X Trio version is going for $1219.99. At 31% higher price vs. 6700 XT STRIX, the MSI RX 6800 has 55% more silicon, 50% more VRAM, 33% more memory bandwidth, and 50% more CUs plus decent 4K gaming.\n\nThis whole situation looks like AMD wants people to buy RX 6900 XT. It's been rumored that AMD want to sell as much high-end stuff as possible and push aside the entry to mid-range market. AMD's first card to come back in stock were the RX 6900 XTs and followed by RX 6700 XTs (also $1700-$2000 price tag means low sustained demand). RX 6800/6800 XTs are coming back last because AMD's solid yields at TSMC mean that most Navi 21 dies can be 6900 XTs, so why disable CUs for lower margin RX 6800 series GPUs? At the end of the day, value and price-to-performance are no longer AMD's intention or goal. In contrast, NVIDIA's RTX 3060 and 3060Ti cards are this generation's price-to-performance leaders when in-stock.",
      "What a piece of crap, the 3060 have the same price/performance while having a lot of extra goodies like 4GB more vram, better rtx performance & support, DLSS, more memory bandwith to handle 1440p gaming without relying on cripplingly small cache.",
      "The biggest joke outside of the terrible \"MSRP\" is that it's AIBs only. So while before, a lucky few are able to get cards at MSRP from AMD's website, for this one... Not a chance. Least Nvidia still sells a 3060 Ti at MSRP on bestbuy when available which is a better buy even under normal circumstances.",
      "A worse 5700xt for more money, this is literal regression.",
      "Regardless of the current market prices, this MSRP is a joke."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "rx6600"
    ],
    "title": "Rx6600 in 2025",
    "selftext": "Built this all AMD system in December 2024,\nAMD ryzen 5 7600x\nAMD Radeon Rx6600\nMSI Pro B650S wifi\n16GB DDR5 RAM 5200Mhz Cl40 (Since Upgraded to 64GB DDR5 RAM 6000Mhz CL30 with Expo)",
    "comments": [
      "bizarre build ngl, that low end of a gpu with 7600x and 64gb of ram + the back fan and cooler fan are working against each other lol.",
      "Not super wierd, if your still on 1080p this is a boss build ready to be upgraded whenever you jump to a higher resolution.\n\n** oh wait yeah 64gb is wierd. 32gb more than enough for virtually any gaming.",
      "Wasted money on 64gb ram instead of improving other parts of it\n\nAnd yeah that silly back intake fan, what were you thinking",
      "6600 XT here with Ryzen 7 5700 and 32gbs of ram\n\nI play mostly older games. Modern games arent really fun much anymore.",
      "It's set to intake",
      "6600 is still good for medium settings, and is excellent for many older games",
      "Ddr5 32 vs 64 is not cheap lol. Especially when your rocking a typical budget gpu. \n\nGet real braaaa",
      "The rear case fan is facing the wrong way, air comes out of the side with the grills. It‚Äôs a simple fix, just flip the rear fan front-to-back.",
      "Don‚Äôt mind the haters, they just want to feel better than someone else. \n\nDef flip the exhaust fan to push air out instead of back at your heatsink. Just moved off a 6600xt good little card. If you upgrade gpu definitely pay attention to how big the card is.",
      "Sometimes there is an arrow on the side of the fan to indicate the direction of air",
      "Did you buy that card secondhand?",
      "Case is probably too small for any meaningful upgrade on the gpu side. Friend has that very same card, and it‚Äôs a fair bit shorter than my TUF 9070xt",
      "If air is coming out then don‚Äôt worry about it, you have it right. \n\nIt‚Äôs just very common for the side that has the plastic that holds the fan is the exhaust.",
      "you installed your exhaust fan in the wrong direction\n\nthe internal parts of this build will not last long",
      "Money wasted on 64gb, 32 is enough for gaming and spare. Could've put the budget into more roomy case. The back fan should be exhaust, its just fighting with the front intakes currently.",
      "Can you tell me the correct orientation? Because for a while i have had questions on the fan arrangement",
      "Oh shit thank you this is by far the best explanation. Really thank you. \n\nActually the system fans were pre installed but during building, I removed the back fan (idk why I was building for the first time) and maybe I put it on the wrong way, ofc I didn‚Äôt know any better at that time but I will change it soon asap.",
      ">The back of the fan (4 black pillars converging on the round black spot in the middle)",
      "Ok thanks, many were saying things about cpu cooler so thought it had some problems too.\n\nWill do so today thanks",
      "Everyone thank you for your comments, even if they were insulting. I did put the fan in the wrong way at didn‚Äôt even bother to check it. I just felt some air movement and didn‚Äôt think much. \n\nNow after seeing all the comments, yesterday I opened up my case, Inverted the fan and then booted the pc. I checked the airflow by dangling a piece of flimsy paper behind the exhaust fan to see it was blowing out the air instead, and it was blowing it out. \n\nOf course as the system fan came with the cabinet, it is not the best. But now it is better and also looks better because it had rgb haha. I hope I could have posted a photo without imgur.\n\nBut thank you all for the help"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "rx6600"
    ],
    "title": "Always wanted a full red build! Went for the budget value meta R5500/RX6600.",
    "selftext": "",
    "comments": [
      "Adorable pig! Where is it from?",
      "Looks great! Enjoy the gaming!",
      "Is that an ITX board???",
      "I have an R7 with 6600 XT and im still pretty happy with it. However be warned of brand new games with Raytracing. Our cards dont handle it well.",
      "i was gonna say that the pc isnt red i think im stupid",
      "NOOOO, WDYM YOU DIDNT SPEND $5000 ON A RYZEN 9 9800X3D AND A 5090 ARE YOU DUMB‚ÅâÔ∏è‚ÅâÔ∏è‚ÅâÔ∏è /s\n\nNice build! I fw the fps/$ for sure",
      "Tons of performance, reasonable amounts of $. This is a nice daily driver!",
      "Asrock B550m-HDV. Cheapest B550 I was able to find, not the greatest VRMs but enough for 65w.",
      "No. No, you are not, I was about to point out that it is white, but then I noticed it was on AMD‚Äôs thread",
      "Corporate only approved a $700 budget!\n\nAnd by Corporate I mean the wife.",
      "I'm coming from an i5-3470 with an RX550, imagine my joy!",
      "Have fun!",
      "You messed up bro. That PC is black, white and pinkish. The ethernet cable is a good start.",
      "It looks a lot like some of Poogie's costumes. (Poogie is a pig character in Monster Hunter. You can dress it up with little costumes, several of which are much like the one on this pig, just in different patterns. You can also pet it, and if you do it right, it'll sometimes give you materials.)",
      "Thanks! I'm trying, but this thing people call job won't let me!\n\nExcel runs really fast tho xD",
      "Love that !! Haha, great value build man, for $700 that's a 1080p beast. My 5500 served me well for sure",
      "The pig ... ‚ù§‚ù§‚ù§‚ù§",
      "i like that pig so much ü§ßüò≠üò≠",
      "That‚Äôs not red at a-whoops",
      "its great for 1080. was my build until last year and im still banging the asrock b350 pro4 (currently on 5700x)"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6600"
    ],
    "title": "RX 6600 render (my concept) created in blender, what do you think?",
    "selftext": "",
    "comments": [
      "WccfTech: RX 6600 OFFICIAL RENDER LEAKED",
      "Looks great, I love it! I think the font weight on your Radeon and R is a bit too high.",
      "You forgot gamer meld and his ‚ÄúaMd CoNfIrMs rx6600‚Äù. I might have seen the thumbnail with ‚Äúbig NAVI with .... confirmed‚Äù at least a 100 times since last year. Don‚Äôt know why YouTube keeps recommending these trash channels.",
      "I know everyone is hyped for big navi but what about small navi?",
      "I just want medium Navi. Something around 5700XT raster perf (or a little better) with ray tracing. I just want good (up to 100FPS) 1440p performance and experiment a little with ray tracing.",
      "[Clearing your watch history](https://www.youtube.com/feed/history) should help with that.",
      "I like it",
      "I read somewhere that the dual fan config for Radeon 6000 has been abandoned and they're all going to be triple fan. It's probably bullshit, but just an FYI.",
      "The chamfered edges on the sides of the gpu look amazing.",
      "We will see",
      "it's actually emissive, but only a little bit, and there is no bloom so it's not as visible",
      "You‚Äôre an asshole. You should delete your account.",
      "The problem is these YouTubers like gamer meld have no integrity and low standards. They don‚Äôt even bother checking the validity of the rumour and even a random Reddit post could be their ‚Äúsource‚Äù. Also those click bait thumbnails. Can‚Äôt count  the number of times I‚Äôve seen sensational titles like ‚Äúbig NAVI destroys nvidia‚Äù or ‚Äúampere/NAVI confirmed‚Äù",
      "gigabyte rx580 gaming 8g, but i had few issues with OpenCL rendering and it took a while....",
      "I like the leak channels occasionally, and they have been pretty accurate lately, but I‚Äôm honestly sick of them jerking off ‚Äúbig Navi‚Äù. Sure, the leaks about Zen 3 were right, but it was a slightly better improvement than Zen 2 was, so believable. I do not believe that Radeon will have some ‚Äú3080 killer‚Äù. People had doubts they would have a 2080ti killer. I really hope I‚Äôm wrong, but the hype for no reason by these channels is annoying.",
      "The surface of the fan hubs look amazing, pretty much the only thing I'd change about the render would be to make the radeon logo emissive just to give it a little glow on the surrounding areas",
      "> and they have been pretty inaccurate lately\n\n\"Lately\" isn't the correct word to use here.",
      "No wonder why you gave yourself a dog's name...",
      "Damn, somebody has some sand their vagina...",
      "What card did you use for the render?"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6600"
    ],
    "title": "AMD Radeon RX 6600 XT allegedly launches in August - VideoCardz.com",
    "selftext": "",
    "comments": [
      "What the article doesn't mention is that \"$399 MSRP\" is pure speculation on Coretek's part. He specifically says there's \"no word on pricing yet\".",
      ">To be fair, you can't find those GPUs at MSRP as well, and there's no guarantee you will ever find them at MSRP ever again.\n\nBased on 6700 XT's pricing, there's no chance this costs less than 349$, sorry.\n\nPC gaming is not value oriented anymore.",
      "$399 is a bullshit price for a low-tier GPU.\n\nthat is about 33% more expensive then the RX 480 which was a mid-tier GPU!",
      "Funny thing is AMD don't have the features unlike nVidia to charge more than them, if you've got the option of buying at RRP 80% of users will still go with nVidia, even when AMD beat nVidia on price with the R9 290 vs GTX 970 many people went with the 3.5GB GTX 970 that was slower while costing more.\n\nAMD has to be careful with pricing, the good will they've gotten from consumers can easily be lost, bought my 3700x to support AMD even though I could've gotten a 10900k but wanted to change, hope Intel come good again for some real competition once again to keep AMD honest.",
      "$400 would be awful. That card is not worth this much. I won't pay more than $300 for it. And if you do pay more than $300 for it, then you are partially responsible for the market being bad.",
      "$399 would be a horrible price. It's sad to see AMD take advantage of the current market like this",
      "Thanks for adding this, I don't watch Coreteks so wouldn't have known. $399 would be garbage pricing for a card like this (I mean, when else have you been able to pay like 50% more to get nearly double the cores, double the VRAM, etc, like this looks vs. the 6800 MSRP..?).",
      "Ya mean \n\n>\"Rdna2 tops out at 2080ti performance and i'm tripling down on it\" \n\n>\"Rdna3 is gonna have only 40% performance increase over 6900xt\"\n\n> -Coretek\n\nand \n\n>\"Nvidia jebaited amd to think they need only 2080ti performance. My aib insiders confirmed it\"\n\n> -Videocardz\n\nThose dudes?",
      "My rx 570 wanna die amd \n\nMy current hope is a 3060 6gb or 3050ti ‚Ä¶.",
      "And what's even worse, I guarantee you that in September, you will see at least one post like \"RX 6600 XT is amazing!\".",
      "400 dollars is a joke. AMD is scamming people at this point",
      "5600XT succesor for 5700XT pricing that should have been cost 249\\~299?\n\nThats when AMD GPU market share goes from barely existing to not existing for all budget majority AMD fans. \n\n\"84% buys only 300USD gpu\" - AMD words\n\nBye AMD and Radeon group.",
      "unfortunately me too, i refuse to getting shafted by gpu companies. Used market is a alternative aswell, a lot riskier but plenty of deals going to appear on the market soon. I hope so atleast.",
      "From what I found, the MSRP for the RX 480 8 GiB was $‚ÄØ239, so that‚Äôs almost 67‚ÄØ% more expensive, not 33",
      "There wont be any 3060 6gb",
      "\"Corporations have more power than the government. The old rules no longer apply\".\n\nI'm pretty sure they're pulling a 5700 XT here (how ironic, considering the performance), \"taking our feedback into consideration\" to only release this RX 570 4GB replacement at 349$ instead of 399$ - which is still ridiculous but people will swallow it much more easily.",
      "RX 5500 XT offers no better value whatsoever for 480/570/580 owners. Same performance/price as in 2016/2017.",
      "5700xt was the successor to rx 480 and it costs 2x",
      "This is the worst time to buy a graphics card ever. The future doesn't exactly look bright, but it looks a helluva lot brighter than the present.",
      "So a $400 MSRP for a card roughly on par with a $330 card. Cool.\n\nPlease, sir, may I have another?"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6600xt"
    ],
    "title": "R5 5600X - RX 6600XT",
    "selftext": "",
    "comments": [
      "That's a sweet build!\n\nI'm curious, what are those characters on the bottom part of the cap?",
      "It's Thai alphabet, still can't do touch type on this.",
      "No, 500W is more than enough for this build. The CPU max out at 75W and GPU is 148W.\n\nCurrently I've only one M.2 drive on the M/B but I can fit 2 SSDs into the case.",
      "The GPU and CPU pull 220w together. I think he'll be fine even if he manages to shove 10 drives into it.",
      "How noisy is the Flex ATX PSU? I've been considering a SFF build that uses one of those, but from what I've heard they're either mostly fine but noticeable or extremely whiny.",
      "wtf are you talking about? 500W can supply even R7 5800X + RX 6700XT no problem with still optimal 80% load, as long as it's good quality PSU. Not to mention PSUs peak their power efficiency above 50% load :) In this case expected load is around 250W - so tell me, how on earth this is underpowered PSU? Are you one of those people using 850W in mid-range level builds?",
      "The one I'm using is Dark Forest, it's not too noisy comparing with other FLEX PSU I've used. I think the fan run at 6500-8500 RPM. The Thermalright AXP-90 CPU cooler is louder.\n\nIf you're looking for the most quiet Flex PSU, it would be Silverstone FX600, that one the fan spin at only 1800 RPM.",
      "I also have Pluse 6600XT, it's exactly the same cooler as Nitro + but it runs 6C  cooler due to  more aggressive stock fan curve.",
      "Pluse and Nitro+ have identical score in benchmark, but Pluse is 45 USD cheaper.",
      "that's because your system would eat ~70W more, and any OC on GPU or Even PBO can push to 100W more. RX 6700 XT is 230W TDP, yours is 295W TDP - that is quite a bit of difference.",
      "You can view the build BLOG here https://en.minicomputers.net/post/gecko-xs-flex-psu-pc-case",
      "Damn is that flex unit crammed with barely any space for cables on the bottom.... Would be better if they used an sfx unit",
      "needs some more 7nm power like a 6950 xt",
      "Your welcome",
      "Yes, DDR 4",
      "It's 92mm slim fan. The P12 won't fit. But I have Noctua A9x14 Chromax, I'll swap that later.",
      "I manually set the fan curve for CPU so it's not noisy with slight load. But the Flex fan is audible.",
      "I use it with 2k monitor, +200 on CS GO and max out 165 Hz screen refresh rate on most lower end FPS game.",
      "Is that you, Mini Me?",
      "I want to do a similar build so bad"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6400"
    ],
    "title": "G.SKILL introduces DDR5-6400 CL30 2x48GB low-latency memory for Intel Z890 and AMD X870 platforms",
    "selftext": "",
    "comments": [
      ">CL30-39-39-102\n\nThe values after CL (TRCD, TRP and TRAS) are quite high. So slower than current kits on the market right? \n\nI know Cas Latency on DDR5 aren't significant in gaming performance (small FPS difference), but the other timings have more impact.",
      "You mean 96GB.",
      "Where can we buy it?",
      "That‚Äôs what I NEED to know. They keep posting about it. Is it for sale or no?",
      "Dual rank is way harder stabilize than single rank. The same can be seen in dual rank 64gb kits, also hitting 8000mhz is essentially impossible on dual rank kits currently.",
      "That‚Äôs the neat part, you don‚Äôt. Just like cl26 6000mhz. At least not yet.",
      "the M and A die are getting good lol. \n\nJust a few more years and we should hopefully see some 7000+ for AMD on the new memory controller.",
      "From what I understand 8000 MHz is possible with CUDIMM DDR5 kits for latest Intel motherboards.",
      "With respect to Hynix A-Die specifically, some XMP kits run at 1.5V out of the box, 1.55V doesn't seem super high to me. From what I've gathered the consensus in overclocking communities it you should avoid exceeding 1.65V for daily usage, but YMMV. You'll want a fan blowing on your RAM if running at 1.65V to prevent errors caused by high temps.",
      "here is values of previous 24x2 48gb kit DDR5-6400 CL32-39-39-102 1.35V . They give safe values for timings. Important one is how far can you push on overclock. my 24x2 kit is set to CL28-38-36-72 at 1.55V. Real question is this kit capable cl28 at lower voltage or cl26 at 1.55V",
      "It just says Q1 so they probably haven't launched them yet",
      "How long have you been running the kit at 1.55V? Do we know the safe maximum voltage for Hynix M/A die? 1.55V seems really high.",
      "I would love this kit, where is it lol",
      "Waiting for buildzoid to review these and talk about them for 3 hours straight.",
      "Lol.. he has a video up actually üëç he took cl26 kit and ran it at 8000, cl30 I think it was.. he hadn't done stability test yet, but maybe now he's got an updated video.. I think I'll check, hahaüòÖ",
      "I expect zen 6 to be able to do 8000 at 1:1",
      "C28",
      "96 but 4 held back for iGPU?",
      "There are 8000mt/s sticks that are on the QVL list for my AMD motherboard",
      "You don't need cu dimms for 8000. You just need good binned a die ( to make your life that much easier ) such a the xtreems 8000 or 8200, and great board with amazing training and a non dogshit imc."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6600"
    ],
    "title": "Can someone help identify this GeForce 6600?",
    "selftext": "There isn't any sticker who manufactured it, I can't read VBIOS because I don't have compatible ROM reader and GPU doesn't power up.",
    "comments": [
      "Ah, a most intriguing conundrum you have presented to us! After an exhaustive and most diligent examination of the evidence at hand‚Äînay, after peering into the very depths of technological history itself‚ÄîI am left with but one inescapable conclusion. Brace yourself, dear OP, for the revelation I am about to bestow upon you may shake the very foundations of your understanding: it is, with all certainty and beyond the shadow of a doubt, a GeForce 6600. I do hope this revelation serves you well in your noble quest for knowledge.",
      "Looks like a geforce 6600 to me",
      "I would show you a zoomed in photo of your capacitors popped but it doesn‚Äôt allow it",
      "This is a Redditor",
      "Yeah, you're right. It's Forsa but non-GT and 256MB variant",
      "Happy to help",
      "Fired capacitors, it's a waste of effort.",
      "Its a Forsa 6600GT 128MB DDR",
      "This exact heatsink screams Forsa. They made GPUs since about 2001 and up until Nvidia Pascal architecture, then they stopped. You'll see a number of these Geforce 6600 cards, some in GT variant, from versions A and B like yours, up to version I.",
      "rozpierdolona",
      "lol those caps look like shit",
      "I believe it's GeForce 6600",
      "Aside from the blown caps, a gpu not posting is mostly related to a missing voltage",
      "Caps are messed up. Writing in tape shows something like ‚Äúdamaged‚Äù. Cooler is in style of asus cards but without decorative cover. Repair is for 3-5 hours of life messed. Value - 0.15$. Nice Thinkpad tho",
      "This guy definitely GPUs",
      "Tldr: GeForce 6600 confirmed!",
      "No way. I didn't know this",
      "It s the X on them?",
      "I'd imagine OP knows, the sticker on the back says it's damaged.",
      "Talk about ancient"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6400"
    ],
    "title": "[HUB] Tiny RDNA2, The Best LP Single Slot GPU: AMD Radeon RX 6400 Review",
    "selftext": "",
    "comments": [
      "its only competition in single slot, low profile, no external power gpu space is the gt 1030. it better fucking win lmao (iirc there is no single slot low profile gtx 1050/ti/1650, there are single slot but tall, and low profile but 2 slots, not both together)\n\nedit: forgot about the quadro Ts and WXpro line oops but theyre also more expensive for similar performance.",
      "Nvidia is overcharging for the 1600 series so AMD has free reign to make a huge margin on its products. The cheapest 1650 at Microcenter is $210 and goes up to almost $300. The cheapest 6500XT at Microcenter is $200 \n\nAMD is getting so much bad press with the PCIe nerf that Nvidia basically ignored it. I believe we needed AMD to lower the price enough to justify the card on its own and only then would the space become competitive again.",
      "Problem is - the use case involves proprietary office PCs that are basically all PCIE 3.0 by which this card gets massively gimped in already quite disappointing performance under PCIE 4.0. Also the price is absurd for what it is - you buy cheap office PC on some sale - and have to then pay very NOT budget figure for superiorly basic GPU. It would make whole another sense, for example, at $100 msrp.\n\nIn other words - market is nuts, and especially in ultra budget segment - it's completely unreasonable.",
      "The only sensible use case I can think of is someone want to build a low profile entry gaming machine, you basically cram a i3 12100F with 6400 and you will get playable performance, as for whether such niche actually exist or not.... well lets see what the actual street price of the monstrosity would be.",
      "Another use case scenario: having a secondary lower power single slot GPU to drive Linux while you pass the much more powerful GPU to windows vm to game with. Currently doing this with a Gt1030 and a Rtx 3080",
      "Complete garbage. Performance in pcie 3.0 comparable to the 1050ti that uses around the same power and it's like 5 years old",
      "The issue is that if you put 6400 into pcie 3.0 system it will get cancer, and I imagine most 560 equipped system is pcie 3.0 base.",
      "Paper specs mean jack shit, power consumption in game is measured in the video and the results are near identical between the 1050Ti, 1650, and 6400.",
      "Until PCIe 4.0 is standard and this whole issues becomes moot, it will never go away. The old ‚Äúoffice PCs‚Äù might die, but ‚Äúnew‚Äù (off-lease or retired 3-4 yr old) ones are constantly showing up for purchase by home users.\n\nFor example, Dell is still shipping the Optiplex 7090 SFF. The available 8c/16t i7-10700 will be relevant for years and the system only supports PCIe 3.0.",
      "6400 (and its similarly cursed sibling 6500XT) both have pcie 4.0 x4 connection, thus only accessible to pcie 3.0 x 4 speed in pcie 3.0 base system, moreover, 3080 have 10GB as buffer, 6400 only have 4GB, the less buffer you have, the more pronounced will the loss of pcie bandwidth be felt.",
      "There is an RX 560 4 GB GDDR5 single slot/low profile from Yeston. Not sure how that would compare to this 6400, but I guess the 6400 might beat the 560 in a Pcie 4.0 system and the 560 would win in a Pcie 3.0 system.\n\nEdit: Based on comment replies before, it looks like the 6400 is definitely better in almost all gaming use cases.",
      "That is a good point. The RX 6400 does have the advantage of having proper open source drivers. Before that your \"best\" option for that use case was to get an RX 550/560.",
      "It baffles me that even on recovering market, AMD still has enough greed for them to release a overpriced product like this.\n\nHeck even on the worst market this product still makes absolute no sense, as a used GTX 1050 Ti just costs around $80 - $100 anyway compared to this which will cost $160 - $200 at least basing from my own country's market pricing back on mid 2021 where i managed to get a 1050 Ti for under $100 as a backup temporary GPU.",
      "If +18% and 53W are the same perf and power as the 75W 1050Ti, then yeah.  If not, then no.",
      "Msrp should have been 80$",
      "Honestly I'm very curious how long these old office PCs will be relevant. With CPU performance finally leveling up and getting a good 15-20% uploft per generation the old CPUs are seriously starting to hold you back. Especially as these system are also getting quite long in the tooth, so they'll start dying left and right sooner or later.",
      "There is asl g1504, a gtx 1050ti single slot low profile card.\n\nAnd there's yeston rx550.",
      "> Nvidia is overcharging for the 1600 series\n\nHow do you know that it's the fault of Nvidia? It could easily be the fault of the retailer.",
      "There's also the ASL GTX 1650 War Knife: https://videocardz.net/asl-geforce-gtx-1650-4gb-war-knife",
      "Apparently they do. The video shows decent drop in performance when changing from 4.0 to 3.0. I wouldn't think they'd saturate it either, but I guess they do, situationally."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6500xt"
    ],
    "title": "Price of 6500xt is close to 450‚Ç¨ in Greece!",
    "selftext": "",
    "comments": [
      "I hoped I could get it as a temporary solution cause my GPU is dead but 450‚Ç¨ is clearly ridiculous.\n\nHope by summer we get better prices as Ethereum gets to POS",
      "When/IF Ethereum goes proof of stake, miners will just move to the next crypto. People seem to forget that Bitcoin was originally mined on GPUs, then asics came and ended that, miners moved to Ethereum and other cryptos.",
      "I swear you could put a pci-e slot on a pile of real dogshit and sell it for 400 Euros / $300/usd plus.",
      "Don't underestimate the stupidity and greed of crypto dickheads",
      "I swear to god an Xbox Series S is just 250 atm. For 450 I could get that and Gamepass for 20 months",
      "Actually (and I know I probably being a bit pedantic here), but bitcoin was originally mined on CPUs (it‚Äôs been around for a long time). It was developed on 2009. At the end of 2010, GPUs took over, then of course FPGAs and ASICs.",
      "Yeah but it would take years to catch up with Ethereum in terms of profitability",
      "Didn't think it was possible to beat a worse priced card than a 3080Ti, but here we are!  \nSituation is completely fucked!",
      "Bro u just proved urself wrong",
      "Looking to trade my 5600 XT with a 2 bedroom apartment and a cat, PM me with your offers",
      "The balkans have fucked prices but im sure OP can get a series S and some months of game pass for that money.",
      "RX 580 8GB goes for 450+ EUR",
      "Kalitera pare Xbox or PS5. Don‚Äôt it. Crappy card. Super malakia me 4GB kai xoris hardware acceleration.",
      "You're missing the point you doughnut",
      "Good luck building a pc that can play games like a Xbox series S can for 450 lmfao xDD",
      "At one point in around 2010 I went to college with someone who was mining bitcoin on their macbooks cpu, they had something like 20-30 bitcoin at one point and sold it all when the value got to about ¬£30 a coin...",
      "The Xbox series S in Greece costs 275‚Ç¨. I know that cuz i consider buying one right now",
      "900¬£ in college is not bad to have though.",
      "PoW crypto dickheads*",
      "Of course. If AMD wanted to sell these for $/‚Ç¨200 they would order millions of 6500XT ref cards and set a maximum retail price\n\nIt‚Äôs obvious AMD (like Nvidia) doesnt give a shit"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6600xt"
    ],
    "title": "Just switched 6600xt for 6900xt",
    "selftext": "I don't know what's more wild, performance boost, size of this beast or fact that 6900xt still can get kick 4070s/ ti ass in raw  performance lol. ",
    "comments": [
      "Why does your 6600 XT have a knob on top right ?",
      "I thought that's obvious. Fan control!",
      "Sounds kinda bullshit. 6800xt should be happy with 750w .",
      "Are you sure that you made a good deal? \nLooks like a keyboard to me",
      "I did this same upgrade. Pretty good performance boost",
      "If you got it used I think it was a good deal, new I don‚Äôt think so, but definitely the 6000 series ado be aging great on the used market",
      "What keyboard is that?",
      "I've bought a 6800xt red devil second hand, but it won't display :(   \nI can hear windows startup sounds through my headphones, but I have no image.   \nSeller told me he had the same problem and fixed it by buying a 850W PSU, I've got a cheap 750",
      "Sick!",
      "The best part is that it is compatible with macOS!",
      "I know the 6900XT should be more efficient and lower power, so I hope you have a better experience. \n\nMy Asrock Phantom Gaming 6950XT has been the worst card I've purchased in a long time. The fan closest to the PCI-E bracket wobbled, then stopped working, and I had to strap a 120 mm case fan to it. Now the middle fan wobbles and will stop turning sometimes. Can only lower the power usage 6% making it hard to keep temperatures reasonable and I've already re-pasted it.",
      "Yup. Pre owned with changed thermal paste + pads.",
      "Cooler master ck 720",
      "I mean, not having a powerful enough PSU could make this problems show up, also not every 750W PSU is the same, mine is a cheap one, so I'm not very confident on it, also Powercolor suggests a 850W PSU. If it still doesn't work I can still sell it as broken and still get some money back",
      "It's mechanical"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6600"
    ],
    "title": "Should I buy a PS5 or a RX 6600 XT",
    "selftext": "Trying to figure out on which I should save for, and im having a second thought on which I should buy first\n\nI'm saving for the RX 6600 XT so my pc will run much smoother on high end games (since I already got high end games on my steam library but my CPU can't run them alone)\n\nbut for PS5 I wanna try a Console (and just wanna play DBZ sparking zero) since I never had a console before, aside from the switch but I don't really use it\n\n  \nWhich is more worth the price?",
    "comments": [
      "Counterpoint, my AMD cards have always been fine.",
      "Counterpoint, my AMD cards have always been fine.",
      "AMD GPUs are currently the best overall in terms of fps/$ and are comparable to similarly priced Nvidia GPUs if not better in some cases. The 6600xt is not the best but if he have the budget for the PS5 I recommend at least the 7600xt/6650xt or 6700/6700xt",
      "Probably bad luck man\n\nI've had issues with both amd and nvidia",
      "Maybe it's a you problem?",
      "Actually I've bought a few, some used, some new, gave a rx 580 to my friend, best thing he's ever had, had problems at first when windows amd everything would just get corrupted for no reason, changed his motherboard with one of mine, and he's been golden ever since.\n\nLike i said, more often than not, it's a compatibility issue or bad hardware, luck can be funny sometimes.",
      "For me l choose PC as l got a great deal last year for 3060ti new for a price even lower than 6600xt now. \n\nI was considering between PC and PS5 and cheap parts l got for great deals sway me to PC again. Also PS5 are more expensive than normal in my region. My old pc can't really game anymore and l have been gaming on series S bought during the GPU,series X and PS5 shortage scalpers period.\n\nAs you still can play most former PS5 exclusives and those that are not one yet will be eventually. Unless you really have to play exclusives on day one then get PS5.",
      "Wrong, either it's a user error, compatibility problem somewhere or you got a bad card. Never had a problem with my 6600xt, going for 7900xt soon",
      "I got the 6600xt when i sold my Xbox series X, no regrets whatsoever, better bang for your money, outperforms the Series X and PS5 it's not even close",
      "I would recommend if you really wanna play some games that come out first on console (like GTA6 next year for example) but for multiplatforms I would stick to the PC. It really depends on what  you wanna play at the end.",
      "I'd definitely gor for a pc but that's me, 6600xt is similar to ps5 performance with lower vram, maybe go for a used 6700xt",
      "almost all or all games, that release on the ps5 are also going to release on pc after a year or so.\n\nso i would rather recommend to just NOT get a ps5 at all and instead get a better graphics card instead than an rx 6600 xt.\n\nwhat makes the ps5 special and worth getting? it isn't the games, as it is just a waiting, until you get them on pc anyways.\n\nif you want to play online with a ps5 you also have a subscription you gotta pay for it. sth, that the pc community wouldn't accept, because we got choices here, so that won't work.\n\nthe rx 6600 xt also has a major issue by not having enough vram.\n\nthe rx 6600 xt has less vram than the ps5.\n\nthat is if we normalize for the unified memory, that is available to a game for the ps5. the ps5 has 16 GB of unified memory of which 12.5 GB can be used for the game alone.\n\n12.5 GB unified in a ps5 translated to a 12 GB vram requirement roughly. we know this by people benchmarking hardware including hardware with different vram, but otherwise the same or almost the same gpu power.\n\nso i would recommend to you, if it fits in the budget to get a new 350 us dollars (on newegg available for example) rx 6800 with 16 GB vram, or wait till q1 2025 to get an rdna4 16 GB vram graphics card, that will match the ps5 pro the closest in features.\n\nthere is also the rx 6700 xt/6750xt, that has at least 12 GB vram.\n\nand again from my understanding, the ps5 controller works just fine on pc and the games from sony and playstation come to pc eventually. so just take some of the money for the ps5, which isn't cheap with blu ray drive + stand + subscription to play online, and get a better graphics card and you get the bettter experience overall for cheaper overall (compared to buying both) and have a great time and just buy dbz sparking zero on pc.",
      "Do you want to play GTA VI same year or do you want to have a kick ass computer? Your choice.",
      "You can play DBZ on PC ? But for the price of a PS5 even a used one you could get a 7800xt or a 7900 GRE especially if you're willing to buy them second hand",
      "DBZ sparking zeroq",
      "All I wanna do is play DBZ sparking zero all day",
      "My PC is Ryzen though",
      "Skill issue",
      "Just switched from NVIDIA to team red and holy my 7800xt runs amazing. Great temps, no crashes, runs everything as expected ie it absolutely crushes games at 1440p (competitive games like warzone I get easily around 200fps; Star Wars Jedi Survivor I get ~100+fps w optimized high settings, often more depending on the location).",
      "Isn't that game on PC too?"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6600"
    ],
    "title": "Unpopular Opinion: At the moment, the 6600 XT is one of the best value cards on the market.",
    "selftext": "Let me get this started by saying I dont like the MSRP either. You're basically getting a 5700 XT for 5700 XT prices. This is not generation to generation progress.\n\nBut... In the current market we're in, MSRP is almost meaningless. All the negative reviews and comments from everyone on launch for the 6600 XT seemed to have forgotten that the 3060 and 3060 Ti are virtually impossible to get for MSRP. The 3060 founders doesnt exist and I have yet to see **anyone** get one for its MSRP price. I have seen the occasional 3060 Ti for below 500, but they're extremely rare.\n\nAt the end of the day, it wouldnt have mattered if AMD set the MSRP at $379 or $250, the price is dictated by the supply and demand. What we have here is a realistic MSRP which matches the current market.\n\nBy the looks of it (at least here in the UK, the sapphire pulse has been sitting at ¬£375 **in stock** all day at overclockers) the 6600 XT has immense supply. Many retailers have received more 6600 XT's than **all** Nvidia cards put together over the last week.\n\nEveryone was saying the 6600 XT is the end of the budget card. But I would argue otherwise. The 6600 XT has been by far the easiest card to buy at near its \"MSRP\". To the point where it will start pushing down RTX 3060 prices. Even if the 6600 XT only matched the 3060's performance, the fact that almost everywhere it can be found for $100-200 less is definitely taking away some of demand from the 3060.\n\nRight now, we simply need prices to drop. Not crazy low MSRP's that wont be achieved. And the 6600 XT is the card doing that.\n\nSure, lets say 6 months from now the 3060 and 3060 Ti can easily be had for MSRP, yes the 6600 XT is bad value. But who honestly thinks it wont drop in price? Remember what happened with Vega? A $400 Vega 56 and $500 Vega 64 were going for as low as $250 and $300 respectively, just over a year after release. I would not be surprised if we see this happen. Heck, I managed to pick up a Vega 64 Nitro+ brand new from scan for ¬£250 in 2019.\n\nThe reason as to why the 5700 XT never dropped in price was because it was so competitive to start with. It punched in the same performance tier as the 2070 Super, a card which cost more than $100 more. The 5700 XT had no reason to be cheaper.\n\nTLDR: The 6600 XT is *currently* our saviour. Not the enemy.",
    "comments": [
      "I do agree in the context of 'need something badly right now'.\n\nThe 1660TI , 1650, 2060, 5600xt, 5700xt, 3060 etc. are all crazily high priced right now. The 3060 Ti is near double in many cases here in the UK. \n\nNot sure how prices will look after a month though?",
      "In a market where used Polaris are north of $300, a $379 card with 3x the performance is a no brainer. It's disappointing that things are like that, but it's a harsh reality.",
      "Considering it's almost half the price of the 3060 Ti here yes, even though it's still above MSRP.",
      ">MSRP? The fuck is that?\n\nMostly Satirical Recommended Price",
      "For who? Few countries? Rest of the world dont have any chance for founders at msrp.",
      "Agreed about the 6600XT. If you can get it at MSRP it‚Äôs not bad at all. All the 3060‚Äôs I‚Äôve seen are $500 or more. People just wanted a $250 card I guess",
      "In Aus, the market is absolutely, completely fucked.   \n\n\nRight now, I can get a Sapphire Pulse for around AU$599. This compares to a 3060, which is DOUBLE the price. It's a no brainer.\n\nI'm just hoping that there's still some in stock by the time I get paid.",
      "Thank you for the constructive take. Comparing by MSRP is simply missing the point, it's the actual prices that one is paying that matters.\n\nIt's a similar concept to buying a property, which has a government assessed value that is often different from the real market value. You won't see people basing their purchases on the government assessed value either, as that isn't the amount they will be paying.",
      "At the moment, it is at MSRP. In UK and AUS at least. At the moment, ofc.",
      "Not for those of us that can't afford to toss money around endlessly it isn't. That's exactly why I care about making sure my purchase lasts.\n\nLike who in their right mind would spend several hundred dollars on building a new computer just to make a gimped and overpriced GPU a little less gimped?",
      "What a bullshit statement. Boards running only PCI-E 3 are still able to push CPUs that‚Äôll last well into the decade. You can‚Äôt tell me a 10900K or whatever isn‚Äôt going to fly through everything for years and years.",
      "Woah there, thank you for bringing me to my senses. Just checked and in my country, the 6600XT is basically the only card I can find at 10% off its MSRP.\nPrices are so jacked that I had scratched my \"build a PC in 2021\" plan and was already planning to buy a laptop. This card makes building a PC feasible now.",
      "I know it's hard to get into the minds of people who don't live in the world of trust funds and the bank of mummy and daddy, but some people don't build new systems every time they buy a new GPU. I'm just replacing an old, dead graphics card and looking to get something I'd want to use, and that won't fall badly behind because of a stupid limitation.\n\nAnd using that logic even high end GPUs are gimped because they could always carry more memory, have bigger dies ETC but that isn't the point here. I don't expect them to perform the same as top end cards but design decisions that reduce performance to save a couple of bucks on substrate to me are not a necessary compromise, that's just AMD being cheap.",
      ">By the looks of it (at least here in the UK, the sapphire pulse has been sitting at ¬£375 in stock all day at overclockers) the 6600 XT has immense supply.\n\nAlternatively, they don't have immense supply and there isn't much demand. We have seen that people are more willing to pay up for green cards than red cards, and people are more willing to pay up for top end cards than low end cards.\n\n>Right now, we simply need prices to drop. Not crazy low MSRP's that wont be achieved. And the 6600 XT is the card doing that.\n\nYup. Any card AMD is willing to produce in volume is great news for the market.\n\n>Sure, lets say 6 months from now the 3060 and 3060 Ti can easily be had for MSRP, yes the 6600 XT is bad value. But who honestly thinks it wont drop in price? Remember what happened with Vega? A $400 Vega 56 and $500 Vega 64 were going for as low as $250 and $300 respectively, just over a year after release. I would not be surprised if we see this happen.\n\nIt strikes me that the 6600xt is bad value at MSRP. Of course, if its street price stays close to MSRP, it's far from the worst value on the market. It remains that very few gamers should be buying at market prices, particularly since this card is basically a half-gen card in terms of release cadence.",
      "If you want to argue that it's the least crappily priced card, maybe. But as someone who will be impacted by the decision to cheap out on PCI-E lanes I'll wait for a 3060 I can afford.",
      "Looking at the issue with Doom Eternal tells me the future. It loses 25% performance in 3.0 x8 mode which puts it behind a 3060. With the new consoles carrying 16GB of memory games are only going to get more memory intensive, so I don't expect this card to hold up well, as someone who doesn't upgrade regularly that would be a problem for me.",
      ">At the end of the day, it wouldnt have mattered if AMD set the MSRP at $379 or $250, the price is dictated by the supply and demand. What we have here is a realistic MSRP which matches the current market.\n\nTell me you know how capitalism works without telling me that you know how capitalism works. \n \nPricing is not mathematical, it's social, prices are determined by *perceived* value.  Is the 6600XT a good value? Maybe not. Is it a good value *in the current GPU market?*  Unfortunately, yeah, it is. \n \n>\"You should buy a 3060 or a 3060Ti instead.\" \n \nThat just *isn't* a viable option right now, it probably won't be a viable option for months to come.",
      "Like an AMD card is going to be priced more reasonably than an Nvidia card in thsse climates. Especially not when it's supposedly a great mining card.",
      "Yup it's currently $200-$300 dollars cheaper than a RTX 3060, so I bought a 6600xt this morning for $700 inc gst.",
      "Well, considering the 6600 XT has been in stock all day **and** is incredibly efficient at mining, wouldnt that suggest that it does have high supply?\n\nAlso, many retailers have come out and said that supply is very strong."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6400"
    ],
    "title": "AGESA 1.0.0.7b Gaming benchmarks: DDR5-8000 CL 38 1:2 vs 6400 CL 26 1:1",
    "selftext": "&#x200B;\n\n[Testing was done with  7800X3D PBO, -30 CO on all cores  watercooled 4090 with galax bios, 666W power limit, +100 core, +1000 mem  fixed fan speeds](https://preview.redd.it/scw50vhglcdb1.jpg?width=1454&format=pjpg&auto=webp&s=126d63f5aa5a68f58b7000a49d8f73c5670f50f9)",
    "comments": [
      "looks like margin of error... but tbh this is probably because of the extra cache. Would be interesting to see the same test done with a 7700x instead.",
      "I mean I guess I'm glad there's no change so I dont feel compelled to blow money on faster ddr5.",
      "I‚Äôm really curious if running 2:1:1 MCLK:FCLK:UCLK makes any positive difference here. If Zen 5 supports these kinds of speeds in Gear 1, it‚Äôd be incredible.",
      "Thanks for the kind words. A lot of dedicated engineers worked to pull this off.\nTo me, this is good to show that if you're running DDR6000-7200, you've got lots of headroom and margin for good stability.  For now, I'll be running 7200CL32 with FCLK 1800 (1:1:2) - boot times are excellent and gaming has been flawless.  Take care!",
      "Not exactly true. Latency will remain the same between those two settings, but a higher speed means higher bandwidth, so 8000C40 is preferable to 6000C30.",
      "It will be similar: https://img2.quasarzone.com/editor/2023/07/21/60c0d651bdad4574ff5cbe98139b2005.png",
      "This.",
      "The memory controller is reasonably fast, but you run into the limitations of FCLK which starts to impact the latency.  I have a Cezanne system in my rack running DDR 4400 24/7 (FCLK 2200 is easy since there is no GMI), and running 4600-5200 on air/water is perfectly reasonable with a bit of luck).\n\nFor a while we did have the DDR4 frequency world record. I worked with Micron and OGS, and provided some CPU samples for Matisse and Renior (Zen2) to get it done. Zen3 Vermeer had the same IOD / memory controller.",
      "Damn those are some insanely tight timings on the 6400CL26. Which configuration was easier for you to stabilize?",
      "Simple, they never claimed to be stable. Buildzoid always does extensive stress tests before he says something is stable. Most reddit overclockers don't.",
      "I'm currently running the Asrock Taichi x670e (already had Asus x670e Hero; will cycle through all the brands for home dogfooding over the next 8-12 months).  Both of these boards are DDR7200 stable in my testing with several samples of each, and various CPUs.  As for 1DPC boards, it just depends on which tier/price-point. The Asus Gene can run DDR7200-7800 easily and you've probably seen >8000 on that one. I thoroughly tested it at 7600 and it was legit daily-driver stable.  I haven't had a chance to test many of them, but I'd generally expect x670/B650 boards to be faster than something like A620 just because the latter would likely have less PCB levels, and is less likely to use low/med-loss PCB material, among other design choices.\n\nAll of the x670e boards that I have personally tested are DDR7200 stable (mostly 2DPC boards).  I'm excited to see the new coverage and reviews that are surely coming over the next couple of weeks.",
      "I would recommend FCLK for gaming at 8000MT/s, which would yield 1:1:2 clock ratio.  For 6400, faster FCLK is fine.",
      "Anything with hynix chips cans do high speeds and they're available on cheap kits too. No need to spend much to get the best.",
      "I spent more time on 6400 CL26.   \nThe 8000 CL38 config isn't as optimized. Just wanted something stable (This has passed 10000% / 3 hours Karhu) for benchmarks. Primary timings are probably as low as they go in my case, secondary and tertaries have room for improvement I guess, but are way better than auto values.",
      "I have the kit that micro center was giving away with cpus for a bit. Gskill 6000 but cl36. I've tuned my 7700 but I just enable expo on the ram and called it a day. I'm just not experienced enough with ram overclocking and timings to really mess with it.",
      "Exceptional work there dude.\n\nI'm just looking forward to better overall memory support and also a fast boot option. My MSI MPG CARBON WiFi board doesn't have a fast boot option yet so it trains the memory on every boot which doesn't take as a long as the first initial train but still has quite long boot times compared to my old X570 board which booted in a mere 8 seconds to windows.",
      "Sounds like there's not much reason to go beyond 6000c30, then.",
      "As OP said, dual CCD will scale better. My 7200CL32 setup at home is >100GB/s for Read/Write BW. I'll try for DDR8000 1:1:2 next (that's why I installed 8000MTs rated modules afterall üòÄ ).",
      "I'm pretty sure my model has Samsung. Again I'm not super bummed about it.",
      "But only if you can run it in 1:1 sync with the memory controller."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6600"
    ],
    "title": "AMD Radeon RX 6600 XT review: solid 1080p performance, but falls away fast at higher resolutions",
    "selftext": "",
    "comments": [
      "Thats 128bit for you. Hurts at high res/qualy modes.\nRdna2 is sure great speedy arch for high refresh gaming at moderate/low resolutions, but stalls a bit when going gets tough.\n\nThat said, at current prices, its complete robbery.",
      "Yeah looks like a great card for $280 but paying more than $400 for this is absolutely ridiculous.",
      "Keeping my 580 8GB still!",
      "Honestly i think it's amazing what AMD's been able to do with a 128bit bus and 'just' 32mb of cache. I mean it keeps up very well with the 5700xt at 1080p and 1440p, which is a GPU with twice the bus width, and almost twice the bandwidth.\n\n>That said, at current prices, its complete robbery.\n\nYes, but it is the mildest robbery available at the moment. if you absolutely need a new GPU now, you can do a lot worse then this one.",
      "Will we ever again get a 1080P gpu at 250$ mark? These prices will kill me!",
      "Yeah, falls away at ultra details... I used RX580 to play @ 1440p and this will be muuuch better.",
      "In their defense, are those the compromises we should be making when we're paying $400 or more? Especially if we can't secure it at MSRP? I say that desperate to replace my reference RX 480. It runs hot and loud and I'm starting to come to terms with the possibility that if I want anything in the next year remotely approaching some pretense of value, this might be it.\n\nMy \"new\" 5600X has been hampered by my ancient GPU for almost a year now. I don't know that I have the patience for another. If I  wait, I'm facing the real possibility that the majority of my current computer's life will have been spent underutilized.",
      "China's Blockchain yuan (if it happens) will definitely not be associated with mining on consumer GPUs. China is interested certain benefits of Blockchain technology, but distributed and independent control of the financial system is not one of them.\n\nI also imagine that if they do roll out a digital currency, not only will it not be private or distributed, but they will also outlaw any type of competing digital currency that is.",
      "Yeah if it was at least less than 350 I'd go for it and upgrade my whole system. And when i eventually get a 1440p (or UHD) monitor i can get a new GPU down the line.\n\n  \n\n\nBut paying close to 4900 SEK (550 USD) is just not reasonable for a 1080p GPU i don't intend to use for myself very long.",
      "This should be a sub-$200 card.",
      "Yeah double the performance! *just bought earlier and replaced my RX580\n\nWhat the reviewers though havent tested or shown and now i am just finding out, is that lowering the setting to just medium with some high makes 1440P at high frame rates possible.\n\nI really want to compare it to a 3060 and 3060 Ti but the tests are at 1440P at med settings",
      "Looks like a great 1080p 144fps buy. It beats the shit out of 3060 and comes close to 3060ti at 1080p.",
      "Yeah. Infinity cache scales poorly. \n\nAt 1080p 32mb is roughly equal to an additional 128 bit bus making it equal to a 256 bit bus total, or what the old 5700xt had, but with faster 16gbps memory.\n\nAt 1440p it's more like 64 bit and, or 192 bit total which is still somewhat acceptable, and usable. \n\nAt 4k it's only acts like an additional 32-42 bit if you do the math, or like 160 bit total, which is why it chocks so hard.\n\nAt least that seems to be roughly what the AMD [cache hit rate chart](https://static.techspot.com/articles-info/2151/images/2020-12-03-image-4.png) implies.",
      "Same.   Wish the market wasn't this absolutely mad right now",
      "How much is a second-hand 5700xt or a 1080ti - I am assuming more than $ 380?\n\nThis seems to beat it in pretty much all tests, it sucks that the graphics card market is ridiculous but are people going to be able to get better performance at that price point in the real world?",
      "Thats why you wait. Paying $450+ for this crap isnt the way to go",
      "So these guys keep hammering the RT argument despite reviewing a (MASSIVE AIR QUOTES) budget 1080p card. Anyone with half a brain has noticed that with the market at the current inflated prices aiming for a tech that [barely changes](https://www.youtube.com/watch?v=nAfsJc_LNjU) the visuals of most games where it's implemented and is EXTREMELY RESOURCE INTENSIVE should not be advocated by any respectable reviewer. Were I buying a 1080p constrained budget card today, RT would be the least of my worries. Looking at the 100 most played games on Steam, it appears it's the least of everyone's worries. Nevertheless, DF continue to choose to use 6 NVIDIA sponsored games, give too much emphasis to RT, ignore that upscaling/reconstruction below 4K is REALLY sub par and more egregious of all, being called EUROgamer, ignore that the 6600XT is the only fucking card you can buy since launch throughout Europe without selling a kidney. Would I advise anyone buying it? Fuck yes, if you need a card and have the money and don't want to pay 150% MSRP, otherwise sit this, the 3060 and 3060ti out, they are absolutely garbage tier value historically, a fact which apparently does not merge well with the very NVIDIA friendly (heavily sponsored) DF editorial direction.\n\n&#x200B;\n\nedit: this should be, at best, a 200‚Ç¨ card. Fuck the current market!",
      "The 6600XT is basically the same performance as a 5700XT -IF you have it running in a PCI-e 4.0 slot. If you stick it in a 3.0 slot it‚Äôs slower than a 5700XT, so it‚Äôs actually less-desirable for the crowd that it should be aimed at (people holding on to their older cards and hardware as long as possible). \n\nPlus you‚Äôre paying the same price or more than a 5700XT cost right before the launch of RDNA2. I got my XFX THICC II 5700XT for $336 a couple months before RDNA2 launched for example. I reckon if the market weren‚Äôt compromised by crypto and the pandemic that the 6600XT would have been a sub-$300 card, and for under $300 it would have been a great buy. $380 for essentially a more flawed version of a 5700xt though? Years later? Yeah not so sure about that.",
      "Its over",
      "if you can find it at \\~3060 prices, its a no brainer"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6600"
    ],
    "title": "RX 7600 vs RX 6600 XT at 1Ghz (architecture test)",
    "selftext": "",
    "comments": [
      "Description API Overhead test from 3Dmark says \"Do not use it to compare graphic cards\" and \"You should not use those scores to compare systems or graphic cards.\".",
      "Doesn't RDNA3 have separate clock domains between shaders and front end, and the latter can't be changed by the driver? \n\nIf they only set the 7600's shaders to 1GHz while the front end is still on \\~2.5GHz, this is obviously going to give a massive advantage to the 7600.",
      "Compare different API's such as dx11/12 and vulkan for the given gpu.\n\n> Dubbed the 3DMark API Overhead Feature Test, this benchmark is a purely synthetic benchmark designed to showcase the draw call benefits of the new API even more strongly than earlier benchmarks. \n\n> . . . \n\n> The end result, as we‚Äôll see, showcases just how great the benefits of DirectX 12 are in this situation, allowing for an order of magnitude‚Äôs improvement, if not more.\n\nhttps://www.anandtech.com/show/9112/exploring-dx12-3dmark-api-overhead-feature-test",
      "So what does the overhead value indicate?",
      "So the 7600 is about 15-20% faster.  Just have to ignore the api tests as they are not valid for comparison of graphics cards",
      "In case of the RX 7600, the clock speed is synced between shaders and front end.",
      "It's to indicate relative performance between APIs on your PC. Judging by ratio between DX11 and DX12/Vulcan I think it test some scenario of being CPU-bound.",
      "Title says 6600, chart says 6650",
      "It indeed is likely clocked higher still. This would make rdna2's cache performance terrible compared to rdna3.",
      "Sounds like that feature that was supposed to be available in the Vega 56 but was never enabled. I do not recall what the feature was, other than it was supposed to boost performance.",
      "> So the 7600 is about 15-20% faster. \n\nWith 13,3/11,06=~ 1,2x the transistor budget. Which is pretty much what you would expect.",
      "You would expect rdna3 to clock higher though.  So IPC increase + clock speed increase should equal a bigger performance delta than what we are seeing right now.  Looks like finewine is back on the menu.",
      "Actually, the dual issue shaders take up relatively little space for the possibility of more shading throughput as only the small execution unit has to be doubled up (it scales well to smaller nodes), while leaving the scheduling and such largely the same. Also RDNA 3 does have quite increased performance per WGP so it is working, though the compiler is not optimal at finding dual issue possibilities.\n\n  \nNvidia also does the same thing although calling it just extra cores, when they made ampere so there must be some logic to it.\n\nAnd looking at the number of transistors, the 7600 has just a bit more than the 6600xt on a similar node, so the \\~15% perf increase is not bad from architecture ipc alone.",
      "It's technically interesting.",
      "Yes this is my mistake. I apologize.\n\nThe difference between the 6650 XT and 6600 XT is the memory bandwidth, the clocks (slightly) and power limit. And all 6650Xts are AIB cards.\n\nNow in this specific case it being a 6650 XT is good since it means the memory situation is close between the two. The 6650 XT has 280 Gbps, the 7600 has 288. Almost equal.",
      "Primitive shaders?\nWe use them since VII/RDNA",
      "Check the source link, the author mentioned that both frontend and shader are running at around 1GHz. The frontend clock is only \\~10MHz higher than shader clock.",
      "The point is to see what differences in performance come specifically from architecture.  Why this seems lost on so many people here is bewildering.",
      "Nice metrics! Can you add power draw or consumption please?  üôè",
      "Thanks for posting."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6600xt"
    ],
    "title": "I don't understand the people angry with the 6600XT MSRP",
    "selftext": "The GPU market is absolutely insane right now. \n\nA bit shy of 2 years ago, I bought a Sapphire Pulse 5700 for $370. This week, I sold it for more than $800. I could have sold it for more because it went in like 2 hours. Probably Could have gotten $860+\n\n$379 is too much for a midrange card, yes, in theory. In practice, these cards will be sold out at $500 as an incredible deal -- because that's almost what a used RX580 costs these days -- and you'll actually be seeing them sold closer to $600+, still being sold out.  I'm 100% going to buy one if I see a $500 price, because I'll get more performance than my 5700 and a few hundred in spending cash as the net result, even if the card isn't worth half of that $500 under normal circumstances. \n\nBoth Nvidia and AMD are selling every single card they make, and they're selling them way cheaper than their actual market value. \n\nBecause, again, $379 is way, way below market value for an 6600XT right now. \n\nHow are AMD or Nvidia greedy fucks for selling below market value? And why would it matter in the first place if the MSRP price is fake bullshit in the first place? \n\nI understand the people who are worried that this is the new normal, but those people are complete idiots. In a competitive market, prices aren't dictated by tradition or expectations. They are dictated by how much it costs to bring something to market (i.e. the margin) and the supply and demand for the thing being made. Supplies are constrained, demand is crazy stupid, the whole market doesn't make a single lick of sense in terms of the resulting prices.",
    "comments": [
      "My economics prof once told me.\n\nIf an product is sold out, it was too cheap.\n\nThe second hand market is actually the price people are willing to pay for such a card.\n\nI don't even dare to look at the market right now what my simple rx 5700 is worth.",
      "Picked up my RX 590 for ¬£150 last January. Will be keeping it for a while given current prices.",
      "You are actually right. Most of us won't able to afford to buy a new GPU in near future. I'll probably just skip this generation and will get myself a new GPU in 2022 or 2023. My 570 is struggling but I'm not willing to pay 600 euros for a midrange card.",
      "At this point they could sell it for 6000$ and raise the price of all their other cards too with this fanboy logic",
      "You re right. Vegas were $250 new by 2019, available everywhere while going for $1000+ with no availability in 2017. Same with Polaris right now. In late 2019, 570s were below $150 regularly (even $99 in same cases). Now, good luck finding any new Polaris below $300... Miners are the ones effing up the market, not manufacturers. And that's not trying to defend AMD or Nvidia, it's simply reality.",
      "I guess I am dumber than a rock for not wanting people to charge me a minimum of $400 for 1080p. I am so dumb for hating the price increase trend",
      "Here, scalpers! Ask OP for 3x MSRP",
      "I‚Äôm convinced that there are people on this sub that don‚Äôt actually use high-end graphics cards, they just buy and sell them like stocks and other investments. That‚Äôs why they snub their nose at people who actually care about buying these things at a reasonable price.",
      "My 5600XT for $290 last year is starting to feel like one of my best purchases in years. \n\nI truly feel for everyone that‚Äôs either trying to build their first gaming PC or those who need to upgrade/replace their GPUs this year.",
      "Well, second hand market is actually below what people would be willing to pay for a NEW product with WARRANTY. AMD could probably sell the cards 200$ above second hand market price.",
      "If one thing this gpu shortage has made it clear is the number of people who don't understand basic economics",
      "People aren't mad because of this card's msrp, they are mad because this msrp means that when the market does stabilize, in the next generation they are going to raise the prices again, and there won't be a gpu crisis by then. That's how we got 1500$ gaming GPUs, and, while I believe the GPU market will continue to creep up its prices, that should really come with an increased performance per dollar, at least sub 1000$, like the guitar market, for example. If they market a 1080p card at 400$ now, next gen will be 450-500$, so what resolutions are fit for a hypothetical 200$ card? 360p?\nNot to mention this card is about the same performance as the 5700 xt at 1080p, will be slower at 1440p, because of the bus limitation and small infinity cache, has bad almost to the point of unusable rt capabilities and has less CUs, for about the same msrp.",
      "There's no low end, nor mid range. the prices start at high end, then go to hoverboard money tier.",
      "32CU 2048 shader ~320mm^2 die size is literally specs of RX 470/RX 570 that launched at around $180. The only world where $380 MSRP makes sense is when you compare AMD to literal scalpers and in that case they can fuck themselves.",
      "Overpaying for a card and telling yourself you understand why you did does not make you an economist.  Also, it is fallacious to correlate a \"good big strong\" economy with increased level of quality.  I think those two things are part of the misunderstanding as well.",
      "i argued with someone yesterday who unironically told me companies will keep inflating prices to $10000 and make more profit off rich people alone. \n\nlike they literally think prices are set by companys' goodwill\n\nand the anti-capitalism 'corporation = evil' meta on reddit doesnt help",
      "Company interest =/= Consumer interests\n\nAMD and Nvidia are making a killing, there's tons of demand, and they can raise prices. Nobody reasonable is trying to argue against that. The point you're missing is that none of that matters for the consumer.\n\nIt doesn't matter to a consumer if AMD is making more money, or if they're \"justified\" in their actions. All that matters to the consumer is if they're being offered a good product at a good price. 379 MSRP for a card that compares to a 3060 is NOT good value. After scalper pricing, it's even worse value. \n\nYou can say that given the totally fucked pricing it makes sense, but that's ignoring that 99.9% of people are not willing to pay 800 dollars for a card that's going to lose to a 3060ti.\n\nIf you keep defending companies actions without considering your own interests, you're just going to keep getting fucked on prices.",
      "I bought a used RX 570 4GB for about $80 back in 2019.\n\nThat was when eBay sellers were listing 8-20 of RX 570/580 GPUs in boxes and would not allow individual sales. It was either buy the entire box or nothing.",
      "what SOME people are willing to pay...higher price less demand.",
      "Yes, just the latest example- Ryzen 5600X, 5800x, 5900X can now be found at -20% from MSRP. Same was for Zen, Zen+, Zen2, Polaris, etc."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6400"
    ],
    "title": "Does Ryzen 7000 benefit from DDR5 6400+? Is it even possible? Like, could I theoretically slap a 7200 MHz kit and see a noticeable difference?",
    "selftext": "Title",
    "comments": [
      "Hardware Unboxed YT channel tested 6400 Mhz RAM, he said the hassle to get it working properly aint worth it even if it yeilds more performance, the best is 6000 Mhz and thats what they have been using in all of their testing.",
      "Beyond a certain point (around or shortly after ~DDR5-6000) the memory *controller* clock can't keep up any more and has to drop to half clock (e.g. 1600mhz to drive DDR5-6400, instead of 3000mhz to drive DDR5-6000). That hurts performance much more than any increase in memory frequency, especially because such frequency gains can't get meaningfully more bandwidth across the limited IF links.\n\nThose IF links are sized for ~DDR-4000 bandwidth. Running memory at higher speeds helps to keep those links full and reduce bubbles and downtime, but with diminishing returns.",
      "DDR5 6000 is the sweet spot, 6200 can be stable 6200+ forget about it.",
      "Nah this is for intel. amd's memory controller isn't great.\n\nPersonally I'd buy the cheapest DDR5 I could find and make sure there is budget for an x3d CPU ASAP.\n\nThere aint a fucking thing 8000mhz DDR5 can do to compete with a huge cache. Something to keep in mind for intel and amd buyers alike.",
      "ngl the sweet spot is *whatever memory lets you put left over budget into an x3d*",
      "\"Infinity\" Fabric more like Finite Fabric amirite",
      "if you have cash khajit has wares! Although you will benefit more from buying high quality ram, leave it at \\~6ghz and just tighten the timings and subtimings. Its just going to take work no matter the money.",
      "with uclk:memclk 1:1?",
      "I run 6400 stable.",
      "Then you buy a 13900k system, a 5800X3D system, and a 7950X system all with 4090's and play on whatever one has 5% more FPS in your given game. All of this stuff is basically irrelevant right now outside of edge cases, and in 12 months the landscape is going to be different anyway with new gens of memory, CPUs, and GPU.",
      "It isn‚Äôt really unfair if the intel chips can run the ram far higher than AMD.",
      "Yet here are your guaranteed supported stick configurations:\n\n* 2x1R DDR5-5200\n\n* 2x2R DDR5-5200\n\n* 4x1R DDR5-3600\n\n* 4x2R DDR5-3600\n\nYour memory can support any speed it wants, the IMC ultimately decides what speed you really end up using.\n\nDo I have to mention how ryzen 2000 series often, but not always could do 3000-3200Mhz, but neither are supported and there was no guarantee? \n\nAlso you're on a new platform, people are going to get duds here and there.\n\nRead the fucking spec sheet.",
      "A 7200 kit will use Hynix A-die, which can't do as tight subtimings as Hynix M-die. Stick to DDR5-6000 kits rated for AMD EXPO\n\nSince AGESA stops training memory beyond DDR5-6600, aiming for A-die is pointless.",
      "Dont know why I have been downvoted. Guess jealous people dont like others good OC settings. Here a pic for proof of 120+ gb bench.\n\nhttps://ibb.co/YDfnbNP",
      "Yeah this is right take. 5800x3d showed that with the extra cache you can have a 3200mhz based rig beating the hell out of rigs with memory twice as fast.",
      "The spec ranges from DDR5-3600 to DDR5-5200 depending on the memory configuration.",
      "6400MHz provides 102.4GB/s maximum theoretical bandwidth. You're using MSI motherboard and have enabled the \"high bandwidth\" mode, or whatever it was called?",
      "Could you please elaborate why? Will it change in the future or are we stuck at 6000 while Intels will be flying at 10000 soon?\n\nIs it a problem of the CPU or do we have to buy a new motherboard too?\n\nFor example I buy a 7700X today with 6000 ram. But once 8800X shows up and supports 8000 ram can I just buy new ram and cpu and my motherboard will support it (after a bios upgrade for new CPUs)?",
      "You have keep mclk sync with uclk to get the benefit",
      "Agreed, I was trying to say it seemed unfair until you learn about the infniity fabric limitations. It's counter intuitive since AMD CPUs are relying more on memory bandwidth than Intel is too."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6600"
    ],
    "title": "Buying an AMD card after 14 years of separation (RX 6600)",
    "selftext": "Hi guys,\n\nMy EVGA RTX 2060 Gaming SC started to have some major heat issues just 3 months after I bought it. Hot spot had nearly 110 Celsius degrees and the card fan noise was similar to the starting airplane. It was working with max RPM all the time (3400) in any games that would make the card warmer than 73 degrees (I read that the issue is related to a faulty temp controller because I was not able to change the fan curve in the MSI Afterburner). So I was told that I will get my money back and now I am looking for a new GPU. My budget is limited and RX 6600 seems to be the best option. My CPU is 12400f, I have a 550W PSU and 16GB of RAM. My MOBO has a PCI 4.0 slot.\n\nAs I mentioned in the title, the last time I used the AMD card was 14 years ago and it was the Radeon HD 4850. I had so many driver issues with it that I just didn't want to have an AMD card in the next years. \n\nNow we have 2022 and I know 2 things:\n1. I don't want another 2060 (I read too many things about how bad the 20xx series is)\n2. I also read many things about how good performance/price you get with the RX 6600.\n\nThe problem is no matter where I go I find lots of people complaining about the AMD drivers. There are users who had no issues at all, there are users who experience some issues for a week or two after releasing new drivers and then they are fine for a month and also there are users who had so many driver issues that they gave up and rebought NVIDIA card.\n\nI mean it happens both ways. All I want is peace. I play a lot. Would you give a shot to RX 6600? I can get the XFX SWFT 210 Speedster with Dead Island code 2 for the price of returned RTX 2060. I saw that it will give me around 10% performance boost on average but all I care about is not looking for another card in the next months after buying this one due to some issues.",
    "comments": [
      "AMD drivers are in a much better state in 2022.",
      "Honestly, with how much they've improved, it gives me hope for Intel's graphics drivers too.",
      "I highly recommend using the AMD Driver Cleanup over DDU if you ever do have troubles. DDU still sounds the best to clean your Nvidia drivers out before the AMD driver is installed. Optional driver updates are really optional, but I still pick them up right away if they targeted a new game I'm going to play.",
      "It's funny because I just picked up a second hand rx 580 for my second machine (1060 in my main machine) and I am really impressed by amd's software so far. It tells you the actual gpu power draw! I had to change the default fan curve, put a cap on power draw to limit it to the same 120w max as my 1060, used radeon chill to lock fps to 60 with supposedly reduced latency compared to vsync, got some really good looking sharpening going on too and it's super responsive. \n\nThere's so many features in adrenalin and so much real-time data that you don't get with nvidia\n\nEdit: the power limiter lead to a bluescreen during darktide, and my fan curve adjustment caused an overheat in darktide after 4-5 hours. My own fault for slapping those values in without stress testing it. Default seems to be OK and power draw was near enough 120 under load anyway",
      "Yup, the entire problem with Arc is 100% drivers - and intel knew it would be, i'm pretty sure that is why they only tried to compete midrange on silicon.\n\nthe reason the amd and nvidia driver packages weight half a gig is because there is an entire library of game specific fixes and optimizations (rewritten shaders, etc) in them.\n\nthe arc is also not even running D3D11 or D3D9. They're doing JIT translation of all non-D3D APIS to D3D12.  That is going to take some time for them to mature that code and get it up and good.\n\ni expect by the end of the decade intel gpus might be competing at the top end",
      "The only time you can probably get some errors is when pushing oc too much, Nvidia doesn't even have a built-in feature like in order to play safe, then people tend to blame AMD for \"bad\" drivers for their own mistakes when in reality AMD is giving you a little bit more freedom to play with graphics card settings, oc'ing, fans speed, etc\n\nAdrenalin is a full feature software, easy to use once you understand how to use it.\n\nI've been using Radeon graphics since the R9270X era exclusively, it's been a great journey for me so far, so much that I have never considered buying into Nvidia at this point.",
      "4850 was my first card in my first build in 2008!\nYes the 6600 cards have no problem with heat and are a bit stronger than the 2060.",
      "Drivers often is user errors.  \nUnstable computers and then blame drivers.  \nDidnt clear out old software and have driver conflicts.",
      "AMD drivers are more sensitive to unstable memory/CPU overclocks. Aside from that, they are on par with Nvidia.",
      "I've still never had a driver issue in 7 years of using Radeon GPUs. \n\nThere were a couple releases where radeon settings was a bit buggy, mainly UI stuff. But always solid performance. \n\nJust stick to the most recent recommended driver and you'll be good.",
      "i used a rx 580 for almost 6 years, and finally switched to a 6800 3 days ago. timeout drivers  is the only issues i got in all this years.\n0 problems with 6800 for now",
      "That works too because of very large chunk of people that have AMD driver issues are people that have switched over from Nvidia and haven't done a clean install or they haven't used ddu",
      "I had a 5700XT before the current 3080FE and never had any issues even during the peak of the black screen driver complaints. It was a Sapphire Nitro+ which was one of the top of the line models which maybe why it was faultless. Also had good quality HDMI cable and EVGA power supply.",
      "And has no warranty. Used cards without warranty are like lottery tickets. There is no point in buying them unless you have 200+ USD to take a risk.",
      "I will just go with a clean installation.",
      "Run the stable driver (not the optional driver) and I doubt you'll find a single instability. Been rock solid",
      "If you are just a gamer, and dont do heavy streaming and content creation, imo AMD has the better drivers by now (simply because of modern looking UI that gives you ton of options you dont have with stoneage nv ui). I joined AMD 1,5 years ago (6800XT) after 17 years NV only and didnt regret it once. More the contrary, i wonder how NV still has this ugly ui and so much less utility in their drivers. The last issue AMD drivers had were their huge DX9/11 overhead. But the pretty much fixed it a couple of months ago.",
      "I don't know who needs to hear this but I was getting pretty regular timeout errors in almost every game I played with my 6900xt.  I tried underclocking it maxing the fans running older driver versions etc.  Turns out it was my RAM the entire time, even though it was on XMP it wanted more voltage.  Every crash seemed like a GPU related crash (adrenaline error or GoW was saying GPU temp errors) but it was RAM in the end.",
      ">Yup, the entire problem with Arc is 100% drivers \n\nOh, the hardware has big issues too.   Awful idle power usage, even in the best case scenario (DX 12 game, higher res) the performance isn't very good for something with that much die are and power usage.\n\nIntel has a long way to go hardware wise as well.",
      "My 6900xt is the first AMD card I've owned since the 290x in 2014. Got it a few months ago.\n\nIn the 4 months I've had it I haven't had any issues. It replaced a 3080."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6600"
    ],
    "title": "AMD RX 6600 stock runs dry in China, the company shifts focus to Radeon RX 6750 GRE 10GB",
    "selftext": "",
    "comments": [
      "This is still pretty much the only card most people need, it runs Doom Eternal at 100+ fps and most modern games on high with RT off at 60fps.",
      "Doom eternal runs at 60FPS on an Xbox One & PS4. 100 FPS is an extremely easy feat\n\nYou also need to specify a resolution if you're talking GPU performance",
      "You can't.  The reference 6600 was never manufactured.  It's just a rendered image only.",
      "Doesn‚Äôt fix everything. Even though it‚Äôs smoother it isn‚Äôt that responsive.",
      "Probably nowhere. The RX 6600 didn't have a reference design, so it's likely just a 3D render made by AMD for illustrative purposes.",
      "60fps isn‚Äôt high enough when a lot of people have 144+ hz monitors now a days.",
      "Where can we buy that single fan RX 6600 from the OP's picture?",
      "I think it's just a mock up. It looks like an AMD design but they never released anything below the 6700 xt for purchase directly on their site.\n\nIt's too bad. It has a great aesthetic.",
      "I've been using a 6600 since early 2022, it does everything you need it to.\n\nZZZ @ 1440p, Eve Online, MH:W, Elden Ring, all the esports. I've even tried LLM's on them(not great, but usable). UE5.3, Blender, Clip Studio, again, it's not a great card, but if you're just starting out, it does enough!\n\nGreat value, low power usage, and cheap!",
      "With mouse and keyboard I just do not find 60fps to be playable. Even drops down to 90/100 from 140/50 sorta range is extremely noticeable.",
      "Same, except late 2022. I feel like it's the 1060 / 580 of its generation. Not the best, but good enough for what most people play, and probably the best bang for the buck out there.\n\nFSR / XESS / etc. are helping me with the few games it struggles with, and honestly, those games generally tend to be poorly optimized anyway.",
      "Ok since people are downvoting me I guess I gotta post sources...\n\n[https://www.youtube.com/watch?v=NdoxEaySXis](https://www.youtube.com/watch?v=NdoxEaySXis)\n\n[https://www.youtube.com/watch?v=EOBE-Ade9MQ](https://www.youtube.com/watch?v=EOBE-Ade9MQ)",
      "I wonder if 60FPS or 120FPS is 'standart' these days",
      "I recently got the Asus Dual 6600 and man this card punches! Playing Warhammer 3, le mans ultimate and ACC all maxed out 1080p with no issue",
      "This. Idk why ppl act like 1080p60fps is the bar to meet in 2024. That ship sailed. \n\nThe new standard is 1440p120fps.",
      "Lemme guess what those \"few\" games might be. AW2, star wars jedi whatever, hellblade 2",
      "By that logic we should have all been happy with 20fps then right?",
      "I would be more interested in the 12GB version wich is basically a cloned 6750 XT so with faster 18Gbps VRAM\n\n2 more GB is welcome for using extra features like frame generation / afmf with texture-heavy games like console ports\n\nI also wish there was a small 2slot model like the PowerColor Fighter series ... guess im expecting too much",
      "ü§ì",
      "I don't know what AW2 is, you're correct with Star Wars Jedi whatever, and another one is Starfield, which I had to use FSR2 just to be able to play with a decent frame rate.\n\nHonestly, if devs optimized their games right, I'd say that the 6600 would probably be relevant beyond 2025, but if Ubisoft is any example, this might not be the case, unfortunately."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6400"
    ],
    "title": "AMD Ryzen 9 9950X DDR5-6000 / DDR5-6400 / DDR5-8000 Memory Performance",
    "selftext": "",
    "comments": [
      "1:2 past 6400 so pointless now. Also this: ‚ÄúThe Corsair Dominator Titanium RGB 2 x 24GB DDR5-8000 CL38 CMP48GX5M2X8000C38 memory kit was the only one problematic and yielding sporadic segmentation faults under some demanding workloads‚Äú. \nDamn you, Corsair /s\nBasically wait for x870e and gskill.",
      "Expo I for each kit",
      "1:2 was always pointless unless you can achieve at least 7800MT",
      "Unfortunately I don't review RAM too much on Phoronix and thus typically end up buying kits on my own. With limited budget that is why there weren't any 4x32 or 2x48 kits tested among other interesting kits.",
      "Interesting results, but the article does not state how the bios was configured.  Was this set to Auto, Expo I, Expo II, Expo Tweaked or custom?",
      "It looks like DDR5-6400 2x32 is the sweet spot.  Would like to have seen 2x48 and 4x32.\n\nDDR5-8000 didn‚Äôt give that much an improvement in most benchmarks and in a few cases was worse.",
      "Unlikely. I don't typically review RAM much unless a vendor proactively comes out to offer review samples for some interesting kit... So usually just look at a few kits I buy myself with my limited budget. I don't think I've heard from anyone at GSKILL in like \\~15+ years, so rather doubtful; IIRC their response way back then was not offering review samples due to few kits performing so exceptionally well while granted these days they seem to be much more robust. The other GSKILL units I have were received from AMD in prior review kit bundles.",
      "the memory controller is the same as last gen i dont think x870e is gonna do much",
      "2200 MHz fCLK is around a 3-sigma deviation on Zen 4, meaning very few CPUs can actually do 2200 MHz fCLK without memory errors. Zen 5 might be a little better, but there aren't enough sample to be sure yet. \n\nWith Zen 4, above 6000 MT/s fCLK is more important for real-world performance than the memory frequency - assuming timings are already tuned. \n\nFrom my experience, unless specified otherwise, motherboards will usually drop the uCLK to 2:1 above 6000 MT/s. In most cases, 1:1 should work up to 6600 MT/s, again, if the CPU can handle it. \n\nSo the absolute highest you can go on Zen 4 would 2x32GB 6600 MT/s (\\~CL28, \\~120ns tRFC) 2200 MHz fCLK, 3300 MHz mCLK and uCLK. This configuration should outperform a 8000 MT/s tuned configuration that is running at 2000 MHz uCLK and 4000 MHz mCLK and 2200 fCLK, since the IMC is running slower and also since tREFI cannot be raised above 65635, meaning that higher mCLK values reduce memory performance due to the memory doing refresh cycles more frequently. This is an artificial limitation on the Zen 4 memory controller / UEFI.",
      "The kit will most likely do 6400 just fine",
      "Another nice test, thanks!\n\nI do have one question about the 6400MHz RAM on your board, was your UCLK set to AUTO, which could be in a non \"native\" mode because apparently above 6000, while Fclk can be stable above 2000MHz I heard Uclock doesn't like >6000MHz ram and goes down a notch.\n\nIE: 6000MHz is 2000Mhz Fabric + 3000MHz UCLK + 3000MHz MCLK(\\*2 = 6000MHz)\n\nIt should say FCLK 2133 (or 2200?) + 3200UCLK + 3200MCLK for 6400? Dunno what the board will output but AIDA64 has that info\n\nand 8000MHz is 2000Fclk (1:4) + 2000UCLK + 4000MCLK",
      "From the PR the only changes seemed to be to AGESA to maybe get 8000 to be simpler for xmp, otherwise the claimed 8000 MTs was possible for a while now with a not very complicated custom tune",
      "tRFC and tREFI are the most important, IMO. You can have a kit that is stable at 8000 MT/s with CL10, but if set tRFC close to tREFI, the RAM is unusable. More realistically, good kits can push tRFC really low (Hynix A-die is around 120ns, or ~360 cycles at 6000 MT/s, M-die is around 160ns, or ~480 cycles at 6000 MT/s, while most Samsung kits are around 800 cycles at 6000 MT/s. Obviously, cutting the refresh cycle by half is going to improve performance noticably. The rest of the secondary timings are also quite important, you can get some nice performance with them. Tertiary timings are interesting when you have dual rank memory, otherwise most of the timings are not really used. Primary timings are the least impactful, apart from scoring well on memory benchmarks that are doing artifacial, burst-y memory operations. Just imagine how often a real game or app, using 8-20 GBs of memory at a time, will access 8 bytes of memory. As in only 8 bytes. No more. In that case, primary timings are super important, but if you need more memory than 4 Unicode characters, secondary timings are in play already, and there you have tFAW and tRRD (S and L) and tWTR (S and L) timings in play, governing the vast majority of memory operations.",
      "trusty ol' phoronix",
      "Add it to the pile of tests that showcase latency is more important than total bandwidth for Zen processors.\n\nCL 28-6000 seems to be the go to, CL32-6400 and CL30-6000 look like cheaper alternatives.",
      "Corsair is the worst ram manufacturer by far.",
      "The primary timings you listed don't really matter. If the memory controller is interleaving commands correctly, those timings are only used at around 5% of total memory requests. What matters more is tRFC (how long a refresh cycle lasts), tREFI (how often the memory is refreshed), and tFAW (how long is the interleaving window) and the corresponding read and write timings for command interleaving.",
      "Hey OP ‚Äî /r/AMD is in manual approval mode, this means **all submissions are automatically removed and must first be approved before they are visible**, this is done to prevent spam, scams, excessive self-promotion and other rule-breaking posts.\n\nYour post will be approved, provided it follows the subreddit [rules](https://www.reddit.com/r/Amd/about/rules/).\n\n**Posts regarding purchase advice, PC build questions or technical support will not be approved.** If you are looking for purchasing advice, have a PC build question or technical support problem, please visit the [Q3 2024, PC Build Questions, Purchase Advice and Technical Support Megathread](https://www.reddit.com/r/Amd/comments/1dsetov/pc_build_questions_purchase_advice_and_technical/).\n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/Amd) if you have any questions or concerns.*",
      "I've ordered the 6000 kit for my new 9950x build, arriving tomorrow. Regretting my life choices now.¬†\n\nTough call to return and wait an extra couple of days for the 6400.\n\n\n\nThe Corsair vengeance 6000 I've ordered are tighter (30-36-36-76) than the tested gskill (30-38-38-96). I wonder how that might narrow the gap.",
      "damn, CL28-6000 is out already? I swear I couldn't find any lower than CL30-6000 around a year ago when i built my rig"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6600"
    ],
    "title": "My Ryzen 7 5800X3D & Radeon RX 6600 housed in an Ncase M1",
    "selftext": "Other specs:\n\nRAM: 16GB (G.Skill)\nSSD: 2 x 1TB (Samsung)\nCPU cooler: Noctua NH-U9S\nCase fans: 2 x 140mm BeQuiet!\nMotherboard: Asus B550-I",
    "comments": [
      "Shoulda went for less bling bling and more gpu ngl.",
      "Good point! A GPU upgrade is probably next on my list, but it's hard to justify, considering most of my gameplay recently is Grand Strategy Games.",
      "Looks cool! Which rgb strips are those?",
      "Linux MasterRace",
      "If you get 6750xt close to the price of a 7600 then its a fantastic choice, region prices are always different.\n\nDepends on what gaming you do because in higher gpu heavy games you will be more gpu limited with a 6750xt, that means a 5600x is still gonna be good. However more competitive games like CS and such then x3d CPUS  are gonna be a fantastic upgrade.\n\nSo in general gaming 5600x with a 6750xt is a fantastic pairing. I had 5600 with 6750xt and upgraded to 5800x3d. Thats because i wanted more fps in games like CS but also a more future proof CPU. The 5800x3d is really good in gaming that it will last for a while and you can just upgrade the GPU and it will still hang with that. In gaming at least. Other things it might hang back but it is very future proof for gaming. If it wasnt for something like CS2 and me wanting future proofing then a 5600 would still have been good and i would have upgraded GPU instead.\n\nHowever i decided to get CPU and upgrade GPU later as 6750xt is pretty good for now.\n\nAs AMD has extended their AM4 support, I would even suggest that you get a better future proof GPU right now. It will do fine paired with the 5600x, unless you want higher performance in competitive games then obviously go with 6750xt and x3d CPU, in that case 5700x3d is gonna be a great choice as well.\n\nHowever if you play more graphics heavy games and such. Then i would even suggest not upgrading CPU just yet(wait to upgrade CPU). Instead put money to get 7800xt or better as GPU. Save up a bit again and buy a x3d CPU later on. That way you will be even more future proof set.\n\nYou could get a 5700x3d as well save that money and put it into GPU. But 5600x or 57/8x3d both will do great paired with a 6750xt.",
      "How is the 6600? I was thinking of getting 6700xt . And thinking of upgrading my 5600x to 5800x3D. I have a 1080GTX right now. Only game I really play much is CS2",
      "Nice build! I've got a 5800x3d in my mid-tower and a 5600x in my M1 with the same cooler, mostly because I thought the 5800x3d would get too toasty in there!",
      "Thanks! I forget the name and brand of the light strips, but they look similar to these https://www.ebay.de/itm/386871643763 .\n\nBasically, it's a flexible rectangular tube, with the top being the light bar. The set comes with the guide pieces to shape the corners etc.",
      "Newest stable (using Wayland), running on Arch Linux.\n\nHowever, I do most of my gaming in a separate VT, running Steam on a minimal X.org-based WM.",
      "look at used gpus, wayyy cheaper than new.",
      "I got the 6600 new in 2022. As I recall, at that time, the used GPU market was dominated by ex-mining cards of questionable value.\n\nBut things might have changed now. I'll probably look at used cards too once I'm itching for an upgrade.",
      "Oh you already had the mobo yea it's a perfect upgrade",
      "I played The Witcher 3 (next gen), Doom Eternal, Spider Man, Spider Man Miles Morales, Red Dead Redemption 2, Assassins Creed Odyssey and Baldur's  Gate 3 on it at 1440p with pretty high settings and it handled it pretty well. Obviously a better gpu would have given me more fps and prettier graphics, but all of them were perfectly playable.\n\nI am thinking about getting a 7900gre or something similar soon, but it's honestly still a pretty good gpu.",
      "Nice, have a 6600 too :)",
      "Which version of GNOME and distro?",
      "It's a Logitech MX Mechanical Mini. If you're interested, you should try out the feel of it in a shop. Note that there are two versions in the same form factor, one with membrane keys, the other with mechanical.",
      "Hey, thanks for looking closely! It's an optical illusion of the spinning fan blades, they're mounted using the heatsink clips in a push-pull configuration on the tower cooler, but the back one is offset due to clearance for the VRM heatsink.\n\nI've experimented with having the back fan as an exhaust too (which would just be a couple of cm further back, almost in the same position) but it basically choked the VRMs, with the tiny, noisy VRM fan spinning up constantly.",
      "Honestly the 6600 still performs decently so it's not that bad",
      "Mini itx am5 motherboards are insanely expensive and rare. So it‚Äôs not exactly comparable.",
      "Yeah well I think the 6700xt is a decent bit better than the 6600 rx. And I think lately it's only like $10 more for 6750xt on Amazon so been thinking of possibly going for that"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6600"
    ],
    "title": "AMD Radeon RX 6600 XT with 8 lanes on PCIe 3.0 and without Resizeable BAR - Dream or nightmare for upgraders? | igor¬¥sLAB",
    "selftext": "",
    "comments": [
      "I would ask what the cost of enabling x16 would be, but that feels kind of ridiculous when we're talking about a $380+ GPU.",
      "Still can‚Äôt see how people defend AMD on this issue. I like AMD but this is just absurd especially on a pricey GPU.",
      "On silicon- it is minimal, the cost is about 1mm^2 area. Surely it would be beneficial. However, when designing the RDNA2 chip lineup several years ago, AMD likely expected N23 GPU to sell at ~$200, including the memory, cooler, board, etc.- and were cutting everything possible to save on costs. The market has changed, but honestly- during the mining boom this is not hurting them, as they sell everything they make and have not even made artificially cut down N22/N23 SKUs for segmentation. The only place this is (mildly) hurting them is in laptop GPU performance- AMD Cezanne is PCIe 3.0 only, and AMD's GPUs are likely to be coupled only with Cezanne, not PCIe 4.0 Intel. So this affects the performance of their laptop GPUs, till they refresh next year with PCIe 4.0 laptop APUs.",
      "AMD and Nvidia are using the fine print to rob us blind, every card now has a small detail . But prices keep going up.",
      "I don't think there is anyone defending it. People might still defend the 6600XT as a good buy in the current market. But I haven't seen anyone defending AMD's decision making when it comes to the 8 lanes issue.",
      "Because it‚Äôs 16x, the 6600xt is 8x.",
      "This card seems intentionally crippled.",
      "That's a fair point, though I think the reality is still the same from the consumers perspective regardless.",
      "Especially when the RTX 3060 has an x16 connector.",
      "Even the 5600XT has x16. This card would have been 6500XT in a normal market, just like the RX 550 and 5500 XT were both x8.",
      "im not a fan of raising amount of asterisks on new gpu performance. Sure ~5% per loss in most cases with pcie 3.0 is not much, but these things adds up",
      "RX 6900 XT also has 16GB of VRAM instead of 8GB on a two times wider bus and it has a PCIe x16 connector.",
      "Because the 6900 XT is likely not totally saturating PCI-E 3.0 x16's bandwidth of 15.754 GB/s. Whereas when you stick the 6600 XT in a PCI-E 3.0 slot it's likely exceeding the 7.877 GB/s of bandwidth at x8, whereas in PCI-E 4.0 it's running at 15.754 GB/s even at x8, so it's like 3.0 at max speed. I mean a 3090 hits like 11.5-14 GB/s usually. A 6800 XT, much the same.",
      "Without PCIe 4.0 it would be limited to PCIe 3.0 x8 and as we can see in the test results that results in lower performance.\n\nAlso at this point it probably doesn't increase the cost at all for this card to support PCIe 4.0.",
      "The lower end the GPU the less it matters, actually. I doubt the 6600XT would show any performance scaling under 16X gen4\n\nCan run a 1060 on 4x.\n\nI ran a 660Ti on 1X gen2 for years (eGPU) with no loss.",
      "440 for the 6600XT, 850 for the 6700XT, at my local microcenter.  I have no idea what you're talking about.",
      "It's probable that they designed this particular GPU around the assumption of mobile variants.",
      "It‚Äôs fine regardless of your board, it doesn‚Äôt cause any problems. People are just upset over design choices that COULD have been, compounded by current pricing, making every little detail scrutinized even more.",
      "The 6600 XT itself is wired for only up to x8. The connector is there for x16, but it is only x8 capable. What people are discussing is the performance loss of the card running PCIe 3 x8 vs PCIe 4 x8.\n\nAMD did the same thing with ther 5500 XT last gen.",
      "Why does this matter?\n\nWhat we're talking about is why the RX 6600 XT loses performance when running at PCIe 3.0 speeds while the RX 6900 XT doesn't and the reason is because 1. the RX 6900 XT has enough VRAM to not run out and 2. it has an x16 connector which has two times more bandwidth than a PCIe x8 connector in 3.0 mode."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6400"
    ],
    "title": "7800X3D and 6400 ram cl32",
    "selftext": "hey there fellow reditors!\n\ni am just fine with using my 7800x3d with 4800mhz safe with all these news with bios updates\n\nupdated my bios and wanted to try the actual potential of my ram\n\nso i tried 1.25 of SoC and 6400 xmp, it was okay for like 2 hours and then my game started crashing, i started panicking because this build wasnt so cheap and easy for me to get where i live\n\ni was waiting on this cpu so bad and finally upgraded to ddr5\n\nim full in team red when it comes to cpu, 2600>5600x and now this..\n\nthis feels awkward being worried about to do or what not to do with all these crazy unfair burns people had trusting everything is fine \n\nsomeone said that he is using 7800x3d with 1.15 SoC and runs 6400mhz. is that fine to use? or should i wait for another bios updates, im using gigabyte b650 gaming x ax btw",
    "comments": [
      "6400mhz is about the limit on many memory controllers at reasonable voltages. Some will not even boot at that speed.\n\nYou would likely have to loosen the timings, increase the RAM and MC voltages or both.\n\nOr just go the easy way and settle at 6000mhz which pretty much all CPUs can do.",
      "6400mhz will be pushing it on most CPUs.",
      "6000 Mhz is the sweetest spot for your CPU... try 6000 for stability and watch SoC v not to be over 1.30. \n\nYou should be fine.",
      "Memory Controller. You may as well see it as VDDIO in the BIOS.",
      "6000mhz also sits at a sweet spot for AMD CPUs as it matches the infinity fabric rate. You'd likely see slightly worse performance at 6400mhz unless you can also overclock the infinity fabric to the same.\n\nTldr: go for 6000mhz",
      "Don't worry so much about the memory voltages - just use the rated value, which is probably 1.35v for that kit. DDR6000 will run with SOC @ 1.2V or lower.  You want to run the lowest stable SOC voltage to reduce waste heat and shift more of the socket power budget to the CPU cores.  1.15V is stable on many/most CPU samples with DDR6000. The reason DDR6000 is the \"sweet spot\" is because it is about the fastest speed you can run while keeping UCLK at 1:1 ratio (3000MHz instead of 1500MHz in this case).  Good luck, take care!",
      "As far as voltages go:\nI and many others are finding 1.1 VDDSOC to be sufficient for 6000C30 using Hynix Adie. I run 6000/2133 using the following voltages, 100% stable, 100% safe. SOC drawing 7 watts at idle and 13 watts under heavy load...\n\nVDDG (both) - 0.85\nVDDSOC -1.07\nVDDIO - 1.35\nVDDMEM/VDDQMEM - 1.43\nVDDP - 0.95\n\nAIDA MEM results - 67500/94000/67500/59.6\n\nZen4 does not require high voltage for 6000C30. The gains from 6000C30 to 6400C30 are almost nil, is less than 1% in synthetics and a 0% gain in almost every game. \n\n6400 is not the way.\n\nYou gain zero on read/copy and about 4000mb/s in write speeds as well as -1ns first word access time going from 6000 to 6400.\n\nThe gains for 7800X3D should target IF instead. Each step of stable IF over 2000 is about 1000mb/s read/copy and -0.5ns first word, up to 2133. Above 2133 you will have latency performance regression whilst still gaining bandwidth, so it's still a gain, but the gain is so small it's not worth pumping any voltage to get.\n\n7800X3D is not limited by IO at 6000C30, it's limited by AMD SMU programing to target 1.08 VDDCPU and 80 watts before pulling core speed back instead of letting the CPU actually boost to 1.15 like it should be. \n\nYou can confirm this yourself, go run OCCT CPU benchmarks or look at the database of results and look at sustained VDDCPU/PPT during high load. The outliers are the people who've been able to coax more voltage safely to VDDCPU like tcclaviger (generally it's people with extreme cooling setups).",
      "Well, for most AMD cpus yes.",
      "Limit both Soc and vddr to 1.26/1.27 and use Expo I.",
      "Thx!  I'm on the AMD OC team and helped develop EXPO :-)\n\nEnjoy your system - I'm sure it's great as-is!  Some folks want to chase down that last 0.5% of performance, even if they would never notice it in real-life.  I think a lot of peoples favorite PC game is \"BIOS Tweaking\" .. i guess that's one of my favorites too :-)\n\nTake care!",
      "Tell us how it is going..",
      "Have you tested for an actual advantge, if any, of 6400 over 6000 in real use? If you are GPU bottlenecked or limited by minitor refresh rate, the only difference would be higher  system temps. I have stable 6000 with SOC 1.15 with Buildzoids timings, but am actually running memory on default 4800 for lower voltages and temps. I noticed 0 practical difference with 3080ti at 4K.",
      "Use 6000 instead",
      "Yeah I guess. What is MC?  \n\n\nThank you for ur answer dude",
      "yeah maybe i just should try 6000, thank you",
      "The 2033 fclk thing is outdated. He mentioned in a late video that it was due to an early bios bug and now scales as expected.",
      "AMD is putting limit on SOC and Mem oc with new agesa updates....as gamers nexus said there are lot of underlying issues....just limiting  voltage and mem oc will not completely solve the issue but that is a  start. ...my suggestion is just wait until AMD fixes it completely...dont play with voltages, mem oc and expo until than\n\nEven at 4800mhz jedec spec ram is still pretty fast....if you xmp maybe you will gain 10 to 20 fps at max depending on game which is not worth the risk.\n\n[https://www.techpowerup.com/308330/latest-amd-agesa-that-nerfs-ryzen-7000x3d-voltage-control-also-limits-memory-overclocking](https://www.techpowerup.com/308330/latest-amd-agesa-that-nerfs-ryzen-7000x3d-voltage-control-also-limits-memory-overclocking)",
      ">Or just go the easy way and settle at 6000mhz which pretty much all CPUs can do.\n\nTurns out there's a very fine line between \"can do it\" and \"will cook itself doing\" it.\n\nThe last few weeks were wild.",
      "yeah probably",
      "Why EXPO I and not II ?"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6400"
    ],
    "title": "MSI X870(E) motherboards now support up to 192GB of DDR5 memory at 6400 MT/s - VideoCardz.com",
    "selftext": "",
    "comments": [
      "Enough RAM for Google Chrome.",
      "Wow with that much RAM you will never need to download more again.",
      "To put it simply:\n\n48gb sticks are readily available. It's doable to do 4x48gb (well good luck on timings/speeds) to get 192gb.\n\n64x4 for 256gb is absolutely possible... But it is very very niche on consumer platforms without registered memory. I do think concepts and designs have been made, I am not sure if there's a consumer product out yet.",
      "‚ÄúAMD does not support 64GB modules‚Äù. \n  \nAre these a thing for unbuffered DIMMs?   \n  \nIt‚Äôs not clear to me if they are improving some sort of training to improve speeds or if there is a new DIMM model being sold that they now ‚Äúsupport‚Äù.",
      "I thought the limitation was in the memory controller of the CPU, not in the MB?",
      "And Microsoft Teams",
      "No, not guaranteed. Even 6000mhz only has a very high chance that it will work.",
      "idk bout 192, but I could use 96 no problemo",
      "And Cities: Skylines II",
      "Is 6400 guaranteed now? Last I checked is still 6000.",
      "They are being released very soon",
      "Is just what you're looking at specifically, the common 6000CL30 kits have been 80-100 bucks for many months now, pretty static.",
      "Notice the CL48 latency in the CPU-Z screenshot though..   :(",
      "It's a setting in your BIOS my dude. Off by default.",
      "Memory prices have been rising with like 10-15% lately (anecdotal, just the kits I've been looking at), so hopefully higher capacity sticks will move the prices a bit again.",
      "And Minesweeper.",
      "Come to think of it the X670E master supports 256GB but I think the earlier versions was less than that ü§î",
      "Speaking of X870E, have any of you had any luck finding ASrock mobos in stock?",
      "I can‚Äôt even get my carbon WiFi to update bios, it doesn‚Äôt read the files. And also my usb ports no longer have power with my pc shut down, on the old Intel asus board i had my ports still had power so i could charge things. \n\nNot having a good time",
      "Anything about AMD's spec sheet is not guaranteed technically. Zen 4 was officially speced 5200 mt/s for example.\n\n\n¬†Zen 5 is 5600 mt/s¬†https://www.amd.com/en/products/processors/desktops/ryzen/9000-series/amd-ryzen-9-9950x.html"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6600"
    ],
    "title": "AMD Radeon RX 6600 XT and RX 6600 to launch on August 11th - VideoCardz.com",
    "selftext": "",
    "comments": [
      "I hope the rumors about $400 will be wrong. We need $250-$300 1080p good card for normal people. On the other hand, prices in stores will be very high anyway. Still the cheapest 6700xt cost over $1200 in my country...",
      "This is a 200usd graphics card tops. a good 480/580 upgrade... fuck those prices. 400usd was the 2nd best model back when prices actually made sense and titan price-boosting series did not exist!",
      "$500+  \nmarket still fudged",
      ">The singe-fan reference model pictured below is said to be used only for marketing purposes, as AMD is allegedly going to launch this card exclusively through its board partners.\n\nTranslation: The 6600 and 6600 XT will have a higher MSRP than the 6700 XT",
      "3060 is technically 330$, but good luck with that.",
      "when on earth has there ever been a point in gpu history where people just went \"the old stuff is plenty\" and then just exit the market",
      "I like how everyone these days just pretends like 1080p gaming and the $200-$300 market doesn't exist. And then also complain about runaway pricing. Great going, guys.",
      "It's a little wrong considering back in 2015 a R9 290 could be had for ¬£300 new and that is still fine for 1080p gaming even today, by now 1080p gaming should be possible on a ¬£100 card, my HD 7850 was a perfect 1080p card back in 2012 and it cost all of ¬£180...\n\nWhat got me into PC gaming was I wanted a Desktop anyway and all it cost was an extra ¬£180 for the GPU + ¬£20 extra for an upgraded PSU, if I was buying today it wouldn't be a gaming PC because of the ¬£600+ cards.",
      "Exactly that is the point. Prices are stupid high nowadays. 1080p gaming few years back was easy for 200 bucks. Technology has advanced. 200 should bring 1440p on the table today.",
      "You must be rich then bro \nAt this point $200-$300 should be a 1440p gpu",
      "Ah yes, the magical $399 \"entry level\" gpu...\n\nJokes aside, this entire generation AMDs been increasing prices to the next segment, for the same price you could've paid 2 years ago you're getting the same performance, just on a lower SKU, reminds me of nvidia's 2000 series, which everyone hated for that exact reason (The 2080 having the same performance as the 1080ti at the same price).",
      "This is by far the worst part about this, if it's true.\n\nIt's bad enough that AMD will likely have MSRPs that are barely undercutting Nvidia. And without reference models, there's no chance they'll be anywhere close to MSRP. AIB 6600s will likely be more or equally as expensive as the reference 6700 XT. \n\nThe mainstream market segment may as well not exist this generation. Anyone looking for a $200-300 GPU should just wait for the next generation.",
      "The 6700 xt is meant to be $479 so I wouldn't be surprised if they market these at $399 and $349. \n\nI would bet the 6600xt is around the same mark as the 5700xt too so if they do market around those msrp's it will mean no improvement in value.",
      "Not like it matters what the MSRP is.",
      "*They're. You can remember it as being a shorter contraction of 'they are'.",
      "If the 6600 XT is better value than the 3060 *at all*, I‚Äôll have to recommend it, but I won‚Äôt call it good unless it beats/matches the 3060 for $299. That‚Äôs the kind of value we deserve.",
      "Yup. Only hope of any of these making it to the market at under $500 would be if AMD launched a reference version. AIB partners will straight up scalp it. When the shortage rolls over, try to remember the worst companies.",
      "The price is 100% correlated with how well it mines.  That's why 5700XT's cost more on ebay than 6700XT's.  As far as \"MSRP\" goes, it really doesn't even matter.  No one's gonna see that.",
      "I have been eagerly awaiting for the 6600XT (as I am after a sub-450$ card for a secondary PC), but the more I read about it, the more it sounds to be a tough sell. With its 128-bit bus and 32mb of Infinity Cache (versus 96mb on the 6700XT) seems like this card is crafted for 1080p and hardly any resolution above it. I hope to be wrong, though.  \n\n\nI would have preferred a 6700 non-XT, but apparently that card is not happening, as all Navi 22 chips are going to mobile versions, as well as the 6700XT.",
      "This may be a comeback chance for affordable pricing in the entry level gpu segment."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6600"
    ],
    "title": "Radeon RX 6600 Linux Performance Rising Even Higher With Newest Open-Source Driver",
    "selftext": "",
    "comments": [
      "Michael does run Linux-vs-Windows comparisons periodically. They used to be of limited value because games would typically use older OpenGL backends on Linux and newer, highly tuned DX backends on Windows, but with the arrival of Vulkan the ability to make useful comparisons has improved quite a bit.\n\nIn the meantime the \"Geometric Mean\" comparisons between graphics cards at the end give a pretty decent picture of relative performance despite the game set being different.",
      "You've just described the entire GPU market. By comparison, it's a good card for the price, if for no other reason than you can maybe find it for less than $500 and it isn't 8 years old.",
      "~~Poorly Optimised Launch Drivers~~\n\n**Finewine‚Ñ¢**",
      "Even if the games did use older backends I'd say there is still value in comparing the two as an overall platform.\n\nIf you just want to know which platform a game runs best on, or what compromises you will need to deal with for your OS choice then it's still useful information.",
      "I'll have a fresh windows vs. linux comparison sometime soon... Only have so much time in a day for all the articles, benchmark development, etc :/",
      "For linux users, since nvidia drivers are closed source and do not always work well, amd cards tend to be a good choice",
      "I just WISH that we can actually buy one at MSRP but Noooo.",
      "[deleted to prove Steve Huffman wrong] -- mass edited with https://redact.dev/",
      "Yes it has awful MSRP/performance but its street price/performance isn‚Äôt as bad as much of the rest of the market.",
      ">Even if the games did use older backends I'd say there is still value in comparing the two as an overall platform.\n\nAgreed, my post was too short. What I should have said was that they were of limited value in terms of comparing the OS/driver ecosystem between Linux and Windows, but still useful in terms of understanding what a typical user is going to see.",
      "It's hilarious/horrifying that a 6900 XT at 1500‚Ç¨ is better value than the 6800 XT which for some reason is also 1400-1500‚Ç¨",
      "Bought mine 6600 XT at MSRP when they first launched and no one seemed interested. \n\nThen the miners found out they'd do 32Mh/s for Ethereum at 60W and suddenly they were all gone.",
      "AMD's software engineers must truly be third rate compared to their main competitors.",
      "[Always has been](https://i.imgur.com/CdG9Lvs.png)\n\n^^^this ^^^has ^^^been ^^^an ^^^accessibility ^^^service ^^^from ^^^your ^^^friendly ^^^neighborhood ^^^bot",
      "Yeah but 3070 is also shit for the price/performance ratio right now",
      "Always has been",
      "Ok yeah, agreed.",
      "FlightlessMango in YT. Also made a great HUD for stats like FPS/FT and sensor values",
      "Totally. I'm sure it will be closer and closer especially for native titles.",
      "I play X4 (Vulkan native) on Linux (Steam) which is faster overall. Not only on just GPU but also CPU. On windows the game hovers around 6-8 cores and the perf issues are noticeable when the playthrough matures with thousands of ships etc. \n\nOn Linux, same system, can clearly see the 3900X been used to 90%+ all 12 cores  and there are people with 5950X saying all 16 cores are been used. Ofc the game runs much better."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6600"
    ],
    "title": "Will FSR be better on the future? Should I get a Rx 6600 instead of RTX 2060?",
    "selftext": "Where I live, Rx 6600 and RTX 2060 are in the same price, even though 6600 is much powerful. But when you count NVIDIA's dlss, the gap closes. And FSR is in really rough shape right now. Even on ultra quality, ƒ± can see the blur. But when it launched, dlss wasn't in much a better place either. So do you think FSR will be better in the future, close the gap to dlss? \n\nShould I get a Rx 6600 instead of RTX 2060?",
    "comments": [
      "People do know FSR is not specific to AMD and runs on Nvidia also ?",
      "This is just my general opinion buy stuff based on what is there not what you think may happen. Even when companies promise stuff, they can disappoint. Just my opinion the 6600 is a lot more powerful, which in a lot of cases I think makes more sense. Dlss 2.0 is pretty great but who knows how many games will implement it long term. Personally I got a 3000 nvidia card with that being one of the reasons like a year ago, but it is important to have expectations for vendor locked features like dlss that needs to be implement on a per game base atm.\n\nPersonally I would take the 6600 vs 260p. If we where comparing to 3000 series maybe the discussion can be different cause the gap is not the same, plus you get newer ray tracing cores.",
      "6600 rasterization performance is significantly more than 2060 and has more VRAM. That's enough reason for me to go for that over the 2060 tbh. I don't care much about upscaling techniques especially DLSS as it's proprietary. Yes it's good but so is FSR and i prefer to play at native resolution. As for RT, ray-tracing performance isn't that relevant at this class of hardware, regardless both have similar ray-tracing performance anyways.\n\n6600 is the obvious option IMHO.",
      "Oh, people...",
      "why would Nvidia write an article about their own basic image scaler (NIS) if they wanted to hide anything to old owners ?\n\n[https://www.nvidia.com/en-us/geforce/news/nvidia-image-scaler-dlss-rtx-november-2021-updates/](https://www.nvidia.com/en-us/geforce/news/nvidia-image-scaler-dlss-rtx-november-2021-updates/)\n\nhaters are ridiculous lmao",
      "[https://youtu.be/EFY7\\_H6rvEw?t=330](https://youtu.be/EFY7_H6rvEw?t=330)\n\n&#x200B;\n\nIdk about you, but as viewed in this video, both are pretty fuckin similar, nvidia one works with all games and unfortunately affects the UI, FSR has a better sharpening filter and doesn't affect the UI\n\n&#x200B;\n\nBoth get destroyed whenever DLSS is in the picture, sure FSR is the second in the competition, but its closer to NIS than DLSS.",
      "6600",
      "Th XMX version of XeSS which will be more similar to DLSS will only be supported on Intel Arc cards . \n\nThe other cards will only run the lower quality DP4a version\n\nhttps://www.digitaltrends.com/computing/intel-xess-is-answer-to-nvidia-dlss-one-big-advantage/",
      "Why are you asking if you should buy an outdated, weaker GPU?",
      "FSR 1.0 will work in anything so I wouldn't really have that be a deciding factor. Consider DLSS as a selling point of the RTX card however, should that be of any merit to you.\n\nThe 6600 is likely the better buy at this point in time regardless, but the market is rapidly settling it seems and things might be more palatable very soon.",
      "Add to that that RSR is driver level... It's gonna be nice.",
      "Nvidia's own spatial scalar is not even close to being any good compared to FSR. DLSS may be better than any of them but FSR is definitely the second in the competition, with no one coming any close.",
      "I would appreciate the source on that.",
      "I have tried FSR on many games with my Gtx 1060, and I can definitely see the difference between native and FSR quality. I ended up choosing native because of its blurness.",
      "No we don't. They're a multinational corporation, not a family run corner store.",
      "XeSS has yet to be implemented and tested, and the 6600 will use the worse version of XeSS and it's pretty unclear if XeSS outside of Intel dGPUs will be any good. I don't expect miracles, generic solutions often come at a cost.\n\nBesides, even nvidia hardware (at least from Pascal) will support XeSS, so it's not an argument.",
      "The amount of time between DLSS' announcement and FSR1.0 being released has nothing at all to do with the progress or current state of FSR2.0. There is no logical reason to connect these very different moments in time. \n\nFSR2.0 *exists* now and is working well internally. The work of getting studios onboard with FSR (which took time) has already been done. \n\nFSR2.0 will come out this year. How it compares to other systems at the time is anybody's guess right now. However, given FSR2, DLSS2, and XeSS use similar techniques they should be more or less similar in results with minor pros/cons split between them.",
      "Don't buy with future expectations. Buy for what's good now. What would fit your needs better now?\n\nI never expected my rx 580 8gb to be worth double then the 1060 a year ago. When I bought the 580 it was basically the same price as the 1060.\n\nYou can try to assume AMD will update and future proof the 6600 longer then NVIDIA the 2060. You can see this currently when most AMD features work on the 580 while some nvidia features do not on the 1060.",
      "So there's been zero information on XeSS and you come swinging for not the fences, not the clouds, but for the crab nebula my guy.\n\nWhere and the actual hell do you get this information?",
      "You're the SAME dude that talked about it last time i think clamiing the same thing.\n\nSuch specifics like \"1.3x\"  and exaggerations like 1000% cleanup of ghosting and shit.  Hilarious dude, let me go ahead and chalk this up as a joke and some subtle AMD shilling because this would put them in the game without them having to spend a dollar."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6400"
    ],
    "title": "Just a FYI: AM5 integrated graphics should make the RX 6400 obsolete",
    "selftext": "The RX 6400 has:\n\n* 3.57 TFLOPs of single precision performance\n* 128GB/sec of memory bandwidth\n\nAM5 should have:\n\n* APUs at least as powerful as the Ryzen 9 6980HX, which has 3.686 TFLOPS of single precision performance.\n* 134.4GB/sec of memory bandwidth from dual DIMM DDR5-8400 RAM. Overclocked memory like DDR5-12600 (which has been announced) would give AM5 201.6GB/sec of memory bandwidth.\n\nThe RX 6400 should become obsolete when AM5 APUs launch. I would not be surprised if AMD ships AM5 APUs that make the RX 6500 XT obsolete at some point too.",
    "comments": [
      "Specs are fun, but it will depend. # of CUs sometimes play a role, sometimes not. \n\nMy 2nd self built PC had an onboard hd 4310? Chipset 780G for am3. Llano blew that out of the water easily.\n\nProgress! But old systems will usually need something cheap to replace dead cards, or newish ones to reuse existing.",
      "Except for that the 6980HX and its Radeon 680M GPU is a 12 CU APU Product, whereas \"Raphael\" seems to shape up to have a 4 CU Design, that in anything but the top end SKUs seems to be binned to 3 CUs for the vast majority of first wave Desktop APUs for AM5.  \n\nYes we heard rumors about \"Phoenix APUs\" being potentially 24 CU Parts, but nobody yet knows if those are meant for Desktop Sockets, when they will come, or what kind of Tradeoff will be made on their CPU side to make enough spacial and thermal \"room\" to fit them there.",
      "Yep, gonna be interesting in three years.",
      "It's worth pointing out that the RX 6400 is out now while the AM5 APUs are still at least half a year or longer away.\n\nI don't see what's so mind blowing about a future APU outperforming an existing low end card.",
      "There are both Raphael and Phoenix. Raphael is the Zen 4 with just some not-too-fast iGPU, kinda Intel UHD.",
      "All APUs we got on AM4 were repurposed Laptop Chips, in which offering \"powerful graphics\" makes sense for single chip thin & light / cheap designs that are space and power constrained, that were put in Packages that allowed them to run on Desktop Boards, but they all were monolithic designs that sacrificed CPU Performance by taking some space from the CPU portion to fit the GPU parts in.  \n\nFrom what we know so far, the reason \"all AM5 CPUs will be APUs\" is because AMD tries to streamline their lineup, by getting rid of monolithic designs, and making the iGPU part of the IO Die, to still be able to offer multi chiplet chips without wasted duplicated resources.  \n\nthose IO Die iGPUs will not necessarily always be on the same process as the CPU chiplets. AMD is trying to get to the \"good enough for basic tasks\" APUs intel has basically had since 2nd Gen Core.  \n\nYes, they might still do \"more powerful\" APUs, but you can only make integrated graphics so good until you run into space, power and cooling issues, because whatever iGPU you decide on still shares the same contact surface and cooler on top other stuff that fits into the socket does.",
      "The rumours out there, for example this one from a leaker that has atleast in the past been reasonably accurate (Komachi) points to a 4CU 0.5Tflop iGPU for Raphael (Zen 4). https://videocardz.com/newz/amd-ryzen-7000-raphael-rdna2-igpu-could-offer-a-third-of-steam-decks-graphics-performance\n\nSome APU's probably will have more CU's, if we get designed for mobile APU's to desktop again (like the Cezanne based 5x00G we have now) as we  but at least, but i wouldn't expect the full AM5 lineup to have powerful gpu's for now. There seems to be a good chance that the desktop parts get a Intel like iGPU, and not something more powerful as for example Rembrandt has in mobile (Ryzen 6000).",
      "Even if that rumour will end up being true IIRC those iGPUs are supposed to be very weak and even then that won't suddenly add iGPUs to all of the AM4 CPUs and other CPUs lacking iGPUs.",
      "Construction Wise, with how Chip and Memory are layed out on the PCB, and how much space and attachment points they have for putting a cooling solution onto it, it much more resembles a GPU that happens to contain CPU cores too than the other way round.  \n\nThe size you have to work with to fit everything is the CPU socket, the heat transfer is not direct Die cooling but is an IHS, and the amount of power you can push through it is determined by how the motherboard VRM is layed out, all this restricts an APU on a PC motherboard far more than the chip of a console.",
      "Presumably, there will be more CUs in future APUs than the 6400 has.",
      "and yet the rx 6500 xt is born as a companion of ryzen 6xxxu/h for cheap(ish) thin& light with discrete gpu",
      "You can only plug so many things into a motherboard. Do you think they're going to start making motherboards with like 8 display outputs?",
      "I wouldn't be so sure. There are still plenty of CPUs on the market without iGPUs which will require \"display adapter\" level graphics card for people who don't game and I don't see Intel's iGPUs making a similar leap at this time.",
      "Something this subreddit never seems to remember is that all the Ryzen generation APUs support displayport multi signal transport, ie multiplexing. You can plug a DP-MST splitter into any of the motherboard outputs and split one port into 3 to 4 independent outputs.  I've been using one for years now.\n\nExample:  https://www.arrow.com/en/products/b156-004-v2/tripp-lite",
      "The PS5 is cooled with liquid metal, a big chunk of solid metal and a fairly large fan though.",
      "There are a few form factors where that's actually a good idea, but that's not true for most.",
      "The market segment that the card occupies is \"inexpensively upgrade Small Form Factor \"Office\" Desktop PCs that only have low profile expansion slots and come with PSUs that provide 0 PCIe Cables, so limits upgrade choices to sub 75 Watts Cards that can be entirely powered via the PCIe Slot itself.\n\nAnd considering you currently find mostly intel 3rd and 4th gen Core Series Chips in Machines that fit that bill being turned into \"cheap entry level gaming PCs\" with cards like that, there will be VERY much time until iGPUs advance enough in these types of system until they make this type of card obsolete.",
      "I've only seen one mostly baseless rumor of a >6 CU desktop AM5 APU, and even that at 20-24 CUs would only put it around a 6500XT with good RAM. If we do get stronger APUs for Zen 4, I can't imagine them coming out in the first run",
      "No, we don't want to pay for a $5000 CPU just to get 64GB ram...",
      "6000 mobile series doesn't just support ddr5 but it's only ddr5"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6500xt"
    ],
    "title": "AMD Radeon RX 6500XT with 6nm Navi 24 GPU to feature 2815 MHz boost clock",
    "selftext": "",
    "comments": [
      "Well, at least that's confirmation that it shouldn't be slower than a 5500 XT. Looking forward to reviews.",
      "This GPU is a joke.  \nNo AVI1 decode, zero hardware encoder (the only media capability is decode for h264 , h265 and vp9 )  \nOnly Pciex 8x, only 4Gb with 64 bits (only 2 memory chips).",
      "the only thing clear from this is it's not gonna cheaper than 5500XT. imagine >$250 MSRP for a 4GB new gpu in 2022...",
      "Wasn't it AMD who proclaimed that \"4GB GPU VRAM ‚ÄòNot Enough‚Äô for Today‚Äôs Games\", and just look at them now, hilarious.",
      "I'm more interested, how bold AMD will be with MSRP. My bet is $249 which should translate into around $400 in actual retail",
      "> No AVI1 decode, zero hardware encoder (the only media capability is decode for h264 , h265 and vp9 )\n\nHas feature parity with my budget phone lol.",
      "> Is the 6500XT supposed to be similar in performance to the 5600XT?\n\nNo. It should be somewhat faster than a 5500 XT, but nowhere near a 5600 XT.",
      "What has been driving the scalper prices is every card's effectiveness in mining. Since this card will only have 4GB (not enough for good mining) it will help keep the card price more realistic for gamers. For example, see the scalper prices for rx 580 8GB vs rx 580 4GB.",
      "In terms of traditional rasterisation performance ,this will be a downgrade from your GPU since this will probably be somewhere between an RX 5500xt and RX 5600xt while your card is already faster than a 5600xt (even upgrading to an RX 6600 from your card would be a side-grade)",
      "It is not just about some specific card's effectiveness in mining. It is about the whole market- if miners can pay 2x price for cards (choosing the ones that are best for them first)- then the gamers are left with depleted market, and prices go up for the rest of the cards too.",
      "and I'm very realistic about AMD's greed. Just look at Zen 3 pricing, Or lower 6600 -/XT pricing.",
      "The only thing that would really irk me is if there's no encoding support at all. Still, most consumers have very little interest in encoding.\n\nFor the rest, AV1 seems like a rather dead standard, PCIe x8 shouldn't be too much of an issue, and 4GB is great if it makes the card less attractive to miners.\n\nSure, in a normal market that would have indeed not even be worth a desktop release, being relegated to entry level laptops, but beggars can't be choosers, and if the market price of this is good enough, I'm sure there will be takers.",
      "Imagine how bad we got that it's **optimistic** to think entry-level GPUs will cost 199$ ...\n\nThese guys are selling us almost \"nothing\" for 200-300$ nowadays...",
      "I miss the days when you could buy a 60 quid cpu and a 120 quid gpu and be on par with consoles.",
      "2815mhz boost clock is nice, as long as we do not see too much price \"boost\" I would assume üôÑ",
      "First paper launch in 2022 comming soon..\n\nRDNA2 and Ampere are \"lost\" generations.",
      "You are way to optimistic in my opinion. Given the 6600 MSRP i fully expect this card to be 249$.",
      "If AV1 is dead, what do you see as being the future? Are we just going to be stuck on H.264 forever? H.265 is dead because of the HEVC Advance guys, Google has moved all development of VP9 to AV1 as its replacement, and nobody trusts the MPEG process anymore so nothing is likely to come out of there.\n\nI think AV1 is still the the coming thing, it is just that the pandemic has delayed things a bit.",
      "man the fucking 1650 super is only 4gb vram, and it gets scalped everywhere. fucking thing is sell for over 450 usd. dunno why people pay that much for that card, that is not even for mining. is the scarcity and demand that makes high prices.",
      "Btw, you can claim the tomb raider trilogy for free on Epic Games (till January 6)"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6600"
    ],
    "title": "RX580 upgrading to RX 6600 challenger D",
    "selftext": "I have an R5 5600G, RX580, and 16gb of ram. I play a game called, ‚Äúcounter strike‚Äù which is a hard game to run and my rx 580 is starting to lose its performance. So I found the 6600 and was wondering how good it would perform and if it‚Äôs a good gpu for my system. I get around 146-170 fps on my current graphics card so what would be the estimate of fps I would get on the 6600",
    "comments": [
      "I need a new gpu because it will drop below my refresh rate and cause stutters and I need something that will stay above my refresh rate",
      "6600xt  is best value compared ,, to 6600 and 6650 xt. Go for 6600 xt if u can",
      "\"starting to lose its performance\"\n\n\"170 fps\"\n\nwtf kind of monitor do you have on an old ass card for this to not be good enough?\n\nbesides, counter strike is generally CPU bound anyways.",
      "it purely depends on area. new in my area rx 6600 is 250-300 but the xt is 500+ and only through amazon. used the 6600 is 200 and the xt being 200-250. so location is a big factor.",
      "165 hz Koorui 24E3",
      "I agree,, m just goin off their msrp price..it launched for 329 vs 379 for xt. For 8gb cards, i would not buy new.. since they are bout to be faced out soon like the 6gb ones\n\nI would also go for 6600xt for 250 other than 6600 for 200 (same $50 difference). Its 20% faster with only 30watts more.",
      "I see. Understandable have a nice day. Usually people with a 580 are 1080p and not super high refresh rate so yea def time for an upgrade",
      "For sure, I‚Äôm hoping that I can get pretty stable 200 frames with the 6600 because I don‚Äôt want to waste 200 dollars on a gpu to get similar performance to the rx 580",
      "Ok, I‚Äôll look into that. Thank you for the suggestion"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6400"
    ],
    "title": "ASRock launches Radeon RX 6400 Low Profile GPU - VideoCardz.com",
    "selftext": "",
    "comments": [
      "Got an RX6400 for a server as AMD is easier with fully open source Linux. Absolutely trash for almost anything but HTPC or server video output. The PCIe interface really hobbles it.\n\nEdit: It does what it is made for really well. Cheap video output in low profile systems.",
      "Arc A380 is better for HTPC because of encode support and AV1 decode/encode cost about the same to biggest con is power consumption and it's a 2 slot card.",
      "That's where the A310 comes in",
      "No AV1 encode/decode really hurts this card. I wish AMD would come out with a better half height card. The Sparkle A310 ECO is the better buy for people looking for a discreet HTPC setup.",
      ">Absolutely trash for almost anything but HTPC or server video output.   \n\n\nWere you expecting much more from such a card?",
      "the video outputs are also cripped on the RX 6400/6500XT, AMD segments the UHBR20 to the workstation versions of the cards.\n\n(yes, there is a W6400, crazy but true, that's how much of an \"only intended for laptops\" chip it is! and as it turns out, there is nothing wrong with putting an encoder on a laptop dGPU either, intel does it too!)",
      "Nope, it does exactly what I wanted it to do for ¬£60. :) I cannot complain at that price point.",
      "Seems like the pace of GPU improvements has really slowed.  \n\nI have an ancient GTX 1050 in my HTPC, and am trying to find an excuse to upgrade it, but can't really find one.   I think I bought the card in 2016 or 2017, and yet it still seems to be comparable to low end power efficient cards in '24.\n\nBack in the day using an 8 year old card would be unfathomable.",
      "An rx6400 is actually one of the few decent low power (& low profile) GPUs out there. There's definitely a void in that segment of the market. It wasn't that long ago that the rx570/580 cards were popular, this rx6400 performs similarly to those cards.\n\nIt's not the card you'd pick up for mid or top tier gaming, but it's not marketed for that. This is one of the few choices for people with OEM or slim PCs that don't have available PCIe power connectors.",
      "More low-profile, single-slot, PCIe-powered GPUs are always welcome.",
      "Seems late to the party. I bought a Sapphire one almost exactly 2 years ago.\n\nI hope that AMD introduces at some point a better low end low power GPU.",
      "Don't need to just say 6500xt. All the cards up to 7900xtx don't use uhbr20.  The latter uses uhbr13.5",
      "I have detected a link to UserBenchmark ‚Äî UserBenchmark is a terrible source for benchmarks and comparing hardware, as the weighting system they use is not indicative of real world performance. For more information, [see here](https://www.reddit.com/r/AMD/wiki/userbenchmark) - This comment has not been removed, this is just a notice.\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/Amd) if you have any questions or concerns.*",
      "The ceiling has been raised, but the floor has remained stagnant. From 2016 to 2023 we had the RX 480, RX 5500XT and RX 6500XT all performing similarly for the same $200 price.",
      "Given that they never released a low-end low-power RDNA 3 GPU, and they're supposedly only going to target the mid-range & low-end for RX 8000 series, we may ideally get it in 2025 or 2026.",
      "Sorry, I've been very confused this whole time and meant RX6300... DOH!",
      "How does this compare to an RX 550?",
      "Frame gen support saves this card really. Most games prefer some FSR.\n\nStill, the best low profile option for sensible money.\n\nPlz rx 6600 low profile anyone??",
      "True, especially when paired with an old office PC.",
      "~~Well its around similar performance to an RX 580, or a GTX 1060.~~"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6600"
    ],
    "title": "RX 6600 fan curve suggestions.",
    "selftext": "is this a good fan curve for this card? I don't have a lot of experince with gpu fan curve tuning so asking for some suggestions & yeah I keep zero rpm feature turned off all the time.",
    "comments": [
      "Looks good, actually you need to tinker it yourself. Boot a game then test whats the quietest curve you can get without the card heating too much",
      "Why the hell are you going this high? Set it to max 50% and forget it. My 6800xt draws twice as much power as yours and tops at 48%",
      "I I personally prioritize my stuff running cool so I set the final slider to 90¬∞ and 100% and the fourth slider to 75¬∞ and whatever percentage you need to maintain that temperature under full load I think mine‚Äòs at like 50% on my 7800xt the rest from there I slowly have it ramp up only being at like 10% at idle I personally don‚Äôt like running zero fan\n\nI just don‚Äôt like seeing my GPU at anything higher then 80¬∞ it starts to thermal throttle but at the same time I don‚Äôt need it running at 100% at 80 that‚Äôs ridiculous",
      "thanks! I will try.",
      "My 4070 super maxes out at 40% above 90 and is mostly forced to stay at 30 (minimum). \n\nI‚Äôm with you, lower it all the way",
      "alright I will try that too."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6600"
    ],
    "title": "Are these ~$300 6600 xt prices the new norm or is this something that I should jump on now?",
    "selftext": "I won‚Äôt need one for at least a month but I always want to take advantage of the prices. Are miners going to buy these out or is it likely safe to hold off a couple weeks?\n\nEdit: can anyone tell me whether the 6600 CT‚Äôs performance is actually $300 good? I‚Äôve never had a gaming Pc. My monitor is 144hz and it seems like I may max out playing on med-high?",
    "comments": [
      "With the crypto market essentially in free fall right now, you won‚Äôt have to worry about miners for the time being.",
      "More like for the upcoming 2 years.. \n\nThen another crypto boom could happen",
      "Futureproof? You'll be buying a 7800XT in November like the rest of us.",
      "In Europe they are all over 400‚Ç¨.",
      "8 years ago, a, AMD x600 / Nvidia x60 series card would run you $150-250. Let's hope we can get even closer to that.",
      "Exactly, look at Bitcoin‚Äôs historical price: peaking in late 2017/early 2018 and immediately cratering in April that year. It spent 2 years below its 2018 peak before eventually recovering in late 2020 and growing for the next year. It‚Äôs been dropping again since November, but crypto is the poster child for volatility - there‚Äôs no way of knowing if/when it‚Äôll start gradually recovering or if it‚Äôll explosively regain its value like it did in 2020.",
      "No, not forever lol.  It's taking a dive as of late but it's not going anywhere.  The stock market has crashed and sucked a lot over the years as well.  Markets like this need to find their bottom and bear markets can suck, but they don't last forever.",
      "Not with currency inflation being what it is. Your dollar is now worth like 70-80% of what it was worth 8 years ago thanks to the crazy inflation over the last two years. $250 in 2014 money likely = $330 in today's money. So you still can get a x600 series today for $330, or $250 in 2014's currency. \n\nThere is inflation calculators out there that use 2% per year, but it's been closer to 5-10% for the last two years.",
      "Ah yes, cratering and mooning is exactly what you want in a stable currency‚Ä¶ right? Right‚Ä¶?\n\nHilarious, this shit will never become a legit currency.",
      "Oh awesome. Maybe I should hold off and 6700‚Äôs might come down in price with the decrease in demand?",
      "Not sure how much prices will go down, so that‚Äôs a game you choose to play. The demand may be lower but that may only mean items stay in stock a while longer. There is still a chip shortage going on into late 2023 I think is the last I heard. Depending on recessions, inflation, lockdowns, etc., demand may spike again as people look for entertainment at home. Not trying to scare you, but there are many variables that could change the demand overnight. With your short timeframe though, it may be ok to wait.",
      "The dollar and euro have been quite stable.\n\nUnlike cryptocurrency ü§≠",
      "rx 6600 for $300, rx 6600 xt for $360, and rx 6650 xt for $380 are the normal now, pretty much mining has died down for a while now",
      "> I *paid* 700 for\n\nFTFY.\n\nAlthough *payed* exists (the reason why autocorrection didn't help you), it is only correct in:\n\n * Nautical context, when it means to paint a surface, or to cover with something like tar or resin in order to make it waterproof or corrosion-resistant. *The deck is yet to be payed.*\n\n * *Payed out* when letting strings, cables or ropes out, by slacking them. *The rope is payed out! You can pull now.*\n\nUnfortunately, I was unable to find nautical or rope-related words in your comment.\n\n*Beep, boop, I'm a bot*",
      "Except this low could be tomorrow's high.",
      "Some of the 6600XT, from Sapphire and Gigabyte fell about 50‚Ç¨ last month. We see price movements, but as long people buy 5700XT cards used for 400‚Ç¨, nothing will happen there much. When the used market drops, the prime market will drop with them. But it might take another month.",
      "Lol when crypto devalues at 50% a year you aren't winning.\n\nInflation, until 2022, was about 2% a year or less.",
      "> ,for the time being the cards are below MSRP and well priced ,surprisingly\n\nThese \"MSRPs\" are well above what they'd be in a normal market, in a normal market the 6600 would probably have *around* a $200-220 msrp while the 6600 XT would be around $250-280, I would expect prices to continue to fall as they've been doing since earlier this year, Although inflation might help keep the prices up.\n\nhttps://pcpartpicker.com/trends/price/video-card/\n\nhttps://i.imgur.com/N9MTdDL.png",
      "The 6600 XT is good at $300, but it‚Äôs never even remotely deserved to be $379. I‚Äôd say get it.",
      "Depends what happens with crypto once Eth merges fully. I think they will stay down for a couple of years though, then we will likely see another shortage.\n\nDon‚Äôt be surprised if new cards try to keep the high prices and blame economy though."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "rx6600"
    ],
    "title": "Is there any game I can play at a decent framerate with Ray Tracing in my RX6600 (I know it has the weakest ray tracing hardware)?",
    "selftext": "So far I've managed to enable ray traced shadows in Shadow of Tomb Raider, but in any other game I've enabled it, the performance drops to unplayable.\n\nAlso, my eyes can barely tell the difference when enabled in Tomb Raider. So I will also appreciate to know if there's any game I can enable ray tracing in my RX6600 that doesn't feel like a gimmick.\n\nWhat about ray tracing in Mario 64 port? Is it possible in AMD?",
    "comments": [
      "Doom Eternal?",
      "Surprised nobody else mentioned this. Doom Eternal runs extremely well with RT on. Control at 1080p with some lower settings, maybe. Metro Exdous should be a decent one as well. Cyberpunk will struggle",
      "Deathloop using FSR 2.0 maybe? The thing is that any game which has good RT effects that make a clear difference also makes use of DLSS to remain very playable with nvidia hardware; To have a chance at a similar experience, you'd need adoption of FSR 2.0 to pick up the pace and even then the performance impact is going to be more severe.\n\nI guess you could try Metro Exodus Enhanced Edition too, but I'm not sure how playable it is without DLSS.",
      "I'm an early RTX adopter.\n\nCurrently I have a 3060ti - I disable RTX in all games.\n\nI prefer higher frame-rates and most of the times, RT doesn't really stand out,",
      "At 1080p I get above 40 FPS in Metro Exodus, Control and Battlefield 5 with a 6600 XT on high to max settings. You should be able to at least test it out on those titles. At higher resolution you would certainly need FSR to get anything playable. Ray tracing hits cards from both vendors heavily. AMD more so than Nvidia currently. I was able to turn it on for long enough to realise it doesn't add nearly enough value to take the performance hit. Next gen cards will hopefully be far superior in performance from both red and green but I'm not personally sold on it just yet. Also, it depends if you consider 40 FPS a decent frame rate. üòÅ",
      "It is because it‚Äôs path traced, no traditional rendering.",
      "Ever since I tried raytraced things stuff like crappy screenspaced reflections sticks out like a sore thumb\n\nRt reflections are underrated. Honestly rt shadows or rt illumination is nice but rt reflections just make everything look right.",
      "I'm pretty sure that rx 6400 is the weakest ray tracing hardware.",
      "An RDNA2 APU, perhaps.",
      "\"RT doesn't stand out\" \n\nYou probably haven't tried metro Exodus enhanced, Dying Light 2, Cyberpunk, Control, ghostwire, Wolfenstein...",
      "Forza doesn't do Ray-tracing in game. It's only in the showroom, which makes it completely pointless.",
      "It is metro exodus low 540p-720p can run on steam deck at 30fps where 6500xt no matter what settings or resolution u gonna put it it's gonna be 15-20fps at most. Digital foundry tested it.",
      "I have a 3090 and although I like RT, it‚Äôs not a game changer for me yet",
      "Minecraft bedrock. Runs better than I thought",
      "Always nice to see a game apparently 'coded well' like Doom Eternal that runs well on older hardware!",
      "Even DLSS looks bad upscaling from under 1080p, disabling RT is a better compromise",
      "Imagine dropping below 90 fps for glossy blood puddles lol.",
      "How about you forget about ray tracing and just play games at 1080p. \n\nCard will never let you down there",
      "Quake II RTX..?",
      "You need to accept the possibility of locked 30 or 40 fps gameplay, using FSR or resolution scaling to play at under 1080p. Also possible lower presets of RT or generally lower presets for the game (Medium or High instead of Very High / Ultra)\n\nDefinetely do-able. Depends on the game of course.\n\n\nThe reflections in Hellblade look amazing. Metro Exodus Enhanced Edition and Control are transformative as well.\n\nResident Evil 7/8/RE2R/RE3R using FSR and maybe interlacing should give a 60 fps experience, depends on you what resolution / clarity you would accept.\n\nModern Warfare 2019 and Cold War have good optimization and RT shadows.\n\nAlso Godfall I think.\n\nThe Crysis Remastered trilogy has RT implemented. Nothing too amazing, but it looked nice. Your 6600 is slower than my 5700 XT and I played Crysis 1 Remastered with RT on Medium + Boost, at 900p (TAA is extremely clean), 40 fps, at High Settings (with LOD, Shadows and Vegetation on Medium)\n\nGuardians of the Galaxy might work.\n\nCyberpunk 2077 also is transformative, but might be entirely too heavy, even at 30 fps and reduced settings and resolution.\n\nThere are also a few other games that aren't AAA, with RT, you may try (Ghost Runner, Observer System Redux, Bright Memory, there was one Soulslike game I'm forgetting)."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6600"
    ],
    "title": "Mid-Range is Dead: AMD RX 6600 XT Review & Benchmarks (PowerColor Fighter)",
    "selftext": "",
    "comments": [
      "Holy shit what a disaster of a card in both performance and value.\n\n2 whole years later and you get a card that performs the same as a 5700xt except it has weak raytracing and costs 20$ less than the 5700XT's launch price. \n\nThe card also gets downright humiliated by the 3060ti which costs just 20$ more msrp to msrp.\n\nThis is the definition of a fuck it anything will sell these days card.",
      "When I first heard of the 6600 series I thought it would be a great stopgap gpu. Buy a good rig with a decent cpu and use this until next gen comes out... Well atleast I got a good laugh out of the reviews. Amds any% ruin the budget market is of to a great start.",
      "AMD is getting greedy boys, it's over, pack up.",
      "The 5700xt is in it for the long run boys. üò≠",
      "I know I'm repeating myself, but I really should've bought the 5700XT when I had the chance to.\n\nBut no. \"Hold off the purchase\", my mind said then. \"RDNA 2 will be amazing\", it said.",
      "Intel, save us, but unironically, huehuehuehue.",
      "The performance is meh and the price is absurd. \nBut with our current GPU market, this will be sold out.",
      "I disagree. Not everyone watches every single GN video. I'm willing to bet most casual people on the market have no idea what's going on, hear about a \"mid range\" card like the 6600x, and Google around for some reviews. GN has to appeal to those casuals who are coming in blind.",
      "miner's and the silicon shortage have already done that, they could have listed this card at an msrp of $199 and gamers still wouldn't have them and they would be scalped on ebay for $5-600",
      "I cant believe it has really come to this. Where my hopes for a decently priced 1080p card now lie with Intel.",
      "Yup, since RX480 I've been runnig AMD gpus for their great value, but the last generations are getting worst every time pumping those prices Nvida style.\n\nBudgets went from $150-$200 up to $350-$500, f-ing stupid.",
      "amd is still increasing profits from the shortage. they're not just selling these things high because costs are up, they're moving into nvidia profit territory. they may actually pass intel's gross profit soon since intel's chips are so far behind and they're dumping money to expand and compete with TSMC.\n\ncould blame miners for destroying the original MSRP last year, but AMD is 100% pumping you for more profit this year. weird seeing people trying to justify \"supply and demand\" for the stupid prices when that was intel's whole BS argument back when nobody wanted AMD chips and it was god awful for the market. just because they're selling out doesn't mean people should be fine with a price hike, especially when AMD and nvidia were playing games with prices even before the shortage and already hiked prices up a tier.\n\nbetter pray to god that there's a market crash or else this is just going to be the new standard pricing.",
      "Yes but Bitcoin value overall affects other cryptos that can be mined",
      "$5 + $500 shipping?",
      "Also:\n\n* 3060TI and 3060 have DLSS - if even some games you want to play  have support but no FSR support then that is a definite benefit (since you can still use FSR on the nvidia cards for other games).\n* Better RTX - depends if you care (personally don't give a shit about RTX and on the 60 cards you might end up with questionable FPS)\n* 3060 has 12G ram (hard to say if that will be a real benefit down the line)\n* 6600XT being a x8 card (see Hardware unavailable review doom results near end) can bite you in the ass if you are on a PCI-E 3 Mobo even now in some games, let alone in a few years... and people who try to get \"cheap\" (AMD probably wont go much cheaper this generation) GPU probably want them to last a few years...\n* encoding and other features - depends if you care\n\nEven at MSRP this card seems like a very poor offering (even vs other AMD cards not just vs Nvidia competition)",
      "I mean, the video has labeled time codes for a reason. If all you care about is the benchmark results you can easily skip the intro and get straight into the numbers.",
      "they cut the infinity cache too",
      "I bought mine last summer 2020 brand new on Amazon for $350 (after $25 rebate). I got lucky",
      "Even if you're not a casual, you have to start somewhere right? Most of GN's videos tell the whole story of a product without the need of prior knowledge and honestly is what draws me to their channel",
      "Damn. The worst years ever for videocards in many ways, with the bitcoin/covid shortages turning the prices to insane gouge levels too."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6600xt",
      "6600"
    ],
    "title": "I think it's weird how the 6600 XT was marketed for 1080p only",
    "selftext": "I really don't get why AMD (and everyone else) said this card isn't for 1440p. Just look at the marketing for it. They pretty much never mention 1440p, ever. People will tell you that the 6600 XT is mediocre at QWHD, they never\n\nI'm gonna go out and say that i'm satisfied with my 6600XT and I play at 1440p. It's run every thing i've thrown at it well at high settings, Insurgency Sandstorm, Battlefield 2042 (I only played it just so I could benchmark it at 1440p, that game sucks), Forza Horizon 5, CoD, etc. I've seen benchmarks of it at 1440p from other people and it did fine. Now the obvious exception is Cyberpunk but that game doesn't run very good on anything, and i'm fine with lowering to medium (which I think gives the 6600XT around 65FPS from what I saw from RandomGamingInHD's video on the card) and I don't really understand how it's lackluster for 1440p when it can run most stuff just fine even at high.\n\nSome people argue that the 3060 TI is superior in every single way and I do agree. The problem is, that it's just much harder to find one. Didn't find no 3060 TIs at my Microcenter but I found two 6600 XTs for just $540. Looking at eBay I find 3060 TIs at like 850 but i've regularly seen 6600 XT deals on r/buildapcsales.\n\nAlso the 6800 (non-XT) is marketed as a 4K card but it performs about the same at 4K as a 6600 XT would at 1440p which is really confusing as to why AMD says you should just stick to 1080p. If the 6800 is a 4K card then the 6600 XT is a 1440p card IMO.\n\nTLDR: I have a 1440p monitor, and i'm satisfied with my 6600 XT, and I think it gets too much hate.\n\nEdit: Lot of people tell me \"the 6700 XT is the 1440p card. Not 6600 XT\" the problem is, that NVIDIA has not one but two 1440p cards: 3060 TI and 3070 were both marketed for 1440p.\n\nHere's how I would've marketed:\n\n6500 XT: 1080p60 medium\n\n6600: 1080p144\n\n6600 XT: 1080p144/1440p60\n\n6700 XT: 1440p144\n\n6800: 1440p144/4k60\n\n6800 XT+: 4k60",
    "comments": [
      "Just my 2 cents here...\n\nFirst appreciate the feedback. It's interesting to market to gamers especially as it grows more popular. I always felt like \"1440p\" was this grey area where your average gamer might not know what it is and an informed gamer might do their own research beyond the marketing. What really matters to me is connecting to people with their use case. \n\nDo you feel like more people are aware of resolutions outside 1080/HD and 4k?",
      "But isn't the 6700xt marketed for 1440p?  I mean, it says right there on the boxes. https://images.offerup.com/y3PtGNMpbiTrdUH4FC5xmRyMKS0=/888x1920/38d6/38d6140b46994885b969b5f7cf6cc071.jpg",
      "Sure does. There is no silver bullet for marketing and there can be reasons to do or not do something without ruling it out. For instance on a shelf I think it can help quickly demonstrate what product class something is in, so putting it on the box seems pretty useful here! On the internet I think research is a quick search away, so on-the-box features seem less important to me personally.",
      "I just find it dubious how the 5700 XT was marketed as a 1440p card, and the 6600 XT, which performs like a 5700 XT, was marketed as a 1080p card.",
      "On some level I can understand the reason for it being marketed as a 1080p 144hz card, and I also doubt that the average PC gamer will go for 1440p by comparison.\n\nThe thing is that there definitely IS an audience for 1440p and i'm a part of it. The problem I have is how AMD priced this card only 20 dollars lower than the 3060 TI, which is a true 1440p performer and as a result this turned many people off from it. Paying close to 400 dollars for something advertised as a 1080p class card is really not the best look for your it, but once I look past that I could understand why one would want this card for 1440p. It's a big leap from 1080p in quality and many enthusiasts say it's the real sweet spot for gaming, not too taxing like UHD and better quality than FHD. In 5 years time I can see 1080p going the way of 720p today.\n\nHonestly I look at the 6600 XT as the ultimate 1080p card with an asterisk for 1440p next to it.",
      "I think the reason is product segmentation. 6700XT -> 1440p, 6800XT -> 4k, so to not mix up with 6700XT, it seems reasonable to put 6600XT in \"Premium\" 1080p, with 6600 non-XT being \"standard\" 1080p and 6500 series as \"entry\" 1080p. FullHD get bit crowded, but realistically no one uses lower resolution anymore.\n\n6800 non-XT is in similar spot, its neither fully 1440p, nor fully 4K.",
      "It mainly boils down to the memory subsystem of the card.  In order for GPU's to churn out rendered frames, they need to keep the shader registers fed with data to calculate from.  That data comes from the graphics memory on the card.\n\nUntil RDNA2, over the past 6 years or so, there have basically been two choices to keep those shaders fed with data.  \n\nOne is to still use GDDR memory but increase the number of memory channels.  This increases throughput, at the expense of die real estate and power consumption, because you need more memory controllers on the GPU, and more memory chips on the board.  It's actually a compounded problem.  Not only do more memory controllers on the chip take up space that might otherwise be used for more shaders, the extra power consumption of those controllers, as well as the chips on the board, might prevent the GPU from running as fast as it could due to power budget limitations.\n\nThe second is to skip GDDR and use HBM instead.  It uses a lot less power, and is a lot faster, because it has a much wider bus and a much shorter distance between the memory and GPU.  It's also a lot more expensive.\n\nAMD did something pretty innovative with RDNA2, however.  They added a whole lot of cache instead of extra memory controllers.  This greatly increases the effective throughput of the memory, while using less power.  It's not saving any die space (might be losing a bit), because the L3 cache takes up room by itself, but you're getting more performance from using that die area for L3 than more memory controllers.\n\nBut it's not a silver bullet.  How effective cache is depends on how big it is and how much distinct data passes through it.  The amount of data goes up with resolution (more pixels to render, with all the associated memory costs of that).  So as resolution goes up, the cache hit rate for a given amount goes down.  \n\nThe 6800, 6800 XT, and 6900 XT have 128MB of L3 cache, which gives those cards a good hit rate at 3840x2160, and an excellent hit rate at 2560x1440.  Combine that with a 256-bit bus, and the effective memory speed is in HBM territory.  The 6700 XT has 96MB of L3 and a 192-bit bus, which basically shifts the performance adjectives down a resolution tier.\n\nThe 6600 XT drops all the way down to 32MB of L3 with a 128-bit bus.  That means its memory performance is merely good for 1920x1080, and not quite adequate above that.\n\nSo while the card, computationally, is easily capable of handling 2560x1440 most of the time, it's going to spend more time than it should *not* computing anything while waiting on data from memory.\n\nYou can also run games at 3840x2160 with that card, and if they're old enough or graphically light enough, they'll work fine.  Just not as well as they would with a better memory subsystem.\n\nSo AMD was correct to market the card to the resolution it provides the best results in.",
      "Cards are marketed based on games being released today, not two year old games.",
      "If you look at the competitor, the 6600 GT/Ultra, it's made for 1024x768. Even 1080p is a huge win for AMD.",
      "It's just to promote the 6700xt",
      "6600XT is 100% capable of 1440p gaming in the 60-90FPS range that 90% of people would describe as a \"great experience\", below 60 is where I feel like upgrading is justifiable.\n\nSo AMD created this whole marketing thing to sell users on \"high frame rate\" gaming to convince users that 120-144FPS is the \"new 60FPS\", in an attempt to give the massive quantity of 1080p gamers a reason to buy a GPU this powerful. \n\nIn their defense, 120-144FPS gaming is a very different experience than 60FPS gaming so their is some truth in their claims, even if the motive is 100% to sell more and more GPUs. And ultimately a GPU being a luxury product anyways makes the entire purchasing decision a product of \"wants\" rather than \"needs\". \n\n6600XT is only \"bad at 1440p\" if your definition of bad is below 120FPS. \n\nFor reference, this card can be around twice as fast as an RX580.",
      ">it's weird how the 6600 XT was marketed for 1080p only\n\nIs not entirely true, is marked as the ultimate 1080p experience, 1080p max settings, and so on. So obviously, is not like you put 1440p and then is shit.\n\n>i'm satisfied with my 6600XT and I play at 1440p\n\nNobody say you wouldn't, just that the card is not so strong at 1440p and AMD is putting all their bets on it being capable to do max settings at 1080p, and this is what they want to sell. Perhaps to don't compete against themselves in the \"1440p market\", who knows, you could argue that it is or it isn't a good marketing strategy, just that they never said is 1080p only.",
      "üíØ\nHere is the thing : it is 1000% a 1440p card. The last year getting back into the PC hobby has shown me how aggressively branded and upsold the PC community is. It's insane what happens in PC communities with people buying these absurdly overspec'd GPU and CPU. A totally killer 1080p card that can easily play modern titles at totally reasonable frame rates in the 2019 GTX 1650 - these days PC marketing treats this like a extinct dinosaur. A 6600 XT is 100% a high performance 1440p card and anyone who doesn't think so has been endlessly brainwashed by the marketing and YouTube / social media influencer community",
      "That was a few years ago. Games were a bit less demanding.",
      "Yeah the RX 6800 is made for 1440p Ultrawide ;) Does pretty great at the resolution for me anyway. Apart from with RT on of course.",
      "totally agree\n\nmy old 5700xt was a 1440p card t6600 xt is 10% faster\n\nhttps://www.techpowerup.com/gpu-specs/radeon-rx-6600-xt.c3774",
      "Mickey I think one of the biggest misses in the PC gaming community as a whole is the value of 1440p/60hz. \n\n1440p60 should be talked about more when demonstrating rich single player story driven games like the Assassins Creed, God of War,  and Horizon Zero Dawn. \n\nThe conversation around these game is almost always driven by 4k because of the television market, but PC users have much more flexibility than the console user. \n\n1440p marketing in general needs an overhaul. It's the best price to performance resolution and AMD could help change some of the mindset around frames per second. Not every game needs to run at 120+ FPS for wonderful experience.",
      "I think they decided to market it rather as 1080p cause you can see clearly scaling issues compared to the nvidia cards 3060/3060ti when u go up in resolution in higher demanding games. But like you for me its perfectly fine at 1440p cause it handles the games i play.\nedit: and that probably was the right move as you can see in the rewiews for this card when it came out. This was its main critic point.",
      "Because they want you to buy the 6700 XT+ cards",
      "It‚Äôs definitely playable on 1440p, but it‚Äôs 1440p results aren‚Äôt that impressive compared to its Nvidia counterparts. \n\nThe 3060 is very close behind (5%) in 1440p and if on PCIE 3.0, it might end up being slower than the 3060. I know MSRP doesn‚Äôt matter much these days but people still do comparison based on MSRP and that wouldn‚Äôt seem nice to market as. \n\nNot to mention at 1080p, it‚Äôs right in the middle between a 3060 and 3060 ti, which makes it super attractive for 1080p gaming as it can run high refresh rate monitors."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6400",
      "6500xt"
    ],
    "title": "AMD entry-level RDNA2 Radeon RX 6500XT to feature 1024 Stream Processors, RX 6400 with 768 - VideoCardz.com",
    "selftext": "",
    "comments": [
      "Can't wait to see $500 price tag in my place, for low end 64bit bus card.",
      "Finally - 560X/550X replacements for double the price and double the performance - after more than 5 years.",
      "Nice to get more details and I'm sure that quite a people will be happy if we get a GPU without a power connector. If there are half height versions, I might even be tempted (as long as the price isn't exorbitant).",
      "RX 580 performance for double the price 5 years later. Incredible\n\nEdit: 4gigs of ram too lmfao",
      "Hey, that's my videocardz comment. :D",
      "but 4gb will cripple a lot of games too",
      "He's stealing your videocardz commentz. üòé",
      ">I made this.\n\nI made this.",
      "If this is true then the RX 6400 might dethrone the GTX 1650 GDDR6 as the most powerful graphics card that doesn't require a PCIe power connector (with possible exception of some workstation cards).",
      "27%VAT + greedy distributor..\n\nCheapest Rx 6600 sold at $600, and I can see this card might go $500. Haha",
      "So these are the RDNA2 succesors to Polaris RX 460 and 560.",
      "Mockup Scalper Raised Price",
      "GTX 1650 is based on the 12nm TU117 Turing GPU while the GTX 1050 Ti is based on the 14nm GP107 Pascal GPU.\n\nAlso the GTX 1650 is 25% faster on average than the GTX 1050 Ti and is closer to the RX 470 in terms of performance.",
      "no, same class of cards but 1050ti is pascal while 1650 is turing.",
      "Considering they're only 4GB, this might be the first GPU that isn't completely bought by bots.",
      "With this limited supply even these will be scalped if the supply isn't plenty.\n\nAnd be honest, I doubt AMD will sacrifice many wafers for these entry products when their top of the line chips sell out immediately.",
      "Generally only with ultra-high textures, where mid-low textures should have the game working just fine. Not ideal, but these are low end cards (likely, at mid tier prices).",
      "What about it? 128EU Xe is likely similar performance to the 12CU RDNA2 here, probably slightly worse. If the full 512EU DG2 competes with the 6700XT on performance, then I don't see how the 128EU (1/4 the size of the bigger DG2) will be able to pull out any significant wins against the relatively larger rx 6400 (1/3rd the size of Navi22).",
      "After what, like a year of the first RDNA2 release? I am glad we are getting any low end GPU release at all. Hopefully the stock is better but its highly doubtful and the MSRP will be comically high as a result as well.",
      "I was thinking maybe it'd be nice to upgrade my RX460 2GB, but not for these prices."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6600xt"
    ],
    "title": "From 6600XT to 7800XT and couldn't be happier.",
    "selftext": "",
    "comments": [
      "This shouldn't be allowed. Someone shouldn't be this happy.\n\nIs there any way I can sue you or effectively ruin your day? \n\nPlease, let me know.",
      "Their wallet surely would not have been. And maybe not even themselves if they had to skip some meals. And don‚Äôt get me started on the piss-poor Linux support for the inevitable install when Windows 12 rolls around to stuff some new ads down your throat.\n\nAll in all, mind your own business mate. Your circumstances ain‚Äôt theirs.",
      "Did the exactly same jump, from an xfx 6600xt to a sapphire pulse 7800x, and finally i can enjoy maxed out vr games and can i use my 144hz monitor to the max!",
      "Just remind them Nvidia exists and that they obviously made the wrong choice because even the base 4060 is the future with frame gen, and that RT is impossible on AMD.",
      "This is roughly my upgrade. 5700xt to 6800xt. It's a huge upgrade! Congrats!",
      "How can it be sarcasm, it‚Äôs very true that the ~~4050~~ 4060 is the better choice because it can definitely ray and path trace, and get all the AI generated frames, and has the better upscaler, and also can be powered by a hamster wheel.\n\nJust don‚Äôt ask about performance or price plz.",
      "Zero issues after one week. I never ever had a single crash with an AMD card in 5 years.",
      "This is sarcasm, right? I legitimately can‚Äôt tell.\nEdit: Judging by the responses, it is sarcasm",
      "I'm 90% sure that 95% of the Linux users are using Linux because they want to, not because they need to. Otherwise they would've already migrated to Windows and would be using WSL2 instead.",
      "Hahahaha come on PastaMasta09, enjoy life.",
      "I'd wager 95% of Linux users aren't using Linux because they want to, but rather they need to. Otherwise there wouldn't be extensive WSL support on Windows. Just like how most of the GPUs in existence aren't used for gaming.",
      "what a fucking man-child",
      "I moved today from an APU  to the 6650xt.",
      "They are not out of reach, we just have to play at 540p!",
      "What a card!\n\nRdna 3 has treated me well so far. Enjoy, dude üëç",
      "And amd‚Äôs drivers were written by some freelancer amd paid 200$ 5 years ago, and amd cards are made of potato chips compared to nvidia despite often being made entirely by the exact same manufacturers",
      "Man it would be hilarious if that wete true. Worlds most capable and cheap freelancer ever.",
      "Hey OP ‚Äî Your post has been removed for not being in compliance with Rule 3. \n\nBe civil and follow side-wide rules, this means no insults, personal attacks, slurs, brigading, mass mentioning users or other rude behaviour\n\nDiscussing politics or religion is also not allowed on /r/AMD\n\nPlease read the [rules](https://www.reddit.com/r/Amd/about/rules/) or message the mods for any further clarification",
      "Yeah if you're sure its only a stopgap then I guess its fine, just weary about buying used GPUs that were around during the mining craze. Most black friday deals are already out right now, there might be something extra on cyber monday.",
      "Congrats man"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6500xt"
    ],
    "title": "AMD Radeon RX 6500XT to cost 299 EUR in France - VideoCardz.com",
    "selftext": "",
    "comments": [
      "I hope my rx 570 isn't gonna die anytime soon ... fuck\n\n&#x200B;\n\nIntel, please be aggressive\n\n&#x200B;\n\nedit : it's the price of a freaking xbox serie s ...... i am really considering to go back to console like what the heck",
      "<< AMD did not communicate the pricing for Europe yet, which is typically the case when the card is not released. >>\n\nClickbait.",
      "Really doesn't matter what Intel's ARC ends up being priced at, it'll all get up bought up instantly and prices will double straight away. \n\nAs for AMD abandoning low end, they're pretty much saying that they want you to buy a console instead, seeing as they made money off the consoles too.",
      "When you can get a Series S (8+2GB 128bit VRAM) for 270 EUR.",
      "intel arc desktop likely postponed, no mention of q1 release anymore.",
      "on them not making a huge fuss over it?\n\nThink about it lol, do you really think Intel would not have made a whole carnaval about it if they had it ready for the next month?",
      "Anandtech's Ryan Smith twitter: ['At this point the company is still targeting the first Alchemist products to be in market in Q1 2022. But they aren't offering any additional details at this time, such as mobile or desktop'](https://twitter.com/RyanSmithAT/status/1479272782017925120).",
      "This is the price of a Xbox Series S. Sorry but computer parts are too expensive right now to justify the pc master race",
      ">The issue is more that 7nm is a very mature process. As a result the failure rate on their chips is very low. So in order to make low end product, they need to take good chips and deliberately cripple them.  \n>  \n>So if you are AMD or Nvidia, what do you do? You keep selling those 700/70/800/80 series where you have a lot of margin, because who cares ( for now ) that miners buy in bulk. Your CEO bonus is looking really great this year (remember its tied to stock and profits ) .\n\nNavi 21/22/23/24 are physically different chips, in order to make a low end product, AMD make Navi 24 chip, instead of making Navi 21 chips then intentionally cripple its performance.\n\nYou make it sounds like RX6000 consist of a singular die and singular configuration, no, it doesn't work like this.",
      "At this point buying a series X and gamepass and waiting till 2024/5 seems like the best bet.",
      "I just bought a ps4 pro for $290 and jailbroke it. fuck em all lol",
      "Shit sucks(Sorry for the foul language). This card is literally perfectly tuned for the current situation, but it sucks so much. It's so cutdown that it's almost shit. No AV1, PCIe 4 x4, 4GB VRAM, Slower than the RX 5500 that is replacing,etc. And now this insane pricing for a card that would otherwise be $99. Sigh.............................................",
      "1650-s are going around that price, and this is according to their benchmarks better then that, again AMD has made a lackluster card that somehow manages to be for a week or two the best card in that price range. Can't wait for crypto to die, luckly it's dropping",
      "My backup PC uses an RX 470 8GB which I got used for 80‚Ç¨ (must've been ~2019) before the supply crisis. The chip is pretty good - it does 1320Mhz at 1075mV and the vRAM can do 2000Mhz, all while staying at or below 110W.\n\nAdditionally, it does have support for video encoding+decoding and doesn't crap itself when data has to be moved over the PCIe bus. The price when new was at or below 215‚Ç¨ (2016, MSI Gaming X model). Don't let yourself get ripped off.",
      "Launch price $335 in JP, so that means $450+ actual retail price.",
      ">AMD/Nvidia do not understand that any card that goes to miners, is a potential customer they are loosing out on.\n\nI'm pretty sure AMD/Nvidia know their businesses much more than we do. \n\n>And no, its in Nvidia and AMD their hands to put limits on the prices, they control the supply chain and can literally dictate terms.\n\nNeither company can afford to piss off their customers that much and demand price caps.",
      "Well, yes, but it's likely laptop limited release.",
      "That's about ‚Ç¨150 too much, if you ask me.",
      "You're too optimistic",
      "> As for AMD abandoning low end, they're pretty much saying that they want you to buy a console instead, seeing as they made money off the consoles too.\n\nThe margins that AMD gets on consoles is extreme low. Its always been like that. Their profit is in the bulk amount but their mainline GPU's is where the real profit is at.\n\n> As for AMD abandoning low end, \n\nThe issue is more that 7nm is a very mature process. As a result the failure rate on their chips is very low. So in order to make low end product, they need to take good chips and deliberately cripple them.\n\nSo if you are AMD or Nvidia, what do you do? You keep selling those 700/70/800/80 series where you have a lot of margin, because who cares ( for now ) that miners buy in bulk. Your CEO bonus is looking really great this year (remember its tied to stock and profits ) .\n\nThe fact that you may turn a lot of customers away to (low margin) consoles, is a issue for later. A lot of companies prioritize short term profits, the fallout is a issue for the next guy while they go on \"pension\" with loads of cash in their bank accounts."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6400",
      "6500xt"
    ],
    "title": "PowerColor confirms Radeon RX 6500XT/6400 4GB through EEC filing, AMD BC-2235 mining card spotted - VideoCardz.com",
    "selftext": "",
    "comments": [
      "4gb in 2021/2022 is a bit silly. I would think 6gb would be the new minimum for a gaming focused card. Even if that focus is on 1080p or more entry level gaming.",
      "I wonder what the MSRP and eventually retail prices are gonna be",
      "real world price $400 and $500 respectfully then",
      "People are still selling 1650's for over 300 on Amazon. Mining performance is irrelevant, if they don't stop scalpers from getting them the price will be artificially inflated. They have literally bought out the market to the point where normal retailers and resellers are using scalper pricing too because they can.",
      "Man, imagine being able to get some new life into your 980ti by just throwing like 8gb of GDDR5 in it.",
      "MSRP: $159-179 for the 6400,\n$200-229 for the 6500 XT",
      "Glad that I got my RX 590 in 2019. Good luck to those still actively looking for a GPU.",
      "I can't help wonder if it is related to the ongoing fab situation driving up the cost of RAM. Makes me wish GPU RAM was as upgradable as CPU RAM.",
      "If the 6600 cards considered 1080p cards, then these must be the 1024x768 cards",
      "Probably not quite that much, depending on availability, since these won't mine well and are too low level for that many people to be interested.",
      "There are a lot of games you can play on a 4GB card. Not everyone is laser focused on playing the latest AAA games.",
      "So get a 710? This will be faster than a 580/1060.",
      "Is the rx 560 still relevant today? Should we still be comparing budget cards to it? This thing should be at least as good as RX 580, which has a 256 GB/s bandwidth.",
      "Halo Infinite is showing us what a lack of optimization can do.\n\nOn the consoles, it runs on a R7 260X with DDR3 and a RX 580.    Yet on a superior spec'd PC it runs abysmally.   \n\n 343 pulled 120 FPS support from XBS, which pushes my suspicion further towards lack of optimization/bloat.",
      "Relatively a bargain. Relatively a really fucking bad price, too.",
      "Are these meant to be gaming focused cards though? 6500xt likely but the 6400 sounds like a prebuilt card especially seeing low profile models and no power connectors. \n\n4gb cards are still holding up ok. My bedroom rig uses a 4gb rx470 still enjoyable. Not every new title is a graphic powerhouse that needs the best of the best and tons of vram.",
      "I think that was XFX that did the Fat Boy",
      "This.\n\nOnce again, My 4 gig 570 is quite happily chewing through a lot of the id software back-catalogue right now, and even manages to keep up in the new Doom games (2016 and Eternal).",
      "Is it though? With 14 Gbps GDDR6 it will have 112 GB/s of memory bandwidth which is the same as the RX 560 which had a 128-bit memory bus while consuming less power as a wider memory bus requires more power.\n\nWith 16 MB of L3 the effective memory bandwidth will most likely be higher than that of the RX 560.",
      "i wish AMD would release a Rx 6700 (non xt) but that won't happen anytime soon"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6500xt"
    ],
    "title": "The 6500xt really is a message to the Polaris gang",
    "selftext": "The message says: \"There will never be an upgrade for you in this price class. Never.\"   \n\nThey want you (and me) to upgrade to higher price tier, preferably before crypto crashes. And it's tempting. It really is.  \nI'm not sure if they even meant this card to be sold in large numbers, other than to desperate people who have no gpu at all. It's really meant to push the people who are waiting for a cheap upgrade, to go for higher tier, right now.  \n\n(Well I'd be upgrading to higher tier card anyway if there was a perfect one, like 16GB(or more) of vram, cuda, blender performance, gaming performance and at msrp (or below)) \n\nBTW, a large computer parts store here in Finland got a batch of Asus 6500xt's, 5+5 cards, ones for 329,90‚Ç¨ and others for 369,90‚Ç¨.  \nThe $199 msrp converts to 217.50‚Ç¨ with 24% VAT. Someone is pocketing 110-150‚Ç¨ extra from these cards. They have sold 3 of them so far. Doesn't feel too popular.",
    "comments": [
      "Well, I just moved to lower tier: I use iGPU and mostly content with that. I'll play cyberpunk in 10 years when in will comfortably run on the iGPU. Not a big deal. \n\nI won't pay those crazy prices for dGPUs. Just no.",
      "If you bought a 1080 TI in 2017, you got the greatest card to ever exist period. Maybe not objectively (3090 TI is obviously better), but that thing was the king of performance to value. It still runs well at 1440p.",
      ">  I'll play cyberpunk in 10 years\n\nHopefully they will have delivered what they promised by then, and maybe the free DLC too!",
      "Anyone with RX580, RX480, Vega56 and so on should be strong right now and keep lowering settings..",
      "MSRP for those cards don't exist and arguably never did.",
      "Not just the Polaris gang. All the cards below the mid to high segment. Neither vendor seems interested in offering serious entry or entry to mid level cards any longer.",
      "Thank god there's more to life than gaming, or so i heard",
      "They did for FE/Reference, but as we know those are were sold at extremely limited supply.",
      "The 1600 series was not really a big enough upgrade to justify. Would say the closest thing to a good upgrade was the RTX 2060 at $350",
      "Pretty much what I've been doing the last few years on a 1060 6GB.",
      "What the hell are you talking about?",
      "When they can get this much more for mid and high end cards and while Gddr6 is scarce and expensive, of course they aren't.",
      "You know it's not only USA on the world map right? Eastern Europe doesn't even have a authorized seller for Nvidia FE for example and what drops on west-central Europe is not nearly enough.\n\nSo I can pout and cry as much as I want because the stock is non-existent or if aib exists it's overpriced by 2.5x.\n\nAlso \"they did sell some\" smells more like a reason for the people to say it exists but don't fool yourself and don't try to come up with motives. People shouldnt protect corporations anyway, doing that it's their job not yours as a customer, I haven't heard anything from them with regards to the situation because it can backfire but by god the community does it pro-bono",
      "I said with DLSS...",
      "Bitcoin used to be mined on GPUs, then asics came along and ended that. But guess what? new cryptos popped up like Etherium and used GPU mining.\n\nEtherium going PoS wont change anything, people will just move to something else. The entire crypto market has to decline for years to put an end of it.",
      "Right, but one can only expect an incremental upgrade after just 1-2 years. I was also staying within the general budget. RX 580 released at $229, so to have a 1660 SUPER performing 28% faster and still at $229 was okay progress after 2 years. (And more than okay if you accept the Nvidia premium for lengthier support cycles.)",
      "I usually only upgrade components when I get a four fold performance increase at the same price point... So I guess at this rate I'll upgrade in maybe 2030? xD\n\nSeriously tho. Last GPU I had before 1060 6Gb was a HD5850 bought in 2009. 7 years for that upgrade. I guess this one'll go close to 10.\n\nSo I'm giving as much TLC to the 1060 as I can. Undervolting, keeping it cool, cleaning it at least once a year, making sure the PSU is top notch clean current wise, having a wall plug with surge protection, etc.",
      "Best buy for FE, and AMD direct buy.\n\nYou can pout and cry about low stock, but they still did sell some and some people did get them at MSRP. Not to mention EVGA has been selling their 3080s +50 to +100 over MSR (ok a bit more Now, but for a long while it was 50-100 above MSRP).",
      "The 3060Ti at $400 would have been THE gpu to get. Insane value at that price. Which means AMD, to compete, would have had to price the 6600XT at $300-325.",
      "*hodl* til the storm passes, everyone. \n\nI'd be happy to pick one up for what it's worth to me, around $130- considering it bottoms out around where a RX 470 does, it's missing some major features, and it's fair to account for both money and technology inflation; I'd say this ought to be in the neighborhood of RX 460-470 money."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6400"
    ],
    "title": "is a RX 6400 to gtx 980 ti for 75$ a good upgrade?",
    "selftext": "My current system has a ryzen 5 5600 and an rx 6400 gpu.\n\nI found a gtx 980 ti (6gb) for 75 bucks.\n\nI used the video card comparison tool on passmark to compare the two and it looks like I get double the raw performance with the 980, and I'm hoping that FSR will help me with playing modern games at decent frame rates. My only concern is that it's an older card and I'm unsure how much its age would affect me if at all?",
    "comments": [
      "On paper, yes. In practice, hell no. Way higher power draw, it‚Äôs about to lose driver support as well (and maxwell is already‚Ä¶iffy in some games). If you‚Äôre going to go with an old cheap card, get a GTX 1080 for 100-120. More vram, more performance, much lower power draw. Still on the chopping block for driver support, but If you need SOMETHING for dirt cheap it‚Äôs a decent option.\n\nIf drivers are a concern, look for an rtx 2070 or RTX 2060 super for 140-150.",
      "It's hella old, the minimum for a GTX series in 2025 should be a 1080",
      "No.",
      "Save and go 1080 at a minimum.",
      "alright, thank you so much for the input!",
      "980 Ti is definitely faster, just far from the best option.",
      "That‚Äôs a down grade .aim for a 6700xt, 5700xt, 7600 or better 2080ti, 3070, 3060",
      "save up some more money and get a functional graphics card",
      "Won‚Äôt be faster when none of your games have compatible drivers. Just get a 2080 Ti."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6500xt"
    ],
    "title": "Why are posts about current 6500XT pricing removed?",
    "selftext": "http://www.reddit.com/r/Amd/comments/s97kgb/gnam_gnam_what_a_deal_and_for_this_price/htlzn50\n\nhttps://www.reddit.com/r/Amd/comments/s8tnzo/price_of_6500xt_is_close_to_450_in_greece/\n\nThese aren‚Äôt breaking rule 7. They aren‚Äôt shitposts nor are they memes/\n\nAnd these posts are especially relevant in light of Dr. Su statements:  \n>We‚Äôre positioning the launch such that ‚Äì and I know, you guys always say, ‚ÄôWell, yeah, they‚Äôre just saying that‚Äô ‚Äì but we really are positioning the launch at a $199 price point. It is sort of affordable to the mainstream. You know, we intend to have a lot of product out there.",
    "comments": [
      "I don't care if these types of posts are allowed or not but can we group them into a single megathread? There's only so much that can be said about the prices, it's not like they're going to change in the current economy unfortunately.",
      "thanks for your work and the prompt response",
      "There's at least three of them. But one of them stands out since he's on reddit 24/7 it seems",
      "At least one of them is a massive fanboy.",
      "Wow mods actually doing they're jobs thank you",
      "cause mods are amd fanboys",
      "Absolutely, but what we should be defining as the minimum for a \"shitpost\" should be much higher effort than the posts removed.",
      "I guess whether something is a \"shitpost\" varies from person to person.",
      "Needs discussing further, but we don't have an official rule against them so they should remain for the time being. Posts of this type usually tone down a little while after a launch.",
      "Posts have been re-approved. Thanks for raising.",
      "Sorry to hear that, I do personally try to engage a bit more in an official capacity, but everybody is to their own on moderating style.",
      "No problem :)",
      "This would be my preference as well. It was fine for a while, but it's annoying when they hide all other topics, so grouping them would be ideal.",
      "You can‚Äôt change the title it have to be the same thing.",
      "Because this sub is getting flooded by people all posting about the same exact thing. I don't know why the discussion can't all be had in whatever the top post is pertaining to that topic.",
      "NGL, this is the first mod I see in this sub.",
      "Very sorry about your post being removed, wasn't removed by me personally and sadly don't have an exact reason to give you. In the future, please do mod mail us to let us know, then all of the mods can take a look in to it.",
      "I start thinking whether some AMD employees are the mods of this subreddit so they could \"influence\" public opinion toward favoring AMD, while removing posts that expose their dark side of corporate greed.",
      "then it‚Äôs on them for not ordering ref. cards so they do have control (through maximum resale price contracts), aint it?",
      "5950X/3090 gigachad: \"peasant price discussions concern me not\"\n\nLul"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6600"
    ],
    "title": "New AMD Radeo Raise the Game Bundle Offer - Dead Island 2 & Callisto Protocol for select 6000 series (RX 6600 to 6900 XTX get both games)",
    "selftext": "",
    "comments": [
      "Sorry, my editing skills are way off today.  I got COVID-19 at the AMD Event in LV last week. . . . Unfortunately, not *everything* that happens stays in Vegas ![gif](emote|free_emotes_pack|dizzy_face)",
      "Call BB and tell them you want to do a \"paper return\" and rebuy to get the promo.  They are very good about it and have done it for me  in the past.  You probably won't have to physically return the card.",
      "how about you get absolutely nothing....",
      "Wow, I ordered a 6950XT less than 10 days ago and they add them.\n\n&#x200B;\n\nGuess I'll see if company will honor it or ill just return and reorder.",
      "Video killed the radeo star‚Ä¶",
      "Wish I knew if these were Epic or Steam keys.",
      "I only see checks on 6950, 6650 and one check for 6500.",
      "I see both games checked for all cards except for 6500 XT & 6400.  Those cards only get Dead Island 2.  That's what I meant by *RX 6600 (and above) to 6900 XTX* get both games ;)\n\n**UPDATED** with image of the promo bundle\n\n[https://imgur.com/a/UALMiR7](https://imgur.com/a/UALMiR7)",
      "Thank goodness you didn't say nVideo.",
      "There is no 6900 XTX btw",
      "Thats what I got when I bought my 6900xt.",
      "Then it just means that you aren't the target audience. Many people want the new MWII game, which comes with the Intel Arc card. That game is \"worth\" almost a quarter of the card cost here in Canada, which could definitely be appealing to some people. Just some food for thought.",
      "I don't know....I never really cared for these bundles.  \nI know this is a great way for GPU manufacturers make the hardware more attractive without reducing the price.  \nBut I am pretty selective with the games I am interested in. Especially since you can't even resell these games this just pretty much adds zero value for me.",
      "For uncharted bundled with my ryzen processor I got last week it was a steam key so I guess this will be the same. You had to download a verification tool to see if you didn¬¥t sell it where you needed to login to your steam to get the key. I don¬¥t think epic allows this kind of stuff even.",
      "And why exactly would they do that? Digital goods are literally worthless, the developer/publisher can generate an infinite amount of redeemable keys at no cost and sell those for a fraction of the retail value or in exchange for whatever they're receiving from a hardware manufacturer (marketing partnership etc).\n\nSo instead of increasing the sales of their products at very low cost to themselves, they should reduce their MSRP by probably at least like 10x whatever they paid for the bundled games? lol",
      "That's fair considering the 6400 would be only 30 bucks if you got both lol.",
      "Can you? Idk how it is with AMD, with Nvidia you need the card to redeem it",
      "That's how I see it. These games are a personal taste thing. Now if you gave me 2 games from a studio, with options, then there's value. This is not the case.",
      "Assuming it works like CPU's, the bundle code only checks if you have *any* hardware that's eligible for the promotion. So you can sell it to someone who has one of these cards.",
      "Anyone know when the Callisto codes go out on the rewards accounts?"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6500xt"
    ],
    "title": "AMD 6nm Navi 24 GPU pictured, coming soon to Radeon RX 6500XT graphics cards - VideoCardz.com",
    "selftext": "",
    "comments": [
      "Why are some GPU die's rotated at a 45 degree angle? More efficient path tracing to the memory or what's actually going on here?",
      "100‚Ç¨ GPU that will sell for 300‚Ç¨...",
      ">More efficient path tracing to the memory\n\nYep.",
      "Everybody complaining about the 4gb of vram but the fact you can‚Äôt mine eth on it will help it being in stock. A bunch of people are buying 1650s at stupid prices cause they need a card. A 6500 at 200$ is miles better than a 1650 at 250.",
      "Oh man, what times we're living in. I upgraded to RX 6600 XT which is what I would optimal 1080p card for almost 2022 now. RX 6600 is what I would say is bottom of what can handle AAA games in 2022 and near future.\n\nNow TX 6500 XT with just 4GB of VRAM - half as much CUs and cores seems like bad joke. It smells literally of 2GB RX 460, but at much higher msrp, and definitely higher retail price. It's just extreme gap even from non-XT RX 6600...",
      "and people will buy",
      "These would be great $99 GPUs in regular times. This section has been ignored for a long time with bad offerings like gt 1030 and rx 560",
      "My RX580 came defective from factory. My best friend had his die within 1 year and Asus didn't honour warranty: now in judicial process. Meanwhile he had to buy GTX1650 because it was the most affordable thing available with better performance than an iGPU. I'm stuck with an underclock/undervolt card I can't upgrade due to low availability and scalping prices. What choice do I have once this card dies? People either buy or don't play games.",
      "You seem to be missing the fact that the RX 580 is extremely overpriced due to its high mining performance, especially the 8GB version.",
      "RX 550 is the equivalent to the 1030.  a 560 was actually a decent entry level gaming GPU when it was new, 1030/550 not so much.",
      "There's no bad product, only bad pricing.",
      "6500 XT at $200? üòÇ what are you smoking dude? Must be strong stuff.",
      "I'm not saying it's impossible to find them at somewhat reasonable prices. It's just very unlikely because most sellers know they can ask for a higher price.\n\nI just checked the used market prices of RX 580s and the cheapest RX 580 4GB cards go for around 300 Euro (including VAT).\n\nThat's a similar price to what I paid for a new RX 580 8GB from an official retailer back in 2017 when the previous mining boom was starting.",
      "6nm isn't really a new node.  It doesn't need a 'pipe cleaner' product.  AMD are using 6nm cuz it helps them make more.  This wont help prices currently, but it'll help AMD make more money.",
      "Except Polaris cards are overpriced due to their mining performance as well.\n\nIf you have a choice between a 4GB Polaris card and a 4GB RDNA2 card then at least you know that the RDNA2 card will have longer driver support.\n\nThe only downside of the RX 6500 XT is that it will only have 8 PCIe lanes which will make the performance drop when running out of VRAM worse on PCIe 3.0 platforms. If you have a PCIe 4.0 platform there's no reason to consider a card like the RX 580 4GB unless it's significantly cheaper.",
      "Well that would be an exceptionally rare circumstance. \n\nIt's like saying that everybody paying $500 for a PS5 are suckers cuz I won one in a sweepstakes.",
      "A few things you're ignoring:\n\n1. the RX 580 in question is likely to be used and that means that it may require you to refurbish it (clean, repaste and in particularly bad cases replace the fan(s)). It will also likely not last as long as a card in a factory new condition.\n\n2. The RX 6500 XT will likely perform better than the RX 580 if only because the RX 5500 XT was already at the performance level of the RX 580. \n\n3. The RX 6500 XT will receive better driver support and it will receive driver support for a lot longer than Polaris cards. AMD dropped support for GCN 1.3 half a year ago and Polaris is next on the chopping block.",
      "I mean... even at $150 or so, it's not the worst option in the world.\n\nThese days you can get a decent enough CPU for around $150. But getting anything that actually plays games reasonably well at that price range is a complete fantasy. The GT 1030 is a fucking *terrible* GPU.\n\nThis thing's not very good, but at least you could get some decent medium/low 1080p gaming out of it for 3 years or so.",
      "not much sense talking MSRP when retails is 2x that on average, even more with some nvidia cards. Also my bet MSRP will be $249 on this one, so expect retail at over $400 if availability is similar to other cards.. And shit won't get any better in 2022, maybe in 2023 if lucky. It's just mining and silicon crisis combined makes GPU market especially totally absurd these days. So you either sit with your Polaris for till 2023 or pay premium scalp and grab the upgrade - that's simple reality we're living in right now. But good luck playing most AAA games with Polaris - Halo Infinite is basically unplayable even at low. Dying Light - don't think 60fps will be achievable. Elden Ring - maybe as game isn't much more visually impressive than Dark Souls 3, tho it's open world so who knows and optimization is always a question mark with Japanese games. So basically Forget AAA 60fps with polaris.\n\nAlso, at least here RX 6600 XT is around 200‚Ç¨ cheaper than base RTX 3060, lol. So it's good card in that sense, actually RX 6600-series is the only \"budget\" option right now at least in most countries at at least can play any AAA game in 1080p.",
      "Console. PC gaming  has been dogshit thanks to covid + mining hitting us at once. Fun."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6400"
    ],
    "title": "This might sound dumb but, has and ever made a non low profile version of Rx 6400?",
    "selftext": "I meant amd",
    "comments": [
      "Edit: Misunderstood, corrected comment:\n\n[https://pcpartpicker.com/products/video-card/#c=521&slotw=2,5](https://pcpartpicker.com/products/video-card/#c=521&slotw=2,5)¬†7 on this page (ignore the Gigabyte low profile one)",
      "Yes, it's called RX 6500 XT.",
      "They are asking about rx 6409 that are NOT low profile.",
      "oops that's my bad. u/Any_Restaurant_4953  [https://pcpartpicker.com/products/video-card/#c=521&slotw=2,5](https://pcpartpicker.com/products/video-card/#c=521&slotw=2,5) 7 on this page (ignore the Gigabyte low profile one)"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6600"
    ],
    "title": "[HUB] Radeon RX 6600 XT vs. GeForce RTX 3060, 50 Game Benchmark",
    "selftext": "",
    "comments": [
      "They cost roughly the same in Europe so its not really a discusion. The 3060 gets you DLSS, better raytracing, 12GB of ram and NVENC. The 6600XT is a really hard sell at a comparable price.",
      "TLDW:\n\nRX 6600XT - 50 games head to head vs RTX 3060\n\n**3% faster @ 1080p**\n\n**2% slower @ 1440p**\n\n*SAM was enabled for the RX 6600XT and Resizable BAR was enabled for the RTX 3060",
      "The 6600xt should be sub $200 and the 3060 $250. It's taking so long...",
      "duopoly bros wont budge",
      ">\" budget card benchmarks \"\n\nThese cards both launched at 329-379$ MSRP and are curently selling for 400$+. There is nothing budget here and it makes perfect sense to include atleast some RTX performance metrics.\n\nEven without DLSS and FSR both can do RTX although Nvidia is obv superior. With FSR and DLSS both are very capable of decent to good RTX performance.",
      "funny thing to say when you have AMD sponsored games like ac:valhalla and far cry 6 on the other side\n\nand since when is RE:Village Nvidia sponsored? That‚Äôs an AMD title as well",
      "Considering 3060 and 6600XT is pretty much at price parity in many market, 3060 is probably a safer bet for a GPU that stays relevant somewhat longer.\n\nI wonder when will 12GB VRAM actually start to net some benefit? Or maybe higher bandwidth will become useful first?\n\nBTW am I remembering it wrong...? I swear when 6600XT and 3060 launch my impression is 6600XT is significantly faster in raster only title, and somehow a few months after launch it no longer is the case?",
      "Basically, the regular AMD \"fan\" functions like this:\n\nPlease do not test any game that doesnt run well on amd. Pease remove all of them. Then cherry pick all the titles that are broken on nvidia and run disproportionately fast on amd. \n\nIm an amd fan damn it, don't give me real results, give me the ones that show amd winning",
      "I just checked and the cheapest 3060 here in Germany is 449‚Ç¨, cheapest rx6600xt is 430‚Ç¨, so yeah they are priced about the same.\n\nEdit: cheapest rx 6600xt is 420‚Ç¨",
      "That is not how you calculate the average, there are at least 3 better ways of going about it. As clearly stated in the video, we leave RT enabled when enabled by default which it is in F1 2021 (2022 isn't out yet), Resident Evil Village and Metro Exodus Enhanced Edition.",
      "Completely unbiased person right here lol. \n\nThe thing about RSR and NIS is a lie, both work the same but AMD has a better GUI switch for it. Quality the same as well.\n\nNow tell us how raytracing is useless and dlss is stupid.",
      "8-10%? Did you do the math ? Removing all 3 RT titles (and keeping all amd sponsord titles as well), only amounted for 1.4% \n\nRemoving all 3 RT titles, the 6600xt is 4.4% faster at FHD, 0.6% slower at 1440p.",
      "> Because ofc people buying this tier of GPUs are all about ray tracing.\n\nThe 3060 runs all those games fine with RT enabled. What's the problem? Wait, you are upset because the 6600xt has terrible RT performance so the 3060 shouldn't do it either? lol.",
      "Don't discuss with this guy, no point. \nHe's just upset that his GPU with about the same price isn't able to do the same in raytracing and has less features so he's mentally justyfing his purchase by telling himself that rt performance doesn't matter for this GPU tier and that those features aren't usable.",
      "I have my doubts if the RTX 3060 will be able to effectively utilize its additional 4GB of VRAM considering its performance level.\n\n> BTW am I remembering it wrong...? I swear when 6600XT and 3060 launch my impression is 6600XT is significantly faster in raster only title, and somehow a few months after launch it no longer is the case?\n\nThese tests have been done with updated drivers. That can change the result quite significantly especially when comparing GPUs that were close in performance to begin with. This is where the \"FineWine\" meme came from as GCN GPUs have gained a lot of performance over time due to improvements on the driver level.",
      "If they are enabled by default then i see no problem, Ray Tracing is the future of graphics and it will only get implemented in future games more often than ever before.",
      "Here in Japan:  \n\nRTX 3060: $370  \nRX 6600XT: $390  \n(before 10% sales tax)",
      "That would only be possible if the 7nm TSMC dies and G6 memory chips and components and shipping were all the same costs as 14nm Glofo and G5 chips and the rest 6 years ago. And the dollar worth the same as 6 years ago, too.\n\nUnless 7nm costs halved since 2019 then Navi23 is about $40 die, and G6 spot price is $10, so a 6600 costs like $100 just for the gpu+mem, so $200 is not a possible \"should\"",
      "We're not including older GPUs in these head to heads but if we did we'd probably show both results. FYI the second highest quality preset in F1 2021 also enables the same level of RT effects by default.",
      "I literally tried WD legion yesterday on my 3060 and on high settings and mid RT it almost never dropped below 60. No DLSS involved.\n\nYou can see in the video the 3060 does 90 fps on Metro Exodus with mid RT. No DLSS involved.\n\nF1 2020 ultra high q with rt also 90 fps, no DLSS.\n\nDLSS at 1080p depends heavily on the title, on some games is completely unusable, like in Warzone or God of War, in others like Cyberpunk or Watch dogs it is unnoticeable."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6600"
    ],
    "title": "ASUS says \"2x Fans. 2x Fun\": intros Radeon RX 6600 DUAL V3 graphics card - VideoCardz.com",
    "selftext": "",
    "comments": [
      "It's not like they have anything else for the lower mid-range. Anything newer is on more expensive nodes, and they don't seem very keen to lower prices on those until new nodes and products arrive.\n\nThe $200 price point being served by previous gen cards is probably the new normal.",
      "At least the RX 6600 is fine enough at $200 - the RX 5700 was the same performance for $350 five years ago, and that‚Äôs not great, but it‚Äôs about what we should get from two generations.",
      "Passively cooled GPUs reading the fans to fun equation üòê",
      "\"A good upgrade when new\" hasn't been a feature of *any* GPU for a long time now.",
      "It's more like a return to normal id say\n\nBack in the day this used to be pretty common to get rebadges of last gen nodes. It only stopped being common in the last decade or so.",
      "\"2 fans 1 chip\" an HBO special.",
      "Didn't realise so much vitriol for this card. It's a pretty good card on a budget. I'd argue that if you don't have the money for the RX6600/50/XT or the 6700/XT, this is a steal. It runs everything that's out with a less than 2 titles in the 30fps range.",
      "I actually think they gonna get replace by RX7600/7600XT. These are make on N6 node, pretty similar to N7 node. And RX7600 die size is actually slightly smaller. 204 vs 237mm^(2)",
      "It would make more sense to make a SSF oriented card with this sku at this point. I know the SSF community would appreciate more options in that space. If they made a low profile or low profile single slot if possible, that would be great.",
      "I recently purchased an Asus RX 6600 and I think it's fantastic for a budget card. Running all the games I play in Ultra at 1080p",
      "2x the RMAs.",
      "What an idiotic response lmao\n\nSpeak for yourself, but not everyone play those AAA rubbish that's released year after year.\n\nLots of people are PERFECTLY fine playing older classics like Total War, Mount & Blade and Skyrim, especially when the modding community for these are massive and guarantees tons of great new contents for free.\n\nThese games have never been demanding on the GPU but always extremely CPU limited, and Frame Gen have been the perfect tool to alleviate this bottleneck.\n\nPerhaps you should grow a brain and understand there are different gamers out there, ones that do not buy yearly trash release from Ubisoft or whatever COD games get pumped out lol",
      "Smaller shroud = less material.\n\n9 blade fan vs 11 blade = cheaper fan?\n\nSo, either more profit or get closer to $199 like Powercolor, Sapphire, and ASRock?",
      "might as well make a single fan version with target GPU temp at higher temp @ 80-85c. \n\nGPU like these need to be as small as possible & fewer fan and heatsink also contribute to cost saving, therefore can sell even cheaper.",
      "I understand where you're coming from, but at the same time this is also a subjective topic. For instance, if someone happens to still be running something akin to a RX 580 / GTX 1060 / GTX 1650 in their rig ( *and there are still plenty of these cards being daily driven today* ) and they are looking for the absolute best bang for their budget upgrade that's not only on newer architecture but will also provide a performance increase they'll easily be able to see - then the RX 6600 fits that bill perfectly while still fulfilling a spot in the ~$200 and below price range.\n\nNow one could argue \"Well, if the prospective buyer could just *add another ~$100* to their available budget that would open up the RTX 3060, RTX 4060, RX 6600 XT, RX 7600 / XT, Arc A770 as potential and even better upgrade options.\" An I agree, the caveat is that there are a lot of PC owners out there that are strictly budget buyers, they're pinching pennies, and they have absolutely no desire or need to spend any more then the hypothetical $200 + tax budget that they have set regardless of the benefits they would see, and the RX 6600 as well as the Arc A750 for that matter fit the narrative perfectly for these kinds of buyers.",
      "Now days they don't rebadge, they just fill the lower price points with old gens.",
      "Ppl are holding onto their hardware for longer too... Bet out there there's a person laughing with their 750TI.",
      "Asus Dual fills a certain use case. For example, the Intel NUC mini gaming PC range are a perfect fit for these cards",
      "\"We noticed a scratch on the PCIe bracket, that will be $75 please or we unsolder your VRAM and burn down your house, thankyoucomeagain\"",
      "For those curious, the Asus Dual range primarily exists to fit in the mini PC's offered by various OEMs. The most prominent that comes to mind is the Intel NUC gaming systems."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6400"
    ],
    "title": "MSI overclocker teases AMD Ryzen 7000 CPU running DDR5-6400 CL32 memory - VideoCardz.com",
    "selftext": "",
    "comments": [
      "I want to know if they did it with 2 dimms or 4. You cant do this with 4 dimms on z690 but with two dimms its nothing sprcial.",
      "Of course they cut off the \"NB\" frequency... would love to know what the fabric clock was at DDR4-6400.  Hopefully 3.2GHz.",
      "Ya get penalized if you show the fclk. That's a controlled leak",
      "amd said ddr5 would be OC a lot so, its happening",
      "> Where in the screenshot does it indicate 4 dimms?\n\nNobody said anything about 4 DIMMs.\n\n>Just because it‚Äôs 64gb‚Ä¶? Yeah, no.\n\nYes.\n\n>All are either 2x16gb or 2x32gb\n\nThe 32GB sticks require 2 ranks per stick and per channel to reach that capacity as they use 16gbit IC's.\n\nThey clock far lower than single-ranked setups.",
      "Its not really anything new though. XMP 6600 CL32 already exists on Z690, and overclockers have pushed into DDR5-10552 (with obviously looser timings). \n\nAnd with a sample size of 1, its hard to know how well AM5/Zen 4 will handle DDR5, because just like on Z690, most people definitely arent going to get insane speeds, these top end results are from $1500 motherboards, with binned CPUs and RAM.",
      "Disclaimer: I'm not very knowledgeable about DDR5.  \nDDR5 has a different design vs DDR4, with two smaller data channels, sort of like a dual-channel design but with half the bandwidth per channel (2x32 bits instead of 1x64 with DDR4). This helps reduce real-world latency where there are many data accesses at the same time, as you get twice the amount of simultaneous accesses.  \nWith that in mind, DDR5-6400 CL32 should have lower latency than DDR4-3200 CL16 in real-world situations. Though I have no idea by how much, if this even holds up.",
      "PC manufacturers will still find a way to disable the second channel on budget PCs and laptops, just out of spite.",
      "I am surprised there are no leaks on this at all.",
      "That's with half as many memory ranks per channel",
      "so IF = 1600 mhz ? OC 7600mhz would be possibly 1900mhz.",
      "There are 2 ranks per channel",
      "So the rough equivalent in latency with DDR4 is 3200 MHz CL16, just the DDR5 has double the bandwidth?",
      "DDR5 has 2 RPC by default afaik (because it's 2x32 bit). So 4 dimms would be quad rank (harder to drive, minimal benefit).",
      "It has 2 channels per DIMM, but each still has 1 rank",
      "Matisse and Vermeer run JEDEC 2133 to 3200 at stock with synced IF which is 1067-1600mhz",
      "The memory controller is a client of the fabric, it is not part of the fabric.  You can swap or remove the IMC and the fabric remains as it is.\n\nAMD links the fabric and IMC clocks together to reduce latency, but they could technically implement a full decoupling and allow them to run at fully independent clocks.  The 1/2 ratio is a demonstration of this simple fact.",
      "in Ryzen 3000/5000 the problem was the I/O at 12nm, Ryzen 7000 will use I/O at 6nm, IF should be able to exceed 2500Mhz",
      "I mean is this supposed to be impressive? G.skill has kits that run 6400 MHz CL-32 out-of-the-box with XMP on z690 \n\nG.SKILL Trident Z5 Series 32GB (2 x 16GB) DDR5 6400 Intel XMP 3.0 Desktop Memory Model F5-6400J3239G16GX2-TZ5S https://www.newegg.com/g-skill-32gb-288-pin-ddr5-sdram/p/N82E16820374360?Item=N82E16820374360&Source=socialshare&cm_mmc=snc-social-_-sr-_-20-374-360-_-08022022",
      "Fabric running at x2 bandiwth but new \"gear1\" mode is 1:2 ratio. Highest leaked me oc is 6600 so far, but no info on dual rank perf"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6600"
    ],
    "title": "AMD Software: Adrenalin Edition 24.9.1 Release Notes",
    "selftext": "# Highlights\n\n* New Game Support\n   * ¬†Frostpunk 2\n   * God of War Ragnar√∂k\n   * Warhammer 40,000: Space Marine 2\n   * The Sims‚Ñ¢ 4 DirectX¬Æ 11 Update ¬†\n* AMD Fluid Motion Frames (AFMF) 2\n   * A major advancement in frame generation technology for AMD HYPR-RX.\n      * **Lower Latency and Higher Performance**\n      * **Fast Motion Optimization**\n      * **Improved Borderless-Fullscreen Support**\n      * **Expanded API Support**\n      * **Radeon‚Ñ¢ Chill Interoperability**\n      * **Optimized AMD Ryzen AI‚Ñ¢ 300 Series Support**\n   * Check out our new blog¬†[HERE](https://community.amd.com/t5/gaming/boost-gaming-performance-by-2-5x-with-amd-software-adrenalin/ba-p/711458)¬†to learn more about AFMF 2 and this driver release.\n*  \n* AMD Radeon‚Ñ¢ Anti-Lag 2 Vulkan¬Æ Support for Counter-Strike 2\n   * AMD Radeon‚Ñ¢ Anti-Lag 2 now supports the Vulkan¬Æ API, offering additional responsive gaming options. AMD Radeon‚Ñ¢ Anti-Lag 2 introduces an in-game option to optimally pace frames, further reducing input lag on AMD RDNA‚Ñ¢ architecture-based graphics products.\n      * Users looking for a way to measure response time can use our¬†[Frame Latency Meter (FLM)](https://gpuopen.com/learn/frame-latency-meter-flm-1-0/)¬†or the built-in latency monitor in AMD Radeon‚Ñ¢ Anti-Lag 2.\n      * Check out our new blog¬†[HERE](https://gpuopen.com/learn/integrating-amd-radeon-anti-lag-2-sdk-in-your-game/)¬†to learn more about the AMD Radeon‚Ñ¢ Anti-Lag 2 SDK.\n\n* Geometric Downscaling for Video\n   * Improved image quality by reducing artifacts during downscaled video playback.\n      * Geometric Downscaling is supported on AMD Radeon‚Ñ¢ 800M integrated graphics, as well as AMD Radeon‚Ñ¢ RX 7000 series desktop and mobile discrete graphics cards.\n\n* Expanded AMD Radeon‚Ñ¢ Boost Support\n   * FINAL FANTASY XVI¬† ¬†\n* Expanded HYPR-Tune Support\n   * HYPR-Tune support allows HYPR-RX to enable in-game technologies like AMD FidelityFX‚Ñ¢ Super Resolution and AMD Radeon‚Ñ¢ Anti-Lag 2.\n   * Support has been added to automatically configure AMD FidelityFX‚Ñ¢ Super Resolution 3 with frame generation in:\n      * Black Myth: Wukong\n      * Creatures of Ava\n      * Frostpunk 2\n      * God of War Ragnar√∂k\n   * Support has been added to automatically configure AMD Radeon‚Ñ¢ Anti-Lag 2 in:\n      * Ghost of Tsushima DIRECTOR'S CUT ¬†\n* Expanded Vulkan Extensions Support\n   * [VK\\_AMD\\_anti\\_lag](https://registry.khronos.org/vulkan/specs/1.3-extensions/man/html/VK_AMD_anti_lag.html)\n   * [VK\\_KHR\\_maintenance7](https://registry.khronos.org/vulkan/specs/1.3-extensions/man/html/VK_KHR_maintenance7.html)\n   * [VK\\_KHR\\_pipeline\\_binary](https://registry.khronos.org/vulkan/specs/1.3-extensions/man/html/VK_KHR_pipeline_binary.html)\n   * [VK\\_EXT\\_shader\\_object](https://registry.khronos.org/vulkan/specs/1.3-extensions/man/html/VK_EXT_shader_object.html)\n   * Click¬†[HERE](https://www.amd.com/en/resources/support-articles/release-notes/RN-RAD-WIN-VULKAN.html)‚ÄØfor more information about other Vulkan¬Æ extension support. \n*  \n* Mesh Nodes in Work Graphs via Microsoft Agility SDK 1.715.0 Preview\n   * Microsoft DirectX¬Æ 12¬†[Work Graphs with Mesh Nodes](https://devblogs.microsoft.com/directx/d3d12-mesh-nodes-in-work-graphs/)¬†support for AMD Radeon‚Ñ¢ RX 7000 Series graphics cards.\n      * View our accompanying blog post on¬†[GPUOpen](https://gpuopen.com/learn/work_graphs_mesh_nodes/work_graphs_mesh_nodes-intro/)¬†to learn more about Mesh Nodes in Work Graphs and how to enable it.\n      * Find our Work Graphs Mesh Nodes samples on¬†[GitHub](https://github.com/search?q=topic%3Ameshnodes+org%3AGPUOpen-LibrariesAndSDKs&type=repositories).\n*  \n* Fixed Issues and Improvements\n   * Intermittent driver timeout or application crash while playing¬†*Warhammer 40,000: Space Marine 2*.\n   * Intermittent driver timeout or application crash during certain cutscenes while playing¬†*FINAL FANTASY XVI*¬†on some AMD Graphics Products, such as the Radeon‚Ñ¢ RX 6600 XT.\n   * Overly dark shadows or desaturated colors may be observed while playing¬†*Black Myth: Wukong*¬†when Global Illumination is to Medium or higher.\n   * Intermittent in-game corruption may be observed while playing¬†*Ghost of Tsushima DIRECTOR'S CUT*¬†with AMD Software: Adrenalin Edition‚Ñ¢ Record & Streaming and HDR enabled.\n   * AFMF may become inactive after enabling certain on-screen overlays.\n   * AMD Software: Adrenalin Edition may unexpectedly initiate upon system wake from sleep mode.\n   * Audio and video may intermittently become out of sync while recording using the AV1 codec in AMD Software: Adrenalin Edition.\n\n# What to Know?\n\n**AMD Fluid Motion Frames (AFMF) 2**\n\nAFMF is a state-of-the-art frame generation technology exclusive to AMD. It enhances frame rates and gameplay smoothness and is integrated into AMD Software: Adrenalin Edition‚Ñ¢. As part of¬†[AMD HYPR-RX](https://www.amd.com/en/products/software/adrenalin/hypr-rx.html), our one-click performance solution, it delivers exceptional gaming experiences on AMD Radeon graphics cards.\n\n* **How to Enable AFMF 2**\n   * AFMF 2 can be enabled for any OpenGL^(NEW), Vulkan^(NEW), DirectX¬Æ 11, and 12 title using HYPR-RX or the AMD Fluid Motion 2 Toggle.\n      * AFMF 2 is supported on AMD Radeon‚Ñ¢ 700M and 800M integrated graphics, as well as AMD Radeon‚Ñ¢ RX 6000 and RX 7000 series desktop and mobile discrete graphics cards.\n      * AFMF 2 currently requires the game to be played in exclusive or borderless fullscreen mode with VSync disabled.\n      * Use the in-game overlay (ALT+R) in AMD Software: Adrenalin Edition‚Ñ¢ to check AFMF‚Äôs frame generation status.\n   * AFMF 2 adds frame generation technology to boost FPS outside the game‚Äôs engine. Users can enable the AMD Software Performance Metrics Overlay to see the resulting FPS. \n      * Users looking for a way to measure the response time of games can make use of our¬†[Frame Latency Meter (FLM).](https://gpuopen.com/learn/frame-latency-meter-flm-1-0/)  \n* **How to Optimize AFMF 2** \n   * AFMF 2 introduces new modes that are automatically tuned for the best experience based on your configuration. These can be manually adjusted to your preferences if needed \n      * AFMF 2 adds a new ‚ÄúHigh‚Äù Search Mode setting for improved frame consistency during fast motion, enabled by default for resolutions of 2560x1440 and above. \n   * AFMF 2 adds a new Performance Mode setting to reduce frame-generation overhead, enabled as ‚ÄúPerformance‚Äù by default for integrated graphics products.\n      * Integrated graphics users may switch back to the ‚ÄúQuality‚Äù performance preset for better frame-generation quality during fast motion. The ‚ÄúQuality‚Äù preset is the default when using discrete graphics cards.\n      * Users can manually enable this ‚ÄúPerformance‚Äù mode on discrete graphics cards to hit even higher frame rates when GPU bound to maximize the FPS uplift.\n   * Users can find these tuning options within the ‚ÄúAdvanced View‚Äù of HYPR-RX. ¬†\n* **AFMF 2 Support for Multi-GPU Configurations**\n   * For any hybrid-graphics configuration, AFMF 2 will use the displaying GPU for frame generation, allowing the render GPU to focus on the game. \n\n# Known Issues\n\n* Intermittent performance when entering certain areas while playing¬†*DayZ*. \\[Resolution targeted for 24.10.1\\]\n* Intermittent driver timeout or crash may be observed while playing¬†*Warhammer 40,000: Space Marine 2*¬†on some AMD Graphics Products, such as the AMD Ryzen‚Ñ¢ AI 9 HX 370. Users experiencing this issue can enable Variable Graphics Memory in AMD Software: Adrenalin Edition as a temporary measure (AMD Software: Adrenalin Edition -> Performance -> Tuning -> Variable Graphics Memory).\n\n# Important Notes\n\n* AMD is collaborating with the developers of¬†*Frostpunk 2*¬†to resolve an intermittent issue causing in game flicker while using AMD Software: Adrenalin Edition Record and Stream.\n* AMD is collaborating with the developers of¬†*Warhammer 40,000: Space Marine 2*¬†to resolve an intermittent issue causing black flickering around certain water areas",
    "comments": [
      "I Hope the bug when the app is opening after the sleep fixed",
      "It's fixed üëç",
      "Polaris and VEGA:\n\n**Fixed Issues and Improvements**\n\n* Increased memory usage may be observed while playing certain versions of Minecraft Java Edition.\n* Some DirectX¬Æ 12 applications may experience an app crash with Windows usernames containing certain non-English characters.\n* Intermittent flicker around the borders of windows placed over Microsoft Teams.Highlights Fixed Issues and Improvements   Increased memory usage may be observed while playing certain versions of Minecraft Java Edition. Some DirectX¬Æ 12 applications may experience an app crash with Windows usernames containing certain non-English characters. Intermittent flicker around the borders of windows placed over Microsoft Teams.",
      "\"AMD Software: Adrenalin Edition may unexpectedly initiate upon system wake from sleep mode.\" \n\n\nGood. This was annoying me more than it should.",
      "Holy shit they fixed the AV1 issue",
      "Does anyone know more information about the Geometric Downscaling stuff for video? I'm curious on what its like versus regular scaling algorithms.",
      "Yea we finally get a September update in - *checks calendar* - October.",
      "Finally üëçüëçüëç",
      "Not mentioned in the notes but they added a new ‚ÄúFreeSync Color Accuracy‚Äù toggle under Display Options for my FreeSync Premium Pro monitor that fixed my HDR‚Äôs washed out colors.\n\nEdit: It doesn‚Äôt seem to have fully solved the issue. Still getting washed out colors in some apps.",
      "9.1 but on 10/1 ü§î",
      "I thought I was just going crazy. I tend to have the app open on a monitor for metrics but I could have swore I closed it, and it somehow kept being there.",
      "Finally.",
      "Good to see that they are working with the devs to fix issues!",
      "lets hope its actually fixed, been waiting a year+ for it",
      "Bit off topic, but I also have the 6900 xtxh. I'm curious as to what your temps are under load. As in when the card is really being pushed.",
      "wow lots of stuff fixed",
      "It was just excited to see us when we came back :)",
      "The blog post has a little more info on it\n\nhttps://community.amd.com/t5/gaming/boost-gaming-performance-by-2-5x-with-amd-software-adrenalin/ba-p/711458",
      "Shouldn't it be 24.10.1? XD",
      "it was packaged before today"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6600"
    ],
    "title": "Neowin: Radeon RX 6600 XT MSRP is 349 USD, RX 6600 to cost 299 USD - VideoCardz.com",
    "selftext": "",
    "comments": [
      "Ohh look we'll finally get GTX 1080 class performance for sub 300 USD. 2 years after it actually supposed to happen.",
      "You already got GTX 1080 performance at 280 dollars last year with the RX 5600 XT.",
      "Radeon RX 5600 XT already delivered that for $279",
      "The GTX 1080 performs about the same as the RX 5600 XT and the RTX 2060 in general, or slightly worse in newer games where Pascal falls behind. In general, the 5700 ranges between 5% to 10% faster than these other 3.\n\n[Source: the last TechPowerUp review that still included the GTX 1080 numbers, dated from March 5th.](https://www.techpowerup.com/review/zotac-geforce-rtx-3080-amp-holo/28.html)",
      "AMD is done being the budget vendor. They buy high end silicon from TSMC and turn it into high end products. They don't have the supply to serve the volume market, anyway.",
      "If you have to hope that Intel comes to your rescue, you have to be pretty desperate.",
      "6600xt has a slightly smaller die size than the $279 5600xt yet is $70 more expensive lol. \n\nThank you AMD and Nvidia. Thank you for abusing your duopoly",
      "I don't get how it's meaningless, this is AMD charging  $349-$399 for a supposedly low-mid range card. Not any greedy retailers or scalpers, that's AMD themselves. And this price may very well be the standard price for low-mid range cards from now on. $350 for 6600 XT though? That's $50 more than it should be. At least.",
      "So it‚Äôs safe to say that we will no longer see a sub $200 price tag for entry level GPUs?",
      "It's also important to note that not all RX 5600 XT cards have the 14 Gbps memory out of the box. Only the most high end models does so and the lower end cards have to get their BIOS [manually](https://www.tomshardware.com/news/amd-encourages-radeon-rx-5600-xt-owners-to-upgrade-memory-to-14-gbps) by end users. I get your point with the 5600 XT can achieve GTX 1080 level of performance but the ones with the 14 Gbps memory generally costs more than \\~320 USD two years ago.",
      "There's a team of financial analysts who says it is.\n\nOr more accurately, they know it's not and it'll sell out anyway.",
      "TSMC hasn't been making high end silicon for all these years. Most of the time in their company history, they've been behind. They are the first team to really figure out EUV, and now they are the high end player.\n\nRight now, team red is using better silicon than team blue and team green, at least in the consumer market. That better silicon comes at a premium price, and it's why red products are so attractive. As long as this is the case, AMD products will not be cheap.",
      "Nope\n\nRadeon RX 5600 XT is slightly faster than GeForce GTX 1080\n\nhttps://www.techpowerup.com/review/powercolor-radeon-rx-5600-xt-red-devil/27.html",
      "Good point, I completely forgot about that whole memory debacle back on launch.",
      "Man I'm really not looking to pay for 300+ for a 8gb VRAM card. I really really don't want to buy NVIDIA because I have a NVIDIA card and it runs like shit on LINUX, but the competition from AMD is so bad.",
      "Agreed, its about the same size as an RX 580 die, but that's a different process node, so comparing to the 5600xt is an even better comparison, especialyl requiring similar power targets.\n\nGamers are getting F'd in the A.",
      "Dang, not really worth :+",
      "I think both of them are testing the waters with the more \"aggressive\" pricing. \n\nIt definitely looks like Nvidia regretted not pricing the 3080 and 3070 higher so they released the TI versions lol.",
      "I think it's the line you draw from when it's entry level. Some might say anything below 1440p ultra settings is entry level while others would see an integrated mobile gpu as entry level. GTX 1080 level is pretty decent, it's twice as fast as my RX480 (for roughly 260$ back in 2016), but on the other hand we had RX 5700 (XT) in the range from 300-400‚Ç¨ some time ago on the market which was also pretty neat. I wish I didn't miss the Superbowl event in Germany, 5700xt sapphire top notch model for like 370‚Ç¨ incl taxes with the best cooling solution from all the 5700 models. Right now is such a sad time being a pc gamer that I rather went for the XSX.",
      ">Right now is such a sad time being a pc gamer that I rather went for the XSX.\n\nI think it's only a sad time to be a DIY PC gamer. Gaming laptops are the best they've ever been. Prebuilts are trending somewhat more expensive than you'd like, but SIs aren't anywhere near DIY prices. Typically, they can get you a PC with a 3080 in it for close to 3080 street price. In shortage conditions, retail eats last.\n\nThat being said, XSX is the best Xbox ever. They are finally building systems that offer a gaming experience I'd actually want. What's more, Xbox Game Pass is a phenomenal value that really addresses the game cost problem Xbox had compared to PC gaming."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6600"
    ],
    "title": "AMD Radeon RX 6600 Final Specifications and Official Performance leaked - VideoCardz.com",
    "selftext": "",
    "comments": [
      "Hard to be excited about GPU these days. Would have been interesting, at $250.",
      "I received an email promo from Newegg the other day for a **$250 Geforce 1050 ti**. I was shocked... That card should be $50. Hell, if things were normal you couldn't even buy one of those new anymore.",
      "IF we were in normal times the 6600 would likely be 200 and the 6600xt only 250, :(",
      "Not that MSRP makes any difference these days.\n\nBut this really needs to be priced below the 3060. It offers similair performance, less in RT and has less features. Aswell as less VRAM.\n\nIn a normal market this card would have been 250-270$-ish. But since the market is fucked AMD will just prices it the same as the 3060 and the scalped prices will be over 400$ anyways.",
      ">This card should represent close to 2X performance of a RX580, which is a huge uplift for those holding to their RX580 or 1060.\n\n2x the performance for 2x the msrp is not exactly an improvement, also considering that the actual price will be even higher.",
      "I actually think this is a GPU worth being very excited about. Depending upon availability, this could be the most important GPU release this year. It is worth remembering that the 6600XT had pretty good availability, particularly in Europe, Australia and the UK. \n\nThis card should represent close to 2X performance of a RX580, which is a huge uplift for those holding to their RX580 or 1060.\n\nAs for the price, my advice is to buy it early. Buy in the first 5 minutes.  That is how I got a 6600XT for 400‚Ç¨.",
      "Only AIB models, no reference card, so will not be on AMD's shop.",
      "Its the only one in stock? Besides, amd can simply drop $80 off its price once stock fixes itself. No big deal.",
      "RT performance is not that  bad because all of the games in the list have very light RT effects compared to other games with RT.\n\nWhen games with heavy RT effects like Watch Dogs : Legion or Cyberpunk 2077 is used , performance will drop badly if I have to guess .",
      "It's essentially the same die size as the RX580, but instead of GloFo 14nm, they're now using TSMC 7nm.   I wouldn't be shocked if the die cost is literally double what it was for the 580.  Of course this is a cut down version, so it wouldn't be the full cost difference, but probably still a good chunk more.  And then it has GDDR6 over GDDR5.  Perhaps if memory prices had actually come down a lot since 2016, it wouldn't be such a big deal, but they sadly haven't.  \n\nI'd be very surprised if this was actually cheaper to make than a 580.",
      "Why do you think it will be more expensive? Because of the MSRP? How many 3060's have you found at MSRP.",
      "This will be cheaper to build than RX580.",
      "379 vs 329. it's priced 20$ below the 3060 tie, but the 3060 tie is definitely worth the 20 bux",
      "The RX580 had a MSRP of $229. The MSRP of the 6600 won't be $458. It will most likely be $329 or lower. As for how to get it at a decent price, I have already outlined: buy it early.\n\nBesides, owners of RX580s are sitting on top of $400-450 (value of a RX580 to miners), and could get an upgrade to the 6600 pretty much for free, provided that they are fast enough.",
      "Yea, it will cost less, mine the same and use like 5w less power than the xt so yea pretty attractive.",
      "I bought a 3060 for 320 from EVGA. The cheapest 6600xt I have ever seen was at Microcenter for 560 dollars.",
      "RT perf is not bad at all. 132W is really good................for mining",
      "The 6600 XT is already priced lower than the 3060, you mean it needs to be priced below the 6600 XT?",
      "First of all you yourself know this wont be 250.\n\nSecond i would actually pay 350 for this if its at MSRP launch day.Because im starting to believe there wont be a 6500xt or 3050ti except when the next gen cards launch.But i also doubt this will be 350 launch day, so i doubt ill even get that.Maybe rising prices in energy,in the EU will mean that this wont be bought up by miners literally in the first 2 seconds and so i might get 1, but i doubt it.\n\nI just want to play Warzone and my rx 570 4gb cant really do that, it looks very bad.So its fine.Ill prob keep this for a few years and then sell it for 100 euro and add 150-200 more and get a normal card when prices come down and im willing to take this kind of hit.",
      "6600 more expensive than the 3060? In what world is that? Not even the 6600XT is more expensive than the 3060."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "low",
    "matched_keywords": [
      "6600"
    ],
    "title": "AMD Radeon RX 6600 Review: The Best/Worst GPU You Can Buy",
    "selftext": "",
    "comments": [
      "Hot garbage...  I thought maybe if they drop it close to MSRP where I live, but after seeing this... in some games slower than RTX 2060 / 5600XT at +$30 MSRP compared to 2+ year old cards... Oh man, situation sucks ass and retailers will likely launch this crap at 500‚Ç¨ here making it even worse than it is on paper.\n\nEdit: even worse: https://www.komputronik.pl/product/737159/msi-radeon-rx-6600-mech-2x-8gb.html which is 570‚Ç¨, fucking lul",
      "This is such a never-ending nightmare",
      "This is just depressing. 5700 could be found regularly in the US for less then this MSRP. I bought a 5700xt for 350 with a rebate and it came with 2 games literally a year and a half ago. \n\nAt least the 3060 ti and above were leagues better for their predecessor. A 3060 ti for 400 outperforms a 2080 super by 10 percent. So at least paying twice MSRP isn't horrible compared to getting a 2080 at launch for the same price. \n\nBut this is literally a regression in performance for more money...",
      "Welcome to 2021.",
      "There's a simple solution: don't buy a card unless you have to. Get the most that you can out of the card you already have.",
      "Don't be fooled, there is always an initial stock of GPU's that's subsidized by the AIB's so they can advertise the MSRP. This was uncovered by Tweakers.net during the launch of the 6600XT. After the initial batch is sold out (the batch is very small), the prices will go up significantly. For example the 6600XT launched very close to MSRP in Western Europe with seemingly decent stock, but less than a week later all of those subsidized cards were gone and the only ones in stock now are well above MSRP (the 6600XT is over 750 USD in the Benelux and Germany right now). NVIDIA isn't doing any better, the 3060 is around that price as well.",
      "10% faster than the 5600XT, 14% slower than the 6600XT. More-or-less on par with 3060, 5700 and 2070 performance-wise. It is worth remembering that HUB doesn't use SAM, so results with SAM might be more favorable.\n\n330 USD *\"MSR-LOL-P\"*\n\nThis card, its performance and its price, surely is not for everyone, but for RX 580 and 1060 owners, this represents a massive upgrade, about 2X raw performance and DirectX12 Ultimate support.\n\nNow I know the argument: *\"I paid $230 for my 580 4 years ago, I am not paying 400+ bucks for an upgrade for 1080p gaming!\"*. The solution to that is: *\"why not sell your 580 for 400+ bucks, in the second hand market?\"* At least back in August, you would find a buyer in a heartbeat. Not sure how the second hand market is now, but I assume it hasn't changed much. As bad as new GPU prices are nowadays, so are the prices of used GPUs, and anyone looking for an upgrade should use that to their advantage. If done timely, an upgrade like this could cost very little, if anything.\n\nAh, and for the \"no chance in hell the 6600 will land in the stores for less than 2X MSRP\", it actually did. 349 euros in a local store, in stock. I checked again 15 minutes later, it was still there, 20 minutes later, gone. Still, I took a [screenshot as proof](https://ibb.co/1bxTb4q). If you are actually dead interested in buying a GPU, you can't wait a month, you have to pull the trigger the moment it drops. This is true for the most recent releases as well as for GPUs releasing in the foreseeable future.",
      "Not sure why you are getting downvoted... the current market dictates the price, AMD could have priced it at $199 and the market would re-adjust it to $500 in 2 weeks.\n\n\nIt's a 1080p card with DX12 ultimate support and 8GB of vram, while using only 120watts. Add to that HDMI 2.1, AV1 decode and most models are really compact.\n\n\nThis is the reality, but people have hard time listening to reason when they are angry...",
      "‚Ç¨349 here in Finland. In stock. Not for long, I am sure.",
      "I'm kinda past that point with RX 470 I never ever thought I'll have it for 5 years... best 220‚Ç¨ ever spent and it was premium model (Gaming X) and still was dirt cheap..",
      "Assuming it works, a GPU is never simply \"bad\" by itself, it depends on its pricing. If the performance was close to 5600XT but at a significantly lower price than the 5600XT, then it would be a very interesting product. However, if you're releasing a similar product at a similar price, that shows no progress whatsoever. So people aren't simply trashing its performance... they are thrashing its performance considering how much you have to pay for it.",
      "There are lots of benefits for having 2.1 - you should read up..",
      "[Article on techspot.com](https://www.techspot.com/review/2343-amd-radeon-rx-6600/).\n\n#Timestamps:\n* 00:00 - Welcome back to Hardware Unboxed\n* 04:52 - Test System\n* 05:33 - F1 2020\n* 06:28 - Cyberpunk 2077\n* 07:10 - Death Stranding\n* 07:53 - Horizon Zero Dawn\n* 08:25 - Rainbow Six Siege\n* 08:51 - Watch Dogs Legion\n* 09:20 - Power Consumption\n* 09:38 - Average 1080p\n* 10:13 - Average 1440p\n* 10:27 - Final Thoughts",
      "I trued to get 6800xt at launch. I had multiple bots alerting me of stock but it was always out of stock as soon as I would try to buy. Randomly at 2am on a Tuesday, i found a xfx 6800 non XT. It was 150 over MSRP because it was their Merc series with a big cooler. After taxes and shipping I paid $800 for a 6800. I felt a bit ripped off but  whatever. This was in Dec 2020. I can now sell that card for 1200 easy. I feel that cards are harder to find and for as \"low\" as 150 over MSRP is literally not possible. Everything is like 250-1000.",
      "I think people, most reviewers included, think that we live in 2019, and that MSRP is set in stone, and perhaps even that AMD is a non-profit organization.",
      "Indeed, I know about these early subsidized batches. That is how I got a 6600XT for 409 euros. One should take advatange of them while they last.",
      "Immoral? The fuck lol. What on earth is immoral about basic economics.\n\nI guess it‚Äôs also immoral to sell your nvidia stocks for 4x 2019‚Äôs stock price.",
      "Whoever is buying a 580 for 400 bucks in 2021 is a miner. You would be ripping off a miner. What is morally wrong with that?",
      "There is more to it then just 1080p gaming, I would recommend you read an article on why 2.1 is great to have in a gpu.",
      ">\"why not sell your 580 for 400+ bucks, in the second hand market?\" \n\nThis is how I was able to get a 6900xt. Sold my Vega 64 for $700 which almost paid for the 6900xt which is still crazy to me."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6700xt"
    ],
    "title": "RTX 3060 will be mining limited to 50%. Will AMD do the same with 6700XT?",
    "selftext": "Nvidia annunced CMP (Cryptocurrency Mining Processor) and stated that RTX3060 will be limited in mining algorithms by -50% to make the card substantially useless to miners, so there is hope that all the cards will be purchased only by gamers.\n\nI think that AMD should do the same with 6700XT / NAVI22 as today is too late to block NAVI21 by drivers\n\nI know that AMD want to sell all its cards nevermind where they go, but if they *really* care to gamers, that's what they should do imho. What do you think?",
    "comments": [
      "AMD's drivers are open source on Linux, so no driver level limitation will be effective, unfortunately.",
      "Pros of open-source software:\n\n* The company can't control the software\n\nCons of open-source software:\n\n* The company can't control the software",
      "Assumption: If Miners buy Mining cards and Gamers buy Gaming cards, everyone wins.\n\nReality: Scalpers buy all of the cards.",
      "Let's face it. It's a matter of time for when miners write a BIOS that unlocks the 3060's full crypto mining power.",
      "This is such a marketing exercise and will probably be either mitigated within days or just completely avoided by shifting the miners to buy higher priced products",
      "In all seriousness, I'd give it a month *tops* until that happens. It's similar to how NVENC is limited to two HW-accelerated encodes on consumer hardware (unlimited on Quadros), but a quick driver patch eliminates that. It's just a matter of time, and an absolute waste of resources on Nvidia's part. It's like DRM all over again (and we all know how well DRM works - it doesn't).",
      "Win",
      "Not with RDNA, but it used to be god tier, Rx4\\*\\*/5\\*\\* 8GB and Radeon VII were so good they are worth more today than 2 years ago.",
      "AMD's mining performance are not even that good compared nvidia",
      "Scalpers can only buy when there is ample supply, usually before the supply problems are evident. So essentially they're taking a gamble before there is a problem with supply.\n\nHowever, especially with Nvidia, there is just such a massive problem with manufacturing and supply that NO ONE is getting cards, and the few that are out there do not match the demand. You can't scalp if there are no cards to scalp, lmfao.",
      "Nvidia want to cater miner but at the same time dont want to hurt gamer. So they release gpu for miner and please gamer by announced driver limitations. Imagine if they announced only gpu mining today? Many will upset and mock them. This is just pure marketing.",
      "5700/5700xt are excellent for mining. RDNA2 is just not that good because of the bandwidth but still good enough to mine with at current crytpo prices.",
      "Yeah, it is all marketing.  And the real reason for them doing it is because it is more profitable for them to segregate the market.  They really don't care about gamers, but they can spin it to get in good graces.  They did something similar back during the first mining craze.  They released a statement saying mining bad, we love gamers, but were selling their supply directly to farms.",
      "You're talking about an ASIC, most crypto algorithms are now developed with one of the goals being to fuck with ASICs e.g. being caching resistant and memory intensive or being able to modify it's algorithms while retaining the rest of the infrastructure so developing an ASIC is not feasible. It really underlines how fucked up the entire concept is - we are *deliberately* making the processing as fucked up and power intensive as possible because if specialized hardware could do it for a fraction of the power and time *it wouldn't be worth doing*.",
      "They can't really do that, firmware does not get that degree of control.",
      "Yes, I'm all for open source and I find this a weird movie by Nvidia. I haven't found yet what they're going to do to hurt miners...\n\nI mean mining software just uses CUDA but CUDA is used for A LOT of stuff. I think machine learning is likely a much bigger market than mining. Even if you add 3D rendering or CFD programs. GPU's these days have enough ram so you don't have to buy the more expensive business ones. (yeah ECC ram is still a thing but a lot of workloads can work just fine with the occasional wrong output)",
      "What is stopping Nvidia or AMD from stopping at mining? \n\nThis game wasn‚Äôt sponsored by Nvidia/AMD. It‚Äôll only perform 80%.\n\nThis game might be cracked, so you‚Äôre locked to 15 fps. \n\n\nThis is a dangerous path to go down and it is concerning the amount of people jumping on board. \n\n\nYes, fuck the big miners buying up all of the supply, but this is not the way to solve this problem.\n\n\nEDIT: checked the specs for the new mining cards from Nvidia. The 30HX is less efficient than a 2017 RX580 omegalul",
      "Watch the custom driver someone puts out funnel 1% of the processing power to the themselves.",
      "Why is it unfortunate that things aren't artificially limited?\n\nThis is like bizzaro world.",
      "beside the 3060, if someone will produce mining hardware that cost LESS than a VGA the job is done"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6700xt"
    ],
    "title": "Yeston 6700xt",
    "selftext": "",
    "comments": [
      "Weeb XT.\n\nOnii chan approved edition.",
      "I remember seeing this card being reviewed at Gamer's Nexus and they said it smelled of perfume. Is it true?",
      "If anime girl feet smells like strong perfume, than yes it does",
      "Yes",
      "These GPUs are so pretty, I just wish they didn't cost as much as a 6800XT.",
      "Yeah man, waifu tax is crazy. Their 6800XT is more than what my red devil 6900XT cost.\n\nThe design is very good though (IMO)",
      "Dawid Does Tech Stuff calls cards like this \"Waifu cards\" lol",
      "I can smell the perfume over the internet",
      "Honestly the card looks infinitely better than the usual, generic GPUs with edgy and gamer design. Wish they'd produce more cards like this one.",
      "I like how Yeston at least tries something different than the rest. Yeah it's not to everyone's taste, but it's different",
      "GN too lol",
      "With jizz-resistant cooling shroud for easy cleanup.",
      "More like there ain't a whole lot of these",
      "Cause they know neckbeards will pay anything.",
      "Meanwhile cards in the west be like \"ASUS TUF GIGABYTE EXTREME DRAGON GAMER\"\n\nCards in the west are cringey as fuck.\n\nGive me some variety. At least Yeston has personality to the cards.",
      "Fully commit.",
      "Cookies+Trackers",
      "Is it difficult to make a whole build around it? Cause the color scheme of the backplate and the fan side looks rather difficult to put together with a proper looking mobo and case, at least I couldn't think of something fitting",
      "The amount of hate because someone has variety is crazy üòÇ \n\nSub is ridiculously toxic \n\nEnjoy your card man. It's way better than the usual bland graphics cards.",
      "redditors say the word woman challenge (impossible)"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6700xt"
    ],
    "title": "Goodbye to my dear RX 570 that kept me afloat during the GPU price pandemonium. Time for 144fps with the 6700XT!",
    "selftext": "",
    "comments": [
      "In 2017 I splurged $600 for a brand new EVGA 1080TI with Destiny 2 from Newegg because I needed a new card and wanted the game. At the time I thought to myself what a mistake spending so much on a video card, and hoped it would last long enough to justify it.\n\nHere I am 5 years later seeing top of the line cards going for $1000+ during the dark times, my card still kicking and looking to maybe get something new towards the end of the year, happy that AMD offerings are much more viable now as well!",
      "I went from an r9 390x to an 6700XT and the difference in performance is absolutely insane. Great GPU for sure.",
      "Gtx 1080ti is one of the few that justified it's price",
      "Congrats. The 6700XT is a great card. I had one for a while and loved it.",
      "I recently swapped out my 6700 XT for my old 570 4 GB just to see how well it holds up. I was surprised just how badly it struggles today. The 6700 XT basically gets exactly 3x the fps in most titles. \n\nI used the 570 for 1440p gaming for a while in 2019. And now you get like 20 fps at that resolution. Although Elden Ring managed to run at 30 fps at high settings.",
      "Ironically I actually bought an even more powerful power supply after watching a linus tech tip video. The idea is even if I only use 50% of its capacity it will run cooler and be more efficient than a lesser wattage power supply running at 90% all the time. Seemed logical to me so I'm giving it a shot.",
      "Meet the new sapphire, *very different from the old sapphire*",
      "Nice upgrade, I‚Äôm running a 5700xt and have been toying with the upgrade to the same card as yours for a while. Enjoy it",
      "I went a couple of steps lower, with a 6600, but Still a salute for the 570, a Magnificent card that carried us all through Mining-mania.\n\nHere's to the GPU that could!",
      "Is the 570 that much worse than the 580? I'm running all my games at 1440p fine on a 580, even AAA titles like far cry 6 and whatnot, though obv at max medium settings.",
      "[But what a lifespan it was.](https://imgflip.com/i/6ofycb)",
      "The 1080ti was an absolute beast of a card, especially for it's price. It still works just fine for 1080p gaming, although it's definitely nearing the end of it's lifespan.",
      "A third of the power? Nah.\n\nSure, 390X is 275W (or 350W when OC'd. Or 200W when undervolted), but 6700 XT are also 220W GPUs.\n\nIt would take a 6500 XT to use a third of the power of a 390X. Or a 6600 when undervolted.",
      "He upgraded. I had one too and it was great for me as well",
      "I had the opportunity to get a 6800XT Gaming X Trio and jumped. My first high end card and its amazing. Flipped my 6700XT Mech2X to offset cost. It's a pretty significant performance increase. I wanted the extra performance for the long term, as this card will go into my sons PC down the road. Nothing wrong with the 6700XT, it's an awesome performer and super efficient",
      "o7 \n\nI upgraded from a 580 to a 6800XT a few months back, and it was a heck of an upgrade. You're gonna love the new card!",
      "That card's got at least another year in it. Maybe two :)",
      "I have the 8gb 570 still in my desktop, and while its showing its age it still holds up pretty well even in recent AAA games. Medium settings for most at 1080p is fairly consistent 60fps.\n\nI use it mostly for streaming older games to my laptop that I havent bothered installing on it though. GF plays AC Valhalla with it too, 50-60fps with settings turned down a bit. It isnt terrible...",
      "Massive upgrade.",
      "Yea everyone loses their minds over nvidia cards (not knocking because I know the reputation precedes) but act like AMD is nothing. I was lucky to snag an MSRP 6800xt in spring 2020 from the direct sale site, upgrading from a Sapphire HD 5870. I‚Äôve loved every minute of it, and look forward to AMD staying in competitive in the GPU market."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6750xt"
    ],
    "title": "I painted my new XFX RX 6750XT for a white/violet build.",
    "selftext": "I've a white and violet/pink build in a Lian Li 011D Snow Mini and recently received my new XFX 6750XT and decided to give it a new paint job to fit the theme. I am by no means an expert when it comes to spray painting and, honestly, after those first coats I realized I should've done way more prep.\n\nPaint job's not perfect, but I call it good enough for my first attempt at it. \n\nFor those wondering, I'm upgrading from an RTX 2060. I wanted to go for the RX 6800 or RX 7700XT but the prices on those were astronomical everywhere I looked. ",
    "comments": [
      "I've always wondered if painting backplates hurts the thermals.",
      "I read that painting backplates does lose you some heat dissipation unless it's a specific kind of paint that helps with thermal transfer. Basically the same stuff they have there originally. I'm not too worried because this GPU will have plenty of fresh air.",
      "Do you loose warranty? I would buy a separate shroud for that",
      "Yeston card would fit right in the theme. Glory to the waifu card.",
      "I do lose warranty because I scuffed the original surface before applying spray paint.",
      "most backplates do nothing for thermals anyway because almost no manufacturer puts thermal pads on the back.",
      "Ayy also upgraded from a 2060 to a 6700xt, I couldn't get anything betterüò≠\n\nPaint looks lovely!",
      "There's really not much to it, teardown the GPU and use a scotch brite to scuff all the parts, then use some compressed air or a microfiber towel to get the loose debris off and wipe each part down with isopropyl alcohol.\nBe sure to wear gloves so the salts, sweat and grime from your hands don't leave traces. \nAfter that use some wire or whatever you have lying around that can fit through the holes in the plastic pieces so you can hang them, I hung mine on a clothes drying rack inbetween coats.\nWhen painting the first two-ish coats are very light, you just want some paint on the pieces so your next layer has something to grab on to. After that you give it a tiny bit more paint each time but overall you're shooting for at least 5 coats. Wait until each coat dries, should be about 20 minutes.",
      "I'm sure it'll be negligible for us regular folks. Unless ur trying to hit some record OC on the card, I would not worry at all.",
      "I came to mention the waifu card as well.\n\nThen OP replies and skirts right over the topic...",
      "Not sure what OP used.. but use plasti dip and it peels right off. No mess and no damage.",
      "Oh the 6700xt is WAY better than the 2060, I was getting 50%+ more frames. Part of it is the 2060 only had 6gb of vram as opposed to 12 with the 6700xt. Also my CPU seems to be less bottlenecked, it used to be my GPU could be pinned at 100 and my CPU's only running at 40-50%, and now my CPU consistently can get to 85-100% depending on the game",
      "It was a full teardown. The front shroud comes in two pieces and the backplate has 3.",
      "Montana Colors - Hardcore series, graffiti paint.",
      "IKR. I don't even know what to reply...",
      "One caution, I used white plasti dip on my 2080ti, and within 3 months the white had yellowed to a really ugly off-white/beige color. \n\nSmoke-free environment too. Just something about the white plasti-dip that doesn't hold its color over time.\n\nFlex Seal didn't have this problem but it has a slightly different consistency and is a bit shinier. YMMV.",
      "For anyone interested in what the build looks like currently as it's still got a bit of progress to go [Lian Li 011 Dynamic Mini](https://imgur.com/rscrq2H)\n\nI went with an air cooler because there's no pump that can die and waste 80 euros. As of right now there are no top exhaust fans because I've given my spare Lian Li fan to an acquaintance to 3D print fan shrouds that will offset the chassis fans by 15mm because they are obnoxiously loud due to air resistance from the chassis mounts.",
      "a very well done paint job makes me leave a comment everytime. someone hire this person !",
      "It's a decent card but I'd only buy it if it was closer to 350 euros. Currently it's about 410, but you can get a 7800XT for 470 which is much better. Really, it all boils down to your needs and how much you wish to spend. \n\nI could've gone with a 7700XT or a 7800XT, but after looking over benchmarks and asking around, I realized I'd much rather get a 6750XT and save myself a 100 euros that I can invest somewhere else in the build. I don't play on 4K and I don't have a 1440p monitor either. I also don't plan on getting a new monitor in the upcoming years so I'm playing at 1080p and for my needs the 6750XT is plenty and then some.",
      "I did try to fly over the waifu cards. Here's my problem with them, it's not that they hare colorful or have anime girls on them - it's the fan shroud on the Yeston. It's so bad."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6700xt"
    ],
    "title": "The RX 6700XT isn't just a $20 cheaper RTX 3070.",
    "selftext": "I keep seeing people say that the RX 6700XT is just a cheaper RTX 3070, but it's not as simple as that.\n\n1. The RX 6700XT does not have a viable DLSS 2.0 alternative. Some people may argue that DLSS is irrelevant, but I think not. DLSS has come to a point where it is a viable feature to use in order to achieve smoother frames and higher resolutions when your hardware can't do so. For example, I have a 3060 Ti and I use it in Cyberpunk. Without DLSS, I am unable to reach a steady 1080p 60FPS with everything (including RT) on Ultra/Psycho settings. With Fidelity FX still being quite lackluster, AMD needs to launch a DLSS alternative soon.\n2. The RX 6700XT also has a lower memory bandwidth. The RTX 3070 has a 256-bit BUS and the RX 6700XT has a 192-bit BUS. I know this is not important to most people, but it still can be useful to have a higher bandwidth. (Edit: I forgot about the 96MB of Infinity Cache, so don't take this point as seriously.)\n3. The RX 6700XT is expected to have noticeably lower Ray Tracing performance than the RTX 3070. Of course, this is due to AMD being on its first generation of RT cores, while Nvidia is on their second. While not everyone uses RT, it has become more and more popular in games.\n4. The RX 6700XT has an extra 4GB of memory. This will make the 6700XT better in some tasks that require more VRAM, such as higher resolution gaming and workstation tasks.\n\nAm I saying that the RX 6700XT sucks? No. I actually plan on switching back to AMD Radeon and buying a 6700XT or 6800 for SAM and Radeon Software (note: Radeon Software ‚â† Drivers), but I will say that the 6700XT is slightly overpriced. With that said, if you manage to find a 6700XT for a reasonable price, you should definitely buy it. I don‚Äôt need to explain why.\n\nEdit: As u/Excsekutioner and u/HaloLegend98 said, the absence of a good video encoder like Nvidia's NVEnc is also a point.\n\nEdit 2: I‚Äôm not trying to start a war between Nvidia and AMD users or start an argument about whether DLSS, NVEnc, and/or RT is important. Some people use and like DLSS and RT, and some people don‚Äôt like DLSS and RT. Some people like AMD cards and some people like Nvidia cards. We should respect each-other‚Äôs opinion and not force or criticize people into changing their opinions. I‚Äôm just laying out the facts on the 6700XT compared to the 3070 and why‚Äôs the 6700XT is not just a $20 cheaper 3070. And again, I‚Äôm not an AMD hater, I use or have used both Radeon and Ryzen and had decent experiences. I‚Äôm also not a Nvidia or Intel hater, and I have used Intel and Nvidia products before as well and had decent experiences.",
    "comments": [
      "Nothin real interesting about these announcements, the performance's kinda expected. It'd be something if they showed superresolution a lil but nope",
      "As a 5700XT owner, I'm skipping this generation. On both sides + the mining shit show.",
      "No super resolution info Is a disaster",
      "Thanks to Infinity Cache, the effective bandwidth of the RX 6700 XT is actually higher than it seems. I agree with your other points though.",
      "If I‚Äôm being honest, the 5700XT will still be solid for another 2-3 years for 1440p or 4-5 years for 1080p. Look at the Vega 56. That GPU is like 4 years old now but still solid at almost any title @ 1080p with high settings.",
      "You don't really need the \"tensor cores\" or \"ai hardware\" to do DLSS, the inferencing work doesn't need to be matrix based and if anything the reliance on convolutional/DL math is less in DLSS 2.0 than it is in original release DLSS (if any at all). It is clear there was a paradigm shift in how DLSS was being designed and implemented - from being actually Deep Learning network that compares scene elements to a model and determines \"what belongs here\" to a pattern based sharpening effect. \n\nSince DLSS is black box we will never know how much it actually relies on \"tensor cores\", but I would be very surprised if end users are really gaining much benefit, if any at all, from the tensor cores. I would instead postulate it is artificially locked behind tensor-core-having cards.\n\nI do think the original DLSS release did legitimately use matrix networks to do content matching.",
      "Without the AI hardware (Tensor cores doing the job) I don't expect their FidelityFX super resolution be on par with DLSS 2.0, anyway, tbh.",
      "Better and open source drivers on Linux.\n\nThat's the main reason why I bought a RDNA2 GPU over any of the NVIDIA cards.\n\nThe hardware isn't everything.",
      "**you forgot a very important point!** and it is that at least Nvidia offers you good Video encoding performance while AMD is straight up horrible; for example a 1650S is better at video rendering, encoding, streaming and timeline performance for both H.265 and H.264 than a 6900xt thanks to cuda support and Nvenc... That is insane.\n\nEdit: I forgot the 1650S also offers really good Fusion performance while AMD cards are just bad, my 5700xt is the living proof of this :(",
      "I think we can safely assume there won't be anything coming this gen. I thought Raja was an expert in false promises but this new guy is far far worse.",
      "5700xt gang once again they called us madmen for how drivers acted look at us now!",
      "Did people forget the memory bandwidth of the Vega cards? It‚Äôs not a significant performance determinant alone",
      "Or look at rx 480",
      "Please go read up on tensor cores, they are actually different and you can‚Äôt do dlss as quickly without them. https://www.techspot.com/article/2049-what-are-tensor-cores/",
      "> The RX 6700XT also has a lower memory bandwidth. The RTX 3070 has a 256-bit BUS and the RX 6700XT has a 192-bit BUS. I know this is not important to most people, but it still can be useful to have a higher bandwidth.\n\nThis isn't really a positive if the performance ends up the same or similar. Unless you mine.\n\nAgreed on the rest though.",
      "Look at the rx 570",
      "And funnily enough Raja might pull a pretty decent Xe lineup this year.",
      "Something, something, fuck you Nvidia, something",
      "Oh great, here we go again.\n\nI swear, these \"hear me out\" opinionated posts are worse than the battlestation ones.",
      "My main uses are gaming and debugging, I also use it for study/work and watching multimedia\n\nThe AMD drivers are open-source, on [Mesa](https://www.mesa3d.org/) which is a set of community driven implementations for APIs such as OpenGL and Vulkan. You have `radeonsi` which is an implementation of the OpenGL API and `radv` which is an implementation of the Vulkan API. \n\nOther than that, there's the [amdvlk](https://github.com/GPUOpen-Drivers/AMDVLK) (note: the actual code is on a different repository) implementation, which is an implementation of Vulkan by AMD and also open-source. It's similar to the implementation of Vulkan they use on Windows, so this is useful to debug driver bugs that occur on the proprietary drivers in Windows but not in radv for example.\n\n**For developers**, these are important so as you can accurately report and fix driver issues quickly. Reporting issues on proprietary drivers is hell, as they may take years to fix even the simplest issues or just never fix them at all. I've reported a few issues on `radv` that I found while debugging RPCS3 (a PS3 emulator project I work on) and they were very helpful and fixed these issues in a very reasonable timeframe.\n\nDebugging is also a pain in the ass on proprietary drivers as you don't have the source code nor symbols (which essentially allow you to see the function's names so you can better understand what that code does when you're debugging instead of only memory addresses). When you hit a driver bug, you have a hard time even trying to work it around on your software, let alone figuring out what's wrong.\n\n**For gaming**, you can get faster and more optimized drivers since they're scrutinized by the community, implementations are discussed on public issues and not decided behind closed doors where you have timelines to meet and may just need to fix things quickly as possible. \n\n**I can give a practical example:** when Cyberpunk 2077 released, it was immediately Playable on Proton (I completed it in 12 December, just 2 days after release, only playing on Linux almost non-stop). \n\nThe catch: **only if you had an AMD card with Mesa drivers**. This is because CP2077 has an engine bug that makes the game crash (seemingly randomly, and that doesn't crash the game on Windows by luck) which was worked around thanks to a Vulkan extension made by Valve called `VK_VALVE_mutable_descriptor_type` (drafted way prior to the game's release, it wasn't created for that issue), and Valve's developers had implemented it on Mesa before the game's release (because CDPR gave Valve developers a review copy of the game prior to launch so they could fix issues on Proton) in order to make the game work.\n\nWhy wasn't this possible on NVIDIA drivers? Because they're closed source. Fast forward two months after the release of CP2077 and that extension is still unimplemented in NVIDIA's drivers, and the only way for you to play the game on Linux without the risk of crashing is with an AMD GPU.\n\nI hope this wasn't too confusing, I tried to keep it simple but maybe I can further explain some things that perhaps weren't explained very well."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6700xt"
    ],
    "title": "My tight Ryzen 3600 and RX 6700XT builld, with a gpu and cpu cooler that are technically too big for the case (h210i).",
    "selftext": "",
    "comments": [
      "Deepcool is killing it with this cooler.",
      "Man, that's a squeeze! I'd be concerned about proper air circulation, but you could always just fire it up and watch temps! I've ordered that same (although white) cooler for a new white themed build I'm doing this winter!  \n\n\nWhat ram do you have in there? Looks like the cooler completely dwarfs the memory, so wondering if the memory I'm looking at (Trident Z neo) is going to be too tall.",
      "It's the AK620, I absolutely love how it looks and it's also quite competitive with the top Noctua and Be quiet! air coolers, while being substantially cheaper.",
      "Temps are absolutely fine, gpu core maxes out at around 67c in furmark and cpu sits at around 70. The deepcool AK620 is quite freakin cool, basically the size of the itx board and looks epic in a small case. \n\nI can't say for sure, but I think it would fit fine with almost any memory kit, when I installed it there was quite a bit of space for the memory left over.",
      "Deepcool is such an underrated brand. Just rebuilt my PC with a CL500, gorgeous, huge and cheap case and their LS500 Water Cooler, also quite cheap but exquisitely made.",
      "I was wondering what it was, it looks good.",
      "I run this setup ( ryzen 5 3600x cpu, radeon rx 6700xt gpu)\nI run a full size case however. It does me very good! How do u find it so far?",
      "Probably ok in an air con room. A heatbox otherwise",
      "As I said in another comment, gpu core maxes out at around 67c in furmark and the cpu has a completely overkill cooler for it. No aircon needed ;)",
      "I absolutely love it, pretty much runs anything I want at 1440p, stays cool while doing so and looks dope af IMO.\n\nAlso I did undervolt the gpu very slightly and that improved the temperatures quite nicely. Honestly would recommend everyone to do that because they have put quite a lot of voltage headroom on the card from the factory.",
      "That's good to know. \n\nSometimes we get so caught up in the tiny world of tech youtubers like GN, HUB, JzTC, that it feels like there's only Corsair, NZXT, Lian Li and Cooler Master out there, but no, there's gold in them there brands if we look.",
      "Welcome to the ITX rabbit hole. \n\nI have the same build (3600/6700xt) but in a Coolermaster NR200. Stays just as cool. This CPU makes like no heat, so my next step is a 5800x3d, which I think should stay plenty cool based  on my 3600's temps.\n\nGo smaller ;)",
      "There are holes in the bottom of the psu shroud, max core temp after 30min in furmark is 67c and max junction is 85c at around 1500rpm, which is very quiet on this card :)",
      "That's phenomenal, really slick looking build!",
      "There's definitely not enough clearance for your GPU to get enough airflow. Might be worth just getting a new case, even if it's 2nd hand.",
      "My lord the owner has already said his gpu runs cool and quite and people still crying over the gap.",
      "Wdym?  Gamers Nexus covers Deepcool stuff when it comes out/has issues.  They‚Äôve got AK 400, AK 620, Assassin III.  They‚Äôre also all in the charts for cooler reviews/end of year recaps for ‚Äúbest coolers‚Äù.\n\nThey even went on a factory tour for Deepcool‚Äôs case fans lol",
      "That‚Äôs like a third of the price of the cooler. Not irrelevant at all.",
      "Problem is with the gpu, the air cooler looks fine",
      "AK620 works really well in almost any case esthetics"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6700xt"
    ],
    "title": "My all amd build, 6700xt and ryzen 5 5600g.",
    "selftext": "",
    "comments": [
      "Bro you can't have the Yeston 6700 and not show off the Waifu on it!!",
      "I think you could use some more fans in this build.",
      "I didn't have a gpu at the time",
      "Iirc it's more comparable to the 3600 not the 5600x.",
      "ton",
      "I can assure you that many fans are not necessary to keep the temps low. It is aesthetic. And there is nothing wrong with that. It is beautiful. OP is just trying to justify the purchase to himself. It‚Äôs ok OP. You have built a beautiful machine. There is nothing wrong with spending money on unnecessary items for the sake of aesthetics.",
      "Why did you get a 5600G to combine it with a 6700 XT?",
      "would be interesting to see the airflow path and turbulence with a smoke machine.\n\nLTT recently has shown that even a case full of fans can have dead spots due to either bad intake/exhaust balance or placement. populating all fan slots is not always the best.",
      "Nice build.  How much did you shell out for the 6700 XT?",
      "What's that liquid cooler you have?",
      "its much closer to the 3600 than the 5600x/12400f",
      "Smells like your Waifu's perfume?",
      "Right?!?!? That's the whole point of the card IMO lol.\n\nI think the front looks... Cheesy.. but the bottom with the waifu actually looks sick as fuck.\n\n\nBut, that's just my opinion! It looks great in this build tho, I must admit.",
      "Yes",
      "$1100",
      "Nzxt z63",
      ">what would be like the best motherboards for AMD ryzen\n\nThere is no \"best\", there are different motherboards with different feature sets and different price tags.\n\nWhat do you want to fit onto that board? Are you going to overclock any components? How many USB ports do you need? Do you need Thunderbolt ports? M.2 drives? What's your budget? These are the questions you should ask yourself, and depending on the answers, look at what fits and what's available in your region.",
      "Damn, glad you could swing that. I've been so tempted to buy one but I can't bring myself to do it.  Really don't want to give in to these insanely marked up prices.",
      "Yes but no.\n\nThat many fans means you can run each fan slower.. So overall the noise made is easier to blend into background noise than fewer fans running at a higher RPM.",
      "Don‚Äôt just scream stuff you hear other people say. \n\nIf you don‚Äôt know what you‚Äôre doing, don‚Äôt advise other people on it.\n\nBesides, how is high voltage a good thing?"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6700xt"
    ],
    "title": "Traded my 5700XT for a 6700XT",
    "selftext": "",
    "comments": [
      "Yeah. I think because of miners rx 5700 xt are expensive. Sold mine rx 5700 xt for 930 dollars and bought rtx 3060 ti with premium cooling for 720. Amazing part is that i have 210 dollars left",
      "Hash rate on the 5700XT is higher, so they are going for $900-1100.",
      "Trying is free.",
      "Post an ad on your local craigslist, lego, kijiji, Facebook marketplace etc.\n\n\"5700XT - will straight trade for 6700XT\" \n\nAnd let the interested miner contact you, thats what I did.",
      "A miner would buy that off of you in a heartbeat. \n\nJust post it on FB and/or craigslist, It'll sell for great money within 2 weeks.\n\nI upgraded from my 5700xt to a 6900xt 2 months ago, it only cost me an extra $450 USD.",
      ":( \n\nHow's everyone finding such deals and not myself :/ \n\nI have an AE and giving the waterblock and the blower cooler.",
      "Yeah i feel really happy and lucky because the pc costed 900 and sold just the gpu for 930. The owner of the pc is regreting now... I guess. that means i got every part for free and gained 30 dollars.",
      "Is selling a gpu online safe? I've been tempted to sell my 5700xt, however I'm slightly worried about being scammed, which would really suck because then I couldn't afford a replacement.",
      "Not the OP, but r/hardwareswap is pretty handy for selling PC parts.\n\nI've both bought and sold things there. I'm not exaggerating when I say you could post a 5700XT tonight and probably have payment for it by tomorrow morning.",
      "No one cares about the box.",
      "People live in other countries?",
      "People absolutely will buy it. Between miners and gamers the demand is there. I just sold my dusty old 980 ti for $350, your 5700xt will be worth more for its mining.",
      "I sold mine for 815‚Ç¨ and got a rx 6900xt for 1k‚Ç¨ got really lucky :D",
      "or they‚Äôre japanese",
      "Yes it's the hellhound. I'm noticing 20-30% more fps. Love that the fans don't spin at idle. Max temperature hit 78 (junction) temp.",
      "Where did you sell it if you don‚Äôt mind me asking?",
      "5700xt is much better in mining than the 6700xt",
      "I sold my old card on eBay, and I was nervous about it at first. Now I wouldn't hesitate to do it again. There are mixed reviews with eBay but they have tons of protections in place for both buyer and seller. They do take a chunk of the money so expect to not get full asking price. They will also ban/lock your account until you physically contact them to verify yourself. At first I was frustrated with it but it definitely goes the extra mile to ensure people aren't being scammed.",
      "Driver issues at launch were a mess but most if not all the issues have been resolved now.\n\nI bought my 5700XT near launch and debated reselling. I just tossed it in a spare computer and used it as a dedicated miner instead. Got lucky with queues for a new GPU",
      "Oh I know about r/hardwareswap. I have something like 20 confirmed trades atm. I was curious if there was somewhere else to post to find someone willing to do a straight trade as I have a 5700xt as well and would love a free upgrade."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6700xt"
    ],
    "title": "Yesterday one person bought 79 x 6700XT and 14 x 6900XT during the EU AMD drop (no joke, with proof).",
    "selftext": "",
    "comments": [
      "I think that's the Dutch browser extension\n\nIt shares the unique queue ID between the subscribers, I saw that in many forums in the web since (at least) 3 months from now so I think AMD/digital river is well aware of that\n\nThat's the new era of scalping: scalp BEFORE the purchase",
      "That was patched months ago nowadays it's way more complex, the guy has thousands of instances open and the more people solve captchas the more different queue IDs are made, his script also has a priority list where people who haven't had a chance as much get picked first.\n\nI'm glad for his script as months of trying manually didn't lead to anything mostly because cards were gone in 2 minutes as the bots shared the same no queue ID but it felt scummy and most of the people in the forums where they discuss this are the scum of the earth\n\nFor those unaware one guy didn't farm 70 cards, those are divided by the people using a dudes paid script which has about a thousand users by now",
      "He sells subscriptions which gives people a position on his waitlist. You need to have PayPal to do this. Yesterday 93 PayPals bought a GPU through this system in 10 seconds making it nearly impossible for others to buy. Earlier this bot was succesful, but not this succesful now it's probably has become the only option if you wan't to buy a GPU from AMD in the EU.\n\nI say \"PayPals\" because there's a lot of people who sign up for this service with multiple PayPal accounts.",
      ">This is the future of pc gaming. Get used to it.\n\nOnly if people keep paying way over msrp for the cards. If the scalpers can't sell their product, they will stop buying it. Problem solved.",
      "Whoever thinks the same thing won't happen when the new gen is out, is out of his mind lol.\n\nThis is the future of pc gaming. Get used to it.",
      "So what you're telling me is that this guy has a better queue (at least from a consumer perspective) than AMD does?",
      "A year ago i subscribed by EVGA for a 3080 at msrp. Still waiting, and shops have plenty evga in stock. The reality is that manufactures want to sell fast at the highest possible price‚Ä¶ thats a part of the problem too",
      "Wouldn't he need a different address for each card?",
      "Except this mentality is part of why prices are still where they are, and if people continue paying the prices that's where it'll stay\n\nThe victims aren't the people paying scalped/inflated pricing (They can afford it) and are only paying the price due to their own impatience\n\nThe victims are those who can't afford the inflated prices and are priced out of PC gaming entirely",
      "people here can't get cards because of other bots and this kind of things\n\nDR must find a way to avoid that\n\nmaybe an early email subscription with lottery will be better than thousand of millions of people and bots going to [amd.com](https://amd.com) only in those 3 minutes\n\nif things will not change we will never be able to buy upcoming gpu",
      "Yeah definitely.\n\nSounds like his queue is super convenient and hassle free. Plus I think it's brilliant that customers who weren't able to buy a card the week before get increasingly higher priority the next round.",
      "this is what happens when AMD picks the worst unreliable partner to run theirs shop ...  \nfrom perspective of customer who attempted to buy anything via AMD shop in past 12 + months  \ni would never ever buy AMD product again ... so bad the experience was and is ...",
      "This was always going to happen\n\nPeople have been paying scalped prices for years now, that is why scalpers are still here, they're opportunists, and they've been given this opportunity (They don't do it just because, they want to make money)\n\nAnyone who has bought from a scalper cannot be angry about this, because you helped create this situation in your own small way, And tbh it's your fault if you payed an inflated price because you chose to do it out of impatience \n\nThe actual victims are those who can't afford the inflated prices and cant build a PC now because they've been priced out",
      "EVGA still has their queue and people have been waiting since launch to see their name pop up still",
      "It‚Äôs trivial to register a bunch of emails so scalpers still win in that case.\n\nIt‚Äôs not an easy problem to solve and no idea you came up with in five minutes is going to work, otherwise it would have been solved by now. It‚Äôs not for lack of trying, it‚Äôs really hard to do without some kind of external reputational signal. For steam, that signal can be your spending history and wallet, AMD doesn‚Äôt have that sort of data for you.\n\n(The one thing AMD/NVIDIA have access to that could legitimately be useful is driver telemetry data tied to your account but nobody wants to talk about that.)\n\nBut seriously, things that are not actually good ways to ensure one-per-person:\n\n* emails\n* credit card numbers\n* shipping addresses\n* billing addresses\n* names\n* phone numbers\n* ip addresses\n\nTime and again every baby redditor thinks they‚Äôve solved the scalper problem by ‚Äújust limiting one per credit card‚Äù or ‚Äúone per billing address‚Äù and they don‚Äôt realize the sneaker market tried that like 15 years ago and scalpers trivially worked around it and found a solution. This is big business, the people who sell the tools make hundreds of grand per year enabling scalping, they have worked around ideas you haven‚Äôt even come up with yet.",
      "Its been 2 years and everything still out of stock,i don't blame people for paying way over MSRP at this point",
      "Friend of mine got his 3080 yesterday from EVGA email listing, almost 9 months after he signed up for it.",
      "Definitely? How did you come to this conclusion because it definitely is not. He just doesn't have to deal with what AMD is dealing with. It does not solve anything: It's first come first serve and thats being botted as well. Of course once you're subscribed to his services you have a very convenient experience but that is not what you need to compare to the AMD queue.\n\nHe only let's about 50 people buy a subscription once every while (allthough he has strongly oversold because of technical issues). Combine that with a high successrate and yes, customers will be satisfied.\n\nIf this wasn't exclusive it would be the same mess AMD is dealing with now. The only thing he is doing is moving the issue from the AMD queue-it queue to the people paying him for a subscripion, he actually started using some \"bot protection\" himself because people (scalpers) want a subscription.",
      "I've been on there since later 2020. The cards I signed up for are discontinued so I guess I'm not in any sort of real queue anymore.",
      "Of course they care. If they didn't care they wouldn't be setting up this complex system with all kinds of protections that make it hard to get anything."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6700xt"
    ],
    "title": "Accidentally upgraded my rig. I7 9700 & 2070 -> 5600x & XFX 6700XT ü§ì The GPU makes this case look tiny.",
    "selftext": "",
    "comments": [
      "There is no such thing as accidentally upgraded build sure you can build a shed or end world hunger but not upgrade rig. Nice rig BTW.",
      "I guess I just \"accidentally\" bought a PS5 bundle from Sony too...",
      "Shhh don't tell the wife lol, thank you good sir ‚úåÔ∏è",
      "Specs:\n-Coolermaster masterbox Q300L (moving onto Corsair 4000D/275R airflow soon)\n\n-Ryzen 5 5600X (cooled by H100i)\n\n-Asrock b550-m pro4\n\n-Kingston HyperX fury 16Gb 2666mhz running @3200mhz\n\n-XFX speedster Qick RX 6700XT\n\n-Corsair CX-750M psu\n\n-Kingston 480gb SSD boot\n\n-1TB WD disk and 1TB m.2 SSD (can't recall brand) for storage.\n\n-I probably could've gone for a better GPU, but I like how well the Ryzen works with this one, it gets pretty much all out of it.",
      "I accidentally bought two bowling balls instead of a 3080 lol",
      "Poor us, right? üòÇ",
      "[shhh, it's a wifi router](https://youtu.be/cEN00wMFB2A)",
      "True, I only bought the PS5 that \"accidentally\" bundle with a 55\" TV and a spare controller, not my fault!",
      "You *could* join the Meshify gang [just saying ](https://imgur.com/a/k2b5Ves)",
      "Sidegrade",
      "That sounds like one big happy accident, have fun with it ‚úåÔ∏è",
      "I hella recommend the 4000D case. It's so fun to cable management in it.",
      "[50%](https://static.techspot.com/articles-info/2216/bench/1080p.png) faster at 1080p without SAM and with release drivers. It's faster now.",
      "Sidegrade",
      "Must have ‚Äúaccidentally‚Äù put it on the credit card?",
      "This does appear to be an accident because it's almost a sidegrade not an upgrade.",
      "Nice! I got an MX Ergo for Christmas :-)",
      "I accidentally bought myself a test bench that I'm not gonna use",
      "Accidentally paid too?",
      "This feels like a side grade more than an upgrade"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6700xt"
    ],
    "title": "I actually managed to get into the store today, and even added a 6700XT to my cart, but when I tried to pay there was nowhere to enter my payment information. I expect nothing, and yet I‚Äôm continually disappointed.",
    "selftext": "",
    "comments": [
      "Congrats on at least getting that far lol.",
      "I feel your pain - made it through processed order for 6700XT and BOA decided the charge was fraudulent and declined the transaction so I got booted to back of the line... feels like we can't win.",
      "For all the good it did for me ¬Ø\\\\\\_(„ÉÑ)\\_/¬Ø",
      "You‚Äôve got an ad blocker running. Same thing happened to me last fall. Had uBlock on and it removed all of those fields. Turned it off and got a card the next week.",
      "punch busy chief agonizing advise versed observation wine adjoining mindless\n\n *This post was mass deleted and anonymized with [Redact](https://redact.dev)*",
      "That exact same thing happened to me months ago, except it was Chase bank",
      "Maybe, but it‚Äôs too late to try it now",
      "Hmmm‚Ä¶I have the Firefox focus content blocker enabled on Safari. I wonder if that caused the problem.",
      "I managed to get through this morning.\n\nI used paypal and got a 6700xt. My buddy tried getting a 6900xt and his popup blocked ruined his day.",
      "Honestly dude, you‚Äôve got a 6700xt and by the end of the year, the 7600xt is supposed to be faster than a 6900xt. You should probably hold fire till the new cards come out.",
      "I think this was my issue as well. Ad blocker on Firefox. Rippppppp",
      "I had the same issue and it was due to Firefox and uBlock. I ended up making my purchase using Chrome.",
      "Same happened to me with another National bank a few months ago. It actually happened on my birthday which almost ruined my day.",
      "For the OP, be careful with this, some checkout processes send you to multiple individual sites along the way, for example order processing and payment processing may be under different individual sites. Each time you need to disable the protection for each individual site you add another factor that risks you not making it out of checkout successfully. Probably better to disable this globally or use a different browser with no adblock when you are specifically attempting to nab a card.",
      "I got my 6800xt on mobile, auto fill is really fast and helps a lot.",
      "Not really, you have to pay to be apart of their program to get a chance at MSRP prices. Scumbaggery",
      "You can also click the shield icon in the Firefox address bar and switch off \"Enhanced Tracking Protection\". It's site specific.",
      "This is the second reason why edge exists.\n\nNumber 1 obviously to install any other browser, number 2 for when shit's broken.",
      "I got in, put in my payment information, hit checkout and got booted back to the queue. Oh well. I don't really NEED a card anyway.",
      "I feel your pain. I managed to buy one and it was stolen by USPS mid transit, and \"they don't know how it went missing\" üôÑ"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6750",
      "6750"
    ],
    "title": "Massive AMD Zen5 Leak Reveals 20% Single-Core Uplift, Sarlak 'Strix Halo' Achieves RX 6750 XT Levels of Performance at 95W-125W",
    "selftext": "",
    "comments": [
      "This feels like a lie",
      "> RedGamingTech\n\n> MLID\n\nThis can safely be ignored.",
      "I don't think performance would be that far. PS5 (Zen 2, RDNA 2) draws up to 210w according to Sony for the whole system which is close to an RX 6700. 125w just for the APU (Zen 5, RDNA 3.5?) seems reasonable to me after all those years of advancements.",
      "Which part?\n\n  \nWe know AMD has been working on Zen5 for a long time, they've [announced it](https://www.extremetech.com/computing/amd-confirms-am5-socket-will-extend-to-2026-zen-5-to-use-rnda-35-gpus). We know it'll be the 8000 series, we know it'll be AM5 platform, we know it launches [next year](https://www.forbes.com/sites/antonyleather/2023/06/05/amd-confirms-2024-launch-for-ryzen-8000-zen-5-processors/?sh=3787e4d56099), and we know the iGPU will be RDNA3.5 based. It's almost certain to use TSMC's 4nm process node.\n\nThere's nothing new or controversial in any of that. \n\nAs to having an APU variant with 6750xt levels of performance I see nothing strange or implausible there. \n\nThe 67050XT is a 17 billion TX chip built with TSMC 7nm and pushing \\~13 TFLOPs with board power \\~250 watts.\n\nThe move from 7nm to 4nm brings an \\~80% boost to transistor density and a decrease in power consumption of around 30% (for same clocks). Plus the architectural improvements between RDNA2 -> RDNA3.5 are quite substantial. \n\nCombine that with the rather hefty efficiency gains from unified memory and I can see it fitting within that power envelope.\n\nSo if this is a lie they've decided to go with a perfectly reasonable one.",
      "But isn't that what 'leaks' mostly mean? It's people from the inside that can \"leak\" information far in advance, not outsiders",
      "Because even RDNA4 and nvidia (4060ti) can‚Äôt get 6750xt levels of performance at 95-125 watts. I‚Äôm glad if I‚Äôm wrong of course. But it just doesn‚Äôt seem to add up.\n\nEdit: got my RDNAs and Zens mixed up. RDNA 3*",
      "Dropping an 8800x3D into my existing 7700x's mobo is gonna be a great day.",
      ">Has RedGamingTech ever been right?\n\nYes, with his name.",
      "RDNA 4 isn't out yet. Do you mean RDNA 3?",
      "Here's a laptop with a 105W RTX 4080: https://www.notebookcheck.net/MSI-Stealth-17-Studio-review-A-laptop-with-a-quiet-RTX-4080-for-almost-every-occasion.708750.0.html\n\nIt seems to be pretty close to a 6750 XT desktop in terms of performance, possibly a bit quicker.",
      "The answer is memory bandwidth. A 6750 has +400GB/s, while ddr5 6000 has around 90GB/s. It would be memory starved to have  similar performance",
      "amd said along the lines of 10-15% ipc lift.  \nquestion is frequency and whenever x3d version is out.",
      "It‚Äôs funny now we are not happy with 20% single core IPC jump from gen to gen lmao.",
      "I'm surprised he didn't also \"leak\" Metal Gear Solid Remake for the 17th time.",
      "Notably he was the first to talk about infinity cache and he was pretty much exactly right about RDNA 2 performance expectations. Otherwise I have no idea.",
      "Even if it turns out to be correct I still think it's a lie. It's reasonable sure, but I don't think one person outside amd has all that working silicon.\n\nIf someone says they know something when they don't, it's still a lie even if it turns out to be mostly true.",
      "- Zen 1 -> Zen 2 : +27-28% (4.0->4.6/4.7Ghz and +15% IPC)\n- Zen 2 -> Zen 3 : +29% (4.6->4.9/5Ghz and +19% IPC)\n- Zen 3 -> Zen 4 : +25-26% (4.9-> 5.6/5.7Ghz and  +8% IPC)\n- Zen 4 -> Zen 5 : +20%",
      "\"RedGamingTech\"\n\na truck of salt",
      "My dumbass spent $900.ü§¶üèæ",
      "Source: MLID\nClose the thread. \nZen 5 rumored performance is as real as MLID sources."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6750xt"
    ],
    "title": "AMD Direct 6750XT sale (CAD $403)",
    "selftext": "",
    "comments": [
      "price error ? the price is simply too good, and it is 400 CAD not even USD, wtf.\n\nedit : hopefully this is an indication that RDNA 3 will be affordable",
      "European prices still at MSRP and out of stock for anyone curious.",
      "It's a pretty normal price drop when moving to a new generation, when crypto isn't relevant:\n\n    Vega 64     500 USD\n    RX 5600 XT  280 USD",
      "For those who like great prices, this is about as good as it gets. The Canadian AMD store has the 6750xt reference model on sale for CAD $403, which works out to about USD $295.\n\nNot sure if other regions have the same deal.\n\nEdit: The price is back to CAD $608 now...guess it was too good of a deal. Hope some of you were able to get it at least!",
      "AMD just brutally discounted combos and GPUs even for EU, check the site.\nMan if would have the money for that right now.\n5800x3d + 6950 combo for 1000 EUR only.\n\nhttps://www.amd.com/de/direct-buy/de",
      "It is only \"normal\" if the next gen GPUs are supposed to hold the price brackets of current gen MSRP +100/200$, not like Nvidia's 700 USD to 1200 USD for an 80 class GPU. Hence why I'm actually looking forwards to it.",
      "definitely, RDNA3 will probably take over the RDNA2 price bracket with slight inflation adjustment while RDNA2 will be on clearance",
      "That is a fucking deal, even in yankee money.",
      "Are you sure that the price is in CAD$?  \n\n\nEdit: Ok, I tried with the Paypal option (just to see, I didnt buy) and indeed it was asking for $403 CAD! Wow, its a REALLY big sale...",
      "Can only be shipped to a Canadian address. Just tried.",
      "*cries in europe*",
      "Netherlands here. No combo deals either. Also the RX 6750 XT is ‚Ç¨678.87 and out of stock.",
      "I don't see any combo deals. Do they have their own page? Or maybe they're country specific? \n\nAlso not super relevant for those of us that already bought a CPU :/",
      "This shit‚Äôs fantastic, it‚Äôs been four years but we finally have a $300 2080 Ti equivalent.",
      "They must be dividing up by country or sub region then, bit hard to check without using a VPN since they force redirect to a local page.\n\nI see:\n\n    RX 6950 XT  1358.98 EUR\n    RX 6900 XT  1235.31 EUR\n    RX 6750 XT   678.87 EUR\n\nall out of stock.\n\nIf you're getting prices in USD, maybe you're covered by the US warehouse?",
      "hope you are right but my predictions are closer to:  \n7900XTX - 1499  \n7900XT - 1199  \n7800XT - 899  \n7800 - 749  \n7700XT - 599",
      "Yeah tried it out myself in Canada. Didn't post the link because it will just redirect depending on the region you are in.",
      ">I wouldn't be surprised if the 7700XT was available this month.\n\nI will be, I don't think they have enough chips to meet the demand.",
      "Yes, but unfortunately it doesn't show any combo offers to me",
      "FUCK IT! \n\nI PULLED THE TRIGGER!\n\nThis is WAY too good of a deal to skip out on, fucking hell üò±üò±üò±"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6650"
    ],
    "title": "AMD Radeon RX 7600 XT Specs: 8GB VRAM & 2.6GHz Boost; Only 11% Faster than the RX 6650 XT at Same Power [Report]",
    "selftext": "",
    "comments": [
      "Needs to be under $300 or dead on $300 realisticly.",
      "Arguably it should be cheaper than that. For 300, it would have the same appeal as 4070. It needs to be max 250 in order to be a viable product at all. \n\nIf this rumor is true, this would mean that RDNA3 is one huge flop though.",
      "Then it's a pointless card. The 6700xt could be had for around $300-350ish for months and is already around 10% faster than a 6650. Plus they're 12gb cards.\n\nAt the rumored specs/performance the only way this card is a success is if it's a $200-250 card for the masses.",
      "It's not delusional when you consider current price/performance. A $400 7600XT would fucking suck",
      "I thought that 8gb vram wasn‚Äôt enough for games according to amd",
      "8 GB is officially considered low end now.",
      "What an utter disappointment. This thing needs to be $299 to not suck, and it might even be bad *then*.",
      "It must launch for less than $300",
      "Brother u are delusional. 6650xt was priced at $399 so I imagine 7600xt would be priced the same.",
      "8GB VRAM for 399 USD  in 2023 makes it meh",
      ">the card will be paired with¬†8GB of GDDR6¬†memory via a 128-bit or 192-bit bus\n\nIf someone manages to get 8GB of vram working on a uniform 192-bit bus I will eat my shoe. The numbers don't number and the person who wrote this article has no clue.",
      "6700 XT is between 20% to usually more around 33% faster than 6650 XT.",
      "Each vram memory module uses 32-bit bus to communicate with the GPU. These modules are made in capacities in the powers of two due to how binary addressing works, most commonly in 8Gbit or 16Gbit  densities or with 1GB and 2GB capacity respectively. To have a uniform access to the entire addressing space you have to use the same modules for the entire vram. That means for a 192bit bus you have total of 192bit/32bit = 6 modules that can either be 1 or 2GB capacity so 6GB or 12GB total. For 128bit bus that is 4 or 8GB. Other capacities on these buses are impossible unless you use uneven/non-uniform addressing space by mixing modules. Something similar was once done by Nvidia on a GTX 970 and received a backlash. Basically you would lose bandwidth once you fill up the capacity of the low density modules.",
      "nobody will buy it over a 6650 xt unless they curb the supply. Historically, AMD drivers aren't quite polished either for new product support.  \nHeck even 6700 xt are available for $320-$340",
      "u can get a 3070 for 300 on ebay",
      "I don‚Äôt think it‚Äôs possible for new cards to compete with clearance priced last gen stuff from AMD. If you want a $325 6700xt you‚Äôd better buy it before they sell out.",
      "It'll launch at $349 and then drop to $329 and then $299 sales once nvidia release their lower end\n\nIt will be noticeably better bang/buck and the vast majority of reviewers will call it the better buy over the 4050 Ti/4060\n\nThe 4050Ti/4060 will still outsell it 5:1 or worse, as is tradition\n\nAMD need to wake the radeon division the fuck up. Nvidias trash pricing and stupid decisions this generation is the best chance they have had in a decade of clawing back market share and they're just doing the same thing they've been doing over and over again",
      "You can also get Intel's A750 with 16GB VRAM.",
      "if you play games at cranked out settings yes\n\nbut 99.99% of people turn them down and hover around 5-6gb VRAM usage so we have 1 gen worth of time before 8gb becomes actual mandatory\n\nand old games exist which look pretty for the VRAM usage they have so i don't know whether to laugh or not at people thinking this is the problem XD",
      "The RX 480 was a mid range card available with 8GB six years ago. 8 is insufficient."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6750xt"
    ],
    "title": "Went from a 1060 6gb to a rx 6750xt, only my cpu 3600x struggles at 1080p, any recommendations?",
    "selftext": "",
    "comments": [
      "Updating w the boisssss",
      "update the bois. it runs much smother. i have that board.",
      "Definitely need to update the *bois* for the best performance",
      "Me and the bois updating to get the best performance out of our hardware",
      "Ikr, the lads arent as good as they used to be.",
      "1.update mpbo bios.\n2.update ryzen chipser drivers\n2. In amd driver sw, turn off everything except anti lag.\n3. Play the games a bit and see what happens. For example in Fortnite, after each update there seem to be some extra work needed so fps drops, but after a few hours fps is again stable.",
      "Can you first tell us what games you struggle on? Your current pc should be enough to rip trough 1080p with ease.\n\nAlso check the lateny and speed of your rams, cpu temperature and could this be some sort of driver issue. How long passed before you did a clean win install.",
      "3600x should be fine for pretty much anything and everything even in 1080p. If your trying to get 240hz in everything you play all the time then you'll have to pay that kind of money though",
      "That‚Äôs cuz the game needs rebuilding of shaders",
      "Bro, I'm on R5 3600 and 6700XT no problem at 3440X1440, you should be getting a lot of FPS with that card on 1080p.",
      "Make sure it's not a skater Boi, or I'll see you later boi",
      "I can confirm this. I had a micro stuttering in games on my 3600 which i figured was due to my rx 580 not keeping up. Updated bios for memory compatibility and the stuttering went away in all of my games.",
      "That sounds more like a storage issue -- you wouldn't happen to be playing from a hard-drive would you?\n\nI have a non-X 3600 and AssCreed Origins (a nototious CPU hog) runs like butter installed in my nvme drive.",
      "The gpu isn't the problem, I have these microstutters and framerate going all over the place sometimes, especially in cpu heavy scenarios. All in all the performance is good, don't get wrong though.",
      "3600 is a beast at 1440p too.",
      "So you are saying it happens in multiple games. I'm 100% sure that this CPU is enough for gaming without problems with that card. The way this sounds is you get high CPU usage and stutters when loading assets and other in game objects means that your disk drive is actually having difficulties. I only get stutters on NFS Heat on 1-2 seconds once the game is loaded. I'd definitely check the disks.",
      "Just out of curiosity, did you try using DDU to uninstall evrything nVidia related and then doing a clean install of AMD drivers?",
      "The 3600x isn't that hot",
      "It is fine normally, but sometimes I have these annoying micro stutters when I think games are loading assets or so, like assassin's creed origins, war Thunder or BFV",
      "Under full synthetic load assuming case airflow isn't complete crap it's will hover between 70c-90c \n\n\nNot thermal throttling but may not boost as much, with PBO enabled it will thermal throttle \n\n\nGames will probably be around high 60-70 \n\nStock cooler is fine just loud"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6750",
      "6750"
    ],
    "title": "AMD announces two Radeon RX 6750 GRE models at $269 (10GB) and $289 (12GB)",
    "selftext": "",
    "comments": [
      "Hold on. This sounds like RX580, RX580 2048SP and RX590 all over again.",
      "More decently cheap midrange GPUs? Nice.",
      "The 10GB 6750 GRE is more or less an RX 6700, no? For $270 that‚Äôs really not a bad card. I should look into buying an RX 6700 soon lol‚Ä¶",
      "Its just the 6700 and 6700xt at a cheaper price. Which is nice since they offer very good value for money. Especially the sub 300 6700xt(6750 GRE 12GB)",
      ">except TDP is down 5W somehow.\n\nProbably just node maturity and better binning.",
      "Apparently there was also an RX 580**X** but I can't find any information beyond the TPU entry and an [AMD driver page](https://www.amd.com/en/support/graphics/radeon-500-series/radeon-rx-500x-series/radeon-rx-580x).",
      "All the specs are the same, except TDP is down 5W somehow.",
      "**G**olden **R**abbit **E**dition *(from Chinese Zodiac's Year of the Rabbit, 2023-01-22 to 2024-02-09)*.",
      "I think those Polaris X versions were used in Apple iMac models around 2017/2018, if I remember correctly.",
      "This is just for the Chinese market so it doesn't matter",
      "Literally every single company re-releases and refreshes chips like this. Zero point to mock radeon specifically.\n\nSilicon lottery isn‚Äôt gonna have a 99% perfection rate, there‚Äôs tons of times where this happens.",
      "That is ***not at all*** how that works.\n\nYour PC hardware should operate at 100% of it's specifications, *for years*, with zero degredation in performance.\n\nMicroprocessors generally either work or they don't. You won't lose performance to \"wear and tear\" of the silicon. (Degredation from overclocking / overvolting is a different discussion).\n\nStuff like the thermal paste can degrade, which can affect performace, but this is easily remedied.\n\nAn engine in a car is subject to lots of friction and wear of the moving parts, and so will age and degrade due to many factors such as corrosion, seals wearing out and leaking etc, which can all harm efficiency and thus performance.\n\nI'm afraid in this case, it's a terrible analogy.\n\nu/DoomGuyIII certainly shouldn't have been getting errors from a card as new as an RX 6600; RMA that thing!",
      "Perfect upgrading from my aging RX 5500 XT(8GB)...",
      "How many 3080 variants has Nvidia released?",
      "6700XT performance for under $300. Sounds good to me.",
      "So‚Ä¶ basically discounts on the 6700 and 6700 XT? The 10GB model is priced too close to the 12GB one, but the 12GB model would be a nice little addition to the market if it wasn‚Äôt an OEM-only product.",
      "Why did nobody tell me I owned a country",
      "Only for the Chinese market.",
      "Just like MREs, GREs = **G**raphics **R**eady to **E**at.",
      "Yeah it was only a performance uplift, literally an hour ago i found out what was causing my system to constantly stutter and shit the bed was a faulty NVME."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6750xt"
    ],
    "title": "5700X with 6750XT!",
    "selftext": "",
    "comments": [
      "Now there's a PC case I can get behind.",
      "I was contemplating getting one since the price is so nice as of late",
      "Let's be honest here, you probably won't be able to get behind that case without moving the table",
      "> highest end upgrade now on the AM4 pathway\n\nIt really depends on what you're doing. If your main use for it is productivity work, then yes it would be the highest end upgrade for AM4. However, if you're mainly gaming, then a 5800x3d will provide better framerates, not to mention at a cheaper price",
      "I'm thinking similar with the 5950x, It's basically the highest end upgrade now on the AM4 pathway and I don't want to go to AM5 so early, so figure I might just cap my rig out and then relax for another couple years.",
      "True, I am mostly doing stuff that needs high core counts (video editing/rendering and CAD for work) but also when it comes to gaming I typically play MMOs and multi-box them, so need more physical cores for the clients than I need per core performance.",
      "It's an amazing build. Lately i was thinking of making a small PC. What's the name of the case and the specs?",
      "Amd version, i think you can get in in their store",
      "Yeah, but AM4 and DDR4 are price champs. I don't believe ryzen 7xxx series can compete against ryzen 5xxx with new mobo and DDR5 pricings. If you got the cash it is a different story of course.",
      "It's the Formd T1 without its side panels for the summer :)",
      "What 6750XT is this?",
      "for $200 it's a steal imo",
      "The AMD made ones are SO nice in person. That whole outer shroud is a (CNC‚Äôd?) single block of aluminum. They feel utterly premium and have way better aesthetics than the cheaper RGB plasticky partner cards.",
      "love SFFPC. fun fact, amd reference 6700xt, 6750xt, and 6800 are the only two slot AMD cards this gen (excluding 6650xt and below cards)",
      "OP wants the decoration without the hassle and I'm fully onboard with that.",
      "Here‚Äôs my little Type R\n\n5800x3D \nRX 6800 \nnzxt h1 v1 \n\nhttps://i.imgur.com/DtntENF.jpg",
      "If I can get one that cheap, great! I saw them at around 240 which is still pretty good by my estimation",
      "We must've been reading very different reviews, because I remember them saying get the 5700X or the 5800X3D and the 5800X is basically redundant with those two around.",
      "yeah GN even said that 5700x is what 5800x should be",
      "I don't know why but I thought amd reference cards didn't exist and they were just renders"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6750",
      "6750",
      "6650"
    ],
    "title": "AMD Radeon RX 6000 Refresh Gaming & Raytracing Benchmarks Leaked: 6950 XT Faster Than RTX 3090 For $1099, 6750 XT Faster Than RTX 3070 For $549, 6650 XT Faster Than RTX 3060 For $399",
    "selftext": "",
    "comments": [
      ">The following results are based on AMD's official data which has been presented to the media.¬†\n\nWill probably need to wait till independent reviews come out",
      "Considering the regular 6600XT beats the 3060 and the non XT 6600 trades blows the 6650XT beating it for $400 isn't anything to write home about \n\n\nIf it beat or matched the 3060ti then that would be interesting but I don't think it will making a kinda obsolete product especially as stock is more and more readily available",
      "I'd like to see 6950xt vs 6900xt @ 1440p and 1080p",
      "RX 6650 XT vs RX 6600 XT = 2% Faster\n\nSo this justified a price increase according the AMD, ridiculous.",
      "Accurate isn't the same as representative.  \n\nCompanies pick benchmarks that show their products in the best light.  That doesn't mean they aren't accurate.",
      "Yeah, whatever, wake me up when anyone makes a video card under $200",
      "I know right. Never trust this until you get independent reviews",
      "Just look at those ray tracing results for the 6950 vs 3090. They're trying to give the impression that AMD 6000 series is a few % behind, or even trading blows with NVidia for raytracing performance. We all know that that is simply not an accurate summary. I think the article was EXTREMELY charitable to AMD when they stated:\n\n>...there's a reason why AMD didn't focus that much on raytracing performance...\n\nThey cherry picked the few results that show AMD cards in a decent light (pun intended) and attempted to pass that performance on as typical. It's disingenuous and just further reinforces the reality that none of these companies are your friend and they all participate in misleading marketing. Early/Mid Ryzen was such a breath of fresh air. A defeated AMD came out and said the truth: \n\n>We got these chips that are \\[OK to great, depending on the generation\\] for gaming, they're really great for productivity and multi-tasking, and we're sellin' 'em cheap enough to be compelling. Also, we're going to have 5 years of socket support so that'll be nice.\n\nThat was enough for me to buy a Ryzen 5 1600, Ryzen 5 2600x, Ryzen 5 3600, Ryzen 7 3700x, Ryzen 9 5900x, Ryzen 9 5950x over that period. The BS marketing is a turn off after being spoiled by a relatively honest 6-7 years from AMD.",
      "They're probably accurate - AMD's benches for the RX 5000 and 6000 GPUs, to date, have been accurate. It is, however, common sense that you wait for independent third-party reviews from people who aren't sponsored by the vendor.",
      "Or when any RT is used.",
      "Because there'd be a huge uproar of gamers who have pre-RT hardware. Considering the (admittedly recovering but still...) state of the gpu market it's good that hasn't happened yet.",
      "That'd be interesting but to be quite frank the 6950XT performs as well as I expect it to. The Infinity Cache does too good of a job that it's up to core clocks to make the rest.\nAMD's focus on memory architecture/hierarchy makes it easy to find where performance is limited.\n\nEdit: By performing well I meant the weak performance increase on the refresh. Memory was never a bottleneck for RX 6800 and up; just like the Radeon VII and R9 Fury series.",
      "Which makes sense, since it's the only AAA title so far which requires RT to function. Everything else just uses RT as optional window dressing for their rasters, rather than an integral part of the rendering pipeline.",
      "the 6800 msrp was $580 and beats a 3070ti and AMD wants you to think a 6750xt which is supposedly faster than a regular 3070 is $550 is a good deal??  Literally I cannot stand AMD the past year",
      "To be fair, it‚Äôs looking like the 6650xt will hang with a 3060ti at 1080p, but it obviously will lose ground as resolution goes up.",
      ">Beats the 3090 at what though? At 4K? At 1080p? At ray tracing?\n\nCherry picked AMD sponsored games.",
      "Correct. Fully raytraced lighting is actually simpler to implement and compute in realtime than the compounded layers required for a good raster. Adding RT effects on top of a good raster kills performance, but replacing the raster entirely improves performance on adequate hardware.",
      "According to Hardware Unboxed , the RTX 3060ti and the RX 6700XT have around the same performance\n\nhttps://youtu.be/pnZRuY-jFVM\n\nI doubt that the RX 6650XT would match the RX 6700XT\n\nAlso , according to data provided to reviewers through AMD's official guide , the RX 6650XT is just 2% faster than the RX 6600XT on average\n\nhttps://videocardz.com/newz/official-radeon-rx-6x50xt-series-gaming-performance-leaks-out-rx-6950xt-is-4-faster-than-rx-6900xt",
      "Beats the 3090 at what though?  At 4K?  At 1080p?  At ray tracing?  \n\n6900xt already beat the 3090 most of the time at 1080p and 1440p.  But at 4K or ray tracing the 3090 ran away.  I can‚Äôt imagine a minor clock bump changes that much at all.",
      "Can‚Äôt argue with that. What‚Äôs crazy though, is even though it‚Äôs fully ray traced, it still runs better than most of the half assed implementations."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6750xt",
      "6650xt"
    ],
    "title": "AMD launches Radeon RX 6950XT, 6750XT and 6650XT graphics cards - VideoCardz.com",
    "selftext": "",
    "comments": [
      "Another difference is the price tag, but not in a favorable way..\n\nNotice how none of those charts AMD made actually compare against their predecessors?",
      "But where is the difference other than power draw and slightly more memory bandwidth?",
      "6650 xt for $400 and the 6750XT for $550\n\nLMAO.\n\nTHis means the 7700xt will be $550.\n\nThe 5700xt was $400 ffs.",
      "My 5700 non xt was 329 before tax. FFS. A full PCIE 4.0 16x card with 8 Gigs of VRAM that could drive anything at 1080p and most games easily at a 1440p. Compared to 2021 / 22 pricing, it seems almost insane.",
      "Its quite telling they are not comparing it to the regular 6600XT, 6700XT and 6900XT because the uplift is probably 5% at most and would make the price incease compared to the models that launched over a year ago comical.\n\nWe're probably in for a trashing in the reviews once the embargo lifts in a few hours.",
      "Sadly yes",
      "well ofc there's msrp bump, why wouldn't it be. That was whole point entire time. 18Gbps memory is barely more expensive - otherwise they wouldn't be putting it on RX 6500 XT.",
      "The MSRP reflects that AMD is in their position to keep increasing margins and milk the desperate consumers a bit more.\n\nAMD keeps pulling one highest profit year after another. Production costs increases are negligible, especially third year on the same GDDR, the same core fabrication which got cheaper with long ago not being the cutting edge node, and with yields continuously improving.\n\nThere's not a single proof manufacturing got meaningfully more expensive for AMD, inflation completely notwithstanding.",
      "Oh no, with his 6900 XT, what a nightmare.",
      "The pricing is likely reflective of what AMD views at the least medium term outlook for GPU pricing to be and they have much more data than consumers/media/etc. to work with. The rumored pricing of Intel's roughly 3060 competitor being $380 also supports similar predictions.\n\nThis means it seems like they feel that the RTX 3060 will likely stall around the $400 mark as opposed to falling down to MSRP range in the low $300s. Likewise the 3060ti will remain around the $500 mark versus falling down to the low $400s. In other words the overall downward price trend for GPUs has reached a stall point.",
      "God, why is AMD so fcking shit again? Why do companies build their reputation up for years and then say \"You know what? Let's forget about that and take the most stupid business decisions we ever could\"",
      "Buying a 5700XT for 400‚Ç¨ felt like the best purchase ever made. Strong card for comparably cheap price. I always thought it would be a stopgap for the next gen big card. Oh how wrong I was. \n\nI hope the 7700XT will be cheaper but I'd guess Nvidia is raising prices and for some reason AMD just doesn't want to compete on price.",
      "7xxx series will probably be positioned way higher performance-wise and price-wise. Only the 6950XT is probably in the same performance tier as N33, but others are higher.",
      "I wonder if they gave salary increases relative to inflation to all their workersü§î",
      "Well... as nVidia, this is just a cash grab.\n\nI'm tired of this stuff.\n\nThe prices are still a joke, even for the older models...",
      "The point is not the performance, absolutely isn‚Äôt. The ONLY point for their existence is to refresh the MSRP. No more, no less.",
      "topkek - poor AMD should launch Patreon, so people like you can give them all the money üòÇ",
      ">Don't always whine about businesses\n\nWhat's with the boot lickers in this thread trying to sympathize with a multi billion dollar corporation and defend this blatantly obvious cash grab? We all understand how businesses work, no one expects them to be a charity. If I feel like I'm getting bad value for the price I'm supposed to pay, of course I'm going to point that out.",
      "One of the best purchases I made, gamed like all hell during the pandemic, bought a 3080 at MSRP and sold the 5700xt for like a grand during the craziness",
      "The 6950 is actually up on Newegg for $1100. The cheapest 3090ti is $2000. I think it is a win simply based on being $900 cheaper for nearly the same performance."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6750",
      "6750"
    ],
    "title": "It finally came! From 6750 XT to 9070...This things a beast!",
    "selftext": "",
    "comments": [
      "It released 3 days ago.. lol, it finally came!!  Grats regardless.",
      "It‚Äôs nearly twice as powerful. \n\nhttps://www.techpowerup.com/gpu-specs/radeon-rx-6750-xt.c3879",
      "I have a 9070 on the way to replace my 6700XT, pretty stoked.",
      "I'll pass for now, 2 years of waiting - RTX 50-series is a scam and RX 9070 is 750‚Ç¨ at the cheapest. I'm not paying that much for a midrange card - the shit is going too far.",
      "Op has some connections",
      "Lol, I was in a panic for the majority of the day yesterday because I'd heard of people having their orders cancelled from other stores and mine had said \"order confirmed\" since Thursday but it finally shipped yesterday evening and then came early this morning. \n\nFeels good to have it here now safe üòÇ",
      "Yea I dont think people realize 70 tier cards from AMD are now $600+. Yea these are fine cards but mid range cards going up in price means the 80 and 90 tier will also go up in price.\n\nThis is what normalization is when it appears most people are generally happy with a product and the price just because the alternative has just gotten so shitty.",
      "Don't worry dude, you're lucky getting that even haha.\n\nI was thinking about an XT at first and the site crashed where I was browsing and then when it came back up the prices had changed to ¬£539 for the 9070 (only ¬£10 more than before) but the 9070 XT had gone from ¬£569 to ¬£629 which is way too much and apparently that's going to be the new MSRP. Which imo makes the 9070 the better value card since it gets within 10fps on average of the XT and is ¬£100 less almost.\n\nIt's very close to the XT, only \\~11% difference. \n\nEither way it's a massive upgrade from a 6700 XT, you'll be pleased, trust me.",
      "Yeah as u/xxxxwowxxxx said, it's almost twice as fast in raster but WAAAYYYY better than it in RT.\n\nAfter a bit of testing and playing around it wipes the floor with my friends 4070 in the MH Wilds benchmark with no upscaling/FG and settings maxed out including ray tracing. \n\nHis score was: 11782 - Average 24.76 fps - Playable\n\nMine was: 26480 - Average 78.19 fps - Excellent",
      "Night and day difference mate, which model did you get?",
      "What sort of change are you getting?",
      "Man I wish this sapphire version of 9070 could be available as msrp in my place. Love the inoffensive boxy design like this",
      "That's what I'm planning to do as well.... I currently have a 6750 which is a very nice card. The 9070 will be a very good update...",
      "Take a shot every time someone refers to their GPU as a \"beast\"",
      "I‚Äôm pretty sure they said that the 9070 XT is the strongest GPU this time around, only a 9060 is coming",
      "Got the same card. Love it! Lots a head room to tweak also.",
      "Have the exact same setup as you down to the CPU and RAM. I'm honestly kinda shocked at how efficient this 9070 Pulse is. Don't think I've seen it break 55c yet, and it's practically silent.\n\nFor a basic MSRP model (not that I got it for that...) with dual fans that's really impressive. My old Gigabyte 3060 Ti was a higher end triple fan model and it was much louder and hotter.\n\nI'm not much of a tinkerer anymore these days but it makes me wonder what kind of gains could be had with some trivial UV/OC on this model.",
      "Agree. Sapphire 9070 is so clean.",
      "Based. These past GPU prices have been a fucking ripoff. $700 used to be the price for the 80ti tier of Nvidia GPU's. The cream of the crop and now it's mid range? Absolute nonsense.",
      "It'll be somewhere near 90%-100%-ish depending on the game, resolution, and settings they're using.\n\nIf he paid the MSRP then its a real solid jump for a decent price."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6700xt"
    ],
    "title": "This kept me from getting a 6700xt at MSRP today. My disappointment is immeasurable, and my day is ruined.",
    "selftext": "",
    "comments": [
      "I cancelled a card because of this back in January.",
      "Bruh my heart goes out to you",
      "I recommend not paying interest on a credit card just buy to computer parts. Seems like that's step 1 or 2 of financial hardship/disaster.",
      "If they only knew the pain they've caused you. They basically replied \"Sorry, not sorry... Peace.\"",
      ">\tjust have the merchant reprocess this transaction!\n\nSure! I‚Äôll just wait through the queue again and oh look at that the queue is over because they‚Äôre out of stock‚Ä¶",
      "If I could get another card with the same interest rate I probably would, too",
      "If someone fraudulently uses my debit card my money is gone, and I have to wait to get it back, if I get it back at all. If there‚Äôs a fraudulent charge on my credit card I can just dispute the charge and not lose my money.",
      "I mean‚Ä¶they borrow money from the government for almost no interest and then loan it to people and charge a lot more interest, so yeah I guess they kinda are",
      "This is the definition of getting cock blocked",
      "Oh for sure. I really just use the card for online purchases so I don‚Äôt have to use my debit card. I just want the lower interest rate for that possible rainy day when I might need to spread out a big purchase.",
      "Fucking *digital river*.",
      "I mean the Chase bank part is already sorted out since I verified it‚Äôs not fraud. I guess I could contact AMD to see if they can do anything about me not getting to buy a card ü§∑‚Äç‚ôÇÔ∏è",
      "I wonder if OP's credit card provider had a lot of charge backs to DRI, hence the flagging.\n\nThat happened to me when I was purchasing some in game goodies ($5!!) and it got blocked until I responded to the text, then I had to do it again, which resulted in a double charge.\n\nOP, that sucks. My new full AMD build is waiting for a GPU, and seeing that hurts .",
      "wait a bird blocked him?!",
      "Chase fucking sucks as a bank.",
      "Heart breaking. I know this doesn't help, but I've got two cards using my Chase account. Both were processed through PayPal though. In fact I can't remember a single PayPal charge ever get fraud denied since I've used it.",
      "Why not use debit for online purchases? Am I missing something US sepcific?",
      "It's a thing all over the world. Credit card companies typically offer $0 liability fraud protection guarantees.",
      "You never want someone with direct access to your bank account. Never use your debit card online.\n\nIt's funny. In US, banks will give you the run around when it's your money, but when it's their money (i.e. a credit card) they'll bend over backwards to solve the issue.\n\nSo, yeah, use a credit card, but pay off the amount within 25 days to not accrue interest.",
      "As far as I know the sales in Amd.com are not handled by Amd."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6750",
      "6750"
    ],
    "title": "Finally upgraded from my 1660 super to 6750 xt ",
    "selftext": "",
    "comments": [
      "Be sure to use ddu to get rid of any nvidia drivers, deleting itself doesn‚Äôt work the way you‚Äôd think",
      "I did *almost* the exact same upgrade (1660ti Mobile > 6750XT) and I'm very happy. Nice pickup.",
      "You must use ddu to uninstall old drivers if your moving from nvidia to amd or amd to nvidia I believe",
      "Get it off the damn carpet!\n\nOtherwise, congrats",
      "DDU is a \"must have\" in any amd gpu, right?",
      "Had to make sure I rub it on the carpet for 5 minutes before installing it into my pc üòâ",
      "Yes. And you might need to use it even upgrading within the same brand, since drivers vary between generations. DDU is the safest bet basically no matter what.",
      "Went from an rtx2060 base model to an rx6700xt, absolute game changer",
      "Because the 6700xt wasnt available for me personally or more expensive \n\nAlso no idea what u mean so much power i havent seen it pull more then 180W with a 1.170 from 1.2 undevolt",
      "Just took my whole pc into the shower with me cheers üôÇ",
      "I asked around and people said get the 6750 if its similar price managed to get it for ¬£310",
      "Lol madlad... Just make sure you throw it in the shower for a few minutes too",
      "As a 1660s user I approve of this post. Nice upgrade sir. Hopefully I'll be upgrading soon too. The 1660s is a great card, but I feel it doesn't have a lot of life left.",
      "Probably the same reason I upgraded to the xfx 6800xt merc about 1.5 years ago.\n\nThe closest nvidia performance in raster would of cost at minimum about $150-$200 more and actually loses in raster and thats the 4070. The cheapest nvidia card to consistently beat mine is the 4070ti, which would of been at minimum $450-500 more than my 6800xt, and it doesn't win by double not even close. For the record I play in 4k.\n\nI paid a little over $500 for my card new.\n\nNvidia can pound sand with its current price to performance.  In the past their premium was worth it because it really wasnt much more price wise and performance was solid, that is not the case today their prices are ridiculous. \n\nThat said my card has been fantastic, no driver issues, has worked great since Ive owned it and a much better menu system with adrenaline. \n\nNvidia is finally getting around to copying adrenaline after a fair number of people shamed them for how poor their software was in comparison. They used two different very slow and old menu interfaces and rely on third party vendors for OC/undervolting tools.",
      "Good man, lots of soap. Pro tip, throw some corn meal in there. Really lubes up those contacts.",
      "Dude welcome! I just did the same thing but to 6700XT. It will change your life completely. Enjoy :)",
      "It's price and availability.\n\n\nBasically the 6700XTs stock is running dry or I would¬†say is nonexistent¬†and whatever left from the overpriced 6750XT is being sold cheaper or at the same price as the 6700XT to clear inventory.\n\n\nThat's how i got mine cheaper than the highest models of the 6700XT.",
      "In many places the 6700 isn't available anymore",
      "Unlikely according to literally all marketing data your average consumer is effectively a herd animal, or tribal in nature.\n\nPolitics, gaming consoles, marvel vs dc and on an on.\n\nYour thoughtful consumer that shops by what actual value they need/want/get are a minority. \n\nJust in these subs the majority boils down to \"no my team is better\" or \"nuh uh, your team is terrible\".\n\nAt 4k raster 6800xt is a better card than the 4070 while costing far less, the cheapest nvidia product to barely beat mine costs nearly double.\n\nLastly as someone who has been running a business for a long time now I can asure you, your average consumer basically needs their handheld just on simple things.",
      "Did the same thing went from 1660ti to 7800xt a few weeks ago, congrats ‚å®Ô∏èüñ±Ô∏è."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6700xt"
    ],
    "title": "Couldn't be happier with this Red Devil 6700xt.",
    "selftext": "",
    "comments": [
      "I just installed a RX6700XT from XFX, the QICK 319. Looking good",
      "nice ram tho",
      "Gskillz trident royal red devil aesthetics for my ram",
      "I picked up a red devil 6750xt and I can‚Äôt wait to install it later! Officially switched over to the Red side",
      "That's Dirt Devil",
      "Meant for you to choose a colour?\nThough I agree it often looks best, it‚Äôs ‚Äúmeant‚Äù for you to do whatever you want to do with it.",
      "Fine whine",
      "Such a sexy card... I REALLY want to get a 7900 XTX Red Devil! \n\nEnjoy your card it is awesome!",
      "Eyyy same here! Its a fantastic card.",
      "still silent even overclocking",
      "I got the SWFT 309!",
      "Nice nice, my local Microcenter has one been tempted to buy one.",
      "Isn‚Äôt the red devil a vacuum?",
      "That or a Toxic 7900XTX",
      "I paired it with 5700g for the meantime.",
      "I'm very happy with mine and have no idea how many years it'll be before I want an upgrade.",
      "Dang, my red devil 6800xt whines a lot",
      "Hot",
      "Any coil whine with that card?",
      "got the exact same card yesterday, it's a beast!"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6700xt"
    ],
    "title": "R9 5950x/6700xt",
    "selftext": "",
    "comments": [
      "Ah a fellow 5950x enjoyer. The rare unicorn cpu of the 5000 series (i \"upgraded\" to 5800x3d when it came out)",
      "Marvel movies need a high-end CPU to process everything being CGI.",
      "ah a fellow 550M Steel Legend! Gotta love the logo",
      "You built this to watch movies?",
      "I got it for a steal from a buddy also! Paid 150usd for it!",
      "I like this answer üòÇü§òüèº",
      "Good setup, the aesthetics of the fans are very well done too!",
      "Looks Sharp! Which AIO is that? How's your temps? What kind of fps do you get in your fave games?",
      "Nice fans",
      "Very nice. I‚Äôve been running that combo for a few years now and it‚Äôs awesome.",
      "Good looking build man!  I have an rx 6700xt as well.  Do you play at 1440p?  Also, are you running Plex for your movies?",
      "Love my Steel Legend board! Never had any issues with them I‚Äôve used a few of the b450 ones on other builds also",
      "Thermalright frozen infinity 360mm, temps stay around 60-65c while gaming! Around 140-150 fps on BO6 at 1440p, 75-100fps 1440p high settings with Ray Tracing on.",
      "No? But I do watch movies lol Why would I build it and not use it for movies also? I play a variety of games",
      "It could be a reverse airflow fan. Looks like a Montech and they do have a reverse fan in this style (I have some)",
      "Good to know!",
      "Correct! It‚Äôs an intake just one of montechs reverse fans",
      "Oh I reread you're comment. You're talking about gaming rather than stress test. My bad. If you run Prime95 or OCCT you will probably hit 90C. Gaming isn't nearly as stressful in terms of heat as it's lightly threaded work.",
      "Why such an overkill CPU with such a \"low\" gpu? I just bought a 6700 with a friend, and upgraded from a 7100 to 7700k (max supported)",
      "Is that bottom fan installed as an exhaust, fighting your graphics card's airflow?"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6700xt",
      "6750xt"
    ],
    "title": "AMD Radeon RX 6750XT shows up on GFXBench website, 2% faster than RX 6700XT - VideoCardz.com",
    "selftext": "",
    "comments": [
      "Can't wait for the flood of reddit posts asking if upgrading is worth it...",
      "Hey man, I need that 2 more fps to increase my cod kd ratio!!!",
      "Hey guys, I just bought a 6700XT a week ago but the 6750XT just came out and I'm wondering if it's worth buying it, selling my old one, going through the hassle of swapping the cards, and reinstalling my drivers for one more FPS? Any help appreciated :)\n\nEdit: It's already started https://www.reddit.com/r/Amd/comments/uai72h/gpu\\_6900xt\\_vs\\_6950xt\\_opportunity/",
      "so I take it 6900xt to 6950 xt will be minor",
      "The purpose of these cards is just to change the MSRP. Just like how the 3080 12GB resets the mouth watering $699 price point.",
      "A 2% increase that will make the price 10% higher",
      "You might get the headshot in that extra frame... I'm seriously considering it. You will also have extra bragging rights about owning the 6750xt. Win - win",
      "\"lol\" said amd, \"lmao\"",
      "I mean I think the 6900xt with the oc chip will trade blows with a low end 6950xt",
      "I think they mean Navi 21 xtxh",
      "As a bonus, you'll feel validated that some random people on the internet told you that your stupid purchase was a good idea",
      "Bruh, Nvidia has been doing this for years. Super, Ti cards literally have 5% or less performance difference between. Hell, they released an entirely new 3080 sku with 2 more gigs of vram.",
      "I'd be shocked if it's only 10% more.",
      ">Bruh, Nvidia has been doing this for years. Super, Ti cards literally have 5% or less performance difference between\n\n2070 vs 2070 Super  \n2060 vs 2060 Super   \n3060 vs 3060Ti  \n3070 vs 3070Ti  \nthose are 5% differences ? They are not cause Nvidia atleast has the dignity to change the core count as well as memory speed or bus width while at it.",
      "The 3060ti, 1080ti, and 1070ti are the real stand outs from these types of cards. The 3060ti is basically a 3070 and a performance tier above the 3060, the 1070ti is basically a 1080 and the 1080ti is the GOAT and smokes the normal 1080. The 3070ti is ass not even in the same convo as 3060ti.",
      "I am a very PRO AMD but what is up with AMD coming up with slight variation of AMD GPU. Are they enabling small subset of features in the GPU just to keep their sales going and 'launching products'? \n\nWith the hype around Ryzen 7 5800x3D and its pricing close to Ryzen 9 5950x, why haven't they released Ryzen 9 5950x3D with it to put 5950x totally obsolete. Or is their excuse, \"still in research and design phase\".\n\nMy gut feeling tells me they are trying to get rid of 5950x before releasing 3D version or successor to 5000 series. Afterall, AMD is a corporation and I have strong fanboyism towards them.",
      "Honestly - I don't know what the hell people expected? 10-15% gains from tiny bit faster memory? It's just there so they don't sell different spec GPUs under same name - like nvidia likes to do. That's all there is to it. At worst - maybe it's their shoddy attempt to bump msrp. Do we know if these cards will have the same MSRP as vanilla cards? Because for sure it shouldn't be higher, if anything - same or lower, because it's end of the gen as next gen GPUs are launching this fall already.",
      "Just wait till the 6770xt it‚Äôll be a whole half a percent faster than the 6750xt",
      "Except they‚Äôre not 6nm. Still on 7",
      "AMD -20 percent faster and 20 percent more expensive 5 years later"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6700xt"
    ],
    "title": "Repasting my first GPU I got back in 2019: the RX5700! Feat. my newer 6700XT on the left.",
    "selftext": "",
    "comments": [
      "Pray that you never learn the fear of repasting an AMD graphics card with HBM1.",
      "Its pretty loud when the fans ramp up and it can get toasty yeah. But its not really a problem for me cause I wear headphones and its only loud and hot when you oc and push it to 99%.\n\nTune the card, undervolt with a custom fan profile and a good repaste, and its a pretty capable and decently quiet card. The performance uplift of the 5700 should be massive over the 470 esp if its cheap. Worth going for imo.",
      "HBM1 is extremely fragile.",
      "Why did you repaste? Was the temps getting higher than normal? Kinda curious how long the paste lasts.",
      "What's up with HBM1 cards haha. Only know that they're faster but more expensive than GDDR.",
      "Nice mate...its msi mech 2x its the same card im using now...i dont have any problems using that card..",
      "A buddy offered me a vanilla 5700 cheap, I was thinking of getting it to upgrade my son's 470 so we can coop in Space Marine 2 lol. Is the blower noise all that bad like people said? Things like new paste and pads, I can manage just fine",
      "I bought used GameRock 3070. Its manufacturing started late 2020 (don't know when it was purchased though). Paste was dried and hotspot was ~108 C. I repasted and now hotspot is ~78 C. It's three months since repaste and hotspot is still ~78 C under hard stress. I used MX-6.\n\nEdit: checked the receipt: it was bought july 2021. So it was used less than two years and paste was dried. Let's see if MX-6 is better than the original.",
      "That's a very aggressive repaste schedule. I've used cards for 5 years straight and had no issues with thermals and did absolutely nothing to them. My server hasn't had any thermal issues and that thermal paste is going on 10 years old, but that's a CPU. Generally, you only need to repaste if you notice thermal issues, which you might have, but otherwise it's probably not necessary.",
      "I did a fury repaste and Vega 64 repaste both were fine except the Vega now is a little weird about how tight the cooler has to be after going from a blower>morpheus II>water block> blower again. The reason I went back to a blower was to shove it in a friends pc after I upgraded to a 6900xt.",
      "How much more fragile was HBM1 compared to HBM2?  I skipped the Fury cards (I bought a house in 2014 so I rode out my 7970 3GB for six years from 2011 to 2017).  I did get a Vega 64 shortly after building a Ryzen 1700 new build at launch.  I repasted my Vega a year or two ago and was really worried I'd chip/flake the HBM2 trying to clean off the old TIM.  I had heard that HBM1 was even more fragile though.",
      "Always Sapphire. They overengineer their cards to the point where they often are both cooler and have slightly higher boost clocks than the competition. I hear they have great customer service but don‚Äôt take my word for it, I‚Äôve had two Sapphire cards and never had any problems with them.\n\nThey didn‚Äôt pay me to say any of that by the way, but I will be more than happy to accept money, Sapphire‚Ä¶",
      "Now it is overheating more than before!!",
      "Oh and I forgot to mention. Has risk to it, but if you like tinkering and playing around with hardware, you can flash a 5700XT bios on it and see how much further yer silicon can go if ya want to.\n\n5700s' are capped at 1800Mhz. With the bios flash I can run it at 2000-2050ish Mhz. Adds a bit more fun to owning the card.",
      "Haha, i threw together an old parts build for my parents a few years ago, so i tossed in my old gtx285 blower card, since they didn't need a good gpu (just basic browsing and taxes, etc). Started it up, and the idle was at 80c, lol.  OG paste was brittle and dry AF.  Repaste got it down to around 50 idle.",
      "While the Sapphire is better yes, especially if they can be had at the same price point, the MSI Mech is popular for a reason. It was the first to drop to the current price point and I've not seen really anyone say anything bad about it who owns one. It's a very good card for 1440p at 120-165 fps. I'd know since I use mine every day.",
      "This can be a fun process üòÅ\n\nI remember repasting my old 1060 a few years back.",
      "my first gpu was a voodoo 2 back in 1998 I wish I still had it.",
      "The current 5700 XT I have I bought in Oct 2019. So I'm at 3.5 years now. .\n\nI never opened the card, but I did clean it of dust by blowing on it or using a thin paint brush.\n\nWith a tiny undervolt/underclock, temps are 55C core and some 70C TJunction at ~70% fan speed during max load.",
      "It's the 5700XT reference that have a loud blower fan. The non XT model's blower fan runs much quieter due to having a lower TDP. I've used the reference RX 5700 for a year and hardly noticed the fan noise."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6700xt"
    ],
    "title": "6700xt Red Trim delete.",
    "selftext": "",
    "comments": [
      "Looks better - Looks \"factory clean\"\n\nNice job :)\n\nMaybe check if the paint does not affect/attacks the plastic, after a while (i do not know the paint)",
      "Thanks! \n\nTestors paints are made for plastics (think model airplanes or gunpla) so Im confident there will be no issues.",
      "First I was like: \"Why?\"\nBut then saw the result, looks good.",
      "Looks really clean, nice work. Wanted to black out my 6800 non-XT when I had it, but didn‚Äôt have the confidence that I‚Äôd do it right lol",
      "Used some Testors Metallic Aluminum paint to get rid of the red trim that just didn't jive with my PC. Hopefully I can figure something out for the Radeon logo.",
      "i like this kind of content",
      "Redeon logo should be red you bastard.",
      "uuu, nice.\n\nWell, if you mod your logo too, I will upvote it when I see it :)",
      "I'm restaining a cabinet with a gel stain. It's supposed to be mostly  idiot proof... Heh",
      "can't agree more. It would have looked killer with that red stripe as an ARGB strip.",
      "Lol. It's not the biggest deal.",
      ">amd radeon rx 6000 rgb tool\n\nUnfortunately the 6700xt is red only :/",
      "Looks much nicer aesthetically. I think AMD should have used an adjustable RGB led strip in their reference cards instead of their mandatory red. It would have allowed people to slightly tune the cards color scheme with the rest of their layout.",
      "Its pretty easy, Id recommend the Testors paint and some of their thinner for clean-up. Black would be even easier.",
      "unfortunately that doesn't work for the 6700xt. It's red only :/ thanks though.\n\nTool is only for 6800 and above.",
      "lol i made a post wishing i got the regular colour theme more but got roasted",
      "Thanks buddy\n\nEdit: This is just me wishing I got the midnight black card, lol.",
      "Such an uncivilized weapon.",
      "I didn't know you could change the colour! I thought it would be just lame AMD red. You just made my day, buddy!",
      ">amd radeon rx 6000 rgb tool\n\ndamn why they call it 6000 tool then so misleading :("
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6750",
      "6750"
    ],
    "title": "Amazon Deal: AMD RX 7800 XT 16GB, 6750 XT 12GB prices puts Nvidia RTX 4070, 4060 to shame",
    "selftext": "",
    "comments": [
      "Should be comparing the 7900 GRE for $550, most people forget it exists lol",
      "They're talking about the 4070 non super...Did you even read the article?",
      "So where in the UK is this price updated?",
      "Here is the breakdown if you compare a $480 7800XT against a $600 4070 Super:\n\n* 4070 Super +25% more expensive\n* 4070 Super [+14-38% faster in RT](https://www.techpowerup.com/review/nvidia-geforce-rtx-4070-super-founders-edition/35.html)\n* 4070 Super [+8% faster in aggregate gaming benchmarks](https://www.techpowerup.com/review/nvidia-geforce-rtx-4070-super-founders-edition/32.html)\n* 4070 Super [significantly faster in these common compute tasks](https://www.techpowerup.com/review/nvidia-geforce-rtx-4070-super-founders-edition/37.html)\n\n\n\nI guess it's not that clear cut. One is a better product, and there is a 25% premium for it.",
      "If you don't care about upscaling, yeah. I love the 7800xt and if DLSS isn't a factor for you it blows the 4070 super out of the water in value but it needs to be mentioned.",
      "The 6800/6800XT late adopters were the real winners if you have to make a fuss about a $480 7800XT years later.",
      "That one compares less favorably. The 4070 Super is clearly the better buy there IMO. [Deadheat in aggregate gaming](https://www.techpowerup.com/review/sapphire-radeon-rx-7900-gre-pulse/32.html), 4070S retains its clear RT/compute/feature advantage while drawing 40-60w less at just $40-50 more.",
      "> So even if I believe you (I dont)\n\nNobody cares, you literally have a nonexistent CPU in your flair, touch grass",
      "It depends, to be fair. If it's a cheap 2 vent card, then the heat and noise will destroy any positives. I know that.\n\n\n7900 gre has pretty cool stuff with not much price that is very efficient. And that makes them more attractive.\n\n\nRT stuff isn't a clear winner here, btw. 12gb hurts 4070s a lot, since you have to sacrifice something to get a decent performance.¬†\n\n\nIn short. The only clear advantage is production in CUDA specific apps (there are lots of them though). If that's important - 4070s is better. Everything else is not worth the premium here",
      "True gAmErS render at native resolutions",
      "You turn DLSS off now? With your 6900XT?",
      "Calling it an article is a reach. They're generating revenue from what is essentially an ad. I was providing more context/performance figures.  Though TIL the non super is still being sold, I thought it was discontinued.",
      "Yeah, sure, but your post isn't relative to what they're discussing...So yeah.",
      "Shame? This \"article\" is a joke. It's just a click-through affiliate ad for $15-20 of a 9-month-old GPU that wasn't even a meaningful upgrade from its predecessor. The laziness of using Nvidia's poor pricing to excuse AMD's poor pricing is so tiresome.",
      "The driver thing is a red herring.  I honestly don't know why Nvidia has been given a pass on driver issues when they've had plenty over the years. I can name quite a few I've personally experienced, even up to today. AMD drivers have been fine for a while. *Shrug*",
      "The 4070S will shortly become the new 3070. Limited by its VRAM. There are currently plenty of games that use over 12Gb at 1440P. Give it another year or two and people will be saying 12GB isn‚Äôt enough for 1440P.",
      "Hows your 9800x3d running? xD",
      "7900 GRE is better at rasterisation which is all most care about though",
      "There really aren‚Äôt any today. It‚Äôs just VRAM-crazed ranting. That why the reply is ‚Äúoff the top of his head‚Äù. The extra 4GB will surely make 16GB cards ready for 2044 and beyond.",
      "Its only my personal experience, but this has not been the case at all for me."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6700xt"
    ],
    "title": "my all white pc v2 - 6700xt, 5900x",
    "selftext": "",
    "comments": [
      "I don't think you have enough fans",
      "Did you just spend $400 on Lian Li fans?",
      "That GPU sag is making me nervous",
      "I‚Äôve learned 2 things from this.\n1) you can actually have all things white \n2) you can actually have enough fans to allow the tower to hover and heat your room efficiently lol",
      "The primary focal point is fuck my wallet. That‚Äôs like 500 bucks for fans",
      "So glad my humongous gpu came with a support arm, I was worried about that too lol",
      "6 fans on an AIO. Ok‚Ä¶ but why",
      "when cosmetics become the primary focal point, practical, or even function deteriorate potentially significantly.",
      "I got the gpu last year when the market was still horrible",
      "Could have gotten a better gpu if you didn't spend all that money on fans. Looks clean though!!",
      "Push pull configuration",
      "Nice build but holy hell is that many fans!",
      "The case is very wide, it's effectively in the \"back panel\" cavity. See this image, it's the right hand corner. https://lian-li.com/product/pc-o11-dynamic/",
      "I think you have too many fans. It's been proven that having too many will blow through the case and be exhausted before the airflow has a chance to properly cool the components. I would lose the row above the radiator and the fans along the bottom. It is a good thing to have positive case pressure. Just my .02",
      "I don‚Äôt see a problem with his choice?",
      "And holy hell the position and direction of those fans. R.I.P airflow",
      "Not worth buying, had three of them burn themselves. So basically like most NZXT stuff",
      "6700xt, 5900x, 32 gb 3600mhz cl18 ram, 1200w psu, nzxt n7 b550, 16 al120 fans, lian li strimer plus v2 cables, lian li o11 evo, nzxt z73 white aio",
      "Humongous gpu sack",
      "3 of the fans push air through from the bottom side of the radiator, 3 fans pull air from the top side, so it improves airflow.\n\nDebatable if it's needed in any standard setup, unless you're OC'ing your chips to their limit and even then, 360mm rad should be enough (excluding extreme OC with liquid nitrogen etc)"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6750xt",
      "6650xt"
    ],
    "title": "AMD Radeon RX 6950XT to cost $1099, RX 6750XT $549, RX 6650XT $399 - VideoCardz.com",
    "selftext": "",
    "comments": [
      "AMD marketing : 7700 XT faster than 6950 XT for only $899.",
      "Bruh this gives me no hope for next gen. It‚Äôs sucks that the low mid range segment is basically gone. No more 200-250 dollar price to performance king",
      "I'm guessing this pricing model will reflect RDNA3?",
      "Finally GPUs were dropping prices and these companies start raising MSRPs again.",
      "I'm not buying any of this crap 100%",
      "This is literally exactly what I said and predicted would happen. So many posters over the past month or two were on this tangent about how prices would return to pre-2016 levels including the MSRP's and I knew that was never going to happen.\n\nThe mfg's know that people are more than willing to pay these higher prices for these cards, and they have perfect justification for the high MSRP's. Inflation, shortages, R&D costs for the process technology, etc etc. People need to stop buying them at inflated prices in order for the prices to drop, and you cannot get enough people on board with that for that the happen. What we are seeing now with the prices dropping is about as low as its going to get IMO. + or - 10% of the MSRP's until supply is used up before the next gen release.",
      "'budget friendly mid range offer!'",
      "$400, literally same MSRP of the 3060 Ti, for a x8 lane GPU. Can't wait to see this thing be torn to shreds in the reviews.\n\n$550, price is nipping at the heels of the RX 6800, which has 20 more CUs / RAs, 4 more GB of VRAM, a 256-bit bus, and 128 MB infinity cache. With this kind of pricing structure, will AMD stop production of RX 6800s and replace it with RX 6750s?\n\nThe 6950 XT already exists - 6900 XTXH models, which are being panic-sold for less than $1100 because GPUs are available again at sane prices.\n\nI think this is even worse than the Ryzen 3000 XT refresh.",
      "Looks like the gtx980/1060 performance tier is never going to leave the 200 dollar price point. I'd kill for even 2060 performance reaching down there now.\n\nWhen it possibly comes, it's gonna be on x2 and x4 slots, so I'll still end up getting the same performance. Remember when $400 was considered the most you reasonably needed? Now, it's the bare minimum.",
      "Terrible pricing, I thought these were supposed to replace the existing cards as refreshes? \n\n**Bad AMD, bad.**",
      "overpriced for the current climate.. \n\n&#x200B;\n\npeople are cutting spending and stocks are dropping like flies today..",
      "According to leaks , they are stopping production of RX 6700XT , RX 6600XT and RX 6800 . So , the prices probably won't decrease much",
      "Here is my opinion on these prices:\n\n6950 XT at $1099 is asking a bit too much for an overclocked 6900 XT. If AMD ships the XTXH chip for all 6950 XTs it wouldn't be horrible since the premium Navi 21 cards are already more expensive than this.\n\n6750 XT at $549 is BAD, really really bad. %15 price pump would only be justified by a 15% or more increase in performance, which is highly unlikely by only adding faster memory and high clocks without core count change. At this price, the card is approaching the current 3060 Ti market price, the 6700 XT competitor. NVIDIA's feature set is superior and makes a 6750 XT at the same price look very dumb.\n\n6650 XT at $399 is fine I guess. But again, this increase in price should be justified by a proportional performance gains.\n\nAnd a reminder, these prices as shown in the posters aren't \"MSRP\", but the price of the reference models, which definitely are going to be fewer in quantity than AIB models and certainly cheaper.",
      "Was considering the 6750xt but $549 seems a little steep.  I was hoping for $500 or same $479 as the 6700xt would have been better.",
      "yeah, its a damned shame theres no budget friendly entry cards, if you want somthing \"okay\" for that price its secondhand market or nothing.\n\nYou could buy a xbox or ps5 for whats \"good\" right now and thats never been the case historically",
      "Yup - looks like budget game is dead. Unlesss.... perhaps I could interest you in YET ANOTHER sub rx580 level performance budget piece of crap with gimped specs for only 250 dollars in 2022?????",
      "Even with MSRP 6750XT‚Äôs pricing doesn‚Äôt make sense.",
      ">will AMD stop production of RX 6800s and replace it with RX 6750s?\n\nYes. \n\nhttps://www.hardwaretimes.com/amd-radeon-rx-6750xt-to-replace-the-rx-6800-lower-performance-same-price-for-better-profits-report/\n\nObviously this is just info from an inside leak, but we've no reason not to believe it.",
      "That's ridiculous. Guess I'm gonna be using a 1070 for a decade..",
      "It's the same thing as the 3070ti, 3080 12GB, and 3080ti, now the GPU has higher yields they rebrand the card for an higher price and this way they can get more money out of that silicon"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6700xt"
    ],
    "title": "XFX Speedster SWFT309 6700XT - $329.99 ($100 Off) with Starfield Key ($69 Value)",
    "selftext": "[XFX Speedster SWFT309 AMD Radeon RX 6700XT 12GB GDDR6 PCI Express 4.0 Gaming Graphics Card Black RX-67XTYJFDR - Best Buy](https://www.bestbuy.com/site/xfx-speedster-swft309-amd-radeon-rx-6700xt-12gb-gddr6-pci-express-4-0-gaming-graphics-card-black/6513905.p?skuId=6513905)\n\n**Update:** Many people mentioned that this was actually the Premium version of Starfield. This turned out to be true. I activated my code this evening and it is Premium. This makes the savings more impressive (Provided you wanted Starfield as I did).\n\nIf you click \"Overview\" in the product details you'll see Starfield information. Puts the overall value of card at $260 new. Picked mine up today and already received Starfield code. Seems like a good deal for my 1440p comrades.",
    "comments": [
      "1440p a gimmick. Okay...",
      "Did you receive starfield premium or the base $70 version? I thought the premium version came with the 6700 and up.",
      "I'm no psychic but I think we already know the answer",
      "1440p is the literal sweet spot for gaming, it‚Äôs not too demanding and looks the best. I visually can‚Äôt see a difference between 1440p and 4K plus 4k is way too demanding for the not so much visual uplift to me. I sold my 4k monitor and went to a 3440x1440p ultrawide and it‚Äôs amazing for gaming. \n\nBoth of my friends have a 6700xt and game on a 3440x1440p ultrawide at max settings without any issues so 1440p being a gimmick is ridiculous to say.\n\nEveryone always uses cyberpunk as a benchmark and it‚Äôs ridiculous because it‚Äôs one of the most unoptimized clunky games. Plus it‚Äôs a sponsored nvidia title so of course amd will have issues with it",
      "Don't undersell it 1440p/60+ is very possible. It says 1440p on the box.",
      "6700xt gives you premium , so it‚Äôs worth $100",
      "You can also get Starfield Premium with the Radeon 6700 non-xt. Starfield Premium is $100 MSRP.\n\n[Newegg](https://www.newegg.com/xfx-radeon-rx-6700-rx-67xlkwfdv/p/N82E16814150874?Item=9SIAD2CJUE7407&nm_mc=AFC-RAN-COM&cm_mmc=afc-ran-com-_-PCPartPicker&utm_medium=affiliate&utm_campaign=afc-ran-com-_-PCPartPicker&utm_source=afc-PCPartPicker&AFFID=2558510&AFFNAME=PCPartPicker&ACRID=1&ASID=https%3a%2f%2fpcpartpicker.com%2f&ranMID=44583&ranEAID=2558510&ranSiteID=8BacdVP0GFs-.RmOPs3FZgmsicMHI7.MPQ) $269.99\n\n[Amazon](https://www.amazon.com/dp/B0BCL3L6ZG?m=ATVPDKIKX0DER&ref=psp_pc_a_ACHKWB63YKPQJ&th=1) $271.43",
      "*demo\n\nBethsoft isn't fixing anything in 6 days. (Or at all)",
      "What do you mean by gimmick?",
      "i got a sapphire 6700xt for 340 euros like 2 weeks ago on a spanish online store, we get deals like that in europe, at least in my county we do",
      "If you don‚Äôt have the hardware to play 1440p high refresh then why are you saying 1440p is a gimmick? 1440p is not that demanding by todays standards if you have the hardware capable of running it. 1440 high refresh can be had in esports games with low settings on a 1050ti at 1440p lol. No one cares about eye candy in those games anyways.\n\nIf you want to talk gimmicks RT is a total gimmick to sell rtx cards. When you get a good title that‚Äôs pre baked with lighting and screen space reflections you see how much RT is a gimmick.  \n\n4k is a waste and not worth the step over 1440p",
      "I think the reason he's getting frustrated with you is your insistence on calling 1440p a 'gimmick'. It clearly is not a gimmick, it is  a significant increase in visual quality.\n\nIf you mean you think 1440p is not worth the tradeoff in terms of loss of performance, then that is an entirely valid opinion. A gimmick however it is not.",
      "Ya I switched from 1080p 60hz to 1440p 144hz it's awesome.  I would never go 4k it's too expensive and the framerate isn't there. \nAfter that I changed to an ultrawide and I love it!\n\nI'd pick ultrawide over 4k any day of the week",
      "Comparing my 4k TV to my 1440p monitor I can't even tell much difference while gaming full res. The step up in resolution to 1440p is much more noticeable from 1080p than 1080p to 4k.",
      "Imo the reason 1440p is used is because 4k is kind of overkill at typical monitor sizes for gaming, while 1440p still being a noticeable uplift from 1080p (it's about 78% more pixels). It also isn't nearly as demanding.\n\nPersonally, I like 3440x1440 the most for gaming.",
      "I honestly don't know because I haven't activated it through AMD rewards. I just assumed it was the base version ($70).",
      "Yes this isn‚Äôt new at all. Stupid post",
      "The terms and conditions from AMD state that it'll be steam\n\nhttps://www.amdrewards.com/terms",
      "Yeah most resellers also give the game too.",
      "Yeah but that's the whole point, 1440p is a balanced reasonable middle ground. The pixel density is much higher than 1080p, without being 4x as much as 1080p therefore easier to run at high refresh rates\n\nIt allows users to have a higher resolution without completely tanking their frame rate\n\nIMO your point kind of sounds like \"the 6700 xt is just there to fill the gap between the 6600xt and 6800, it's kind of a gimmick\", when the whole point is that there is a huge gap between the two"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6750xt",
      "6650"
    ],
    "title": "AMD Radeon RX 6950X, RX 6750XT and RX 6650 XT pictured, release date moved to May 10th - VideoCardz.com",
    "selftext": "",
    "comments": [
      "Gotta' hand it to AMD, they've really knocked it out of the park with their new reference cooler designs, I like the way these look more than most of the AIB offerings.",
      "Can‚Äôt wait to see how they get priced",
      "\"Moved\" lol. They never announced any date, videocardz just doesn't want to admit their last rumour was wrong.",
      "Indeed, Nvidia too - I'm really glad that at least the first party cards don't have any of that l33t g4m3Rz nonsense.",
      "calling $530 - 550 for the 6750X\n\nedit: called it https://videocardz.com/newz/amd-radeon-rx-6950xt-to-cost-1099-rx-6750xt-549-rx-6650xt-399",
      "I hate the fact there is no all black 6800 non-xt",
      "people who missed out on the all black 6800XT can now rejoice",
      "You have some really weird cheese graters.",
      "I'll eat my hat if it doesn't sell for at least 700 euros in Netherlands",
      "I still wish one of the aibs would just sell a reference card with no cooler and discount it by the material cost of the cooler.  As someone who has a low maintenance custom water cooling loop on my main rig, I hate that I always have to buy cards that I immediately remove the cooler from.  I prefer the reference cards because they are the easiest to find a water block for at a reasonable price. I also avoid the special edition models that already include a waterblock not just because of steep price markup that comes with such limited production run SKUs but the issues with everything from QA to likely hood of any firmware issues being addressed after launch.\n\nLet me buy a reference model without a cooler and knock a few bucks off the MSRP.\n\nI really do prefer my custom water cooling loop because it's lower maintenance than air cooling.  I just occasionally run a vacuum over my case air intakes and am good. Years back I got tired of all the enthusiast water cooling hardware and decided to copy data center water cooling by going to AutoZone for [EPDM](https://en.wikipedia.org/wiki/EPDM_rubber) rubber hoses, [crimp clamps](https://m.media-amazon.com/images/I/616u4IFDAvL._AC_SL1000_.jpg), and [gasoila thread sealant](https://www.jmesales.com/gasoila-soft-set-thread-sealants-w-ptfe) .  I just add 30% pure propylene glycol to filtered water and the coolant level never drops due to zero leaks ever. No water reservoir needed because no loss of coolant. No dye or additives and hoses are EPDM rubber so coolant never becomes fouled. Always use fittings and water blocks that are nickel plated so no chance of galvanic issues. I change the coolant every 3 years when I upgrade my system.",
      "I don't mind the edgy gamer cards (I actually think the Aorus ones look quite nice), and I think it's cool that Yeston is making some unique designs (even though none of them really appeal to me, personally), but AMD's \"Fuck you I'm a graphics card\" approach is a kind of sweet spot.  Obviously a lot of design time went into it, it's detailed, but it's still simple.  \n  \nIt's a really good middle ground, it'll work in a gamerz build, it'll work in a professional build, or you can put a solid panel over it and not feel like you're hiding something that's supposed to be attention grabbing.  \n  \nUnfortunately aesthetics matter, it's why I'll probably never get anything made by ASrock; they have good to fantastic hardware, but I don't like the way it looks.",
      "Higher clock/power limits, too. Let's see a 3GHz/21Gbps OC on a 6950XT water",
      "I got a reference 3070 (when such a task was difficult but not impossible) and I couldn't imagine why you would want to get an AIB. The reference cooler is so good and it's the cheapest version. Some of the 3070s were approaching or surpassing 3080 pricing which is just silly.",
      "They look badass with the stealth black.",
      "I mean, it's not rocket appliances.\n\n1. They'll go slightly faster.\n2. They can charge slightly more.\n3. It's fuck all engineering work to make them.",
      "At least you can get a 6800XT blackout, we can't get them at all in Australia, never have - unlikely to ever get them here either.\n\nReference navi21 cards ended Jan 2021 and haven't been seen since. AMD lied about further stock for distributors.",
      "Or just a price cut on the 6600",
      "Sucks that we can't get them in most of EU.",
      "Gonna hold out until next gen, hopefully I can get a good deal on a 7800/4070.",
      "It's a typo."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6700xt"
    ],
    "title": "Chonky boi upgrade today Vega 56 to Asus 6700XT OC",
    "selftext": "",
    "comments": [
      "Wait, vega 56 is old already?\n\nIm crying here with my rx 580 I bought from some miner in August 2019.",
      "I got my vega 56 back around then too its not old but its a stock blower one and I really did not want to after market it. The vega architecture was good but sadly not that good",
      "Its on EBAY atm, im uk based so seeing what happens with it, it is a hairdryer tho :)",
      "Any plans to sell the 56? \n\nI was planning on building a new rig for my wife.",
      "To be honest my Rx 580 is still fine, even with 4 gb of VRam it kills everything.\n\nRecently I bought 4k screen since I moved to work from home and need 2 screens (some people did it at the start of pandemic, I just decided to take it slow :P )\n\nAnd it lags a bit but it might be because of the HDMI cable they gave me, need to replace it with Display port and see if it helps. If not then I guess it will be time for new GPU ;/",
      "I just ordered my 6700xt too! Had an vega 56 as well. Sold the 56 to a miner for 500‚Ç¨ and bought the 6700xt from an amd drop for 500‚Ç¨. Will arrive next week.",
      "So far its been good Timespy more than doubled from 6,625 to 13,355 at 1080p 144 HZ no longer do I have a small hairdryer taking off when gaming.\n\n&#x200B;\n\nGot the GPU for ¬£779.99 from Scan UK. Its marked up but it was in stock\n\n[https://imgur.com/a/Px9EwJV](https://imgur.com/a/Px9EwJV) here is the Chonky boi in the case\n\nalso shoved another 16GB of ram in while I was at it",
      "Nothing wrong with a RX580 I've had mine since April 2017",
      "well I have more than doubled the Timespy score, Overwatch is locked at a solid 144FPS now with my free sync monitor can get like 250+ if I uncap it but that's not needed. the main thing that is good now is that its no longer like standing outside an airport when gaming :D",
      "Removed the link ... i guess it was not listed about linking to Ebay even tho I checked",
      "Holy fuck! They're so big now!",
      "Current gen hardware is really something, especially the higher end. I have a NH D15 cooler on my 5900x and an EVGA 3080ti, I can't even see my motherboard (ATX).",
      "Love my Strix 6700xt! I overclocked and undervolted it, and it beats most of the 3070 benches I‚Äôve seen.",
      "Mine is up on Ebay atm, if I get ¬£300+ for it I'm happy looking at what is available right now It should go for that easy",
      "Was the upgrade truly worth it? I'm eyeballing a 6700xt and I'm coming from a Vega 56 on 1080/144. My Vega is on custom water though...",
      "Link to the page?",
      "got the wife a 3070ti which comes in a couple of days I was toying with the idea of one but I have liked AMD updates etc since I got the vega 56, and recently went to 5800x from an i7 4790k so its not too bad now, the price was over the top but got it on paypals 4 months interestifree so that will be paid before thats up",
      "aye my vega 56 was fine too, but new job and all that so why not get myself something shiny :)",
      "I love the reference vega design, soooo slick",
      "Did the same yesterday from a gtx 970 to 6700 xt"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6700xt"
    ],
    "title": "Pretty much done. Excuse the GPU sag sigh. 6700xt with a Ryzen 7 3800x. Future hardware swap for chip and GPU. Most importantly I did it myself.",
    "selftext": "",
    "comments": [
      "In before Sag",
      "Just get some white plastic rod and cut it to length to make a support-strut.\n\nI personally use carbon fiber with a little black heat-shrink on the ends.\n\nhttps://flic.kr/p/2mgR3jv",
      "GPU sag excused üëç. But seriously that‚Äôs gna break either the card or PCIe slot on your motherboard. If it were me I wouldn‚Äôt leave it like that at all I would take the card out, grab a GPU bracket before I even use it.",
      "Looks good man! GPU sag brackets are pretty cheap on Amazon for a decent one. \n\nOther than that amazing work!\n\nOn the next iteration of your build, plan your cables on the top left a little more and it will be perfect. üëåüëè",
      "heatsinks usually have weight",
      "It doesn't have to have a serious weight. Your long-ass card is being held in the air by 2 screws and a filmsy connector that won't be a able to carry a lot of weight.",
      "More of a small gpu person. I think big gpu tend to sag despite looking nice when new. Not a serious opinion but just wanted to share.",
      "Any more I just build cube PCs so I can avoid the sag, well that and it lets me mount the motherboard upside down quite often so if there is a watercooling leak incident it is likely to miss the motherboard entirely.",
      "You can guarantee they aren't selling as many brackets as they used to ü§£",
      "Where did you get those cables... also what case is that",
      "Bad advice. This will make the air bubbles trap right at the tube interface and get frequently sucked into the tubes and at least pass through the pump.\n\nIdeal mounting would be to switch the rad with one of the horizontal fans at top of the case, but what you're proposing is worse than what OP has done. As it's in OP, the bubbles should mostly settle in the top part of the radiator and stay there, as the much lower velocity flow through the radiator won't be drag them through the rad to the bottom.",
      "your radiator is fine don't move it.",
      "If you have money to buy a brand new 6700XT, you have $10 for a GPU holder.",
      "The stupid part is that there is ZERO weight on this card. I've checked 1000 times. I just checked again as I was typing this. I can only think that I bent something when I installed. I ordered the bracket, it's on the way. Thanks",
      "Look for a GPU Support Bracket. Don't cost much. :)",
      "flip the rad it‚Äôll look much better and won‚Äôt rest the tubes on your card. Jayz2cents and gamers nexus both say as long as the pump isn‚Äôt the highest point in the loop you‚Äôre safe",
      "Good, clean build! Get yourself a GPU bracket for that sag. I have an MSI 3090 Suprim X and that shit is sooooo heavy. Cooler Master has a good one that I currently use for like $20 off Amazon.",
      "If you have a friend with a 3d printer, they can print you an adjustable anti-sag part for under 50 cents.\n\nThis is the one I use: https://www.thingiverse.com/thing:3033580",
      "Thank you!! So after looking at what you said it occurred to me that I never actually finished tucking those wires away.",
      "The cables are Lian Li strimers. I love the 24 pin into the motherboard but hate the VGA one. I'm going to play around with the bend more. The case is a basic Thermaltake. Can't remember the actual"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6750xt",
      "6650xt"
    ],
    "title": "AMD Radeon RX 6950XT, 6750XT, 6650XT RDNA2 refresh with 18Gbps memory now expected to launch on April 20/21 - VideoCardz.com",
    "selftext": "",
    "comments": [
      "More like 1st April.",
      "These are 7nm I presume (although they could be 6nm in which case a clock bump + memory speed bump would make a reasonable refresh with +10% perf or so).\n\nN31 is 5nm GCD + 6nm MCD so they are using different nodes which means they can be built alongside each other without really impacting on capacity.\n\nFurther if N31 is the 1st RDNA 3 part and 2.5x performance is true expect a new price tier for 79xx series parts rather than a replacement of the $1,000 tier 6900XT.",
      "Why, when the 7000 series is supposedly around the corner. With a chip shortage, isn‚Äôt it better to concentrate on getting the 7000 series out?",
      "Same chip, better memory ICs, this is not a new product, but a minor refresh.",
      "tl;dr: based on AMD's behaviour over the last 7-ish years of GPU launches, AMD will service lower price points with older cards based on RDNA2. RDNA3 will only be used for premium SKUs for maybe 6-12 months.\n\n---\n\nRDNA3 will probably follow AMD's tried and tested strategy of, when they have fast products which can compete with Intel/Nvidia, only having high-end and upper-mid range products at launch. They thus use last-gen parts to service the lower-end market segments for 6-12 months. Recent examples include:\n\n* Ryzen 3000 desktop (Ryzen 2000 was lower-end))\n* Ryzen 5000 desktop (Ryzen 3000 was lower-end)\n* Ryzen 5000U (Zen 2 based APUs were lower-end, not Zen 3)\n* Ryzen 6000U (Zen 3 based APUs were lower-end, not Zen 3+)\n* Threadripper 3000 (TR 2000 and the 3950X were lower-end)\n* Radeon RX Vega series (RX 500 series was lower-end)\n* Radeon RX 5000 series (this didn't even have a top-end, and Vega and RX 500 filled in the gap until the 5600/5500 series)\n* Radeon RX 6000 series (gaps filled by RX 5000, Vega and RX 500, until the 6600 / 6500 XT launched)\n\nAMD aren't Intel; they have about a quarter of the manufacturing capacity, so aren't in a position to flood the market with SKUs top to bottom. AMD have, in fact, not done a top-to-bottom SKU launch on desktop within a launch window since maybe 2010 for CPUs (Phenom II) and 2015 for GPUs (RX 300 series). Every other launch since has either been top-heavy (e.g. Threadripper 3000) or bottom-heavy with no real flagship that can compete against Intel (e.g. 1800X and 2700X were still far slower than the i7-7700K and i7-8700K in gaming).\n\nExpect AMD's late 2022 GPU product stack to look something like this:\n\n* Titan-class prosumer card: \"Rage Fury RX Turbo\" with 2.5x the performance of the 6950 XT\n* Ultra-enthusiast: \"7990 XT\" - 2.2x the 6950 XT\n* High-end enthusiast: \"7900 XT\" - 2.0x the 6950 XT\n* Enthusiast: \"7900\" - 1.7x the 6950 XT\n* Lower enthusiast: \"7800 XT\" - 1.5x the 6950 XT\n* Upper mid: \"7800\" - 1.2x the 6950 XT\n* Mid-range: no 7700 XT at launch, just a cut-down 6950 XT\n* Lower-mid: no 7600 XT at launch, just the 6750 XT\n\nProblem is, all SKU tiers will move up in price. I'd expect the 6750 XT, for example, to be far more expensive than the 6600 XT despite filling the same relative performance tier.",
      "new gen every 2 years\\~ish?",
      "Demand is still very high for these parts, new parts are a way off (six months or more), and releasing a very slightly updated existing product doesn‚Äôt detract from anything upcoming. It‚Äôs really just ordering different memory chips.",
      "Tsmc have a certain manufacturing capacity agreed with amd. That capacity needs to be met at all times for both companies profits and future business. Rdna3 may not have been in manufacturing when these refreshes began to be made. Stopgap cards like these arent just to fill a small hole in the market but a small hole in manufacturing capacity too",
      "*excuse to raise msrps",
      "What are the \"7000 is around the corner\"expectations that I see in comments based on?",
      "Around the corner probably means at the end of the year; October or later. Plenty of demand to fill in the meantime.",
      "They are only refreshing the highest SKUs of Navi 21,22 and 23. \n\n6800XT is a cutdown Navi 21.",
      "5nm process, MCM, refinement of the architecture (RDNA3 is a bigger departure from its predecessor than RDNA2 was). Major improvement to perf/watt once again.\n\nThe 6900XT is a less than 300W card. Efficiency improvements brought by the process and the architectural changes could bring it down to 200-225W. Put two of them together thanks to MCM, and you're at 400-450W, for 2x the perf. And finally add the RDNA3 improvements and you get a 2.2x or so monster of a GPU. Really not inconceivable, it's just that years of +5% yearly by intel and +30% every couple years by Nvidia made us believe we had reached some sort of wall. That was never the case, the issue was always the lack of incentive for any of these companies to really push the envelope. Now we have AMD delivering on both CPU and GPU sides and look, intel just dropped one of the biggest performance leap in CPU perf of the past 5 years. Of course that wasn't just because of AMD, these architectures take many years to develop but it's no coincidence such a big perf jump happens when they have to defend their marketshare.\n\nNvidia Lovelace is also rumored to be a giant leap (but not quite to the level of RDNA3 because of the lack of MCM)",
      "I don't see the point.  How much extra fps does 2 more gbps give?  My 6900 xt toxic LE is already 18 gbs.\n\nEdit:  That good silicon could be put to use on next gen or bettering the 6500 xt.",
      "The 6900xt is pretty much a 6800xt with faster clocks so it makes sense why there isn‚Äôt",
      "Navi 31 is projected to be 2-2.5x the performance of the 6900 XT. There's no way the 7900 XT will be $1000 (the same MSRP as the 6900 XT) unless the 7900 XT is only about 1.2x the performance of the 6900 XT.\n\nBeing realistic, the actual 7900 XT will be about $2000. 2.5x the performance, for 2x the price...",
      "It's working for Nvidia with the 12GB 3080, 3080ti, 3070ti, and rumoured 3090ti.",
      "7900XT is enough for me, $999 only plz thanks. They have prosumer to take the higher brackets now, leave the $999 bracket for the 7900XT to pair with a Zen 4 7800X for maximum gaming.",
      "> Also pls fix ur drivers amd\n\nA tale as old as time.",
      "I have no such crashes with a 6800 xt. Their drivers have been solid, maybe try a clean install of them using DDU to remove the old."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6750",
      "6750"
    ],
    "title": "[HUB] Lining Their Pockets: AMD Radeon RX 6750 XT Review",
    "selftext": "",
    "comments": [
      "The TLDW; Compared to the 6700xt it is 5-6% faster, uses 13% more power, and the costs 15% more.",
      "waiting for hardcore fanboys trying to justify these numbers ü§°",
      "Actually this subreddit is suprisingly full of Nvidia fanboys. It's funny when here people are saying that RTX 3060 is a better choice than RX 6600 XT / 6650 XT in the same price range, but everywhere else AMD card wins.",
      "Are you the person that writes the userbenchmark reviews?",
      "It's because this sub allows open discourse and dissent; try taking an opposite position on r/Nvidia and they'll soft ban you - you can post, but it isn't actually published unless a mod approves it - and you can't tell unless you browse reddit anonymously and notice your post isn't present.",
      "> It's funny when here people are saying that RTX 3060 is a better choice than RX 6600 XT / 6650 XT in the same price range\n\nBecause it is? Sort of.\n\n\n\nThe 3060 definitely performs slightly worse, but at the same price i'd still go for the 3060 over the 6600 XT/6650 XT due to having more vram, NVENC, better RT performance, and DLSS**. But the catch is, you cant buy them at the same price right now, checking pcpartpicker and the cheapest 3060 is $70 more than the cheapest 6600 XT.\n\nDLSS**, yes FSR 2.0 is out, and its pretty good, but the caveat is its in one title so far, DLSS is in 100+ titles today, and FSR 2.0 games will work on the 3060. Eventually this feature benefit will erode, but right now its still a feature.\n\nCurrent pricing 6600xt is better, same pricing or MSRP the 3060 is better.\n\nPS. HUB came to the same conclusion in their video on this topic, so its not clearly not just fanboys.",
      "reply concerned slave six special door public boast person oil -- mass edited with https://redact.dev/",
      "Yes, the 3070 at that price is \"highway robbery\". The AiBs who charge a $200 premium for a 2% overclock and a worse looking design are right to be criticized. And when AMD sets an MSRP that is closer to what those AiBs charge, they should receive the same criticism (EDIT: Because I know people are going to point this out, yes, Nvidia started doing the same thing, and yes, they should be criticized for it too).",
      "I honestly don't understand why people use NVENC or RT performance as an offset against worse general performance. It's just not comparable like that, people who don't care about those things don't have a reason to factor them in, and people who do care about them should be picking Nvidia regardless of some small AMD performance advantages.",
      "I am already done with this generation of cards. I dont see the point of buying a 6750 or 6950 at this point.",
      "If this card is a cash grap, than 3070 is a highway robbery: https://i.imgur.com/hIiMUsT.png Not to mention you get ~~16Gb~~ 12Gb of VRAM vs only 8Gb.\n\nIf you want slightly more performance and faster RAM and can stretch the budget for $50 more, I don't see an issue. Or else just get a 6700xt, it's an excellent GPU.",
      "It costs the same as regular 6700XT in Australia.\n\nOur prices down here are still inflated.",
      "That's not how this works, that's not how any of this works.\n\n2060 has 336 GB/s to VRAM and PCIe3 16x to RAM ( ~16GB/s ).\n\nIt's much faster as long as you stay in VRAM. The moment each frame must access system RAM to render because it can't store it locally you'll see a major performance drop as the GPU is twiddling its thumbs waiting for data from the slow system RAM.\n\nCyberpunk 2077 with RT enabled comes to mind. See: https://youtu.be/U0Ay8rMdFAg?t=643\n\nHad the 2060 been a 8GB card, you would never see that performance drop because the content in VRAM wouldn't be overflowing to the system RAM.\n\nAnd mind you, that's in 1080p. 2060 is also a 1440p card and there the problem would be even worse.\n\nMore VRAM is always good if you can have it.\n\nIt's the same principle when your system RAM is full and your CPU must access the much slower SSD/HDD storage.",
      "> 11 game average 6600xt is 45% faster\n\nReally!? I remember HUB retested 3060 vs 6600XT in 50 game benchmark recently and their conclusion is performance parity, sometimes these game benchmark gives really wack result.",
      "In Europe it's actually ‚Ç¨40 cheaper than the 6700XT",
      "offend aloof wasteful scale steep bow zonked snobbish quarrelsome berserk -- mass edited with https://redact.dev/",
      "Yea, that's not true at all. People have been putting nvidia on blast over there since the 2000 series came out.",
      "TPU has the 6600xt as only 12% faster than the 3060. Where are you getting 45% from?",
      "Maybe the 11 games he's talking about are all Assassin's Creed Valhalla",
      "because a 6700xt in my region is 500 dollars cheaper than a 3070 and 300 dollars cheaper than a 3060 ti?"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6750",
      "6750"
    ],
    "title": "Upgraded to RX 6750 XT and 5800X from 1660Super and 3600.",
    "selftext": "",
    "comments": [
      "AMD is so much easier to work with on Linux compared to Nvidia, it's ridiculous. Enjoy!",
      "Kde üëç",
      "Darknet Diaries, I love that podcast!",
      "(Rant)  \nAfter seeing the kind of stuff Nvidia users have to deal with on Linux, I'm so glad to not be using one. I wouldn't care if Nvidia was twice as fast, I'm not subjecting myself to that nor am I going to support a company that manages to be such a pain for no other reason than to save some money on development. Not to mention their seemingly anti-open-source stance leaving a bad taste in any Linux or BSD user's mouth who ever has to deal with it, probably discouraging a decent amount of users from ever buying another Nvidia GPU. AMD and even Intel GPUs both offer far better support and Nvidia is embarrassing. \n\nThen don't even get me started on them holding people back from using Wayland with their awful drivers, causing even more trouble for users and developers who now have to spend more time to deal with Nvidia's nonsense and trying to make Wayland work properly with those GPUs.",
      "How are you liking Plasma 6 so far?",
      "KDE 6 rules!",
      "Well, 5700x was just 10-15‚Ç¨ difference and 5800x3D was 280‚Ç¨ at the time and I don't really need the performance of the 3D. I am really satisfied with the 5800x.",
      "Way less bugs and I dont have to wait 10 min on every kernel update for dracut to finish. Love it.",
      "It's really stable and smooth, I am using Xorg because I want to set saturation on my monitors manually but Wayland is also really stable and I have not encountered any bugs....",
      "Do you need support for a gpu of that size? Asking for myself",
      "AM4 POWER!",
      "I guess yeah, ‚Ç¨173.26 from [amazon.de](http://amazon.de)",
      "Not bad!\n\nDon't see many builds with a new 5800x since the 5700x and 5800x3D released.",
      "What monitor is that? I want one",
      "After upgrading to a 5800x3d and 6700xt thats probably one of the best mid range $/performance combo out right now. The 5600-5800x3d range cpu and that gpu is just so good for the money. Im sure it was a solid upgrade for you! GLHF! \n\nI also had 2 8gbx2 kits of ram too. Worked flawlessly.",
      "I have the 6750 and a 5600x, doing great at 1440p 144Hz.",
      "It's a heave boy, I think this one needs a support...",
      "Indeed, the performance is amazing!",
      "üòÖ This is a normal 24' 1080p monitor, but it looks on the photo like [LG Dualup](https://www.lg.com/us/monitors/lg-28mq780-b-dualup-monitor) because the photo is taken with 0,5x camera üòÖ",
      "Casual computing temps are 30-40¬∞, while gaming is about 70-80¬∞, depends on the game, sometimes is below 70¬∞.\n\n  \nThis temps are with PBO enabled and Curve Optimzer set to Negative with -20 magnitude."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6700xt"
    ],
    "title": "It has been MONTHS, when is this going to end. Its not even the games fault. My older drivers never had this problem and my card is perfectly healthy in all regards. What the hell! (6700xt)",
    "selftext": "",
    "comments": [
      "Not your issue.\n\nWar thunder has been having issues with models bugging out for a couple months now... most noticeably it was tank tracks (which was fixed a few weeks ago) but some stuff in ships is still messed up since they don't care about the game mode.",
      "Its war thunder of course it's the games fault. I used to have the same issue with my intel and nvidia system back years ago.\n\nThe games known for bug regression for a reason",
      "it's a game problem for a long time now.  \nfor me it is basically fixed when i run the game in borderless window.",
      "Nah sorry bruv but that glitch is age old on WT and they give zero fucks on fixing it.",
      "Hey look, my glame glitches... let's blame it on the drivers!",
      "This could be a graphics glitch. Was there an update recently?",
      "Nah, this is definitely just a War Thunder thing, Gaijin are just terrible devs. Every time they \"fix\" 1 thing, they break 17 other things.",
      "Not playing naval, but havent seen anything like this recently while playing GRB using 22.5.1 and 6900XT.\n\nLike a month or two ago there were many graphical glitches similar to this. That time it  was the game and not hardware. All my friends on Nvidia experienced it too, maybe more than I did.",
      "That's 100% a wt bug.",
      "you have to choose \"previous drivers\" or check link if it doesnt get blocked:\n\n\nhttps://www.amd.com/en/support/previous-drivers/graphics/amd-radeon-6000-series/amd-radeon-6700-series/amd-radeon-rx-6700-xt\n\n\nI have no experience with this game but I'm running 22.3.1 (whql) on my 6800xt.\n22.4 and 22.5 had hdmi issues with my tv and 22.7 froze my pc",
      "Such a misconception.  Cards from both companies have issues at times",
      "It is not ages old, it just recently started happening and I‚Äôm on Nvidia.",
      "Sabaton simulator",
      "It's War Thunder. Every match is a new 'game'",
      "Never had a issue with amds drivers.",
      "So, did you try installing the old drivers again and see if the issue is gone or still there?\n\nNormally you have a copy of older drivers under C:\\\\AMD from where you can reinstall an older version. Or you could redownload it on the AMD website.",
      "its a common bug in wt",
      "As a long term Nvidia owner I can 100% confirm that Nvidia has bugs too.  Took them 6 months to fix VR stuttering.  Of course there was also New World bricking cards and space invader 2000 series.  Course those are just the bigger ones, Nvidia just released a hotfix driver this week for graphical artifacts in select popular first person shooters like Apex.\n\nI don't update my drivers often specifically to avoid bugs introduced by Nvidia and I don't install GeForce experience.  Then again if I were using AMD I'd do the same too.  Let other people test the new stuff.",
      "Revert to the old drivers would be my suggestion.",
      "ever since 22.5.1 I have had bad performance on multiple things. I currently reside on 22.7.1 which has been the smoothest for me all save for this game. And each time I do I click factory reset and I have even used DDU."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6750",
      "6750"
    ],
    "title": "Anyone else annoyed that AMD removed all the reference models and replaced them with the 6750 and 6950 XT instead?",
    "selftext": "I was eager on buying the reference 6700 XT from them because it was cheaper than all the AIB models here in Canada and then poof... gone.\n\n6700 XT was around $610 and the 6750 XT is selling at $710, for what is a marginal performance boost.\n\nEdit: here in Canada only the 6750 and 6950 XT are being sold on AMD's website store, all the other cards are gone.",
    "comments": [
      "Yep, Hardware Unboxed hit it on the mark, should not have replaced existing cards, and should not have such a huge price hike (region dependent) in comparison to the paltry performance gains.\n\nAlas, the pandemic broke the mold, now AMD is following suit of the rest and just seeing what they can milk out of consumers wallets with continuing price hikes.\n\nThere is making profit, then there is this...",
      "AMD was planning to kill the reference models back in 2020 but didn't due to COVID.  I think if you want a remaining reference design, you may have less than 3 months to get one.\n\n[https://www.notebookcheck.net/It-s-all-AiBs-now-AMD-reportedly-discontinuing-production-of-Radeon-RX-6800-RX-6800-XT-RX-6900-XT-reference-design-cards.508693.0.html](https://www.notebookcheck.net/It-s-all-AiBs-now-AMD-reportedly-discontinuing-production-of-Radeon-RX-6800-RX-6800-XT-RX-6900-XT-reference-design-cards.508693.0.html)",
      "No they are worse than NVIDIA, they at least still sell their old cards even with the stupid Ti versions out you dont need to buy a 3090 ti or 3080 ti 3090s and 3080 10gs are still being made and are readily available now. \n\nAMD went a step above that and just completely nuked their non XT versions to leave these price bumped same performance versions",
      "As much as some people forget about it, companies/executives/CEOs/etc. aren‚Äôt our friends. Cash is king.",
      "The Rx 6800 and 6800 xt have also just disappeared",
      "Jeah they just pulled an \"Nvidia\" , because they are just the same. A big corporate with the ability to print money ;)",
      "Pretty much making the choice for consumers that if you don't want to spend money on expensive dGPUs but still want to game, you buy a console instead, which is fine for AMD cause it's their hardware too.",
      "> Alas, the pandemic broke the mold, now AMD is following suit of the rest and just seeing what they can milk out of consumers wallets with continuing price hikes.\n\nIt's not the pandemic though, AMD consider themselves to be a premium brand now. It's why they increased the Ryzen prices across the board by around $50 originally with Ryzen 5000, it's why they didn't ship lower end models of Ryzen CPUs because they can simply milk their customers to buy a more expensive product and it's why they continue to push out graphics cards with prices of $1000+ now. They actually believe that they're a premium brand that can charge those prices. The days of AMD being the \"cheap alternative\" to NVIDIA and Intel are over. In some ways, Intel and NVIDIA provide better value than AMD in a lot of segments now, think 12400F vs R5 5600 and RTX 3050 vs RX 6500 XT. It wasn't until Intel started shipping 12400F's and 12600KF's in droves that AMD pushed the panic button and released the 5700X and 5600.\n\nI get AMD has been successful under Lisa Su, especially architecturally, but mostly business wise. But they're leaving behind their fans that really have been dedicated to them for eons because of their value-oriented approach in the past. If AMD's not careful, a lot of their old fans might abandon them if they keep pushing prices higher and trying to milk every dollar. The Ryzen 5000 price hike was pretty sickening to me, considering that the node was super mature and the die size only very slightly increased on each product compared to Ryzen 3000. I would have bought a R5 5600X but that $50 hike and the fact they took away box coolers just showed me they were doing bean counting to make profits, rather than willing to give their customers value. And yes, I know, the box cooler sucks for products like the 5800X, but that doesn't matter, it was included in the 3800X, so why was it removed? I think purely for bean counting to take $5 off each product's margin for AMD to increase profits. But I want the box cooler in case, I dunno, my cooler has some problem I have some sort of backup, even if the thing is junk, or perhaps, my new cooler takes a while to come or if I need a bracket for AM4 to come in the mail, I can use the box cooler for a while. It's $5 to them, but that $5 translates to a lot of value for consumers.",
      "AMD: watch this magic trick!",
      "Early adopter is a bit of a stretch. It's just optimizing an existing product.",
      "I‚Äôll be honest‚Ä¶they don‚Äôt give us a shit about us, even if their marketing departments creatively make it seem so.\n\nThey say ‚Äúfor gamers‚Äù this, ‚Äúfor gamers‚Äù that, blah blah blah, but their bottom-line is money. Their executives and investors don‚Äôt care how they get the money, as long as they get it. It‚Äôs the same for any major business.\n\nDo they have a ‚Äúgamer‚Äù on the inside with a bit of soul who feels for us? Maybe, hopefully, but they didn‚Äôt get to C-suite or major investor level at those corporations without putting those feeling aside when it really mattered. They‚Äôre not going to risk their 6-7 figure salary and careers doing stuff ‚Äúfor gamers‚Äù if the rest of the execs and investors only see a monetary loss.\n\nSad‚Ä¶but, Hey Siri, play ‚ÄúThat‚Äôs how the world works‚Äù by Bo Burnham.",
      "Yep. \n\nIf you're not happy with the current price point for products, you have a great method of expressing that to companies. \n\nDon't buy their products.",
      "The thing is, \"time\" is running out. It's what? Maybe 4 months before RDNA3 and Lovelace from NVIDIA are announced. Whoever's waiting for 6950 XT prices to come down are basically wasting their time because the new cards will be basically around the corner. Waiting is a smart move, you'll only win if you wait long enough. But it's also stupid if you buy into a 6950 XT in August, only for RDNA3 to come out in September/October for around the same price. These cards should've launched like last September if they wanted to make a splash, back when NVIDIA was launching the 3080 Ti and 3070 Ti etc. The 3090 Ti was extremely late and is a completely dumb product, hell NVIDIA missed their own announcement window in January about more information because the product was so late.",
      "U do realize that going from 93fps to 98fps is more than 5% right?",
      "The only games that saw a +5% increase in that infographic were Fortnite and Far Cry 6. The 5 fps metric I stated comes as an average of all they showed. \n\nThe breakdown is as follows:\n\nVanguard: 3.1%\nF1: 3.4%\nGotG: 4.6%\nFC6: 5.5%\nDeathloop: 4.0%\nApex: 3.7%\nFortnite: 5.3%\nR6: 3.7%\n\nHardly worth the estimated $100+ price increase IMO",
      "Crypto is going down, so expect some good deals on older GPUs.",
      "What the fuck?? I was still trying to get a 6800xt.\n\nThis is extremely anti-consumer and I expected this shit from Nvidia, but never AMD. But I don't think Nvidia did this, but AMD did??\n\nedit: i'm sorry AMD, but this is the type of shit that loses market share.",
      "The price hike is awful.",
      ">Early adopters have to pay more.\n\nIt's a 2 year old product that has been refreshed with cheaper memory and faster clocks.",
      "Says someone that actually purchased a 3090 and is proud of it... lmao"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6750",
      "6750"
    ],
    "title": "5800X3D RX 6750 XT",
    "selftext": "The last iteration of my personal build",
    "comments": [
      "Love the color scheme",
      "Pretty similar to my system.\n\nJust upgrade to 5800X3D from 3900X. My gpu is RX 6800XT and case is H510.",
      "It‚Äôs an nzxt 210i but I wouldn‚Äôt suggest it because of GPU clearance",
      "I had one, the glass shattered randomly one day, and NZXT said, \"ahhh, that sucks bro.\"\n\nAnyway, i bought a bigger case.",
      "Thank you",
      "What case is that",
      "Whoever designed this case should be shot, that GPU clearance is a travesty",
      "Nah the whole all team red bs is only for fanboys",
      "Love the red color! Hopefully you get to enjoy it. I've recently ordered a 6950XT with a 13600KF but I'm really wondering if I should have gone with an AMD CPU too.",
      "Why didn't you? Isn't the 7600x cheaper, more power efficient and faster in games? And gives access to 3d chips as well as long term support.",
      "There are some games where the performance gains can be upwards of 30% or higher, SAM it‚Äôs not a joke. The gains on AMD cards is insane.",
      "Hold up, I've seen this before... On my desk! XD\n\nhttps://www.reddit.com/r/pcmasterrace/comments/12sa707/updated_battlestation/\n\n5700G & 5700XT in mine.",
      "Beautiful colour scheme, cleanly done. But your GPU can't breathe",
      "5800X3D RX 6800 build here. My first full AMD build.",
      "Hows the GPU? Seems VERY close to the bottom shroud :D Is it getting enough air?\n\nA clean build, though.",
      "Oh cool, I upgraded this over the last few years all the way from a 3600 and 5700XT reference card. I can‚Äôt believe what this CPU is capable of sometimes and really makes my GPU shine.",
      "That's a NZXT H210",
      "Why?\nIs the 13600KF holding you back in anyway?\nThe 13600KF is a terrific cpu, and won‚Äôt need to be replaced for a long time",
      "It‚Äôs unbelievable. Major improvement over 5600x. In Escape From Tarkov it‚Äôs incomparable.",
      "I guess I'm slightly worried about the compatibility, I'm 99% sure using an AMD GPU with an Intel CPU will be perfectly fine, but still... most users with AMD GPUs usually have AMD CPUs as well. This is my first high-endish build too, so it's normal to be worried at least a bit I guess."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6700xt"
    ],
    "title": "Out of the Box Image Quality 6700XT vs. 3070",
    "selftext": "I recently acquired 2 cards at MSRP - an EVGA 3070 FTW3 and Rog Strix 6700XT (Shout out to Memory Express in Canada). \n\nMy plan was to use them both for a couple weeks and compare decide on the card I wanted to end up keeping knowing that resale of either wouldn't be difficult.\n\nI used the 3070 for the past 2 weeks and was extremely happy with everything about the card. It looked great, ran cool and quiet and kept my frames at 240 no matter the scenario in Dota 2 @ 1440p on a 32 inch TN LG panel. (Using a DP cable).\n\nI just plugged in the 6700XT last night. I immediately did a double and triple take. I was floored by the image, I couldn't put my finger on it, but the sharpness and color, both in games and Windows made me feel like I had just got a new contact lens prescription and a new monitor at the same time. I didn't even know this was a thing until I hopped on Reddit to take a look.\n\nPurely anecdotal evidence but I came in with no knowledge that the image quality would be different on different brands - but out of the box score a BIG win for AMD.\n\nReviewers make huge deals about the software support like DLSS and Ray Tracing, but the number one job of the Graphics Card is to produce an image - and to see that one brand is clearly superior was shocking to me. I'm sure there are many variables and things that you can do to an NVIDIA setup to improve upon this gap, but it made my choice of what card to keep an easy one. I'm surprised this isn't a bigger deal in the review landscape.",
    "comments": [
      "Could be the RGB setting (limited/full) or something similar.",
      "I have both a 3090 and a 6900. I notice no appreciable difference.",
      "* Your monitor uses a TN panel. Most TN panels have banding issues and require dithering for smooth color transition. AMD enables dithering by default, [Nvidia requires a registry tweak](https://old.reddit.com/r/nvidia/comments/aghfqk/dithering_can_now_be_enabled_via_registry_tweak/)\n\n* AMD driver's default settings has slightly higher saturation than Nvidia \n\n* People are way overthinking this",
      "I had a 5600 XT and now I have a 2070 Super, same display, same cables, same everything. I see no difference either.",
      "I got a 1060 and my gf has a 5500xt. Her image looks better, but I thought that was just differences in monitors or image sharpening maybe? But I've heard people talking about this long before AMD implemented RIS, so I have no clue",
      "Depending on the connecting he's using, this is probably it... I've had many AMD GPUs on the past, as well as Nvidia ones and now I mostly use Nvidia cards and when I connect displays through HDMI in a Nvidia card it defaults to a worse color config everytime, and I have to set it manually on the Nvidia Control Panel...\n\nAfter setting it up, the image quality is the same as AMD when compared on the same display, IMO",
      "washed out colors and blurry image on nvidia back in the days it was said that AMD had fulll RGB color support while nvidia had only limited RGB support that you needed to tweek manually but has not been the case since i belive 1000 series. There was another theory that AMD gives you full 10bit color on the card while Nvidia uses 8-bit and keeps their 10bit for their quadro range or something. Another quess was that nvidia has been using compression to save on memory so maybe that. Maybe it's all of them combiined all i know is AMD gpus put out a more pleasing image for my eyes while Nvidias looks like everything has color washed right out.",
      "Since they are taking about \"out of the box experience\", I don't think they are overthinking it.",
      "This.\n\nI've had both AMD and nVidia and I've never seen a diference in image quality. But recently I connected my monitor through HDMI and it looked pretty bad, then I found out it was defaulting to limited RGB. Changing it back tu full RGB fixed it.",
      "Nvidia claims that it doesn't affect image quality, and because Nvidia would never tell a lie you sir are a scoundrel.",
      "AMD doesn't compress textures the same way, the same image will require more bandwidth and a larger footprint in vram. This is measurable but reviewers don't talk about it much. Nvidia says that memory compression doesn't affect image quality, so I guess this whole post is a figment of my imagination. \n\nScroll to the bottom, it started with Pascal and got more aggressive in Turing:\n\nhttps://www.anandtech.com/show/13282/nvidia-turing-architecture-deep-dive/8",
      "I am not an engineer nor I have studied anything in the direction  \nof GPU architectures.  \nSome time ago someone explained it and the essence is, that  \nAMD/Radeon manages the data a bit different and doesn't  \ncompress the shit out of it.  \nThe result is a better picture.",
      "When you use lossless compression - you don't lose anything. That is what both AMD and Nvidia use in their vram compression.\n\nThese posts about image quality being different tend to come from users that don't install the proper color calibrated profile for their monitor - when doing the driver swap, the resulting image might look wrong.\n\nOr have another setting enabled/disabled that affects it.\n\nThere have been multiple articles written about this - at this point in time, you will have the exact same experience at least on the desktop with a properly calibrated/setup monitor.\n\nObviously ingame, with dlss etc. things will differ.",
      "Good post!\n\nThis was evident 20 years ago, as well, believe it or not.  It was plain to see even then.  It goes all the way back to when 3dfx introduced FSAA to the industry--no one else had it, including nVidia.   Right after 3dfx imploded, ATi came on the scene from literally nowhere with the darkhorse ArtX acquisition GPU, R300, and the GPU did FSAA & general image quality so much better than nVidia that *of course nVidia criticized it heavily* for a couple of years until it could begin to field competitive FSAA GPUs to compete with R300 and beyond.  Despite nVidia's adamant protestations at the time, FSAA became a staple in the industry and is a checkbox feature today for all 3d GPUs, including nVidia's. \n\n nVidia has always been a company absolutely obsessed with frame-rate benchmarks to the exclusion of the best image quality possible.  Considering the number of people who aren't very demanding about their image quality, that approach has sold a ton of GPUs for nVidia.  But you are right--and you aren't the first to have noticed what is often the stark difference between the competing families of GPUs.\n\nIf you care about your image quality, imo, and it's as important to you as frame rates, or even more important (that's me),  you are going to go with AMD.  DLSS is really sort of amusing to me...;)  I game at 4k with a 5700XT (which I will be keeping until I can land a 6800XT at MSRP, and so that might be a long time to come...;))  Anyway, if I want \"DLSS\" I just drop the res to 1440P, pour on the FSAA to a desirable degree--and I'm there...;)  Frame rates go up appreciably and the image quality is but a tad lower than native 4k.  RayTracing?  It is 100% optional in all of the tiny number of games that support it--and many people don't really understand that when you use ray-traced shadows and/or reflections in a given scene/frame, and even ray-trace a few object surfaces, *maybe as much 95% of everything else* rendered on the screen *is still rasterized*, anyway! For instance--every object in every scene is rasterized--none are fully ray traced.  None.    \n\nI don't have anything against DLSS or D3d ray tracing...but as you say, how many game reviewers ever bother to go that deep into the differences between D3d ray-tracing and the kind of ray-tracing special-effects companies rely on for movie production, in programs like Lightwave, for instance?  I cannot think of a single one who really understands the enormous differences.   The differences are *vast*.  But that's OK--D3d RT is what it is.  What's not OK is the idea that D3d RT'ing is *a lot more* than what  it actually is...;)\n\nSo in the final analysis, all of these perceived differences boil down to marketing hyperbole--but you know, it's all in the eye of the beholder in terms of DLSS and D3d RT'ing.  Shown the same exact frames, one guy will opine on how he has never seen anything quite so beautiful, while another will say, \"Meh!  I prefer to turn those features off, myself.\"  \n\nBut in terms of general IQ--comparing the two GPUs on the same monitor in the same games with the same settings on the same desktop--is about as clear as it gets!  Yep, the win is definitely AMD's.",
      "I had a similar experience switching from a 1080 to a 6900xt, something about the image from the amd card is just better and I can't really put my finger on it, obviously the performance is miles better in my case too but even in low motion scenes like just walking around the city in cyberpunk the amd card just made it look more like the trailer than the actual gameplay I got from the 1080",
      "i can't for the life of me find the damn video.. but there was a diagnostic tool for HDMI output bandwidth that measured what was ACTUALLY being sent from the device to the display. And the reason the test was initially conducted was to determine what the problem was with the cables and the display problems to explain them. Coincidentally the person conducting the test was using set top boxes and got a bit curious about graphics cards. Suffice it to say, they discovered that nvidia's hdmi bitrate being spat out to the displays was lower than what AMD's cards were doing which raised a few questions as well as explained why some of the cables were working fine on nvidia's cards while having issues on amd's. 144hz display requiring more data, but nvidia somehow managing to spit out less data while producing the \"same\" refresh rates at the same resolution while AMD was requiring more and resulting in a bad cable producing blanking/flicker/multiple hand shakes or failing to even produce a signal (black screening even). Replacement of the cable with a better own would resolve AMD's issue.\n\n&#x200B;\n\nGranted it's merely a variable. But there is consistently a difference in colour and clarity between the 2 products and always has been. Since the days of the TNT, and nvidia's introduction of Digital Vibrance to combat their lack of shall we say, colour accuracy, kinda like nvidia was stuck with a \"slightly washed out appearance\" is still today a common statement from people.\n\n&#x200B;\n\nColour profiles are irrelevant if nothing was setup to begin with and simply attaching one card to the display and another even at the same time (in the case of a highend tv for example) and swapping between both or doing side by side you can CLEARLY see there is differences even at the desktop level.\n\n&#x200B;\n\nNvidia often opts to go with a limited range via hdmi, 16-255 rather than amd's default 0-255. Manually changing this in the nvidia control panel can/will help but it still doesn't quite match the output amd delivers.\n\n&#x200B;\n\nIt's rather strange to be honest. It's certainly not placebo as you get enough customers in which a swap too or from one or the other gets the common utterances when i call in or they do about the displayed image colour/quality differences.\n\n&#x200B;\n\nI've sold an nvidia user and AMD product and they occasionally report that the display looks richer but they can't put their finger on it, and in the opposite case, i sometimes get a complaint from a user that has bought an nvidia card to replace their amd about the display looking washed out somewhat (to which i point to digital vibrance and while it does help, it doesn't usually look right to them)\n\n&#x200B;\n\nMeanwhile we see posts on even this subreddit from users asking where AMD's \"digital vibrance\" is and i can't help but laugh a bit.\n\n&#x200B;\n\nIn terms of texture quality and such, AMD certainly tends to have and historically always has had the lead in that, not to mention other effects, Nvidia's often touted frame rate leads can be traced back to things they've done in the past that were proven to be short cuts or optimizations that have impacted visuals either significantly (easily called out), or rather difficult but once compared fairly obvious.\n\n&#x200B;\n\nI owned a 3080 before getting a 6800xt.... i tried out DLSS and RT and then had the opertunity to compare it to the 6800xt. Honestly no matter how much calibrating i did on the nvidia card, i could never get quite that pop that AMD's cards consistently deliver out of the box every time. I REFUSE to adjust my displays colours and settings to make a video card spit out an image that's comparible, as calibrating the display for nvidia's cards buggers up the other devices and settings i may already have configured. I only had the card for a week and a bit roughly before i dumped it, as i wanted to see how DLSS mostly did and personally seeing the trash it produced on a 65\" 4k display made it completely irrelevant and grossly overhyped. Maybe DLSS3.0 might fix it's glaring problems but it's most definitely not a selling point for me. I'm perfectly happy with a 6800xt spitting out 90-120FPS @ 4k in most of the games i play (or higher).",
      "Back in the day, early 2000's, reviews used to rate 'image quality' and ATi regularly won out by a healthy margin. Rocking a Nvidia card usually led to more washed-out colors and everything looking a bit drab and not as sharp. Never understood why but perhaps that's still the case? I've never done a back to back but I wouldn't be surprised if it was still the case.\n\nI mean, some people have TN monitors and think their colors and image look great. A LOT of people wouldn't be bothered by a slight lowering in image quality for higher performance",
      "Nvidia compresses colors to make up for sloppy optimization. That's why AMD cards have better IQ.",
      "I'm not sure either, but how things look out of the box is important. Might be worth flipping monitors to see but I suspect the difference is in the cards.",
      "It's because amd applies temporal dithering by default on everything while nvidia does not, on windows (works for linux on nvidia)\n\nThe excuse nvidia uses is \"compression is ok as long as the graphics card run faster\"' or something along these lines.  \n\n\nSearch google for nvidia/amd dithering and the same picture quality difference threads will pop up by dozens."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6650xt"
    ],
    "title": "AMD reportedly halts production of Radeon RX 6650XT, expected to be sold out in China by end of September - VideoCardz.com",
    "selftext": "",
    "comments": [
      "Yep, why shouldn't they lol.\n\nIts fine for 7600 to take over that segment.\n\nIf you really want a 6650xt grab it now, maybe as a backup card or for a budget build. You get a Starfield code with it too.",
      "If the rest of the market follows suit like MicroCenter, bringing down 7600 to $230, I think that'd be the no brainer",
      "The problem they have is that they overproduced RDNA 2 graphics cards during the cryptocurrency bubble and a lot of the cards were being bought up and hoarded by miners. Once the cryptocurrency bubble burst, the used market was flooded with used cards and retailers have to get rid of any stock they have.",
      "Most likely price drops once they get rid of the old inventory.",
      "I find it odd that they continue to produce RDNA2 cards with clear RDNA3 replacements. Don‚Äôt they want to sell their new stuff?",
      "From a general business perspective, it is actually quite difficult (and even expensive at times) to make immediate short-term changes. For example, it is hard for a business to immediately lay off many individuals, make last-minute changes to inventory orders, alter contracts, etc. \n\nAMD might have been slowing it down all this time, and ceasing altogether now/soon as per the rumour. \n\nAlso have to consider: AMD doesn't want to compete with themselves for this segment. Basically, AMD would rather have both cards sell than just people buying 7600s and leaving a large inventory of 6650 xts, or vice versa. People want to buy whatever is the best value. If the 7600 is worse value, it won't sell as well. Hence, AMD wants the 6000 series cards to finish selling.\n\nSome people believe this is why lower segment cards have taken so long to arrive. Of course they want to sell the new stuff, but it may be inconvenient for them.",
      "Yep. You can also get a 6700XT and OC it to match the 6750 XT.",
      "Just get the cheapest 6700XT/6750XT you can get. They're all the same card pretty much. You can get pretty much same performance out of a 6700XT.",
      "Because for mid-range cards they probably want more sales numbers.",
      "Did you read what I said?",
      "does it come with that on a 6750 XT cuz I wanna get one of those",
      "How dare a company stop producing an old product in favor of a new one!",
      "Considering how bad graphics card pricing right now, I don't think a shortage will happen anytime. Especially those 4060s are low demand and overflowing with stock everywhere.",
      "Uh it's a lot worse actually. Slower GPU, slower memory, less memory. There's even a whole SKU between them, the 6700 10GB.",
      "The 7600 is better by 5% more or less. Passmark isn't a reliable benchmark for GPUs because it is more a measure of compute performance. R9 390 scores higher than RX 580 for example.\n\nThe price you listed is still high though, but that's just how it is, some regions have it better, some worse.",
      "To increase sales?",
      "What? You're telling me they've kept production going up to now? I thought they would have stopped months before the 7600 dropped.",
      ">Or just for the Starfield bundle tbh, good value way to get a copy\n\n  \nNote that you need at least the RX 6700 to get premium version ($99). 6650 & 6600 get standard ($69)",
      "Perhaps the chips were just in inventory. The boards were still being manufactured though.",
      "Why would they drop the price if the main competitor of rx7600 is their last gen's products."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6700xt"
    ],
    "title": "Repasting Reference RX 6700XT with PTM7950, before and after",
    "selftext": "",
    "comments": [
      "Frame rate stability tightened up to 99.5%. Waiting on my sheet to arrive this week for my nitro 6700 xt, hotspot temps are around 87c with Mx6 applied.",
      "Had 30¬∞ Delta before on my 6800 xt red devil, like 68¬∞ GPU Temp and 95-98¬∞ Hotspot, switched to PTM7950 and now my temps range between 10-20 and the temps in general are down 5-8¬∞ so it was worth it for me.",
      "6750xt ptm7950 repaster here. I absolutely can confirm. Good job. Welcome to the club.",
      "Seems accurate. Lower delta and better temps than thermal paste.",
      "13 degrees lower CPU temp.",
      "Its underrated on benchmarks how important this stat is along with %1 lows. Its ok to play at 40fps flat rather than 60 that goes back and forth to 30's for exampel",
      "Good results. I was thinking of getting some for my 6700XT since my delta is 25¬∞, with the hotspot being 98-101¬∞ in very demanding loads... Quite toasty",
      "Did you replace the termal pads as well? I'm thinking about repasting mine but I'm worried that the pads gonna break and I'll have to replace them.",
      "There's only one legit PTM7950 thickness, can't remember which one it is right now but you can get it from moddiy.\nEDIT: 0.25mm is the correct thickness. Anything else is fake.",
      "It's meant to be applied by screen printing machines (hence \"SP\"). It has a solvent to keep it liquid at room temp, but you are supposed to let it completely evaporate before mounting the cooler. Ideal thickness is \\~0.3mm, and they recommend 15 hours at room temp. The thicker the application, the longer it takes to evaporate.\n\nI wouldn't recommend the paste version.",
      "TG-PP10 is good stuff, but there's even better and cheaper putties these days. Here's some VRAM thermal testing from Snarks Domain, mining with a 3070Ti (GDDR6X) : https://drive.google.com/file/d/1pVga9tnnxTEf1-kJZzaUPgd9WGn6eaqI/view",
      "Where do you guys buy  ptm7950?",
      "Did this on my 7900xt, significantly dropped my hotspot temps. And i bought mine off Amazon so who knows if it is legit ptm but still happy!",
      "No I didn't. I moved them back in place a little. No further issues.\n\nExchanging that would have been to complicated (different thickness) and expensive for me.",
      "I have my ref 6700xt underclocked but still gets hot under load. Might be doing this soon",
      "I‚Äôve been building for almost 15 years, but earlier this year was the first time I ever repasted a GPU. Gotta say my results were incredible. Highly recommend for anyone who is having trouble with hotspot temps.",
      "Please update us, mx6 user here",
      "I would try undervolt from 1.200v to 1.120v. From 90c to 80c hotspot in my case.",
      "doesn't that messier than normal paste? Wonder if you need to freeze a bit too",
      "Don't bother... warranty won't do anything, because hotspot up to 110¬∞C are normal/ expected...thermal paste pump out is an issue, so open it and slap a ptm on it and be done..."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6700xt"
    ],
    "title": "Small upgrade. Was it worth it? [6700XT]",
    "selftext": "",
    "comments": [
      "Now change the cpu maybe a 5800X3D üòÑ",
      "If you want to buy a new mainboard I would by a AM5 board with the new 3d series in february",
      "Hmm... 6600 - 5450  \nThat's only 1150 better. Mine is a 6440 improvement. Definitely a smaller upgrade.",
      "Was my smaller upgrade from a HD5450 to a RX6600 worth it?",
      "That's the plan. 5800X3D and a new mobo to have all features. I'm waiting to see if I can get it on a sale.",
      ">HD5450  \n\nbruh that's like a cellphone processor from 2015 lol",
      "Indeed, either that or simply a 5600 cpu upgrade while keeping the same motherboard",
      "Deleted by user, check r/RedditAlternatives -- mass edited with redact.dev",
      "But I would be paying full price for that plus I would need new RAM.",
      "SAM was been allowed via BIOS updates on all AM4 boards, including X/B/A 300 boards as well.\n\nSAM works on Zen+ or newer and officially on Intel 10th gen or newer (though there have been reports of working on previous Intel gens). It definitely does not work on Zen1 tho.",
      ">Was it worth it? \\[6700XT\\]\n\nLemme werk it. I put my thang down, flip it and reverrrse it.",
      "It's badly limited right now. I'm gonna upgrade to a 1440p 144hz monitor . Currently on a 15yr old 1080p60hz display. Everything is holding it back. It's chilling right now.",
      "It‚Äôs possible you‚Äôd need new ram anyways. I used to run the 3000 series which was unstable without 3200mhz + ram. I‚Äôm not sure if the 5000 series is the same as I‚Äôve now got 3600mhz with the 5800x. The new processors are such an unnecessary expense right now. New processor, new ram which is overpriced, new motherboards which are also overpriced. Upgrading to the 5800x3d would be a better option and just sell your ram and get 3600mhz",
      "Hell even a 5600 or 5700 would be a huge upgrade.",
      "Just buy the cpu first. If you're satisfied then, you won't need to buy a new mobo, but if you're not satisfied then a new mobo it is.",
      "what resolution are u at with that ryzen 1700? i think u would be limiting this beautifull card at 1080p",
      "Just get a 5600 and wait until next year for a full upgrade.",
      "just get a 5800x3d with no other upgrades. 3000mhz ram is fine, b350 is fine.",
      "I see you‚Äôre on a ryzen 7 1700, you could just do a BIOS update and make any of the latest AM4 processors including the 5800x3d work. That‚Äôs your cheapest route. If you plan on upgrading to a different motherboard you might as well move on to AM5. If you got microcenters close to you, they are giving out free 32GB DDR5 kit of ram with the purchase of an AM5 CPU, and $20 off a compatible mobo. Good luck!",
      "You made a bigger jump than OP with 260X to 6700 XT, lol."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6700xt"
    ],
    "title": "price for 6700xt",
    "selftext": "this guy listed his used 6700xt for 225 in my area should i jump on it now, or is it just an ok deal.",
    "comments": [
      "6700xt is about 30% faster, but if need Nvidia features such as DLSS or video editing, the 3060 is the better GPU. Both come with 12gb of VRAM variants.",
      "It's a fine deal imo",
      "Yes, it‚Äôs a good deal for $225.",
      "Great deal, snag it.",
      "Pretty good.  I would definitely consider a 2080ti though, which gets dlss transformer while the 6700xt is not getting fsr4.  Definitely a bit faster of a card.",
      "Great deal, but test it with a steel nomad run using 3d mark demo",
      "I just bought an asrock challenger dual fan 6700xt for 250, so not bad",
      "That is a steal if it's working correctly. Avg price is 3-350",
      "It's an ok deal. RX 6800 a year ago-18 months, were retail 333-350, and 6700XT/6750XT less than 300(260-280).¬†\n\n\nTake pre-owned factor over the course of time, and age of the GPU tech, a 6700XT 12GB should be 175, and not over 200.",
      "6700xts used have never been under 200 dollars.",
      "200 tops imo, but what's an extra 25 just to get a GPU if don't need Nvidia features. Else would say 3060 12gb for less only if needing the features.",
      "what‚Äôs the performance difference between a 3060 and 6700xt?",
      "6700xt is faster",
      "Quite alot. 3060 has 8gb (I think)of vram and as such is slowly fading as being usable.¬†\n\n\nThe 6700xt can max out most games at 1440p",
      "If you are just using it for gaming and nothing else, the 6700xt is probably the better choice. If you will be using your GPU for content creation, video editing, productivity or machine learning/ai, etc., then the 3060 is objectively the much better choice. Of the two, I think the 3060 is the better GPU for most people.",
      "The RTX 3060 has 12gb of gddr6 vram over a 192-bit bus with a bandwidth of 360 GB/s, per techpowerup.",
      "no. The 3060 has (or had, it seems they stopped making the 8gb) the 3060 12gb has 12gb",
      "Fair enough, as they did have 5 different versions of the 3060, all with different configurations, though the 12gb model on the GA106 is much more common than the other 4 versions, two of which were 8gb models, at least here in the States. It looks like the 8gb models were released in the fall of 2022, nearly two years after the 12gb models which were released in early 2021. There was also a 6gb model released in 2021 with the fully unlocked GA106 utilizing all 3840 shaders of the GA106, according to techpowerup. I think it‚Äôs fair to say, though, at least here in the USA, that the 12gb model on the GA106 with a 192-bit bus and 48 ROP is the most common model, and it‚Äôs what most people are going to think of when you refer to the 3060. However, it would behoove the consumer to ensure they are getting either of the 12gb versions."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6700xt"
    ],
    "title": "Went Full AMD! Upgraded from an i7 6700k & 1060 6GB to a R5 5600 & 6700XT",
    "selftext": "",
    "comments": [
      "Tried to go for a teal and purple aesthetic. Huge performance uplift from my system I built 6 years ago.\n\nProud of the cable management to keep it neat and tidy, used USB3 header extensions and daisy chaining fan cables to tuck everything in the back chamber.\n\nStill considering if I want to use a vertical GPU mount as apparently airflow would be better in that scenario where i'm pulling air from the bottom and side and exhausting at the top.  \n\n\nSpecs:  \nCPU : Ryzen 5 5600  \nGPU : Sapphire 6700XT Pulse  \nMOBO: B550 Aorus Eilte AX v2  \nSSD: Samsung 980 m.2 500GB + PNY 500GB SSD  \nRAM: Klevv Cras X 16gb 3600mhz CL18  \nPSU: EVGA Supernova 750 G2  \nCPU AIO: NZXT Kraken X61  \nCASE: Tecware VXC",
      "welcome on the good side dude",
      "Thank you! Can't wait for the new AMD product line up! Kinda bummed I got in on AM4 so late as my old PC suddenly died but I can still upgrade to a 5800x3D in the future or sell the whole system and upgrade to AM5. Here's to hoping for a good future and prices for hardware \\*fingers crossed\\*",
      "Welcome to Red team and to the 6700 XT gang !",
      "It's a Tecware VXC, I didn't want something too big and I like the easy hinged panel design and the dimensions fit right for me for an ATX board.\n\nCase does not come with any fans.\n\nI recommend the LianLi O11 mini if you want a similar case but higher quality and more flexibility. Granted the price I paid was 1/3 of that so... Yeah, also my PSU couldn't fit you need an SFX or SFX - L to fit that case.",
      "I recommend TechPowerUp for GPU comparisons.\n\nFor example:\n\nhttps://www.techpowerup.com/gpu-specs/geforce-gtx-1060-6-gb.c2862\n\nAccording to the relative performance chart, the 6700 XT is 140% faster than the 1060 6GB.",
      "Cant say exactly since I transplanted some parts from my old build but I would say total value for both the new hardware and equivalent things I transplanted new would be around $SGD 1500 or about $USD 1000 at current exchange rates :)",
      "Very nice, I ended up with an AMD cpu and nV gpu but this most recent 4xxx release has me doubting nvidia wants to continue competing in the gaming space. Hope AMD lays the smack down this gen",
      "Sry for dumb question, what is this case? looks sick.  \n\n\ndo these cooling fans come with it?",
      "That's the same combo I have! Was able to play anything smooth as butter at 1440p.I don't have an aio unfortunately though I'm trying to get a new case that can fit one.",
      "Was a little worried about replacing AMD with AMD cause my 5700xt had a lot of black screen crashes until I reflashed the memory timings with Apple straps. There was always an issue to solve. Got a 6700xt for 150 after selling my 5700xt. It's amazing, cooler, more frames, everything runs flawless.",
      "How much did it all total up too?",
      "RDNA2 is beast just think how much better it would have done if RDNA1 wasn't so plagued with issues and bad reputation it's really sad to think about.",
      "Thank you for the kind words, validates the time spent working on it :)  \n\n\nWell, maybe a fan curve setup might help with noise, honestly building PCs LOOK intimidating but instruction manuals and YouTube videos are your best friend! Try it out for your next build! Also, hardware is much more durable than you think!",
      "I've just ordered a 5600 too, can't wait. Your build looks great!",
      "awesome photo!",
      "I just got a red devil 6750xt, so I‚Äôll have to go red if I follow this. But man this really looks clean wow.  I am totally copying you bro üò≠üò≠ü§ùüèæ",
      "Good for you my dude, I made a simalar upgrade recently,  hope you have a good time",
      "*AMD is the way to be.*\n\n**Welcome**",
      "I read fuck instead of tuck, was kinda confused, maybe a bit overly enthusiastic"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6700xt"
    ],
    "title": "Switched from my 5 year old 1060 to the rx 6700xt and i've tried it for only 5 minutes.. Its so much better",
    "selftext": "",
    "comments": [
      "Went from 6700k/1060 to 5800x/6800xt what a massive jump. Enjoy that upgrade dude I sure the he'll am.",
      "You are mad brave when you hang a dart board above your pc",
      "Can we all agree than Radeon cards all basically look premium no matter what, unless it‚Äôs an rx 6400 of course",
      "This is the jump I wanna make, but I also wanna go one step higher (6800xt) so that I never worry about 1440p 60fps gaming.",
      "I went from the GTX 1060 to the RX 7900 XTX and boy what a massive jump that is in performance.\n\nNice upgrade enjoy bro.",
      "Haha you went from a ‚Äúentry‚Äù level card from 7 years ago all the way to the top of the line flagship!",
      "Hell yea they do :D",
      "Ya its an electronic one my parents put there like 8 years ago. I should take it down cus we dont even use it",
      "I've been playing for hours now and had 0 problems",
      "Yes. I know. Was just suprised by just how much better it is",
      "Went from gtx960 2gb to 6600xt and it was so nice to have games just work no fiddling.",
      "My fps went from 80 with lowest settings in apex to 165+ with max settings",
      "What time do you live in? The average user can plug in an AMD graphics card and never have to touch a setting and have zero issues.",
      "Going to be doing the same going from 1660 super to 6800xt",
      "So worth it. I just upgraded from my GTX 1080 to the 6800xt. Getting like 160fps ultra settings on Call of Duty with that card at 1440p",
      "To the moon and beyond it right there lol",
      "oh ye of course.   \nApex legends at pretty much max settings 165+ fps absolutely no problems  \nLast of us part 1 roughly 60 with almost max settings. i gotta try to drop the graphics settings a bit tho cus my cpu is bottlenecking really badly  \nRocket league roughly 200 fps almost max settings  \nOverwatch... 10 fps even in the lobby and it takes 5 minutes to even load the game but its not because of the gpu. its cus my cpu (i5 8400) cant keep up with it",
      "Sure are a lot of people upgrading specifically to Ryzen 7000s and Radeon 6000s/7000s from specifically ye olde Core 7000s and GeForce 1000s. I guess the PC market really was that bad for so long.\n\nIt is good to see people realizing all the AM5 whining is just that though. If you're building a new PC, you might as well go AM5 at this point. Such is the growing pains of a new board, and this is exactly why AMD did not want to do a new board for so long.",
      "In summer of 2021 I went from a 1060 6GB to a Radeon RX6600XT and I thought that was a great upgrade. Couldn't believe how much faster it was, all those stream hardware charts must be lying.",
      "I had a 1070 and went to a 6700xt and was blown away at how fast it is. Then I got spoiled and got a 6950xt lol. Still have the 6700xt I'm gonna put in a PC for my son. I'd imagine it will be good for at least 4 or 5 years."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6650xt"
    ],
    "title": "Looking to upgrade from a 6650xt. 1080p 60fps with some future proof capability. Any recommendations?",
    "selftext": "",
    "comments": [
      "really depends on the GPU. I'd be willing to pay more for a 9070 than a 7800xt, you know? I'd say Roughly $700",
      "7800xt maybe. Its about a 40% jump in performance boost from the 6650xt.",
      "If you can get your hands on it a 9070 xt but for 1080p there aren‚Äôt too many upgrade paths that make sense without more context like cpu",
      "What's your CPU? I could recommend a 9070 or 7800XT but maybe your CPU will bottleneck it if it's too weak",
      "What's the budget, that's the most important thing",
      "With 700 you might be able to score a 9070xt :) I'd said anything RDNA4 would be better because of better RT and fsr4 if you want to stretch the life out of the card even more",
      "The 9000 series are RDNA4 cards hahaha",
      "I upgraded from a 6600 xt to 4070 ti super been playing games pathtracing no problem",
      "Oof this has me worried about following some budget pc build stuff from YouTube. I‚Äôve got a ryzen 5 5600 with a 6600xt coming‚Ä¶ I‚Äôm not a big gamer and just want to game at 1080p and be able to play most games without any huge flaws. Guess I might have to pull the trigger on a 6700xt and send the 6600xt back‚Ä¶",
      "7600x (dogshit pairing I know lol) I mainly said 1080p because I wanted to stress I don't need to run 4k. I just noticed that I'm struggling to run a lot of new games now",
      "Not OP but would a 7500f be bottlenecking either cards?",
      "7600x",
      "Tf is rdna4? And yeah $700 is enough to get a 9070xt at MSRP. Good luck finding one though haha. Cheapest 9070 (nonxt) I see is $800",
      "Made the same upgrade. Somehow it's worth more now than what i payed msrpüòÇ",
      "I mean it depends on the games you're going to play. Certainly now that games are getting more graphically intensive, I wanted a better gpu",
      "Wow what‚Äôs struggling if you don‚Äôt mind me asking",
      "Check gaming benchmarks, but I'd say yes",
      "Yeah for now I think the 6600xt is fine. Not going to get ahead of myself just going to build it and see how long it suites my needs. Worst case it sounds like AMD4 will be supported for some time and I won‚Äôt be looking at a complete overhaul anytime soon (if it makes it 4 or 5 years with maybe one GPU upgrade I‚Äôll be happy)",
      "Uncharted, Spider man 2, GoW ragnarok.",
      "saw a few benchmarks and a bunch of posts, the 7500f is pretty good. Very little bottleneck to none at all apparently. It's competitive with the 5800x3d."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6750xt"
    ],
    "title": "Should I even upgrade from my 6750xt?",
    "selftext": "Title says it.  \n\nCPU - 7 7700x\n\nRAM - 32 5200 Mt/s\n\nGPU - 6750xt\n\nSSD - I have two, one 990 pro and a slower one CT1000P3SSD8\n\n  \nI have a 1080p 165 Hz monitor. Really, I'm just second guessing myself on getting a 7800xt or just putting the money elsewhere in my pc or monitor. \n\n\n\n",
    "comments": [
      "Prob not, unless can get a RX 9070 or 9070 XT at MSRP. Hopefully new shipments coming in when the 9060 XT releases.",
      "No the jump from a 6750xt to a 7800xt isn't big enough imo. Just keep saving money and wait for a msrp 9070xt",
      "Not right now, definitely keep a look to see if 9070 XT prices come back down in a few months though.",
      "Get the 9070 XT. If you wanna stay on 1080p a 12700k+ or 5700x3d+ could push some high fps for you. For 1440p can't go wrong with the 9070 XT at MSRP. 5070 ti is comparable. Do not get the 5070. It's a bad price to performance.",
      "Msi Pro B650-P? I have the same board. Are you on the newest bios?",
      "I was sayin that the cpu‚Äôs you mentioned are slower then the one he has his gpu could use an upgrade",
      "Ram would be the upgrade id reccomend too i have a 7600x and a 6750xt and im pulling around 100 fps on 1440p high/ultra settings in helldivers 2",
      "A 7800 XT will be a good upgrade but why exactly are you looking to upgrade?",
      "The 5070 is just a reskin of the 4070 Super with roughly a 10% uptick in performance. \n\nhttps://youtu.be/ntSylZ1Bp1Y?si=tGW6CLLmXil29iRO\n\nIt received a fairly scathing review from most big reviewers. Here is Gamers Nexus one but even LTT said sort of similar stuff. It just isn't worth the cost.",
      "The 6750 will serve you well at 1080p. I moved to a 7800 after purchasing a 1440p monitor. Honestly, the 6750 was doing fine but I needed just a few more frames to be satisfied. If you plan to move to 1440p in the near future then it may be a good investment. If you're going to stay on 1080p for the foreseeable future stick with the 6750.",
      "If you need more Raytracing performance then 7800xt, if not then a 6800XT deal might be good, if its around 300-400, performs very similarly to 7800xt for a lot less money (6800 can do raytracing too, just not as good)",
      "Do you think I should get the 9070xt over either of the 5070's I've been with AMD for a while, so I'm used to getting them for the price to performance, but I've heard the 5070's are not as good?",
      "Well I was wanting to go to 1440p but then I'd have to wait longer to get the money for the monitor",
      "Since it only costs around $90, I‚Äôd get a better ram kit. 5200 is really slow. I‚Äôd get a 2 x 16 kit of 6000 cl30-36-36-76.  Ram actually makes a big difference at 1080p.",
      "Absolutely the 9070xt is only 2-5% slower than a 5070ti and the 9070xt has 16gb of vram while the 5070 only has 12.",
      "Dude he has an am5 7700x those suck comparativly",
      "Actually I have a set of cl40-40-40-84, but I tried for like an hour or so and I couldn't fix it with my bios maybe it's my motherboard, but I have no idea (PRO B650-P )",
      "They are the white t force delta ones they are supposed to run at 6400hz",
      "Personally had a 3700x and went to 7800x3d for 700$. Yeah not really worth as the FPS increase and 1% lows don't justify it compared to my GPU upgrade to a 7900 xtx. Not even close. I'm not playing comp games at 1080p either which a cpu upgrade benefits the most.",
      "You might want to manually lower them down to 6000. But yeah even still, you bought the wrong die looks like."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "rx6750"
    ],
    "title": "What GPU to upgrade from RX6750 XT Dual",
    "selftext": "Hey, so i currently have the asus RX6750 XT Dual and I am thinking about upgrading. I am mainly playing CS2 and Overwatch 2 and I would like to also livestream these games. I currently own a 240hz monitor but want to upgrade soon to 360 hz or maybe higher. My Processor is a AMD 7800X3d.\n\nLet me know you recommendations please, I would buy a used one, since I don¬¥t have a unlimited budget",
    "comments": [
      "6750xt is still a really good card. . . but. . . if you are using an ultrawide or a 34\" 2k then yeah, you will want to upgrade that card.  My suspect is you are going to want to be in the 9070xt range or a 5070ti.  I normally went AMD for price but since 9070xt and 5070ti cost the same. . . 5070ti this generation.  \n\n5080 would be ideal, but. . . . that jumps from $900 range to $1500 range.  Up to you though.",
      "for streaming purpose i advice 5070ti overall the cheaper models you find not msi ventus/shadow\n\nif you find a 4070ti super cheaper than a 5070ti is very good. .. also 4080/4080s\n\n\nminimun a rx  9070 but if you streaming in twitch nvidia is better encoder.. not for amd fault beacuse amd h265 and av1 are very good encoder but h264 amd econder is way worst than nvidia.. it Just twitch using ancient codecs like h264\n\nwhat s you budget?\n\ni will  advice to not go lower than a 4070s 3080ti  raw perfomsnce.. 12vram can be a problem in the future but not for overwatch and Cs \n\nif you can go for a 16gb card. \n4070s super does a +50% from 6750xt\n\nhttps://www.techpowerup.com/gpu-specs/radeon-rx-6750-xt.c3879",
      "i mean i'm not seeing much of a performance jump for you unless you buy into the $1000.00\\~$3,800.00 card range so you already know what to shop for.",
      "The best value card at that fps will be the 6950xt or 7800xt with the latter being slightly slower but also a little more expensive",
      "Isn‚Äôt your GPU the 7000 dollar editing one? Or I might be getting it mixed up with something else",
      "What is your budget?",
      "Depends on your budget and what your goals are. The 9070 and 9070xt are the winners this generation, IMO. Several issues, including drivers, causing problems with Nvidia 50 series.",
      "9070 and 9070 XT are the successors to your card and have also better quality for streaming purposes.",
      "ya 5080 is a scam.. too much price difference from 5070ti for too low perfomsnce gap",
      "The price is around 360‚Ç¨ now and its for gaming",
      "Unreasonably priced is not the same as a scam. Stop making words lose their meaning.",
      "legal scamüòÇ",
      "For it to be a scam, there needs to be some form of deception.  High prices are not deception."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6750",
      "6750"
    ],
    "title": "AMD RX 6600 stock runs dry in China, the company shifts focus to Radeon RX 6750 GRE 10GB",
    "selftext": "",
    "comments": [
      "This is still pretty much the only card most people need, it runs Doom Eternal at 100+ fps and most modern games on high with RT off at 60fps.",
      "Doom eternal runs at 60FPS on an Xbox One & PS4. 100 FPS is an extremely easy feat\n\nYou also need to specify a resolution if you're talking GPU performance",
      "You can't.  The reference 6600 was never manufactured.  It's just a rendered image only.",
      "Doesn‚Äôt fix everything. Even though it‚Äôs smoother it isn‚Äôt that responsive.",
      "60fps isn‚Äôt high enough when a lot of people have 144+ hz monitors now a days.",
      "Probably nowhere. The RX 6600 didn't have a reference design, so it's likely just a 3D render made by AMD for illustrative purposes.",
      "I've been using a 6600 since early 2022, it does everything you need it to.\n\nZZZ @ 1440p, Eve Online, MH:W, Elden Ring, all the esports. I've even tried LLM's on them(not great, but usable). UE5.3, Blender, Clip Studio, again, it's not a great card, but if you're just starting out, it does enough!\n\nGreat value, low power usage, and cheap!",
      "Where can we buy that single fan RX 6600 from the OP's picture?",
      "I think it's just a mock up. It looks like an AMD design but they never released anything below the 6700 xt for purchase directly on their site.\n\nIt's too bad. It has a great aesthetic.",
      "Ok since people are downvoting me I guess I gotta post sources...\n\n[https://www.youtube.com/watch?v=NdoxEaySXis](https://www.youtube.com/watch?v=NdoxEaySXis)\n\n[https://www.youtube.com/watch?v=EOBE-Ade9MQ](https://www.youtube.com/watch?v=EOBE-Ade9MQ)",
      "Same, except late 2022. I feel like it's the 1060 / 580 of its generation. Not the best, but good enough for what most people play, and probably the best bang for the buck out there.\n\nFSR / XESS / etc. are helping me with the few games it struggles with, and honestly, those games generally tend to be poorly optimized anyway.",
      "With mouse and keyboard I just do not find 60fps to be playable. Even drops down to 90/100 from 140/50 sorta range is extremely noticeable.",
      "I wonder if 60FPS or 120FPS is 'standart' these days",
      "I recently got the Asus Dual 6600 and man this card punches! Playing Warhammer 3, le mans ultimate and ACC all maxed out 1080p with no issue",
      "This. Idk why ppl act like 1080p60fps is the bar to meet in 2024. That ship sailed. \n\nThe new standard is 1440p120fps.",
      "Lemme guess what those \"few\" games might be. AW2, star wars jedi whatever, hellblade 2",
      "By that logic we should have all been happy with 20fps then right?",
      "I would be more interested in the 12GB version wich is basically a cloned 6750 XT so with faster 18Gbps VRAM\n\n2 more GB is welcome for using extra features like frame generation / afmf with texture-heavy games like console ports\n\nI also wish there was a small 2slot model like the PowerColor Fighter series ... guess im expecting too much",
      "ü§ì",
      "I don't know what AW2 is, you're correct with Star Wars Jedi whatever, and another one is Starfield, which I had to use FSR2 just to be able to play with a decent frame rate.\n\nHonestly, if devs optimized their games right, I'd say that the 6600 would probably be relevant beyond 2025, but if Ubisoft is any example, this might not be the case, unfortunately."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6700xt"
    ],
    "title": "Huge FPS gain after 21.12.1 GPU driver in Forza Horizon 5. 114>>148fps, 6700xt",
    "selftext": "",
    "comments": [
      "There was a big Forza update as well. Are we sure it was drivers that did this? Note how the game version has changed between runs.",
      "I noticed really big boosts in Halo Infinite also. Well in excess of the 15% they claimed.",
      "I rerun the benchmark in latest game build with 21.11.2 after DDU. Even worse FPS than before. So its definitely driver related.\n\n[https://imgur.com/a/12RfBRK](https://imgur.com/a/12RfBRK)",
      "I haven't tested this new driver but just wanted to share my findings with RX 6800. So since launch I had massive fps drops in races (especially cross country) and didn't know the cause. Changing overall settings didn't seem to matter, but actually particles quality is the culprit. So with high or ultra, the drop is absolutely massive when there are lots of cars on screen emitting smoke or dirt (like going from 100+ fps to 40) it's a slideshow. With medium there's a big gain and it goes at like 70-80 in those moments. At low it basically stays over 100 but then the smoke starts to look like ass when you drift on asphalt.\n\nI also found out that terrain deformation isn't actually active because there should be deep tracks in the sand, all I see are faint tyre marks.",
      "Did you have the ‚Äúready for halo infinite‚Äù drivers before that? Or just the previously available through the amd software",
      "I can personally confirm this on my own system.\n\n21.11.2 (82 FPS): https://i.imgur.com/2MmaqvZ.jpg\n\n21.11.3 (88 FPS): https://i.imgur.com/nzNQa0H.jpg\n\n21.12.1 (98 FPS): https://i.imgur.com/twgn9Fu.jpg\n\nI was GPU-limited in all three benchmark runs and used identical graphics settings.\n\nEDIT: Performance uplift in RDR2 as well. \n\nBenchmark Scene #| Avg. FPS (21.11.3) | Avg. FPS (21.12.1)\n---|---|----\nScene 1 | 71.647758 | 78.857147\nScene 2 | 85.386040 | 88.528145\nScene 3 | 105.904663 | 109.190758\nScene 4 | 82.836662 | 86.451599\nScene 5 | 81.112938 | 86.385429",
      "Damn that is an insane boost!!",
      "Amazing boost. And no mention in driver releases. Congratulations to amd. Performance like forza horizon 4 with the latest drivers.",
      "That's absolutely nothing like the 30% gain that OP is suggesting.",
      "Likely the improvements from the beta Halo driver now in a stable version. Can anyone beat my +42% improvement with ultra settings at 1080p? :P",
      "Not op but i have an rx 570 +r5 1600 and was getting 20-25 fps. Turns out i havent updated my drivers since 2020 so i downloaded the new one and now i am at ~70",
      "Raja was right after all",
      "Excellent, that‚Äôs really impressive.",
      "RX 6800 was around 85-90 FPS at 1440p High and is now at 120-130 FPS same settings",
      "Completely off topic, but any Rush fans out there?  If so I love the drivers version for this month 21.12  !",
      "Does anyone know if RX570 would gain any FPS in FH5 from this driver update?",
      "Yes, I also have RX5700 and installed the latest driver. \nOn WHQL driver, 1080p and same video settings as Xbox performance mode, I had 70-90fps with dips to 60fps in places like Guanajuato. \nNow, with settings unchanged, I have around 100-110fps with dips to 90fps, so there is a significant fps boost.",
      "RT isnt working in gameplay or benchmark scenario. It just works in car showroom.",
      "lmao so thats why car showroom is so slow for me",
      "Yeah but it‚Äôs very good for the price imo. I‚Äôm hoping to score a 3080 or 3070 ti through Best Buy at msrp so I can sell what I‚Äôm using (6700xt reference card)"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6750",
      "6750"
    ],
    "title": "Say hello to my little friend (upgraded from a RX 6750 XT Red Devil)",
    "selftext": "",
    "comments": [
      "Sapphire Nitro+ is unarguably the best looking card of this generation",
      "Fir every beautiful women in the world, there‚Äôs a man who is tired of how she looks.",
      "aRGB",
      "That is to connect the GPU to the motherboard to control the RGB colours if you wish, I just used Trixx though.",
      "You might be the beautiful woman in the analogy. Sorry lol",
      "What are those pins for? Right from the power connector",
      "I think it's my favourite but in person the hotspots on the LEDs are much more prominent than in pictures which is a bit of a let down. Wish it was a smoother diffusion.",
      "I knew somebody would mention that buy yeah its the photo slanted.",
      "the 2nd photo, is the GPU sagging or the photo was taken slanted",
      "I was a photography nerd at one point earlier in life, and in case you want the technical term for what you're seeing, this is an optical aberration known as \"barrel distortion\", caused by an imperfectly shaped lens which causes a bowing effect, usually in the center of the photo.\n\nIt is indeed wonky.",
      "Nice I have the same BUT do you use the anti-sag bracket included?, because it seems that you have quite the sag there!",
      "Controversial take but I think the Pure and the white tuf look better,\n\nAs a seasoned nitro+ owner this card has been mid for me honestly.",
      "I was thinking of getting the same card i.e. 7800 XT but I changed my mind and now I'm getting the 7900 GRE, in my case, I only have to pay a bit more for the upgrade.",
      "Was it even worth it? It's like going from 6750xt to 6800xt",
      "Yup, I simply love it and the looks played role in my selection.",
      "That's the third 8-pin connector, (i think) all Sapphire cards have 3 connectors so they can pull more power to get just a bit more of overclock. OP doesn't seem to really mind though",
      "Well I am able to max out all game settings now and still get more fps than than I was getting with the 6750 with some settings turned down. Plus you get the newer tech. For me I think it was worth it.",
      "no",
      "Hu?",
      "Oh OK, then enjoy I ended putting mine vertical with a cooler master GPU bracket/riser."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6700xt"
    ],
    "title": "This GPU generation is gone",
    "selftext": "I think that substantially this generation of GPU is gone for us, and that when there will finally be stock and prices somehow near MRSP, we will already be close to the first leaks and the first engineering samples of navi3\n\n5700xt July 2019\n\n5600xt January 2020\n\n6800xt November 2020\n\n6700xt March 2021\n\nif the development time between one gen and another stays the same, it's not difficult to hypothesize navi3 more or less in 10 months from now, so end of this year or beginning of 2022\n\neven if in September / October there were finally stock of cards at \"normal\" prices, it would not make much sense to buy those cards with navi3 coming out so close\n\nwhat do you guys think?",
    "comments": [
      "I remember over the summer everyone advising not to buy a GPU since the new ones were right around the corner...\n\nFool me once.",
      "If only I could believe in September/October to have normal prices. I decided I'd just play mostly older games and backlog and put my GPU upgrade on hold indefinitely and invest in other hobbies instead. In my time high tier GPUs were 400-500‚Ç¨, not 600, not 1000 and certainly not 1500‚Ç¨ or more. That's just ridiculous.",
      "Usually it's 2 years between GPU cycles, and we're 6 months since release. We've got awhile yet. lol Late 2022 is when the next ones will theoretically, and that's assuming everything goes well. There will probably be a refresh like the 3080ti etc late this year.",
      "Same. Saw Pulse 5700xt's and 5600xt's on sale frequently from July through october, perfectly reasonable prices all day, and now those same cards are on ebay for $800+.",
      "I've been fooled. Now rocking a 3900X with a R9 280 lol",
      "fuck these scalpers and miners this is the worst i have seen it been pc gaming for 3 decades",
      "I HAD a 5700xt and returned it because it was too close to better cards coming soon.\n\nLuckily the 1060 lives on.",
      "i'm just waiting for the second-hand market after the crypto currency crash",
      "AMD have already stated they're on a 12-18 month cadence for both CPUs and GPUs. Expect the next gen to come by mid next year.",
      "The pandemic hasn't helped. There's chip shortages in all industries. \n\nBut the combination of scalpers, miners, and the shortage has made this absolutely insane. I'm just glad I'm content with my current GPU.",
      "From a gamer's point of view this makes perfect sense. There are hundreds of excellent games out there that each person has never really enjoyed, and no time to play them all. Also, even if you want to have fun with a modern game you don't have to force yourself to only play it on ultra settings 4k 120fps and so on.\n\nA lot of people waste their money paying inflated prices because they \"need to have the latest just because\".\n\nOthers use the GPU for research, rendering, or some other work. That's fine.\n\nBut strictly for gaming, yeah.. like you said, there's no sense in pushing it that far.\n\nI myself have an endless backlog of dozens of  games I consider \"must play\" stuff.",
      "This, I would not expect RDNA 3 gpus until mid/late next year.",
      "This might be the time it does not crash",
      "Ugh, you have to be kicking yourself. LOL",
      "Prices wont normalize by Q3. I don't know why people keep saying this. It doesn't make sense.  \n  \nThe west market will likely stabilize a lot quicker than the rest of the world but not by Q3. How many people are still waiting for GPU's? How many resellers are going to try and continue an artificial scarcity just to sell at inflated prices for a bit longer? This will get milked dry just as everything always does. It makes no sense to normalize prices unless inventory starts filling up. It wont happen by Q3. People are still waiting on GPU's they ordered back in November at launch and some of those are even getting cancelled because the GPU's they originally ordered are no longer in production. Remember how they said supply will be back to normal by end of March? It's far from normal. I've said it before and I'll say it again; don't expect things to go back to normal for a while. **If** it ever even is going to be normal again.  \n  \nThe MSRP has been getting worse for generations now. Mid-range GPU's going for $350-400 is unacceptable. Now that we're being *conditioned* to these ridiculous scalper prices, what's wrong with raising the MSRP for next gen another $100? People are already willing to pay scalper prices so clearly GPU's aren't generating enough profit. The days of affordable GPU's are gone. We will eventually get back down to MSRP but the MSRP will never be the same again. Remember this *if* or when the next 4060 starts at $375 or $399 MSRP.",
      "Stay strong buddy our time in the sun will come",
      "shits so bad alot of people are giving up on pc gaming",
      "Oh, oh yes indeed.\n\nBasically I bought the 5700xt for my \"old\" pc of 4 years, and then decided it was stupid to not just build a whole new one with all new gen parts. So I had a \"reason\" but man hindsight is murder.",
      "I believe Linus made a video in 2020 summer recommending to buy computer hardware right away, predicting massive shortages.",
      "Yea they really have no reason to push out rdna3 when 6800 xt and all are flying of the shelf's and is gonna keep flying"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6750",
      "6750"
    ],
    "title": "AMD Radeon RX 7600 XT's China release date uncertain amid RX 6750 GRE series popularity - VideoCardz.com",
    "selftext": "",
    "comments": [
      "Wait a 16GB GPU at $300, why did this GPU not come out here ages ago?",
      "Needed to get rid of RDNA 2 inventory",
      "Illusion of choice. They wanted you to either spend $260 for the 7600 or cough up $450 for the 7700XT which they priced terribly in order to upsell you on the $500 7800XT with not much in between. \n\nAll while clearing inventory of last gen 6700XT in the $300 range. \n\nNow that inventory is drying up BOOM release a product to fill the gap and give it 16gb of VRAM for those who you couldn‚Äôt successfully upsell the 7800XT to.",
      "Texture settings usually don't cost much performance as long as you have enough VRAM. So this will let you run ultra textures for a long while even if you have to turn down other settings.",
      "if it comes with 40CU, its more like a 6700 XT with 16GB",
      "Golden Rabbit Edition. Supposed to be China exclusive, but I can find all the gre cards in my home country (Southeast Europe)",
      "lol as if radeon marketing division was that competent.  or they were the top choice in gpus.",
      "Not quite. 7600 trounces 6600xt across the board. 6650XT is SLIGHTLY slower then the 7600, but they trade blows.",
      "This is what I don't get, I feel like this 16GB will be used as a crutch to sell it at like $370, because you know, ain't nothing out there with 16GB of memory below $450. Memory is cheap, but that doesn't translate to better prices for us, that 16GB can justify at least a $50 up charge in the eyes of corporates, i don't want it if it means $50 more than what an 8GB card would've been, it's a 1080p GPU, would be nice if there was an option between both.",
      "4060 Ti 16GB enters the chat. $500 launch MSRP for 128 bit LMAO\n\nDamn, some people actually bought that. They got hosed so badly.",
      "It's almost definitely a 7600 with twice the VRAM and like 10-15% better performance",
      "They sell all their allocation just fine. Most of it goes to CPUs, consoles, and handhelds so they don't have that many left-over for GPUs. \n\nThey can't be any more of a choice than they already are since it would take years or decades to order more, receive more, and produce more.",
      "I'm looking to buy a RX 6700 XT next week, should I wait for this instead?",
      "But is it fast enough to make use of 16GB?",
      "Its kinda amazing. when it comes to toyotas and japanese automobiles they took all the market by storm. But AMD's \"Toyota\" lineup AM4 and RDNA2 didnt dent the marketshare of other brands. and now AM5 and RDNA3 is fighting for the same picky buyer %20 that already upgraded leaving stock behind. I guess cars are more expensive entitites to push people into value products while Chips are just more like guccis?",
      "Exactly.  I picked up a used 7600 and has been working really well as an experiment.  going to pick the XT Up and keep it as my primary machine.",
      "The 7700xt is already a rx6800 so..",
      "Agree. Electricity cost is much cheaper in mainland China compared to a lot of states in Us",
      "If you see a 6700 XT for $300, get that. This will most likely be slower than a 6700 XT and it'll probably cost at least 299.",
      "Did you forget about the ARC A770? 16 GB variant has been on sale for quite some time now. Can find them easily for under $300."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6700xt"
    ],
    "title": "RX 6700XT + RYZEN 5 5600X | 25 Games Tested at 1080P, 1440P and 4K",
    "selftext": "",
    "comments": [
      "I shouldn't see much difference at 1440p if I use a 11400F instead right?",
      "Depends on the game still. In something like cyberpunk where crowds seem to hit the cpu hard you would.",
      "I am glad I managed to secure a 6900 XT while my 6700 XT was being shipped to me. Upgrading from 1080p @60fps to 1440p  @144hz is insane.\n\nYour previous video on the ultrawide 6800 XT + 5600x helped me a lot to justify the purchase of the 6900 XT.\n\nI just don't get why AMD recommends the 6700 XT for 1440p gaming. Sure for 60fps it is solid but anything above depends on the game and what settings you are comfortable to compromise for more fps.\n\nOverall excellent video.",
      "It depends heavily on the game, in most games it'll be fine but some games are more CPU heavy. 11400f definitely has better value than 5600x imo",
      "If the gpu is at 97-98% the difference will be minimal if any, this ofc if the power limit is removed",
      "Meanwhile there‚Äôs those random channels that only shows bar graph and it just looks skeptical",
      "I have a Sapphire Nitro+ 6800XT and it is Awesome for 1440/144. 6800XT runs 1440/144 buttery smooth. Doesn't break a sweat.",
      "This comment should be renamed - user that doesn't know the basic and usually has unstable overclocks and then blames gpu drivers",
      "Hey, i mean, why would you use a lower resolution when this card can play most games at 1440P around 100 fps? I see no sense in there. Also, releasing the OC/UV tutorial in some minutes ;)",
      "Dude I intended to get a 6800 XT but it was impossible to get one for MSRP. I was lucky to grab the 6900 XT slightly above MSRP from a guy who accidentality ordered two. The 6900 XT was a bit overkill for my use case but I will take that over scalper prices",
      "Thanks, i get it. That's why you have timestamps. Live stats are always better for this, charts are for the gpu and cpu comparisons :D",
      "For the price it‚Äôs at now a days, yeah",
      "I run a  5800X with the 6700 XT. It's brilliant.",
      "Thanks for the words",
      "Thank you",
      "I agree. I really wanted the Sapphire Nitro+ 6900XT to pair with my 5900X but I have zero regrets or qualms with my 6800XT",
      "Seems like you overclocked your brain also",
      "You got to appreciate all the effort put into this 1 hr bench video !",
      "Here https://youtu.be/h5C5jNedZqM",
      "Thanks!"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6750xt"
    ],
    "title": "New VGA 6750XT w/ 5600X",
    "selftext": "CPU - 5600X\nVGA - Xfx merc 6750XT\nRam - Vengence 3600Mhz C16 16 (8*2)\nSSD - Crucial P5 1TB m.2\nMB - Tuf B550 \nHDD - 4TB (2 x2TB)\nPSU - corsair RM 750 \nüòÖ",
    "comments": [
      "I really like the design of the XFX shroud. I got a 6800xt because of it. Enjoy it!",
      "Nice build you don't see many XFX cards with the white merc logo its black on my 6950 XT.",
      "Its called GPU as a short term or video/graphics card to be more specific, not VGA, VGA is an old port used to display GPU output to monitor.\n\nAnyhow, congratz as its a solid card, enjoy :)",
      "The 7900xtx only has XFX lights :(",
      "Yeah this made me wonder if OP might be a bit on the senior side as VGA hasn't been used in some time now.",
      "Yeah I have no idea why they got rid of the extra text, it made the GPU look really unique. No other GPU does it.",
      "And that ugly silver backplate instead of black",
      "back in days we called them as VGA cards , thats why xD . thanks",
      "I like that backplate!",
      "I have a white build and it looks great in it. But I get it that most builds are black. They should give the choice between silver and black.",
      "I got a Red devil 6750xt, but man does that XFX one look good.",
      "Whats the performance difference between a 6600xt and 6750xt?\n\nReally nice looking build.",
      "My buddy got this exact model and it's too much for a 6700 XT but oh boy it never gets warm. Enjoy man.",
      "Same card as in my friends build i did for him. Such a sweet card",
      "I put this same GPU in my son‚Äôs computer, nice peppy little card",
      "Very well proportioned build, I like it !! üòÅ",
      "![gif](emote|free_emotes_pack|heart_eyes)",
      "VGA stands for Video Graphics Adapter, not the port, which is a 15 pin D-Sub, so OP is technically correct. Greetings from another senior user!\n\nCGA - Colour Graphics Adapter\nEGA - Enhanced Graphics Adapter\nVGA - Video Graphics Adapter \n\nThere were other more obscure ones too.",
      "Roughly 30%.\nBut on top of raw performance you get extra 4GB of VRAM, wider bus and more L3 cache. The jump is nice, but I think 6800 makes more sense, it's ~54% faster.",
      "thanks :D"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6750",
      "6750"
    ],
    "title": "RX 7700 XT vs. RX 6750 XT for game development and 3d work",
    "selftext": "Hey all.\n\nI'm planning to upgrade from my current laptop (i5-2430M, Radeon HD 6470M, 8gb DDR3-1333) to something faster. Way faster.\n\nI'm torn between these two cards (RX 7700 XT and RX 6750 XT). I have heard something about the RX 7000 series being better for productivity than the RX 6000 series, I don't know if this is true.\n\nThe price difference between these two cards is 63 euro.\n\nI'm planning to use it for Unreal Engine, Unity, Godot and Blender. I don't know much about these programs since I have never used them before.\n\nDoes anyone know how much more the RX 7700 XT is better than the RX 6750 XT for game development and 3d work?",
    "comments": [
      "Between those two I'd say the 7700 XT is the better choice, but you can't go wrong with either. AMD cards will do fine in all of those but Nvidia is just superior in blender thanks to CUDA.  I've done unity dev work on a 6800 XT and it was perfectly fine. \n\nIn all honesty, except for blender your CPU matters more than your GPU with these tasks- Unity will use all the threads you can throw at it when compiling and if choosing the 6750 XT over the 7700XT gives you the budget to go for an 8-core chip instead of a 6-core chip, do it.\n\nThat being said i agree with the other commenter, a used RTX 3080 10GB is the best value in that price range right now. Those that work are well within the valley of the bathtub curve and you'll probably get at least 5 years out of a used one. (Just maybe avoid the zotac trinity model of the 3080 those are cheaper for a reason)",
      "Excuse my ignorance but aren‚Äôt nvidia cards better at these tasks?",
      "used 3080",
      "I think you will be better with Nvidea hardware as they might be better at handling productivity...",
      "All this info is very helpful, thank you!\n\nBoth options feature a Ryzen 7 7700.",
      "Probably, yes. Sadly, the best nVIDIA card that fits in my budget (430 euro) is the RTX 3060 12gb.\n\nIsn't the RX 7700 XT better than the RX 7700 XT for all my use cases (except Blender ofcourse)?",
      "They are said to be, yes.",
      "I don't really know about buying used. It's quite risky.",
      "Might be, yes.\n\nAlthough the best nVIDIA card that fits in my budget (430 euro) is the RTX 3060 12gb, what costs 290 euro here.",
      "Well productivity wise nvidia seems like your best bet. Although I don‚Äôt do any of these tasks and only game, so I went with AMD. But for productivity go for nvidia. Where are you from? 430 for a 3060 seems a bit steep imo.",
      "Less than you'd think. the biggest risk is the lack of warranty",
      "Bro Actually sometimes 7900xtx performs similar to 4060ti in Productivity so it will be better to research if AMD support those applications. It's all on your applications.",
      "I'm from the Netherlands btw.\n\nI mean't my max. Budget for a gpu is 430. The 3060 12gb costs 289 at a minimum here.",
      "I'm afraid when the buyer protection of the platform is over, That then for some (random reason) the gpu dies, and I've then lost a lot of money.",
      "Yeah, I'm researching. But it's quite difficult to find a benchmark or anything for Unreal, Unity and Godot.\n\nAtleast I found out that the RX 7700 XT is quite close to the RTX 3060 on blender.\n\nNVIDIA GeForce RTX 3060\tMedian score:2147.17\tNumber of benchmarks:411 AMD Radeon RX 7700 XT\tMedian score:2128.77\tNumber of benchmarks:59\n\nSource: [opendata.blender.org](https://opendata.blender.org/)",
      "Thats an idea. Yes, you may need the VRAM. You may want more modern features though. Just a thought.",
      "That doesn't really happen with GPUs a ton UNLESS they've been reflowed. If they've lasted 2 years, they'll probably last another 5 if cared for properly.",
      "I have had a used 3080 for 2 years with no issues. I always buy used cards. No risk and way more performance per dollar.",
      "If possible try the things physically at a Centre near you. Whichever satisfies you buy it... I think this suggestion is sounds good but I don't know if the seller can let you check these things.... Gamers love AMD but Nvidea shifted focus to AI...."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6700xt"
    ],
    "title": "RX 6700xt ASUS TUF BEST Undervolt. Using only 112W and 52C at 100%",
    "selftext": "Hey i was trying to undervolt my gpu because it has some coil whine, after an hour I found a good voltage and clock  speed that don t crush so I decided to play with them. As I loaded to my game (ARK) I Saw that a GPU that s supposed to use 200w is using only 112W while staying at 52-55C at 30%fan which is crazy.I just wanted to share my settings with you because I think this is really good result.\nEdit: Don t blame me if doesnt work on your GPU, maybe i just have some really good model.\n\nhttps://preview.redd.it/dyotg3qdaccb1.png?width=1920&format=png&auto=webp&s=71aa87ae28e981449aabdd5a8e3def1ddc89704e\n\nhttps://preview.redd.it/5xuwj0qdaccb1.png?width=1887&format=png&auto=webp&s=1153b8918a2d8e5eecaf35454b50dcc15b5c9b07",
    "comments": [
      "Stability trumps power and temps anyday. I highly doubt this is stable. You just haven't found it's weakness yet.\n\nEdit: ya it wasn't stable. Huge surprise.",
      "It's a very good result! Just keep in mind that you might run into some crashes down the line. Getting the undervolt stable requires some time and patience, for reference at 1100mv mine seems stable in heavy benchmarks but I do get some sporadic crashes so I upped it to 1140 for now. Still a very nice saving :)",
      "Only one crash, so far.",
      "Here's my spreadsheet of stable voltages and clocks across the whole range of my 6700xt sample. \n\nhttps://docs.google.com/spreadsheets/d/1sOVt4gNZQYdSHWGY24a6u3yRolVa5qb6ACAD1DJ1Ck8/edit?usp=sharing\n\nNote that they mostly all use 1130mV, which means a -70mV undervolt from the stock 1200mV of my card. \n\nTL;DR Stockish 187W at 2470MHz, all the way down to peak efficiency of 67W at 1345MHz. Sweetspot I'd say is 124W at 2110MHz. \n\nKeep in mind these are Unigine Superposition 4K tests, which I've found to have up to 30% higher power consumption per clockspeed than the majority of games.",
      "my 6700 runs at 90w (stock is 160w) since january and it never crashed even once, to be fair a lowered the clock a little but it didn't really degrade my performance much, it's maybe 5%",
      "Not all cards are born equal",
      "I got cucked by the silicon lottery it seems üò≠",
      "Bro I get crashes at 1165 with 2400-2500 core clocks and +100 memory clock.",
      "I m playing on that since posted, only 1 crash So i incresed voltage by 10",
      "Yeah the software reporting on this generation of AMD cards is not very accurate to the real power consumption. At a reported TGP of 185W reported in software, it's actually pulling ~230W from the PSU/Motherboard. \n\nhttps://www.igorslab.de/en/graphics-cards-and-their-consumption-read-out-rather-than-measured-why-this-is-easy-with-nvidia-and-nearly-impossible-with-amd/",
      "Run 3dmark stress test.",
      "Difference is that the 4060 is manufactured E-Waste or as Gamers Nexus put it: A waste of Sand.",
      "I literally have every option enabled, GPU usage at 99% CPU is 5 5600 so there isn t any bottleneck, what is your problem?",
      "Makes sense, I have the Sapphire Pulse 6700 XT",
      "Most self aware redditor.",
      "Try testing other games, ARK is too dynamic and has terrible cpu/gpu optimization.",
      "Xfx 6800xt merc at 4k undervolted to 1055mv uses a whole 130-180watts, very rarely hits 200w and is usually around 150-160w.\n\nUndervolted and overclocked, it gets better fps than the factory OC.",
      "Undervolted amd = next gen play",
      ">Stock 187W\n\nUnrelated but kind of related question as I am a brand new owner of a 6700XT & you seem to have *some* knowledge. What's the maximum Total Graphics Power it's supposed to pull in watts? I've seen websites advertise the total power draw as 230W but from what I can see in the AMD Adrenaline software & HWinfo64 in TGP field, it maxes out at 180-185W; is that normal?",
      "I love this. Did you fill up the spreadsheet manually, or programatically? I would like to do this on my 6800xt"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6750",
      "6750"
    ],
    "title": "ASUS Radeon RX 6750 GRE \"Megalodon\" graphics card spotted",
    "selftext": "",
    "comments": [
      "Region limited products are so stupid.",
      "Even worse, there are 2 versions of it.\n\nThe 6750GRE 12GB is 40CU and fed by the full 192-bit bus. It boosts to 2581mhz.\n\nThe 10GB version is 36CU,  and only has a 160-bit bus. This one only boosts to 2450mhz.\n\nIn theory (CU x Mhz), the 12GB version is like 15% faster. This is some 3060 8GB type shit.",
      "The GRE (Golden Rabbit Edition) branding confuses me, 2023 was the year of the rabbit in China. It's been year of the Dragon in 2024.",
      "I just call it RX 6750 Gregory \n\n\n\n/s",
      "GDE.\n\nI love it!",
      "The naming is deceptive. It's got the same VRAM size and speed, same shader count, and same boost clock as the RX 6700 non-XT. It's an RX 6700.",
      ">The GRE (Golden Rabbit Edition) branding confuses me, 2023 was the year of the rabbit in China. It's been year of the Dragon in 2024.\n\nAMD never said GRE comes from Golden Rabbit Edition, that's why they continue using it, plus this name already has brand recognition.",
      "The GREG edition.",
      "We've had this chip since forever as the 6700 10GB",
      "naw it's just a rebadged 6700 (non xt)  \nnot THAT egregious",
      "Why are you spreading fake news? All GRE models are literally called ÈáëÂÖîÁâà in china and that literally translates 1:1 to golden rabbit edition.",
      ">Why are you spreading fake news? **All GRE models are literally called ÈáëÂÖîÁâà in china** and that literally translates 1:1 to golden rabbit edition.\n\nThat's not true. **There's no mention of  ÈáëÂÖîÁâà on any GRE products on chinese amd.com.**\n\n[https://www.amd.com/zh-cn/support/downloads/drivers.html/graphics/radeon-rx/radeon-rx-6000-series/amd-radeon-rx-6750-gre-12gb.html](https://www.amd.com/zh-cn/support/downloads/drivers.html/graphics/radeon-rx/radeon-rx-6000-series/amd-radeon-rx-6750-gre-12gb.html)\n\n[https://www.amd.com/zh-cn/support/downloads/drivers.html/graphics/radeon-rx/radeon-rx-6000-series/amd-radeon-rx-6750-gre-10gb.html](https://www.amd.com/zh-cn/support/downloads/drivers.html/graphics/radeon-rx/radeon-rx-6000-series/amd-radeon-rx-6750-gre-10gb.html)\n\n[https://www.amd.com/zh-cn/products/graphics/desktops/radeon/7000-series/amd-radeon-rx-7900-gre.html](https://www.amd.com/zh-cn/products/graphics/desktops/radeon/7000-series/amd-radeon-rx-7900-gre.html)\n\n[https://www.amd.com/zh-cn/products/graphics/desktops/radeon.html#tabs-32886884b5-item-ebdfea529f-tab](https://www.amd.com/zh-cn/products/graphics/desktops/radeon.html#tabs-32886884b5-item-ebdfea529f-tab)\n\n[https://www.amd.com/zh-tw/products/graphics/desktops/radeon.html#tabs-0a31ea901d-item-dd3584f26e-tab](https://www.amd.com/zh-tw/products/graphics/desktops/radeon.html#tabs-0a31ea901d-item-dd3584f26e-tab)\n\nHere are a few listings on [JD.com](http://JD.com), one of the largest etailer in China. Just GRE in the names, **no mention of ÈáëÂÖîÁâà anywhere.**\n\n[https://item.jd.com/100102125601.html](https://item.jd.com/100102125601.html)\n\n[https://item.jd.com/100100540622.html](https://item.jd.com/100100540622.html)\n\n[https://item.jd.com/100102125601.html](https://item.jd.com/100102125601.html)",
      "I'm now disputing what GRE means. I gave you a bunch of links where AMD said nothing about \"Golden Rabbit Edition\" or ÈáëÂÖîÁâà  being an AMD official name. It's simply GRE.\n\n**I'm still waiting for your proof where AMD said that GRE is Golden Rabbit Edition is the full, official naming.**\n\nUnless you provide an AMD marketing material or PR release, you're the one spreading fake news.",
      "AMD boardmakers are still releasing new GPUs 2 generations behind!  They are #1 in overproduction, if not anything else!",
      "Can we get those boxes outside of China too?",
      "I expected more from a Megalodon class card. üòÖ",
      "Exactly AMD is doing it more & more, where is the 7600x3d in rest of Europe?",
      "Your comment has been removed, likely because it contains trollish, antagonistic, rude or uncivil language, such as insults, racist or other derogatory remarks.\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/Amd) if you have any questions or concerns.*",
      "Ever heard of retcon? AMD realized its a bad move marketing wise to keep using GRE over the years despite it no longer being the rabbit year. Its just a bandaid fix to prevent people from realizing its original meaning through cencorship.\n\nGo to any independent chinese reviewer that did a gre review, all of them call it that.\n\nThe same naming concept actually happened before the GRE, in the form of the RX 590 GME, aka Golden Mouse Edition.\n\nAMD realized how damaging it is to brand recognition to keep changing names every year they need to release a defective product at a lower price point below the XT model so they kept GRE while removing the original meaning of GRE.\n\nIts common practise in the business world, a quick example being an esports organization called Gamers2 rebranding entirely to G2 forgoing its entire meaning because Gamers2 is such a dumb name."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6750",
      "6750"
    ],
    "title": "RX 7600 XT 16gb vs RX 6750 XT 12Gb vs RTX 3060 12Gb vs RTX 4060 8 Gb",
    "selftext": "I don‚Äôt know shit about graphics cards, but I need to buy one. After doing some research on my own, these are the four options I came up with for something around 350‚Ç¨. But as I stated before, I don‚Äôt know shit, and there seems to be a lot of discourse about which is the better option, so I hope one of you who‚Äôs more knowledgeable can enlighten me.",
    "comments": [
      "6750xt is the fastest card in non ray tracing workloads, and has a good balance of vram to speed. 4060 is second fastest but suffers from 8gb vram, it will be OK at 1080p wouldnt go 1440p on it though. Some games can really suffer from the 8gb not all though. The 7600xt and 3060 12gb are about the same speed, the 3060 has the benefit of dlss. The 7600xt 16gb seems nice but it's not really fast enough to play games in a scenario where you would need it. \n\nTldr: I would get the 6750xt if you can still find it for a good price.",
      "If you video edit/ professional 3d work etc., 3060 12gb, otherwise if you're just gaming no rt it's the 6750xt",
      "Gaming? Go AMD. If you can swing a 7700XT it would be insanely good. 7600XT is right behind it, so that‚Äôs fine as well. Definitely not Nvidia in this price range.",
      "What resolution?\n\nThis changes things a little but if it were me I'd play @1440p and I'd pick the 6750XT if prices are okay still with low stock. \n\nOtherwise it would be the 7700XT id budget allows, if not a 7600XT",
      "In that forget Nvidia. The 760pxt will play 1080p very well and do ok in 1440p compared to the 6750xt, that does very well 1440p and has great p2p",
      "Picked up the 6750xt during the holidays. With a 7600x3d, it dominates at 1080 ultra on everything. Space Marine was the toughest title so far,  with average FPS in 70, with dips into mid 50's. Tried it at 4k with Space Marine, and managed an average 60 on low and medium settings with quality upscaling. Most other titles are 100+ fps ultra at 1080.\n\nNot telling you to trust my feedback alone, but I debated my options at length during the building process, just check my post history. The 6750 XT smokes the rest of your options if NVIDIA luxuries are not needed. I purchased at $320, and given the market at the time, it was evenly priced with the rest. I don't know how prices have fluctuated, but be aware that the 7700 XT has come down to $350, and if it's within your budget, you should pick that up instead, if the price difference isn't significant.",
      "It‚Äôs mostly for gaming but I‚Äôd also wanna do some video editing and do some hobby 3d work is the 6750xt still the best option?",
      "assuming you don't make money video editing them yeah sure",
      "Nah I don‚Äôt just for personal enjoyment and potentially social media preciate the help tho also the 3060 is like 40‚Ç¨ cheaper at 320 does that change anything",
      "nah it don't. 6750xt can be anywhere from 30% to 100% faster than the 3060",
      "Alright last question before I press order we‚Äôre both talking about the rx 6750 xt mech 2x 12gb (refurbished but don‚Äôt think thats an issue) cause there is also a 6750 trio",
      "generally a 3 fan should always cool better than a 2 fan card but you should only get the trio if it's the same price as the xt mech",
      "Nah the trio is almost twice as expensive unless I buy a second hand one really appreciate the help man"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6650"
    ],
    "title": "went from a 1650 up to a rx 6650 xt",
    "selftext": "",
    "comments": [
      "Apes here don't know how to say CONGRATS ON NEW BUILD.\n\nCongrats bro xD It must be a massive boost. Also Welcome to team red üö©üòÅüö©",
      "I think you are supposed to use the non-split part of the split PCIe",
      "I currently have a GTX 1650 and a Ryzen 5 5600 (non-X). How noticeable is the improvement? I wanna update at some point.",
      "Thnx bro ye AMD is great (drivers work perfectly didnt have any issues)",
      "Your cpu cooler design puzzles me",
      "Oof its a helluva improvement but if you had to upgrade i suggest you get a rx 6700 xt when the prices drop i got mine for a reasonable price brand new so i got that warrantyüòä",
      "Doesn't really matter for a low power card like this as long as your psu isn't a bomb",
      "I think he meant the pcie power cable",
      "Like the part thats hanging now, the one that splits in to the one plugged",
      "No no, he's definitely on to something.",
      "What CPU do you have?",
      "2.5-3x the improvement going from 1650 to 6650 XT.",
      "Currently a ryzen 5 5600g i ripped out of a prebuilt but im getting a ryzen 5 5600 or an 5600x next week",
      "Why? It would not be such a stark improvement. Rather upgrade to something which will show a more meaningful improvement. Or I would rather spend that money on games.",
      "theres something else wrong with ur system linus tech tips did a whole video dedicated to amds \"driver issues\" and its usually something else with your pc thats causing instability and i can tell you i had minimal issues with amds drivers",
      "Perfectly smooth, all the time, on AMD.\n\nYou're confusing ini»õial game launch where the driver creates a cache in DX11 and earlier, that goes away in 5 min, with general stuttering.",
      "no, it is the other way aroud",
      "I'll be going from RX470 4gb to 7900XT 20gb\nSoon",
      "Notice any difference? ;-)",
      "Enjoy the serious jump. And possibility of RT here and there.\n\nAnd use FSR2 and mod in FSR2 wherever possible.\n\nAnd use driver RSR where neither FSR2 options are possible. 77% scale looks as good as native quite often."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6650xt"
    ],
    "title": "PowerColor RX 6650XT Hellhound has 2689 MHz boost clock, features 17.5 Gbps memory - VideoCardz.com",
    "selftext": "",
    "comments": [
      "So with a 4% increase in frequency and a 10% increase in memory bandwidth, what kind of performance increase are we looking at? I have no idea if Navi 23 might benefit from the additional memory bandwidth.",
      "I'm pretty sure all of the lower end rdna 2 gpus had memory bandwidth problems, I mean the 6500xt is in its own league but the 6600 and 6600xt didn't have the most memory bandwidth, so I think this will help it get like 5-15% more performance which isn't a lot, especially considering that rdna3 is going to be launching soon with twice the performance as rdna2",
      "Jesus Christ, why everyone's so toxic? I sometimes forget that you can't comment in some subredits.",
      "I wish, but I think AMD is going to set the MSRP at $379, the original MSRP of the 6600 XT.\n\nPrices have gone down a lot and I don't expect them to use these refreshes to increase prices, but at the same time I don't see them lowering the MSRP yet (cause then the remaining stock of the original models would have to get huge pricecuts.)",
      "For $299?",
      "When you are comparing to card in the same architecture, yeah they actually do. While clock speeds certainly aren't everything and they certainly are usable for comparisons within a lineup, especially when comparing to a card with the same CU count.",
      "Man, it's depressing how much people forget that's exactly how things used to work.\n\nWe're *supposed* to get improvements in performance per dollar as the years go by.",
      "Must be Sapphire fans.",
      "RDNA3 is launching soon, but Navi33 is launching much later, or so are the rumors. These cards will still have a lifetime of almost a year I would assume.",
      "If you really believe AMD actively worked to make RDNA2 \"bad for mining\" then you're delusional.",
      "Other way around. Navi33 is first, Navi31 and 32 later",
      "RX 6500 XT has strange issues even running in PCIe 4.0 mode. An example of this was that in HUB's review the RX 570 4GB outperformed it in Rainbow Six Siege with the HD textures enabled.\n\nPerformance issues caused by textures are typically the result of not having enough VRAM and/or not enough memory bandwidth since as long as you can keep the textures in memory they should be essentially \"free\".",
      "I am just trying to figure out if this is a worthy upgrade from my 1080... alas its not. \nWould like to go for a 3060ti, if I could find one for a decent price. But alas eh no",
      "Why would they drop 80 dollars off the price while improving it?",
      "The 6500 XT had problems when used with PCIe 3.0 (6600 series less so): [https://www.techpowerup.com/review/amd-radeon-rx-6500-xt-pci-express-scaling/29.html](https://www.techpowerup.com/review/amd-radeon-rx-6500-xt-pci-express-scaling/29.html)\n\nBut I don't think memory bandwidth was the problem.",
      "You can't directly compare clock speeds between different architectures.",
      "I get that reference. Good times...",
      "Yeah,I made a mistake there,though the performance tier will probably be much different,and prices probably as well. Otherwise these midrange refreshes won't make sense at all... Guess we'll have to wait and see.",
      "lol, what a nonsense. RDNA2 is terrible for miners in general. RDNA1 is like like twice as fast in mining at the same gaming performance. That's because RDNA2 mostly scales in core frequency which does not scale mining performance at all, more CUs is what would scale mining in the first place and increase memory bandwidth will still be held back by low CU count in mining. I mean RX 5700 XT has around 80% higher hashrate than RX 6600 XT, while latter one has mostly even small lead in gaming performance.. So basically bad mining cards will be slightly less bad at it - that's it.",
      "CashGrab50XT^^TM"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6750",
      "6750"
    ],
    "title": "Sapphire launches Radeon RX 6750 GRE 12GB Black Diamond edition - VideoCardz.com",
    "selftext": "",
    "comments": [
      "Golden rabbit edition Black diamong edition",
      "black diamond edition wowweeee",
      "What year is it again?",
      "Year of the Rabbit, it's in the name",
      "370$ lol",
      "The Golden Rabit Edition Black Diamond Editio. 6750XT what a name",
      "Lacy Black Thong Edition",
      "Well the lunar new year isn't here yet so technically it is still year of rabbit",
      "PC gaming is doomed",
      "350-range is for 4060.so a special edition 6750 is good for special edition collectors. if they wanted to be a good value they wouldn't bother with special cards inomo",
      "id say new pc games are, but there are a million older awesome games that are way better on new hardware",
      "Where can you buy this.",
      "It‚Äôs been doomed for a number of years now.",
      "I still can't find the Aurora version.",
      "So what would you replace \"is\" with?",
      "So what would you replace \"is\" with?",
      "Remember when the HD 7000 series got rebadged as the R9 290, the R9 390? They're not new to this, they're true to this üò≠üò≠",
      "You're thinking of the 280 and the 280X. The 290 and the 390 were Hawaii and Grenada, respectively. Both of those were new evolutionary steps of graphics core next architecture.  The 280 and the 280X were refreshes of the 7970 and the 7950, because they were just too competitive against what Nvidia had put out for the mid-range.",
      "Wat?",
      "Was doomed years ago."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6700xt"
    ],
    "title": "6700XT - I want to confirm high idle consumption does not happen only on dual monitor setups (One monitor, 1080p, 144hz - Freesync disabled vs. enabled)",
    "selftext": "",
    "comments": [
      "First of all using Adrenaline and Afterburner together is a no no no, it can mess up things really bad. Delete Afterburner fast!",
      "I thought the high idle power consumption was an RDNA3 thing, not an RDNA2 thing?",
      "You gotta turn off fast boot. Or at least that's what fixed it for me.",
      "My 6800XT downclocks to \\~50-200Mhz VRAM and idles at 7 watts with triple screens (1x 1440P 144Hz and 2x 1080P 60Hz). So saying the cards without HBM memory can't downclock is clearly false.\n\nIt really seems to depend on the combination of monitors you use, and possibly even if you use Displayport or HDMI, idk. With so many different brands of monitors with different specs it's basically luck of the draw.\n\nThis applies to both AMD and Nvidia. RDNA3 does seem to have extra issues with absurd idle power use but RDNA2 does not, at least nothing worse than Nvidia.",
      "Why I'm saying configurations. It's easy to point fingers, but in the end NV has a similar issue, so even them with their giant reach can't handle all configurations.\n\nI'll just say, that with NV you are less likely to see the issue at least to the same severity, but there is enough evidence to say they aren't immune from it.",
      "I noticed the same thing with my 6800. Free sync was turned off and my vram clock speed was not clocking down so I tried turning on free sync and it fixed the issue.",
      "You have to disable fast boot in bios to solve the performance settings resetting issue.",
      "Yeah, sadly with the growth of higher resolution monitors with higher fresh rates, things had to change. I believe it would affect almost any generation of device, I've read users with Polaris10 having the issues.\n\nYou have to think of it in just a normal concept of \"more power.\" A device out putting 165hz versus one doing 60hz is naturally going to use more power. The level will vary on the hardware in the configuration why it can strike just about anyone if they have hardware that wasn't accounted for.\n\nIt's a nice big can of worms.",
      "Uh no.. FreeSync will clock the same as your framerate, anywhere between 48-144Hz. It only clicks to 60Hz if you're getting 60FPS in which case you're not gonna notice anyway. \n\nYou should always enable it. It's literally called Adaptive Sync, so you do NOT need smooth 144FPS at all. \n\nIt's V-sync that has certain negative effects.",
      "Funny, I get high idle usage on a single 1440p 144hz display if I turn freesync ON. With freesync off the usage is normal.",
      "It's a monitor configuration thing from things I've read.\n\nI've read some users buying a new monitor hit them with the clocks.\n\nIn the end, use some of the solutions and hope you get satisfying results.",
      "Yeah, I'm just saying, I never heard of the high idle usage in RDNA2 before, only started hearing about it with RDNA3.",
      "it's actually since GCN 1.0..",
      "If you're running at 60FPS, you still see 60 new images per second. That your monitor refreshes more often than that doesn't change anything. If anything it can introduce screen tearing. But it doesn't make it smoother.\n\nAlso any half decent, relatively cheap GPU will get you the high framerates you need anyway. It's extremely easy to get 100+ FPS nowadays. A $500 6800XT will serve you well. If that's out of your budget you can try the used market, or the 6700XT, also a GPU that handles 1440P high FPS gaming well. The 6700XT can be found for $200 used.\n\n**You seem to have an old system. What monitor do you have?**",
      "Im seeing people with this isue that i never saw on mine, im using 2 displayes same model and resolution, both on DP.\n\nA note: dont use msi afterburner, it will case some conflits with adrenaline",
      "No issue here 6950 XT on 144hz Benq I get a feeling this is monitor specific and I also use MSI afterburner for OSD and no It does not cause issues. Also OP maybe you should try the latest drivers 23.7.2.",
      "this is amd bug (if you have a monitor non 60hz (75/144 etc))\n\nmemory clock always max\n\n\\--\n\nfix:\n\n[https://www.youtube.com/watch?v=xhWfShsy\\_Bk](https://www.youtube.com/watch?v=xhWfShsy_Bk)\n\nor\n\n[https://www.reddit.com/r/Amd/comments/ex685k/if\\_you\\_have\\_the\\_full\\_memory\\_clock\\_bug\\_heres\\_the/](https://www.reddit.com/r/Amd/comments/ex685k/if_you_have_the_full_memory_clock_bug_heres_the/)\n\nor use 60hz",
      "I only use afterburner for monitoring",
      "Why would you ever turn FreeSync off though.\n\nI have a triple screen setup, 1440P 144Hz and 2x 1080P 60Hz. The two 1080P monitors do not support Freesync, yet my 6800XT idles at 7 watts powering these 3 screens. So idk if it's truly related to FreeSync. I seem to have won the jackpot at 50-200Mhz VRAM clock at 7 watts.\n\nIt seems to be total luck of the draw regarding your monitor combinations, for both Nvidia and AMD. RDNA3 does have extra issues but RDNA2 is the same. Nvidia cards can also experience higher idle power consumption depending on the monitors.",
      "Are you saying that memory clock max is a bug?\n\nAlso those fixes aren't universal. In the OP's case it would be enabling freesync. That's when it idles. I had the opposite experience for example, inhzd to disable freesync on all monitor osd's to make it idle"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6750",
      "6750"
    ],
    "title": "Refurbished Radeon 6750 xt mech 2x 12 gb v1 (359‚Ç¨) vs new gigabyte GeForce 3060 gaming oc 12 gb 2.0 (319‚Ç¨)",
    "selftext": "I wanna use it mostly for gaming and possibly video editing but I‚Äôm really struggling with making a choice cause everyone is saying the 6750 but when I look at the 6750 people are saying the mech 2x is the worst possible model",
    "comments": [
      "I would rather have the 6750.",
      "get it anyways.",
      "Worst possible model but you are getting  40% more performance for 10% more of the price",
      "AMD, I have that exact card it‚Äôs good. Cons of amd is that it has worse rt performance. Other than that I don‚Äôt really use upscalers so idc about dlss but maybe u might",
      "Which country, 7700xt might be similar pricing",
      "The 6750xt is superior to the 3060.",
      "you dont need a crazy cooler for a 6750xt even the lowest end models perform fine. id take that 6750xt for the significantly more powerful raster (closer to a 3070ti than the 3060) you may get better results with video editing but if gaming is your priority a few extra mins editing isnt worth losing 40% performance in games imo.",
      "Get the 3060 for DLSS4.",
      "It‚Äôs MSI‚Äôs lower end sure, but I had a 5700xt mech that still runs like a champ and has had constant abuse since its release. After 4 years of service I repaded and repasted then it went to my a new home.  I‚Äôd argue that anything Asus is inferior. I‚Äôve RMA with ASUS 4x now.",
      "It's a brand new premium model. DLSS performance mode IS faster than 6750 native. I had both card, returned it and got a 5070ti.",
      "The 6750xt is 40% faster, a 3060 on performance mode upscaling isn‚Äôt as fast.\n\nThe 6750xt performs like a 2080ti, 3070 or a 4060ti. \n\nThe 3060 performs like a 1080ti, 2070,  or 5700xt."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6750",
      "6750"
    ],
    "title": "Out with the old and in with the new! [XFX QICK RX 6750 XT ‚Üí SAPPHIRE PULSE RX 9070]",
    "selftext": "",
    "comments": [
      "The GPU got smaller!",
      "Yet quieter and cooler!\n\nVery efficient card.",
      "I can't tell if you're being serious or not üòÇ it's a massive upgrade. \n\nIt's like 80% faster on average and doesn't even compare in RT and FSR 4.",
      "It was from Overclockers UK. The Nitro+ model looks great, it's a beast.\n\n9070 is a best in general! Managed to get it on launch day for ¬£539.",
      "I just ordered my NITRO+ today! The waiting paid off üí™üèº",
      "Oooh! Newegg? I‚Äôd love to get my hands on a Nitro+ ü§§",
      "i do have an question, is all the 9070 non xt come with 3 fans configuration ? i though at least the pulse from sapphire came in two fans....\nMy case is limited to 280mm max...",
      "It does, that's the Sapphire Pulse you're seeing in the third picture, the 3 fan card below it is my old XFX 6750 XT.\n\nThe Sapphire Pulse 9070 280mm long, it's a great card...quiet, cool and efficient. Great for 1440p/4K.",
      "Sweet!\n\nBeen loving this thing, it's made me jump back into gaming again. Wait till you see FSR 4, it's incredible. \n\nAlso idk if you've heard or seen it, but there is a mod called OptiScaler which allows you to inject FSR 4 into games that only support FSR 2/3. \n\nI was playing with it in AW2, check out the difference.\n\n[https://youtu.be/070vbz\\_Eu\\_A](https://youtu.be/070vbz_Eu_A)"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6750",
      "6750"
    ],
    "title": "Help to choose budget GPU RTX 3070 Palit/Gamerock, RX 6750 XT, RTX 4060",
    "selftext": "Hello, please to make a choice with budget GPU.  \nSo far from google i got that 4060 only good in power efficiency, but loses in raw FPS. But i was wandering if 4060 performance is smother in newer games and there is going to be less problems in future.\n\nMby there is some GPU that i should look into it. Going to take they from local \"ebay\".\n\nRight now im on Ryzen 5600, RX 580 PCI 3.0x16. Im going to upgrade motherboard in future, but right now its not much performance lose compare to PCI 4.0. And im sticking with 1080p monitor in a near future. ",
    "comments": [
      "6750 xt because the vram then 3070. I say this as a 3070 user I wish I went for a 3080 because of the vram. 4060 is just shitty like 15% worse than a 3070.",
      "Thank you"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "rx6750"
    ],
    "title": "What GPU to upgrade from RX6750 XT Dual",
    "selftext": "Hey, so i currently have the asus RX6750 XT Dual and I am thinking about upgrading. I am mainly playing CS2 and Overwatch 2 and I would like to also livestream these games. I currently own a 240hz monitor but want to upgrade soon to 360 hz or maybe higher. My Processor is a AMD 7800X3d.\n\nLet me know you recommendations please, I would buy a used one, since I don¬¥t have a unlimited budget",
    "comments": [
      "The RX 6750XT is too close in performance to the RTX 3070 and RTX 3080, because they are within the 20% range above what your RTX 6750XT can do, so, your only choices would be on AMD's side this would be the RX 9070XT only and with Nvidia the RTX 4070ti Super and RTX 4080 are your only options. There is no Intel ARC video cards that can beat the RX 6750XT 12 GB card.\n\nI don't think you have any option really if you want to save money other than to just wait a couple more years and either get used cards mentioned or look to the next generation cards in about two years from both AMD and Nvidia. I don't think Intel has anything that can beat an RTX 3070 yet.\n\nPlease note - If you decide that the RX 7800XT 16 GB is good enough, then on the Woot website the Sapphire RX 7800XT is $599, and on the Newegg website there are more than half a dozen brands that sell the card from 540 to 7730 US dollars.",
      "7800 xt decent jump.. but at right price",
      "thanks for your reply  \ni really hope intel brings out some higher performing cards...  \nI guess ill wait for the upcoming amd cards this year and see how they perform in real scenarios"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6650"
    ],
    "title": "Looking to upgrade from my RX 6650 XT",
    "selftext": "As the title say.  I have an AMD Ryzen 5 5500 as a CPU.\n\nWhat can I get that will allow me to see a nice jump in performance? My budget is arround 500‚Ç¨. Big max at 600.",
    "comments": [
      "Tbh i would use that money to upgrade both ur gpu and cpu. Get a 5600x or a 5600x3d depending on ur budget and maybe the new rtx 5060 ti if y can find it for msrp ( sell ur old components too ) u can probably go higher cuz idk how the prices r looking where u live and ur psu could be an issue too. I‚Äôd rather upgrade everything equally than dump everything in the gpu and have it bottlenecked",
      "Okay, thank you for your input. I will look into it. If I have to change both I might aswell change the whole computer haha",
      "Find at MSRP. ROFL. U mean the MSRP that predates tariffs?",
      "If u see it that way sure, maybe not the answer u were expecting but this is how i see it, u could just get a 5060 ti but im just saying"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "rx6700",
      "rx6700"
    ],
    "title": "The RX6700 is a 1080p/1440p beast and probably the best VFM right now.",
    "selftext": "Hey there. I‚Äôm just making the following post to share my appreciation and to say that I‚Äôm so impressed with the RX 6700. \n\nI‚Äôve been a NVIDIA boy since forever, I only owned a RX580 for a secondary PC but I sold that too. \n\nMy main rig has a RTX3070 Ti. My second rig now uses a RX6700. \n\nI never felt so exciting for purchasing a GPU as I feel about RX6700. I‚Äôve only bought for 350‚Ç¨ plus the 2 games from the AMD promotion which I sold minimising the exposure to 300‚Ç¨. \n\nThe card is amazing, it‚Äôs perfect for 1080p and can rock 1440p as well as I tested them on both monitors.\n\nThe consumption power is nuts! 120W and a temp of just 54oC under stress test with just the default fan curve. VRAM set at 2100 fast timings, min freq at 2500 max at 2600 , rock stable at 1100mV (I‚Äôm just now doing the appropriate tests to lower the Mac), I mean the card is just killing it.\n\nWell done AMD,\nYou‚Äôve earned a huge fan!",
    "comments": [
      "The 6700XT is even more impressive. Especially considering anyone who owned a 5700XT prior and sold it during the crypto boom practically got a free upgrade.... it sips power runs quietly and runs 3440x1440 no worries",
      "Yup, did this. Bought a 5700xt for ‚Ç¨300,- just before the price went mad. A year later I sold it for ‚Ç¨600 and bought a 6700xt for the same money.",
      "I have a 3080 and a 6750 XT (preeetty much a 6700 XT but you have the privilege of paying more) and can vouch for a similar observation. \n\nI lent away my 3080 rig for work purposes and kept the 6750 XT at home. It produces enough FPS for 1440p-gaming in my experience.",
      "On 1440p in Warzone which isn‚Äôt the best game to benchmark (I know) paired an Intel i9 9900K I was at about 130-140FPS average out of the box but using low to medium settings. In PUBG I was running 210+ FPS. I did a 3D Mark test as well but I‚Äôd need to search to find the link.\n\nI never felt so enthusiastic about a GPU purchase. I even convinced my friends to go for a RX6600XT as they want to play in 1080p. And it was hard to do as they were green fan Bois . üòõ",
      "Shit I managed to get a 6700XT for MSRP on launch day and sold my RX 580 for a high enough price that I basically broke even. Those were some crazy times.",
      "Thanks for the post. I am going to grab one for the new year. It looks amazing vfm. It rocks 1400p hard? Glad to hear the temp and power are low. I like low power / temp. It feels like good engineering.",
      "yep the 6700xt and RX6800 are peak units in terms of power/performance ratio, it's legit absurd and rarely seen.",
      "Im still hoping the 7700XT will be equally impressive just with a bit more juice. A 6700XT without the crypto boom selling of a 5700XT isn't a meaningful upgrade for the price for me.",
      "The Callisto Protocol and Dead Island 2. It was Sapphire Pulse. I‚Äôm in Europe too (Greece).",
      "Did you have to do anything special to get fast timing to work? I just get BSODs when i try",
      "In AMD favour games it does better obviously. In Warzone 2 I noticed for reasons unknown that it outperforms the 3070 Ti.",
      "Its slightly better than 6650 XT  \\[like 5 -10% ?\\] and 2 more gb of VRAM, think its a bargain for that price with 2 games for sure. Which games tho ?\n\nAlso what brand ? I have seen some Powercolor Fighter and its the worst model and stuff like MSI Mech also meh, but i guess for that price and not so high watt usage then temps should be fine \\[can always undervolt as well\\] . For that price in Europe you can buy rtx 3050, im really mad at team green in the last couple of years for those prices, dont need DLSS and RT either.",
      "I just got a notification that here in Europe the 6700XT brand new dropped to ‚Ç¨300!\n\nThe used market will go down to ‚Ç¨150-200 tops.\n\nIt's most likely the best value GPU around right now. I paid ‚Ç¨750 for mine lol.. But it's a 1080P monster and still a good medium-high setting GPU for 1440P.\n\nThe 6700XT at this price point is unbeatable, delivering 3070 performance, and if you're willing to buy used (which is perfectly fine if you pick it up in person and get a demo etc) then it is sick value. Used cards often aren't even that old.",
      "Ah, neighbour then - Im from Bulgaria, Sapphire Pulse is way better in my opinion compared to the ones i mentioned - budget models of Msi Mech and Powercolor Fighter.\n\nThose 2 games are not the best \\[Calisto Protocol was hyped \\] but still seems like great value Sapphire Pulse plus 2 games for 350 euro, not sure i can find so amazing deal in my country, may be 350 euro without games and not Sapphire pulse.\n\nRyzen 5600 \\[X\\] and 6600/6600 XT /6650 XT / 6700 seems like great deal lately for mid range PC 1080p/1440p money and performance wise, cheers.\n\nEyeing an upgrade myself soon enough ryzen 2600/rx 570 4gb and would be willing to upgrade to 5600 non X cuz better price here like under 150 euro and one of the mentioned above cards depending on price, Sapphire is my favorite brand for AMD Radeon for sure tho.",
      "I paired with a R5 5600X replacing my 2600 so I‚Äôm overally satisfied with the upgrade on a secondary PC.",
      "Yes its a great value, i was tempted to buy it and call it a day but in the end i ordered the rx 6700xt nitro+ (the non oc model) for 485 ‚Ç¨ in my country.\nI personally thought that if i have to upgrade my gpu (i have right now the rx 580 nitro+) i will buy a nitro+ (i am very pleased my 580 nitro+)again if the price isnt outlandish.\nIn my country the sapphire 6700 cost 390( the pulse edition) so i thought that for 100 more i will buy more performance more vram more features (top end model) and better temperatures .. and it was inside my budget (500‚Ç¨)\nAnd also it would be better combination with my rest of the system r7 5700x 32 gb 3200 cl14 ddr4 , 1440p 180hz monitor.",
      "For 300 bucks ? Gonna grab them in my local european retailer , oh wait, it's 500 euros.. nevermind",
      "No I simply followed a YT video who tuned the 6700 non XT. Set the memory at 2112 and Fast Timing enabled. Though Jayz2cent claimed that in his tests it made no difference at all. (Having it enabled and disabled).",
      "Bought mine last week (6750XT same chip as 6700XT) as christmas present since i had years to upgrade (last GPU upgrade being my r9 290), im pretty satisfied so far, the card is very competitive if you like high refresh rates displays but it can do better if you don't mind RT, i found 4K being plausible with my Freesync monitor.\n\nHere some things i noticed:\n\n1200mv as stock voltage is crazy, this Navi 22 chip can be very efficient, totally waste of power + heat.\n\nOverclocking (uh...) was a very complicated thing at first coming from old gen GPUs had no prior experience how boost + undervolting works so some research had to be done.\n\nMy model is the MSI Gaming X Trio, the cooler is probably overkill but coming from sapphires Vapor-X design i didn't want some generic two fan cooler.\n\nDunno if AMD gave all good Navi 22 chips to 6750XT, i can actually overclock the card to 2950Mhz with 1085mv but the memory is unstable so im running rn 2750min Freq. 2850max same voltage as above but with maxed out memory and fast timings.\n\nAlso, it might sound cringe but i like how this GPU has the same CUs/Cores configuration as my dead R9 290, it's like my old GPU still lives on xD",
      "How does it compare to the RTX 3070 Ti in your main rig?"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6650"
    ],
    "title": "Your experiences with the RX 6650 XT",
    "selftext": "Hello, \n\nI currently have a MSI RX 580 8GB Armor, and I experience a lot of driver crashes (timeouts), especially while booting up games. \n\nI thought of getting a new card, as the RX 580 also isn't up2date any more. \n\nI am kinda fed up the AMD graphic drivers, so I thought of switching to NVIDIA. I thought of an RTX 3060. (My CPU is i5-10400F)\n\nBut now I saw the RX 6650 XT, which even seem to perform a little better than the 3060 and it is cheaper in my country. \n\nBut - Do you guys have any issues driver timeouts related (Using the latest drivers, no overclock, no underclock, no undervolt)? This would be important for me to know.",
    "comments": [
      "The 580 is a rock solid (driver) platform now.\n\nIf you are getting crashes you have actual problems. Driver timeouts can be anything from dying cards to weakening power supply transient spikes, or even bad PCI lanes on mobo.\n\nI would start by checking for GPU sag, maybe repaste the card, swap PCIe slots, and then swapping or borrowing a different PSU.",
      "GPU drivers crashing can be borderline anything, having my ram running with xmp on was crashing my GPU drivers üòÇ",
      "> swapped to an nvidia card, poof, problem‚Äôs gone. \n\nReplacing an old, broken card with a working one is usually a solution to it being broken.",
      "I had a Sapphire RX 6650 XT Nitro+ for about a month, but the fans on it died and I had to return it to the store.\n\nIn return, they sent me an MSI RX 6650 XT Gaming X.\n\nAside from the minor setback of the fans on my Sapphire card, in terms of software, both cards performed well. I used the 22.11.1 and 22.11.2 drivers and had no crash, timeout or anything like that.\n\nSingle monitor, Windows 10.",
      "In which country it's allowed to marry GPU?",
      "Lol @ RTX Remix on a 3060ti. I just bought an NVidia card & listing RTX remix as a plus at the 3060ti level is beyond silly. Dlss advantage is very marginal, *slightly* wider support for now, quality basically the same. At this price point, I'd go for whichever card offered more raster performance for the price. Driver issues are very difficult to quantify either way. The best you can do is look for widely reported issues in games or software that you use a lot; ie that matter to you.",
      ">  nvidia drivers will handle it way better \n\nAs in, they just produce very random errors/corruption instead of actually catching the issue and crashing.\n\nThat is likely better for casual gamers, but *horrible* for professionals.\n\nAs always, stress test and error test your RAM!",
      "Zero issues with the games I play on the RX 580. Could it be a cable problem? Even the ones that come with the monitor can give you trouble (don't know if driver timeouts in particular.)",
      "Murica, baby.",
      "If I were you I'd pay the Nvidia tax... while my switchover to AMD has been pretty trouble free there were issues with the drivers that I had to troubleshoot (drivers > 22.5.1 unstable, display timeouts in Chromium browsers with video playback).\n\nConsidering how long AMD seems to be taking to release stable driver iterations I'd have stayed on Nvidia.\n\nI will say that on 22.5.1 it seems to be rock stable so take that for what its worth.",
      "It matches a 6700XT while being $70 more expensive. At a price of about $410, in the US, that means that it trades blows with a card while being about 18% more expensive.",
      "I recently upgraded my wife from a GTX 1060 3 GB to a 6650XT. As far as I know, she hasn't had any issues.",
      "You just proved it wasn‚Äôt the drivers by switching hardware lol.",
      "Hmm. How beefy is your power supply? Any fluctuations in voltage on the rails when the card is loading textures? (HWMonitor can watch this for you)",
      "I recently upgraded from an RX 580 to an XFX 6650 XT. It‚Äôs been very stable for me. If you‚Äôre thinking about anything raytracing related, forget about it with this card. Even the Unreal 2 demo is flaky with frame rates. I didn‚Äôt care about that, I just wanted to take advantage of my ultrawide 1440 monitor. And for non-RT it does a very good job at that.\n\nWhile newer games will drive temperatures higher than the RX 580, older games tend to run cooler in my experience. Plenty of ventilation in your case is still a good idea. \n\nBe sure to enable SAM on your motherboard, it really makes a difference in performance with the 6650 XT. Especially with preventing stutters and drops. \n\nFSR is pretty neat too, it definitely ups your frame rates for more demanding games. Just understand that thick vegetation and stuff like that can really break the upscaler, so if the graphics start looking chunky, that‚Äôs the first thing to adjust. \n\nHope that helps!",
      "Why would he buy the nvidia card instead of the amd one? The amd one is cheaper, yet surpasses the rtx 3060 ti by a bit.",
      ">Even the choice of cable can cripple a GPU nowadays. (Looking at you DisplayPort Pin20)\n\nOr just power cable splitters..",
      "> I currently have a MSI RX 580 8GB Armor, and I experience a lot of driver crashes (timeouts), especially while booting up games. \n\nThat almost certainly means the card is unstable, due to damage to itself, or other components in your PC failing/being unstable.\n\nDriver timeout just means the driver stopped responding, not that it actually caused that to happen by itself. The card crashing because it, for example, hit a bad voltage dip while the VRMs shift gears during a game launch, can also cause that if it falls short of completely crashing the system.\n\nHave you attempted to underclock the core and especially VRAM? Also, what PSU are you using? Any problems not caused by the GPU itself being bad will continue to haunt a newer GPU, often worse due to the architectures being more sensitive to electrical antics.",
      "Yeah. It has honestly gotten very difficult to troubleshoot nowadays, and it doesn‚Äôt help that seemingly every card is pushed to some voltage or performance limit out of box nowadays. Even the choice of cable can cripple a GPU nowadays. (Looking at you DisplayPort Pin20)",
      "Frankly, the first time you wiped with ddu should have told you it‚Äôs not the problem (weekly wipes would be irrelevant). \n\nBut I sympathize, because it‚Äôs getting nigh impossible in windows to troubleshoot GPU issues without advanced knowledge (finding break points in voltage, memory timings etc). \n\nFor lots of people they never find why a particular card just ram like crap in their rig (and not someone else‚Äôs)."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6650xt"
    ],
    "title": "I7 9700F and RX 6650XT?",
    "selftext": "I7 9700F and RX 6650XT combo? \nAre they still enough?\nBottleneck at 1080P gaming?\nThis Upgrade will be last upgrade of my old setup.",
    "comments": [
      "The 6650 XT is pretty capable at 1080p, on par with the 7600. Not sure about the CPU.",
      "Yeah this should be okay for most games. Obviously both components are aging, the 8GB frame buffer and the 14nm++++++++++++++++++++++\n\nEdit: I salute any budget banger pc like this. So reasonable!"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6650"
    ],
    "title": "Should i get a 6650 xt or a 4060?",
    "selftext": "I'm a newbie to graphics cards :)",
    "comments": [
      "Why not a 6700XT?",
      ">4060 is outdated\n\nWhere the hell do you live? In 2050? Lol people still going strong with a 1080ti these days.",
      "Check your monitor first, then go from there. Black Friday in 6 weeks. Cyber Monday so huge deals",
      "That doesn't make it outdated. There's GPUs from many years ago that still work fine for a lot games. If you can get a good deal on a 4060 then it's probably worth it depending on what you want to do on your PC. Like, I have a 3060, everyone says it's not worth it but it still runs games pretty well at 1080p. Just because it's the low end version of the 40 series, does not mean it's outdated.",
      "4060 is outdated, pick 4070 at least, or simply 6700xt.",
      "outdated, what do you mean? you can still enjoy games using something \"outdated\" like an rx 5700xt",
      "stream, ia , 3d , rt    4060   \npure gaming 6650xt",
      "6700xt",
      "What's your budget?",
      "Look for used 2080ti/6700xt/6750xt/3080/6800xt\n\npreferably locally and tested working in front of you before purchase,  \nif bought through ebay or other test it thoroughly when you get it and Read the description carefully of any card being sold (like if its for parts only/not working) if any issues come up report them with photos and ebay customer service is very good generally.",
      "I have a 4060 and an Rx 6750 xt. They run basically neck and neck. 4060 over a 6650 all day everyday.",
      "That's not really a good comparison. 4060 wins that matchup all day every day.",
      "Same price? 4060, but there's also the 6750XT which is better than the 4060 and only costs like $10-20 more",
      "Never 4060",
      "neither.\n\nget a 3060 12 GB or a 6700 xt.\n\nyou want at least 12 GB vram as 8 GB vram is a major issue in lots of new games.\n\nif all you can afford is an 8 GB vram, then the rx 6600 should be the least shit option, but as you mentioned at least a 4060, the 3060 12 GB is clearly on the table.\n\nthere is also the rx 6800, which if you can get it for 360 us dollars new would be a great deal,\n\nbut if not the 3060 12 GB or 6700 xt would both be vastly better options than the 4060 8 GB insult at least.",
      "Save up that extra couple hundred and buy 4080 super or 7900xtx man, you want it to be future proof( play games years on like butter and without updating ur card)",
      "4060",
      "yeah sad reality, is why used 2080ti is such a hot item rn honestly.  that or like a 6750xt/6700xt\n\n8gb gpu's run into more issues more often now days and when buying a gpu I'd hope user can get at least 3-4 years out of it at best.  6-8gb gpu's will have to be careful with some games and tweak settings to avoid hitching especially as time goes on.",
      "12gb one is ok, but yeah its a bit underpowered for price.",
      "me using gt 1030 4gb rn:"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6750xt"
    ],
    "title": "First time going AMD! Really looking forward to this RX 6750XT",
    "selftext": "Any tips on getting most out of it?",
    "comments": [
      "You know, people do complain about the prices of GPUs nowadays, which is fair enough, but whenever I see a comparison like this it always reminds me that modern cards in general tend to feel way more premium than they used to.\n\n&#x200B;\n\nCongrats on the upgrade! A few things you may want to investigate:\n\n&#x200B;\n\n* Does your system support Smart Access Memory (SAM)? It can produce a small gain in specific titles.\n* What resolution is your display? If it's at least 1440p you may be able to use FSR with little visual degradation (in Quality) to get a bit more juice out of your card (or run it more quietly if you're maxxed out in framerate). This goes double for 4k, where the technology really excels, IMO.\n* I've personally found the open source Linux drivers to be quite stable; not sure if there's an open source Windows equivalent.\n* Have fun!",
      "Each time I see a DirectCUII card it remembers me \"the good ol'days\" I dunnow why but this is so symbolic of an entire era ! This DirectCUII and the MSI TwinFrozr !",
      "Make sure SAM is on, if it's greyed out then you'll need to enable Resizable BAR in your BIOS.\n\nRadeon Software > Performance tab > Tuning > SmartAccess Memory\n\nAlso in this tuning tab you can undervolt your GPU and set a custom fan profile if you'd like. By undervolting you can cut power usage by a decent amount while keeping the same/better performance. This resets every driver update so make sure you export a profile after you're done tuning and reapply it after you update.",
      "Yup, that card quality shift definitely started gaining a lot of momentum with the Nvidia 10 series. \n\nEven backplates were very rare to find on any brand/AIB‚Äôs GPU models. By the time the 30 series/6000 series hit it was the norm for almost every model down the stack. \n\nAIB‚Äôs must have finally realized that people shop with their eyes a lot of the time.",
      "I got the 6750 for Christmas; it replaced my 5700. The 6750 has been outstanding for me... fast, stable, and cool. Great performance to price.\n\nHere are my Radeon settings:  \n\n\nhttps://preview.redd.it/izgji0okbf5b1.png?width=1963&format=png&auto=webp&s=8da76c21379282461e863e1d696391d1f381f8db",
      "> Any tips on getting most out of it? \n\nPlay around with Adrenalin's Performance tab. Enjoy undervolting and playing around checking what you can get from the card's specs/speed/power draw etc.\n\nI recommend trying Radeon Chill. I turned it on once not expecting too much, and it turned out to just seamlessly let me play while eating less power.\n\nAlso, Adrenalin offers customised settings per game. Depending on what you play, you may want to sometimes activate Chill, other times Boost, and so on. Enjoy!",
      "Out of those options, you should definitely be looking at the 6800xt for a reasonable upgrade over a 2080ti.  I upgraded from a GTX 1080 at the start of this year to a 6800xt and I've been thrilled with the performance.  It's over double the performance of my 1080, and more importantly, should perform well for the next few years.  As far as coil whine goes, it's luck of the draw.  All I can tell you is my own experience.\n\nI bought an XFX 6800xt Merc, and I'm running it on an 860w Platinum PSU.  My card had light coil whine, which got drowned out as soon as any fans started to spin up seriously.  Five months later, and all coil whine is either gone, or so slight that I can't hear it.\n\nI would highly value performance over some coil whine, but it obviously bothers some people more than others.  In \"most\" cases, if cards do have coil whine, it tends to eventually shake out and quiet down, assuming there isn't a power issue of some kind.  But, there is no definitive way to make sure you get a card without one.",
      "Seen so many people moving from Nvidia to AMD because of price/performance but in the end... Market share doesn't move a bit. It's tragic",
      "I remember the 8800 GTS very fondly.",
      "One more thing... be sure to turn off Windows' driver updates. For some reason, every once in a while, Windows will take it upon itself to replace the Radeon driver with its own driver, which prevents my games from loading. [Here's](https://pureinfotech.com/disable-automatic-driver-install-windows-11/) how to turn off Windows driver updates.",
      "I used to have a reference 6700xt and Sapphire Nitro 6800xt se. I absolutely loved the cards. Like the previous people before me stated. Manually go download the second latest driver. Use DDU to delete all other drivers on your system. Then install the second latest driver. No beta drivers. Watch for new drivers. Usually I check once a month. Once a new one comes out move up one driver. I think you'll enjoy your new card.\n\n If you do have any issue's. Don't hesitate to reach out to someone either here or AMDs reddit. Free help might not always be the best but there's people here with alot of experience and knowledge. That would be willing to help you resolve the issue\n\nWelcome to team Red.",
      "It‚Äôs not *terrible* advice considering that there was an incident in the past with a rare case of [radeon drivers bricking windows](https://www.neowin.net/amp/amd-confirms-updating-radeon-gpu-drivers-can-brick-your-windows-installation/).\n\nSo if you‚Äôre running completely fine then there‚Äôs no reason not to wait for an update.\n\nAnd FYI, I‚Äôd say the same thing about every single company especially nvidia. They have occasional issues as well.",
      "Watch AncientGameplays. He has videos on AMD settings optimizations, troubleshooting issues and patch rundowns.",
      "People dont believe when I tell them that I never had single problem with the XTX SWFT\n\n6700XT I got . no driver issues whatsoever , runs every game efficiently , stays cold, fans not too loud, no coil whine.. \n\nTell them that they are very good for what they offer !",
      "To some part depending on the Model its also for cooling and making the card more stable cause heat sinks get heavier.",
      "Welcome brother",
      "Stable undervolt for me on the Powercolor Red Devil counterpart is 1130 but obviously test different values out",
      "NGL seeing that 8800 made me all warm and fuzzy inside‚Ä¶\n\nThe 6750 is a great card, just whack SAM on and enjoy!",
      "Nice bro, my last Nvidia card was GTX760 from asus. Nice card, very quiet. After that I've only had AMD cards though, Nvidia is not worth it anymore.",
      "I just got an RX 6700 and it's already so efficient, I can't wait to see what it does when I undervolt it."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6700xt"
    ],
    "title": "Cyberpunk 2077 | FidelityFX Super Resolution on Linux | RX 6700XT | FSR",
    "selftext": "",
    "comments": [
      "It really does look the same to me, I mean...there are probably differences but is very hard to perceive.\n\nThe improvement in FPS though, pretty sweet.",
      "CP2077 is really perfect for FSR - the game is never super sharp to begin with and there is a lot going on.\n\nWould be nice if they implemented FSR in an upcoming patch.",
      "YouTube videos not good to see differences without zooming. But I do appreciate it looks close to the same either way.",
      "Unfortunately, it does not work on Windows as of now, I mean specifically on Cyberpunk. OP did on Linux using some mod...but yes FSR works on a few other games\n\nhttps://www.amd.com/en/technologies/radeon-software-fidelityfx-super-resolution\n\nHere is a link to supported games *on* Windows with official support.\n\nHope it helps! :)",
      "It works on Linux as a form of fake fullscreen window. You know how a sub native resolution window can get stretched to fill your entire screen? Well, you can change a setting so the window is upscaled using FSR instead of the regular Bilinear Filtering, that's how it works.\n\nIt haven't been done yet, but it's possible to do the same on Windows. [This program](https://github.com/Blinue/Magpie) does that with a variety of high quality upscalers but it doesn't has FSR yet. The next version, however, will.",
      "Pretty acceptable quality if you're not zooming or pixel peeping.\n\nhttps://imgsli.com/NjI4Nzk/4/5",
      "I made the video, so I was zooming in and out closely, so I could tell the difference, because I know \"where\" to look. But my girlfriend for example could not tell which one is which, showing her the pictures side by side.",
      "The thing is, your eyes do not zoom in no, but when you actually look at the whole image from a normal viewing distance, all those small pixel peeped details together give a visual downgrade that is  noticeable.\n\nSure, for somebody that just wants to be able to scrape by, that is a sacrifice worth making, but it is not close to native or no difference. And that is at 4K, at lower resolutions it is really obvious. \n\nI was perfectly fine playing games using gpu scaling and a reshade sharpening filter on my shitty laptop, \n\nFSR is a tiny bit better then that, Nvidia's new \"Sharpening +\" or AMD's CAS will give similar results with other simple upscaling methods.\n\nHowever it is easier for people to just toggle an option in the game menu, but for anyone who has been doing upscaling + sharpening before I just don't see where the hype is coming from. \n\nI do however feel that AMD needs to provide some other upscaling solution using similar tech to Nvidia's DLSS or some form of temporal solution, their GPU's are similarly priced and don't provide a real answer to that, FSR is  not enough to compete.\n\nIt is a good thing to offer something to people that don't have any upscaling solution or don't know how to get a decent image using regular upscaling techniques. \n\nBut let it be an extra, not an alternative to a far superior tech.\n\nI am looking to buy a product that offers me as much as possible for similar prices and AMD has not convinced me with this, I don't care about the company that makes it, but I do want to buy a product and not feel like I am missing out on something.",
      "Does it work on Windows too? Would love to test this with my 6900XT.",
      "\"DLSS will never be mainstream as long as only RTX cards can use it\" Lets see, COD? DLSS, Warzone? DLSS, Fortnite? DLSS, Battlefield? DLSS, Cyberpunk & the Witcher 3 remaster? DLSS, DOOM? DLSS, Watch Dogs? DLSS, Minecraft? DLSS, Metro? DLSS, Mount & Blade? DLSS, Read Dead Redemption? DLSS, Tomb Raider? DLSS, Wolfenstein? DLSS, Rust? DLSS, Final Fantasy? DLSS\n\nAvailable in UE4 & Unity with no work. Id say its already mainstream? Assassin's Creed Valhalla is about the only triple-A game I can find at short notice that doesn't have it.\n\nPeople have been saying it wasn't in many games for a long time, but guess what, we only get a few big game releases a year! It's been in the majority of releases for some time now. In fact, its got to the point where its more likely to be in the game than not.\n\nOn the flip side, AMD FSR is literally just a lanczos upscale with sharpening, you're welcome to check that in the source. Which is why below 4k it performs very poorly. In fact if you compile the dev version of [Magpie](https://github.com/Blinue/Magpie) you can try it and upscale any game you like! Just set to windowed borderless and choose a lower resolution and it will upscale the image using FSR.\n\nThat said, its not exactly all that much better than existing upscaling. I played with it myself but for example in Fortnite it didn't really provide much of an increase in quality over the traditional upscaler.\n\nThreatened? No, wanting to comment when people have massive double standards? Yes.\n\nFSR has its uses, but comparing to DLSS is just not something its in a position to do.",
      "DLSS Almost indistinguishable in blind tests with minimal ghosting in edge cases- 'Complete garbage, looks terrible \\*downvote & harass\\*'\n\nFSR Significantly worse image quality, blurred but overall pleasing image - 'No pixel peeping boys! Wow so good! Just don't zoom in or analyse, most people can't tell the difference! A\\*'\n\nThe sub of double standards.",
      "About the same as DLSS performance mode going by the amount of blurring going on over the whole image, especially the sidewalk, but its very very noticeable. The end result is still usable though. That said, this sub has spent months trying to destroy DLSS even when results were far better than this, so to hold this to the same standards would mean its terrible.\n\nThat said, it does look comparable to DLSS performance mode, which is far faster.",
      "there's a very clear loss of detail without zooming or pixel peeping. I had to look closer, but I can definitely tell the difference.\n\nI made sure to not look at which was FSR/Native when I opened the link and I guessed the one that's native.\n\nLook at the mini map, there's lines missing in the FSR side, that's an easy example to compare.\n\nEdit: look towards the white light, and the black stuff has clear detail loss. You have to look at static sections of the scene. Since the comparison shot isn't the same image, you have to do that.",
      ">A little oversharpened to my eyes\n\nCheck again, the oversharpened is the native one. We got baited since the positions are switched compared to video, FSR is on the left while Native is on the right.",
      "Yeah it‚Äôs hard to spot differences in a 4k image with 1080p video on my phone‚Ä¶",
      "Better than the comparison image posted here by my reckoning! The base game has ghosting in it to quite a degree because it uses TAA, which is still there with FSR, FSR just runs on top of it.\n\nThat said, using the newer DLSS 2.2 dll file give better results. For the most part though, even gamers nexus hailed it as extremely impressive, and the LTT DLSS blind comparison video showed that most people can't tell the difference either.\n\nLegitimately the ultra quality pre-set looks similar to the DLSS performance pre-set in many cases, especially at 1440p where FSR does far worse.\n\nI'll just have to disagree with you, coming from someone who has a 3060Ti and a 6800XT, of which the 6800XT is sat in its box not being used.",
      "I meant with the open source driver (Radv). Last time I checked CP2077 froze after the menu with the pro driver.",
      "https://github.com/andrewcs0901/Magpie/releases/tag/v0.5.1",
      "Right you are, my bad. Just goes to show how close they are if it comes down to personal preference.",
      "Calm your tits my dude, I actually quite like FSR and am not looking to trash it. One of the images looks overly sharp to my eyes, just turns out it's not the one I expected.\n\nHaving said that, I've played Cyberpunk on a 4K TV from a distance, thought it looked great, and then played it much closer on a UWQHD display and thought it looked crap. The game natively has this amazing ability to look fuzzy in some places (NPC character models seems to suffer with this) whilst overly sharp in others (like ground textures, for some reason)."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6700xt"
    ],
    "title": "Here's something you don't see every day: PyTorch running on top of ROCm on a 6800M (6700XT) laptop! Took a ton of minor config tweaks and a few patches but it actually functionally works. HUGE!",
    "selftext": "",
    "comments": [
      "Linux: the hobby of getting your platform to the starting line.",
      "Pytorch runs flawlessly on Nvidia cards. A single command to download and install, and you're done. The current situation for compute on AMD cards is all due to AMD, not Linux or pytorch.",
      "That's a lot of work to flex that you use Arch.   \n\n\nBut serously good job getting it working.",
      "I previously tried running Microsoft's DirectML version of tensorflow, but it was slow and only used Tensorflow 1.15.  I'd previously tried and failed to get pytorch to work with ROCm.  But today I thoroughly went through the steps and got it working.  Note that in the picture the speed varies a lot.  This is because it is still building up a good cache of optimized kernels.  Once that cache is built it should be very fast.  If anyone has questions, ask away!",
      "AMD always eventually gets their act together, but it's usually sadly a few years too late.  I'm just glad I'm able to get this working before my GPU is totally out of date!",
      "Now you only need to write a nice blog post or gist with details on how you made it work ;)",
      "It's totally AMD's fault actually.",
      "AMD has been dragging their feet with ROCm support for both RDNA and RDNA2.  It does not inspire confidence or development work when AMD's CUDA equivalent still does not run on two year old hardware, and is only barely starting to work for the current gen.  From what I've seen, PyTorch has actually been doing a rather good job of supporting both APIs.  The reason the patch was necessary is all the old ROCm cards had a warp size of 64, whereas these new ones are more like NVIDIA cards with 32.  Overall it's very new and untested.",
      "Yessir",
      "This is actually a case where Windows is behind. You want to do DNNs, you go to Linux (and NVIDIA).\n\nEdit:\n\nBy the way, that is not to say that Linux isn't still a shitty experience. We have a DGX Station A100 at work, and the NVIDIA people came around to install it and explain how to work with it. While at it they explained how to update the OS version and firmware, managed to bork it while upgrading it and spent a couple of hours restoring it.\n\nI personally never had a Linux experience that was fire and forget, except running live CDs or anything else prepackaged that doesn't need any installation or updates.\n\nStill, that doesn't invalidate what I said before. Some things just don't have a good Windows infrastructure. That DGX Station runs only Linux, nothing else.",
      "I was referring to the Linux ecosystem. The fact that many companies don‚Äôt put the effort in isn‚Äôt the Linux OS‚Äôs fault, but it‚Äôs part of the reality of embracing the ecosystem.",
      "ROCm recently added support for gfx1030 (6800XT).  I've seen reports of it working in Tensorflow, but not PyTorch.  My GPU always spouted a hipErrorNoBinaryForAllGPUs regardless, as it is a 6700XT/6800M/gfx1031.  What I had to do was manually edit the CMakeLists.txt file in each component of ROCm to only say \"gfx1030\" instead of all of the other ones, as well as replacing the name in the ifdef sections.  However, pytorch would still not work..  I found a pull request titled \"[ROCM] query warp size for host code, do not use C10_WARP_SIZE¬†#67294\" and decided to try it out.  Sure enough, it worked perfectly!",
      "Have you documented the tweaks and configs you had to set? If so please share with the community.",
      "Just install ubuntu if you don't want to tweak a few things. Or even mint, it's even easier.",
      "Well done. Pity it still takes an effort, but it's certainly better than not working at all. Hopefully AMD will get to the point where no work is needed.",
      "I feel like I'm the only person in the world who hasn't had problems with Nvidia drivers. On Ubuntu I just go into the Software Updater and tell it to use the proprietary Nvidia drivers and they just work.",
      ">Pytorch runs flawlessly on Nvidia cards. A single command to download and install, and you're done.\n\nNow if only drivers worked this easily for Nvidia as well.",
      "Personally I had a lot of problem with my nvidia drivers. I have to disable browser hardware acceleration, and APST on my nvme drive because Nvidia drivers doesn't work well with them.",
      "I don't really know how difficult this will be to do. Could you explain in more detail the directions you followed, what configs were tweaked and why, what patches were applied and why . Could you clarify which AMD gpus this is applicable to. Like is it only necessary to do this particular setup for RX6000 series GPUs but not for other AMD GPUs.",
      "Why is it so much trouble to get it working on AMD GPUs in the first place? Do the PyTorch developers just not support it that well?"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6650"
    ],
    "title": "[Tom's Hardware] AMD RX 7600 Could Cost More Than the RX 6650 XT",
    "selftext": "",
    "comments": [
      "Can I politely ask all these rumours to shut up?\n\nIt's getting announced at Computex. That's in one week or so.\n\nIf they're right, AMD can shove it. If not, stop baiting and wait and see.",
      "Yeah, they're intolerable. If you're also into football (the European one), then every other year you get a confluence of PC hardware rumours and transfer rumours. Kills the internet dead.",
      "For sure, saying \"the new version is more expensive than the current market value of the old one\" is a given. That's literally how retail works.",
      "Rumorers never shut up. \"Hey did you guys know the 4070 TI is a rebadged 4080 12...\"\n\n\"YES, WE KNOW. YOU TOLD US 20 TIMES\"",
      "It's going to be interesting to see how the RT performance of the 7000 drops off below the 7900 cards. It's possible that they'll offer a meaningful improvement on the 6000 the whole way down the stack. Otherwise, it's hard to see why someone wouldn't just get a 6700XT",
      "A $300 price for the 7600 also bumps it up against the 6700 XT and one can be found on Newegg for $320 as I type.  How will its performance compare to the 6700 XT?  What happens if 6700 XT's drop further in price?",
      "> A pair of listings on PC-Canada has revealed the price of AMD's upcoming RX 7600 in Canada. One of the listings features a Sapphire Pulse RX 7600 for $451.99 CAD, and the other is $443.99 CAD for an MSI RX 7600 Mech 2x Classic. After converting to USD and factoring in any potential \"early adopter tax,\" we end up with approximate prices of around $299 USD. That's technically less than the launch price of AMD's RX 6600, and well below the RX 6650 XT's $399 MSRP, though these days the various RX 66xx-class GPUs tend to sell far below their launch prices.",
      "> And that \"companies are not your friends\"\n\nThat's because yeah, companies are not your friends.",
      "Swear to Christ people are angrier at AMD for not selling a GPU for the price of a McChicken than they are at Nvidia for raising prices.\n\nThis card is cheaper than its predecessor, last gen GPU's have been marked down to even cheaper than that within the past few weeks, this cards main competition is pathetic (4050 6GB of RAM), and people still find some reason to bitch and want the price to be lower.",
      "If only social media extended that same courtesy to Nvidia.\n\nOver the last few months we had some really cool rumors taken at face value, examples:\n\nWhen someone said that RTX 4070ti would launch at $1000 MSRP (increased from $900 after rebadging the 4080 12GB). Ended up being completely false.\n\nWhen someone said that 4070 was $750 ($50 below the $800 MSRP of 4070ti). Ended up being completely false.\n\nYou can still find thousands of angry comments in Reddit threads discussing these rumors.",
      "A real informative headline would have simply said \"RX 7600 expected to cost $299\". The article would have discussed the source of the price speculation and the reasoning, and compared it to MSRPs and current street prices.\n\nWhich is largely what the article did, it just framed it in \"this chip doesn't seem worth the price\", which is just another bunch of speculations thrown over the price ones.",
      "Thanks for sharing that. It had big \"The Onion\" energy, and it actually surprises me how keenly they skewered the tactic by showing an example of it right in the article.\n\nThat said, I don't understand people who hate click on things. If I see clickbait, I move along. And if it's in a feed I have control over, I permanently block the source the first time and make sure only to read from places that don't use clickbait titles.\n\nI honestly think that eventually, people catch on and that clickbait's a short term strategy that fails in the long run however.",
      "There has been a general meme trend that AMD is out to gouge consumers by raising their hardware costs, and I fully expect more articles to lean into that overly cynical mindspace\n\nOften when people on the r/amd reddit talk about it, that I have seen, it seems to come out~\n\n that they also expect AMD is currently, or would have, taken all of the anti-competitive actions against their competitors, like that Nvidia and Intel have done time and again.\n\nAnd that \"companies are not your friends\" to the extent that historical pro-consumer actions on AMDs part should be ignored, cause reasons\n\nAnd they get mashed together in various ways to claim that AMD is screwing us, or has been, or would have been if only they could have been\n\nReally, it is just confusing.",
      "Yes and no? If you bench 6950 XT vs 7900 XT in 1440p and 4K, the difference in raster between them is significantly smaller than the difference in RT. Like say if performance difference in raster is 20% in a completely GPU bound scenario, RT will be 40-60%.",
      "leaked out of his ass",
      "[Stop following lying sacks of @!#$ such as \"Moore's Law is Dead\" and stop giving them the time of day.](https://www.reddit.com/r/GamingLeaksAndRumours/comments/pke49l/new_xbox_series_s_model_with_new_6nm_amd_apu/hc30xsk/?context=3)",
      "Seeing that this GPU is essentially the same as a 6650XT, except with dual issue SIMD, thats pretty sad.",
      "Wow, so a newer and faster card is more expensive than the *current market value* of the last gen card?\n\nI'm shocked, utterly shocked. Wait until they find about clearance TV pricing...",
      "Well, in the pre-crypto days. As launch of new GPUs whose performance overlapped with the previous gen approached, the previous gen would drop in price. When the new gen came out the new generation would cost a touch more for the same performance. Typically, they would have lower power and new features to justify costing a bit more. So, a 7600 at $300 probably performs a little bit worse than a 6700XT at raster, and at least about the same ray tracing.\n\nIf that plays out, we should be dealing with a bunch of posts along the lines of \"should I buy a 6700XT for $x or a 7600 $y?\" And, there will be no right answer.",
      "That's twice the cost of this class of card, and it would likely require a larger PSU for many people considering this card and most of them probably don't even have 4k monitors.  \n\nThis card is for people building a whole computer for $650, not just graphics card."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6750",
      "6750"
    ],
    "title": "Sapphire launches Radeon RX 6750 GRE 10GB Starry Sky graphics card - VideoCardz.com",
    "selftext": "",
    "comments": [
      "Cut down crappy cards for the Chinese market. \n\nWe won't see these, nor should we want these.",
      "> nor should we want these          \n\nAll depending on price/power usage/size",
      "I mean, it's the same thing as a RX 6700 10GB which has been available for a long time now.",
      "Because they know that it will sell better that way. If they make it seem \"new\" people will go and enquire about it. It's probably that simple. [This is not the first time AMD has done this sort of thing, I remember the RX 590 GME, which is just a rebranded RX 580, not even a clock bump over the 580 like the real 590 was because the 590 was the 580 moved to a smaller node. This is just a straight up rebrand like the 6750 GRE is.](https://videocardz.com/newz/amd-radeon-rx-590-gme-features-polaris-20-xtx)",
      "Radeon RX 6750 Golden Rabbit Edition Starry Sky Graphics Card? \n\nWho the fuck names this shit?",
      "100%, if the price is right it could be a good budget pick for some people, although I doubt the price will be right.",
      "I agree it's stupid to rename it.",
      "These could be great for like $250-$260",
      "It's jyst a 6700 with an \"upscaled\" name üëé.",
      "A 6800 GRE would be more interesting by far.",
      "Even if they decided to sell them outside of China, they'd be way too expensive for what they are.\n\n\"At the current exchange rate, that's approximately $330\"",
      "I kind of love the design of the grey one. It's always nice to see some experimentation that isn't the standard black/white affair.\n\nI hope they use this same design ID with the RX 8000 series. It'd look even cooler with some premium materials.",
      "GRE made more sense last year. This year is Dragon year.\n\nThis card makes no sense. 7700XT is not that fast so shouldnt have issues with sanctions. Sell 7700XT instead of outdated 6750.",
      "Boo, another refresh",
      "It‚Äôs for the Chinese market.",
      "Why chinese market gets those cut down versions? Why not just sell standard cards like in EU or US",
      "they are more cost sensitive and big enough of a market to warrant a version tuned to their needs.",
      "I want that if its only $180",
      "Well supposedly its more power efficient but nobody wanted to buy one off Amazon to prove it :(",
      "Hey OP ‚Äî Your post has been removed for not being in compliance with Rule 8. \n\nBe civil and follow Reddit's sitewide rules, this means no insults, personal attacks, slurs, brigading or any other rude or condescending behaviour towards other users.\n\nPlease read the [rules](https://www.reddit.com/r/Amd/about/rules/) or message the mods for any further clarification."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6700xt"
    ],
    "title": "5800X / 6700XT PowerColor, in all its glory",
    "selftext": "",
    "comments": [
      "If your graphics card glows this kind of orange you really need to improve the cooling.\n\n(Yes, I know, just couldn't resist)",
      "The CPU cooler is a Dark Rock Pro 4 (BK022)\n\nThe memory is [G.SKILL Trident Z Neo Series 32GB DDR4 3600 14-15-15-35](https://www.newegg.com/g-skill-32gb-288-pin-ddr4-sdram/p/N82E16820374093?Item=N82E16820374093) (Got it on Black Friday for $239.99)\n\nThe PSU is a Seasonic PRIME 850W\n\nThe CPU I got lucky and picked it up for $299 at Microcenter, which triggered the rest of the build (of course)\n\nSome benchmarks here if anyone is interested: \n\nhttps://imgur.com/a/9GmwwNH\n\n[Geekbench 5 (Linux)](https://browser.geekbench.com/v5/cpu/11490863)\n\n[Geekbench 5 (Windows)](https://browser.geekbench.com/v5/cpu/11491585)",
      "Damn, your build is nearly a dead ringer for mine. 6700xt Red Devil, 5600g, 32GB Trident Z RGB 3600MT.\n\nMy Red Devil has no problem hitting 2800MHz all day long at 57c/81c hot spot, fantastic card. Not going to OC the memory because apparently there's no VRAM temp sensor?",
      "Nice, only missing the pc case üòÖ",
      "I got it at the Microcenter in Tustin, CA. Paid $899 for it, was orig $999 with $100 marked off. Picked it up about a week ago.\n\nI have a RX 480 also myself, and I picked up a 1440p, so I'm leaving the 1080p on the old machine, and using my new GPU with the 1440p. Really enjoying it. It's a nice change.",
      "Man I want that 6700 red devil.\n\nI just settled for a jigabyte 6600",
      "I definitely understand. I paid $899 at Microcenter for the card. Obviously a lot, but I mean the options are limited. At least I didn't reward a scalper. That I refuse. But I knew I wanted this particular card, given its looks and how well it cools. Got really great reviews.",
      "Both my 6700xts that ive owned (msi gaming x, gigabyte gaming oc) have vram temp sensors. (Hwinfo64) My msi 6700xt (the one I kept) is waterblocked right now and vram temp doesnt go above 52c. Heatsink had the vram temp junction at 78c with max oc. \n\nYou got a great 6700xt if it can hit 2800mhz, my waterblocked one can't sustain 2700mhz in game or its unstable",
      "Shit man I was JUST mc a few hours ago. It was 999.99 I want it, but not for a g note",
      "Hundred bucks is a hundred bucks",
      "You got 3 fans on Dark Rock Pro 4? Damn man. I'm using mine on a 5600X with a single fan on front.",
      "All the case anyone need. Nice build.",
      "Sweet build.\n\nDoes the X570S have dual bios? I'm guessing not based on the docs, but wanted to hear from a board owner.",
      "Hello dad. I have r5 3600 + devil 5700xt. I hope to be big and strong like you one day",
      "finally someone else posting a pre built test pic.\n\nFor alot of you out there, first timers and not first timers.\n\nDoing this helps finding problems easier and tests make sure shit works.\n\nnicely done OP",
      "No case gang",
      "Now that's a red hot machine.ü§ò",
      "Love that red afterglow!",
      "I have a 3060ti but i really want a 3070 or better\nI love the 6700xt but I‚Äôm not positive it is a big enough upgrade for me\nBut damn the red devils look sexy af",
      "I have the same exact card. Managed to get it for msrp! \n\nGreat card for 1440p gaming!"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6700xt",
      "6750xt"
    ],
    "title": "For 6700xt and 6750xt owners, what model did you buy, why, and how has it been treating you?",
    "selftext": "I'm wondering what models people are satisfied with and why. I would appreciate it if some of you could share your experience with temps, noise, and any issues you've had.",
    "comments": [
      "I have what is probably the cheapest model or one of the cheapest ones in the XFX 6700XT Speedster SWFT309. \n\nIt does the job just fine. The default fan curve on it is maybe a bit too conservative letting the GPU junction temp go up to 95-100¬∞C while trying to stay quite and while thats still comfortably below the 110¬∞C limit raising the fan curve just 10% lowers the temperatures into the mid to low 80 or even high 70's.\n\nRealisticy i wouldn't recomend this model purely because there days models like the Sapphire Pulse, XFX Merc or Powercolor models hover around a comparable price. I pretty much just bought it because it was cheapest by quite a mile on Black Friday due to a deal.",
      "My mate got an msi 6750 xt and it's been very good for him, relatively cool and runs games just fine at 1440p",
      "Initially bought an Asus Rog Strix 6750XT but returned it due to insane coil whine. Picked up a Red Devil 6700XT the following week and although the whine is still there, it's nowhere near as bad as the Asus. Hoping a few weeks/months break-in will get rid of the whine completely.\n\nRunning a small undervolt/underclock and perfectly happy with it.",
      "6700xt, bought the cheapest one 2 months ago, powercolor fighter.1440p and games I play flies.Noise wise is fine as long one dont push it.3 fan models are recommended for those noise sensitive ones.\n\nHappy with it as it replaced my old trusty Vega56",
      "Sapphire Pulse RX 6700 XT running spiderman 70-75celcius average 90 fps can reach above 144 there more but i'll can't recall the stats",
      "Sapphire Nitro+ 6700xt. Runs Calisto Protocol at \\~90fps on 1080p ultra, 135-165 on high. Mostly 60fps(capped at 60) on a heavily modded skyrim. All the rest of my games run at 120-165. whatever i've got my monitor set to or higher if i'm not frame capping. 35-45C main, 40-65C hotspot. It stays cool even at a 2740 clock. Note i cap my frames to 60-165 depending on what I'm playing. No sense in making it work harder than necessary.",
      "xfx 6700XT merc  \n\n\nAmazingly, nice temps, cant hear the thing full fanload. No whine. ¬£300.. can't moan at all.",
      "I bought the red devil 6750xt and it‚Äôs great. Runs silent and crushes all my games that I was struggling with before.",
      "1080p",
      "For anyone getting crazy hotspot temps with the 6700's, I've got the cheapass Sapphire 10gb one and I flipped the whole PC upside down and now the hotspot temp never gets above 90. I think it's something to do with the vacuum chamber in the cooler not having enough water in it.",
      "I got the MSI RX 6700 XT MECH 2X OC 12G. I've had it for almost a year now and I can't say I've had any issues. I got it because it was the first time I saw this tier of GPU under $400 that I was able get at my local microcenter for $350. I figured that MSI would be a reputable brand and most variants perform within 1-2% of each other generally. Definitely an upgrade over my previous GTX 1070 and lets me utilize my 1440p monitor. I think the thing I like the most besides the performance increase of the upgrade is the Software. I had no problems with my 1070 but it felt like a chore every time i had to open up GeForce or control panel compared to opening up Adrenaline which feels more intuitive and user friendly. The price and performance of Intel Arc does interest me but I hear that some older games dont work well and the software still needs development.",
      "Is this at 1440p?",
      "Got the same card. Limited it around 1500 rpm which makes it quieter but you can still hear it. (Thing ships with 100% fanspeed for like 65 degrees? Wtf?)\nTemps tough are quite good.(even with tamed fans)\n\nSadly mine got coil whine but i almost always wear my headset while playing, so its not the end of the world.\n\nPlaying at 1080p 144hz and recently upgraded my rx 5700 non xt to  a 6700xt and my 3600 to 5700x.",
      "Cool beans.",
      "A lot of times corruption comes from memory errors. You could run it at stock settings and see if it still happens.",
      "Thanks. I have installed latest adrenalin driver and turned off GFXOFF using MPT. I haven't noticed any problems yet while using my pc with low gpu usage (its been around 3 hours now). Hopefully its fixed now.",
      "I have mine fot around a month now and im quite happy with it (still the coil whine is a bit annoying)",
      "3700x and 5700x its been fine so far",
      "Power Color Red devil 6700xt, performs very well, and had no problems at all..\n\nNoise is almost silent because i undervolted it..  1105mv with 2600 gpu and 2100 mem? i can't remember.. temps are around 60/65 when i play games.",
      "I just bought a sapphire pulse rx 6700 xt. Playing with D2R 1440p maxed settings about 90-110 fps and 65-70C gpu and 90-100C hot spot temps, depends on the area. Everything fine so far. Stock settings for the card. One more thing its very silent cant hear in closed case and zero coil whine. So its a very good card i think."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6750xt"
    ],
    "title": "Xfx speedster qick 6750xt vs powercolor fighter 6750xt",
    "selftext": "Wanted some help deciding between these two cards. I mainly play city builders/strategy games (really looking forward to civ7). From what I can tell these cards are essentially identical. The only thing I notice is the warranty for xfx is 3 years vs 2 for powercolor. I have no prior experience with either manufacture. For reference in trying to spend around $350 on the card and pairing it with a 7600x, mobo undecided yet, 1080p for now but will eventually upgrade that. Thanks in advance! ",
    "comments": [
      "Prices have gone up the last couple months sadly. I picked up my 7700XT for $350 during the summer. The 6800XT was around there too. Currently though, the 6750XT is solid for that price. A used RTX 3070 would be a good choice as well, just keep in mind it's only 8gb. If you plan on going 1440p in the future, i would skip a 3070",
      "If your case can fit it, get the XFX. It's not even a comparison. Better support, better reputation, and better cooling. I have an XFX speedster 7700XT, and it is a REALLY good card. Under full load, the core never goes past 55c. Memory and hotspot sits closer to 70c. It can get loud under full load, but a 2 fan card would be even louder.",
      "ja i saw a response above said choosing a short card\n\na three-fans one might overlength",
      "Might as well get the Gigabyte Gaming OC 7700XT for $400. \n\nThe Qick 6750XT is $360. I'd pay the extra $40 for a significant performance jump.\n\nAs for the motherboard, considering you have the Fractal North and you don't wish to install a micro ATX board, go for the MSI B650 Gaming Plus Wifi for $170.\n\nHowever if we're talking most value for money, that would be the AsRock B650M PG Lightning Wifi (micro-Atx) for $120. It's good enough for a 9800x3d.\n\nPrices seem to be high across the board and many items are out of stock - so these are the decent options I could find.\n\nhttps://pcpartpicker.com/list/JDxq6D",
      "I just got the xfx one  been playing mainly CS2 and it stays nice and cool and works really well",
      "I believe it can. I have a fractal design north so without a front radiator it should be good to about 350mm. \n\nDo you have any other recommendations in that price range or are those my best options for what I'm trying to do?",
      "I actually wanted that board but the prices and availability are horrible right now. I was seriously contemplating the microcenter deal with the 7600x, gigabyte b650 auros, and 32 gb of g skill ram for like $450. I already have the case and a PSU.",
      "Any cheaper bundles?\n\nHow much is the 7600x3d bundle?",
      "Thanks for the info!",
      "Sorry I misspoke. They have 7700x (not 7600x) with either the gigabyte gaming x ax b650 ($400) or gigabyte auros elite ax ice b650 ($440). Both come with the same gskill ram. They don't officially list the 7600x3d bundle anymore since it's out of stock but i believe it was around $450\n\nCheaper they have the 7600x or 9600x with asus b650-a prime ax 2 for $300 and $330 respectively. Or you can upgrade and get it with asus b650m tuf gaming for $340 and $370.",
      "The asus prime is a mediocre motherboard, I'd recommend going for the 7600x + B650M Tuf Wifi bundle for $340. I'm hoping the RAM is 6000Mhz and not 5600Mhz.\n\n[https://pcpartpicker.com/list/qnKpHW](https://pcpartpicker.com/list/qnKpHW) \\- Similar equivalents are $400 if bought seperately.\n\nIt's not worth paying extra for the 9600x. Spend the $30 on a decent air cooler like the Peerless Assasin or the ID Cooling A620.\n\nThe Gigabyte Gaming X AX is one of the better boards out there and going for a more premium board is not worth it. If you want an ATX board, the 7700X bundle for $400 is pretty decent.\n\nThe $70-$100 price difference between the 7600x and 7700x bundles are significant enough to jump to a higher tier GPU. For example you can get a 7800XT for $480 instead of a 7700XT ($400)."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6750",
      "6750"
    ],
    "title": "AMD's upcoming Radeon RX 6750 GRE reportedly just 'an overclocked RX 6700 10GB' - VideoCardz.com",
    "selftext": "",
    "comments": [
      "Called it. We knew cut-down Navi22 was mainly used for mining.\nDumping the leftover chips to the Chinese market makes the most sense.",
      "no gpus were sitting on the shelf in 2020 trust me",
      "Did anyone ever expect otherwise?",
      "I'm not sure what you expected. It's literally in the same \"6750\".",
      "What psu does he have, might be possible with a high quality psu but don't really think those exist at 450w, a 6700 is already cutting it close for a stable experience and a 6700xt uses 60w more",
      "Golden Rabbit Edition, in reference to the Chinese lunar year. In relation to the 6750 GRE and 7900 GRE, both utilize cut-down variants of their bigger siblings‚Äô GPU cores.",
      "It will be GREat company to the other GPUs sitting on shelves since 2020.",
      "That's true, but if Windows and / or Radeon Software has an error, there's a chance that everything including the power settings will be set to default, which could strain the power supply if the user doesn't remember to set that power limit again.",
      "I'd say go with a 6600 or a 6600 XT, power supplies degrade with time, and it's nice to have some extra headroom for safety reasons.",
      "Makes sense...dump em off in a value market in China for a small to moderate profit or sell them over the rest of the world for a slim profit or loss. This isnt relevant news for most of us so Im not understanding the unrelated comments here when this has nothing to do with most local markets.",
      "I would definitely go for the 6700 XT, then test it; it may doesn't need any undervolt either, but in the long run he should upgrade the PSU anyway (when he have the spare money).\n\nhttps://www.guru3d.com/articles-pages/amd-ryzen-5-5600-review,6.html\n\nhttps://www.guru3d.com/articles_pages/amd_radeon_rx_6700_xt_(reference)_review,5.html\n\nIt worth mentioning that some non-reference card could go a bit higher than that 240W max",
      "Re-brandeon moment",
      "I oced my rx 6700 to 2.8ghz with a great uv of 1075mv from 1200mv. Should I call it 6750gre instead. Lol",
      "5700X and powercolor rx 6800 in combination with bitfenix 450w no problem",
      "what sorcery is this.",
      "I was making fun of this weird gpu man.",
      "An RTX 4060 or an RX 6600 XT would be adequate for a PSU of this wattage, the 6700 (XT) would be maxing out his PSU that there wouldn‚Äôt be any sort of wiggle room.",
      "Just save yourselves the hassle and get the model that only requires 1x 8-pin by spec.  \n\nI guarantee you can still get more performance out of it beyond what Sapphire ships it at.",
      "Gotcha. Posts on previous \"GRE\" releases were acting as if they were a global release so I guess I'm having flashbacks of people not reading past the title.",
      "of course just like the 6750xt is a 6700xt with 18gbps memory and a tiny gpu core oc"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6750",
      "6750"
    ],
    "title": "AMD to launch Radeon RX 6750 GRE graphics card in China, \"RTX 4060 price with RTX 4060 Ti performance\" - VideoCardz.com",
    "selftext": "",
    "comments": [
      "Isn't \"4060 price for 4060 Ti performance\" literally what the 6700 XT is for?",
      "That‚Äôs literally the definition of how the entire CPU/GPU market works, except worldwide and not just china",
      "XT sounds horny, GRE sounds cooler.",
      "so likely that 7700xt will be slightly faster than 4060ti and more expensive?",
      "Well I prefer Radeon all-in-wonder. That sounds the sexiest.",
      "This is literally how all cpus/gpus are made and sold",
      "Based on leaks - 7700xt will only have 12gb.",
      "lol",
      "More expensive than the 8gb card, but less than the 16gb card.",
      "Hardly unprecedented for AMD. Both the RX 580 2048SP and 896SP RX 560 come from this die harvesting.",
      "Thank you for that mental image, UnwashedArmpitLicker",
      "Yes",
      "Agreed. It makes me the most... \"curious\".\n\n\"What!? You do TVs, too!?\"",
      "Better for them to be on peoples hands then on a landfill.",
      "ok, i stand corrected, but its definitely not 8 gb.",
      "AMD loves Xs.",
      "I feel like these are just repurposed leftover mining chips",
      "But doesn't GRE stand for \"Greatly Reduced Expectations\"?",
      "You mean AMD owns twitt...X ?",
      "Nah. I think the purchase of my 6700XT after 3 years of Polaris use is breathtaking. It does everything maxed out at 1440p well over 144 FPS. What more do you want?"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6700xt"
    ],
    "title": "PC with 7900XTX red devil pulls 666 watts from the wall.",
    "selftext": "Recently upgraded from a 6700XT to 7900XTX. \n\nMy powersupply is 750W so I'm cutting it very close, but it's a new Seasonic focus gold, so I'm sure it's reliable. I'm just not going to overclock the card, this was worst case scenario with a Ryzen 7900X and GPU both maxed out.",
    "comments": [
      "Now you know why it's called a Red Devil.",
      "Is this a peak or sustained wattage?\n\nIn any case, 666 from the wall at around 90% efficiency means the PSU is supplying about 600W, so you have a 20% buffer.",
      "Ah gotcha, I appreciate the info! The card does recommend a 900W PSU minimum, but I should be good. \n\nThis was at peak load, realistically when gaming I'm only pulling like 450-580W depending on the game. Idle and basic tasks it's 110-170W (this is total PC usage). \n\nI know modern GPUs also have power spikes, but I haven't crashed or had any issues yet.",
      "Wait till the wires turns hot red and start to melt everything.",
      "Maybe that's why it's called the red devil.",
      "The old Seasonic Focus line was really bad at dealing with transients, so you are either lucky or have a newer model (or maybe Powercolor kept the transients low with this model, I haven't seen any proper review.)\n\n>This was at peak load\n\nYou mean like running a CPU and a GPU stress test at the same time?",
      "Might be time for an exorcist",
      "Correct, this was everything at 100% load. Which while gaming the Ryzen 7900X barely does anything, it's all the 7900XTX",
      "OP was playing Diablo 4 at that moment.",
      "They recomend higher to avoid liability. They don't know what the rest of your system is, so it's better to overestimate.\n\nI would still look at undervolting any card, less draw with no draw backs.",
      "Then wrap them around a can of Chef boyaRDee.",
      "So basically your PC is a bit of a demon ;)",
      "That seems about right, 13900K+4090 users report 650w peaks. A good 750w PSU is fine for that. I love posts like this to prove the 1000w gang wrong.",
      "‚õß",
      "I have a 4090 and 5800X3D and I've gone never gone above 600. Running a 750 watt, and the 4090 is slightly overclocked. 750 watt gang",
      ">then it'd consume 812W of power at the wall to supply that.\n\nAnd it would be rated to do so. PSU ratings are the sum of the DC rails, not the draw from the wall. A 750W PSU can supply 750W of DC power combined, it's just a matter of how efficiently it does it.",
      "Plot twist he was also running Diablo 4",
      "Truly a red devil!",
      "r/AyyMD",
      "Where are you seeing that the red Devil XTX recommends a 900w PSU minimum? Everywhere lists it as a 750w min PSU"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6750",
      "6750"
    ],
    "title": "AMD's last-gen Navi 22 GPU is still competitive against Nvidia's latest Ada Lovelace GPU ‚Äî RX 6750 GRE beats RTX 4060 in a new review",
    "selftext": "",
    "comments": [
      "6750 GRE 12 GB*, which is basically overclocked 6700 XT.\n\n6750 GRE 10 GB is the 6700 10 GB, which is closer to RX 6650 XT and slightly slower than 4060, but very close to it nontheless.",
      "Higher tier old product beats lower tier new product news at 11. What's tragic is the 4060 is really a 4050 but priced like what a 4060 ti should be priced at. That said $289 is a pretty good MSRP for this... too bad it's china only",
      "As far as I know, the RX 6750 GRE 10GB and RX 6750 GRE 12GB are a second set of refreshes of the RX 6700 and RX 6700 XT, and were originally China only and European OEM ( only available in pre-builts ) only but have since become available retail. I personally find the 6750 GRE 10GB naming to be pretty stupid because it is slower than the original 6700 XT despite having a higher tier name.",
      "It‚Äôs also competitive against 7600. Interesting way to frame the headline",
      "In other news, the 2080ti beats the 4060.\n\nMore shockers at 11",
      "The GRE cards are literally a rebadge of existing parts with no changes in specification.\n\nThe card refresh progression:\n\n* 6700 (10GB, 160-bit bus) --> rebadged into the 6750 GRE 10GB\n* 6700 XT (12GB, 192-bit bus) --> rebadged into to a 6750 GRE 12GB\n* The 6700 XT also got a previous refresh long before the GRE cards came out, called the 6750 XT. It's faster than the 6700 XT (and thus the 6750 GRE 12GB), due to higher clocks for the cores, memory, and cache.\n\nRDNA 2 (and RDNA3) is great value in many regions compared to the horse shit value RTX 40 series.",
      "Because there is little/no improvement over the 3060 and it has less VRAM",
      "The 4060 is shit so this isnt really unexpected.",
      "Breaking news",
      "I think it's compared to each other because the price is close. That's why the 7800 XT is compared to the 4070, even though it's \"higher\" tier. 4070 is still 50 to 100 USD more expensive.",
      "The cheapest 4060 right now is $290. For $310 you can get a 6700xt which is not only 20% faster but also has more vram.\n\nNvidia isn‚Äôt competitive in the mid range market at all right now. They are competitive in low end $250 price point, where the 3060 goes head to head with the 6650xt, and then the high end. At the $500 price point the 4070 beats the 7800xt in value, at $700 the 4070ti and the 7900xt being a tie, and at $1000 the 4080 beating the 7900xtx.\n\nAmd is killing it at the $200 price point where the 6600 has no competition, at the $300 price point with the 6700xt crushing the 4060, and at $400 the 6800 crushing the 4060ti.",
      "How is it shit",
      "The 10 GiB could've been named 6700 GRE",
      "You still didn't explain the difference lol.",
      "It‚Äôs what would be a 4050 in every other generation for $300. After the 3050 was a distance of a gpu at $250. It‚Äôs terrible, apart from using the gigabyte LP version for niche situations.",
      "I did though? They are refreshes of the RX 6700 and RX 6700 XT? Same as the first refresh of the RX 6700 XT, the RX 6750 XT. Same die, just with tweaked power limits and better binning to allow for increased clocks. Some refreshes might also include higher speed memory or even a die shrink as well, but I don't believe these do.",
      "amd should have just named it the 6750 XL like they used to do in the past. It would be less confusing.",
      "4060 is x50\n\n4060 ti is x60\n\n4070 is x60 ti\n\n4070 ti is x70\n\n4080 is x80\n\n4090 is xTitan\n\n6750 gre = ???",
      "I mean the power efficiency is the point",
      "Even in raytracing?"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "rx6700",
      "rx6700"
    ],
    "title": "Rx6700 vs RTX 3070",
    "selftext": "Hi. I'm upgrading my pc completely, and I'm in doubt about my new GPU. How good is it to use Ryzen 7 with an RX6700, and how good is it to use a Ryzen 7 5800x with an RTX 3070? Does the Smart Access Memory make a big difference?",
    "comments": [
      "To get the best performance your ryzen 7 would have to be  Ryzen 5000 cpu due to its ipc and either of these cards. The choice of card will probably depend on what your going to be using it for as they both have SAM/ Resizable BAR, albeit Sam does seem to perform slightly better. The 3070 is the slightly faster card but only has 8gb compare to 12gb plus it also has dlls and rtx.",
      "3070 is without a doubt the better card at the same price. Slightly better performance overall, much better raytracing, DLSS. Only reason some people are recommending 6700XT is because you're on the AMD subreddit.",
      "Whatever you can afford/is available. If closely priced, I'd take the 3070 for DLSS and RT if you care about that.",
      "6700XT cuz 30 series are VRAM choked",
      "The 3070 is better than the 6700XT at 4K tho.",
      "11GB VRAM is recommended for playing in 4k native max settings which is not really doable with either of the 3070 or 6700\n\nfor 1440p (the target of these cards) 8GB proved to be enough\n\nthat 16GB on AMD cards is mostly marketing for the 1440p cards and lower, it could still be useful if you use these GPU for modeling or video/image editing as you could really use these 16GB then",
      "If the prices are the same I'd go with rtx 3070. But in my experience the 3070s are harder to find and cost double it's rx equivalent.",
      "done. it's the 5800x",
      "ehhem where the hell is rx6800 non xt in your comparisons. 3070>6700xt 3080>6800 3080ti>6800xt 3090>6900xt is that what you meant?",
      "It's funny people are sticking to the 8 gigs vram not enough but don't mention the lackluster raytracing performance on the AMD card and a lack of a proper AI upscaler.",
      "The rx 6800 is close to 3070ti, the 3080 obliterates it",
      "FYI SAM works with Ryzen 3000 series and Intel CPUs at least from 10000 series onwards.",
      "Do you know how ram a works?\nIf a game uses 20gb vram with a 3090, that doesn‚Äôt mean that it won‚Äôt run with a gpu less then 20gb vram\nAlso msrp is $499 for the 3070\nQuestion: what‚Äôs the better gpu 470 8gb or 580 4gb?",
      "Not comparable to the rtx 30 series, but even on those cards it‚Äôs not worth it without DLSS, the best feature imo. Too bad most games don‚Äôt have it",
      "Dude, in this market, if you HAVE to buy a Card, take what you can get/afford...3070 is better, 6700xt is good enough. They are roughly on 2080ti level, so unless the pricing is the issue, either one will get you what you need to do. My 2080ti crapped out on me, and I'm looking to get either one of these myself, but I had a Vega56 as a backup so I'm waiting for saner prices...",
      "Hi.\n\nNo, it does not make a big difference. Between those two cards, the 3070 is the best card, and will do great üòä",
      "Radeon is only better if its cheaper 3070 > 6700Xt 3080>6800XT 3080ti > 6900XT",
      "As if VRAM is the only thing that matters or differentiates the cards‚Ä¶",
      "OP is asking about 6700XT - you are listing \"6800XT>3080/6900XT>3080TI\"...\n\n\n3070 is simply the better card overall, but  DLSS is more widespread and its performance in RT is way better, it also has nvenc and cuda for professional workloads.\n\n\nThe 8GB only hurts it at 4K in couple titles. Honestly it all depends on what the price is for either of them.",
      "Personally, I‚Äôve owned a 3060ti and 6700xt. The 6700xt is noticeably more powerful than the 3060ti but I think it‚Äôs still a small tick behind a 3070, but at the same time the 8gb on the 3070 will become a bit of a bottleneck soon enough. Also the AMD GPUs seem to be gaining performance through drivers faster than Nvidia so the 6700xt might eventually be equal to or better than the 3070."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6700xt"
    ],
    "title": "This was my first building a PC. It has a 5900x and a 6700xt. I love it!!",
    "selftext": "",
    "comments": [
      "Enjoy it!",
      "Right on. I got a 3900X and an XFX 6700XT and couldn't be happier.",
      "Nice.",
      "Looks awesome.",
      "You got the Merc 319? Mine has been incredible! Like I seriously couldn‚Äôt ask more any more out of it as far as just quality. It‚Äôs so so nice.",
      "5900X is overkill for just gaming, but it's still a great 1440p system. I have a 5600X/6700XT and I love it.",
      "I can imagine the happiness you're feeling right now - nothing like getting a badass first system.\n\nEnjoy it !",
      "It really is. The temps are nice, the fans don't go full-blast and the performance is great.",
      "It's looks soo good! :D",
      "Good job",
      "Looks dope ! :D",
      "Thanks everyone! It was super fun to do ngl.",
      "Nice build but kind of lopsided imo",
      "Great job dude!",
      "I'm gonna get a prebuilt for now just for the games, and then build my own in the future, because building your own right now is way too expensive.",
      "That's awesome dude! Welcome to the PC world! :)",
      "Up until today I never cared for reference AMD cards.  This build changed that, and I commend you for that.",
      "What are those fans? \nEdit spelling",
      "(I haven't built in a while) the memory has lighting, where to buy this?",
      "Just got a 5800x, coming wed to replace my 3700x. Going with my 3080, definitely excited. Might get my first nvme drive too. But seeing your nxzt cooler is tempting! Nice neon look!"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6700xt"
    ],
    "title": "Help for a gamer dad...6700xt, 6800 or 6800xt.",
    "selftext": "Currently have an i5 11400, 32gb ram and a 3060 gpu with a 600watt psu.  I'd prefer to keep total costs around 400.  Mainly play fortnite, halo infinite, COD... just got an Asus tuf vg27aq3a (1440P, 180hz) that I'd like to max out or just be able to play at 1440p and at least 120fps without issues.\n\nGiven this, which should I go with?  Look like prices are $359 for the 6700xt, $429 for the 6800, and $489 for the 6800xt... however I believe for the 6800xt I'd need to spend another $100 on a PSU upgrade no?\n\nSo $359, $429 and $589?  I'm not looking for bleeding edge tech as I have a series x and ps5, just looking to add a good 3rd option for our family where I don't have to fiddle with settings and can just set and forget at good resolution/fps.\n\nUpdate - After some good feedback I've decided to stay put for at least another 2 years with my 3060.  At first I thought it was my GPU causing the issues which started this whole thread.  Apparently the epic games launcher was set to stream the graphical assets in fortnite, which explained why the first game would stutter but subsequent games were smooth.  I went ahead and checked the box to download the 30gb's or so and boom...1440p, epic quality and runs at no less than 90fps.  \n\nSo yea, I'm just going to hold off for at least 2 years.  Thanks!",
    "comments": [
      "I would say 6800xt. 6700xt would be best value but would not be a substantial upgrade from 3060. Especially if you want 1440 p at 120fps.",
      "I have been researching similar and I am upgrading from a budget build. I am finding that the 6700xt is the best value for the dollar when on sale. However the 6800's have 16gb ram I think. Benchmarks I saw put the 6800xt about 20% faster than the 6700xt. So you can try to search for a price that justifies that 20% gain or not.",
      "Thanks!  Okay so I'm now between the 6800xt and the 7800xt. Both are the same price.... What should I go with?  And any reco on the PSU?",
      "No, no. Your at 1440 so i think your cpu will be fine for that resolution, not for 1080.\n\nHeres the deal, u want your jump from 3060 to next, to be substantial and u ideally want a gpu that can push 1440 to high refresh in future games too.\n\nThats why Id say 6800 as minimum but the 6800xt is a good deal more performance to last u longer, ive had both actually.  \n\nI would also not be trying so hard to keep a psu.  Ran my 6800xt for two yrs on 700w also.  Were it not for transient spikes, id try it on 600w maybe power limited. But bottom line, psu not that expensive.",
      "7800xt, its a better performing card.",
      "Agreed, 6800 or maybe 6800xt would be the best for longevity. However if you don't want to also spend more for a power supply. My 6700XT keeps me happy at 1440p. I don't expect that to last forever with newer games but I'm not exactly playing the latest titles either. \n\nTbh, you might find more stability with a higher wattage power supply anyway, even the 6700xt,  say 750 atleast. Depends on quality of current unit.",
      "6800xt!",
      "Upgrade to a 6700xt hardly seems worth it, especially at current prices. \n\nThe 7700xt at $421 and 6800 at $409 on Amazon don't seem too bad.\n\nThe 7800xt I'd say is a better deal than the 6800xt. 60w less power and a similar price. I think I've seen $480 or $490 recently.",
      "The 6800XT is, of course, the best option for your immediate and future wants and needs but yeah... I tested mine, 700W suggested, in gf's PC (5600X, 750W PSU and usually a 3070) It did ok but 600W isn't doing it, even with tweaks aso. Fwiw I used the 6800XT (in my PC) with a 5800X and a 1000W PSU that's also fine for a 7900XTX's appetite. If you take the 6800XT/new PSU route I'd suggest at least 850W to cover you for any later upgrades on a similar scale.\n\nAs for perf, my 6800XT was a 3440x1440 card 3 years ago but since then has been written down to 1440p for more recent AAA's approaching the kind of frame rates you're looking at with any real longevity (and short of cutting settings hard as you go on) For the other cards there's somewhat less compromise re the PSU (600W base for both) but more for the performance. All are fine cards at their respective levels though with the 6700XT's 12Gb being the lowest cap I'd use for 1440p and the 16Gb of the others offering some buffer.",
      "How much are you going to sell your 3060 for? Does that change anything? Because as of now I wouldn't upgrade the 3060 to any of these if I was just paying the prices you're saying for them and not getting any of it back.\n\nI see it like this, with that 3060 you should already be able to get 1440/120 in those games with tweaking settings/dlss and the only one you're going to be able to max out and still be at 1440/120 is cod with the 6800/xt which you should upgrade your psu for making it even harder to justify. There aren't really any cards capable of consistently comfortably maxing out games at 1440/120 aside from the 4090. Even the 4070 super which is another $100 more than the 6800xt at least in the US only runs at around 1440/90 using dlss in Fortnite at max settings.\n\nThat PC should already be a good match for the performance level of the PS5/xsx as it generally performs similarly but with the benefits of better rt and dlss.",
      "6750 will get you 95 fps In COD running max settings in 1440p. And you can find it for under 400$",
      "Man, if you could put a little bit more, 7800xt's are dropping. just picked up a hellhound",
      "7800xt. 1440 solid performance.",
      "Oh nice, thanks for the input!  Yea I mean $359 seems pretty good, considering I have a 600watt psu and it's max draw is 230 watts. With my i5 that puts it around 300-400.  Really didn't want to incur an additional cost for that.\n\nYea and like you, I'm coming from a semi-budget build, but also want a good price/value ratio.  Curious what graphics card did you upgrade from?",
      "Ohhh I didn't even consider bottlenecking..... Crap.  So then what about the 6700xt vs 6800 non xt?  Or still a bottleneck?",
      "650 watt  recommended min per AMD.",
      "Any bottle neck issues?",
      "So I just looked it up... Wow!  Yea same price.  So 7800xt seems like the winner.  Any PSU reco for that?",
      "Yeah that's a good point. So I wasnt looking to be fairly aggressive with the 3060 sell it for about 200.  Must used ones seem to be going for 250.  My rationale is I also want to future proof my rig as a have a 14 and 11-year-old, so trying to get something that would run 1440p at 120 for the next 4 to 5 years.  \n\nThat being said, yeah your point remains. I booted up Halo infinite and had no issues whatsoever.  I guess I was a little nervous because fortnite was stuttering which threw me off.  Then after some research I realized I guess it's prone to do that?  Anyway, with 200 back would you still recommend moving forward with the 7800 XT and PSU or no?",
      "And you'd reco that over my 3060?  Worth the upgrade?"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "rx6700",
      "rx6700"
    ],
    "title": "Possible Radeon RX6700 series graphic card Render Leaked by JayzTwoCents",
    "selftext": "",
    "comments": [
      "Still think the VII is the best looking card out of RTG",
      "Vega 64 Limited Edition reference blower LOOKS sleek as hell.\n\nIt just hurts my ears a little.",
      "A non insignificant number of the issues with the 5700xt was (probably) due to power delivery. Put more headers on it the card won't boot without and you have less issues of people not realising the adapter they bought from Amazon made of aluminum flakes coated in plastic that can't carry the current required aren't acceptable. There's a reason NVIDIA put a disclaimer that your warranty is void if you don't use the adapter included with the 3080.",
      "I'll wait for some Pulse design from Sapphire Tech.",
      "Dual 8 pin= power. Next month for full specs/price is to looooong AMD!",
      "I actually like it.",
      "Im still a big fan of the HD7990 https://images.anandtech.com/doci/6915/7990Car_678x452.jpg",
      "Blowers suck though. So I rather have performance over blower",
      "If Team Rocket sold gpus",
      "Looks horrible, but whatever, as long as it delivers. (and isnt trying to steal my pokemon...)\n\nIts not like the AIB cards look much better... when I look at what they created for the 30XX cards... ugly af.\n\nI really liked the \"flat\" and \"not special\" design of the Vega FE cards, and Radeon VII. But nowadays, its all about \"who can fit the most RGB and branding on the shroud\"... and then they all try to differentiate by coming up with \"unique\" RGB... which then messes up the entire aesthetics of the card.\n\nThat aside, I also dont need a \"Radeon\" or \"Geforce\" logo on the card, I know what i paid hundreds of dollars for.\n\nIts not like I am constantly looking into my case to figure out if my card suddenly changed the branding and is now a RTX 6900 or so, made by nvidia.",
      "Not really, in the renders it seems worse than it is assuming the Fortnite render is accurate. Buildzoid talked about that, fearing that they may have repeated the same mistake from the Radeon VII cooler with the giant Radeon logo blocking the airflow, but that's not the case with this card, the Radeon logo barely takes any space and shouldn't obstruct the airflow.",
      "Or the Nitro+ if it comes in that variant.",
      "Team Rocket",
      "My problem with most of the non-rectangle cards is the aesthetic is attempting to be too gamer-y. Any detail on the plastic housing makes it appear less cheap than it actually is.",
      "Your one 5700xt is the golden standard to which all 5700xt‚Äôs shall be compared. It is known. Amen.",
      "that seems like a LOT of plastic to keep heat trapped....",
      "It's ugly.  Like *really* ugly.  A big step back from AMDs minimalist design.",
      "I personally loved the 295x2... love that red fan! :-D  \n\n\nWould of loved a Radeon VII design with these fans.  \n\n\n[https://www.guru3d.com/index.php?ct=articles&action=file&id=9746&admin=0a8fcaad6b03da6a6895d1ada2e171002a287bc1](https://www.guru3d.com/index.php?ct=articles&action=file&id=9746&admin=0a8fcaad6b03da6a6895d1ada2e171002a287bc1)",
      "400W would definitely be three 8-pins. And no reason? Look how many people crashed their GPUs with single pig-tail connector on 225W Navi cards. Transient power draw is an issue.",
      "2x8pin means between 301W and 375W peak power consumption unless AMD is going over PCIe power standards (which they've done before)."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6700xt"
    ],
    "title": "Maybe not the best 6700XT model, but I'm incredibly happy with it and it was $320",
    "selftext": "",
    "comments": [
      "I think anybody would be happy with it at that price.",
      "There's big devaluation currently happening in my country (Argentina). The dollar exchange price was up like 50% in a short amount of time and some retailers hadn't updated the prices. I had some Ethereum that I mined with my old 5700XT and it's essentially valued as dollars here so I said fuck it and got it.",
      "Where are you guys finding $320 6700XTs?",
      "There's hardly no difference in models . Enjoy your card",
      "Lucky break",
      "It's Argentina pricing, he is using the \"black market\" USD exchange rate. \nThe importers here get USD at cheaper prices, and even with all the tariffs and stuff the cards end up being cheaper with the black market exchange rate.\n\nTake into consideration that the median monthly Argentine income is around 350-400 USD (taking black market exchange rate), so someone needs to save for a few months to buy a graphics card. I would rather pay 500 USD a graphics card with a 1500-2000 USD monthly income If you ask me.",
      "This.\n\nHave an ASRock 6800XT in the house and it has been doing as well as can be expected from any 6800XT.\n\nEnjoy!",
      "No they not. Stop spreading bs. As long the block is lower then the rad its ok.",
      "Not the OP, but I bought a used Qick 319 6700xt on ebay for $320 last month. If you don't mind a used GPU, you might be able to find a similar deal as well.",
      "Yeah, I watched that video too. Steve mentioned that the tubes should always be higher than the pump and they are. There's literally no other way to orient it I'm my case and it's been running fine like this for 3+ years",
      "I tried but it's longer on the side with the tubes so sadly it doesn't align properly if I install it upsidedown. It also doesn't fit on the top so I have no option but to leave it as is. The hoses are a little bit higher than the pump so it should be fine though.",
      "Hey, if it works it works, what's important is that it is sufficient for your needs and doesnt overheat.",
      "Awesome card for that price. The 5600X/6700XT is a great combo",
      "HOW?!\n\nHere the cheapest RX 6600 cost like that!",
      "I got my RX 6600 Powercolor in 230USD (argentina)",
      "Yeah aio seems to have to short hoses anyway to put them at the bottom.",
      "I 'just' want a 6700 XT msrp or lower",
      "So cheap‚Ä¶ I can‚Äôt get that price in Malaysia ‚Ä¶zzzz",
      "You don't need to feel like your card is lesser than just because it's not a premium model regardless of the GPU you get but especially of a mid range one like a 6700xt, used or new. It's nothing to brag about to get a premium model of a mid range card. In fact, kind of the opposite; it's a bit foolish, unless you somehow got it for a cheap price.",
      "I mean personally i'm looking at selling a 6800XT around the $500s."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6700xt"
    ],
    "title": "2022: Join team red 6700xt + 5600g",
    "selftext": "",
    "comments": [
      "Right?",
      "Nice!\n\nThe HDD is just for backup purposes, right?",
      ">D is just for backup purpose\n\nHahahaha yes and just extra cheap storage (got two m.2 NVMe SSDs in the motherboard)",
      "Coming from a 1070 ti and 2700x I absolutely love the increase in performance and lower power draw (both GPUs while gaming draw the same about 180w +- and the CPU is much lower on the 5600g 60w vs the 2700x 105w).",
      "Great question and one I meditated on for a number of weeks. After a ton of research I saw that the 5600g was around the gaming performance of a 3700x which is enough with my 6700xt. AND I want to repurpose the 5600g in another sff (non GPU, 3 litre case) build that's currently got a 2200g. I'll do so when my 5600g starts to bottleneck in games (if it does) I'll consider the 5800x3d or AM5 depending on the times. I've got a fairly large library and it doesn't bottleneck any of my games except for the new spiderman (with everything in highest and has been know to hog all CPUs hoping there's going to be a new patch to take less load on the CPU).",
      "Doesn't look like enough to affect performance. The back plate is a bit bent as well. Wonder if it was shipping damage.",
      "Compact!",
      "Why did you choose the 5600G? Wouldn't a 5600 non-X offer much better performance?",
      ">u radiator fin seems to be a bit curved at the end. Cute build overall, i like this si\n\nWow didn't even spot the back plate! Yes I got it for a steal on the second hand market now I know why lol. Check performance and cooling though all it perfect on that front.",
      "Your gpu radiator fin seems to be a bit curved at the end. Cute build overall, i like this simplicity.",
      "About every three years I upgrade my system, and realized this time, I could get away with upgrading only the CPU (after flashing MB bios), as everything else was still sufficient. Went from 2400G to 5600G. Wow, what an increase. Everything in Windows just flies. Going from Zen 1 to Zen 3 is a huge increase.",
      "Hmm why the G though and not a 5600/5700?\n\nEdit: Nevermind, read the comments.",
      "Haha \n\nBarracuda go boom!\n\nhttps://i.imgur.com/GU4O57V.jpg",
      "It's a Cooler Master NR200 \n\nInitially bought it as it seem like a budget all rounder and to fit my old atx psu (with 3d printed bracket) in now I'm just great-full I went for \"bigger\" mini itx case as gpu's have gotten really huge!",
      "All good if used. I would be a little annoyed if it was new.",
      "Enjoy the 6700xt such a beast",
      "Welcome and congratulations üéâ",
      "I can't imagine having something that's sensitive to magnetism, that is that close to an object that emits electromagnetic radiation.\n\nBut I'm sure there's been tests about that otherwise they wouldn't do it. Neat compact build!",
      "very nice build! i have the same cpu paired with 1080ti and its great.\n\nMake sure to run RAM at highest clock your cpu allows. you can pump 1.3v vSOC safely to Cezanne , it should let you run fclk at 2200+ . due to smaller cache than Vermeer , these chips benefit greatly from fast ram and fclk. also don't underestimate the performance impact of the below timings (up to 15% more fps in some games) :  tRC tRRDS tRRDL tRFC",
      "that pc looks so small if i try hard enough i could fit it in my pocket"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6650",
      "6650xt"
    ],
    "title": "The RX 6700 (Non-XT) is currently 10‚Ç¨ more than an RX 6650 XT, worth it?",
    "selftext": "Sapphire Pulse RX 6650XT = 376‚Ç¨\n\nSapphire Radeon RX 6700 Gaming OC = 386‚Ç¨",
    "comments": [
      "2gb extra of vram and 4% more performance. For 10,sounds not bad to me.",
      "Yes of course it's worth it!\n\nRegarding the GPU part:\n\n32CUs(2048 Shader Cores) => 36CUs(2304 Shader Cores)\n\n2MB Level 2 Cache => 3MB Level 2 Cache\n\n32MB Level 3 Cache (renamed InfinityCache) => 80MB Level 3 Cache\n\n&#x200B;\n\nRegarding the VRAM part:\n\nVRAM bus width: 128bits => 160bits\n\nVRAM size: 8GB GDDR6 (17.5Gbps) = 10GB GDDR6 (16Gbps)\n\n(here the VRAM frequency drops in favor of the quantity, but this drop will have no impact on performance because it will be largely compensated (or even surpassed) thanks to the increase in InfinityCache and the VRAM bus widths)\n\nFinally, the PCIexpress bus goes from \"PCIe4.0 x8\" to \"PCIe4.0 x16\", and all this for an identical thermal release (TDP) of 175Watts, in stock settings of course.\n\nSo of course that for 10 Dollars the Radeon RX 6700 10GB is more interesting than the Radeon RX 6650 XT 8GB, it is slightly more efficient (5 to 10% depending on the game) but above all it is more \"future-proof\".",
      "They're the same. The 6650 XT is a 6600 XT that's pushed a little further on the performance/power curve while the 6700 is a cut down 6700 XT (larger die).\n\nIn general, a larger die gives greater performance/clock and performance/volt. So if you undervolted and clocked both cards, the 6700 would be much more efficient.",
      "It's technically a stupid question on their part as you're fully in control of the power limit. So simply setting a lower one would be better. Matching TDP they should perform better still.",
      "$10 for 2gb  more vram seems good to me!",
      "Bruh. Who cares? You‚Äôre getting a better chip and more VRAM. Get it",
      "The trick is to UV and limit the frames to the max your monitor is capable.  \nNo need for 300 frames when your monitor can just handle 144hz",
      "Honestly, currently the Radeon RX 6700 10GB is the GPU with the best Performance/Price ratio, and even more so if you plan to overclock the card a little(or even more).\n\nOtherwise, if you want to wait a little longer to decide, soon the graphics card that will have the best Performance/Price ratio will be the Radeon RX 6800 16GB because in my country (in France) it is starting to slowly (but surely) approach 500 ‚Ç¨, which will give it the best performance/price/future-proof ratio with its 16GB GDDR6 and its excellent 4K performance.",
      "Get the better chip and do -100mV in the driver and you are golden",
      "6700 uses same or less power than 6600, let alone 6650 XT",
      "So silicon needs a certain amount of voltage to hit a certain clock speed, but it varies with every unit. So they set a super high voltage to get the highest yields (working units divided by total units), but by definition it's excessive for most of the units.\n\n\"Undervolting\" is reducing this voltage while keeping the clocks the same. This can actually *increase* performance as the card has more thermal headroom and can thus hit those clocks more, as well as free up thermal headroom for the memory and reduce load on power delivery (further efficiency gains). By reducing heat you also reduce CPU temps so it may boost more aggressively.\n\nAdditionally, the clock targets tend to also be set quite high, and there are steep diminishing returns to having higher clock speeds. So you can also reduce those clock targets which allows you to reduce the voltage further. You may lose a little performance but less than you think.\n\nFor example, by reducing clocks and voltage I was able to cut power consumption by nearly 20% and only lost ~3% performance on a 5700 XT. [See this user](https://www.reddit.com/r/Amd/comments/dgkfyb/more_undervolting_results_on_a_reference_5700xt/)\n\nEdit: Another thing is that silicon quality *increases* over time, but to my knowledge the stock voltage settings are not changed or set per card. So the later you buy the card, the higher the chance your card is overvolted. At least with rdna1",
      "Can you make a 6700 perform like an XT with some driver shenanigans like you could with the 5700?",
      "I don't think so, less memory and memory bandwidth keeps it separate.",
      "175Watts TDP too, i have said same thermal release, that's what it meant.",
      "I know, but electricity in my country is very, very expensive, I'd like to save as much money in the long run (electricity wise) as possible",
      "20W difference from what I saw. You could look up both cards specs (which I did on Newegg)",
      "6700 > 6650\n\nUndervolts and overclocks really well and is better suited to 1440p resolution\n\nCheck out Ancient Gameplays youtube reviews on the very card.",
      "Because the 6700 is clocked lower.  The 6650XT is pushed outside of the efficiency window for the chips.\nThe 6650XT is juiced to the max to squeeze higher performance out of a smaller chip.\nThe 6700 is a bigger chip with more compute units, so it can do the same work at less power.  \n\nObviously you COULD push the 6700 to use more power, but you wouldn't want to.  Even AMD's site shows the 6700 @ 175w TBP vs the 6650XT @ 180 TBP.\n\nIt's the same logic as what we're seeing with the new CPUs coming out where you can get like 95% of the performance but can cut 25% of the power usage.  (Those are arbitrary numbers, but the logic still applies.  The higher you push piece of silicon, the more inefficient you get.)",
      "Yes",
      "take the 6700"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6750xt"
    ],
    "title": "I upgraded my RTX 2060 to a 4060 today only to go online and fine out that apparently it sucks. Is it worth returning and getting an RX 6750xt instead?",
    "selftext": "",
    "comments": [
      "Not sure why you would decide to do your research *after* buying the product, but if you‚Äôre happy with the performance you‚Äôre getting just stick with it.",
      "The 6750XT is a card I would have suggested over the 4060 if you had asked before you purchased.\n\nThat said, you‚Äôve already got it now. And to its credit, the 4060 does have DLSS and frame gen. It‚Äôs not that it‚Äôs a terrible card, it‚Äôs just that its overpriced compared to its competitors which perform better with more VRAM.\n\nThe 6750XT is around 18-20% faster. Which means if you‚Äôre getting 60fps on your 4060, you‚Äôd be getting more like 72fps on a 6750XT (with better textures probably because of the higher VRAM). If that‚Äôs worth it to you, then sure swap em out ü§∑üèª‚Äç‚ôÇÔ∏è",
      "Brother you don't check framerates / frame times ? Install MSI afterburner and learn how to use it..",
      "Did your performance increase?  Are you happy with the performance you have?  If so why change it after you already purchased and installed it?",
      "Thanks man I'll ask my dad if we can try and return it tommorow. I feel really awful about the whole thing cause I adamant it was the best one for the price",
      "why does 4060 suck tho",
      "I don't think it'll fit onto the motherboard now that I'm looking at it :((((",
      "why did you keep it?",
      ":)))) yeah see.. use MSI afterburner bro it's worth it for watching CPU and GPU % usage and temps",
      "I tend to find out that small upgrades, like same tier of card but two generations younger don't paint such a beautiful picture in my computer as they do in reviews and tests and whatnot, and gains in-game can be smaller than in benchmarks. This may depend on what you're trying the card to do (e.g. churn out frames vs process ultra-HD textures in 4K, the latter of which is of course VRAM-intense). I feel that to some extent, in some ways, a 60 is a 60, a 70 is a 70, and a generation or two doesn't always cause a big uplift in the same old games (though it could in newer ones).\n\nRe: nVidia vs AMD, choose nVidia for DLSS and/or ray-tracing, choose AMD for rasterization performance and if you're okay with FSR instead of DLSS, and if you want more RAM for textures (but of course compare how much they have, it's just that AMD will normally tend to have more).",
      "Try turning on DLSS and frame Gen.",
      "A 4060 should be around 50% faster (at 1080p) than a vanilla 2060.",
      "I did some research before and didn't see any of the bad shit about the graphics card yet like IMMEDIATELY after installing it I get a video in my YouTube recommendations calling it Nvidias worst product",
      "It's still a powerful card compared to a 2060, when people say its bad it doesn't mean its going to explode in your face, its just not the greatest value to performance card out there, if you're happy with it then stick with it. If you're someone that cares about saving a buck and/or getting a bit more performance then look into better cards.",
      "No problem. But hey, just make sure it fits your case. The cheaper 6750XT and RX6800 are pretty long cards depending on which one you‚Äôre looking at. Just be careful not to accidentally swap for a card that won‚Äôt fit in your PC case.",
      "Cut twice and measure once!",
      "Idk. I think people are mad it has 8 gigabytes of vram. It's running pretty smooth for me so far",
      "Man i wish it was the same here, the 6750xt is a whole 100$ more expensive than the 4060 here",
      "will 6750 XT run quiet at 4k gaming (3840 x 2160) ?",
      "Okay so turns out the game I was playing auto changed all of the settings to ultra murder fucker raytracing 3000 and that's why the game was running like ass. Turned it off and it's running smooth as hell now"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6750xt"
    ],
    "title": "Deciding Whether or not to get the RX 6750xt now for $349 ($379 Ship & Tax) or wait to some other deal comes out",
    "selftext": "",
    "comments": []
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6700xt"
    ],
    "title": "6400 to 6700XT comparison",
    "selftext": "My old rx6400 compared to my new 6700XT.",
    "comments": [
      "[a 6900XT reference Vs a Zotac 4090...](https://i.redd.it/9m5kgio8tc5b1.jpeg)",
      "Don't talk to me or my son ever again :p\n\nPs, congrats, enjoy!",
      "I need to see a 6400 next to a 4090 lol",
      "My old desktop PC was a SFF office computer with a LP 6400.  The kids used it for Minecraft and war thunder.  \n\nI decided to finish my desktop build so I could get Starfield.  Did a 7600/6700XT build.  I thought the 6400 was hilarious next to the 6700XT.  \n\nNow I'm going to sell my 3070ti Alienware laptop and buy a new monitor.",
      "I have no reason to buy a 6400 but it's just plain adorable lmao.",
      "also sand down the gpu die and get some closeups of the transistors, i wanna compare",
      "It's like those videos that compare starship sizes, or Kaiju sizes.",
      "Nice get! Last year I upgraded my CPU to R7 5700X and now I've gotten myself the 6750XT also because of Starfield!",
      "That is just ridiculous",
      "cool upgrade\n\n\nyour cpu cooler's fans are on backwards",
      "Thanks, I figured that out after these pics.  I have them both on the \"forward\" side of each stack now, with a front to back airflow direction.",
      "You vs the guy she says is just a friend",
      "There are very very few reasons.  Its probably the best priced low profile option that can actually fire up a modern game (at 1080 low or medium) at playable framerates.",
      "Shroud and fans are important. More powerful GPU's need larger cooling and fans to function.",
      "When i went from a 6800xt to a 7900xt lets Just say it was similair",
      "I wonder which one is faster.",
      "Amazing upgrade, enjoy the extra FPS!!üòÅ",
      "Unfortunate how all RX 7600's are the size of the 6700XT while the RTX 4060 has not only plenty mini-ITX sized options (meaning <180mm), but also a LP variant on the way... :/\n\nSo RX 6400 sized RTX 4060 or RX 6700XT sized RX 7600?\n\nIf I want to replace a certain 160 mm AMD flagship from 2015...\\* you can get about the same performance and the same VRAM capacity from AMD in form of the 6500XT (8!!! years later) OR get something from NVIDIA if you actually want an upgrade (RTX 4060/Ti).\n\n\\*R9 Nano (596mm¬≤ 28nm) ![gif](emote|free_emotes_pack|heart_eyes)",
      "I have the exact same gpu. One of the few dual slot 6700XT in existence.",
      "I have that same Sapphire 6400 on one of my SFF's. Great little low power bugger."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6700xt"
    ],
    "title": "Rx 6700xt very low power draw??",
    "selftext": "Hi ,\n\nI just upgraded from Vega 64 to Rx 6700xt .\n\nI have got Shappire pulse model , I have quickly tried ac vallhala at 3440x1440 and I get gpu clock 2500Mhz , memory 2100Mhz about 75fps and a power draw of 130W \n\nIs that normal? Seems very low to me my vega used to draw 280W in games ...",
    "comments": [
      "To be fair, Vega was very power hungry beside using hbm",
      "6000 series cards are actually very efficient",
      "Don‚Äôt use hw monitor, it is not updated.  Use hwinfo64.",
      "I wouldn't trust power draw readings from Afterburner/Rivatuner, they've given inaccurate readings with AMD cards many times before. Use HWinfo instead. I'd like to know if you get the same power draw on HWinfo as well, if that's the case then there is something weird going on in my opinion..\n\nEdit: 75 fps at that resolution is crazy good by the way, my 5900X + 3080 struggles to stay at 60 fps @ 2560x1440",
      "Thanks it might be normal I am just so used to see 300W power draw that I was very surprised was expecting about 180-200W not 130 xD",
      "That's true I had to buy a new 850W PSU as it was crashing with my previous 650W all the time",
      "cup you use? Is the card at 100% utilisation?",
      "75fps is pretty good for ultrawide 1440p for 6700xt, so it's not like the card can push out significantly more and is in a need of power",
      "I have found it , Hwinfo shows that in ac vallhala at 1440p uw max settings is pulling 162W and Gpu PPT limit is 213.9W",
      "That's more reasonable. This made me open the game and check for myself and I'm only pulling  roughly 195W on an undervolted 3080 so ~162W is likely accurate.",
      "That is low.",
      "Is amd chill turned on in Adrenalin? My normal gaming load is pulling around 180w to 220w.",
      "If you don‚Äôt mind me asking,when, where, and for how much did you get an RX6700xt?!",
      "RDNA2 is very power efficient compared to Vega64.",
      "AC: Valhalla draws surprisingly little power, I have tested AMD and Nvidia cards and I have seen them drawing less than expected. On the other hand, The Division 2 draws an insane amount of power, pretty much more than any other game I recall testing.",
      "You'll never get accurate board power readings on an AMD GPU as it can't be done from the card itself, you need to monitor the external power rails.\n\nAMD only monitors power usage on the die itself, they don't monitor board power.",
      "Thanks I'll check it now and let you know .",
      "Or just use the AMD FPS overlay which gives the power draw as well",
      "Cpu is at : 36-40% Ryzen 3600\nGPU is at 99%",
      "Guess only undervolting could have saved you"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6750xt"
    ],
    "title": "7600xt vs 6750xt",
    "selftext": "A year ago I would've blindly picked up the 6750xt due to the raw performance for 1440p (considering the values), but today I don't know. \n\nI'm unsure, I think dropping 15% performance for 4gb of VRAM is actually tempting, seeing as a few games I'd like to try can suck up to 16gb.\n\nAny thoughts? Thanks!",
    "comments": [
      "im taking the 6750xt then. i thought you had the 6750xt and were gonna downgrade to the 7600xt lol.",
      "thats a downgrade in terms of performance. smallest uptick id take in your situation would either be the 7800xt or minimum the 7700xt. wouldnt lose performance for slightly more vram.",
      "My OG 6700xt is still going strong 3yrs later 1440p 144/165hz gaming",
      "you didn't mention prices.\n\nfor example depending on the prices the rx 6800 could be the far better deal at 360 us dollars nw instead.\n\nit has 16 GB vram and it outperforms both.\n\nat 1440p the rx 6800 is 40% faster than the 7600 xt, while generally being better price/performance compared to the 7600 xt.\n\nand the rx 6800 is also 24% faster than the 6700 xt. don't have data on the 6750xt for comparison exactly.\n\nbut the rx 6800 would be a big step up and better value/us dollars.\n\nso while again not knowing the prices for your region for those 3 cards, the rx 6800  may be the best option and it is quite close in absolute price to those other cards generally.\n\nif i were a friend of mine, i'd tell you to either get the rx 6800 if you want a new card for the holidays, or wait for q1 2025 to get an rdna4 card.\n\nand as rdna4 might just be great value at 500 euros/us dollars, but maybe 360 us dollars range is still shit, the rx 6800 at 360 us dollars might still be the best option.",
      "Budget won't allow me for a 7700xt. I only have enough for a 6750xt or 7600xt, 1440p and it has to last at least 3 years",
      "Oh no, I'm discussing 16 X 12gb VRAM for the performances. Are you sure 12gb will be enough for 3 years?",
      "no one knows. im regardless gonna take the significantly faster card even if that means lowering settings to fit the vram allotment of the card i choose. i play at 1440p high refresh and with my 6900xt i can basically pin my monitor at 165fps with any game that i play. id also look for some used options ive seen 6800xt sell right around the price of a 6750xt. yeah no warranty but for 1440p being on a tight budget seriously limits your options considering its more difficult to run than 1080p for a gpu.",
      "Brazil used prices are as bad as new ones, it ain't worth. Guess it's gonna have to be the 6750xt",
      "No feedback but they are widespread for $350 shipped new now.",
      "would have been nice to know you luved outside the us because i just found this https://www.ebay.com/itm/387605579168?mkcid=16&mkevt=1&mkrid=711-127632-2357-0&ssspo=vbocw198ruc&sssrc=4429486&ssuid=&var=&widget_ver=artemis&media=COPY brand new 6800 for 320 which is cheaper than ive seen 6750xts going for. look for a 6800 in your area you might get a huge performance boost for not much more money."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6750",
      "6750"
    ],
    "title": "2080 super vs ry 6750",
    "selftext": "Currently i am running the 2080sp but its really struggling to run stalker 2 so im thinking its time for a upgrade, i dont care for raytracing tbh so im thinking of going for a rx 6750 or should i wait for something else, Any guidance is appreciated.",
    "comments": []
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "mid",
    "matched_keywords": [
      "6650"
    ],
    "title": "AMD Forces a Price Increase: Radeon RX 6650 XT Review",
    "selftext": "",
    "comments": [
      "\\> But why?\n\nFor the price increase duh",
      "Absolute shockers how basically with [worst marketshare](https://g3f4h2w2.rocketcdn.me/wp-content/uploads/2021/12/GPU-Add-in-Board-Market-Share-2002-to-Q3-2021-1024x358.png) ever, instead of looking for ways to gain some marketshare back - they drown themselves even further with, as predicted, lazy msrp bump for final RDNA2 cashgrab",
      "Yes, and rumor has it that the 7xxx series is supposed to be at least $50 dollars more than these MSRP. Simple answer is, don't buy them. I realize that may not be an option for some people but the only way to get the point across that we won't be gouged to death for corporate profits is to not buy the cards.",
      "Sure, but at this stage, AMD is losing marketshare at a rather alarming rate. Intel hasn't even entered the space yet either, AMD should be fighting tooth and nail to keep as much marketshare as they can before Intel enters, because you can bet your bottom dollar, Intel's strategy will be to target the mainstream market which is where AMD is currently succeeding. \n\nIntel will simply outprice AMD and NVIDIA to gain marketshare and then what will AMD have to show for it, AMD's fanbase primarily buys based on value in dGPU, so once Intel provides better value why choose AMD? AMD can't beat NVIDIA in sales in the high end halo market due to NVIDIA's mindshare and they also can't beat them in the midrange sector where NVIDIA will simply out-ship and out-market them. Adding Intel into the mix only puts AMD in a tough position, so they better believe they're gonna have a problem when Intel starts putting out cards at cost price or at a loss just to get marketshare.\n\nThe only saving grace for AMD is that they will be able to match NVIDIA for performance or slightly beat them or slightly lose to them in a particular segment, but that matters very little because AMD's had that advantage for years and still cards like the GTX 1060 out-shipped the RX 480/580 and RX 470/570 combined. AMD for whatever reason can't penetrate the market towards gamers, despite their business being slightly profitable in terms of margins. I think it really has to do with their marketing, it's cringe, Radeon Rebellion is a good example of just cringe marketing. Then you have situations like Vega where they hyped it up only for it to release later than the GTX 1080 by a year and match it in performance. I'm happy those days are a bit behind AMD but they also don't seem to not market very effectively. NVIDIA's name is plastered everywhere in net cafes, at eSports events, they will send parts to streamers to promote stuff, they will even work with Intel on overclocking records etc. AMD does none of that because they're too stubborn or too stupid to. AMD's marketing \"hype\" is to put RDNA2 in Fortnite, which isn't their target market for starters and especially when Fortnite was losing popularity too... It's not even comparable the two types of marketing, NVIDIA is simply better in that area, even if NVIDIA imo is disingenuous, they simply will put their name out there more effectively.",
      "Would have made it even more sense to launch it at the 6600XT price then if they are discontinuing it.",
      "This thing gets basically the same performance as a 5700XT and costs the exact same amount, the only advantage it has over the 5700XT is some lackluster RT. Modern GPU prices are a joke...",
      "Fanboys will twist anything to argue \"it's good for us!!!\"",
      "In my country and i also checked in Germany the price difference was around 60‚Ç¨ so maybe it depends a bit on market.",
      "this looks utterly atrocious",
      "The whole point of a refresh is to offer better performances at the same price",
      "Be aware that we've been told by multiple sources that the initial wave of 6650 XT stock has been subsidized by AMD in quite a few regions, so I'd wait a little bit before making any conclusions regarding pricing.\n\nThat said if they are going to continue to keep selling the 6650 XT at the same prices the 6600 XT's were available when why make the price hike official? Not a good look for AMD if that's the case. Ideally at this point you'd want the MSRP to be $20 lower, not higher :D",
      "If you check Newegg there actually isn't a price increase. There's 3 models in stock for 400 right now, which is the same price AIB's were selling the 6600 XT for and also the MSRP of the 6650 XT\n\nWhat I think happened is AMD is stealing the scalper margin from AIB's with this card. The price AMD (and Nvidia) charges AIB's for GPU dies is based on MSRP. However, the 66X0 cards do not have a reference model, so AIB's decide the actual selling price. AIB's were basically buying dies from AMD with the 380 MSRP in mind and then scalping them to 400.\n\nWe saw this before with the 2060. Nvidia reduced the MSRP to 300, but after quickly selling off their remaining FE's, they never restocked them. That means AIB's were free to set the actual selling price so the *actual* cost of a 2060 was 320-340. But AIB's got the dies from Nvidia with the 300 dollar MSRP in mind.\n\nAMD (and Nvidia) likely set the contracts up this way because in a normal market, the selling price for the card would be around their MSRP. Both companies do not have the scale of AIB's to produce PCB's and the other needed components, so they're reliant on them, especially for the cheaper models. Which is why that compromise was historically left in. But obviously AIB's took that little loophole and *ran* with it over the past two years.\n\nSo AMD just set the MSRP at what the actual selling price would be to be more honest and get more from AIB's. So this is actually a net positive for gamers oddly enough because they're now getting a *faster* card for the same price as before.\n\nThe issue is the reviews didn't know that this would happen since they can't see the future so they all come off as negative. Even though this card is actually a net positive for gamers. But imo the price jousting is pretty interesting from a business perspective.",
      "Their mindset has always been the same...the only difference is that now they can get away with more due to the high demand.\n\nThat doesn't change the fact that this is a trash refresh that add nothing to the current generation so people have all the right to be pissed off.",
      "It looks like the 6600 XT is getting discontinued but the 6700 XT and 6900 XT will still be around. Good news is that multiple models of the 6650 XT are in stock for MSRP (399) at Newegg so it's actually overall an improvment.\n\nThis card looks like AMD stealing the scalper margin from AIB's without changing the street price for people.",
      "Market share doesn't matter if your margins are still massive. Losing sales/market share isn't always a bad move if you can charge more % wise.",
      "This wouldn't be the product to gain marketshare back though, and certainly not at this stage, perhaps 4/5 months out from the next generaton. \n\nAlso desktop GPUs is one of AMDs lowest priority product categories.",
      "Expected really.\n\nEurope is basically the MSRP in euro (1:1 vs $) + 19-27% tax.",
      "There's been RX 6600 XT at 380 with launch batch. So what's your point? Making conclusion on launch batch?",
      "> Why cannibalise profits and future sales while the demand and price are sky high?\n\nDemand and prices are dropping pretty fast. Stuff's all going back to normal, so really, the whole bubble is about to burst. Plus, Crypto is in shambles.",
      "39% makes up a considerable chunk of their revenue though, and is by the far the fastest growing segment. \n\nFrom your own link:\n\n>between Q1 2020 and Q1 2021, which was a 92% increase. Further analysis reveals that revenue from the Computing and Graphics segment has grown at a rate of 46%, while that from the Enterprise, Embedded and Semi-Custom segment has grown at a rate of 286% during this period.\n\nThe margins on enterprise will be that much higher than mainstream as well."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "rx6800",
      "6800"
    ],
    "title": "Why is no1 talking about this: AMD is setting a new Performance/Watt standard with the RX6800",
    "selftext": "AMD is setting a new Performance/Watt standard with the RX6800(XT). 95% of the performance of the 3080 at 66% of the power consumption!\n\n&#x200B;\n\n[https://tpucdn.com/review/amd-radeon-rx-6800-xt/images/performance-per-watt\\_2560-1440.png](https://tpucdn.com/review/amd-radeon-rx-6800-xt/images/performance-per-watt_2560-1440.png)",
    "comments": [
      "Because we're busy talking about how we couldn't even have a chance at getting one.",
      "Because that's a terribly cherrypicked reading and clearly not representative of reality. I quickly looked at three other publications (Gamersnexus, computerbase, and PCGH) and all three conclude around 280-290W for the 6800XT and 320-322W for the 3080 (both within spec as quoted by the manufacturers), which are both a far cry from the numbers presented by TPU.\n\nRegardless of that, you fail to understand the reason of why AMD was called out in past years for their power consumption; It wasn't because they were drawing X amount of watts past some arbitrary threshold, it was because they were drawing FAR more power than the competition with much less performance to show for. Right now, AMD cards are undoubtedly more efficient, but the gap is so small that they could almost be considered on the same tier of power consumption/cooling requirements for the performance that they bring. \n\nIf you're going to be power hungry, you better be bringing performance to the table to justify it, which is what both companies did.",
      "Because that's like discussing supercars fuel consumption. Noone cares.",
      "As an ITX case user - I care. The performance per watt is really impressive. ITX builds are quite niche, but AMD definitely have an edge there because of it now.",
      "I dont want to be cooking during summer!",
      "Don't live in a hot climate I see. Thats one of the most important things to consider when living in a hot place. Yes I can use AC but the less heat I generate in my room, the better.",
      "I never got those \"arguments\". Were not comparing microarchitectures or nodes, we're comparing GPUs, how they perform and what power they draw. The rest does not matter, really.",
      "Exactly, Can't get an Nvidia, can't get an AMD, heck can't even buy the 4K monitor that I'm after. Gaming is going to be pretty shitty this year and 2021. Maybe even 2022. I guess I will be waiting for the next Generation of cards.",
      "Sure, but you can undervolt the 6800XT, too. \n\nComputerbase say you can knock 10W off and actually *improve* performance by ~4-5% overall. I'm sure if you give up those improvements you can knock even more wattage off of the top.",
      "After seeing the power of rtx 3000 series people just slide off the power usage.",
      "> uses GDDR6X\n\nThat's part of its architecture design. NV used it because they needed more memory bandwidth.\n\nAMD went with on-die cache to avoid using expensive & power hungry 6X.",
      "Because TPU's power consumption numbers are nowhere near close to other reviewers numbers.",
      "As a stockholder, I care because that's all the enterprise market cares about lol",
      "TBH, I'm wondering if I'm just going to permanently hang 1+ generation back. Buying computer parts has become a circle of hell, these past few years.  A 3900X paired with a 570 can actually give me utility, today. My 1080Ti is waterblocked, and can hang awhile longer...",
      "I'd save this type of rage (and yes, that is what it sounds like i'm sorry.) for after seeing how the stock is with non-reference cards. I personally wouldn't mind if the reference was sacrificed for non-reference stock to a degree.\n\n I mean we will still see \"no stock\" day 1 of non-references no matter if they have acceptable stock or unacceptable stock because the demand is just insane atm but we can probably still judge them by how many ppl can get their hands on one / reseller volume on ebay etc.\n\nAll that said, it really weirds me out how much feeling people invest on launch-day product availability i have to say. I don't mean this as to be an apologist, just i've never been in that boat and i cannot get used to seeing it happening still.",
      "AMD building automatical boost into their chips is actually a perfect example of how efficiency means more headroom. If their chips used 20W/core to sustain 4GHz instead of 10W, they wouldn't be able to boost as high and the feature would be far less impactful.\n\nAlso, efficiency definitely means more thermal headroom for a given level of performance, which means exotic solutions are not needed. Look at some of the partner 3090 boards. Like, holy fuck they are just comically large.",
      "It's only 20-30W less than a 3080, not going to make a big difference. Seeing power figures from GN or HUB, it's not more efficient than Amp√®re. TPU is the outlier.\n\nhttps://www.techspot.com/review/2144-amd-radeon-6800-xt/",
      "Because you‚Äôre ignoring literally every review that does not support TPU",
      "I don't consider this an efficiency win. Ampere is on a considerably worse node, has a bigger die, uses GDDR6X (80-90w) and still manages to perform similarly.\n\nImagine if this was apples to apples with Nvidia on a comparable node and it would be the same story as usual which is exactly what's going to happen when they make the move.\n\nEven now the core only power draw of a 3080 is in the 200w range with most of the rest of it's power budget going to VRAM. This is just my opinion but I don't see parity with Nvidia in rasterization as the incredible achievement it's being made out to be here. AMD had a huge opportunity while Nvidia sandbagged in favor or profit using what is essentially a 10nm node and still came up short. They will take a beating next go around.",
      "To be honest, while I dont care about power draw that much, its still nice not having a sauna in your room."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800xt",
      "rx6800",
      "6800"
    ],
    "title": "Anyone got experience with a Rx 6800/ xt with only a 550W PSU ?",
    "selftext": "\nManaged to get a RX6800 and thinking of using it with my ryzen 5 3600\n\nOnly problem is I have a 550W PSU. It‚Äôs an Corsair RM550 and it hasn‚Äôt even been in use for half a year\n\nWould also be interested in the performance with a 6800xt (maybe undervolted)",
    "comments": [
      "What's the power supply recommendation from AMD or the board partner? Follow that.\n\n\n\nAMD's website says 650W for 6800 and 750W for 6800XT.",
      "Don‚Äôt ever cheap on power supply. You may run it , probably gets black screen (an indication of insufficient power) but you‚Äôll also be putting all of the components inside your PC at risk overtime due to early degradation from maxing out your PSU. A blown out PSU can easily destroy your whole PC.",
      "Stick it in the computer. If it reboots at max. load, then the PSU isn't enough. It might also run fine for a while (months/years) until the PSU degrades and then it will start rebooting or causing other problems.\n\nThe best scenario is to follow the min. psu recommendations set by the manufacturer.",
      "I tried using a reference 5700 on a 500w psu and it‚Äôd occasionally reboot itself. I got a 650psu to prevent potential damage. If you have a 6800, id go no less than a bronze 650w. I‚Äôve since upgraded to a RM750 gold but used a power spec 650 on it just fine (with my reference 6800)",
      "1) Wattage isn't the end-all be-all of a PSU. It's much more than that. Efficiency, transient response, ripple. These are all just as important as wattage.\n2) Suggesting a wattage based on only the GPU is meaningless. A suggestion that does not at the very least also take the CPU into consideration is to be discarded. \nYou can run a 5950X and a 6900XT on a cheap 800 watt PSU and it can go out in fireworks, and you can pair it with a high quality 600 watt PSU and never have any problem.",
      "Any source for the \"degradation from running at max power\" ? Seems strange that the manufacturer would advertise unsafe power ranges for the product.\n\nLower efficiency at max power why not? But degradation?",
      "Shit 700W PSU can be a lot worse then good 500W PSU. It gets complicated. And the efficiency rating is not always a reliable indicator for PSU quality, but there's some correlation.",
      "u/str33tsofjust1c3 said what I came to say.\n\n\\*edit\\* I see now the RM550 only has one 8-pin EPS CPU connector on the PSU end, and one 8-pin PCIe connector on the PSU end, which means you'd be using a daisy-chain cable (one PSU hookup, two PCIe hookups on one cable).\n\nI would not run the RX 6800 XT on a single, daisy-chain PSU cable.\n\nThe RX 6800 would \\*probably\\* be fine...\n\nPSU Quality is SO much more than that pretty number on the side of the unit.  The Corsair RM series is a solid, basic, gold-rated PSU.  For an RX 6800, you shouldn't have an issue at all.  For an RX 6800 XT, so long as you didn't go ham with the power limit, and especially if you locked clocks to say, 2500MHz, and undervolted, I don't forsee you having issues.\n\nSpeaking in general, a few good \\*rough\\* feeler gauges of PSU quality are:\n\n\\- Price of the unit, compared to...\n\n\\- The max wattage rating, the max single-rail 12V amperage rating\n\n\\- The length of the warranty.\n\n\\- And the efficiency rating (though this is MUCH less important than the previous two items)\n\nRe: Warranty.  The warranty length is telling you the general quality of the electronics components used within a particular unit.\n\nMy rules of thumb are: A gold-rated PSU with a 5-year warranty is the \\**BARE*\\* minimum I would ever consider, and I would *only* buy it if there were NO other PSU's with a 7+ year warranty available.\n\n7-year warranties are the bog-standard for decent-quality Gold-rated PSU's.  A lot of gold-rated PSU's are coming with 10-year warranties now, with higher efficiency rated PSU's coming with 10-12year warranties.",
      "Because of transients tripping the OC protection.",
      "One thing about the psu, case, and fans, is that they can last you 8-10 years over multiple systems.  My cx500 is circa 2013 and it lives on with a 1700 gtx 1080 system I use as a backup.",
      "I'd say the same, don't go cheap on a psu. My last psu, Corsair HX520w, lasted me 12 years and still worked ok. I only upgraded it recently because of a new build. Also running a psu close to full load will kill it faster.",
      "Read manual I got a 6800xt and manual reccomend no less than 750w",
      "I have 5700 gaming x paired with a Pure Power 10 500w and never had a reboot (ryzen 3600)",
      "I‚Äôve seen my 6800xt hit 330w, that cpu will hit 120w = 450w and change... it‚Äôs damn close, too close I‚Äôd say. I have a 700w I‚Äôm not worried when recommended is 750w.. but 550w you say? Gulp.",
      "i'm talking about from the socket full system powerdraw",
      "with platnium efficency at 240V it's around 95%+ efficency so 532W for the components still extremly close to 550W",
      "I don't know enough, but it happened with the Vega cards and some Seasonic high-end models a few years back.\n\nWith more recent GPUs and their dynamic/opportunistic boost, it seems the problem is the fast load changes more than the mere wattage.",
      "Well OP if your reading this 6800 mostlikely fine 6800XT prob fine but if you start getting Black screen crashes Swap the PSU.\n\nthere everybody should be happy now",
      "That's marginal at best. Very marginal.\n\n[https://www.whatpsu.com/psu/cpu/AMD-Ryzen-3600/gpu/AMD-Radeon-RX-6800-XT](https://www.whatpsu.com/psu/cpu/AMD-Ryzen-3600/gpu/AMD-Radeon-RX-6800-XT)\n\nI honestly think minimum 600W as recommended by [whatpsu.com](https://whatpsu.com) is marginal. The PSU is most happy when it can deliver about 40-50 % of max rated, and a practical max is about 60 % of rated. Pushing it to max rated over time not only produces an ungodly amount of heat, but it also shortens the life of the PSU significantly, and potentially worse if you're really unlucky...",
      "Would not realy try that i got my 6800xt hooked up to a 850W platnium PSU and with wattmeter from the socket i'v had spikes up to like 560W and i'm on 240V so it's more efficent to compared to if you are in the states on 120V and your rocking a gold PSU"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "rx6800"
    ],
    "title": "Radeon RX6800 is overpriced IMO",
    "selftext": "I think the pricing of RX6800 is not right it's $80 more expensive than RTX3070 which is $499, yet RX6800 barely beats RTX2080Ti, also RX6800 lacks DLSS which is a huge deal moving forward. I think RX6800 should cost around $449 otherwise it‚Äôs DOA.",
    "comments": [
      "it's 18% faster on average.",
      "only with the smart access memory feature and you need ZEN3 for that. They didnt show \"stock\" 6800 performance.",
      "I disagree, 3070 is DOA because 8GB is not enough anymore at all. Games already taxing 8GB for awhile now. Probably why Nvidia is rushing a ti version with more VRAM.",
      "I do think the 16GB of VRAM makes it a bit of a better deal, but I'd also have preferred if it was a bit cheaper and the 3070 as well for that matter.",
      "It beats it by 15-20% and has double the VRAM. Some of you guys will never be satisfied i swear. Its a very good value product.\n\nI guess AMD should just start undervalluing their products and sell them for bargain prices to make some of you people will be satisfied.\n\nAnd lmao at the DOA comment. The hyperbole is strong.",
      "It beats 3070 in AMD select titles, we need to wait for real reviews before saying anything, but I still see NVIDIA advantage since it has DLSS which boosts FPS by almost 40%",
      "I think after benchmarks we're going to be left with the 6800XT as the only card worthwhile in this lineup.\n\nSame for NV and their 3080. The flagships from both companies look absolutely worth their costs but the halo cards are just looking like poor value and I'm iffy on the 3070/6800\n\nThe 3090 is ridiculous, the 6900XT looks like a 3080 + Zen3 helping it reach 3090 speeds. The 6800 doubles RAM of the confusingly low 8gb 3070 but the 6800 doesn't have DLSS.",
      "Do you really think the 3070 real market price will be 499?",
      "The 3070 basically matches the the 2080Ti. The 6800 beats them both, and has double the VRAM. That's how I see it",
      "I think it is unfair to say that 8gb is not enough anymore when in all the third party reviews the 3070 managed to match the 2080Ti even at 4K. It may not be enough for 4K in future, but at 1440p I am sure it will suffice for future games.",
      "Same can be said with AMD.",
      "Lol this. FE prices are a lie.",
      ">\"Remember, the 3070 handily beat the 2080ti also.\"\n\nLmao it does not. Where did you get that from. The 3070 and 2080ti are basicly matched in performance down to a 1-2% difference.",
      "I don't think you understand how GPU works. Just because your 5700xt is maxed at 1440p doesn't mean 8gb is not enough. If 8gb will bottleneck a 5700xt then how does a 3070 even match a 2080Ti the first place. Your 5700xt is being maxed out before it can even utilize 8gb of vram.",
      "Cyberpunk 2077 will have DLSS support",
      "KEK \n\nAccording to gamersnexus the rage mode accounted for just 1%-2% improvement. The 6800xt already matches 3080 native without rage mode or sam, look at the benches without those features enabled\n\n>Anythign above that was pushed by the ZEN3 smart access memory feature + RAGE mode\n\nwhat makes ya say that increasing cu count by 8 adds nothing to it? We have rumors of aib cards clocking to 2.3 or 2.4ghz gameclock. The 80cu card already beats the 3080 just by having higher cu count because it runs at similar clocks to the 6800xt which matched rtx 3080, it just has additional few % from sam and rage mode that brought it closer to 3090 for marketing bench purposes.\n\nThe claim that amd ain't gonna beat 3080's already wrong because 6900xt without rage mode and sam definitely beats rtx 3080 in pure raster. You were also wrong about amd showing their best card in the zen3 teaser.\n\nHey i can man up to being wrong about zen3 gaming performance (yea i overestimated zen3), seems you can't do the same when you're wrong",
      "I know what you meant the first time; your vram is maxed out at 1440p. What I am saying is that just because you see you 100% vram usage does not mean that it bottleneck factor. If that's the case then a significantly more powerful gpu like the 3070 with 8gb of vram would not perform the same as a 2080Ti at 4K. \n\nI am willing to bet that a 3080 with 8gb of vram will perform almost identically to a 3080 with 10gb of vram within a 5% margin.",
      "You didn't mention 6800xt? You said amd showed their best and they ain't gonna beat 3080\n\nSo you're just gonna ignore the 6800xt matching 3080 at native and assume that increasing the cu count by 8 and maintaining the same clocks ain't gonna put the 6900xt ahead of the 3080?\n\nThat's denial man, hilarious how ya were going ham on others calling them delusional and in denial but are exactly that rn",
      "Why ain't the math checking out? +11% cu on 6900xt with same clocks, +7% performance across titles (not perfect scaling) and +3%-4% to match 3090. 3090's on average 10% ahead of 3080. \"Sam\" ain't gonna add 10% performance on average, it's on the low side between 3%-6% with outlier at 13%\n\nAin't gonna matter if it's 10% ahead of the 3080, even if it's just 5% ahead without sam and rage mode it's already ahead",
      "Didn't the 6800 use the smart thing too? So technically its less FPS then the chart if you don't have a new cpu?"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800xt",
      "6800"
    ],
    "title": "4060ti or 6800xt ? Which one should I buy, in your opinion.",
    "selftext": "I am stuck between getting a 4060ti (16gb) or a 6800 AMD gpu   \n\n\nI have always had a Nvidia GPU so don't know much about AMD   \n\n\nIs the XT version like TI / SUPER ?   \n\n\nIf you were in my position which one would you get ?  \nThanks, and sorry for my lack of knowledge.   \n\n\n&#x200B;",
    "comments": [
      "if you're gonna be using it for mostly gaming and don't need any software using CUDA cores, get 6800xt, it's not even close. Both rx6800 and rx6800xt are gonna beat every version of 4060 and 4060ti in gaming.",
      "If you will do any blender or 3d modeling work on or if you want to use Ray tracing, nvidia is the best at that. So 4060 ti is the way to go. Though if you just want better fps go for 6800xt",
      "If you will do any blender or 3d modeling work or if you want to use Ray tracing, nvidia is the best at that. So 4060 ti is the way to go. Though if you just want better fps go for 6800xt",
      "6800xt easily i would say that is if you can find one. I was in the same predicament a week or 2 ago. My 2080ti started artifacting in March and  i wanted something that could replace it for another 2ish years untill i build a new pc. Everything i saw pointed towards the 6800xt but in the UK i just couldnt find it at all and im not really a used/refurbished kinda buyer so got a 7800xt on early black friday deal for pretty much the same price as a 4060ti 16gb. Just make sure you do the DDU steps correctly and the switch over to AMD should be fine- its not ideal imo as fresh install of windows is better but it does the job",
      "Thanks"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "rx6800",
      "6800"
    ],
    "title": "RX6800 vs RTX3080",
    "selftext": "I managed to snag a 6800 on launch, and have the opportunity to trade it for a 3080 at no extra cost to me. I am wondering what everyone‚Äôs thoughts are on this? \n\nI game in 2K at 144hz. Plan on playing the new cyberpunk game. \n\nWhat are the pros and cons?",
    "comments": [
      "If it‚Äôs a 6800 non-XT then you definitely should trade it in",
      "I'd trade a XT for a 3080",
      "Literal no contest the 3080 is same level as the XT this is a no brainer for upgrading basically.",
      "You'd be foolish not to take that trade.",
      "Do it, even it if were xt model. 3080 is just more mainstream atm. With dlss2.0 and rtx if you would want to use.",
      "Yes it‚Äôs a reference design 6800 non XT",
      "False narrative that keeps poping up. Without RT games, without DLSS :\n\n[https://www.3dcenter.org/artikel/launch-analyse-amd-radeon-rx-6800-6800-xt/launch-analyse-amd-radeon-rx-6800-6800-xt-seite-2](https://www.3dcenter.org/artikel/launch-analyse-amd-radeon-rx-6800-6800-xt/launch-analyse-amd-radeon-rx-6800-6800-xt-seite-2)\n\nWith 6800XT normalized (100%)\n\n1080p : 3/13 sites 3080<100%,  103.5% avg.\n\n1440p : 2/17 sites 3080 < 100% ,  103.7% avg.\n\n4k  :  0/17 sites 3080 <100%, 107.4% avg.\n\nRT 1440p :   127,6% for 3080.\n\nA few patterns emerge also, the less tests, like \\~9 games, mostly a similar list to AMD's, show the 3080 under, or other with some gimped DDR4 speeds (2933) which seems to bottleneck the 3080 somehow at low resolutions.",
      "Trade it. It's pretty much a no-brainer.",
      "Don‚Äôt you bring the truth here!",
      "If it‚Äôs a 6800 non XT I would say do it. The 3080 will still trade blows with rasterization but come out on top  60% of the time. However the 3080s RayTracing is far better.",
      "Sounds like a pretty good deal. Go for it.",
      "Sounds like a deal too good to be true",
      "It also loses out in 4k and DLSS makes the gap even larger",
      "Um, who the fuck's just *giving* you a 3080 for a 6800?\n\nIs there anything else to this?",
      "Someone offered me the price of a 3080 for my 6800 and I am able to place an order through a local shop for a 3080.",
      "It could be on backorder for a few months, so I'd confirm when stock will arrive at your store first.",
      "It's objectively faster. Not sure what you're smoking but nvidia use standard dxr api for directx game. The only proprietary stuff nvidia used was vulkan rt extension because untill recently vulkan didn't support ray tracing at all.",
      "You do know AMD has been in console forever.  By your logic this should have happened 5 years ago",
      "Nope! Just dropped off my card and heading to the store tomorrow to order a 3080",
      "The xt beats the 3080 in most games that are not ray-traced though. Can be a bit of a toss-up"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800"
    ],
    "title": "Need suggestions: is a 650W PSU enough for the RX 6800??",
    "selftext": "Hello, as title says, will a 650W PSU be enough for a Gigabyte RX 6800 Gaming OC? Or should I go for something slightly less power hungry like the RX 6700 XT?\n\nThe PSU is Seasonic Focus SGX-650. Full [specs](https://seasonic.com/focus-sgx#specification) here.",
    "comments": [
      "Yeah amd recommends a 650 for the 6800 and they pad it generously bc they dont know if you have a 65w cpu or a 200w threadripper.\n\nYou aren't pairing it with a 200w threadripper are you?",
      "You're totally set then, enjoy it!",
      "Yes, it's fine",
      "Ahah no, I'm running a quiet 3700X, two M2 and couple of fans. That's all.",
      "They pad the power rating because peak power draw is much higher then continuous power draw.  A 6900XT might consume 314w full load but it'll spike up to around 600w for 20ms periods.  It's gotten to the point where the upcoming new ATX PSU standard requires new PSUs to be able to handle 2 times their stated wattage for short periods of time (when in reality they should improve the DC to DC converting on graphics cards to prevent these spikes).  I'm really not a fan of these because if these spikes increase on next gen GPUs (which is likely given the increased power draw rumors) it means that more people will have to buy new PSUs.  For how expensive modern GPUs are, they should be able to afford the couple of cents in hardware to tame these spikes and I expect it'll cause people headaches.",
      "same i run my 6800XT on Strix 650W",
      "AMD recommend a 750w but power supply being enough would also depend on CPU pull and all other components in system and if you are going to overclock..\n\nIf you have a 700w power draw for total system you want to be in the 70% efficiency range. Of the PSU so you would need a 1000w to leave room for minor upgrades and overclocking \n\n\nYou want power cables for each plug on GPU no pigtails a cable for each plug to reduce possibly of not enough power through a single cable.  \n\n\nLack of power can cause system crash. It can also cause black screens and other system issues never cheap out of power supply get a good one it's worth it when you are powering $1000 dollars of hardware. And a cheap power supply can die and take hardware with it.",
      "I run 3700x and 6800 on a 600 Plat no issues whatsoever",
      "I have the same PSU with a 3600X and an RX 480, so a total TDP of 215W, even at full load the PSU is under 50% load and the fan doesn't start. The 3700X and RX 6800 are at 315W so your PSU will also stayt quiet most of teh times",
      "I have a seasonic focus 650w running with a 9700k and a 6800.\n\nBeen running since 2019 like a charm.",
      "I ran my 6800 on a very good quality 530W beQuiet! Pure Power PSU with a 5900X, so it can be done.",
      "Thanks for your feedback.",
      "Thanks!",
      "this is the only card that measured power spike 20ms.\n\n[https://www.techpowerup.com/review/asus-radeon-rx-6800-strix-oc/35.html](https://www.techpowerup.com/review/asus-radeon-rx-6800-strix-oc/35.html)\n\n[https://www.techpowerup.com/review/powercolor-radeon-rx-6800-red-dragon/](https://www.techpowerup.com/review/powercolor-radeon-rx-6800-red-dragon/)\n\nreference : 318w , Asus : 334w , Power color: 338w\n\npower spike can be related to black screen so forget about sustained power consumption\n\njust grab 750w. I wish there was an additional spec that AIB could tell us what are their value about power spike.\n\nYour PSU datesheet doesn't say Single rail or Multiple-rail but i think it's single rail then I see no problem.\n\njust read more comments :\n\n[https://www.reddit.com/r/Amd/comments/l99p1w/amd\\_6900xt\\_power\\_spike\\_is\\_real/](https://www.reddit.com/r/Amd/comments/l99p1w/amd_6900xt_power_spike_is_real/)",
      "I am getting a 6800 with 650W and it should be completely fine.",
      "There are GPU calculators where you can plug your PC specs in and it will tell you the suggested GPU to use. EVGA has one on their website.",
      "When companies make up these PSU requirements they play it safe and expect your PSU to already have 10 years of wear with 4 mechanical drives and 2 optical drives installed. I've never had problems running a video card that recommended 50 or 100w more than my PSU, if you're only running 1 or 2 ssd's and your cpu only has a 65-95w tdp then go for it!\n\nThe only thing you shouldn't do is put a high end card in a low end pre-built workstation with only 250 or 350w. Also never use molex to pcie adapters, always make sure your PSU has proper separate pcie cables for every connector on your video card, never daisy chain them!",
      "If you can afford it atm, I would counsel going with something like a Corsair 850W PSU--not because your current build needs it, because it doesn't, as many have correctly stated.  Your 650 should do fine.  But  in 1-3 years when you get ready to upgrade to a much more serious system, if you do, you will more than likely already be set with a PSU that could last as long as a decade, maybe.  I've got a Corsair, HX-850, fully modular, and I've had it for a long time and during all kinds of hardware upgrades it has performed well without so much as a squeak.  Right now it's pushing an Aorus x570 Master with a 3900X, 5 hard drives and two NVMe drives, totaling \\~10TBs, a DVD writer, 32GB (4x8GB) of system ram running at 3733MHz, and an AMD 50th Anniversary ED 5700XT, with the GPU and boot NVMe runn in PCIe4 mode, and some other stuff which I cannot recall atm...;)  I game at 4k, with two Noctua CPU fans--push-pull--and three Noctua case fans.  And I've never had so much as a squeak out of the PSU in complaint...;)\n\nThat's all I wanted to say about that...;)  Have fun!",
      "It's fine for me 5600x, B550m TUF Plus RX6800 EVGA G2 650W Gold",
      "Even 550 is enough, I run that with a 3900x and RX6800."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "rx6800"
    ],
    "title": "RX6800 XT Merc319 Core + Ryzen 7 3700x + 32GB 3600mhz <3",
    "selftext": "",
    "comments": [
      "excellent performance, the only downside is a little coil, but other than that it's excellent, very good temperatures. low fan noise",
      "Niceee",
      "How the 6800xt performs ?"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800xt",
      "rx6800",
      "6800"
    ],
    "title": "RX6800 Morpheus 2 Mod",
    "selftext": "I did the absolut mad thing of taking my reference 6800 apart and mounting a Morpheus 2. I realized the great OC potential but did want the card to stay quiet. So I took it apart shelved the front and backplate (if you drill four holes you can keep both on like with vega) and mounted the better cooler.I had not drill at hand so I did go for custom VRM cooling:\n\nhttps://preview.redd.it/l0ryi8ucc1661.jpg?width=4000&format=pjpg&auto=webp&s=78acf5d41549c9fe5c49fde417be867b0deb10fb\n\nhttps://preview.redd.it/ydqrczcec1661.jpg?width=4000&format=pjpg&auto=webp&s=d57821f1746c4f06c4f66c12de847b1fb9f689aa\n\n[ thermal glue and paste combo](https://preview.redd.it/6hx0ncsfc1661.jpg?width=4000&format=pjpg&auto=webp&s=dfb474d42e2f65d100c5ba28c1b571bf52686405)\n\n[ One small cooler to the left of the die is still missing in this picture](https://preview.redd.it/s8kwonmjc1661.jpg?width=4000&format=pjpg&auto=webp&s=fac95c043667788b3741576ca42fa696406054e6)\n\n[ The cooler barely covers the whole chip](https://preview.redd.it/53eh8m8mc1661.jpg?width=4000&format=pjpg&auto=webp&s=356bb8b875b4b3f18d106dfcf950c1c3e0b12beb)\n\n[ Mounting it with enough \\(but not to  much\\) pressure was a little tricky, I later used the Morpheus bracket  below the Vega one to get more pressure. \\(The 6800 bracket has smaller  holes that would need drilling to fit morpheus screws\\)](https://preview.redd.it/b3gnx1qqc1661.jpg?width=4000&format=pjpg&auto=webp&s=3510098a0d6a42ab17bc636694b15511957aaf4f)\n\nhttps://preview.redd.it/x7b5essuc1661.jpg?width=4000&format=pjpg&auto=webp&s=6c3bba754386a27d34b84c89a2a34c3beb56498c\n\nHotspot temp in idle is 5¬∞C above core and while benching within about 15¬∞C. Idle 35/40¬∞C, gaming max 60/75¬∞C.  All \"noise\" is gone and temps are much better, so I call it a success. I did not yet beat my TimeSpy scores but those where pretty crazy anyway (16 837 GPU Score). I get almost reference XT performance with OC. Non demanding titles dont even activate the fans. (e.g. csgo capped at 600fps stays below 55¬∞C with passive cooling)\n\n[ In SOTTR at WQHD it is matching 6800XT performance with 2444Mhz Core  2150Mhz Mem. Holding 2390 - 2400Mhz. I am using reference 6800XT power  limits with 1150mV Vcore. ](https://preview.redd.it/otmc0updd1661.png?width=2560&format=png&auto=webp&s=d4e3c2c8bb10d9cc398f4ad4d5d3a97a49361856)\n\n[ Ultra with RT about 15Fps more than what I saw in stock benchmarks, also XT territory](https://preview.redd.it/exrmej7ed1661.png?width=2560&format=png&auto=webp&s=8cc9bf23a64d266e468f571f602e468c491e3b20)\n\n[ sottr temps](https://i.redd.it/9zl9kw4hd1661.gif)\n\nWas it worth it?Yes it is cooler and quiter. Performance did not change signifcantly, maybe a few mhz more for my stable oc. Max Benchmark clock did not change even whith 10+¬∞C better temps.\n\nSo if you have a morpheus lying around go for it. Otherwise the reference cooler is good enough even for top 100 scores. There is always risk of damaging something. Imagine being me after switching the cooler, trying to boot and get \"AGP Error\" beeps with my old vega (swapped the cooler) and the new 6800. Turned out my mobo just wanted twenty minutes of no power no battery time before it worked again (swapped again).",
    "comments": [
      "Thanks for sharing! Never seen anyone doing the Morpheus mod on a RX 6800 before. Great results tbh üòä",
      "Nice to see that it works! I had a Morpheus II on my 1080 Ti. It was a Inno3D X3 ultra edition, but the cooler was bad. Always had temps at 80c and the card would throttle. With the Morpheus II and two ML120 fans my temps dropped to 52c and clocks were stable at 2050Mhz, while staying silent.\n\nFor the Radeon 6800 series I think the Morpheus 8057 is a better option than the II. The heatsink dimensions on the 8057 are 40x38mm vs 40x32mm on the II. You'll have better coverage on the core with the 8057.",
      "I put one on a Vega 56 and shit was hilarious. 1600Mhz rock steady levels of hilarious.",
      "Hey, what is your total card height(incl fans)? i want to know if this would fit in my NR200",
      "I've been wanting to pick up a Morpheus to cool my 7970 while I wait for a 6700 to exist & be in stock. \n\nDoes the 8057 come with newer mounting brackets? Think I'll have trouble mounting it to such an old card in the interim?",
      "Yeah, your temps are looking pretty good though. The 5000-series had massive issues with GDDR6 temps, even with much bigger heatsinks than yours and heatsinks+active cooling on the back of the card I can barely get temps below 90¬∞C. Seems that the new chip casings have better thermal conductivity",
      "Can you link your 3DMark Timespy result? My 6800 only gets 15,512 with the max frequency set at 2450MHz. Can't complete Timespy with any higher frequency. Curious what your frequency is to get >16k.",
      "What are your VRam temps (if the card gives a readout of those)?\n\nGDDR6 is a bitch to cool, chances are you are cooking them",
      "Hi,\n\nI've bought used Raijintek Morhpeus Core for Radeon VII, but soon bought Silverstone FT02, so was not sure if it will work rotated.\nBut I wonder if this \"Morpheus II core\" would work on 6800XT, or if I need special version for this GPU?\nHave you tested it in 90deg rotated position? (I use Silverstone FT02 case)",
      "Will the morheus 8057 fit the sapphire 6900xt?",
      "This is great! I have a Morpheus II Core lying around and a new 6700 XT.  \n\n\n[u/Falk\\_csgo](https://www.reddit.com/user/Falk_csgo/) If you want more performance from the 6800 ref, you can use the MorePowerTool (MPT) to raise power limits. You mention above using a Vega AND Morpheus mounting bracket, did you use a bracket from another card, or only what was included with the Morpheus?",
      "With 25mm fans about 77mm, backplate not attached, so better take 8cm",
      "Sure, place 73 gpu score: [https://www.3dmark.com/spy/16369088](https://www.3dmark.com/spy/16369088) Freq I set the card to was actually 2544Mhz but it does not reach much more than 2500.Also cooling is important, I opened the windows and cranked my case + gpu fans to server mode. The rest is silicon lottery I guess.\n\nOh and this was only bench stable, my everyday oc ends below 2450Mhz. Above 2500Mhz I had crashes in timespy every few runs, but still stable enough to go for it.",
      "How do I read my VRam temps?\n\nhwinfo64 Memory Junction?\n\nThis is after 15min of stresstesting with MSI Kombustor - FurMark Donut:\n\n[https://imgur.com/a/lJsOgWp](https://imgur.com/a/lJsOgWp)",
      "Hi, I used a Raijintek Morpheus II Core Black. And the XT reference design is the same pcb except the actual die, so it should work.\n\nI did not test 90¬∞. But if you want to do 90¬∞ with normal motherboard mounting (no vertical gpu mount) the heavy weight probably has to be supported somehow or you risk your pcie slot. Oh wait :D you mean vertical gpu mount not cooler 90¬∞ on the gpu xD I am getting tired!\n\nBe aware that you might need extra washers for optimum mounting pressure. Have a drill ready so you can use the original front and backplate to keep the card rigid.\n\nAnd if you do this dont forget to post results :)",
      "Im not sure, what is the difference between the 8057 and 2?\n\nAlso the upgrade from 6900 stock cooler to a morpheus does not have as much potential as for a 6800 since the stock cooler is bigger.",
      "I was just looking at the mounting points of the 5700 XT and 6700 XT on techpowerup and they \\*appear\\* to be the same. \n\n  \nDM me if you want to buy a Morpheus II Core, NIB. I purchased it for my Nitro+ V64 and never needed it.",
      "thanks!",
      "Thanks!",
      "Thanks for reply. So I'm happy I haven't sold Morpheus.\nCould you point me what I need to drill? (I've got drill)\n\nAbout 90deg mount, not only GPU, but whole botherboard. Look for Silverstone FT02, RV01 or RV02. Its superior cases, but problematic with so many coolers."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "rx6800",
      "6800"
    ],
    "title": "RX6800 and RX6800XT in stock in UK",
    "selftext": "[https://www.overclockers.co.uk/search/index/sSearch/rx+6800/sPerPage/12/sPage/1](https://www.overclockers.co.uk/search/index/sSearch/rx+6800/sPerPage/12/sPage/1)\n\nMany available as of 19:22",
    "comments": [
      "Actual Fact: That wasn't erroneous, it was to purposely give the forum users\\\\regular customers a chance!\n\n&#x200B;\n\nit's quite good actually, very clever. \n\n3d printer - more like 3d virtual printer",
      "OCUK so its no surprise the rip off merchants",
      "Fun fact about why they're not selling that fast:\n\nthey are erroneously categorized under 3D Printers:  https://imgur.com/LqLVija",
      "Wow ridiculous pricing",
      "Approaching ¬£1K for a 6800XT (yes I know it's a Limited Edition version) and hovering around ¬£800-900...  \n...no thanks. I'll wait for the next gen of GPU releases at this rate.",
      "Got  a Sapphire Reference RX 6800 this after noon about 3pm ¬£599. Over the moon. \n\nThere is still 6800 available. its a good one too ¬£700 unfortunately  [‚ñ∑ Sapphire Radeon RX 6800 Pulse 16GB GDDR6 PCI-‚Ä¶ | OcUK (overclockers.co.uk)](https://www.overclockers.co.uk/sapphire-radeon-rx-6800-pulse-16gb-gddr6-pci-express-graphics-card-gx-39d-sp.html)",
      "3D printers? more like money printers selling them for a grand a pop when they should be 700ish for partner cards.",
      "According to that page, they have at least 60+ of various 6800/6800XT AIB models in stock.  Impressive.  Wonder how fast they'll go?",
      "They've got the 6800s priced so close to the 6800XTs there's no reason to buy a 6800 until the XTs are out of stock.",
      "And not a one in the US AMD store.",
      "They haven‚Äôt got shit on CCL and AWD tbf",
      "Radeon RX 6800 XT NITRO+  ¬£900 = $1234.82\n\nI would rather buy from ebay scalpers then these scumbags.",
      "Sapphire 6800XT Nitro+ for 900GBP/1200USD is hilariously preposterous and I guess I'm going to stay on 5700XT until it dies and then find a hobby where it doesn't feel like I'm stuffing banknotes into a shredder.\n\nI've pretty much impulse bought fun things for more (coincidentally, a 3d printer for instance) but I refuse to spend this much on something that brings this little on principle.",
      "What are the msrp on these cards? As I know overclockers heighten the prices but not sure how much they have done so for these",
      "Think im just gonna stick to my 480 with those prices üòÖüò≠",
      "God, ¬£700 for the lower end flagship card.\n\nI remember paying ¬£90 for an HD 3850.",
      "Limited Edition really doesn‚Äôt mean much this time.",
      "I got this same card from overclockers today, are you impressed with it??",
      "Apparently they've been up since about 3pm according to the forums (I saw it there before seeing this thread). That's 7 hours at this point.\n\nWon't last long once the wider internet figures it out though.",
      "The 6800XT Nitro+ would be around ¬£720-¬£750 if there was no shortage. The OCUK price is ¬£859.99 right now so an extra ¬£110. If you have an old gpu to sell then it balances out since you would probably get an inflated price for it on ebay."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800xt",
      "rx6800",
      "6800"
    ],
    "title": "1440p : RX6800 or RX6800xt",
    "selftext": "It is difficult to make a decision.   I run games at 1440p and I don't think I am going to get a 4K monitor soon.\n\nRX 6800 are sporadically pop up here and there but the price difference between the 2 is not much.  I am wondering if I should go for 6800 now since I would not be a person that would benefit much from the 6800xt.  Am I wrong ?",
    "comments": [
      "6800, costs less. Since both are not ready for ray tracing, chances are in 2 years you will want to upgrade again to buy a gpu with good RT. If you're not worried about that, at msrp, I'd get the XT, the difference in price isn't high (the performance jump isn't high either, but if you can afford both, 70 is good to have the better card)",
      "Personally I would just get the 6800XT considering the small 10% difference in MSRP price. But finding something at MSRP is very hard so I would just get what you can at this point.",
      "For what it's worth, even if you buy a Ray Tracing card in 2021 you'll still probably need to upgrade it in two years.  If folks think a 3080 is going to have great Ray Tracing performance in 2022, even though it didn't in 2020, they're gonna have a bad time.",
      "The XT is ~15% faster and costs ~10% more.\n\nSo it's actually better price/performance ratio than the 6800 which is unusual.\n\nBoth are good though, if you can get them at MSRP its not going to make a world of difference.",
      "Surprised there are no \"but it has DLSS so it's ok\" answer to your comment yet.",
      "the 6800 vanilla would probably be more than enough in most cases.... it's last i checked, still the best bang for the buck. Obviously the 6800xt will have a definite edge over it... but that's entirely up to you.",
      "6800 non xt",
      "Get the RX 6800XT",
      "6800XT due to the fairly small price premium over the 6800",
      "As mentioned. How things are going we may be looking at throwing the 69XT to bin in a year or two if all new AAA games come out with RT stuff like CB2077 as RDNA2 is currently quite week with RT. If nothing major happens in the software department it is more than likely that RDNA3 will be way more powerful with RT, like double or triple, and at this point the RDNA2 cards are quite literally struggling.\n\nSo bearing this in mind we need to look at the price vs performance vs longevity formula. And if all RDNA2 cards will be scrap when next gen hits, in a year or two, then getting the cheapest option is the wisest decision, unless you are sleeping on piles of money, then of course get the best there is everytime.",
      "The idea of rdna2 being garbage in a gen is laughable. It's the same tech the consoles have, it's gonna be optimized toward for many years to come.",
      "Only game I have that the 6800 struggles to play a bit at high/ultra 1440p is Cyberpunk 2077, but even then it gets in the area of 70-80 FPS, everything else I play the 6800 stomps on at 1440p.\n\nThat said, if I'd had the option I would rather have the 6800 XT.",
      "The RX 6800 might be fine. I have the 6800xt and for the most part can play games 4K 60 max settings. I think 1440p has half the pixel count of 4K, so it'll be a lot easier on the card to get playable frame rates. I'l probably go for the 6800xt because you'll probably want to upgrade after 2 more generations unless next year's cards are 30-50% better.",
      "I went with the first one I could buy msrp (msi 6800 from best buy). I am extremely happy with it. 1440p 144hz paired with 2600x until my 5600x arrives. Upgrading from a heavily overclocked/uv pulse vega 56. Really a great Reference design vs. the 5700 or vega lineup.",
      "I got the non xt because I just felt like it was all I would need now and later on when something else shiny pops up.",
      "I guess im a bit late for this but i figured i would post anyway.\n\nInitially i had aimed for the 6800XT or 3080 since i planned to get a 1440P monitor.\n\nBut when i found a Reference 6800 for a good price i could not pass it up so i ended up going with that.\n\nAnd i had no reason to worry regarding to 1440P performance.\n\nIt has no issue running current games in 1440P\n\n(I get 70-80 in Cyberpunk 2077 at ultra settings and it feels / looks perfectly smooth and the same with my flight sims etc)\n\nSo i would say in regards to todays games the 6800 is prefectly capable for 1440P.\n\nNow if i would have had an option for a 6800XT for 70 usd more i probably would have taken it.\n\nBut the 6800 is prefectly fine for 1440P and i have no issues or complaints with it so far.\n\nEverything runs prefectly smooth.\n\n(And the reference card runs extremely cool and quiet as well with temps of 58-62C att full load with the fans at 30-35%)\n\nSo to summarize my opinion. \n\nIf you want the 6800XT (and can get it) then sure go for it.\n\n (Since it is more powerful and the MSRP price difference isnt huge)\n\nBut the 6800 seems to be perfect for 1440P (as of now atleast)\n\nso if you do not want to wait for a 6800XT i dont think that a 6800 will disappoint you.",
      "I suggest wait for FSR, and then make final verdict about RT",
      "Where I live I saw price difference of around 20% to 23% going from a 6800 to 6800 XT, depends on the models of course, the \"big\" retailer with multiple stores (sometimes more than one per city) even have some in stock at some stores, and in stock at the warehouse for online orders, meanwhile the specialized retailers that have a single / several stores stores across the country (they deal mostly on the web store) have them at higher prices and limits them to a whole PC purchase, funny. Personally I \"want\" an 6800XT but REALLY cant justify upgrading the 5700XT, its not twice as fast at 1440p and ray-tracing performance are 2070-2080 levels, so logical thing would be to wait a gen.. but hey, who does that \"logical\" thing.",
      "Did your comment Age fine ? Or were you wrong cuz we‚Äôre in 2022 now",
      "DLSS is fantastic, game changing technology, and I'm a huge fan of it!  But at the same time, if Ray Tracing is going to grow more complex with time (and I imagine it will) then DLSS will have to make similar advances in performance to compensate for the extra processing.  \n  \nNow to be fair DLSS could improve more quickly than Ray Tracing does, and if that's the case then yeah, 2020's RT cards are going to hold out a bit longer.... but when one has to depend on *two* technologies at once to get a playable framerate, that creates potential negative conflicts and consequences.  \n  \nAs of right this moment I'm not convinced that Ray Tracing is more than a gimmick.  In five or ten years it could be the industry standard, but today, in 2021, I just don't think the tech is ready for primetime.  A lot of these games don't present a significant visual improvement over rasterization, but *all* of them have a 20% performance hit.  (I've been reassured repeatedly that my opinion on Ray Tracing is wrong, though, so take what I said with a grain of salt.)  \n  \nDLSS is cool, Ray Tracing will be cool, but if somebody is getting a top of the line RTX GPU in 2021 and expecting it to perform really well in Ray Traced games in 2023, I just think they're going to be disappointed is all.  God bless early adopters, I guess."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800xt",
      "rx6800",
      "6800"
    ],
    "title": "Waterblocks for Smaller Reference Radeon RX 6800 PCB - Pulse 6800 - Fighter 6800 - Are any actually being created???",
    "selftext": "I noticed Bykski had designed an A-RX6800-X waterblock on AliExpress, based around a smaller reference RX 6800 PCB, however when I ordered one I was sent the larger A-RX6900XT-X waterblock, which was for the larger stock reference boards (I was later told that the A-RX6800-X was only an illustration).\n\nFrom my research online, the smaller reference Radeon RX 6800 PCB seems to be the basis for the Sapphire Pulse 6800 & Powercolor Fighter 6800. I'm wondering in these crazy times of graphics cards, if anyone is actually doing waterblocks for these 6800 cards, that can occasionally be purchased, as opposed to the standard reference that have basically never existed in any reasonable numbers (at least here in Australia).\n\nThese cards are faster than the geforce 2080ti and 3070 cards, and can sometimes compete with the 3080, and yet the slower, older 5700xt pulse seem to have plenty of waterblocks available.\n\nI was originally hoping to buy a reference 6800xt, (which would have made the waterblock search easy), but could only find a Pulse 6800 for around the same price. Now 6700XT cards are even more expensive locally than both of their much faster stock siblings, were originally sold for.\n\nIf anyone has found a waterblock for the Sapphire Pulse 6800, would you please let me know?\n\nhttps://preview.redd.it/2846jq14f8q61.jpg?width=706&format=pjpg&auto=webp&s=6f1e32664fc6fd91ba3c587a8a010c2b4c106247",
    "comments": [
      "I‚Äôm pretty sure Bykski does actually sell a separate block with the A-RX6800-X name, and that it‚Äôs not just an illustration of the A-RX6900XT-X block. If you look closely at the photos, they are actually different blocks, so I reckon your seller sent you the wrong product and then tried to claim that it‚Äôs all the same thing.\n\nEDIT: Bykski also lists a block by the name of A-SP6800-X for Sapphire 6800 cards, so that one might fit the Pulse if it has a different PCB from reference cards.",
      "I'm still waiting for someone with some inside knowledge.  The pulse 6800 is quite a beast of a card (2500mhz+) and quite energy efficient.  I would love to be able to add it into my custom loop which has plenty of headroom available...",
      "I think I just found the waterblock. The Bykski A-DL6800-X has just been released. It should fit the Sapphire Pulse 6800, Powercolor Fighter 6800, and the Dataland X-serial 6800 model, which all look like they share the same PCB layout.\n\n[BYKSKI A-DL6800-X](https://imgur.com/a/dprkdma)",
      "http://imgur.com/gallery/7VRkjif",
      "I can't find any pcb pictures or diagrams of the 6800xt pulse. The pulse 6800 is based on a smaller amd reference board design, also used by powercolor fighter & dataland x series. \n\nThe only thing I can find from techpowerup is the pulse 6800xt has a slightly longer heatsink than the 6800xt nitro. U might need to disassemble it to check if it uses the amd reference or nitro, which should have waterblocks, or another model out there. Make sure you check the vrm clearances for compatibility. The ek site also has some compatibility photos & diagrams which may be useful. \n\nGood luck.",
      "The A-SP6800-X waterblock is for the Nitro 6800. I was told from a Bykski AliExpress store the A-RX6800-X was not actually physically available, it was only listed in online pictures. They provided the A-RX6900XT-X block which will fit all the the standard stock AMD reference parts.\n\nThe Pulse 6800 and Fighter 6800 closely resemble the smaller 6800 AMD reference design that is shown in the diagrams of the A-RX6800-X waterblock\n\n[Smaller Reference RX 6800 PCB - Pulse & Fighter](https://imgur.com/a/e8p8bOT)",
      "Did you ever find out if they work ?",
      "Did you ever find any new information? I have a pulse that I desperately want a waterblock for.",
      "It should arrive any day now. I saw someone show it installed on what looked to be a powercolor fighter 6800 card. So fingers crossed the pulse fits as well",
      "Unfortunately, still waiting.  The ali express seller said they would let me know if a compatible block ever became available.  It's a shame amd only produced the 6800 on the larger 6800/6900xt reference design boards and not the smaller reference design pcb sapphire and powercolor utilised. \nIt seems crazy that most of the much slower mid range 5700 series have waterblocks,  but many of the high end 6800 series have nothing available yet...",
      "I think I just found the waterblock. The Bykski A-DL6800-X has just been released. It should fit the Sapphire Pulse 6800, Powercolor Fighter 6800, and the Dataland X-serial 6800 model, which all look like they share the same PCB layout.\n\n[BYKSKI A-DL6800-X](https://imgur.com/a/dprkdma)",
      "Thank you so much. I‚Äôll probably get it when i get back from vacation. If you get it let me know if it works for you.",
      "I have ordered one from AliExpress. Its on its way & should arrive in the next week or two. Ill post up how things go. The initial A-RX6800-X waterblock design didnt account for the bottom capacitor nearest the pci-e notch that this one seems to overcome with a larger cut out, which I guess its why it was never made.",
      "It fits nicely. U might need to use the included thermal pads along with the grey thermal clay already on the board to properly connect the PCB to the VRM and memory, on the main block and the back plate to ensure you achieve the best results. I went the full hog by also  using conductonaut liquid metal on the core and surrounded it with nail polish to protect the components around it",
      "Thanks for testing and the info.",
      "How have temps been holding up? Any issues?",
      ">A-RX6800-X waterblock\n\nDid you ever get yours for the pulse?"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800xt",
      "rx6800",
      "6800"
    ],
    "title": "EK-Classic Water Block for the Radeon RX 6800, RX 6800XT, and RX 6900 Graphics Cards!",
    "selftext": "EK release custom Cards blocks..\n\n[https://videocardz.com/press-release/ek-announces-classic-waterblock-for-amd-radeon-rx-6900-and-rx-6800-graphics-cards](https://videocardz.com/press-release/ek-announces-classic-waterblock-for-amd-radeon-rx-6900-and-rx-6800-graphics-cards)\n\n&#x200B;\n\n**Current Compatibility List for EK-Classic GPU Water Block RX 6800/6900 D-RGB**\n\n* AMD Radeon RX 6800\n* AMD Radeon RX 6800 XT\n* AMD Radeon RX 6900 XT\n* ASRock Radeon RX 6800 16GB\n* ASRock Radeon RX 6900 XT 16GB\n* ASUS Radeon RX 6800 XT 16GB\n* ASUS Radeon RX 6800, RX6800-16G, 16GB GDDR6 (90YV0FY0-U0NA00)\n* ASUS Radeon RX 6900 XT 16GB (RX6900XT-16G)\n* BIOSTAR Radeon RX 6900 XT 16GB\n* Gigabyte Radeon RX 6800 16GB (GV-R68-16GC-B)\n* Gigabyte Radeon RX 6800 XT 16GB (GV-R68XT-16GC-B)\n* Gigabyte Radeon RX 6900 XT 16G (GV-R69XT-16GC-B)\n* MSI Radeon RX 6800 16GB\n* MSI Radeon RX 6800 XT 16GB\n* MSI Radeon RX 6900 XT 16GB\n* PowerColor AMD Radeon RX 6800 16GB GDDR6 (AXRX 6800 16GBD6-M2DHC)\n* PowerColor AMD Radeon RX 6800 XT 16GB GDDR6 (AXRX 6800XT 16GBD6-M2DHC)\n* PowerColor AMD Radeon RX 6900 XT 16GB GDDR6 (AXRX 6900XT 16GBD6-M2DHC)\n* Sapphire Radeon RX 6800 16GB\n* Sapphire Radeon RX 6900 XT 16GB (21308-01-20G)\n* Sapphire RX 6800 XT 16GB\n* XFX AMD Radeon RX 6900 XT (RX-69TMATFD8)\n\nsource: videocardz\n\n&#x200B;",
    "comments": [
      "Oh, finally!\n\nI hate the vector series design with that space wasting RGB piece at the very end.",
      "agree.. i fixed it with milk glass foil on LED chips also on acrylic part. i hate to see transistors.. no its smoth light..\\^\\^",
      "at least there will be plenty in stock",
      "Is the EK AIO for the reference cards worth it? \n\nMy Chinese cheap ass case is having hard time expelling the heat from my 69XT and on top of that it doesn't really like to undervolt but I feel like there could be some performance to unlock with lower temps, it goes nicely 2600-2700 at the beginning of any tests but starts to throttle quite fast when the junction hits 95C..",
      "I hope this time with 100% QA and no scratches..",
      "gpu block + plate costs $190 shipped, and only they have it in stock. they stick it where the sun don't shine. alphacool block+plate costs $143 shipped from PPCs.",
      "Instead of spending $400 on the gpu loop, why not spend the money getting a better case?",
      "I have no idea what milk glass foil on LED chips means, but it sounds delicious haha",
      "Good question. Partly why I'm here. My vega with a blower was fine and I have a feeling that the case is kind of fine without the 69XT dumping 350W of heath into it.\n\nBut if I get a better case, will the junction temp go down by 10C or so? Or am I still looking at the 95C junction, maybe not at 30seconds but maybe at 3 minutes?",
      "haaha.. xD .. it means i don¬¥t like to see the capacitors. So i put some frosted glassfilm on the acrylic part on the end of the 6900er.. and with EK GPU Block on the right end is the led implented. it give nice frosted effect.. luv it..",
      "gonna buy one of these and then finally get the card in 6 months!"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800"
    ],
    "title": "I‚Äôm tore between the 6800 XT vs 3080",
    "selftext": "I‚Äôm gonna be getting prebuilt so actually getting one won‚Äôt be of any issue, the thing is that i have no idea which one i‚Äôm gonna go with; i know for sure that i will get for a Zen 3 CPU so i‚Äôm really considering going for for the 6800 XT because of the compatibility between both (and not to mention the extra 6gb‚Äôs of memory), however i‚Äôve never owned an Radeon gpu and from what i‚Äôve heard their drivers are not as good as Nvidia‚Äôs. What should i go for?",
    "comments": [
      "Wait 18th, see benchmarks and then decide.",
      "If you‚Äôre going with zen 3 then get the 6800xt. The driver issues were from last gen and were mostly fixed. Supposedly it was due to a hardware issue, but with rdna2 it should be fixed",
      "Get whichever are in stock you can sell the other for retail if you don't like it anyway",
      "Wait for benchmarks and make an educated decision. :-)",
      "30 mins? That‚Äôs optimistic.",
      "Wait for whatever's in stock but I hope amd made loads of cards that wont go out of stock in less than 30 mins",
      "Wait for benchmarks",
      "I see, thx for the advice.",
      "I'll be glad if it stayed for 3 mins",
      "Zen 3 and RX6800 XT perfect match :)",
      "Feel like if you don't have zen 3 then you missing out",
      "6800xt supposedly has increased performance when paired with a zen 3 cpu on a pcie gen 4 lane. If you have a b550/x570 MOBO from which the GPU can take advantage of the pcie 4.0 slot, then its probably better to get the 6800xt. Again, wait for benchmarks though just to be sure."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "rx6800",
      "6800"
    ],
    "title": "NVIDIA RTX 3070 or Radeon RX 6800/XT",
    "selftext": "So I'm looking into buying one of the newer graphics cards, but of course I'm unsure of which one. I've been trying to get Nvidia's 3070 since it released until I learned of Radeon's new RT 6800 and 6800 XT. \n\nI know that the RTX 3070 is the cheaper option, but the RX6800 is reportedly faster in most aspects. (This will actually be my first GPU so I don't know much about the terms).\n\nSince the latter is coming out tomorrow I'd like to know: \nShould I attempt to buy Radeon's or hope I can nab Nvidia's during another sporadic restock?",
    "comments": [
      "The RX6800 is also about $100 more... ü§®\n\nAs mentioned there is zero true benchmarks of the RX6800 or RX6800XT.\n\nWhat your basing your comment off is the AMD presentation and or a random leak on the internet claiming their benchmark results to be legit.",
      "There are no benchmarks of amd cards except for the claims of amd.",
      "from my experience it wasn't really playable, I think the game tries to get the missing VRAM from your \"other\", much much much slower ram, and this translates in a ton of spikes.",
      "What resolution are you interested in? Are you interested in ray tracing? If so, from what I've seen, the 3070 actually beats the 6800 XT despite being $150 cheaper in terms of 4K ray tracing. However, if you just care about raw rasterized performance, AMD has more VRAM and is quite good at non-ray tracing fps. The 6800XT is on par with the 3080 in non-4K ray tracing fps, despite having a $50 lower MSRP while also having more VRAM.\n\nI think the 3070 has plenty of VRAM for 1440p, but if you intend to keep it for a long time, then I think it would not be great for 4K. I think the 3080's 10gb is plenty for 4K, but AMD's 6800 and 6800XT have 16gb, which is clearly more. \n\nFinally, not all of these cards are in the same price bracket. However, oversimplified, roughly:\n\n4K, ray-tracing: 3080 \n4K, no ray-tracing: 6800 XT\n1440p, ray-tracing: 3070, 3080 (if you can afford it)\n1440p, no ray-tracing: 6800 XT (if you can afford it), 6800 (budget alternative), 3070 (Not the highest performance, but still a reasonably strong contender given its price)\n\nRather unfortunately, both NVDIA and AMD are having supply issues right now, so purchasing any of these at MSRP is going to be difficult.",
      "idk what led you to believe any or this... the benchmarks show that the 6800xt is either equal or better than the 3080, which itself is significantly better than the 3070. And I have personally tweaked down settings because I was using too much VRAM (8.9Go on mh:world) in 1440p, which means players who play in 4k use much more themselves.",
      "Thanks for the advice! I actually managed to snag a 3070 amidst the chaos of the 6800 launch. Great timing too since my laptop fan broke soon after",
      "Benchmarks already exist. The RTX 3070 is trash compared to both 6800 cards. Again, it also has half the VRAM as well. Only an obsessed fan would buy a 3070 at this point.",
      "how does this showcase, when the game wants more vram than the card got?\n\nDid you get stutter, bad fps, objects noticeably popping into existence?",
      "thx for the info, was honestly wondering how the missing vram showes ingame.",
      "The RTX 3070 is a shitty buy. The AMD 6800 cards are both way faster. They also have 16 gigs vram, where the 3070 only has 8 gigs.",
      "Uh don't trust what a company tells you. Wait for actual reviews before saying which is faster",
      "3070 obviously, its cheaper and perform the same as 6800 , don't let anyone trick you with an extra VRAM story, it's near impossible to reach  8 GB of VRAM . however if u can pay extra go for 6800 Xt  its cheaper than 3080,"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800xt",
      "rx6800",
      "6800"
    ],
    "title": "650W PSU. RX6800 or undervolted RX6800 XT ?",
    "selftext": "I'm already preparing for the time when the prices will drop to somewhat acceptable (not in a hurry anyway haha), but I have a problem :\n\nI thought about getting a 6800XT, for which AMD recommends a 750W PSU.\n\nI only have 650w (bequiet straight power 11 platinum) - that's what they recommend for the 6800.\n\nSo here are my options : \n\n\\- Get a 6800XT anyway, and run it as it is : what do I risk ?  \n\\- Get a 6800XT and undervolt it so it suits the PSU : would it still be better than 6800 ?  \n\\- Get a 6800 : the most secure choice as I understand it.\n\nWhat do you think ?",
    "comments": [
      "Get whatever video card you can get. It's that hard to purchase a GPU.\n\nIf the card performs better than an RX 6700XT, then you can underclock the GPU using MSI Afterburner. Please note that, if the wattage requirement of the video card exceeds 90% of your PSU which is 585 watts, you should reduce the power usage of the card to get under the 585 mark, so, that the durability of your power supply is not reduced in the future.\n\nIf you benchmark the video card, the Nvidia RTX 3080 and above and the AMD RX 6800 and above can hit 500 watts during the tests. I'm not sure if you want to risk it, because that will be the moment your computer system might crash. Almost all power supplies are able to exceed their stated maximum power totals, but they can only do it for a short time."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800xt",
      "rx6800",
      "6800"
    ],
    "title": "Help request for AMD 6800/6800XT owners - benchmark against RTX 3080",
    "selftext": "Hello, AMD users!  I am the creator of the performant, open-source and cross-platform Fast Fourier Transform library for Vulkan - VkFFT ([https://github.com/DTolm/VkFFT](https://github.com/DTolm/VkFFT)). I have recently made a post about comparing RTX 3080/ Radeon VII in VkFFT benchmark: [https://www.reddit.com/r/Amd/comments/jwrkj9/rtx\\_3080\\_and\\_radeon\\_vii\\_benchmark\\_results\\_in/](https://www.reddit.com/r/Amd/comments/jwrkj9/rtx_3080_and_radeon_vii_benchmark_results_in/). I wanted to ask if some of you have access to the fresh AMD GPUs to help me do the benchmark of them (the GitHub repository has Windows executables). Older version of VkFFT used in Phoronix benchmark ([https://www.phoronix.com/scan.php?page=article&item=amd-rx6800-linux&num=8](https://www.phoronix.com/scan.php?page=article&item=amd-rx6800-linux&num=8)) has some big performance gains on smaller systems due to Infinity Cache. New benchmark should give more information on how Infinity Cache works and scales and I would like to make a post about it afterwards. You can contact me on reddit or through E-mail (at the bottom of GitHub page).\n\nThanks!",
    "comments": []
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800xt",
      "6800"
    ],
    "title": "What GPU to get",
    "selftext": "Hello people,\n\nSo I need help deciding what GPU to get\n\nGPUS:\n\nRX 6800 XFX NEW = 444.50eur\n\nRX 6800XT PHANTOM NEW = 500eur, USED same GPU selling for 400eur\n\nRX 6800XT Lenovo Legion USED = 370eur\n\nRX 6800 Nitro + USED = 370eur\n\nRX 7700XT Acer Nitro NEW = 444eur\n\nThose are the GPU's I am looking into. Can't decide which one to get. I never bought USED gpus so I am kinda scared about that don't know is it worth buying used GPU's.\n\nI currently have Gigabyte RTX 3060 12gb, and for CPU ryzen 5 5600. When I buy a new GPU, i won't be buying a new CPU for the next 6-9 months (when I get new, I will go with ryzen 5 7600x).\n\nAlso for now I have 1080p monitor but after buying new GPU il buy next month new 1440p monitor.\n\nAlso I have Thermaltake Smart BM2 750W PSU.\n\nSo if someone has some free time please help me decide what GPU to get because I am kinda lost. (also never had AMD GPU)\n\nThanks for your time beautiful people.",
    "comments": [
      "Hey man so I got ex 7800xt and paired with my ryzen 5 5600 its actually really good. I am having crazzy fps on 1080p except in new call of duty and warzone. For some reason my gpu is not at 100% while running extreme settings with native resolution. But overall i am happy with it got it today so will test mode tomorrow but for now i am really happy with the purchase.",
      "Given your current setup and plans, here‚Äôs my top choices for performance and value:\n\n1. **RX 6800 XT (Used) f** (Lenovo Legion or Nitro+)\n   *  The RX 6800 XT is a great 1440p GPU, and at 370 EUR, these used options are strong value buys. Both models should give you a substantial performance boost over your RTX 3060, especially in 1440p gaming.\n   *  Used GPUs are a bit riskier, but if these come with a warranty or are from a reputable seller, they can be excellent deals. Just check for clear seller policies on returns or issues.\n2. **RX 7700 XT (New)** \n   *  The RX 7700 XT is newer and generally has better support for modern features like AV1 encoding and lower power consumption. It performs close to the 6800 XT in 1440p and provides a safer, new option without the risk associated with used hardware.\n   *  Performance-wise, the 7700 XT is generally close to the RX 6800 XT but is a bit more expensive than the used 6800 XT options. However, as it‚Äôs new, it comes with full warranty support.\n3. **RX 6800 XFX (New)** \n   *  This new option offers a balance of performance and price, without the risk of buying used. It‚Äôs a bit below the 6800 XT in raw power but still excellent for 1440p.\n   *  For a similar price, you might get more future-proofing with the RX 7700 XT, though the 6800 XFX is still solid.\n\nThe 7700 XT, being newer, has the advantage of possibly longer driver support. However, for raw 1440p performance, both the RX 6800 XT options will perform similarly.\n\nIf you‚Äôre cautious about used GPUs, the new RX 7700 XT or the new RX 6800 might be safer choices. But if you‚Äôre comfortable with the used route, the 370 EUR RX 6800 XT options are an incredible value for performance.\n\nIf you‚Äôre comfortable with used, go with either the RX 6800 XT Lenovo Legion or Nitro+ at 370 EUR for the best price-to-performance. If you‚Äôd rather stick with new hardware, the RX 7700 XT at 444 EUR is a strong choice that will handle 1440p gaming and comes with warranty support.\n\nEither of these will be great at 1440p, especially when paired with your planned Ryzen 5 7600X upgrade.\n\nWell I feel like I have just typed more than I should but I hope you find this helpful. I have tried as much as possible to dig deep into all aspects just to provide a more played out opinion.",
      "They are all the same, more or less. I had the RX6800 16GB for 3 years and the 6800XT for two weeks. Would prefer the RX6800 16GB again and overclock it to 6800XT performance level. The 128MB IF$ is just insainly good for 1440p, although the compute power is on a medium level of ~17 Tflops fp32 for the RX6800. The RX6800 has the best compute/cache ratio of all RDNA2/3 GPUs. 60CU over 128MB, it's 2.13 MB IF$ per CU, the RX6800 swims in bandwidth and is always Compute limited. The IPC per CU is here in greatest form. \nThats the reason why I would go for the RX 6800 for 400‚Ç¨ by now.",
      "Have fun man I am happy for you.",
      "Wow thanks man for your great answer. Il prob go with 6800 xt used, or I am considering also rx 7800xt to buy on amazon in Germany since I have friends there that can get it for me and bring me to Croatia. 7800xt is 460 euros on amazon and for 100 more euros I can get new GPU from new Gen.",
      "Yea I get that thanks for the info. I am now thinking about getting 7800xt since i can brand new for 460‚Ç¨.",
      "Welcome, I am happy I got to lay it out for you.",
      "Yeah, brand new with guarantee is always better.",
      "One more question do you think it would be worth it pay 100‚Ç¨ more brand new from store 7800xt over used 6800xt that is selling for 370‚Ç¨?",
      "Yeah it is worth it. You have to look at it with from an angle of longevity new will always be better than used regardless of specs but of course there is a matter of preference. Personally I would always go for a new if I can.",
      "Yea thats what I thought. Il prob go with new 7800xt its good price new gen and its brand new not used. Thanks man for help",
      "You also happen to be very lucky with these prices from the part of the world I am from the prices would range somewhere between 600-790",
      "Welcome. You'll bring reviews of how it performs from your end."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800xt"
    ],
    "title": "new card, futureproof for the next years",
    "selftext": "I built a new system in December 2020. As there was already a problem in getting videocards a bought a 2nd hand 980ti. \n\nNow 2 years later the supply is better, prices are dropping for both used and new cards so it is time to look for an upgrade, especially because I replaced my 51\" HD television for a 4k 55\" (I game on my pc sitting on 180cm distance from the screen) and the 4k resolution¬† is pushing the 980 to its limits. \n\nInteresting options now are the RTX 3070 8gb for ‚Ç¨400¬† used, or 6800XT 16GB for ‚Ç¨475 used in the Netherlands. The 3080 is a lot more expensive. \n\nWhich card is a better choice at the moment, which is a more futureproof choice for the next 4 years?\nMy hesitation of the 3070 is especially the 8gb ram, a relatively small amount for 4k resolution. \n\nAlso, will the prices drop more in the next months/year (new and used)? \n\nThe games I play are mostly 3-5 years old. So in 2026 I play most likely the games released in 2022. \n\nCurrent system: \n\nMainboard: Gigabyte Z490M Gaming X (Z490, socket 1200)\nCPU: Intel Core i5-10400F 2,9GHz (4,3GHz) 6core\nRAM: 2x 8GB PNY XLR8 DDR4 3600MHz\nPSU: MSI MPG A650GF gold rating\nSSD: Crucial 1TB M.2\nGraphics card: Asus Strix GTX 980 TI 6GB",
    "comments": [
      "I would choose rx6800 because of the vram",
      "It's also about 25% faster so an easy win for the 6800XT",
      "The 3070 is a 1440p card,  if you want 4k go 6800xt or (preferably) higher",
      "Also don‚Äôt forget when going to amd from Nvidia I would run the program ddu to completely remove the nvidia drivers.",
      "For future proofing, I would avoid the Rtx 3070 because it‚Äôs vram is only 8GB. I would definitely choose the 6800xt because the 16GB will help in the future.",
      "All right, 6800 XT or higher it is. Hopefully the prices will drop more :)",
      "As a 7900 XT will be eur1200 (MSRP in USD times 1,3), I expect a 7800XT to be around eur1000\n\nThat said, I think eur700 for a 6900XT is a good price, with availability right away instead of waiting another year and the hassle to get one.\n\n(Hopefully I can get one for 700 , as the prices a increasing and dropping each day)",
      "6800 „Äã 3070.",
      "There‚Äôs no real future proofing with gpus, but if you want to at least have a good experience without spending crazy amounts of money, it‚Äôs better to stay at a mid range and upgrade more often than going with a higher end and trying to use it for a long time:\n\nIll use nvidia as an example.\n\nit‚Äôs better to upgrade to a x60/x70 every 1/2 gens, selling the old card while it still has some value so in the end, after the cost of the first card, it feels more like a subscription where you‚Äôre only paying the difference between the new card and sale price of the old card every year / couple of years.\n\nNot only you keep a good and constant performance that keeps up with games over the years, you do so without actually spending a crazy amount of money, you also keep up with newer technology.\n\nAlso don‚Äôt forget the power cost, people ignore that but at the end of the year, can bit quite a big amount depending on how expensive is electricity there‚Ä¶ x60-x70 are the most efficient in power terms, deliver the most frames per watt so keep your power bill in mind.\n\nI mean, a 980ti, while still being slightly more powerful in raw terms than a 3050, it doesn‚Äôt have tech like DLSS, meaning it consumes like 2-3x the power while actually performing worse than the 3050 once you enable DLSS. I bet a rtx6070 in a couple gens will be much more desirable than even a 4090 is by then, and with the cost of the 4090 (and the high power bill), you can literally pay the x70 upgrade/sell cycle for many years, way longer than the 4090 realistic lifetime. So even a 4090, unless you need that performance now, wouldn‚Äôt be a good future proof GPU, even if it performed well these years, just because of the power consumption.",
      "If you can stretch a 6950 are not crazy to buy compared to a Nvidia line up. The only 2 down sides to amd is their rt is better and drivers can be more stable",
      "That is also a factor that I am considering, but the difference is not that big with our electricity prices.\n\nIn the recent past  is usually bought 2nd hand mid range or high end for ‚Ç¨ 200 each 3 years. But with 4k that is not a good option. So I need to increase the budget\n\nIn the ATi 8500 and 9800Pro era  I bought those two cards brand-new. But then, a high end card was costing ‚Ç¨300 new instead of the 1000+ now.\n\nNew prices now are 649 for a 6800 XT, 699 for a 6900 XT and 1049 for a 6950 XT. Still the 6800 XT and 6900 XT are above my normal budget.",
      "Actual new Prices at the moment \n\n‚Ç¨649 for 6800 XT\n‚Ç¨699 for 6900 XT\n‚Ç¨1049 for 6950XT\n\nSo the the price gap to a 6950 XT is big",
      "Yeh, cards are too expensive nowadays, I haven‚Äôt upgraded my old ryzen 1600 and 980ti (i have one too) because of principle, im not going to pay scalper prices, and shops are still selling them at that, rather not play at all even thou the 980ti can still handle games well enough for 1080p (cyberpunk at high settings and fsr in 1080p still runs at 60 fps)\n\nBut I only got the 980ti because i needed the performance back then since i had a oculus rift, but before that i used to upgrade the x70 every gen from the gtx275 to gtx770 and it costed always under the 100‚Ç¨ per gen to do so after selling the old and it kept me playing the latest games at quality settings and the standard resolution of the time and i always had the latest drivers and technologies (shadow play, hairworks, etc).\n\nI skipped the 1070 because made sense downgrading from a 980ti, i waited for the rtx2070 but we know the story there‚Ä¶ the gtx1000s where probably the last time we had reasonable prices.",
      "https://www.newegg.com/msi-rx-6950-xt-gaming-x-trio-16g/p/N82E16814137733\n\nWe can get a 6950xt for 779 USD I don't know if new egg shios international",
      "6950xt pricing is very temporary, IMO. Once the 7900's are available, this will also fall.",
      "The Asus 6900 XT is now 32% below MSRP here at the moment.\n\nI bought the used asus 980ti in December 2020 for EUR 210  one year later, they where asking EUR 400 for a used 980ti... now it is EUR. So a bit more normal, so the prices a dropping and stabilising.\n\n\nBut still deciding if I am willing to pay 700 euros for a brand-new Asus 6900 XT (or 650 for a 6800 XT)",
      "You never, ever ship a gpu to europe, not only they will still kill your deal with vat, you have extra fees for importing and you can also say bye bye to rma if something goes wrong unless you want to pay a lot in shipping.\n\nGpus are stupid expensive here in europe (I haven‚Äôt seen a rtx4090 for under 2000‚Ç¨ with the avg price being like 2200-2400‚Ç¨) i bet a 4080 here will cost as much as 4090 in the us, which is annoying as the majority of europeans still have much less purchasing power/expendable income (these high gpu prices are clearly being condoned and promoted by american buyers)",
      "Divide the avg fps by the price, at this point 50‚Ç¨ wont make much of a difference if you‚Äôre paying over 700‚Ç¨, but tbh, id check benchmarks, calculate the avg cost per frame of all current gpus and pick the cheapest gpu of the bunch (it will be probably still be one of the mid to mid high tier ones) and that would be my choice and new tier for the upgrade and sell cycle, just add just a bit of offset if you want technologies like ray tracing or not",
      "Yeah vat is a pia, I wish everyone would just use Australia's vat amount.",
      "Indeed 50 euros for 10% more fps, so could be interesting for the rest value or more lifespan on the long run\n\nFact is, that it is more fps and vram per euro in comparing to the nvidia cards, the 3080 is 900 euro here, 3070 ti 750 euro"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800xt"
    ],
    "title": "AMD Queue 05/19/22",
    "selftext": "Got on the AMD queue today and was in almost immediately.  They've added the 6900xt back, but no 6800xt still.  My guess is they're only selling the 6750xt, 6900xt, and 6950xt moving forward.  Sucks for me, because I've been hoping to pick up a 6800xt.  Looks like I'll have to go third party once the prices get a little closer to MSRP for the reference card.",
    "comments": [
      "After months of getting high wait times and leaving empty handed, I finally got to the store instantly, just to leave empty handed again because the 6800xt aren't for sale anymore, I guess that everyone wanted one? It seems that not even the bot/scalpers bothered this week.",
      "Same issue with Nvidia.\n\nAMD knows they can get more money by selling those GPU dies as 6950s, than as 6800's, and the yield is so good they just don't get enough defective cards to create 6800s.\n\nWith Nvidia, they were even greedier, they created the rtx 3080ti, so they could sell the defective 3090 dies at 70% markup compared to 3080s, so a MSRP rtx 3080 is now almost impossible to get.",
      "AMD HQ: \"Yes, we beat the scalpers!\" /s",
      "No sign of the 6900xt in the canadian store, but I got one  6750xt quite easy and both the 6750xt and the 6950xt are still available at 13:40 EST.",
      "Yep.  Exact same story here, and that's my guess to your points.  We know miners are starting to offload due to profitability issues, so it looks like the bots are probably on hold until RDNA3 hits later this year.",
      "store still 100% in stock lol",
      "Makes me laugh at the scalpers trying to sell reference 6750s for $750 on ebay.",
      "Where are you located? If in the bay area, I have a used midnight black 6800xt I need to sell.",
      "Yeah, all 3 cards are available on the US site still.  I think the days of needing to queue are gone (unless they actually bring the 6800xt reference back).",
      "Beaten scalpers: yes, we're beaten /s",
      "Yeah, I'm not comfortable one-offing a shipment like that too.  Appreciate it, though.",
      "[https://www.newegg.com/xfx-radeon-rx-6800-xt-rx-68xtaqfd9/p/N82E16814150867](https://www.newegg.com/xfx-radeon-rx-6800-xt-rx-68xtaqfd9/p/N82E16814150867)\n\n$769 plus one month of game and the game bundle added to the offer; That's as close as I would expect you to get to the \"MSRP\" of the 6800XT, especially since the AIB 6800XT was never offered in 2020 at anywhere below $790-800 (even at launch)",
      "East coast.",
      "Hey I live in East Bay! Check your dm‚Äôs",
      "I actually saw that earlier (it'd be $779, though).  The only thing I hesitated in is that I need to water cool it, and I had a hard time pinning down any water blocks that were made specifically for this version of the card (plenty of Merc varieties out there, though).  I'll have to keep watching it.",
      "Damn, I'm west coast. Didn't want to leave getting the product to you up to shippers who can steal/break it.",
      "I'm on the East Coast.  I sent a PM.  Not sure if you'd be interested.",
      "don't see anything",
      "[https://www.amazon.com/XFX-Speedster-MERC319-Graphics-RX-68XTALFD9/dp/B08TJ2BHCQ/](https://www.amazon.com/XFX-Speedster-MERC319-Graphics-RX-68XTALFD9/dp/B08TJ2BHCQ/)\n\nMERC319 for $799 and does have waterblocks available for it. (At least from bykski)",
      "Okay, check now"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800"
    ],
    "title": "AMD Radeon RX 6800 allegedly 1.5x faster than GeForce RTX 3090 in cryptocurrency mining",
    "selftext": "",
    "comments": [
      "Bots+Scalpers+Miners+Pandemic. The four horsemen of the GPU apocalypse.",
      "How do I delete someone elses post?",
      "Please don't..",
      "Well first you'll need to crack their password, so I'd recommend getting a really powerful graphics card capable of calculating a lot of hashes quickly.",
      "I actually heard it deletes your cryptocurrency. Best not to risk it.",
      "Reviewers get all the stock*",
      "(**Here we go again**)x2",
      "Everyone just repeat : fake news, fake news, fake news.... Fck",
      "And by that we mean one single GPU that has to be passed around.",
      "And here I thought the Nvidia launch was bad... turns out it was just a warmup",
      "Probably start with some small talk. \n\nGet to know them a bit. Find out what is their birthday, any pets/children, favorite sports teams and colors.\n\nToss that all into John the Ripper.",
      "Now we're REALLY never going to get it.",
      "Ah shit, here we go again.",
      "Another 3 years with RX 580 it seems.",
      "**Please read this before buying up all the gaming cards thinking you'll get rich from bitcoin mining:**\n\nGTX 3090: 106 m Hashes/second at 300 watts. price =$1500\n\nRX 6800 XT : 150-200 mhashes/second. price = $650\n\nAnt Miner (low end ASIC bitcoin mining card):   1,000  mhashes second. 63 Watts. Price $38\n\nSo the BTC miner is about 100 times better value than the Graphics cards, and has lower running cost. SAVE THE GRAPHICS CARDS FOR GRAPHICS PEOPLE!\n\n\\----------------\n\n\"How is that possible?\"\n\nbecause ASIC hardware doesn't  waste silicone space on circuits that do graphics. They can focus 100% of the silicon on dedicated circuits that only perform the Bitcoin Hashing algorithm. It's not uncommon for ASIC to get 2 orders of magnitude improvements over generalized hardware.  \n\n\nEdit: Misspelled a word",
      "And it's gone",
      "Fuck you crypto miners!! If prices start to rise at launch, I'm not going to upgrade my system. Tired of this crap...",
      "But this is guaranteed sales of their parts. And that's what they want.",
      "No please... not again",
      "That's the actual truth about review samples. They have to send them around to other reviewers since early supply is always an issue."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800"
    ],
    "title": "One of the big offical AMD sellers, in the netherlands selling the 6800 xt for more than 1200 dollar at this point it isn't even funny anymore",
    "selftext": "",
    "comments": [
      "And here I was thinking the 850‚Ç¨ Alternate Germany are asking were ridiculous.",
      "Fun fact: it Was ridiculous",
      "Yes, but sadly this pricing decision has nothing to do with AMD. Anti-trust laws prohibit AMD from dictating a minimum or maximum price to resellers - this is entirely Alternate's doing. \n\nWhat Alternate is doing is shitty though and shows that yesterday's assertion that no dutch retailer had cards was not true. They just did not want to sell those cards at MSRP...",
      "Yeah we should rename Alternate to Scalpernate",
      "And they have the gall to charge 5‚Ç¨ for shipping too...",
      "To sell it for 1800‚Ç¨ on eBay",
      "This i'm so suprised nobody mentioned this but AMD does it as well, we are buying cards that cost 600 euro+ why the ever living F are they charging shipping??",
      "We could also register the domain scalpernate.de/com/net/nl/etc. and \"adjust\" google search results for \"alternate\", which is a common word in english language to be suggested and redirected to scalpernate.\n\nI seriously wonder why we dont have laws against scalping on that scale in the EU. Ofc you have a variance, but how can it be over 1.5x of the MSRP not even 1 day after launch? It can't.",
      "Its a joke, Spain's price was 670‚Ç¨ for the 6800xt from the major retailer, a very reasonable price.",
      "Alternate is just the shittiest company I know. Pls don't buy there.\n\nThey did the same with the oculus rift S.",
      "Because that would add ‚Ç¨5 to the MSRP.",
      "You know what's even more ridiculous? That OP didn't mention that that listing doesn't even have an order button. Let alone stock. You can't buy it. It's obviously a placeholder.\n\nOf course his story is a better narrative for kudo's, so...\n\nEdit// As of 16:17 European Time (30 minutes prior to this edit), the situation changed and Alternate has put 5 pieces of stock on their site for this particular card. They also sold.",
      "Yeah i know that but its still a very shitty thing to do",
      "Seriously.. what amount of time has to pass so that people can clearly call NVIDIA/AMD out on the actual price of their product? Are people going to use the \"free market\" excuse until the next gen arrives? Why are PS5/XSX and many other products being sold at their advertised value, but GPUs somehow get a free pass?",
      "Just Alternate overcharging like they always do - even when supply is much better (though not to this extent).",
      "same thing happening with nvidia.. The prices are way beyond what nvidia said the prices would be.. so annoying. At this rate by the time most people get a card at a normal price its gonna be 1.5 to a 1 year before the next gen lol",
      "Knowing the very basic principle of economy doesn't make this any less frustrating. You are not the only one who has seen wikipedia articles.",
      "Supply and demand. Which obviously works out fine for Alternate.",
      "Lol for 100 units\n\nIt was a decent price, but the stock was a joke. It's a perfect marketing strategy. Look at all of *ass trying to grab one.",
      "Are you sure? German alternate price of 850 (1000$) was not a placeholder"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800"
    ],
    "title": "It's been awhile since I've had an AMD GPU. Just replaced my GTX 1080 with an RX 6800 XT and I couldn't be happier with this absolute UNIT!",
    "selftext": "",
    "comments": [
      "This is definitely 1st world problem. I'm gonna hold on to 1080ti until it dies ngl. There are so many excellent old games so I don't need to play the latest games",
      "Following the trend, your next GPU will be roughly 5 slots thick and 18 inches long.",
      "You are talking to man who is running R7 260X 1Gb",
      "So for those interested, the cards from left to right are:\n\n1. Unknown, cause I was 7 when we got it lol\n2. Zotac GT 440\n3. Asus GTX 660 (I had 2 in sli)\n4. Gigabyte GTX 1080 Xtreme\n5. Asus TUF RX 6800 XT\n\nIf any of you Reddit wizards knows what that first card on the left is, let me know. It's a Radeon something. I feel like it's 4000?",
      "Usually I win these ‚Äòmy GPU is old‚Äô fights with a HD6950 but I think you win this time.  I tip my highly inefficient old hat to you.",
      "That Asus card is what they use as a model for the house in escape from tarkov",
      "I have experience with that kind of dimensions, so no stress about that.",
      "I've got a GTX 1070 and feeling it but with no stock and overcharging everywhere it's difficult to know what to do.",
      "Yesterday I picked up this beast\nhttps://imgur.com/a/t0QN8G9",
      "Look at dem anime tittes",
      "I think that was your CPU...",
      "Pretty sure the one on the left is a Radeon HD 4350, I have one of those cards too.",
      "Old games for 1080ti? \n\nGames have stagnated since it came, it will work just as well as a new card next 5 years. It was to good when it came out.\n\nI figure 5 more years before i replace it. My 6600k cpu also stays, new CPUs have marginally better single thread performance and that's what I need.",
      "New cpus are significantly better than your 6600K. \n\nI dont wanna tell you that your cpu is bad. If you like it thats great. \n\nBut since the launch of ryzen in 2017 it is low end. And almost every newer game will give you stutter and a worse framerate. And your 1080ti will get bottlenecked in many games even in 4k for some. \n\nThat 4 cores are enough for gaming was true maybe 4 years ago. \n\nDont spread false stuff just because you are fine with your performance.",
      "Lol i use an hd 6870 with a dedicated power supply xD",
      "Lol surprisingly no. I got it from memory express (Canada). It was definitely still overpriced compared to MSRP though",
      "I just upgraded from a 2080 Max Q to a 3600X/  6800 and I‚Äôm sold on AMD. 1080‚Äôs are pretty great still if you‚Äôre a 1080p gamer tho, it‚Äôs just not enough for 1440p IMO.",
      "Omfg is that a tank on the right",
      "It's not. But similar. In Tarkov it is a 750 Ti",
      "Yeah I'm not sure the guy above you realises how far CPUs have come recently in terms of raw performance.\n\nUntil fairly recently I thought my 6700k was still fairly high end, until I looked at benchmark scores. Don't get me wrong, it's a fantastic CPU, and certainly still plays modern games with no problems, but the newer generations are just way, way, way better in almost every way."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800xt"
    ],
    "title": "Unpopular opinion here but 6800XT should be $100 cheaper compared to 3080.",
    "selftext": "\n\nAMD is not fighting on features, they are not fighting on performance, they don't have user base with brand loyalty, they don't have more inventory and they don't have better drivers.\n\nYes it was a good leap compared to 5000 but that is also because they didn't compete at higher end.\n\nWhy would you tell anyone to buy 6800XT over 3080?\n\nComparable performance at 1080p and 1440p is good but for $50 more you get playable ray tracing and better overall package.\n\nMore VRAM is a good point but why would it matter when it is not getting utilized right now and probably won't for quite some time.",
    "comments": [
      "The demand is greater than supply so far, so they could sell them even higher.",
      "Popular Opinion: Both should be made $100 cheaper.",
      "It‚Äôs hard to raise prices later, but it‚Äôs easy to lower them. If in doubt start high and slowly lower the price, moving down the demand curve, until you get the quantity sold that you want.",
      "Unpopular opinion here, but AMD could have launched the 6800XT at $800, and they'd still sell everything they can ship until the new year.",
      "It's about \\~$300 cheaper in my country compared to 3080 ($1200 vs $1500).\n\nBoth, however, are MIA.",
      "> Less scalpers\n\ndohohoho.",
      "I am surprised that the price isn't higher.",
      "You can't easily raise MSRP, but you can lower it. Expect a price drop if they actually manage to meet demand in a few months.",
      "It already is $100 cheaper or more depending on the region. I wish people would pay more attention to real pricing and less attention to MSRP fantasy pricing.\n\nI paid 680‚Ç¨ for a RX 6800XT from AMD directly. 3080 FE isn't possible to buy in Europe anymore and the cheapest AIB models where I live are 800‚Ç¨.",
      "Someone knows their firm-level economics!",
      "3090 enters the chat.",
      "...and why would either AMD or NVIDIA charge $100 less when their products are sold as soon as they hit the shelves as-is?",
      "they said *should*. thats unrelated to the actual market value",
      "It's gonna be $100 high for non-reference models. So yeah...",
      "Would make sense to sell on higher price actually. Less scalpers, less price hiking by dubious stores and after all better margins. Lower the price only when you can meet the demand.",
      "That's not unpopular. That just being real and doing business.\n\nThere is a business demand, and there is a void from nvidia. AMD listing at a higher price is the highly touted capitalism working just as expected. Too many out there don't understand business and have been brought up in the US culture of discount, discount, discount. \n\nNow, on to chapter 2. The first hands of cards are dealt, competition is real (finally). Will green or red make any pricing reactions in Q1 will be the first thing to watch, and whether refresh in Q3/Q4 will be hasten is also be interesting to keep an eye on.",
      "Same for Romania lol. They are inflated, but literally 6800xt is the same price as 3070s.",
      "wishful thinking, opinion, frustration. I dont know, everybody got their own reason",
      "I think this statement is 3 days early. We need to see what the AIB cards come in at for the 6800XT. Realistically even if you can get a 3080 you are paying at least $750 if not more as the AIBs are mostly just making their top end cards the Strixes and FTW3's of the world. Are they $699 or higher. Keep in mind the AIB cards will likely beat the 3080 flat out a well.\n\nAMD has also said that at least through the end of the year, so you have a situation where the reference design is $100 cheaper and the AIB boards are $50-100 less for better overall performance in all non RT titles.",
      "WTF do you mean they're not fighting on performance?"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800"
    ],
    "title": "Get your brand new rx 6700 xt for the price of an rx 6800!",
    "selftext": "",
    "comments": [
      "More like at the price of a 6900 XT, screw buying a GPU these guys suck.",
      "Yeah there's a reason why the dutch sites have stock and its the euro sign followed by 4 digits.\n\nI've been waiting for a replacement for my old gpu for overa year now because of no stock anywhere but I'm not blowing 1k for this",
      "It's totally insane. I've paid 1280‚Ç¨ at the beginning of this year for my 6900XT, because I had a bad feeling about the prices. Seems, my feeling was right.",
      "It's legit crazy. I don't know why we even have an MSRP anymore.",
      "An rx 6800 at bloated price that is",
      "I don't know if anything will ever be MSRP again. Even after crypto boom ceases - these guys know that gamers are willing to pay 2-3x MSRP for cards so why wouldn't they just make them that price forever?",
      "Volume and competition, I suppose. The number of people willing to pay this much are relatively small: for every entheusiast who is buying cards somehow, there are the literally five people who asked me to make a cost effective build that I have flatly told \"not until prices come down\". I'm not upgrading any time soon, and I'm directing people to buy consoles when they ask me how to game right now, something I've never done before in my life.\n\nCompetition, theoretically, will help push prices down - Intel GPUs have to put themselves into some niche in the market, and amd and nvidia will want to respond, so once the market HAS supply then it might act rationally again.",
      "[This comment has been removed by author. This is a direct reponse to reddit's continuous encouragement of toxicity. Not to mention the anti-consumer API change. This comment is and will forever be GDPR protected.]",
      "I'm in China, got a 6900XT reference for 1100‚Ç¨ (MSRP is around 1030‚Ç¨ here) from a reseller because they weren't selling so well, everyone was trying to get the lower models from AMD and nVidia around MSRP at the time. These days the 6900XT goes around 1500‚Ç¨ at least, lower models above 1000‚Ç¨, so glad i pulled the trigger even though i planned to get the 6800xt originally.",
      "I ordered a prebuilt the other day for $1700 just so I can get the 6800 out of it and sell the rest to make up the difference. That entire system is cheaper than one 6800 on eBay.",
      "Right I was looking how much my pc build is worth today. And my 5700xt was selling for $1700 on amazon.  It's crazy",
      "It's a bullshit. I'm really tired of this shit. I just wanted a SINGLE 6800 XT at a fkn normal price as they promised. Just one card to play my fkn games as it's supposed to be.",
      "1500‚Ç¨ lol, try 2000‚Ç¨.",
      "FFS. ~$1620 AT START for cheapest 6700xt here. Jesus christ. I'm done!",
      "Bruh, intel is gonna take full adevantage of the price level. Only hope is a crypto crash.",
      "Yeah I paid $950 for a 6800 XT with an msrp of around $800 in December and slightly regretted it until this somehow managed to get so much worse this year. Definitely glad I did it now.",
      "So how‚Äôs the hash rate efficiency? Asking the important question here /s",
      "Fuck that geez, I'm pissed off about AMD  still not fullfiing  5900x orders  from nov 5th  (uk), while still releasing more products they can not fullfill but man I feel so grateful  I was able to get  zotac trinity  rtx 3080 order on launch right near the bottom of the queue  till Oct then was able  swap to a Palit gaming Pro as that queue had been fulfilled at the time  for an extra ¬£30 in Oct which shipped 2 days later  just gets shitter for gamers",
      "Haha dit is azerty maar alternate kan er ook wat van. 899 voor de goedkoopste wat geen pre order is. \nSorry maar 2x adviesprijs gaat mij t petje boven. \n\nMijn 1060 werkt nog goed genoeg",
      "You got lucky then. I've tried this in the UK and even selling the parts I'd still end up paying nearly ¬£900 for a 6800.\n\nThat would be a preorder 6800 as well!"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800xt"
    ],
    "title": "i5-2500k / R9 390 into 5600x / 6800xt - i'm finally here",
    "selftext": "",
    "comments": [
      "After few years of waiting for an upgrade i've managed to get here. I was casually gaming at 1080p and it was managable but decided it's nice to check 1440p / 144Hz as i was astonished with high refresh rate when seen it in action @ my friends house. That's why i discarded 4k60 from the list.\n\nGrabbed 5600x as there were plenty of them available here in Poland and lucked out with 6800xt with an order @ 15:16 local time at second biggest retailer. Didn't expect i would make it and received info from retailer, that it will be shipped in a month which got me sad. I wanted to cancel and wait for AIB drop next week, but then got a message next day that it's ready to be shipped.\n\nOriginally i wanted to buy 3080 FE but restrained myself until i will see what AMD will release with RDNA2. After reveal the choice was simple but still if i wouldn't get 6800XT, 3080 was my backup plan. I don't care about the brand, just about the performance.\n\nThis system is perfect now, 5600x with PBO boosts up to 4850Mhz if required. It's still a fresh lineup of CPUs so i think next AGESA / BIOS releases will allow for better OC.\n\n6800XT is just a monster for my needs. Some people reported coil whine but mine doesn't have any. Idles @ 50 degrees Celsius and goes up to 80 when gaming.\n\nFull system specs:\n\nR5 5600x  \nASUS TUF X570-Plus  \n16GB 3600 CL16 IRDM Pro GoodRAM kit (Hynix CJR) - still need to play a bit with it  \n6800XT Ref by PowerColor  \n750W Gold PSU  \n\nTo everybody waiting to snag the card / CPU: it's worth it.",
      "CPU in MediaExpert, GPU in x-kom since in morele it was already sold out.",
      "Where in Poland did you buy it ?",
      "Great buy! Congratulations on the new build. \n\nI myself am surviving with an i7 2600 (non-K) and RX 570 4GB (2nd hand to replace a failed RX 480 8GB). \n\nAm currently indecisive whether to pick 5600X or 5800X paired with RX 6800 or 6800XT.",
      "It‚Äôs going to be the same CPU upgrade for me. The 2500k was an absolute beast for its day and I‚Äôm hoping the 5600x will have a similar longevity.",
      "Haha, Sandy Bridge is really immortal, i've waited so many years but always had the feeling that it ain't worth it yet. \n\nFor the CPU choice i had the same and as i purely game (without streaming), went with 5600x as i really doubt those 2 extra cores will make a difference. Still at 1440p i will be more GPU limited than CPU.\n\nAnyway, both of them are great choice. 5800x runs a bit hotter form what i see (65W vs 105W TDP) but if you've got a proper cooling, won't be a problem.\n\nI have a friend who bought 5800X and is really happy about it.",
      "Immortal Sandy bridge crew unite - before we quickly disband and jump ship to Zen 3. \n\nso looking forward to replacing my old 3820. It has served me well but I'm way overloading it atm. My 5900X is getting ever closer to being sent - have it confirmed for the 30th. \n\nPersonally I think the balance of a 6800XT and 5600X for just a gaming rig is pretty much perfect.",
      "Congrats man, what a sweet build! Did a similar upgrade 2 years ago from a 2500k, 60hz 1080p, and gtx 580s to a 9900k, 1080ti, 120hz 1440p UW. What a crazy upgrade, enjoy it!",
      "Already gave it to my younger brother. He likes to play old games so will perfectly fit him :)",
      "So are you going to sell that old sandybridge pc ? Or are you looking to use at as a secondary/streaming pc?",
      "There are so many of us upgrading from a i5-2500k this generation. Every top comment on the YouTube videos (LTT, J2C etc) all have people saying the same thing!",
      "That's a great gaming PC you have there. It should serve you well for years to come.\n\n&#x200B;\n\nAfter getting my stimulus check I decided to finally build a new PC that would replace my PC from 2012 (outside the GPU). It was the PC below:\n\nCPU - i7-3770K @ 4.5 GHz \nRAM - 16GB forgot speed\nGPU - GTX 680 until a 980 ti the day it was released\nPSU - 650 watt\n\nAfter doing my research I learned that the new CPUs and GPUs were right around the corner. Luckily AMD was going to support the current AM4 socket for at least one more CPUs series. So I bought the following to hold me over until the new CPUs and GPUs launched.\n\nCPU - 3800X @ 4.5GHz all cores & IF at 1800 w/NH-D15 stable in games, not in stress testing\nRAM - DDR4 3600\nMB - Gigabyte X570 Aorus Ultra \nGPU - EVGA 2080 Super XC Ultra\nPSU - Corsair 850 watt\nStorage - 1x256Gb (OS) 1x1TB Samsung 970 Evo Plus (games) 6TB of HHDs (2TB & 4TB)\n\nMy plan was to wait until the new GPUs and CPUs dropped and buy the best for VR games. Yesterday I was finally able to buy a 3090 FE (not paying %300+ for the EVGA FTW3 3090) from Best Buy and I will be buying a 5900X as soon as I'm lucky enough to be able to click the \"purchase\" button on a website.\n\nAfter I get my 5900X I will use that computer for at least 5 years and upgrade again. The only thing that would cause me to upgrade before 5 years is if a part comes out that gives me 200% better performance than what I will have now or a game I must play isn't enjoyable because of my current hardware.\n\nI plan on buying a PCI-E 4.0 M.2 drive in the future but for now if I need more storage I will just pickup a large mechanical drive or a large 2.5\" SSD for gaming stuff.\n\nI might buy better RAM since it seems that the memory timings for RAM effect the CPU performance more than the previous Ryzen chips.\n\nSince I play VR mostly I think this rig will allow me to have fun for years to come.\n\nFinal PC Form:\n\nCPU - 5900X with a NH-D15 (OC not known yet since I don't own it yet)\nRAM - DDR4 3600 for now and IF at 1800 (1:1)\nMB - Gigabyte X570 Aorua Ultra\nGPU - 3090 FE\nPSU - Corsair RMX 850\nStorage - 1x256Gb (OS) 1x1TB Samsung 970 Evo Plus (games)",
      "I have the feeling that it will be usable for quite some time :)",
      "Very good choice hope  he will have a good time!",
      "Also part of the immortal Sandy Bridge crew! I5-2500k here, this week I got a 1080 for ¬£200 to replace my GTX 670, and looking to get the 5600x with a new mobo and RAM! I feel Sandy Bridge's time has come!",
      "‚ÄúWelcome, time-spanning soul. Welcome... to your destiny.‚Äù",
      "Damn, i felt like 2500k was getting too slow in 2016 and then i upgraded to ryzen 1600x near end of 2017.\n\nI actually didnt expect that big of upgrade in gaming performance due to single thread performance being really about same when both are overclocked, but it was actually big improvement. Having done that i think that sandy bridge owners think improvement is less than you actually get by upgrading.",
      "It's like moving from HDD to SSD in terms of responsivness of the system and overall experience. Its just faster in everything what i do, even causual activities like web browsing seems to be more umm, fluent?\n\nFrom the gaming perspective, there's nothing even to compare now. Zen 3 demolishes my SB very much.",
      "Haha i fully agree. I think the time has come to really abandon old platform and get going with new shiny stuff.\n\nI restrained myself for so many years because Sandy Bridge was still delivering what i needed but i told myself it's time to go and do not look back.\n\nIt was a perfect decision :)",
      "That's a huge jump. I think one zen3 core would almost outrun that whole 2500k. Congrats."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800xt",
      "rx6800"
    ],
    "title": "Reference 6000 series Or AIBs?",
    "selftext": "I wanna purchase RX6800 but if I go for AIB cards price will be closer to 6800XT reference card...if I get reference will it be good ? I know aib card usually performs better.",
    "comments": [
      "With the XT version only beeing 70 $ more expensive than non XT, its going to be really awkward when aibs want 100-200$ more for their cards. Considering the smaller nvidia cards are 200 $ apart and even they get mixed up with 3070 surpassing 3080 in price, which is pretty stupid.\n\nIf the same happens as with nvidia now, you are gonna see these 2 models completely mixed all over the place and a crappy aib 6800 will have no reason to exist beside the reference 6800 xt for even cheaper. A triple fan, 2.5 slot card cant be that bad , can it ? ;)",
      "Reference Vega was a single fan blower wasn't it?\n\nSo everyone knew it was gonna have shitty temps. Especially considering it's a 300w card.\n\n6000 series all have triple fan designs so there is no chance in hell that it will even perform anywhere NEAR as bad.",
      "Do you know when is the review of 6000 both aib and reference ?",
      ">With Nvidia, everything almost always provides adequate cooling and it is really a matter of what is better but nothing is flawed to the point of being unusable or sounding like a fighter jet taking off under load.\n\nYou never bought a lower - medium-end AIB Nvidia model or ?... like ... Zotac 970 DUAL fan fucking thing is a jet engine on 80C and tons more like this...\n\n&#x200B;\n\nEvery aib on both sides makes shitty and better models.",
      ">Do we know if/when AIB cards are going to be released?\n\nGN asked amd and AIBS\n\nAMD said they hope they have enough stock , at least for a few hours after release something along that.\n\n&#x200B;\n\nand AIBS told GN different time lines some 1 week after release some weeks after release.",
      "wait for benchmarks and reviews",
      "I'm waiting for custom boards personally, I want to see if there are higher binned models.",
      "AIB",
      "Reference should be okay, but right now the main challenge is making sure there is enough supply. If an AIB card is in stock and it's in your price range, you might as well get that.",
      "Serious question.  Do we know if/when AIB cards are going to be released?",
      ">apart and even they get mixed up with 3070 surpassing 3080 in price, which is pretty stupid.\n\nLiterarily every single  aib 3070 on the german market is at least 50 more expensive than a 3080 FE... so stupid...",
      "At launch most likely",
      "That'd be because it has a metal shroud and part of the vent is blocked... which is basically fixed on the 6000 series. Also the 6000 series has ducted fans... which are quieter at high speeds.",
      "The Radeon 7 was a triple fan open cooler also tho, but was slammed for being too noisy by the press.\n\nIt would be great if we can finally get a good reference cooler by Radeon, so they can shed the \"hot & loud\" meme.",
      "On the AMD side definitely wait for reviews and performance to be evaluated. AMD has historically made some really poor reference cards (ahem Vega 64) that didn‚Äôt have adequate cooling designs and required massive fan speeds. \n\nAIBs on the AMD side have historically been awful as well at times, with Asus on the 5700xt for example totally forgetting to cool the VRMs on one of their models.\n\nWith Nvidia, everything almost always provides adequate cooling and it is really a matter of what is better but nothing is flawed to the point of being unusable or sounding like a fighter jet taking off under load. On the AMD side you have to be more careful in your decision making.\n\nHopefully, this isn‚Äôt an issue with the RX 6000 series like it has been in the past but there have been so many issues in the past I‚Äôd definitely remain wary until the reviews prove otherwise.",
      "We don't know",
      "Look at Price performance from the date we have right now 6800 is the worst deal ever it's 70 bucks less than 6800xt for like 15%-20% less Performance  \n\nAMD is trying to Milk the Market hard right now to be honest if you look at the Market it makes sense for them at least Short term to do so, which sucks from customer perspective  your choice though \n\n(not even mentioning 6900xt which is only for people who don't care about money period)"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800xt"
    ],
    "title": "6800XT launch was as bad as RTX3080 launch.. change my mind..",
    "selftext": "AMDs chance to get all mad Nvidia people... fail.",
    "comments": [
      "This launch actually seemed worse",
      "Newegg- sold out in 8 seconds.\n\nBnh - screen came up saying its in demand, doesnt let you search.\n\nAmazon - nothing ever came up if you search for it. You need the specific link to see it, but then it says unavailable\n\nBestbuy - coming soon thats it",
      "Bots bought every graphics card with \"6800\" in the title.\n\nAll the old 6800GT's sold instantly.",
      "Can't see him having a job long if he's going to act that stupid. Lots of angry customers and you post something like that LOL",
      "Newegg was sold out before the page even refreshed. Literally less than half a second.",
      "AMD Frank Azor(marketing) on twitter:    \n*Just successfully ordered an @amd @Radeon RX 6800 for myself on http://amd.com. Required some refreshing to get the order through but it worked.*    \nhttps://twitter.com/azorfrank/status/1329068706538811392?s=21\n\nIt just works!",
      "Worse",
      "Yeah, when I was searching, the 6800GT's came up for \\~$138 so I saw that every time the page refreshed.\n\nThen they went out of stock precisely at 6AM PST, the same happened with a ton of other things (CPU's) but the funny thing was 15-20 minutes after, they started coming back in stock again (except for the GFX Cards) as if someone realized the mistake and was cancelling orders.",
      "So far, it was worse. No Best Buy, Amazon or BH Photo sales. Pretty pathetic.",
      "The launch is worse as they made zero bot prevention knowing full well it would be needed. I managed to get to order confirmation page before the website crashed, never once asked for any verification I was human. Just popped up add to cart, then pay with paypal, 2 button pushes before it crashed.",
      "Yep. 2070 died a month or so before the 30 launch after two RMAs (thanks, MSI!), gone through three successive utterly shit launches. Look forward to the fourth utterly amateur hour performance on the 8th when the 6900 launches. \n\nNvidia installed the bar in the fucking basement and after two months of talking shit, AMD still managed to trip over it.",
      "wait really? lool",
      "Does he have any awareness at all?  He acting like a fucking troll",
      "6800xt.....for a media center. Talk about overkill",
      "Made it through checkout on AMD.com and then it just closed the page, didn‚Äôt charge my card, and I got nothing lol.\n\nNever saw the cards go available on Amazon or Newegg. Apparently they were up on Newegg but they must have gone so fast I missed them between refreshes.\n\nOverall 0/10, would not F5 on launch again.",
      "hahah worse. i have yet to find ANYTHING relating to 6000 series in any online shop ^^",
      "I need to make some BS product and, when AMD/NV next announce their lineup, sell it with the same number in the title. Then cash in on all the bots.\n\n\"All sales final.\" (well, I can try at least)",
      "Covid really messed up the tech hobby. Lowered production because of closed factories and increased demand because mod more people at home. Then you have to deal with scalpers, retailers and companies trying to exploit the situation. The demand should decrease once the vaccines are out and more people abandon the PCs and consoles to go out. However, I really feel bad for people who really need an upgrade or wanted to make a full build this year. Stay strong friends.",
      "I felt the same way.",
      "''sEe ? iT wAsNt A pApEr lAuNcH!!! I gOt oNe !!!11''"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "rx6800"
    ],
    "title": "¬£800 for a RX6800 :(",
    "selftext": "",
    "comments": [
      "The is a 3070 in stock in the Netherlands and they are asking ‚Ç¨999 for it. I didn't get an EVGA 3080 FTW3 for ‚Ç¨880 3 months ago because I found it too expensive compared to Asus Strix (little did I know my non OC would never be in stock), I got the 3060ti Tuf OC for ‚Ç¨530 just before Christmas. Little bit more than the $399 MSRP for the FE, but compared to the 2021 prices... it was a good price",
      "Yeah I'm just leaving this gen to it I think, I don't like the idea of years with 10gb vram, or crap price performance ratio with no raytracing/dlss. Kinda resenting everyone paying so far over the top because it's showing them how much they can charge.",
      "I feel you, had the chance to buy a then overpriced 3080 a few months ago, thinking I'll get a better price by waiting and it then never happened and prices shot up FAR more.\n\nI got lucky now though by using a Twitter/Discord channel that alerts on stocks and I bagged myself a 3080 ASUS STRIX OC (UK) at a good price from Amazon, it should arrive this week or early next week... can't wait!\n\nI'm just hoping the delivery happens and it doesn't get delayed, destroyed or whatever in transit.\n\n**Edit**: added link as people are asking me in PM from where I got the notification.\n\n**Edit 2**: the price was about 800 pounds including import taxes/fees/etc, far cheaper than retailers that sell them at 900 now (which you can't also find).",
      "That's actually the MRSP for that GPU right now. In my country they cost up to 1000 USD :(",
      "Acording to Google, MSRP should be around ¬£600 in the UK. This is a 33.3% rise.",
      "I say that as someone that already has 11... The new console gen has started so it's reasonable to expect the texture size and quality to go up and not be limited by xbone and PS4 capabilities. I generally prefer 4k 60 so it really will matter when they start to push capabilities within a couple of years probably",
      "Here there is an RX 580 for 500$",
      "Well I think I'm gonna buy a console if prices don't go down, eh",
      "This is a custom AIB model a high end one at that. At worst it should be 100 USD more than reference MSRP not 150-200 USD",
      "Lol you say that like 10gb vram isn't a lot...",
      "just as a reference for the UK, I got the AMD reference 6800 from amd direct for ¬£530, so assume that's the msrp for the UK.\n\nAs a side note the reference is fine, typically 70 - 80 degrees for the temps (85 for the hot spot), but can easily be lowered by adjusting the fan curve, if you can find the reference go with that the AIB cards aren't worth the premium",
      "The market decides the price.  \nIf it is overpriced, don't buy it until it returns to a reasonable price.",
      "I'll be buying and RTX3000 if this is how its going to look. If the 6800 XT is ¬£1k there is no way im getting one.",
      "'Member when a mid-high end GPU was like $300-400(US)?\n\nI 'member",
      "Nearly 900 euros incl taxes and all, which I think is pretty good all things considered as it's 800 pounds in the UK.",
      "Not if people keep buying this shit.",
      "Technically yes, but short supply and high demand usually pushes things the other way.\n\nPersonally I think I'll skip another generation of GPU my GTX1070 will have to do I flat out refuse to pay anything approaching ¬£1000 for a GPU.\n\nThe short supply is also a demonstration of what happens when you put all your manufacturing eggs in a single basket. Seems someone skipped school the day that lesson was being taught.",
      "I paid ¬£420 for my gigabyte gaming oc pro 3060ti from currys",
      "The new consoles have shared system memory. They've got a lot because it does 2 jobs. \nYou'll not saturate 10gb vram very easily. \nPc gaming has has high resolution textures for years and years. They aren't a new thing. He'll go load half life 2 at 4k and see how good a 16 year old game and it's textures look!",
      "That's insane. I bought my RX 580 2 years ago for around $200 USD used!"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800"
    ],
    "title": "[HUB] 16GB vs. 8GB VRAM: Radeon RX 6800 vs. GeForce RTX 3070, 2023 Revisit",
    "selftext": "",
    "comments": [
      "tl;dr \"definitive proof that 8GB of VRAM is no longer sufficient for high end gaming\"",
      "That is now. We're in the middle of a VRAM boom and it's only gonna get worse. 8GB will be for 1080P low settings soon. 12GB is considered entry level now by game devs, with 16GB being normal and playing on ultra will require even more. We will likely see this change in the next 1, max 2 years.\n\nThis is why AMD put 20-24GB VRAM on RDNA3. It's also why 4070Ti/4080 owners are getting ripped off even harder than they realize. \n\nFor years game devs gimped their own games to fit into 8GB VRAM, but now that PS4 support died they have collectively decided..  nope. Textures alone will be 12GB or more.",
      "1080P with high details is hardly \"highend\"....",
      "4070Ti vs 7900XT will be a similar scenario in 2 years. Except then we're not talking $500 cards but $800 cards.\n\nNvidia really messed up here. Even if it's intentional to make people upgrade much sooner than the normal 4-5 year upgrade cycle, the backlash will hurt.",
      "and yet this would be a -40 vote comment in 2022 let alone 2020.",
      "Reminder that both the RX 6900XT and 6950Xt cost the SAME price as the 3070 Ti.",
      "Daniel Owen just did a review on 3070 ti vs 6950xt as they are priced the same (in fact the 6950xt is cheaper on average) and showed how, for the money, the 6950xt destroys the 3070ti, even beating it in many games with RT enabled.\n\nHe is also a very pleasant youtuber.",
      "NVIDIA Can do whatever they want because most gamers want their cards over any brand. Sadly.",
      "exactly, had a chuckle when the nvidia GPU still stutters with DLSS On.....",
      "It‚Äôs great that AMD is forcing the VRAM competition even if they couldn‚Äôt compete on the top-end. At least NVIDIA is being forced to lower their price or increase VRAM on the mid to low end.",
      "If you google it you'll find reddit threads from 1-2 years ago laughing about this topic and saying 8GB is fine and AMD is dumb for putting so much VRAM on their cards, that it's just a \"trick\" to sell their GPUs because they suck.\n\nThat's what Nvidia gamers were thinking. And keep in mind the ones on Reddit tend to represent the more knowledgeable portion of gamers..",
      "To be fair, DLSS doesnt do that much for VRAM usage.\n\nDigital Foundry on this topic:\n\n[https://youtu.be/hkBTOUOqUCU?t=4278](https://youtu.be/hkBTOUOqUCU?t=4278)",
      "üéµVRAM killed the ray tracing starüéµ",
      "not sure where it was said, but nvidia hopes to replace gamers with ai customers...atleast a plan b",
      "This (vram) was a rising issue, 8gb don't cut it it's just people slow to catch up and pull their heads out of Nvidia's ass.\n\nAlso the 6800 nonxt seems like the golden goose of last generation of GPUs, enough horsepower to match or beat the RTX 3070Ti, 16GB vram, decent ray tracing and almost same or lower price than RTX 3070.",
      "I was debating between a 4070Ti or 7900XT, but this has definitely swayed me to the AMD GPU with its 20GB VRAM. I feel even 12GB is cutting it a bit fine these days.",
      "Hogwarts already using nearly 15GB of VRAM (12GB from game, 2.5GB for other stuff) at 1440p ultra with RT enabled. Those 12GB cards are toast in the future.",
      "The fact that some games run normally on 8GB GPUs, but look like shit, even tho settings are set to \"high\" and \"ultra\" is really problematic. In the past you at least got low FPS and would scale down settings as a result, here you don't even get consistant settings, it is all over the place. I guess game developers prefer angry posts about poor image quality over angry posts about poor performance.",
      "That's actually their goal, they want to be an AI company in the not so distant future.\n\nIntel's total worth: $135 billion\n\nAMD's total worth: $148 billion\n\nNvidia's total worth: an eye watering $662 billion. More than double the worth of AMD and Intel combined. Despite having a lower annual revenue than both.\n\nAnd this has very little to do with their consumer gaming cards. They could stop production of all Geforce GPUs, focus entirely on their professional cards and still make bank. Especially with the razor thin margins on RTX4000 cards. Smart people have invested in Nvidia because of AI. \n\nAlthough, if you had invested in AMD in Q3-4 2022, you would have doubled your money by now too..  crazy swings, almost like crypto.",
      "And yet only 20% of steam users (from the latest survey) had more than 8GB of VRAM.  Either the devs are out of touch or they just want to cater to the high end."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800xt"
    ],
    "title": "5600X + 6800XT first time with AMD proc",
    "selftext": "",
    "comments": [
      "Move your GPU to the top slot for better performance",
      "Please the gpu to the top.",
      "Already moved GPU to first slot. I will add benchs soon\n\n[New photo first slot](https://i.ibb.co/tp8XzMk/IMG-20201129-122817.jpg)\n\n\\-**Borderland 3 test BADASS QUALITY: 2560x1440p**\n\n*TOP PCIE SLOT*: 112FPS ***(+43%)***\n\n*BOTTOM PCIE SLOT*: 78FPS\n\nI am doing further analysis because this is toooo much difference...\n\n\\-**Unigine Superposition 1080 extreme:**\n\n*TOP PCIE SLOT*: 10263 vs  ***(+3,8%)***\n\n*Bottom PCIE:* 9885\n\n\\-**3dmark Timespy**\n\n*TOP PCIE SLOT:* [https://www.3dmark.com/3dm/53861960](https://www.3dmark.com/3dm/53861960) 14851 points ***(+8,5%)***\n\n*BOTTOM PCIE SLOT:*  [https://www.3dmark.com/3dm/53855003](https://www.3dmark.com/3dm/53855003) 13685 points\n\nIn this case GPU temp was even better on top PCIE slot (72¬∫ vs 74¬∫ avg)",
      "Yes, but one is directly connected to the CPU while the other one is going through the chipset. The performance difference is very small, but its not optimal.",
      "Lower slot is only 4 or 8x (depending on motherboard), while the upper one is 16x / 8x (16x if the one you're using now is unpopulated).\n\nAMD CPU has only 24 PCIe lanes, on X570 4 are for chipset (sata and so), 4 are for NVMe (the upper one, the lower goes thru the chipset) and the remaining 16 are switchable: 16 on top or 8 + 8.\n\nOn B550 first slot get the whole 16 lanes and the remaining ones gets their connectivity from the chipset.\n\nInterestingly X570 drive PCIe 4.0 chipset latched PCIe connectors, while B550 only gives you PCIe 3.0 ones. Not that much of a difference, but this partly explains why X570 requires active cooling.\n\nThat's why.",
      "Edit (already moved it) \n\n[Moved to the top](https://i.ibb.co/10gdHYG/photo-2020-11-29-19-55-53.jpg)",
      "Yep and that's why you always put the gpu as priority in the pcie hierarchy",
      "Last time I had an Amd gpu it was a 6850 so technically I am downgrading\n\n[Ryzen 5600x without vent installed](https://i.ibb.co/fnTVncX/IMG-20201127-212702.jpg)",
      "Why do the people who have no idea, argue with people who do.....?",
      "Try running [Superposition](https://benchmark.unigine.com/superposition) and/or [Furmark](https://geeks3d.com/furmark/). They're both free benchmarking utilities. Some games have in-game benchmarks, such as the Tomb Raider games. If you have 3Dmark ([currently $4.49 on Steam sale until 2nd Dec](https://store.steampowered.com/app/223850/3DMark/)), then you could use its Time Spy benchmark.",
      "ALL",
      "Borderlands difference was huge. I am thinking of doing a retest on bottom pcie to find out if initial test was wrong somehow",
      "Not arguing, but why? Want to see if I am missing something. See OP's reply to the other comment.",
      "This is a bit easier to understand.\n\nX570\n\n[https://www.gamersnexus.net/images/media/2019/news/amd/x570-chipset-block-diagram.jpg](https://www.gamersnexus.net/images/media/2019/news/amd/x570-chipset-block-diagram.jpg)\n\n&#x200B;\n\nB550\n\n[https://www.gamersnexus.net/images/media/2020/amd-chipsets-b550/amd-b550-chipset-block-diagram.png](https://www.gamersnexus.net/images/media/2020/amd-chipsets-b550/amd-b550-chipset-block-diagram.png)",
      "Except if you look at the specifications list:  \n\n\n>**AMD Ryzen‚Ñ¢ 5000 Series/ 3000 Series Desktop Processors**  \n1 x PCIe 4.0 x16 (x16 mode)  \n**AMD RyzenTM** **4000 G-Series / 2000 Series Processors**  \n1 x PCIe 3.0 x16 (x16 mode)  \n**AMD RyzenTM** **3000 G-Series / 2000 G-Series Processors**  \n1 x PCIe 3.0/2.0 x16 (x8 mode)  \n**AMD X570 chipset**  \n1 x PCIe 4.0 x16 (max at x4 mode)  \n2 x PCIe 4.0 x1 \n\nThat second \"x16 slot\" is limited to x4 lanes despite using a physical x16 slot. There will be performance loss by using that second slot, although it'd most likely be in single digit percentages.",
      "Its ok to move the card to 1st pci slot,  you were afriad the heatsink is too close to the gpu? If they are not touching its should be no problem.",
      "They are usually the same people who pay ass tons of money on top of what a product should cost for RGB all over their components/peripherals",
      "Thanks for posting the results! Can‚Äôt believe it makes that much of a difference.",
      "I want to test differences between both configs",
      "Bought it here in Spain... just at release... it was hell crazy because they werent listed so doing F5 all the time till somehow they got insta-listed then delisted but I was already at the article page so I was lucky to get one (669‚Ç¨)"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800"
    ],
    "title": "AMD's Radeon RX 6800 and the RTX 3060 are Faster than RTX 3070 in Doom Eternal w/ Ray-Tracing Enabled",
    "selftext": "",
    "comments": [
      "So it runs out of memory?",
      "Sort of. Doesn't crash or anything. Minimal stutters but the average is affected by quite a bit.",
      "\"Really 4gb of vram!\"\n\n>3.5gb fast vram\n\n>0.5gb s l o w vram",
      "Why i have feeling the rtx 3070 is the new gtx 970",
      "DOOM and DOOM Eternal are very sensitive to VRAM when the graphics are all the way up.\n\nDoes no one recall NVIDIA using 4K settings that made the 3080 choke a bit due to VRAM usage and made the 3090 look MUCH better by comparison?",
      "That's not the point. The point is that the 3070 has a 4K capable GPU but not enought VRAM for said resolution",
      "Generally tech press tests in highest available settings for maximum GPU bound test. That's pretty much industry standard.",
      "https://i.gifer.com/9U4v.gif",
      "There was fuckery with vram\nIt was advertised as 4gb but it actually was 3.5 + 0.5 (3.5 being of good, fast, memory giving you effectively 0.5gb less)\nIt causes stuttering and performance problems",
      "I agree that 8GB isn't enough today for a new high end card, but this ain't why. It's a setting that forces the GPU to cache extra unused textures in memory - reducing it doesn't affect image quality at all.",
      "Remember when they told us VRAM won't be a problem and we're overreacting?",
      "The VRAM in nvidia's cards is too damn low",
      ">Does no one recall NVIDIA using 4K settings that made the 3080 choke a bit due to VRAM usage and made the 3090 look MUCH better by comparison?\n\nI believe the comparison was between the 2080 and the 3080 and the scenarios in question would make the former run into issues with its smaller frame buffer. It's one of the few games that had the touted \"up to 2x performance uplift\", in part because of that.",
      "Yes that‚Äôs why people were doing 4K benchmarks with MSAA cranked up back in the day.  \n\nIt‚Äôs not always as simply as just cranking everything up.  Benchmarks back in the day used to run low/med/high quality presets for comparison which seems to have been replaced strictly by resolution tests.",
      "8gb is busted.... How long till it's 10gb?",
      "Yeh but also imagine paying all that money for a really small bowl",
      "No, that _is_ the point. The textual pool option in Eternal simply allocates additional VRAM, and has nothing to do with the quality of the textures. This is a non-issue *for this title.*\n\n8GB is small for a premium card, yes, but this case is an anomaly.",
      ">DOOM and DOOM Eternal are very sensitive to VRAM when the graphics are all the way up.\n\nYep. Doom was the game DF used to do the misleading \"3080 is two times faster than 2080\" video  (crippled perf by not fitting in 2080's VRAM)",
      "I'm sure they did know better, but \"Texture Pool Overflow Affects Performance in Doom Eternal\" doesn't net nearly the same number of clicks.",
      "Remember when this sub shat on Digital Foundry for testing Doom Eternal with Ampere gpus using this setting to purposefully make the 2080 perform worse (and thus make the 3080 look better)?\n\nNow people are using the exact same thing they criticized to shit on the 3070. Disingenuity at its best."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800"
    ],
    "title": "[Optimum Tech] Test Fitting the RX 6800 XT in ITX Cases",
    "selftext": "",
    "comments": [
      "The only fucking Youtuber I can actually stand more than 5 minutes of. No 20 minute unboxing videos like some people. No useless outtakes and gags, no screaming and acting a fool, no baseless claims, no beating around the bush and stalling, no filler. Just incredible and actually valuable information with a calm, cool and collected demeanor, and the best editing in the game to go along with it. Sorry Phil, but it's not even close. He is honestly the only one I truly trust as well, and he has been a godsend to the SFFPC community. If it sounds like I am a cuck, it's because I am.\n\nEdit: Even the fucking screenshot shown above for the video is perfect. No cheesy Photoshop, and no eye roll worthy click bait title. He just tells you exactly what the video is about in about 7 words. Love this man and his plain black shirts.",
      "omg this looks beautiful",
      "*cough* Jayz2cents *cough*",
      "Do the cards ship with googly eyes?\n\n[https://imgur.com/a/tv9bx5a](https://imgur.com/a/tv9bx5a)",
      "Optimum Tech always create relevant video. All other YouTubers just create unboxing video for the sake of having a video.",
      ">no screaming and acting a fool\n\nI wonder who you are referring to here lol.",
      "I dont know what it is but I cant stand that channel, and I like LTT.",
      "He's whiney and entitled, whereas LTT is mostly just \"disappointed\" if something isn't nice. I've tried to watch Jayz, but he's just so annoying to me. I watch LTT occasionally, but I prefer a more technical presentation. I mostly watch Gamer's Nexus and Level1Techs, but even they seem to have a bunch of filler.\n\nWhy can't I just get a 5-10 min video or short article that summarizes the important details. I don't care for staring at FPS graphs, I just want to see a general overview at each resolution. Leave the graphs and whatnot for a blog post, video should be concise and high interest, with links in the description for more details.",
      "ooooooWHAT is up guys, we're BACK with ANOTHER video card review, this time it's the RADEON! 69 (nice) HUNDRED XT! \n\nBeforewegetintothevideothoughguys, PLEASE smashthelikebuttonandsubscribe. It really us helps grow the channel, and don't forget to hit the notification bell so you don't miss ANY of the GAMER CONTENT we put out EVERY SINGLE DAY.\n\n\\*to person behind the camera\\* Haha, did we get everything?\n\nPerson behind the camera: \\*some bullshit haha we're relatable\\*\n\nHaha, WOO! Let's get into it!",
      "Lol, so many people here and on /r/hardware are too young to realize that good print media exists.\n\nGamersNexus was a print website for several years before Steve started a Youtube channel. Same with HardwareUnboxed Steve. He wrote for TechSpot for over a decade (and still does) before he even started doing Youtube. Almost all of their content is available in written form for anyone who wants to spend 5 minutes looking for it rather than mindlessly clicking on videos.\n\nThis doesn't even include the dozens of websites that exist and publish content with no Youtube analog. If you're complaining that you don't like these videos and prefer to read news/reviews/benchmarks, then you're just lying to yourself. The written content exists and is not hard to find. You're either just too lazy or don't actually prefer reading.",
      "You mean you don't want to listen to Gamers Nexus stretch 3 minutes of news into a 32 minute video?!",
      "Linus is very entertaining though.",
      "Well good thing I just ordered the Nr200p, I knew the 6800xt wasn't gonna fit in my ghost s1",
      "anyone gave a verdict on the silverstone sg13?",
      "And these days his staff is often more watchable than him. You got Anthony and Colin who are just great, Alex and Jake who are madmen with their projects, and even Riley (NCIX Keys) and James have truly come on their own. If there's one thing I won't give Linus shit for, it's how he treats his employees.",
      "Gamers nexus DO have articles too. So you can pick whatever.",
      "RX5700 reference barely fits in it. I doubt RX6800XT will.",
      "HU benchmarking 4 recently released games is not bad, that said exact dimensions are also welcome.",
      "I'm watching this thinking how nice it is that it would fit in my NCase M1.\n\nThen I remembered that I have a better chance of winning that iPhone draw on the apple sub that getting one.",
      "Second image reminds me of [this](https://i.imgur.com/82PYlbs.jpg)."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800xt"
    ],
    "title": "6800XT from Dell Alienware, impressive cooler surprisingly. Green PCB is not so nice.",
    "selftext": "",
    "comments": [
      "\"Any PCB colour you want as long as it's green\" - that used to be the norm like 20 years ago.\n\nOf course it would've been nicer if the PCB is black or red (or even grey), but as long as the card is okay, you don't have much to complain.",
      "I wasn't aware dell used oem GPUs in their desktop builds. Makes sense, though.",
      "If there's the choice between the PCB being green or costing a little more, green is the obvious choice",
      "Getting even older, brown was common.",
      "Sometimes they came in like a yellowish color. You could either get green or a yellowish green color.",
      "If there‚Äôs a choice between green and even getting one at all, green is the obvious choice.",
      "dell, alienware, same thing, proprietary is their thing",
      "Yeah, Dell does do that. Anything they make has the green PCB board, which, it's not a big deal, but I prefer the newer black ones",
      "Green PCB looks cool though",
      "This! Maybe I'm old, but I never understood why green became a \"low tier/budget\" thing. Remember those blue Intel MB PCBs? I liked those the most.\n\nBut then, I don't like RGB, so it's probably being 30s me.",
      "It kinda looks like a cost-down Radeon VII. Interesting!",
      "I mean if I was given the choice between no graphics card or green PCB graphics card I'm taking the green PCB. Even if it was $10 cheaper to buy new I'd take a green PCB.",
      "What is wrong with green PCB? It has some impact on performance? Or you can see it from kilometre away?",
      "The UD mobos from Gigabyte have brown PCB and I think it looks pretty. It reminds me of wood.",
      "I think the Radeon VII cooler still the best looking GPU cooler.",
      "TFW you buy a $650 graphics card for $650",
      "Dell are notorious for using awful coolers. Their proprietary stuff is complete garbage\n\nAlienware is literally the worst brand that exists in terms of quality",
      "I'd love to see cool red PCB, like on my old Radeon 9550 and Radeon x1600",
      "Red PCBs on ATI Radeon cards back in the day was nice too.",
      "Every once in a while you‚Äôd see blue, but I think that was only motherboards idk ¬Ø\\_(„ÉÑ)_/¬Ø\n\nEdit: YES I GET IT YALL HAVE SEEN BLUE GRAPHICS CARD BOARDS BEFORE."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800"
    ],
    "title": "AMD Radeon RX 6900 XT, RX 6800 XT and RX 6800 reference desings are being discontinued - VideoCardz.com",
    "selftext": "",
    "comments": [
      "Not surprising. Every AMD reference card disappeared when the AIB partner cards were ready.\n\n\nThe only downsides to this are the fact that the reference cards are thus far the most compact variants of the RX 6800/6900 series cards (they're shorter than all AIB partner cards and the RX 6800 non-XT refrence card is the only two slot card in the RX 6800/6900 series) and the fact that these cards were the safest bet if someone wanted to water cool theirs.",
      "Don‚Äôt blame yourself, sonny boy. You missed out on the reference card F5 bonanza. But I got some great news for ya! We have partner cards with your name on them, starting at just $899 + tax! Now, I know it‚Äôs not the same deal we talked about before, but don‚Äôt worry. Your computer deserves this card and so do you. Who cares about a couple hundred bucks here and there. So just enter your CC info today and you can have your card in time for Easter!",
      "Also makes it a nightmare for watercooling blocks. Means manufacturers like EK have to either not produce a waterblock or produce many different designs for all the different AIBs.",
      "So mrsp is literally a lie. Is there even any msrp 6800XT, if not this card literally isn't even a 650 dollar at all.",
      "So we are then stuck with overpriced AIB cards? Screw this... I was happy for GPUs to finally go down in prices and would have gladly payed 650‚Ç¨, but the AIB price markups are insane...",
      "So, AMD finally makes a competent reference design and they decide to discontinue it less than 2 months after their paper launch?\n\nlmao this is hilarious, I honestly didn't think AMD would manage to mess up their launch any worse than Nvidia did with their, but holy shit this is amazing.\n\n\nSo, what's the official MSRP of these cards now?",
      "so only 20 of each were ever made before discontinued. what is this, streetwear?",
      "Damn straight there mr salesman, i just dropped 1.5k new zealand dollars for a rx 6800 xt red devil card, pleasure doin' business with ya",
      "Are you fucking kidding me??? There was never even a chance to get one!\n\n>end of life\n\n?!?!!!",
      "Nvidia is still making FE months after launch while AMD‚Äôs reference production was basically dropped after 1 week lmao",
      "Oh it's not need. Air coolers are very good these days. Watercooling is purely enthusiast. But it is still a big market.",
      "They're not overpriced, the reference models were underpriced so that AMD could put a graph up to make the pricing look more competitive than it is.\n\nIt's an absolute disgrace, and I can't help but feel they'll do the same thing with the 6600xt and 6500xt, which are the cards I was actually looking forward to.",
      "so mr scott herkelman literally lied about saying the ref design will still be manufacturate until early 2021. it's not like i prefer the ref design or performance over aib models but aren't they suppose to exist to at least available at msrp ? aib models pricing is even worse than nvidia situation rn",
      "AMD is seriously becoming anti-consumer. I had high hopes and support for them through their dark times and now that they're even competitive with intel & Nvidia I thought only good times were to roll. NOPE! It's chuck \"fucking\" testa.",
      "Another downside is they are the only reasonably priced models.",
      "And 15 of them were sent to reviewers",
      "I wonder why you actually need a full GPU water block (except hard overclocking with powermod).\n\nI use CPU AIO on 1080 TI with a bracket. Sure it doesn't cover VRM or VRAM, but it has a 90mm fan that blows directly against main VRM. The I/O side VRM is a concern though, but all reviewers shown it's colder than with high-end air coolers.",
      "MSRP is also being discontinued with them",
      "Prices were a lie then and all reviews need to be redone without the fake US$649 price.",
      "According to what AMD told Hardware unboxed. Can we really take their word for it though?"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800"
    ],
    "title": "RX 6800 XT Midnight Black is a beast and a beauty",
    "selftext": "",
    "comments": [
      "Don't know if you know about this but you can actually change the colour of the Radeon logo on the 6800 XT and 6900 XT.",
      "Thanks for sharing this! Engineer on my team did a great job on it‚Ä¶ but it seems often overlooked.",
      "You just go to the AMD driver page, select GPU, select OS, then there should be a tool called \"AMD Radeon RX 6000 RGB Tool\".\n\nThe build looks great BTW. I also have a 6800XT Midnight coming in. Can't wait!",
      "I looked slightly into it but stopped, how do I do that?",
      "Thanks for letting me know! Enjoy your new card!",
      "That's a big ass cpu cooler. [Noice](https://youtu.be/UBX8MWYel3s)",
      "Beautiful rig dude! glad to see a special edition midnight black card getting into capable hands!",
      "Honestly, the midnight black version should have been the stock color of the card. I have a 6900xt and I love the card dont get me wrong but the 3xxx reference cards have a very classy look to them while these cards just dont.",
      "Yup, very much overlooked. Only found out because I noticed the logo diffuser is clear on the 6800 XT and 6900 XT. A quick google search and found out you could change the colour. Maybe should advertise it somewhere on the box?",
      "I doubt even AMD employees or executives know that for certain. Demand is unpredictable.",
      "An engineer who‚Äôs team mate worked on building the software (or firmware interface) for changing RGB lighting on a graphics card probably wouldn‚Äôt have any exposure to the logistics side of the company, sadly",
      "When I game or benchmark I see it around 65-69 range. I would say it cools just about the same as the 360mm rad but it is way more quiet in my experience. The Corsair H150i I had on balanced settings would make a ton of noise when i'm gaming",
      "Are those Lian Li chain fans? If yes, how do you feel about them?\n\nP. S. Looks really awesome BTW, the Radeon red logo really stands out with all the other white highlights.",
      "Yes they are. I recently just switched over from the Corsair QL120s. I like these a lot. Way more than the QLs. The whole ‚Äúunifan‚Äù design where you can chain them is game changing when it comes to cable managing. The back of my case looks more neat. They are easy to set up (6 wires in total for all the fans) and the diffused lightning look is great. The QLs I feel like has too many LEDs and can be too bright, along with having to cable manage 16+ wires and invest in the corsair ecosystem",
      "If the 6900 XT had this variant then it'll be slightly more desirable. I had a 3070 Founders Edition and it was hard to let go",
      "MSI's version to do the same is 200MB+.",
      "I had a 3080 before getting the 6900xt. The 3xxx series is just so well built and classy looking. These aren't bad by any stretch but man  the silver and red trim just is so meh",
      "That cooler looks like itll cool a car engine",
      "LOL I went from a 360mm rad to this, wanted to try something new. It's HUGE",
      "An engineer can do a great job on a features function, it takes a UX designer to make sure it‚Äôs presence is clear and appropriate."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "rx6800"
    ],
    "title": "Upgraded: rx580 to rx6800. Holy mother. Eye watering fast.",
    "selftext": "",
    "comments": [
      "I changed from Vega 56 to 6800XT recently and yes, the difference for me (gaming @ 1440p) is massive.",
      "Congratulations. I did the same basically rx580 to 6900xt.",
      "It's one of those moments where you don't understand how you could have lived without it till now.",
      "Wait until I get from Intel HD graphics to 7900xtü§¶‚Äç‚ôÄÔ∏è",
      "It is true but don't get me wrong, the Vega has served me well for almost 5 years but I found myself reducing the graphical fidelity lower and lower to keep the FPS around my 60Hz monitor's range.\n\nWith some luck and the new GPUs prices coming down I've managed to get the Nitro+ SE on sale brand new for ¬£649 (twice as much as I paid for Vega all these years ago). \n\nThis coupled with new CPU (5800X3D) and new monitor (165Hz) I can enjoy my system for another few years easily playing 100+ FPS in most demanding games (or reducing it with AMD Chill to a comfortable range whilst using much less power).\n\nThe 6800XT is a brilliant GPU.",
      "You really should stop daisy-chaining pci-e power. Not only is it a fire hazard, it can lead to some crashing issues due to transient power spikes that gpus produce.",
      "Thanks, to you as well.",
      "Congrats for living into the 202X graphics age. I remember in 2019, I was buying \"mining rig\" used Rx580s for like $95 off of eBay and Mercari.  Low and behold, the card would become the pandemic favorite and the resell market prices were over $300.",
      "I still love my Sapphire RX 580. Been one of the best GPUs I have had in years. I need to repaste her, been about a year.",
      "Congratulations in advance :D",
      "just waiting for the new amd gpus to drop so i can upgrade from rx470 to 6650xt at an even cheaper price",
      "i went R9-290, to temporary RX480, to RX6800XT, and yeah, big jump for real. the only reason i even did the 480, was i got a deal on a good used card, and the driver support had ended on everything before the 400 series, and i couldn't play Forza Horizon 5 due to driver issues.",
      "Because they are not out yet. If you always follow the \"next\" release, you never buy",
      "Can't wait to ditch my GTX 1080 for a sweet new RDNA 3 card",
      "I am running a RX580 right now and want to upgrade to this as well. Thanks for the post!",
      "Crappy products exist because there are people who‚Äôd still buy them. The very existence of wish.com is a testament to that.",
      "Why do they make such cables then? Always bothers me",
      "He was mentioning transient spikes, that said the 6800 is less of a worry than say a 6800xt -6950xt if overclocked.\n\nI can cause system shutdowns on my 6800xt if I OC too much using MPT due to transients even though the power usage shown in something like hwinfo is what is expected.\n\nStock with a decent power supply you should be fine though",
      "Yeah, the performance is awesome, and also undervolting potential, at least if you're lucky. I went from a reference Vega 56 that I bought for 160‚Ç¨ right before the GPU craze, to selling it for 420‚Ç¨ during it and buying a new reference 6800 for 900‚Ç¨.\n\nThe difference in performance but also noise was incredible. Then I managed to sell my 1.5yrs old reference 6800 for 515‚Ç¨ and bought a 3 months old MSI Gaming X Trios for 420‚Ç¨.\n\nI run this thing at 2300-2400MHz with an insane 880mV, it's so quiet, even compared to the reference model, which I actually liked more design-wise. Really happy about the decision, though. These GPU's are crazy price to performance wise, especially in my market, where Nvidia is still overpriced. Wouldn't want to support them anyway, though.",
      "Same went from Sapphire Pulse RX 580 to Sapphire Nitro+ RX 6800 and It's unreal. Can't wait to uv/oc this."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800"
    ],
    "title": "Stealthy mATX build w/ RX 6800",
    "selftext": "",
    "comments": [
      "OMG look how close it is to the GPU lol",
      "yeah it's a really tight fit lol, the backplate is so thick on the 6800 too, idk how I'll remove it if I ever have to",
      "[PCPartPicker List](https://pcpartpicker.com/b/jMx6Mp)\n\nManaged to snag a RX 6800 off amd.com at MSRP! this is basically my end-game build for the next few years :)",
      "Ive done that with my build too, but one day my screwdriver is going to slip off the clip and nick the Mobo and I am going to cry hysterically hahahaha",
      "Man that's a HUGE cooler for a 3600.",
      "personally i bought a solid cooler back when i had a 1600 because i knew that i‚Äôd upgrade soon and it‚Äôd last me years. now i have a 10900k and the arctic freezer 34 holds up excellently. \n\nabsolutely no shame in the big cooler on a 3600",
      "I bought this board back in 2018",
      "Ryzen 5 3600 clocked at 4.25GHz",
      "Why a B350? Unless I am mistaken, there are B450 matx boards around 70 to 80 dollars. I'm just curious.",
      "It will be fine.",
      "There is a big difference between clean and FUCKING CLEAN",
      "What CPU are you using?",
      "Honestly saying PCIe 4.0 doesn't make any noticeable difference. It is more of an improvement to a NVMe SSD (A PCIe 4.0 one obviously).",
      "I still remember the old AMD socket retention clips (CPUs) for the cheap heat sinks. You had to get a screw driver in them and push down to get the retention clip on the socket. One false slip and a screw driver comes down full force onto the motherboard.\n\nDid I mention the CPU beneath the heat sinks also had exposed tiles at the time? So all the while you had to make sure the pressure wasn‚Äôt too unequally distributed.\n\nI‚Äôm so glad things have moved on from those days.",
      "I did that once, and the motherboard died. Fortunately, the retailer was kind enough to give me a replacement.",
      "Oh OK makes sense. Nice build!",
      "yep! it's virtually inaudible though. at 1000 RPM, I never go over 65c, even in prime95",
      "I agree the arctic freezer is a beast of a cooler at it's price point. I bought it originally to replace the H80i V2 (my ryzen 5 1600 4.0  was thermal throttling). Hilarious that a cooler about half the price of H80 did a far better job cooling my OC cpu. \n\nI recently upgraded to a 10700k and it's doing a superb job cooling my cpu at stock settings, hell the fan barely ramps up playing games.",
      "I so hated those clips",
      "It's a really good cooler if you plan on going zen 3 later."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800"
    ],
    "title": "Completed my Build! 6800 XT",
    "selftext": "",
    "comments": [
      "Big Ass tower coolers have a style of their own. They're like like the big muscular bodyguards next to a VIP. Silent, but imposing.",
      "Dope!! I got my 6800.... little jealous you got that extra slot... but that Radeon in red is beautiful to look at. Enjoy!",
      "He's forcefeeding air which might be necessary due to the amount of space underneath",
      "I see a bottome intake fan just for the gpu, i upvote",
      "What's the reasoning behind the Extra fan crammed under the GPU?",
      "^^Be  ^^Quiet",
      "Love that",
      "More like the engine block on a powerful V8 engine.",
      "Learned it from the years with my Node 202 case. It was very tough getting this fan in (spot wasn‚Äôt intended for fans), but it made a huge difference",
      "Thank you!",
      "DAMN SON WHERED YA FIND THIS",
      "Yeah I can see that. But, would it be of any use since the air is just going to be recirculated i.e. no source to fresh air? I'm actually asking because if this actually works I'm tempted to try this",
      "Launch day, snail monitor discord, Newegg, Apple Pay",
      "dark rock pro 4 is awesome. almost silent with my 3700x. cant hear it i open my window even a little bit in a big city on a zero traffic street",
      "If he has another fan in the bottom front or below the psu shroud, it should definitely work, since air pressure below the GPU/shroud will be higher than ontop of it. This would force the air to go directly towards the GPU",
      "Can the Radeon logo be turned off?",
      "Cooler Master V8.  \nOr the actual V shaped Scythe kama cross. \nAnd honorable mention; scythe ninja that looks like the cylinder on a 1 cylinder air-cooled motorcycle.",
      "You can fit so much more RGB on an aio though right?",
      "One question \n\n**how**",
      "Mostly an anesthetic reasons I would say. \n\nThere is also clearance (tower cooler are big AF).\n\nAlso some misinformation. People think watercooling is better. Custom loop is better than any AIO/Air Cooler but AIO aren't really better than Air Cooler."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800"
    ],
    "title": "Radeon RX 6800 vs. GeForce RTX 3070, 40 Game Benchmark: 1080p, 1440p & 4K",
    "selftext": "",
    "comments": [
      "TL;DW- The RX 6800 is 11% faster in 1440p and 10% in 4K\n\nThe reason why those numbers are quite low from what some of us are expecting is because the Radeon card have issues in some of the games such as Warhammer Vermintide 2 and Kingdom Come: Deliverance and is neck to neck in some others such as Hitman 2 and Star Wars Jedi Fallen Order.\n\nPersonally this card should've been the same price as the 3070 if AMD is serious about undercutting Nvidia but it seems just like with Zen 3 they're being overconfident about their products which might or might not be the top dogs in the long run with ~~Comet~~ Rocket Lake coming soon and new titles will be able to leverage Nvidia's software and feature more 2021 and beyond. I'm hoping for price cuts across all their product ranges to remain competitive.",
      "Agreed. 6800 for $500 and the XT for ~$600 after the shortages would be extremely competitive against NVidia",
      "The $650 pricetag is fine for the XT version but you don't ever see them at those prices. Even in my country the 6800 XT has the exact same price as the 3080 which isn't supposed to be.",
      "The main issue here is the 6800 is closer to price to the 6800xt than it is to the 3070.",
      "# Timestamps:\n\n* [01:16](https://www.youtube.com/watch?v=5mXQ1NxEQ1E&t=76s) - Test setup \n* [02:41](https://www.youtube.com/watch?v=5mXQ1NxEQ1E&t=161s) - Battlefield V \n* [04:02](https://www.youtube.com/watch?v=5mXQ1NxEQ1E&t=242s) - Hitman 2 \n* [04:36](https://www.youtube.com/watch?v=5mXQ1NxEQ1E&t=276s) - Borderlands 3 \n* [05:01](https://www.youtube.com/watch?v=5mXQ1NxEQ1E&t=301s) - Fortnite \n* [05:28](https://www.youtube.com/watch?v=5mXQ1NxEQ1E&t=328s) - Apex Legends \n* [05:51](https://www.youtube.com/watch?v=5mXQ1NxEQ1E&t=351s) - PlayerUnknown‚Äôs Battlegrounds \n* [06:12](https://www.youtube.com/watch?v=5mXQ1NxEQ1E&t=372s) - Cyberpunk 2077 \n* [06:38](https://www.youtube.com/watch?v=5mXQ1NxEQ1E&t=398s) - Call of Duty Modern Warfare \n* [07:06](https://www.youtube.com/watch?v=5mXQ1NxEQ1E&t=426s) - The Witcher 3 \n* [07:35](https://www.youtube.com/watch?v=5mXQ1NxEQ1E&t=455s) - Control \n* [07:58](https://www.youtube.com/watch?v=5mXQ1NxEQ1E&t=478s) - Red Dead Redemption 2 \n* [08:30](https://www.youtube.com/watch?v=5mXQ1NxEQ1E&t=510s) - The Outer Worlds \n* [08:50](https://www.youtube.com/watch?v=5mXQ1NxEQ1E&t=530s) - Warhammer Vermintide 2 \n* [09:49](https://www.youtube.com/watch?v=5mXQ1NxEQ1E&t=589s) - World of Tanks \n* [10:07](https://www.youtube.com/watch?v=5mXQ1NxEQ1E&t=607s) - Kingdom Come Deliverance \n* [10:56](https://www.youtube.com/watch?v=5mXQ1NxEQ1E&t=656s) - 1440p \n* [11:42](https://www.youtube.com/watch?v=5mXQ1NxEQ1E&t=702s) - 4K \n* [12:06](https://www.youtube.com/watch?v=5mXQ1NxEQ1E&t=726s) - Final Thoughts",
      "Note, it's only 14% faster if you take those games out.\n\nI agree with you that AMD are being excessively greedy with pricing for the Radeon GPUs here. I can understand it with Ryzen, they've established themselves in that market, they are providing industry leading performance, they should charge a premium.\n\nBut with Radeon? Charging a 15-20% premium over the competition, with a worse software stack and worse features all around, for a 10-14% performance uplift is unacceptable. They need to aggressively take the market from Nvidia the same way they did from Intel with Ryzen back in 2018. RDNA2 is in many ways comparable to Zen+ and Zen+ was, and even still is, insanely good value for the performance you get out of it.",
      "I really really wish u/HardwareUnboxed would be more careful when arguing against the 8GB VRAM of the RTX 3070. They said:\n\n>and we've already got a number of examples where the RTX 3070 is hamstrung by its 8GB VRAM buffer: Doom Eternal using the ultra nightmare preset is one example, Cyberpunk 2077 with ray tracing enabled is another and there would be more to come surely (shortly?)\n\nWhy is the RT performance in Cyberpunk 2077 mentioned here? With RT enabled the RX 6800 would be almost unplayable. So how come this is mentioned as a shortcoming of the RTX 3070 versus the RX 6800?",
      "For me (UK here), I got the rx 6800 for ¬£10 less than an AIB 3070 I also had, so the 6800 was a complete win for me, region pricing for these seems to vary wildly",
      "tbh, anyone who doesnt need the high end cards for some specific reason, will be very happy with either of those cards for msrp. \nComparing with msrp you get 10% more performance for 10% higher costs. So you should choose between the amd brand or far superior rtx performance. (And special cases of cuda and so on)",
      "Performance doesn‚Äôt matter if neither exists anywhere",
      "Exactly, in Portugal there is only one model for 6800 and 6800XT that is listed at the msrp\nAll the other models are 70+‚Ç¨... It's actually kinda annoying\nCause i wanted a 6800/6800XT but the ones available are all way over msrp",
      "It's common knowledge that the 6800 beats the 3070 but if only you could buy a 6800 for MSRP that would be a great buy.\n\nEven 100 euro more than MSRP i'd be fine with, but what i'm seeing is at least a 250-300 euro extra if I want to own a 6800.\n\nI went for a 3070 that was 100 euro over MSRP.",
      "It's 16% though",
      "Yeah... where i live both 6800XT and 3080 go for 1200‚Ç¨+.  \n6800 non XT for 1000‚Ç¨+  \n\n\nAt least i got the 5900x at msrp.",
      "You mean Rocket Lake? I won't hold my breath on a back-port from Ice Lake to 14nm. Even Ice Lake notebooks weren't that much of a competitive challenge for AMD.",
      "Yes because they're testing on stock basis. DLSS, SAM and overclocking results aren't tested",
      "No? For $50 more you get equivalent rasterization, way better raytracing, and better features in the 3080. $600 would be a very compelling pricepoint and if the 6800XT were $600 I probably would have gotten it. Instead, I felt like the 3070 was the better pick for me (especially because I was able to find one).",
      "Where I am, the 6800 is $150usd more expensive than the 3070 cards and it's only $30usd away from the RTX3080.\n\nSo I don't know, maybe the 6800 vs 3070 makese sense in HUB land but where I am the 6800's competitor is actually the RTX3080. 3070 vs 6800 doesn't make sense for me personally because the 6800 is 10% faster but 30% more expensive",
      "Neither card is future proof and the VRAM won't change that.",
      "But keep in mind that top 5 (with 30% lead) games are just as misrepresentative and are also the exeption and not the rule. Im mean in ac vallhala the 5700xt matches the 2080ti ... Like wtf"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800xt"
    ],
    "title": "My all blinged-out AMD rig. (5600x, 6800XT, Turtle)",
    "selftext": "",
    "comments": [
      "Damn golden rig",
      "What are the clock speeds of the turtle?",
      "You might be shell-shocked, but it's a fat zero for all of them. Too bad everything else is bottlenecking turtle's performance.",
      "Black and gold never dissapoints, looks dope!",
      "Dog?",
      "[I love goooooold](https://youtu.be/HnzH15hwt48)",
      "This is nice. I like lighting when it‚Äôs a single colour in the system.",
      "It's Adam Jensen's personal rig.",
      "Just reseat the turtle and Afterburner'd the heck of it",
      "Yeah that's what I went for from the beginning. Thank you!",
      "Ahhh, Dog",
      "Your faja must be proud",
      "I really like this. Well done.",
      "Really clean and aesthetically pleasing build, nice work!",
      "Thank you. :) This is the RGB strip I used twice:\nhttps://www.amazon.com/GIM-Compatible-Magnetic-Addressable-Gigabyte/dp/B0899P2SBD (GIM KB-14 RGB PC Light Strip)",
      "Praise the dog!",
      "It's kind of sad that gold is falling out of favor for rose gold in tech products.",
      "Thanks! One of my main goals obviously.",
      "Thanks! For Corsair iCUE? To be honest, I'm just using a profile I found here:\nhttps://lewisgerschwitz.com/corsair.html\nIt's the Pumpkin profile from the Halloween collection. Maybe go from there and make adjustments if needed.\n\nFor Gigabyte RGB Fusion, I'm using the standard yellow color on all devices. (GPU, Mainboard, Strips)\n\nThe image makes my rig probably look more golden than it actually is. Have been struggling with this as well, but it's still my favorite RGB setup!",
      ":D Maybe a step up in terms of GPU, CPU or Mainboard, but I can't complain. The \"bang for buck\" above 6800XT or 5600x doesn't improve at all, and I'll be able to do all I need and want to for years to come."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800xt"
    ],
    "title": "Replaced a 10 year old pc recently! 5800x3d 6800XT",
    "selftext": "",
    "comments": [
      "I adore XFX's GPU shrouds",
      "Replaced a 10 year old pc recently! 5800x3d 6800XT\n\nhttps://i.imgur.com/FZm5rJs.jpg\n\nParts list here! https://pcpartpicker.com/b/4jNPxr\n\nReplaced this guy: https://pcpartpicker.com/list/YC9423\n\nWent the lazy way with undervolting the cpu and just gave it -10 per core. May creep it up. I am currently getting about 63c average in game. 62c average on the 6800xt. Only minimally tweaked the fan curve using msi afterburner. Not a pc person but am now becoming one!\n\nPosted this earlier this week but got taken down for breaking the weekend rules!",
      "don't mind these lame commenters, that is a very sweet build and you will be able to run everything up to 4k if you really want to.",
      "Sick setup bro. It will carry you for many more years to come.\n\n\nI just snatched myself a 6700 a month ago. Best ever GPU I've ever had !",
      "it's recommended that you run two seperate pcie cables from your powersupply to your graphics card rather than using one cable and its daisy chain. Each cable is rated for 150w and your graphics card can pull 300w. Nice all black build though",
      "They probably like having more than 10% profit margin.",
      "And here I am thinking of switching my 6800xt for a 7900xtx haha fucking consumerism",
      "No dumb RGB, simple, clean - this thing's superb",
      "I believe its generally recommended because you don't 100% for sure know what's on the other end in the psu. Some are meant to put out that much power and support their daisy chains in that manner, while your mileage may vary with others.\n\nThe cables themselves should be able to handle it if designed to spec. I have a Corsair SF 750 and it was confirmed by Corsair that it was intended to be used as such. There are various places that test out the limit of spikes as well. The SF 750 delivers around 950 watts of oversurge before shutting down. Its probably best to confirm with your manufacturer though.\n\nI've been using a 6900xt daisy-chained for awhile with no issues, though it is just the reference model with no overclock.\n\nHere's a link that helped me better understand the EE side of it.\n\n[https://linustechtips.com/topic/1431258-how-much-power-an-8-pin-to-2x-62-pin-connector-can-output/](https://linustechtips.com/topic/1431258-how-much-power-an-8-pin-to-2x-62-pin-connector-can-output/)",
      "Looks really clean. I upgrade recently from a 4790k and a 1070  to a 5800x and 6800. Enjoy.",
      "I ran a 8320 + 970 combo for a while too. Upgraded to a 3600 cpu a couple years ago but I‚Äôm still rocking that 970",
      "Yea they look so damn gooood, wish they did nvidia too.",
      "No matter what there‚Äôs always something out there better than what you already have. And someone will always wish that they had what you have. Stay Humble gamers.",
      "I have a feeling you don't understand computers very well.",
      "What in the hell is wrong with you?",
      "I just upgraded a 770 to a 3080 and I'll be upgrading my 4790k to a 7950X3D soon, can't wait!",
      "Absolutely.  Newest games even can hit at least 60 fps easily with that card.  I have the 5900x.  Was a free upgrade from my 5800x that a coworker bent the pins on.",
      "Sorry to hear that",
      "Tell me you are spoiled asf without telling me",
      "There is more to that recommendation than is perceived by most.\nIf they are smaller than 14 gauge cables then it is recommended to run individual cables. It actually has nothing to do with the amount of power running through the cables but the resistance of the wire itself. Wire degrades throughput by resistance to amperage requiring more voltage to move the amperage. This is why quality power supplies output 12.3v-12.5v on the 12v power wires. 14 gauge can handle about 28 amps before going below the 3% voltage drop required for critical or sensitive components.\n\nExample at under 2 feet for 14 gauge wire \n12v*25 amps is 300w total\nVoltage drop of 0.31 or 2.59%\nSo only 11.69V*25 amps or 292watts is actually making it to the end of the wire (graphics card). Shorter distance or bigger wire is the only way to lessen the problem.\n\n12v*28 amps is 336w total\nVoltage drop is .35v or 2.9%\nSo 11.65v*28 amps or 326w is actually making it to the end of the wire (graphics card).\n\nTo fully understand the issue look at a marine wire chart for amperage by gauge for critical components and a voltage drop calculator.\n\nhttps://www.bluesea.com/resources/1437\n\nhttps://www.inchcalculator.com/voltage-drop-calculator/"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800"
    ],
    "title": "AMD Radeon RX 6800 drops to $469, while RTX 4070 is still in stock - VideoCardz.com",
    "selftext": "",
    "comments": [
      "$399 sounds right for both cards.",
      "Kinda wanna sell my card and get a used RX 6800 / 6800XT to be honest. The only Nvidia exclusive feature I use is DLSS, which will be missed, but i'm sick of having the worry about VRAM since I play at 1440p.",
      "The prices are in free fall. I predict the prices will fall further. Mindfactory still has lot of 4070 in stock at MSRP or close. That's extraordinary for a new GPU launch. \n\nWe are in recession lads. The new status quo has arrived.",
      "Dips where? Still $600-650 in Europe :(",
      "in europe still > 600$/‚Ç¨",
      "Same. My next card will be AMD. Killing Gamestream was the final move to push me over.",
      "4070Ti should have been 4060Ti at 399.\n\n4070 should have been 4060 at $350\n\nthe true 4070 should be the current 4080, at 499\n\n4080 Super 20gb at 599\n\n4080 Ti 20gb at 799 \n\n4090 at 999\n\n4090Ti/Titan at 1599",
      ">4070Ti should have been 4060Ti at 399\n\nBy that logic, the 7900 XT should be $399 as well, since AMD has clearly pegged its value to that of the 4070 Ti.\n\n1. The \"4080 12GB\" was originally MSRP $899 before being \"unlaunched\"\n2. The 7900 XT gets announced and later released for $899 despite that price making no sense next to the $999 7900 XTX.\n3. A month later the rebranded 4070 Ti releases for $799\n4. AMD (eventually) drops the 7900 XT to $799",
      "Prices are not in free fall. That would be lovely, but it‚Äôs not the case. The new cards have been holding steady at msrp, with the occasional modest sale. \n\nSome good deals to be had on last gen AMD cards for sure, but free fall is a bit hyperbolic.",
      "They named their 7800 the 7900XT to try and overcharge for it so, yeah.",
      "Soon the price difference will be so big I‚Äôll just fly out and come home with a few GPUs.",
      "I‚Äôd bite at 297 instantly, even though I don‚Äôt feel the need to upgrade my tried and true 5700xt",
      "Oh, my bad. That one card can be had for like $80 under msrp now. \n\nTOTAL FREE FALL. \n\nGrab one at the bottom of a dumpster near you, spring ‚Äò24.",
      "If the best AMD can do with their high end hardware is compete with cards that should be the xx60 ti and xx70, then they would also have to price them accordingly. Lucky for AMD that Nvidia decided to make a giant price increase.\n\nI'm not saying they're in on it together, but it does seem awfully convenient for both parties.",
      "The reference RX6800 has a msrp of 579. I know that an aftermarket version is slightly more expensive, but still it's been 2.5 years now for a mediocre +/- 110 drop. I don't consider this as a free fall. I was expecting between 350-400 by now.",
      "Funnily enough, the GTX 770 10 years ago was a rebranded GTX 680, which was likewise accused of being put too high in the product stack.",
      "> I'm not saying they're in on it together, but it does seem awfully convenient for both parties\n\nThose must be the \"corrective forces of the free market\" that I've heard so much about.",
      "Would it be weird to wait for the 7800xt just so I can have a 7800x3d/7800xt build?",
      "GameStream sucked anyway. I bought a 20 ft active HDMI cable and will never look back.",
      "I bought it a week ago for like 100 more ü•≤"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800xt"
    ],
    "title": "Bought this factory refurbished 6800XT for $405",
    "selftext": "",
    "comments": [
      "where? also congrats",
      "Congrats. I got a 6900xt for $570 and here I thought I got the best deal haha",
      "From lttstore.com?",
      "Local distributor. Me and my friend bought one each.",
      "I had that option for $600 but chose the 6800XT since gaming will be limited to 1080p/1440p plus the $200 savings.",
      "Lol ...",
      "Bro i got a 6600xt for 435e a week ago, damn you americans",
      "What‚Äôs the currency so I can convert it to cheeseburgers per block",
      "Sick, have fun with it",
      "Did it came with LTT Water Bottle?",
      "Definitely a better choice, Extra $200 isn't worth it for 6900xt. What was the problem with the card tho?",
      "No clue. The local distributor was just selling a bunch of them. Said it was sent back to the factory and repaired. Came in a sealed box. Looks brand new. They gave me 3 months warranty but honestly GPUs don't die easily (if you use the right PSU/cables) so if it passes the 3 months mark without a hiccup then I'm not stressed about it long term. Plus I doubt I'll lose much value if I plan to sell it next year outside the warranty period.",
      "Thats what I say all the time for fuck sake, thats what I envy about americans, fucking garage sales, godwill stuff and shit like that. Freaking 10$ gpus that work",
      "Can you let me know about the local distributer?",
      "These [guys](https://www.pcgarage.me)",
      "Noted üôÇ",
      "Yeah,  linus sex tips",
      "580-> 5700 -> 6800xt, never had a driver issue.",
      "Check your drivers, OS, and the rest of your system before blaming AMD. Same goes for NVIDIA.",
      "I had driver issues with the 5700 XT that was resolved soon after launch. Never had any issues with my new 6700 XT other than it failing (but that was probably ASUS's fault, got it RMAed).\n\nI had numerous driver issues with my 3060 Ti and with a 3070. I don't swear off NVIDIA cards though."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800"
    ],
    "title": "6800 XT Midnight Black is awesome! First AMD build. waited years for this!",
    "selftext": "",
    "comments": [
      "very nice setup! i always wanted that hsf...",
      "Seeing that cooler instantly made me angry. I broke 2 MBs because of this stupid thing.",
      "Thanks man! I got lucky and got it at MSRP from AMD's official website.",
      "Sorry to hear that bro. What happened? I love this cooler",
      "Sick Build bro, and congrats on getting a GPU",
      "Wait, is the Midnight Black Triple 8 Pin? Or is it Dual 8 Pin, but your RGB is just sticking out?",
      "It's double but i used a triple 8 pin strimer and removed one part of it and moved the 2 remaining cables to the centre.",
      "Thanks a lot bro! had to spend many weeks trying my luck on the AMD drops. But it was worth it in the end. cant complain when I have this beast for 650 Euros",
      "I like the simplicity in color choice, but it also looks bad ass!!!",
      "Taking off the fans were far harder than they have any right to be, making me get rougher with handling the while system than normal, breaking them.\n\n  \n\n\nGoing with the Scythe Ninja 5. You don't have to take off the middle fan to access the screws to take them off, and the clips that hold onto the heatsink actually have little parts sticking out that makes it far easier to remove the fans should you need to. The DRP4 doesn't have the clips stick out which means I need a flathead or knife to take it off.",
      "sorry but i have to disagree with you on that. I actually went with an air cooler so that i don't have to tinker with it anymore and it has almost no point of failure in the future beside the fans and they can be replaced easily. big ones like this and the Noctua competitor run extremely quiet. i sent mine to max 60% fan speed and I get amazing temps.",
      "https://gathering.tweakers.net/forum/list_messages/2027306/0\n\nThat's a link to a Dutch page that has a lot of advice on the Thursday drops. You can translate the page with Google.\n\nAlso join a discord alert server.\n\nMy tips are:\n\nLogin to PayPal on a separate tab and set auto refresh add on so that you won't get logged out.\n\nUse the script that you should find on that page. It basically makes the add to cart button appear. Without the script there is almost no chance. Drops are usually at 5:33 central European time. I started using the script every minute starting at 5:30.  However AMD fuck with us every once in a while and drop earlier around 4 or later around 6.  But most of the time it's at 5:33",
      "Noice!  About to put the exact same card in my system but it will not be quite so pretty.  Also on big air with a Cryorig R1 Ultimate with 3x 140mm fans.",
      "Nice! Enjoy the card man! It's a beast. Running everything 1440p at ultra",
      "What was your process for getting one on their site? I‚Äôve been trying for a bit now to no avail",
      "Glad you like it! It's very calming and not too much at all in my opinion.",
      "ah yes true, it was tricky taking off the middle fan especially with smaller cases. I hate to use the included screwdriver to reach far enough. no way I could have reached with my hands. and my hands are actually small.",
      "While I agree that it's a bit tricky to get the middle fan out, i still love the cooler. I changed CPUs on my brother's build with the same cooler and it was no problem using the screw driver. It can be made easier but i don't mind spending an extra 15 minutes if i can have a nice looking quiet cooler.",
      "Absolutely beautiful",
      "Thanks bro! I love Lian Li and AMD!"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800xt"
    ],
    "title": "Upgrade day! Vega 64 to 6800xt",
    "selftext": "",
    "comments": [
      "congrats that's gonna be a huge boost",
      "Yeah it is! The Vega served me well until I switched to a super-ultrawide monitor (3480x1200, so roughly 2.5k). Now this thing is crushing it.",
      "> Strangest part of the upgrade is that it made my RAM oc unstable. Still working through how that could happen since I didn't touch settings for it.\n\nYou lifted your GPU bottleneck, so now your CPU is more likely to present one. CPU and RAM are more dependent on each other.",
      "Out with the venerable MSI Vega 64 air boost, in with the Sapphire Pulse 6800xt. Going through settings and benchmarks now. Surprised how big a jump SAM made. \n\nStrangest part of the upgrade is that it made my RAM oc unstable. Still working through how that could happen since I didn't touch settings for it.",
      "Exactly what happened to me, running Radeon VII then upgraded to 3480x1200 and watched my GPU cry. Luckily for me, the funds from selling the VII more than paid for my MSRP 6900xt replacement.",
      "Still on Vega 64 üí™",
      "Lttstore.com",
      "The VII is also god tier at mining. That and it being rare is why it maintains value. BIG HBM2 quad stack energy",
      "yup still holding a good value and kinda rare too",
      "I can hear that blower styled Vega 64 even though it‚Äôs unplugged.",
      "I had a PCIe 4 ssd already (wd black), and it didn't cause issues. Guessing EMI from the new gpu is most likely.",
      "Pcie 3 vs 4?  EMI from the new gpu?",
      "Same.\n\nNot even considering it until RDNA3.",
      "Had a Steel Series one about the same size before this and it was great, I just didn't like the solid black cause it showed dirt. This is the first printed one I've had that didn't fade in a month.\n\nMock em if you want, but it's a good desk matt",
      "That must feel amazing",
      "Well enjoy the new toy.  I do love my powercolor red devil 6800 xt for messing around tweaking and overclocking.",
      "Good thing I sold my vega 64 a couple of months ago for slightly below its retail price. But what to upgrade next. The RX580 does her job kinda ok running ffixv on 3440x1440.",
      "Not considering anything until graphic cards will be in a normal price.",
      "Are the Vega cards holding price as well as the VII? I went from a 56 flashed to 64 to a 6800xt that I got lucky with in the amd queue a couple weeks ago. \n\nI have the components to make a server/spare/2nd pc out of the left overs, but would it make more sense to sell the vega56 now, sit on the 2nd computer idea and get a cheap MSRP card in 6 months?",
      "Red Dragon K556"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800xt"
    ],
    "title": "Wait, 57fps with SFR at 4k with 6800XT ?",
    "selftext": "",
    "comments": [
      "I wouldn't be worried, pc port is apparently true 4k while ps4/ps5 version where upscaled using checkboarded\n\npc is also getting unlocked fps and other graphical improvements. you're basically getting the version of gow that devs wanted everyone to enjoy.",
      "Wait until you see the 1% lows",
      "To be fair that's still 1662p + the small frame rate hit FSR costs. I'd imagine this would mean like 70fps if you played at native 1440p with no FSR. Still not great, but who knows what kind of useless things they incorporated into \"Ultra\" settings.",
      "exactly, people overestimate average framerate while ignoring 1% lows. 57fps average, so 1% lows are in 40ies range and that's with FSR? Unless there's something super taxing at ultra - that's pretty shitty result",
      "Yep, never play ultra, always go high and some stuff medium to gain FPS with no quality loss",
      "Finally a game with proper Ultra settings. It has been years since we last had one with Ultra Settings intended for future hardware.\n\nUltra presets are dumb for gaming, use high.",
      "Cyberpunk awkwardly sitting in the corner intended for the RTX 10090",
      "You‚Äôre not wrong. The [visual] difference between ultra and high is usually pretty minimal in most games.",
      "What is this peasantry? If I can't play at ultra, I uninstall the game.",
      "Played it on ps4 and will play on pc. O.O you not special",
      "Interesting: God of War was tested on the old driver 21.5.2 with Windows 10 October 2020 version. I hope that in the release version with new drivers, performance will be much higher, otherwise you can already panic about optimizing the game.",
      "in few weeks yes lol",
      "Not to mention ultra presets typically crank AA to the max, which generally isn't necessary at 4k.",
      "Obligatory \"we are not the same\" meme here",
      "gow is on pc now?",
      "I leave the room.",
      "Isn‚Äôt cyberpunk more cpu heavy as well so if you don‚Äôt have a really beefy cpu to match to let‚Äôs say a 3090 your kinda f‚Äôed",
      "> while ps4/ps5 version where upscaled using checkboarded\n\nPS4 is also like 8x weaker lol",
      "Ultra 144fps or I leave the room.",
      "Either the game is extremely badly optimized or they are using ultra settings that have a high performance cost."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800xt"
    ],
    "title": "Kopite: \"Mining performance of the 6800XT is a bit higher than the 5700XT, but much lower than RTX 3080.\"",
    "selftext": "",
    "comments": [
      "Terrible, now don't buy them, the 3080 is better please buy it.",
      "Wow. No one should buy these. Terrible",
      "Clearly a mark of weak and faulty gpu, AMD should be ashamed of themselves. Everybody should really avoid buying this generation gpu and should just stick to earlier generation.",
      "Yeah, totally not worth it. Everyone line up and wait for the RTX3000s, they are so much better and I'd recommend them to anyone who wants to buy a graphics card right now !",
      "Unfortunately for us N21 stock will probably seem super low precisely *because* nobody can buy 3080s and want something just as fast.",
      "N21 is terrible, don't look at it at launch (wait 3 months), go seek the 3080. Great value!",
      "Pile of garbage. Can't wait to not have one of these in my PC.",
      "Good.  Please keep it that way.  Don't want to have to deal with scalpers and their distant relatives too.",
      "First time AMD fans are glad Nvidia is faster xD",
      "Petition to open micro center in every major city",
      "I recommended my grandfather a 3080. Great value! Definitely better than the Rx 6000 series.",
      "Why get garbage when you can get great value! Get the 30 series ;)",
      "I walked into a microcenter on Zen 3 launch day at 2pm and bought a 3080 EVGa FTW for an employee with his credit card. They had manyy in stock. It was quite odd.",
      "THE MORE YOU BUY THE MORE YOU SAVE",
      "And in the rest of the world",
      "I assume everyone is just fucking around and cause there's no stock they want to joke and tell people to buy Nvidia cards so there's less competition for the new rdna2 cards.",
      "\"The Toyota Urban Cruiser...\"",
      "Radeon VII is still best mining card from AMD. Undervolted and memory OC and its even better.",
      "Go for the 3090, its even better.",
      "Or Nvidia"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800"
    ],
    "title": "My Entry to team Red 5800X3D + 6800 XT",
    "selftext": "",
    "comments": [
      "Impressive cable management.",
      "System components 9/10\n\nStyle and Ergonomics 0/10",
      "Nice specs it's gonna run great but that is a horribly messy build.",
      "Sarcasm taken thanks for the chuckle though xd",
      "Built my son a 5800x/6800xt rig for Christmas and it's a ripper. Congrats on the new system!",
      "\"It just works!\"",
      "Ergonomics? Are you regularly using your cases as footstools?",
      "Dont listen to these guys, if it works, it works!",
      "That is completely pointless, if the case still does it job (holding shit in place), no need to change it except for aesthetic purposes.",
      "Cable managemen‚Äôt",
      "I've seen worse. We've all seen worse, he may be going by the term life's too short for cable management.",
      "As god intended",
      "There is no PSU shroud so the cables are out in the open and you run the CPU fan cables out of the top of the cooler instead of hiding them underneath by flipping the fans. A bit more cable management and it would look pretty nice",
      "You are an awesome dad!",
      "Those are load bearing cables holding the cooler in place",
      "Why should he if the old one works fine?\n\n You should upgrade because of a need, not because something is simply old yet still good.",
      "Case is 7 years old never had a shroud",
      "I mean its still a great case being a bequiet silentbase 600",
      "Correct",
      "Cosmetic shit doesn‚Äôt affect performance. \n\nDoesn‚Äôt matter how it looks with the side on the case and tucked under a desk anyway."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800"
    ],
    "title": "Is it just me or the Radeon 6800 XT is a combination of the front and back end of the 197O Dodge Charger?",
    "selftext": "",
    "comments": [
      "Is it just me, or did the original poster put an \"O\" rather than a zero in \"1970\"?",
      "I'm glad your mind is at peace now.",
      "AMD: Dodge Charger   \nNvidia: Doge Neon   \n   \n^(This post brought to you by the /r/AyyMD/ gang.)",
      "yes",
      "Oh man i was in the same boat. Thank you",
      "Given how HD5870 was inspired by Batmobile, I don't think it's absurd to think their latest GPU design was also inspired by a car.",
      "With the way the market is right now, ive seen them go for in my area up to 2000",
      "RX 68O0 XT",
      "Glad I'm not the only one. It also reminds me of the og Battlestar Galactica cylons.",
      "How much is this video card",
      "[Like this?](https://i.imgur.com/IDOF7Km.jpg)",
      "Indeed. Nice catch",
      "197 O",
      "Please put two different power cables in that baby! Love the card I have the same one!",
      "Throws me for a L0OP",
      "Good one. I laughed out loud.",
      "It is not me, it is just you. we can't go on this way with suspicious minds.",
      "I'd this the top of the line card now",
      "Fun fact, the guy that designed K.I.T.T.'s scrolling sensor in Knight Rider based the design on the og Battlestar Galactica's Cylon Centurion helmet. \n\nCoincidentally, both series were created by famed show writer Glen A. Larson.",
      "I don't know how you thought of a 1970 Dodge Charger (except for the grill I guess) when it clearly looks much closer to, say, [a 2019 Dodge Charger](http://sf.co.ua/id30577)"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800xt"
    ],
    "title": "My first build: 5900X + 6800XT, all black yet all red",
    "selftext": "",
    "comments": [
      "Jesus, that GPU almost doesn‚Äôt fit!",
      "That‚Äôs what she said.",
      "That cooler looks a bit small for an 5900x.",
      "If thats the Noctua NH-U12S I have the same one on my 5900x and it runs good... then again I can't ever get above 30% load because my 1660S is a bottleneck ü•≤",
      "Very nice .. How are your temps?",
      "Whilst I agree it‚Äôs far from ideal. No need to shit on the guy on his first build. Instead you could have suggested a better case and a better cooling solution.",
      "CPU tops out around 73¬∞C or so, GPU around the same, while gaming at 4K in games like MSFS 2020 and RDR2. So well within the chips‚Äô recommended temps.",
      "In cases bigger isn't necessary better.",
      "hard disagree. Perfect fit is a lot more attractive than taking up excessive space on your desk or floor, without accomplishing anything. This build could be 1/3 of the size, actually.",
      "You named your dick GPU?",
      "Slight angle on the GPU hurts my ocd",
      "Ummm......",
      "Hi case brother! [https://imgur.com/mHvNKwR](https://imgur.com/mHvNKwR) \n\n5800x, with a DH15S squeezed in. Good taste you have on the Chromax. \n\n(apologies to the subreddit for the GPU).",
      "You didn't?",
      "I‚Äôve got the same case with a 1080ti and a 5950x temps and noise are fine. Fractal is pretty good wish case design specifically around isolating noise",
      "It is, and it works perfectly fine. CPU temps rarely get above 73 or so degrees Celsius, so no worries really.",
      "Yeah, so most people's typical use case isn't running Prime 95 and Furmark simultaneously for 12 hours, so it doesn't really matter.",
      "No RGB 1337 stuff, take my upvote!",
      "Just what I thought. Such a beast deserves a bigger, better case.",
      "Nah, I named mine CPU cause it cums in smaller package and fast."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "rx6800"
    ],
    "title": "Officially joined team red today. PowerColor RX6800 16GB.",
    "selftext": "",
    "comments": [
      "Is buying RX 6800 over RX 6700XT worth it?\n\nIn my country, Sapphire pulse RX 6700XT is $422 and Sapphire pulse RX 6800 is $664. Is the $240 premium worth it for RX 6800 ?\n\nEdit: 1440p gaming.",
      "Fuck Jensen",
      "Jensen is unhappy seeing you go red :)",
      "Fuck Jensen",
      "Upgraded from an EVGA GeForce 1070ti. Smooth installation using DDU with no problems.",
      "Depends if the used market price is good enough, I got my rx 6800 for 400 bucks. It came with all the original packaging with even some hardware still unopened. I still ran tests recommended by tech YouTubers to make sure the card is in good health.",
      "Fuck Jensen",
      "That's a really big difference so I'd say no. In US the difference is little so people jump to 6800 even 6800xt as it sometimes discounts really low to 550",
      "Might wanna change that 550W PSU to a bigger one",
      "Fuck Jensen",
      "big card = big pp\n\nalso AMD = big pp\n\nOP must have massive anaconda pp",
      "All my homies hate Jensen",
      "wowww that's a big card",
      "I bought a ASRock Phantom Gaming 16GB OC 6800XT Card a few months back. I have loved using the Adrenalin Software. When combined with a 5800X CPU, I have become full on AMD. No regrets here.",
      "Fuck Jensen",
      "Upgrade that PSU my brother",
      "6800xt is closer to 6900xt than 6800 to 6800xt so that's not where to cheap out but I won't judge op.",
      "What Tests are you referring to ?",
      "Seconded",
      "Amen"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800xt"
    ],
    "title": "5900x / 6800XT OC tuf edition. With a little Boba Fett Theme that I finished this month !",
    "selftext": "",
    "comments": [
      "This is the way.",
      "Looks good! The case choice is a shame though, that airflow is gonna be tough",
      "Where the hell are you people getting your 6800s?",
      "tuf*",
      "5900x / 6800xt oc tuf / asus x570 tuf plus mobo  / 32gb TridentZ 3200mhz / Corsair RM 850x psu / 1Tb Crucial P1 NVMe / 1Tb WD NVme / Noctua DH15s / top fans are 140mm, rear and front are 120s. Case is ‚Äúwell, was black‚ÄùLian Li  205. Couple rgb strips in there as well.",
      "No offense but I don't think you understand how airflow works",
      "Boba festus sounds like a rotting milk tea drink",
      "TBF, The Mandalorian helmet they cut in tho the front will probably help...",
      "Legend mate what giveaway",
      "Thanks for being nuanced.\n\nThere's something about PC builders that makes them want to have a YES or NO about every part.\n\nIt's the worst or it's the best.\n\nThere is such a thing as \"good enough\", if he likes the looks, the CPU isn't at like 90C and the noise is fine, who cares?\n\nTbh, I'll take a creative \"imperfect\" setup over the same 3 cases post with 0 creativity between them.",
      "That a really good idea ! Didn‚Äôt even think to add those. üëç",
      "Where is the green?\n\nThis is more mandalorian\n\nVery nice",
      "This is the way",
      "https://imgur.com/a/6cDrwK6\n\nHeres a pic. Before that I treid the Lian Li PC-O11 Dynamic XL case, was not impressed with that case as it came damaged (returned it) and the build quality was meh. I was much more impressed by the Fractal Meshify 2 case, found the build quality was much better (IMO).\n\nEdit: Also, gotta say, NOCTUA has been absolutly the best company I have ever had the pleasure contacting. I contacted them about my CPU cooler, as it came with a defective screw and I also requested an AM4 mounting kit from them. They sent all the spare parts for free. Just provided supporting documents.",
      "Bad bot",
      "Just wanted to drop a note saying that someone downvoted every comment, so I upvoted every comment.\n\nCome on people. Be nice.",
      "Stock discords like stockdrops.",
      "I did it with a frosted glass spray and stencils. Lot of places that have spray paint will probably have it. Not hard to do, and you can add layers depending on how transparent you want it to be.",
      "I have this case. Airflow is great, actually.",
      "Looks like orange and black to me lol"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800"
    ],
    "title": "Fresh AMD RX 6800 XT reference cards 'expected to be available in the first quarter of 2021'",
    "selftext": "",
    "comments": [
      "\"Rumor\"\n\n\"Expected to be available\"\n\n\"RX 6800 XT priced at $649\"\n\n\"Hot single girls in your area\"\n\n&#x200B;\n\nPressing \\[X\\] for doubt right now",
      "Well there are hot single girls for sure in my area, just not interested in me, so that's the more believable out of those",
      "All the hot singles in my area are busy gaming on their new RX6800s :(",
      "Let me make a prediction. They'll make them available at the same day and time the 6700XT drops, instead of doing a staggered approach, making the website turn to shit yet again.\n\nThey did this when they released the 6900XT and put the 6800XT back on sale at the same time.",
      "...but will it be organic?",
      "I bet Frank Azor's cousin will click buy now and get one ;)",
      "Right now my Vega 64s are making 5 bucks a day, so good luck on supply. This will be the worst gpu shortage ever.",
      "Hot Single GPUs",
      "I am already thinking about buying its successor instead, since I don't believe the prices will get any better in the next 6 month.",
      "I doubt you will see the successor anytime soon. As they don't even have the production capacity to meet the demand for its existing product line.",
      "With 0 added growth hormones and artificial preservatives!",
      "And they're only costing $4.99 in electricity!",
      "> So next gen will be far easier to get.\n\nwell, ignoring that apple and others will also be doing their best to get that supply, some already are(apple is already on 5nm)",
      "I still cant get over the end of SLI support... as a kid i aspired to have a triple gpu watercooled build... those 980 builds were out of this world",
      "Yeah more cards for scalpers to sell woho",
      "I think the \"Hot single girls in your area\" is the most probable out of those.",
      "Frank Azor will buy a second one to spite us.",
      "1st Quarter: January 1st through March 31st. Well, were already in February and still none available.",
      "Yep it was a fucking headache. I spent almost 2 hours solid F5'ing and it was all pointless because not a single 6800XT actually sold from the main store page I don't think, pretty sure the whole stock got sold via a secondary store page someone found because they still had stock for a few hours after launch but soon as that link got shared around they were gone in no time. Thankfully some kind soul shared it in this subreddit lol. They should just let people enter in a raffle for them really. Yes some scalpers still get them but its as fair as you can reasonably do, better than letting your website die for half a day and let everyone waste their day.",
      "We went from \"I bought it easily on our store site!\" to \"Rumors indicate that at some point in the future there maybe the potential to possibly see a reference 6800xt in stock one second before it sells out.\""
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800xt"
    ],
    "title": "Update: A very kind member of the medical community helped me get the final piece(6800xt) of the build I am gifting to my brother.",
    "selftext": "",
    "comments": [
      "Hey its me your brother",
      "Wow what a coincidence I am also his brother!",
      "Bro you can change the Radeon logo to a different color: https://www.reddit.com/r/Amd/comments/kg9vni/you_can_finally_change_led_color_on_the_reference/ggdlfj3/?utm_source=share&utm_medium=ios_app&utm_name=iossmf&context=3",
      "What a beautiful build man, gz!",
      "i also choose this guys brother",
      "The build looks amazing. Are you looking for another brother by any chance?",
      "I had no idea thank you!",
      "Thanks! Waiting for my brother to come home and reveal it to him for the first time.",
      "My long lost brother! We finally meet. Just a heads up father should be back any second with the milk. Prolly a long line or traffic it's been a few years since he left.",
      "Not at the moment lol",
      "Woah.   I had to leave a comment on this when I normally don‚Äôt.\n\n\nStunning.   \n\n\nI don‚Äôt think any other word I can think of at the moment, sums up how I feel about this build. \n\nHats off m8",
      "Well executed!\n\nI just don't understand the popularity of this case. Having moved the front intake fans to the backside of the case, next to the mainboard, makes no sense. You want 3 fans there for aesthetics, but in order to have proper airflow they must be installed as intake. So you see the ugly backside of the fans. And in addition to that your airflow now is restricted, because the air must turn 90¬∞.\n\nPeople who chose to go fully visuals use the fans as exhaust and pull dust through every gap of the case.\n\nThis case makes no sense...",
      "Beware, it's AyyMD heresy to change from red.",
      "Wait so who‚Äôs the father?",
      "Are those bottom slot fans in exhaust config? Seems like you'd want them intaking directly into the GPU.",
      "Dad where's the milk?",
      "What keyboard is that?",
      "Looks like the Drop Alt Mechanical Keyboard.\n\n[https://drop.com/buy/drop-alt-mechanical-keyboard](https://drop.com/buy/drop-alt-mechanical-keyboard)",
      "Let me know how he reacts hahah",
      "Ok I‚Äôm gonna sound dumb, where‚Äôs the power supply?"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800"
    ],
    "title": "Early RX 9070 XT benchmark compared to 6800 XT and it's almost 4x faster",
    "selftext": "",
    "comments": [
      "This sounds like the similarly misleading junk that some rags were touting in their RTX 5070 \"preview\" articles yesterday.\n\nWhat the cited tweet actually says:\n\n>263% faster than 6800xt in wukong benchmark cinematic RT + frame gen fsr50%\n\n1. It's in a single RT benchmark with frame generation, the same marketing BS that Nvidia did to say the 5070 was bringing 4090 performance.\n\n2. It's comparing a leaked benchmark from one unknown source to the tweeter's own benchmark.\n\n3. Even past that trash, the article is rounding up an extra 10% in performance to call it \"almost 4x.\"\n\nSo, we've got two different data sources that aren't using identical setups being pumped up by frame gen, then getting a second pumping from the article author's rounding crap.",
      "stupid post",
      "‚Äúin wukong benchmark cinematic RT + frame gen fsr50%‚Äú",
      "crazy we get these posts when AMD already released performance numbers. The 9070XT is around 65-70% faster than the 6800XT ü§¶‚Äç‚ôÇÔ∏è\n\n4x faster.. that is about as dumb as nvidia claiming the 5070 is faster than the 4090 üòÇ",
      "Framegen just invalidates the result lol",
      "AMD doesn't have multiframegen tho, which was the biggest reason 5070 fps was exaggerated to be 4x the actual",
      "At this point, I don't care for rumors. Reviews are live tomorrow, and a lot of the reviews I've seen so far for the 5070 have said we should keep an eye out so I'm interested in RT. I know raster will be good.",
      "If framegen gets that high, base fps is what 120?",
      "9070xt uses basically same boosts than 6800xt, but they are comparing ray tracing performance, on which 6800xt is pretty much unusable so it's relatively easy to quadruple the fps",
      "No, it's an Apple-like comparison",
      "....\n\nPretty misleading title as they picked a game that's RT heavy and run it against 6800xt.",
      "What a load of BS!\n\nIf the 9070XT is 4x faster than the 6800XT that means it will be the fastest GPU in the world, surpassing the 5090 by a significant margin \n\nWhen you want to lie, at least make it doable",
      "The GN video today made the 5070 MF claim look way worse. Its not even close.",
      "Why? What's stopping 6800 XT from using exactly the same framegen?\n\n\nLol indeed. Someone clearly doesn't know anything about critical thinking.\n\n```\nRX 6800 XT under the same settings\n```",
      "I need to know what the rt numbers look like tho.",
      "Hell yeah, shame OP, shame!",
      "\"The[¬†leaked benchmarks](https://x.com/GawroskiT/status/1896838352844026103)¬†seem to come from the Chinese forum Chiphell but were posted on X by tech enthusiast Tomasz Gawro≈Ñski, who showed the RX 9070 XT reportedly being 263% faster, delivering 69 FPS compared to just 19 FPS on the RX 6800 XT under the same settings. **The test was conducted at 4K resolution with** ***cinematic ray tracing*****, frame generation, and FSR set to 50%, making it a demanding scenario that favors the**¬†[**improved ray tracing of RX 9000 series GPUs**](https://www.pcguide.com/news/significant-gen-over-gen-gains-in-rt-titles-amd-claim-2x-rt-performance-in-9000-series-gpu-lineup/)**.\"**\n\nIt's with RT on. It's just expected.\n\nhttps://i.redd.it/50b4biez1qme1.gif",
      "Exactly, and unlike Nvidia, AMD never claimed this",
      "based on steve's review from GN on the 5070, everyone should wait a day before making a decision and he kept referencing how the 7900XT was beating the 5070 in too many situations even some with RT but who knows what that was about.",
      "Yeah, my criticism isn't with AMD, it's the author of the article."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800"
    ],
    "title": "Broken AMD 6800/6900 GPUs after driver update? Video in the description (not mine)",
    "selftext": "",
    "comments": [
      "Just in case you haven't heard of KrisFix and are questioning his expertise or motives:\n\nHe has been repairing a lot of GPUs on a very high level for a number of years so he knows what he is talking about. Just look at the videos on his channel, they speak for themself\n\nExample: \n\nHere he is reballing a 3090 chip + ram because the card was drenched in liquid metal: https://www.youtube.com/watch?v=6nQCj5N9fV8 (skip to the last third of the video to see the soldering)\n\nHe is not some random small hobby Youtuber trying to create drama for views. \n\nIf he says \"I see a pattern here\" then people should certainly pay attention to what he is saying",
      "XFX 6900xt on 22.11.2 and nothing weird on going for me.\n\n(Knock on wood. Fingers crossed. Toes crossed.)\n\n&#x200B;\n\nedited",
      "This is crazy. My RX 6900xt recently died. About a day after I installed the newest driver.",
      "`if (warranty > 24) {`\n\n  `execute = \"overvolt.exe\"`  \n  `greeting = \"Check our brand new 7000 series GPUs\";`  \n`}`",
      "Count mine in. I had to replace my 6900 xt a month ago. I upgraded to the newest drivers at the time.i also used the auto undervolt feature in adrenaline software. then, I  played Black Mesa with every setting on ultra at 144hz 4k for an hour. I shut the PC down. The GPU never came back on the next day.\n\nEdit - my GPU is a reference 6900 xt model. GPU died after I updated to 22.11.2 recommended whql. Never mined with it. Just benchmarking/gaming/productivity",
      "People replying should include which aib card they are using \n\nCould help isolate the issue",
      "Unfortunately it's going to be very hard to verify this, as I don't think there are many repair shops doing GPU board repairs, that also have a social media presence. \n\nAIBs would know due to warranty claims, but it's not in their best interest to tell journalists about abnormally high defective GPUs.",
      "Same Here for me. Excact Same Symptom.\n\nPowercolor Red Devil Ultimate 6900XT",
      "JFC can we as consumers ever catch a freaking break???",
      "My Gaming X Trio is working fine too. This shit is making me nervous tho lol",
      "I suppose it's good that i'm still on ye olde circa may 2022 drivers because black screen crashes are the bane of my existence and I refuse to modify windows settings to compensate.",
      "Yeah Kris Fix is a professional. Love his channel.",
      "Out with the old. In with the new",
      "No issues with my card (reference)\n\nLast driver 22.11.2 WHQL",
      "*nervously walks behind you...\n\nThis is like a horror film, but first person.",
      "I like your funny words magic man",
      "Technically you only have 1 year of hassle free warranty in germany where you can return the product for rma. The second year becomes a little more complicated because now you as the customer have to prove to the seller that the damage/fault was already there at the time of buying the product.\n\nSo if a component was maybe already faulty but did not immediately result in a failure for example.\n\nNormally you would expect them to be accomadating and still just give you a replacement unit but they could also refuse it and demand that you prove them that this fault was already there at the time you bought the product at. Which would obviously be quite difficult as a consumer to do so.\n\nMaybe that's why they just send it to a repair shop.\n\nEdit: Of course this is just the minimum warranty requiered by law but individual companies can extend this if they so choose to.",
      "Mit dem Angriff Medions wird alles in ordnung kommen!",
      "My god. If this is true, this is absolutely disastrous for AMD.  \n\nThe GPU world has been an absolute dumpster fire as of late. Both AMD and Nvidia dropping the ball again and again.  \n\nThat said, a botched driver update that bricks a bunch of previous gen cards absolutely takes the cake.",
      "Some games specifically ask to update drivers. I was happily using the may release and WZ2 will not run unless I update the driver."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800"
    ],
    "title": "In Love! 980 to 6800 Xt.",
    "selftext": "",
    "comments": [
      "You should use two separate 8 pin cables from the PSU.",
      "Ty, i will look at it tomorrow :)",
      "It's a 300w card. You should use two separate PSU cables.",
      "Generally it's recommended to use separate cables to power the card, if it has more than one connectors. Especially if it's a 300W VGA.\n\nEven most PSU makers [agree](https://knowledge.seasonic.com/article/8-installation-remark-for-high-power-consumption-graphics-cards) with this, which is why the purpose of these daisy chained cables is questionable -  you need a 2nd cable anyway for the most optimal power delivery and stability, so they just make things more complicated and they look ugly... \n\nIf the card has 2x6 pin connectors it should be okay, but most modern cards (released in the past 5+ years) won't use that layout since 1x8 pin can offer the same with just one connector.",
      "I have seen people Complain about bad performance Or worse then they expected from their cards because of this.",
      "Someone had stuttering issues yesterday and got mad at me for recommending this for a 5700xt.\n\nIt even says to run separate PSU cables in the manual.",
      "Since it's above 250W max draw right?",
      "Liking how industrial this card looks, looks the business.",
      "I was considering using the be quiet cooler.how does it perform?i assume you have a ryzen cpu",
      "Is that the DRP4? Why does it look different\n\nedit: That's the Dark Rock Pro 3. I don't see anything wrong with it",
      "~~While you are at it, install your CPU cooler in the correct orientation/way.~~ The middle fan of the Dark Rock Pro 4 is the most effective in cooling and doing loads of work. It needs to be properly orientated however. The first and second fan should both be in the same direction, taking fresh air from the front of the PC and exhausting towards the back. Make sure to double check the orientation of your fans is correct and they are flipped the correct way. There are small arrows on the side of the fan which show the direction of flow of air.\n\nEdit: Thanks for the corrections. Was sleepy and didn't notice the differences with the Dark Rock Pro 4. I have the DRP4 and it would be installed incorrectly if it was the same cooler. Something was registering off with my brain because the fins seemed to be orientated the correct way, but I wasn't sure.",
      "Big boy!",
      "Word of asterisk.  EPS-12v 8 pin for the CPU carries a 300W stamp from PCI-SIG, and uses 4, 12V conductors.\n\nThe 8-pin, PCIe addin power connectors uses three conductors for 12V, is rated at 150W by PCI-SIG (margin). Termination pins, cable length and gauge, PSU capabilities and in-PSU distribution header config/layout for modular are such a grab-bag it's safest to always run two cables per spec -- and really not that inconvenient.\n\nOld AT power connectors are a favorite example of getting things wrong even at the highest levels where things won't fail safe. Add in vendors sometimes add a Y-adapter for their particular card, but these adapters often find themselves in the cable collection to be reused under the wrong conditions.\n\nI've seen people soften and deform small areas of plexiglass side windows where a single, 8-pin wiring was pressed against it while plugged in to a Y adapter with high power cards.\n\nRunning 300W in a cable can heat up the PSU end and/or GPU end as the resistive joule-heating will conduct through the copper if it's out of spec enough for the setup.",
      "Industrial can sort of mean it looks sleek/modern, but also looks tough and rugged.",
      "Very nice cool down a lot. As long as you have the space for it.",
      "Like it belongs in a factory / manufacturing",
      "This isn't technically true if the cables are above spec, and on good PSU's they will be. Basically, the cable itself can feed enough current, without voltage sag, to feed two connectors. You don't really need a large increase in cross-section of the core to double the amps the cable can feed. And in most PSU's there arent multiple rails, it's one large rail feeding all the 12v cables.",
      "very quiet and keeps my 3700x below 65 degrees at around 1000rpm",
      "While it may run, it may shut down because transient spikes can exceed the rating of the single cable bundle. So if it has two connectors use two cables. Three connectors can use two cables with one pigtail if needed.",
      "Been running my 1080ti even overclocked with just one cable and I‚Äôve had zero issues."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800"
    ],
    "title": "I gained almost 1000 points on Timespy rolling back my drivers. (rx 6800)",
    "selftext": "",
    "comments": [
      "I found this as well, but not with the score, only the stability of the card.  When I first purchased my 6800XT back in February, those drivers at the time (21.2.1?) were significantly more stable than the latest ones.  On the latest ones, I got screen flickering, black screens and random game crashes, whereas re-installing the older ones resulted in none of those.\n\nMoral of the story : never update to the latest drivers unless you absolutely have to i.e support for a particular game you want to play that requires them.",
      "I have had the exact same issues. Bought the card in February, performed amazingly well, I was really impressed. Updated to the 21.3.1 drivers from late March and have had nothing but problems described by yourself. \n\nShame, as the ray tracing support for dirt 5 and cyberpunk came with these drivers.",
      "You probably just had a bad install, here's a comparison with my 6800 on the same driver version:\n\n[https://www.3dmark.com/compare/spy/19543014/spy/19522581](https://www.3dmark.com/compare/spy/19543014/spy/19522581)\n\nEdit: Driver had a hickup, so here's another comparison after reboot:\n\n[https://www.3dmark.com/compare/spy/19522581/spy/19543355](https://www.3dmark.com/compare/spy/19522581/spy/19543355)",
      "\"bad install\" for as basic thing as a driver is something evil.",
      "21.3.1 and 21.3.2 are a mess, i dont know how they got throug QA at all",
      "yet it is a thing more common than anything else, this 'bad install' is not only related to drivers you've got firmware/bios flashing as well there your possibilities can brick the device or an unstable one, reflash the same bios and it works perfectly the second time around just like with drivers.\n\n21.3.1 works perfectly fine for me that being said Intel,NVidia or AMD or any other vendor for that matter bad driver installs is as old as it can get, it goes back as far as I can remember which would be Windows 3.1\n\nand I am curious how you define a driver as something 'basic' technically it is vastly more intricate compared to application level software like games or office.",
      "welcome to AMD drivers, where bugs are proclaimed as intended behavior (my 5700XT was locked at max memory speed, but there was a workaround for that \"intended\" behavior)",
      "21.3.1 sapphire 5700xt reporting in.\n\nthis driver was for us. hella stable for me. 2600+5700xt",
      "These scores are meaningless as they are combined scores. Show us the GPU scores please.\n\n&#x200B;\n\nI can not talk about stock performance, but I reached my personal best with the latest whql driver. (21.3.1)",
      "GPUs are fine, it's just that software isn't AMDs forte.\n\nIts not just drivers too, Intel has better AI and ML suite for a couple of years now, without even having a HPC card released. Don't even talk about infinitely delayed DLSS alternatives and other features.\n\nIts like one day they open sourced their drivers on linux and said to hell with a dev team, we only need 5 anyway.",
      "\"I'll keep it ok those drivers until I can't anymore\": You should not need to do this with a high end gpu",
      "Drivers is the number 1 reason i switched to Nvidia after experiencing the for a year 5700 XT since launch",
      "Ditto. 3700x and 5700xt, running much smoother with the update.",
      "It was very likely a bad driver install, as your GPU wasn't boosting properly. I downclocked my 6800 to the average frequency of your GPU and got approximately the same result:\n\n[https://www.3dmark.com/compare/spy/19522581/spy/19549521](https://www.3dmark.com/compare/spy/19522581/spy/19549521)",
      "Same here. No issues on my end (5900X, 5700 XT).",
      "Well Nvidia fucked up support for VR headsets for 4 months, so team green is not always better...",
      "Why such a degradation in performance with the latest drivers?\n\nThey're also extremely unstable. Radeon Adrenline 2020 refuses to open some times.\n\nI'm new to AMD gpus, is this the norm? having to dig around for good drivers for my card? (I'm now using the 21.2.3 drivers)",
      "6900XT on 21.3.2 here, not noticing any issues. I did DDU prior to installing the new drivers though.",
      "Vega 64 locks core voltage to 1.2V (max) for all frequencies after resume from sleep if voltage floor was modified in Wattman for 2 years now.\n\n\"Works as intended\" was answer, despite workaround with another sleep on default voltages fixing it existing.",
      "RadeonPro Drivers 21q1.1 is the best for RX Vega at moment, adrenalin 21.3.1 anda 21.3.2 is bad for RX Vega's and Polaris too."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800"
    ],
    "title": "[Guru3D] Availability of the Radeon RX 6800 (XT) & 6900 XT Is Still Extremely Poor",
    "selftext": "",
    "comments": [
      "6800 2930 ordered 117 delivered\n\n6800xt 2513 ordered 42 delivered\n\n6900xt 354 ordered 0 delivered\n\nfor the 159 delivered: \"we did not expect so much demand\"",
      "ordered=from manufacturer\n\nnot by customers",
      "Saw the 6900xt on ebuyer today had it in my basket almost purchased it but then did a double take on myself like \"do I ACTUALLY need this? nope\" so gonna wait till stock normalizes I was only going to pull the trigger because of low stock like \"if I don't get one when will I?\" just gonna wait 6 month and see whats on sale then. Not going to be triggered to buy somthing because of low stock which I almost was.",
      "Are these numbers accurate? That just blows my mind. I‚Äôm one of the 2513 ordered and now I just feel like I‚Äôm never gonna receive it",
      "Honestly I feel that if it wasn't for the high level of demand for high end GPUs people wouldn't be as willing to buy an RX 6900 XT or RTX 3090. In a \"normal\" GPU market it simply doesn't make any sense to buy these cards unless you are using them for work.",
      "I was told by Canada computers that my 6800 XT will just never come in, so I can either wait for an AIB that they have no expected delivery date, or go to the back of the line for a 3080. Definitely a month of waiting well spent /s",
      "they said 2 months for availability, we are on month 1 + 5days and counting\n\nI said that it was a lie but.. who knows, I hope I'm wrong",
      "The 6800xt red devil variant from powercolor retails for 1197 USD. What is worse, I don't think this will go down any time soon",
      "Yeah thats the problem im having right now, I don't really need a 6800xt / 6900xt but currently running a rx 580 8GB and the games I play run fine so I don't \"NEED\" one of these new cards but I would certainly notice the difference.\n\nPersonally I wish there was more of a mid tier GPU available, right now 5700xt is about the price I want to pay, but fuck buying something like a 5700xt or anything not \"this generation\" for the IPC uplift.\n\nHoping next year AMD puts out some replacement for the 5700xt or Nvida up the amount of VRAM in their cards because I was even looking at the 3060ti etc but its like I am not going from 8GB VRAM to 8GB ...",
      "AMD confirmed that more reference cards will be made for all models. But given that at most AMD is only getting at most 60 GPUs per wafer and Nvidia is getting at most 50 GPUs per wafer for both companies largest dies, don't expect supply to normalize any time soon. Keep in mind that that's only 140,000 TSMC 7nm wafers processed every month in total. And AMD has between 44,000 and 70,000 of those (we know that no customer is over 50% and some customers have dropped without disclosing who the allocation went to). Nvidia is using Samsung 8nm and we aren't sure how many wafers they're buying or even how many wafers per month Samsung is making on 8nm versus their 7nm process. But total supply to Nvidia is likely between 100-300% of what AMD is using at TSMC for GPUs based on what numbers look like in wholesale channels.\n\nMy guess is that Nvidia probably has around 10k-15K wafers/mo for all of its Ampere products including the A100 which is currently out of stock with earliest possible delivery via air being listed as 3 weeks. And AMD is likely only dedicating 2-3K wafers/mo to their high-end GPUs with the vast majority of their TSMC 7nm wafer allotment being slotted for console APUs, processors, and low- and mid-range GPUs that are launching next year. Furthermore, AMD also is starting to fulfill CDNA which is a 120 CU  computer focused GPGPU solution for data centers which features better FP16, FP32, and FP64 performance compared to Nvidia's A100 and has already been ordered in bulk, along with the not yet publicly released new Epyc processors for the first two exascale supercomputers.\n\nOh, and to top this all off, we've had shortages of the following so far this year:\n\n* Screws\n\n* Shipping containers from China\n\n* Shipping containers to China\n\n* Air freight capacity due to decreased intercontinental flights and now vaccine deployment\n\nAnd all of that is affecting the ability to move produced products from Asia to the rest of the world. Not to mention the fact that shipping is taking longer due to COVID-19 mitigations that slow down the loading and unloading of ships, planes, trains, and trucks.",
      "AMD told Hardware Unboxed that in up to 8 weeks MSRP cards from AIB partners would be available so we will have to wait until mid-January to see if that ends up being true or not.",
      "No. The mining craze was way worse. I know it first hand because I bought my RX 580 back then and I remember that I had to wait for months to get it.\n\n\nIt eventually got to a point where the only card that was readily available was the GT 1030 (even the RX 550s were selling out immediately). At least currently I can still buy an RX 5000-series card or an RTX 20-series card if I needed to.",
      ">AMD confirmed that more reference cards will be made for all models\n\nAMD's word means nothing at this point.\n\nThey have said-\n\n- There would be more stock than nVidia launch - **false**, *nVidia had more cards - both sold out quickly but nVidia had 2-3x the cards available on launch day.*\n\n- There would be 5-7x the stock for AIB cards - **false**, *there were even less cards for the AIB models than reference.* \n\n- There would be a general availability and a return to MSRP within 4-8 weeks (still in progress, but considering we're hitting christmas, new year then chinese new year - we can do this one early, there won't be stock before march) - false",
      "My canada computers hasn‚Äôt told me this, but they have no idea when I‚Äôll get my card either",
      "I saw my first social media post about someone actually getting a 6800XT yesterday. It was a reference design from XFX. Compared to nvidia, I see maybe 5-10 posts every day of people getting 3080's and 3070's. \n\nI know this is far from a quantitative analysis, but this is a factor I've been using to judge availability for years and it has always worked for me.",
      "The fact they decided to keep the reference going means they might think this won't happen now.",
      "Nah its not that one dimensional, they do proper market research and much more to find out the demand but they also are restricted by foundry capacity.",
      "Weren't 580s and 1060s going for $500? That was super rough. A $200 msrp card going for $500 and what's worse is that eventually retailers started charging that much. It's even funnier that despite all that and despite 4-5 years, the msrp of the rx 580 hasn't changed (still around $180?)",
      "I got a 6900xt this morning at microcenter. Had to be there at 5:30am outside though to be one of the first 10 in the store",
      "It‚Äôs so much worse than the 30 series. I‚Äôll grant them that they were released later but I‚Äôve seen basically no restocks of these cards."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800"
    ],
    "title": "Leaked Radeon RX 7800 16GB TimeSpy Score Shows 17% Improvement Over Last Generation's RX 6800",
    "selftext": "",
    "comments": [
      "The 6800 feels like the forgotten GPU in the 6000 series lineup. Everyone talks about the 6750XT, 6800XT and 6950XT but never the 6800.",
      "I think you forgot the long lost 6700 10GB",
      "So weaker than my 6800xt",
      "I have the 6700. It really is the forgotten child of amd. Runs great at 1440p and has 10gb too. It basically the 7600 but with a bit more power and more vram",
      "This whole gen has been incredibly mediocre for AMD. Between the bad efficiency (especially compared to RTX 40), underwhelming uplifts in raster and RT, and major driver issues with power draw and VR I don't know how anyone could go for an RDNA3 card until they're heavily discounted.",
      "It's rarely worth upgrading just one generation anyway, unless you consciously bought the bottom of the stack of one generation with the specific intent of buying the top of the next.\n\nRX6800 is a fine 16GB card and will last you a while yet.",
      "Yeap, that's the reason they'll market it as \"7800\" not \"7800 XT\"  \nPeople would riot otherwise",
      "$549 is way too much for this when there is a 4070 which is regularly cheaper with bundles. Given how atrocious upscaling and drivers have been this series, this should be considerably cheaper for it to be viable‚Ä¶ but hey, literally every new gpu from any manufacturer is shit value.",
      "Think I'll just hold onto my RX 6800 for a while longer. I really don't see a huge reason to upgrade this generation from either Nvidia or AMD at this point.",
      "Fellow 6700 user. Got it 260 brand new and it‚Äôs great! Can even do 4k on older titles with a little settings tweaking or fsr",
      "The 6700 is what the 7600 should've been. A 10 GB 1080p high performer that can dabble and dance in 1440p pretty decently\n\nEdit: accidentally typed 4k instead of 1440p initially",
      "That's because for a while the 6800 was going for 480$ with the XT at just 30$ more",
      "The worst part? It's hardly more efficient and just not worth the extra cost when compared to cheaper Navi21 options.",
      "You'd hope so. If it's anywhere near $600 then it would make 0 sense to get one over a 6950xt",
      "They did that with the 7600, and people still rioted.",
      "Cheapest 4080 I see right now is $1140. Cheapest XTX is $960 looking on Amazon and Newegg. So for $180 more I get a significantly more efficient card with better RT, DLSS3, and CUDA. Wouldn't be a hard decision for me to go for the 4080 if I was deciding between the two.\n\nAMD is delusional with their pricing this gen or maybe they just don't care and know they won't sell much at their current prices and are ok with it as long as the profit margins are high.\n\nNvidia is also delusional with their pricing this gen but at least they have a good line of cards and people justify paying more for the better features.",
      "The 6800 XT is a pretty big step up and isn‚Äôt that much more. It‚Äôs not as good of a value proposition as the others.",
      "Yes, while consuming ~30-40W less power.",
      "the really ugly one is going to be 7700, where you're using almost as much N6 wafer area as a 7600 and then adding 200mm2 of N5P.  The MCM area overhead is atrocious.\n\nSo basically take a 7600 and then add three Zen4 chiplets worth of area, to slide performance upwards from 4060 to 4060 Ti performance.  Which it should edge past pretty easily ofc (4060 ti + 5-10%?) but it's gonna be a godawful deal for AMD.  Like I guess if it's 10% faster than 4060 Ti 8GB they do $429?  What an absolute waste of silicon from their perspective.  \n\nThere literally is not a number where that product is worthwhile - even at $499 it would be a waste of silicon for AMD compared to Zen chiplets.  And 7800 really needed to be sold for at least $600.  But the product performance just can't justify that.  This is Vega 2.0 where AMD is getting pinched by how poorly their silicon is performing relative to the established performance levels of the competition, and even AMD can't pretend it's an awesome deal at MSRP, but neither can they afford to go any lower on pricing.\n\nThat was when we saw the bundle deals (\"buy a GPU for $100 more than MSRP and get a coupon for $100 off a specific monitor nobody wants absolutely free, coupon expires in 30 days!\") and other crap kick in to shift ASPs upwards.  And even still, standalone MSRP was so low that partners couldn't actually make a profit on the cards they were ordering from AMD (\"made by AMD\" reference cards).  Everyone got real mad about that with NVIDIA a year ago, I think everyone forgot that was an AMD thing with Vega too lmao.\n\nI think the numbers have to be $499 for 7800 and $399 for 7700, *maybe* they will try for $529/$429 to squeeze a couple more bucks but at $450/$550 they are DOA.  DLSS alone is worth 10% to me.",
      "AMD didn't charge $400 for a 8GB card, which is what they taunted Nvidia for."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800"
    ],
    "title": "AMD Radeon RX 7800 XT GPU Review & Benchmarks vs. RX 6800 XT, RTX 4070, & More",
    "selftext": "",
    "comments": [
      "Happy with my recent 6950xt purchase",
      "My decision to buy the 6800XT last year is looking better and better.  This is no doubt the best price/performance AMD has released this generation, but the lack of generational uplift is disappointing.",
      "Guess I‚Äôll be sticking to my RX 5700 XT or finding a 6000 series replacement.",
      "People calling it Trash are mostly correct. Its not a great card for its price. \n\nWhen compared to its Nivida equivalent? Its ALOT better. Can't wait to see nvidia sell 4 for every 1 AMD sells",
      "So mostly the same performance to last gen but costs slightly less and consumes less power",
      "It seems like it should have been the 7700xt, with the 7900xt being a 7800xt, and 7900xtx being a 7900xt.",
      "Just bought a 6950XT as well, working wonders in Starfield",
      "I'm guessing most people expected a better generational uplift over the 6800XT.",
      "I know the price is okay in the USA, but here in Australia, it's not that great. \n\nA 7800 XT the cheapest I can find as of writing is $879 AUD, that's converted to USD with tax included ~$561 USD which is about right once you add 10% GST/VAT and maybe some extra fees for being shipped to a penal colony. \n\nThe cheapest 4070 is like $889 AUD. So yeah the 4GB of VRAM extra is nice, but the RT performance, DLSS and other features like NVIDIA Broadcast and just general driver stability or rendering performance keep the RTX 4070 lingering around as an option. The $100 pricing gap between the 7800 XT and the 4070 in the USA is basically not really a thing here.\n\nThe 7800 XT desperately needs a price drop here in Australia to be a relevant purchase. A good $80 AUD price drop puts the 7800 XT into a spot of consideration. But then I remember that a used 6800 XT goes for around $650 AUD, so unless you really use RT or want AV1 can't see a reason to buy a 7800 XT.\n\nAnother AMD graphics card release, another dead on arrival product here in Australia.",
      "and improved RT performance, and AI Accelerators, and AV1 encoding.",
      "Spoiler: he wasn't that happy.",
      "Forgot about the 4060 Ti already? It didn't even have cheaper MSRP",
      "I had been looking at buying a 6800xt but now with the 7800xt out, I might just do that. Sure, they're comparable in performance, but the 7800xt seems to win in the power consumption category. Maybe I'm in the minority here but that actually matters to me.",
      "Hubs video too. No significant change in performance. Thanks amd for blessing us with this massive W today. Same performance as last gens card something I have not seen on either nvidia or amds side in so long but hey. It's just $15 more expensive than last gens card so that's good ? Maybe...? I'm so fucking upset how did we get to this? Maybe by the time we get a 9800xt it might be a slight improvement who knows",
      "Nvidia is our best friend. We dont talk about issues, because they dont have any and never make mistakes.\nAlways the best choice for gamers!",
      "I just bought one after looking at the reviews. Also an important point is that 6800xt performance uplift via drivers is likely not going to happen anymore but 7800xt is likely going to get quite a few driver updates that improve performance. \n\nPlus I have seen reviews from 3 different sources running sometimes the same games and where Steve was getting better performance on the 6800xt the other two were getting equal or better performance on 7800xt. \n\nImportant thing to note, Steve was running the stock version of 7800xt vs sapphire nitro+ version of 6800xt. Jayztwocents was running the same version of two cards(red devil powercolor) and 7800xt was showing better results vs 6800xt. \n\nAnd I was hoping for exactly this, similar performance for less power draw and same price or cheaper. And it is in UK same price or cheaper.",
      "AMD has no shame anymore.",
      "In theory, yes. But honestly modern cards tend to really struggle with OC's compared to older cards. The way they boost is just pretty aggressive out of the box. I think very few people get meaningful OC's on any 5000/6000/7000 series cards.",
      ">it's $499 and runs as fast as a 4070\n\nSure, that's one way to look at it.  The other way is that it runs like a 6800XT for the price of a 6800XT.  Not saying that's bad (at least compared to the competition), just not very exciting.  People want generational uplift and this has essentially none.  If you have a mid-range or better card from last generation, there is nothing for you here.",
      "Stick with the 6950xt"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800xt",
      "6800"
    ],
    "title": "Bullsh1t_Buster on Twitter: Navi21 (6800XT/6800) mining performance is not very good.",
    "selftext": "",
    "comments": [
      "Whatever brings doubt to miners, I'm all for it.",
      "First guy says it‚Äôs great at mining, second guy says it sucks at mining? \n\nWhy should we believe either one? Who the heck are these people? Can somebody explain?",
      "Yes pls.\n\nReally hope 6800XT stock isn't as garbage as the 3080.\n\nReally want to build a PC in Jan/Feb next year and really hope there are GPUs available.",
      "I do t know who to believe. But i know who i want to believe.",
      "Fair warning: it will be. For the last several GPU releases, regardless of Nvidia/AMD, the high/mid-tier GPUs consistently sold out during their initial launch runs. It's kind of expected and you should plan around it.\n\nDoes it suck? Definitely. It's just part of that early adopter tax you pay for the newest hardware.",
      "In theory it should be worse as RDNA is gaming tech vs the compute strength of CDNA. AFAIK, mining relies on compute performance more than graphics/rasterization performance.",
      "God I fucking hope this is true.",
      "yea it absolutely sucks balls, don't buy it. Hell, go out of your way to avoid them. Don't even load up the websites. They're terrible. So bad. \n\n\n\n    Maybe I'll actually be able to get one now",
      "Yes.",
      "Ah 2020, where a card being shit at mining is a cause for hope.",
      "I don't know who bullsh1t\\_buster is, but I trust [kopite7kimi](https://twitter.com/kopite7kimi/status/1325831282434035712). If this is credible to him, that's good enough for me.",
      "eth mining is bandwidth dependent RDNA should be perfectly fine at this but eth is going pos so it's still fine",
      "fragile handle mindless worthless north squalid sip fear rinse onerous\n\n *This post was mass deleted and anonymized with [Redact](https://redact.dev)*",
      "To be clear, I hope it's garbage at mining because I want to actually be able to *buy* said Ferrari, haha",
      "Is the PCMR thing really taking off nowadays or is the production just low?",
      "The whole fucking thing just wastes resources for no good reason.",
      "Meh, with that memory bus it probably isn't much faster than a 5700xt mining ethereum.",
      "I hope so. Fuck the scalpers, bots, and miners.",
      "Hope this is true. I hate everything mining. The whole thing is just distributed criminal money laundering and I want mining to have not a single fucking cent of influence on pricing and not a single board of impact on availability",
      "It won't the whole point of ETH is to circumvent caching."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800xt"
    ],
    "title": "6800xt midnight black",
    "selftext": "",
    "comments": [
      "On 1440p gaming with a manual fan curve I'm barely tickling 60-65c under full load",
      "Someone correct me if I‚Äôm wrong but dooesnt the cooling of amd reference 6000 series suffer when on its side?",
      "Hurts. Been trying to beat the system since the black edition popped up first....",
      "It suffers in lengthwise vertical orientations (I/O on top). This orientation is fine. If we can trust some of the posts comparing temps and orientation, it might actually be the best orientation option. Either way, as long as the long edge is parallel to the ground there isn't a severe performance impact.",
      "Other than AMD.com occasional restock, is there anywhere else I can get this sexy beast on MSRP? Thank you.",
      "I was lucky and landed it first round of release",
      "its front mounted hoses on bottom which is how they recommended to mount it if you cant top mount",
      "Low and slow, ow to make a great chilli",
      "I just did my first ever AMD build with a 5600x + 6800 XT. I‚Äôve always had Intel+Nvidia. This thing rips! The midnight black is slick. Red Devil for me.",
      "Msrp? No",
      "So long reddit, thanks for all the fish.",
      "I got mine in the normal way. If I could put it vertically like this I would tho. I baught the SAPPHIRE NITRO RX6800XT special edition which has RGB fans. Didn‚Äôt realize I wouldn‚Äôt even see them though unless it was vertical. Still looks like a beautiful card tho because the sapphire cards are already just very visually appealing with the mirror rgb sapphire logo and silver top. But I still run at good temps. About 75c under full load running demanding games. So I don‚Äôt think it makes much of a difference as long as you have good cooling within you‚Äôre pc. I got a micro atx case. Corsair crystal 280x. My card is one of the bigger 6800xt cards so it literally just fit the case with about a half inch between the card and front fans. I got a AIO rad and 4 other fans. 2 fans on the bottom(intake), 2 on the front(intake) and the aio rad on top (exhaust). Runs pretty cool for a smaller case with some beastly hardware. Rx6800xt and 5950x",
      "Teach me your secrets. I have been trying for a 6800xt for 7 weeks now.",
      "What case is this?",
      "Front mount bottom hoses and tank well above pump height",
      "I had and early invite and had it in my cart but couldn't submit because it wanted Canadian province info entered for my address as well as a state. I was on the US site and had a US address selected too.",
      "Has NZXT's software improved?  I've avoided them for years because their software left much to be desired.",
      "Convert my reference 6900 to water..Temps never crest 50c. At 2700mhz. If I set Modern Warfare to 1080p render resolution I can push 400 fps. Who knew you could get CSGO fps in a modern game.\n\nPic for reference.\nhttp://imgur.com/gallery/NbXCFb5",
      "Oh my bad I thought the rad was on the bottom of the case.  You're right.",
      "me too i just got an AMD build, always been intel nvidia but by god this thing is a true thread ripper."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800"
    ],
    "title": "Introducing, Sleipnir, my first ever team red build! 5800X and 6800 Nitro+",
    "selftext": "",
    "comments": [
      "That GPU sag is scary; have you considered getting something to prop it up?",
      "Yeah, I have to move it to it's permanent home, I'm thinking of rigging a sag bracket to the SSD tray",
      "Lian li anti sag bracket order it from microcenter.",
      "GET A GPU BRACE ASAP!",
      "I nabbed mine from Newegg Business, it was available, I wanted it, and I bought it. Couldn't have done it without Falcodrin's AMD stream though.",
      "Looks like bequiet pure base 500.",
      "Yep! BeQuiet! Pure Base 500DX",
      "What case is this?",
      "YES! FALCODRIN! He's an absolute legend. I ended up finding FairGame, a bot used to fight back against scalpers on that stream and I was able to snag a 5600X",
      "My  RTX 3070 came with a support bracket, but I don't need it.\n\nthankfully not a problem for my a Silverstone FT02 case, with the vertical case orientation. Heat vents upwards.\nThe weight is supported by the PCI slot screw\n\nMore cases need to do this!",
      "So you have to buy a new one from them",
      "It sags a bit but the angle of the shot also makes it look worse than it is, probably.",
      "Cheap solution: suspend it with wire from top of the case. Fishing wire is transparent.",
      "How are your temps with your CPU and that cooler?",
      "GPU sag is unlikely to cause any functional issues. PCBs are designed to flex",
      "I just looked it up, ugh I hate how python always breaks its own backwards compatibility... (Needs 3.8, 3.9 breaks the program.) I honestly wonder why python continues to be popular when shit like this keeps happening, release after release, year after year.",
      "Because for those of us that write Python it‚Äôs a non issue to have multiple versions installed. You just use a virtual environment and create it with the needed Python binary, easy peasy.",
      "Unless you are completely blocking all airflow it won't affect temperatures. Cable management is purely for visual and maintenance purposes.",
      "I don't understand why GPU manufacturers can't include something that prevents the damn thing from destroying itself.",
      "Cinebench pushed it to 82C in MC, 63C in SC with just PBO and no other tuning. Clocked between 4.4 to 4.6ghz"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800"
    ],
    "title": "AMD Radeon RX 6800 XT Performance Has Increased by Up to 9% Since Launch: Faster than the RTX 3080 at 1080p and 1440p",
    "selftext": "",
    "comments": [
      "Well this is good news just still waiting for a real price to pick one up.",
      "I'm not sure this data is comparing performance in the same games, or it's simply a case that more or different games are now being used for testing. It's probably worth noting that we tested with 18 games back in 2020, and our margins haven't changed: [https://twitter.com/HardwareUnboxed/status/1408975767535460355](https://twitter.com/HardwareUnboxed/status/1408975767535460355)  \n\n\nI noted that a lot of these review outlets were testing with less than a dozen games, so if they've since updated the games list this will change the margins a lot.",
      "First review of TPU :\n\n[https://www.techpowerup.com/review/amd-radeon-rx-6800-xt/35.html](https://www.techpowerup.com/review/amd-radeon-rx-6800-xt/35.html)\n\n6800XT is slower than 3080 by 6%\n\nLatest benchmark of  TPU (Geforce RTX 3070 Ti ) :\n\n[https://www.techpowerup.com/review/gigabyte-geforce-rtx-3070-ti-gaming-oc/28.html](https://www.techpowerup.com/review/gigabyte-geforce-rtx-3070-ti-gaming-oc/28.html)\n\n6800XT is faster than than 3080 by 1.81%\n\nsummary : since First review to now , 6800XT is improved by 7.81% more.\n\n&#x200B;\n\nedit: wrong math , It's 8.3%",
      "Until then the next ones are out probably",
      "That's 100% fine. My 5700xt is fine until I can get a 6800xt for msrp.",
      "It was faster below 4K at launch.  The only reviews which showed otherwise had far too few games to get a proper average, and/or skewed heavily towards nVidia-tuned titles.",
      "You love to see it. Apparently the latest patch was a big one, with a few percentage point gains from reading some comments.",
      "You may want to think about trading for a 6700xt. Apparently you can just trade 1:1 since it current value leans towards mining profit and not gaming performance. After prices (hopefully) drop the 6700xt resale should be a little higher than the 5700xt as it leans towards gaming again.",
      "Not quite. It started at 94% of the 3080 and ended at 101.81%, which is an 8.3% increase. Think of the 7.81% you got as a proportion of the original 94% :)",
      "Great, so when can I buy one for MSRP?",
      "Yeah that's my point, the games list is different. Anno 1800 has been dropped for example and Assassin's Creed Odyssey has been replaced by Valhalla which is a big win for AMD and they've added Cyberpunk 2077. They've dropped Project Cars 3 which was a really bad title for AMD.\n\nThen other changes include the addition of Watch Dogs Legion, the upgrade to Hitman 3 from 2, and the removal of Star Wars Jedi in favour of Squadrons. So a good number of changes there that completely invalidates the comparison.",
      "How much are we talking here?",
      "Faulty reporting.  It hasnt \"increased\".   They tested different games, a bunch of them AMD partenered ones - Dirt 5, Valhalla, Resident Evil Village which place the AMD cards ahead. And many outlets dont retest older cards that might benefit from driver and patch uplifts.  So the newer released cards get benchmarked with newer drivers and patched games while results for 3080 and 3090 are showed from last year.",
      "Maybe its worth doing another fine wine investigation",
      "True, but it also depends on what titles you're comparing. As well as what graphics settings you're using.\n\nMSAA in use? AMD's probably winning due to the incredible pixel fillrate of 128 ROPs combined with 128MB of cache.\n\nSuper-heavy volumetric effects? Nvidia's probably going to win due to the big FLOPS advantage.\n\nAs for FineWine, it's probably going to be less of a thing with RDNA and RDNA2. The strength of RDNA2 is that the chips seems to be very well balanced and utilized, which wasn't the case at all for GCN. Even at GCN's launch, AMD needed more execution units to match Nvidia. Going back 9 years, AMD's gone from 2048 ALUs with the 7970, to 5120 ALUs with the 6900 XT.\n\nAmpere on the other hand, is a lot less balanced than previous Nvidia generations. It even exhibits similarities with GCN where higher gaming resolutions perform noticeably better when compared against previous generations. Going back 9 years, Nvidia's gone from 1536 ALUs with the 680, to 10496 with the 3090.",
      "20-25% so it is like jumping up 1.5 tiers to something between a 2080 super and 2080 ti and your card sits a little below a 2070 super. If you look at ebay sold listings prices, you can potentially get another $100 cash during the trade too.\n\n\nYour current card is a solid 1440p card at high settings so even if you sit on it and not trade up, you at least won't be struggling for playable framerates and settings (unlike my gtx 980 that is struggling at 1080p medium settings on a 1440p144hz monitor).\n\n\nI feel you about the prices. A $1200 rtx 2080 ti equivalent should be $500 right now. Gaming is a hobby and paying 2-4x more than a console for a single part is one thing but paying up to 3x the MSRP of a card is insane even if I can drop $3k on a 3090 without any financial strain.",
      "Biggest con is, they are even harder to get than the RTX3080,  I've only ever seen 6700XT or 6900XT for sale irl mostly 6900XT",
      "Nvidia is years ahead in adoption, ML, hardware encoding, and software (CUDA).\n\n While RDNA 3 might be great for gamers, AMD has a long way to go with rocm and broader use case support before Nvidia will truly be threatened. \n\nRDNA3 will rock I am sure, but let's not get lazy!",
      "Thank you, I do love cake.",
      "I'm curious how raytracing performance is, that's a big thing for me"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800xt"
    ],
    "title": "My 6800XT purchase from November was cancelled yesterday",
    "selftext": "I bought a reference 6800XT at MSRP from a UK store, and at the time was told I was in a preorder queue dispite the store saying there were no preorders. I was then told a couple days ago that Sapphire has discontinued making reference cards so I will never get my preorder fulfilled. To the store's credit they did offer me a discount on one specific card but I'm building in a Meshify C so most AIB cards are too long so I refused and was refunded.\nNow I'm just like everyone else 5 months into this mess waiting for a 6800XT to exist at remotely reasonable prices.\nGood luck to you all.",
    "comments": [
      "Would have been easier to get a different case and go with the card they offered IMO.",
      "Should have just taken the discount on the other card, and traded it for a reference model or something in your local area for the price difference.",
      "I have an sffpc and you can be damn sure that if I got the chance to get a full lenght 3000 series at msrp I would've changed cases to one that allows a longer gpu.\n\nGot a good enough deal on a 2 fan 3060ti so I didn't have to do that",
      "Man, you wouldn‚Äôt be profiting if you just bought it and traded for something else at MSRP. At this point, just getting any card in your hands should be the goal. Then go over to r/hardwareswap and get yourself the card you want...",
      "I have absolutely no clue why he thought it was a good idea to refuse the different model knowing just how shitty the market it is right now over a case; It's going to cost him MUCH more to get any other card than it would have to just get the card now plus a Meshify 2 to replace his Meshify C.\n\nI can't even blame the retailer in this case, since they gave OP a very reasonable option and he decided to be obtuse for the sake of being obtuse.",
      "The worst part is that the sapphire models aren‚Äôt too long for the Meshify C as long as you put the hypothetical AIO at the top instead of the front, so he gave up the card for no real reason...",
      "some people just dont think no point in doing it for them.",
      "That's not a vote of confidence from your retailer.\nDid they just have a 90 day cron that cleans out old orders to keep the books tidy fiscal period to fiscal period?",
      "That feeling when you reject a rx 6000 card because it doesn't fit in your case:",
      "massive facepalm on OP's part",
      "I'm sure like most people they get locked into an idea or upset about the current issue they close off their mind to any other possible changes they could make to improve the situation because it wasnt their fought and blame was on the store.\n\nNowadays consumers gotta learn to take responsibility because stores are handcuffed by things mostly out of their control.",
      "Well, perhaps the OP didn‚Äôt want the hassle for trading the card ? Idk, also most the of the deals are made in the US, op is from the UK, if something goes sideways it‚Äôll be a mess",
      "Pretty sure most online retailers have a policy that any purchase that isn't shipped within 90 days is voided. Hell, even scale model figurine websites have this policy.",
      "came to the comment section to see OP getting roasted and i gotta say, i‚Äôm not disappointed",
      "According to Fractal's own site, the Meshify C can hold a 315mm long card with a full size front fan installed. If you were to install a slim front fan, you could get that up to 325mm long. Did you check the length of the AIB? There are only a few 6800 XTs that would qualify as too long for that case.",
      "Sorry to say but if they offered you a card at a discount, should've changed cases",
      "If they're out of stock then the prices are imaginary anyway.",
      "It's like rejecting a pallet of money because it doesn't fit in your wallet. OP is obtuse.",
      "The Mesh C is massive...I don't even understand...I fit an AIB 3080 into a 12L case with 240 AIO\n\nThis is some pepega stuff here my dude.",
      "Id say its a significantly larger hassle to not have the gpu, and have to wait for the prices to go down and get one then, rather than making a post on a reddit."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800"
    ],
    "title": "Powercolor Red Devil RX 6800 Series",
    "selftext": "",
    "comments": [
      "ENOUGH WITH THE TEASERS",
      "They think it's much more of a big deal than it really is. 90% of us just want any 6800xt chip and will stick it in a case which itself hides the look.",
      "40 and I want my shit to glow like a unicorn on molly.",
      "wow it got fans! next  level",
      "Just show it, ffs.",
      "Yeah it *can* definitely be an age thing. I'm 33 so I have my case literally behind my desk where you cannot see nor hear it. However, I've been building rigs since I was 13 and I've never wanted RGB. For many years my computer was my only way of watching movies in my bedroom and who wants laser lights lighting up the room during a movie or when trying to sleep?\n\nJust need the shit to work and not fail, and not be super loud.",
      "49 here.  These kids don't know the beige world we came from.",
      "So sapphire and XFX have been teased, now Powercolor. I take it Gigabyte is tomorrow, Asrock on Sunday, MSI on Monday and ASUS on Tuesday?",
      "It is composed of..... Only Fans ;)",
      "32 here, I try to buy parts that don't RGB",
      "Can we just get a product page with a release date? This is annoying and pointless.",
      "Cringe!",
      "51 and I have a case with RGB on full display in my living room. White and red at the moment, but I can switch it to whatever color and whatever effect I want. All of this anti-RGB sentiment is getting ridiculous. There is nothing wrong with it. Blast unicorn vomit to your heart's content or switch it all off. It's up to your own personal preference.",
      "Well, at least Sapphire has the cards up on a product page with specs, so they are past the tease phase. Gigabyte, ASRock, MSI and Asus have already done their teasing.\n\nXFX and Powercolor are the last ones out of those where they've only shown snippets of the cards. The other ones at least they've shown the whole thing.",
      "Petition to ban these fucking things from the sub. They have absolutely no purpose! I feel like I'm taking crazy pills.",
      "No they do not. Beige cases with beige mice and keyboards and beige CRT monitors.",
      "All I want is an AIB card that will fit in my NCASE (as long as it's not an iffy brand). So far my last hope seems to be Powercolor, if not that I guess I try to get a reference card.",
      "AMDRewards codes are getting wild.",
      "If this bothers you to this extent, then yes, you are taking crazy pills lol.",
      "A bland looking GPU would be a nice change of pace for me over the ultra gamer aesthetic many seem to be going for."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800"
    ],
    "title": "AMD Radeon RX 6800 XT up to 12% Faster than the NVIDIA RTX 3080 in Unreal Engine 5 Demo w/ Lumen Based S/W Ray Tracing",
    "selftext": "",
    "comments": [
      "Why not just post the Digital Foundry video. You can gain a ton more info out of there than from this article that is poorly written and not even accurate in some stuff.\n\nFSR is not even used in the demo.",
      "Because OP is the writer. I have pointed out some of his mistakes in the past as well.",
      "\"...at the 1080p Epic setting with FSR upscaling to 4K.\"\n\nWhile that's nice I suppose, I was really looking to see that claim be at native resolution. I mean, hasn't the 6800 xt already been shown to outperform the 3080 at 1080p? Plus I would certainly hope the 6800 xt makes use of fsr better than Nvidia would considering its an AMD developed upscaling solution. All in all a bit disappointed in the article.\n\nEdit- The article is misleading. As pointed out, FSR wasn't used.",
      "If it has to run fast on consoles, it's going to be well optimised for AMD hardware.",
      "Taken straight from the article: https://www.hardwaretimes.com/wp-content/uploads/2021/06/image-20-1024x540.png\n\nIt's TSR, Epic's engine upscaling, not FSR.",
      "People have been saying this for a decade already and yet we still get games that run faster on Nvidia hardware.",
      "Nvidia puts in a lot of work to help devs optimise for Nvidia hardware, to be fair. So that‚Äôs not surprising to me",
      "https://youtu.be/C99VwDGyLg0",
      "Dear lord, what a clickbait headline this is.\n\nAlso, 75 fps at native 1080p is pretty depressing stuff. Between that and the \"this only works on stationary objects\" thing, let's not all jump on the software raytracing just yet.",
      "Not sure why you are downvotes, this was literally done and shown with hidden tesselation for example.",
      "And slower on amd",
      "And u didn't post the link either? üòÇ",
      "The article is just blog spam, Digital Foundry video is source.  They never mention FSR because its not using it.  Its TSR.. but its just like improved TAAU... which is fine.. like DLSS is an improved TAAU.  But nothing to do with FSR.",
      "Do you have a link?",
      "And not using dedicated RT hardware...\n\nThis is like a one legged man challenging a two legged man to a race and then tying the other guy's legs together.\n\nIn the real world AMD isn't even close at RT performance.",
      "Why is he being downvoted? Someone else confirmed that it was TSR below",
      "You're missing the point because you didn't read the article. The article suggests this demo uses FSR which is false.",
      "I mean, they literally tested it in the demo and yeah, the 10900k was getting a higher fps.",
      "GHz =/= single-core performance. I guess the word 'speed' is throwing people off here?",
      "It IS Unreal Engine 5's Temporal Super Resolution. The video this article took the information from deliberately points it out multiple times.\n\nBut this is Hardware Times we are talking about. Quality journalism isn't something you should expect from them."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800"
    ],
    "title": "Zen 4 build. R9 7900X + RX 6800 XT",
    "selftext": "",
    "comments": [
      "Fans cost more than most people‚Äôs builds",
      "Dude bought a 7900x+x670, good value isnt a concern to him",
      "seems like >$550 in fan cost if you include tax lol",
      "And they aren't even that good!",
      "Are the fans next to the mobo tray reverse flow (airflow away from motor mount side)?",
      "I'm surprised your case doesn't hover off the ground with all of those fans lol. Nice build!",
      "Very nice! Looks like we both jumped on the 7900x bandwagon. I decided to air cool mine which I haven't done since 2008 so that's been fun.",
      "Yep... Marketing sells lmao",
      "People who don't care about rgb save so much money. You can usually pick up the 5 pack of Arctics 120mm fans for like 40 or $50 Canadian and they're such a good value. Good air flow and very quiet.",
      "The fans next to the motherboard are in a push pull configuration to cool the GPU AIO rad so they take air from the front fans that are intake and exhaust it to the side of the case. Bottom and front fans are intake. Rest of the fans are exhaust. There are 15 Lian li SL Infinity fans total in this case connected to 2 SL controllers. And 3 noctua fans on the top CPU AIO rad that is also in a push pull config. 18 fans total in the case.",
      "Hello there. The PSU is a ROG Thor Platinum 1200W.",
      "Lol powered by the gods themselves build looks great man someday i hope to get one that nice",
      "What power supply you have in this beast?",
      "I don't think its necessarily bad, I'm looking to get the same (but waiting first to see if B650 will bring any atx 2-dimm boards first - there were tachyon rumors but we shall see).\n\nOtherwise 7900x fits my needs exactly and the board well, that's the only chipset currently available.\n\nBut out of curiosity what did you mean by good value? What it seemed to me when I was laying all this out - the 5000 ryzen chip upgrade would've been maybe $300-400 less (ram cost is negligible since it seemed like good binned ddr4 for ryzen costs similarly to hynix m-die <ddr5>, this may not be optimal value per cost but I enjoy the OC), however the cpu performance uplift seemed worth it for tasks - this of course varies per person but just goes to show that it is maybe harder to judge \"good value\".\n\nedit: but also yes excessive shiny fans are expensive but it does look nice :)))",
      "Looks like you ready for 2025 CPU & GPU Cards",
      "I am sure you will. Post it here then so we can also appreciate it. üëç",
      "Might be a couple months away on that but im hoping these prices drop some more",
      "so i  dont understand the logic of the side exhaust, wont that pull alot of the fresh air from the front directly back out?",
      "Lian li dynamic XL I believe.",
      "How does the air cooler perform? I also ordered a 7900x and would like to use a air cooler. I was thinking either the nh d15  or dark rock pro 4 on a fractal design torrent with stock coolers since I can't really find other 180mm fans"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800xt"
    ],
    "title": "3070 order delayed/ cancelled, 6800XT here I come!",
    "selftext": "So I guess Best Buy couldn't even get the 3070 stock in that they were promised. My order that actually went through was just marked as delayed and if they don't fill it by the 20th they will be cancelling it. I was already feeling like AMD might make me regret my decision as I want to play some games on my 4k/120 TV. I hope AMD can have the stock to make fools out of Nvidia, because I want a 6800XT!",
    "comments": [
      "If AMD can beat Nvidia on supply, just think of how much market share Nvidia will lose simply due to not being able to meet demand. I'm in the same boat, to be honest. Will go either way depending on what I can get fastest.\n\nAlthough the shared memory feature of Ryzen & Radeon paired together makes me lean more towards AMD now...",
      "Samsung 10/8nm is low yielding. through and through a paper launch to get some attention off of amd. yield problems for this node has been known since 2017... (8nm is a 2018 refresh of the 10nm node, also low yielding).\n\ntsmc 7nm+ actually has yields to back up demand. and is newer with higher quality.\n\nedit edit: amd group stepped up, I was -1 karma for pointing this out.\n\nit's not hard to find info on the Samsung 10nm yield problems... one commenter said \"back up your claims\", how hard is performing a Google search yourself?\n\nhttps://www.electronicsweekly.com/news/business/samsung-tsmc-hit-poor-10nm-yields-2016-12/\n\nhttps://www.xda-developers.com/report-unsatisfactory-yield-rates-for-10nm-finfet-process-pushing-back-smartphone-schedules/\n\nhttps://www.slashgear.com/low-10nm-processor-yields-could-delay-high-end-smartphone-06477200/\n\nhttps://www.extremetech.com/gaming/315898-nvidia-rtx-3080-and-3090-shortages-likely-to-persist-into-2021\n\nhttps://www.guru3d.com/news-story/nvidia-allegedly-moving-ampere-to-7-nm-tsmc-in-2021.html\n\nhttps://fuse.wikichip.org/news/1443/vlsi-2018-samsungs-8nm-8lpp-a-10nm-extension/2/\n\nhttps://www.techradar.com/news/you-might-have-trouble-getting-an-nvidia-rtx-3080-or-3090-until-2021\n\nhttp://www.worldpronews.com/39224/1178/290/26f31dce9cf105e05c66d2b4fed68cab7f86a2a4",
      "Yeah I think the shared memory is a super cool feature, but I don't think it's something that will get me to ditch my 3700x for awhile",
      "Only works with 5000 series chips and a 500 series MOBO",
      "I'm far more optimistic that TSMC can pump out the chips but they're also massively booked by others as well so it makes me wonder what kind of sustained production they'll be able to achieve over time after their initial front-loaded stock gets depleted in 6 seconds by bots.",
      "Wish you luck because they will sold out soon after launch.  You're more likely to see the 3070 back in stock before the new 6000 series (obviously released first)",
      "I was rooting for Samsung to do well with Nvidia tbh. I think in the next 5 years, TSMC could have a monopoly on the industry with Apple, AMD, and Nvidia. Some competition could be good for everyone.",
      "3070 had much bigger supply, but i assume it also had much bigger demand.",
      "It doesn‚Äôt work with the 3700x?",
      "TSMC 7nm yields are kinda godly tbh. TSMC is doing something very right",
      "I think you're under representing the demand for Ampere. Nvidia is the go-to graphics card manufacturer regardless of if AMD is making up ground.",
      "With all the hype around modern GPUs and their improvement over last gen, the real winner is anyone who gets a next gen AMD or Nvidia card in their system this year.",
      "Even if AMD beats Nvidia on supply, the demand will be even higher, so it won't matter.\n\nI'm 100%  sure that Big Navi demand, especially for 6800XT will be higher than Ampere, and AMD can't do any magic that'll have any supply for that.",
      "The amd supply isn't going to be much better according to rumors",
      "What if the 6800XT is sold out too and you can‚Äôt get it? Are you just gonna not get a gpu?",
      "Please keep your 3080 orders!!!  I want to have a better chance of landing a 6800XT on launch.",
      "Meaning I'll be able to do this with my 3700x and B550 MOBO?",
      "I have a bad feeling, it will be the same for the 6800 series. Not because of TSMC yields, but because of PS5, the new XBox and Ryzen 5000. All releasing at the same time.\n\nI'm in the same boat, preordered a 3080, will try to (pre)order a 6800XT on lanch day and whatever arrives first will be kept. Both cards will be great.\n\nRyzen 5000 release on thursday might be a good indication about possible supply issues on AMDs side, even though CPUs are a bit different i believe.",
      "I'm wondering if Nvidia's supply bottle neck on the 3080 is Samsung making the GPU or micron making the gddr6x.  If we see 3070 (which uses normal gddr6) availability normalize faster than the 3080 it would make me suspect the gddr6x is what's holding back the 3080.",
      "i would say samsung. there have been a lot and long rumors about problems with samsung 8nm. dont forget 3070 isnt the same die as 3080 and 3090. 3070 is smaller and easier to make. \n\nsoon after 3080 launch there was a picture either from chip manufacturing lab or card manufacturing lab, of a 3080 cards or chips in testing. failure rate because of cooling was over 30% i think. that means at least 30% of tested chips didnt qualify as 3080 because they need too much power and cant be cooled properly if chips are running at advertised 3080 frequencies.\n\non other hand, the gddr6x maker had basically 0 rumors about problems with its manufacturing, and as other pointed out in older topics, they were making quite many very high speed ram chips, that would indicate their manufacturing process is in good shape. i know, its not quite the same because gddr6x isnt a industry standard but something memory company and nvidia made together for nvidia, and it doesnt automatically make gddr6x production yield quality as the ram chips they are making. \n\nbut from all the rumors floating around, i would say samsung is the issue, kinda. because there is also a rumor than nvidia is buying limited amount of big chips until samsung improves yields. i am not sure how this works and why nvidia would have to pay for defected chips and not just good ones, but thats the rumor.\n\nanother bad sign for samsung as culprit is that Ampere architecture, similar as Turing, has one of the worst performance jumps in generation in nvidias history. and it is with a node jump, from Turing at TSMC 12nm to Ampere at samsung 8nm. since Ampere launch, many are saying that samsung 8nm is not a a big jump for silicon from TSMC 12nm. \n\nfor full truth we will probably have to wait a few months though"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800"
    ],
    "title": "RX 6800 positive experience makes AMD GPU's hate hard to understand",
    "selftext": "I have owned an RX 6800 (PowerColor Fighter) since December 2022 and I just want to say that it probably is the best card I have ever owned, firstly thanks to its performance (relative to its contemporary competition), secondly for not having issues with it contrary to general opinion about AMD GPU's and thirdly for its value for money (425 EUR, second hand, 2 years of warranty left). \n\nI use it on an AM4 platform with a 5800x3d for 1440p gaming and I have never noticed anything majorly fishy during all these months. In recent times I have owned an RX 3070 (positive feelings as well) and an RX 6600 XT, which gave me some headaches because of ReBar Z390 compatibility issues, I'll admit, but I managed to get the best of it in the end. \n\nPositives for you with this card or rather a negative experience?\n\n\\*Since 2002 I have owned 8 GPU's (4 Nvidia and 4 ATI/AMD), so non-partisan consumer here. \n\n&#x200B;\n\n&#x200B;",
    "comments": [
      "Went from a r9 390 to a 1080ti to sapphire pulse rx 6800, all great cards honestly.\n\n\nNever had a problem with either brands.",
      "What hate ? Doesn't most of Reddit recommend the rx6700 and rx6800xt as the gpu to get ?\n\nPeople go for nvidia because it's either all they ever know or they really need ray tracing, upscalers and CUDA. Personally I can't stand upscalers(only game at 4k native) and the games I play either don't have ray tracing or it's an half assed attempt of it's implementation that changes very little, so radeon was the only logical option.",
      "This is a bit of a ramble that doesn‚Äôt really have much to do with the RX 6800 and more to do with AMD cards overall, but I guess this all comes down to that user‚Äôs personal experience. For the most part I‚Äôve only owned ATI and AMD GPUs, integrated and discrete. I‚Äôve had the odd Intel iGPU (and a couple of Arc cards) and the odd Nvidia GPU, but by and large, I have a love/hate relationship with AMD given my varying experiences of their cards. \n\nLargely, you can boil down a lot of peoples‚Äô frustrations to drivers, power consumption and/or performance in a given scenario. Bad drivers are something I experienced first-hand on my R9 Fury X, which didn‚Äôt work on the Adrenalin 2020 drivers until the August 2020 drivers - and it took the final legacy driver patch in June 2022 to make official post-2019 drivers usable on it. I know drivers have burned a few people that I‚Äôve talked to (predominately those with cards that AMD has neglected on Windows, like the discrete Fiji and Vega cards), but at the end of the day, your mileage may vary. \n\nAnd that‚Äôs what it boils down to: what does your setup and use case play nicer with? I had an RTX 3060 and while it was a performance uplift from my Fury X, I felt massively disappointed by it and decided to go back to AMD to get a 7900 XT. Outside of instability from my card‚Äôs high boost clock that I‚Äôve had to fiddle with (2850MHz), I‚Äôve been massively satisfied by it - and I don‚Äôt think I could‚Äôve said the same about an RTX 4070 Ti for myself. This could very well go vice versa, too - I have a 4K monitor, which really leans into what the 7900 XT does best, but if I was gunning for HFR 1440p gaming, I could‚Äôve lived with the 4070 Ti easily.",
      "A lot of people still dont buy AMD because the hate of the years ago are still somewhat in their brain.",
      "I went from R7 370 to 1660 Super to 6800xt.\n\nNo problems here either.",
      "I've had many cards from both companies. My experience was similar on both sided with pros/cons and minor issues at times.\n\nI love AMD for it's superior gpu software and interface (for my needs), but I like Nvidia for DLSS and better ray tracing (I don't use it much, but it's nice to know it's there when I do).\n\nI'll buy whatever feels like the best deal at the time, but I have a bit of a soft spot for AMD due to them making adaptive sync affordable.",
      "I ran Nvidia since 2008 till this year, it's the only GPU and software for that GPU that I really knew. It was a leap of faith that my RX 6750XT wouldn't mess up for fail me on what can honestly be a varied selection of games I play. Maybe there would be crashes or driver errors or whatever and maybe it was worth the $50 more to just get a 4060Ti and play it safe. \n\nIt has been the most boring fucking transition ever. I set it up and forgot about it as it just runs flawlessly if not better than my Nvidia card as I didn't have to scrub through emails to remember my login for geforce experience this time.",
      "The only thing I know that I'm missing is better RT. Some games it be nice to have a better playable RT experience. With my 6900XT, I generally just leave it off. Even with FSR2, the fluctuations are too extreme even when it seems playable. 80/90fps one second down to 35/45fps the next second. \n\nThe only upside is RT ATM overall seems meh. Not very noticable to me in SpiderMan or Fortnite and Hogwarts is so rough around the edges it isn't worth having on. \n\nGames I want to have RT, like Stray or DRG, don't sadly. \n\nThough it seems like RT on RDNA3 is greatly improved. \n\nOtherwise I'm happy with my pick. Maybe if I go Nvidia I'll notice more of what I am missing. I had upgraded from a GeForce 1660S. But at the end of the day I am still mostly focus on the most raster performance I can get for my money. When I got my 6900XT it was during the crypto boom so comparable Nvidia was like 600-800 dollars more at the time.",
      "I swore I would never buy a ATi/AMD card ever again after several bad experiences in the past. But the Covid shit show forced me into buying a RX 6800 XT. And it's been a great overall experience. No driver issues, great performance and the software experience with adrenaline is much better than what team green is offering. And considering how Nvidia is pricing their stuff now I think I will be sticking with AMD for the foreseeable future.",
      "Reddit loves AMD cards tho. So do all my YT suggestions i get.\n\nBuilt a new PC recently, 6800XT was the most suggested card everywhere in the price range i was looking.\n\nI decided to go with the 4070 in the end, but i really like that we have options to chose from. \n\nPower consumption plus more expensive PSU are not always counted in the comparisions tho. That was the deciding factor for me.",
      "Not as if nvidia were not just as hated (if not more) at different times.  \n\n\nI guess for a lot of people it might be the attitude around when they go their first machine.  \n\n\nMaybe I go more AMD since ATI was my third \"3d\" card, voodoo 1 add on being the first, but then again I have been nvidia a lot too. Hey my current laptop is (not that it gets used as much!).",
      "A lot of them hating on it have probably never tried DLSS themselves tbh",
      ">are we dealing with an irrational consumer\n\nNo. Most consumers like DLSS, Reflex etc and it is usually worth the extra $50-$100 over the AMD alternative. Most people also buy prebuilts, which almost never feature AMD cards.",
      "The problems people have with AMD are the fact they aren‚Äôt much cheaper than the Nvidia alternative and are lacking features. DLSS is sorely missed on AMD and they don‚Äôt even have an answer for framegen so going forward they are going to have some competition problems.\n\nThey aren‚Äôt bad cards, but there are some frustrating things. Issues with DXVK on older games, people having issues with VRR, Dolby Atmos issues, etc.",
      "The reddit cloud loves and hates on them. The reality is Nvidia has the mind share so the world outside of reddit really doesn't care. They buy Nvidia, it works, they move on. Without something to generate a lot of buzz, AMD feeds their niche in the GPU department and tries to claw back any ground they lost over the last decade. Last I read steam surveys had them at 8% market share and combined with other sources a high estimate of 12% is possible. \n\nI personally love the reddit AMD crowd. They're over zealous sometimes but hopefully Intels next GPU round does better and we get more people realizing there are alternatives. Nvidia sitting pretty at 90% market share and legions of investors isn't good for anyone in the consumer segment. We need all the viable options we can get.",
      "Nvidia is really driving the GPU industry with a huge investment in R&D, that's why. CUDA, Optix, RT cores, Tensor cores, DLSS, DLSS-FG for example.\n\nAMD is always responding, ROCm, HIP-RT, RT cores, WMMA instruction, FSR 1/2, FSR3, so while their raw raster performance is certainly up to snuff they're typically at least a generation behind on all the other bits.\n\nMost *gamers* don't care that much beyond raw raster performance so that's why AMD is such a good option in that space.",
      "Same, I've had an RX 480 and now an RX 6950...   Nothing but good experiences outside of Windows Update causing driver issues with Adrenaline Software...   But that's because Microsoft removed the option to disable automatic driver updates in the Windows Updater...\n\nDriver stability and issues are slightly better than my experience with Nvidia over the same period.",
      "sis kid had a 6800 soon 3 years, he is happy and me with a 6700xt runs stuff perfectly.\n\nvery few writes on social medias usually so ignore them works",
      "Funny enough you can not even use RT in any lower end Nvidia GPU because u run out of vram and they end up losing to AMD in many RT scenarios.\n\nYeah the freesync was amazing for AMD to open that up.\n\nAMD has done a scummy thing on Freesync is that they make freesync over HDMI (not the vesa standard in 2.0 and above) an AMD only thing and refuse to open it up.",
      "Why should anybody care if DLSS is a ‚Äòstandard‚Äô or if it‚Äôs open source?"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800xt"
    ],
    "title": "Minor update here. GTX 970 to a RX 6800XT Red Devil",
    "selftext": "",
    "comments": [
      "Awesome! I too had a GTX 970 (MSI), though a Sapphire RX 6900XT popped up for me! How are you liking the switch from Nvidia to AMD? It's been nothing but improvements across the board for me, but I still need to get around to streaming, video editing and Blender.",
      "I got the card this Wednesday. On Friday I went on a business trip so I wasn‚Äôt able to do some testing yet. The AMD software is far more complete than Nvidia‚Äôs and this beast is so powerful that some games I play, the fans don‚Äôt need to turn on even at high frame rates.",
      "When I got my first Nvidia card last year (3060), I was pretty surprised how much worse GeForce experience was compared to the Radeon/Adrenalin app. I just assumed Nvidia‚Äôs default software would be way better but it‚Äôs actually pretty underwhelming haha.",
      "I have the same card except its a 6700xt. With those phanteks neon rbg strips it looks really sexy! üòÄ",
      "That‚Äôs an even bigger jump than I made. I went from a FuryX to a 6800XT. Enjoy!",
      "look up \"rnnoise\" there are many forks for many different applications for it. it's free and open source.\n( one fork for example is for use with general windows equalizer apo https://github.com/werman/noise-suppression-for-voice )\n\nif you want a \"commercial\" solution then \"krisp\" would be the way to go. they do ai based cancellation and there is also a free version, i am not sure about the limitation tho. -> https://krisp.ai",
      "I went from nvidia to amd with a 6700xt and the AMD software feels way better, the only thing I miss is the Nvidia rtx voice, that shit completely blocked out my loud ass keyboard and random background noise. Is there an AMD alternative to that software? I'd pay for it if I had to",
      "As an nvidia GPU user I don‚Äôt even use the GeForce experience app lol. I just use the standalone drivers.",
      "> I know everything don't bother\n\nlmfao",
      ">How are you liking the switch from Nvidia to AMD? It's been nothing but improvements across the board for me\n\nI have no allegiance to any manufacturer, but it's important to note that any improvement you're seeing should 100% be **because you've upgraded to a far newer and more powerful graphics card**, and nothing at all to do with changing from Nvidia to AMD.\n\nI've not decided what my next graphics card will be yet, but I've never had an AMD graphics card, and I still occasionally see bad stuff about their drivers, which puts me off a bit tbh.\n\nI'm happy with the move I made from and Intel 2600K to an AMD 5900X, but there are still some issues which I feel AMD haven't properly addressed yet (hopefully it's a matter of \"when\" and not \"if\"!)",
      "Smaller node means much smaller heat density, concentration in a single very small spot vs high spread area",
      "I'm moving from 2080 to 6800  (XFX Merc) - your jump must feel huge\n\n1440?",
      "FWIW, ReLive is my one major complaint with AMD's software. Shadowplay is *so* much better by comparison.",
      "Same card I have here (in 6900 XT flavor). Boyo you are about to FLY! Enjoy man!! Cheers",
      "I wasn‚Äôt able to test yet. My plans is to hook it to my 4K OLED tv :D",
      "Now you'll know what having more than 3.5gbs of vram is like.",
      "It does! Sadly my strips got some weird color strains in white and blue colors after 3 months of use. But the red looks totally amazing.",
      "IIRC those can be rmad, id give it a try. They have a high failure rate, or at least they had.",
      "same. went from gtx 1070 to rx 5700 xt and now back to rtx 3070 ti. it‚Äôs not even a matter of opinion it‚Äôs just a fact that shadowplay is so much better. plus nvidia has a better encoder",
      "Massively more power efficient, double the VRAM. Supports open standards like FSR, SAM. \nBetter driver tools for overclocking. \n\nNVENC is the single item that‚Äôs a true trade off, and it‚Äôs relevant to basically 1% of users."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800"
    ],
    "title": "Sapphire RX 6800 XT Nitro tease",
    "selftext": "",
    "comments": [
      "Looks really good so far. Pls no weird color accents.",
      "I mean, nothing's stopping you from turning off RGB on RGB components, meanwhile, you can't turn on RGB on shit that doesn't have it in the first place. \n\nOptions are always better, that's what PC gaming is all about.",
      "Came to say the same thing, please leave it stealthy/normal looking.",
      "Sapphire Nitro cards are always the best on when it comes to Radeons. I'm hyped.",
      "Fuck RGB, let Monochrome rule supreme.",
      "Yes. I pay thousands and thousands of dollars, it has a glass side panel and I want my things to look aesthetically pleasing. I'm quite frankly astounded that you could even ask that question 'genuinely', like it's some big mystery that people want their things to look nice?",
      "these \"teases\" are so tiring, it's just a fucking GPU",
      "Not even, it's 3 fans and some plastic. Or a rendering of them.",
      "That‚Äôs a very interesting fan blade design, I‚Äôll say that much!",
      "Dis looks gorgeous",
      "It looks like 2.5 slots from the image.",
      "So, one huge fan on one end, and two same sized fans on the rest of the cooler.\n\nI wonder how big this cooler is going to be vs the reference design.",
      "I personally miss the crazy Vapor-X models...",
      "The only \"tease\" will be the 3.5 seconds these GPUs will be in stock before getting scooped up by bots.",
      "Might as well ask why people care how their clothes look, or why anyone cares about art, music, or poetry.\n\nI don't understand how anyone can be genuinely puzzled as to why anyone wants anything to be as pleasant as possible.\n\nIt's not a problem to not care what your hardware looks like, but it's also not a mystery why anyone would.",
      "I'm with you on that.  I've got a closed case and I never see my card, but I don't mind a bit if there's RGB on it for folks who like that stuff.\n\nThough it does make me wonder a bit what a fully utilitarian card might look like.  Just all function dictating form, no nod to aesthetics at all.  I think I might like to have a card like that.",
      "VaporX and Toxic. They‚Äôre gonna happen",
      "I‚Äôm waiting for the 32GB heavily overclocked toxic 6900xt.",
      "Hope the rx 5700 xt gets a price drop when this bad boy comes out.",
      "Please be a 2-slotter. üôè\n\nITX needs some love."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800"
    ],
    "title": "First GPU Upgrade in Five Years: GTX 1080 to RX 6800 XT",
    "selftext": "",
    "comments": [
      "Next you should go after a 5800x3d...that will be a huge upgrade for your gpu and cpu on one platform. Like a generational jump. Pretty crazy",
      "That's the plan, eventually.  My computer budget is used up for a few months, though I think it was money well spent.  I got the 6800 XT for $570 new from Amazon back in December (though it took a month to arrive), and before that, I upgraded my old 2560x1080 75hz Ultrawide to the HP X34 3440x1440 165hz Ultrawide for $400.\n\nHopefully there will still be some good deals on the 5800x3d a few months from now, rather than stock shortages and price jumps from people buying them up...",
      "Almighty frame rate unlock! As others have said, bang in a 5800X3D and you're set for another 5 years. Very neat setup you've got as well.",
      "Specs:\n\nCPU: Ryzen 7 3700x\n\nCPU Cooler: Fractal Celsius+ S28 Dynamic X2 280mm AIO\n\nGPU: XFX 6800 XT MERC Core @ 2550/2150 1035mv\n\nMotherboard: Asrock x570 Taichi\n\nMemory: GSkill Ripjaws 32GB DDR4 @ 3600\n\nPSU: Fractal Ion+ 860W Platinum\n\nCase: Phanteks P600s\n\n[Timespy Graphics Score 21136](https://www.3dmark.com/spy/34892327)",
      "I recently seen 5800x3d for 274 at a microcenter ([link](https://www.reddit.com/r/buildapcsales/comments/10mejzp/cpu_amd_ryzen_7_5800x3d_27499_29999_25_new/)) but I think the extra discount is for new customers. Still seems like a great deal. I'm hoping it goes near 250. That could be a striking point for me.\n\nI also recently got a 6800xt (the red devil one) and wasnt sure yet if I want to get the 5800x3d now or wait since it could be the best for the current platform I am on.",
      "I'm no fortune teller but I think the 5800x3d won't get much lower. It's basically endgame for am4 so people with am4 boards will continue to buy it and AMD will move on to produce am5 stuff.",
      "BTW I love this phanteks case and congrats on the upgrade",
      "Your PC specs are almost identical to mine (I still have a 1080). How is the 6800XT? I'be been thinking about buying this GPU for some months.",
      "Overall it's been great.  For general gaming, it's over double the performance I had with my 1080.  I got a 3440x1440 ultrawide monitor last year, and the 1080 was still putting up a valiant effort thanks to the release of FSR, but now I can crank settings to max or near-max in most recent titles at native resolution and get 60+ fps.  It even does pretty well with light raytracing.\n\nDriver-side, things have been a little spottier.  When I first installed the card, I installed the (still) newest 22.11.2 drivers, and got video playback issues in Firefox and some driver resets.  I happen to be on Windows 11, and in its \"infinite wisdom,\" automatically installed a recent beta driver shortly after I installed 22.11.2.  Normally I would be annoyed, ...except the beta driver is running beautifully.  Youtube playback on Firefox is fine ...up to 1440p 60.  4k playback is choppy, but doesn't black screen or do anything wonky.  And 4k HDR youtube plays fine through Edge and Chrome, so, meh.\n\nI'm rambling.  TLDR: some driver kinks that might pop up, but when things work smoothly, performance is amazing.",
      "Thanks!  This Phanteks case was the first really modern case I've owned.  I bought it when I switched platforms to Ryzen back in 2020 and it made managing cables a breeze.  And yes, sometime this year, hopefully sooner than later, I'll be looking to get a 5800x3d.  That should keep me set for the next several years, as you and others have said.",
      "That‚Äôs crazy‚Ä¶ here in the middle of Europe the cheapest 6800XT sits at 700‚Ç¨ (incl. VAT). For 970‚Ç¨ you‚Äòd get a 7900XT‚Ä¶\n\nYou can basically decide between spending a lot and overpaying for the newest gen or spending less but still overpaying for an older gen.\n\nLast week a friend asked for advice for upgrading from an GTX 1080 with a budget of 700‚Ç¨ and the only thing I could tell him was ‚Äûraise your budget or stay put for the time being‚Äú.",
      "Ha, I did a very similar upgrade...had a 2600x and 1080ti, bought a 3440x1440 ultrawide and couldn't drive it properly so thought...time for an upgrade. Bought a 5600x and then 6800xt (Red Devil) and am so impressed with the improvement. 6800xt is a beast.",
      "I also have a 3700x but for someone who also values some workloads, would the 5800x3d hurt me there? I been using my 3700x at 4.4 ghz stable for almost 4 yrs but was thinking to upgrade to 5700x. However, I heard it's not much difference if I did upgrade to 5700x. \n\nWhile thinking about the 5800x3d, I understand that it's better for gaming. I just worry about the workload on editing and basic things.",
      "How's 6800xt handling 2k ultrawide? How often do you hit 100fps+, or is it just hovering around 60? I was considering this GPU as i have the same specs for the screen, but i was worried a bit about future proofing.",
      "Pretty sure you would see a pretty massive improvement in any single or multithreaded workload over a 3 series. Clock speed isn‚Äôt everything, the architecture, cache etc are all going to contribute to performance. Not to mention if you plan on keeping this system for years why not just slot in the best processor you can get for the motherboard you already have, it could let you get another 5 years out of the system you already have. If you see one at the right price I say go for it.",
      "You could make a new account, Aliexpress style, but you know, depends on how much you care about contributing to the profit margins of Micro Center. \n\n&#x200B;\n\nI like Micro Center and wish to contribute to its continued success so I personally wouldn't do it, but individuals must make his own decision.",
      "6800xt user here, by 2k ultrawide did you mean 3440 by 1440? If so thats what i use, and for example in Modern Warfare both in the multiplayer and Warzone it sits above 100 fps comfortably at Ultra settings with 110 fov. \n\nI do use FSR cause i have a 144hz monitor so i want to get closer to that number, but i think even without that i think the framerate would still be good.\n\nIf you want to i could run a benchmark for you if i have the game!\n\nEdit: FSR is at Quality i believe",
      "Thanks!  Aside from a few small hiccups, I've been blown away by the 6800XT's gaming performance.  It's over twice as powerful as my 1080 was, and going by what limited ultrawide benchmarks I could find, I'm in 6900XT territory with a decent undervolt and overclock.\n\nAnd yes, I love this case as well.  Upgraded to it when I upgraded to Ryzen back in 2020.  The netting and dust guards have been invaluable as my computer sits in a room that loves to gather dust, and the cable management features are great.",
      "Yep, I've been really impressed with the performance increase.  I was looking at both the Red Devil and the XFX Merc as upgrade options, but the XFX card had the best deal going when I snagged it on Amazon.  Funnily enough, the last four AMD cards I've owned have all been from XFX, and they all worked great for me.  I think I've managed a pretty solid overclock on my 6800xt as well.  It's currently sitting at 2500-2600 core, 1035mv and averages 2560 in most games.  Memory is at 2150 (2140 actual) and fast timings, and power is maxed at 295W.  I've tried More Power Tool and upping the power limit, but I think my card is maxed.  Throwing more watts at it ups the heat but not performance.  How's the Red Devil been treating you?",
      "I‚Äôm on a 1080 but at 4K. If I was 1440p the 6800xt would have been perfect and I see them around 520-550 bucks. Decided to step up to an XTX which will be here in March. Can‚Äôt go wrong with the 6800XT if you‚Äôre in less than 4k, and even at 4K it‚Äôs still double or more than the 1080."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800"
    ],
    "title": "6800 XT with 6900 XT/3090 Performance. Higher clocks do not always mean higher scores!",
    "selftext": "",
    "comments": [
      "TUF Asus Gaming Radeon Rx 6800 XT AMD Wattman Settings\n\n* GPU Clock Speed: 2350-2450 MHz\n* GPU Voltage: 1100 mV\n* Memory Timing: Fast\n* Memory Frequency: 2150 MHz\n* Power Limit: 15%\n* Smart Access Memory: Enabled",
      "Try 2120 on the memory. The VRAM automatically loosens timings above 2124 MHz, so you want to stay below that.",
      "6800XT is low key in the shadow of the 3080/3090 tbh. But it's a silent beast! Nice!",
      "vanish worthless wise frightening wide grandfather file point jellyfish spectacular -- mass edited with redact.dev",
      "Man I love my 6800xt but missing out on ray tracing and dlss kills me sometimes",
      "Is the same true with the 6900XT as well, do you know? Or is this just the standard enforced product segmentation in effect again?",
      "Nice, I'll see if I get a boost that way. I also haven't tried lowering the voltage even further, so I think I can get even more performance that way. I'll give this a shot when I get home from work and let you guys know how it goes! Let's see how far we can take this card!",
      "Mine clocked itself aroud 2730 mhz or so sometime.\nAll i did was undervolt... there was some artifacts, limites it to 2675 mhz and never had artifacts after this. Also saw some 327 watts consuption LOL. Now i limited it to 180 fps, consumes about 225 watts average whatever i do lol.",
      "only really in terms of ray tracing and 4k.\n\n&#x200B;\n\nif you're not on those trains, then its blow for blow pretty much and the 6800Xt is slightly ahead.  if you're into ray tracing and 4k, then its an obvious loss.\n\n&#x200B;\n\nnot sure why the 3090 is mentioned, it's not a competing card.",
      "At least it can run raytracing even if it's not amazing at it. If some super crazy RT game comes out there's the option to tweak settings until it's satisfactory. The 5700XT was the true dead end card since it offered great performance per dollar but lacked any future proofing.",
      "Plenty of people would love to get their hands on a true dead end card given the insane inflated bubble we are in.",
      "Yeah I noticed something funny with my gaming PC when I was tuning it for nicehash. Anything over 2120 on the memory was causing it to lose performance which I thought was weird. Your explanation would explain why",
      "Just picked on up a few weeks ago. They're a beast of a card. Ulgraded from a 980ti.",
      "All of us don't care about unrealistic benchmark scores either.",
      "dlss sucks in a lot of games man. 3090 here and i find dlss in cyberpunk unbearable, blurry mess even on quality. Ray tracing also feels like a single graphical setting, you turn it on and have to look for it. Most scenes in cp2077 are identical, but shiny glass is reflective. I painstakingly went back and forth in various areas turning RT on and off‚Ä¶long story short, youre missing very little. Check YT comparisons if you dont believe me\n\n\nIts not world shattering stuff. I firmly believe marketing has planted a seed in peoples heads its world shattering, and it really isnt yet. Amazing what adverts can do tbh, especially for cp2077",
      "The trick is to find settings where the card does not permanently hit the power target limit of 293W. My card's sweet spot is 2560 MHz @ 1030 mV and mentioned memory settings. The power consumption in Time Spy is  around 285W, the card constantly boosts to 2500 and my graphics score is well above 21,000 while my hot spot temp is below 95c (reference card). Since you have an AIB card and a Zen3 CPU, you should get even better results.",
      "It is. I have my 6900xt same settings",
      "3090 is also double the price.",
      "Okay but from the perspective of a gamer it won't be a big deal for quite a bit. Until most people have a decently powerful ray tracing GPU, developers will still have to create a decent rasterization based lighting system and tack on ray tracing effects afterwards.\n\nRay tracing will be revolutionary when everyone has it and developers can stop spending tons of time and resources creating point lights and faking real world lighting that can be simulated, and instead put that time to improving other aspects of the game.",
      "I would say its above 3080 and below 3090 (dlss not counting), source: i got both and tested them."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800xt"
    ],
    "title": "Got my hands on a brand new 6800xt for an amazing price today.",
    "selftext": "",
    "comments": [
      "I traded my rx 580 and $450",
      "You leave us without the price?! What kind of monster are you!",
      "very nice indeed.",
      "Congrats! Got myself a 6900xt about 3 weeks ago. Love it. Make u tweak the setting via the AMD adrenaline software, undervolt it between 1110 to 1150 and turn the power consumption up to 15%. Theirs plenty of YouTube videos on it if u need help. Enjoy ur new card!",
      "Performance and cooling. These Radeon cards have a high TDP but for what ever reason doesn't fully hit the power limit yet the stock voltage really heats up the card and can cause it to thermal throttle. So it's basically a balancing act between the 2. This is a very weak explanation,  videos on YouTube explain it much better. \n\nOh and tweak the fan curve too, the overall card Temps aren't bad but as u see on the software the junction temp on the card can get over 100, so tweak the undervolt and fan curve accordingly.",
      "> Make u tweak the setting via the AMD adrenaline software, undervolt it between 1110 to 1150 and turn the power consumption up to 15%.\n\nWhy for?",
      "Note that this is a problem mostly on reference cards and low-end cards. Once you get to the XTXH cards and the super nicely binned cards (Asrock Taichi), the coolers are so over-engineered that it won't thermal throttle even if you push the card to an extreme (unless the card is in like some sort of NZXT hot box case).",
      "Great deal. I just paid $850 for a Gaming X Trio model. It's a hell of a card. I love mine. Enjoy it",
      "850?\n\nOmg we're getting fxxxd over here in Europe!",
      "Ooo nice deal!",
      "What am amazing price",
      "Thank you thank you it was a Facebook market place find believe it or not!",
      "Had mine for a yr and a half. Rx 6800xt are Great cards",
      "I actually traded my 5700XT Red devil for 6800XT and paid 100‚Ç¨ with the trade. It's running super smooth, even after almost 6 months :)",
      "Sorry, I traded my rx 580 and $450 for it",
      "It's one of the best designed boxes ever, a delight to open.",
      "Just got mine 2 weeks ago. I upgraded from a 6700XT and I'm still surprised by the performance increase. Over 20k in Time Spy and it crushes in 1440p. Love it. The 6000 series cards have been great",
      "Outstanding! Congratulations!\n\nGlad to see enthusiasts able to get hardware.",
      "> It's running super smooth, even after almost 6 months \n\nIs that surprising? What were you expecting it to do after 6 months?",
      "Ah ok thanks"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800xt"
    ],
    "title": "anyone else think that the 6800xt looks like a boombox?",
    "selftext": "",
    "comments": [
      "Batteries not included...",
      "ObnoxiousLittleCunt",
      "Yeah, I do think it does. Does it matter though? I'm happy they ditched the blower-style coolers.\nAnd also: who doesn't like a good boombox? :D",
      "Requires 8 D batteries and lasts 1 hour",
      "No, unfortunately the 6000 series doesn't include a Ryzen CPU, you still have to buy that separate. Would be a great bundle deal though!",
      "as long as they deliver great performance idc honestly. just found it funny",
      "It reminds me of a transformers toy from the 80s or 90s",
      "Those were the days, now it'd have a built-in non-user-replaceable battery under 5 layers of plastic, epoxied to some structural piece to prevent you replacing the battery at all costs.",
      "So, now we will update the BIOS using mini audio cassettes now ?\n\n&#x200B;\n\n/jk",
      "Yeah.\n\nSome have interpreted them to mean AMD bad, and some have interpreted them to mean AMD good.\n\nI'll wait for actual reviews before making any kind of judgement.",
      "lol Boombox and Soundwave",
      "Amd did that with zen1 back in the day, it was good for people to have a selection of compatible mobos and cpu to pair with gpu inside.\n\nAaaaahhh the good times.",
      "Yeah, it's somewhere between beating the 3090 handily and barely beating the 2070S. It's simultaneously going to be a pair launch and have plenty of supply. It's also going to have somewhere between 6GB DDR6 and 16GB HBM2. It's shr√∂dinger's GPU launch.\n\nSeriously though, the only thing we know for certain is XBox Series X performance from Digital Foundry, which is 52 CUs, and people have been extrapolating from that despite not even knowing the settings it's running at other than resolution.\n\nWait for benchmarks and reviews.",
      "You have to live it !!!",
      "What?",
      "I‚Äôm not keeping up with the news very well, are there any leaks about performance yet?",
      "The  3,840 stream processors make the streamers get dumb\n\nThe base clock's bumping but I need the FPS higher",
      "Actually no, this is only the 6800 not the 6900 XT",
      "I think this looks rad",
      "Well now that you show us this..."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800"
    ],
    "title": "Finally retired my 1070 with this used, AWESOME, RX 6800 XT!!!",
    "selftext": "",
    "comments": [
      "Hi guys. I don't have any friends that are into PC stuff, so I came to share with you. This is my ship of Theseus. It started around 2008, and I've been upgrading it since then. (all cpu and gpu were bought as previous gen, sometimes 2 or 3 years after release. all new, except the current gpu)\n\nIt started with a intel core 2 duo and a nvidia fx 5000 series, can't remember the models\n\nchange platform to a amd phenom 2, with a radeon hd 5770\n\nupgraded to a radeon hd 6870\n\nthen change platform to intel i7 3770k\n\nupgraded to a nvidia gtx 680\n\nupgraded to a nvidia gtx 1070\n\nchange platform to amd Ryzen 7 3700X\n\nupgraded to a 5800x3d\n\nand lastly, to this monster of a rx 6800 xt (used), 16 gb lets go!!\n\nrest of the system:\n\ngigabyte x570 aorus ultra\n\ngskill Trident Z ddr4 2x8gb 3200 cl18\n\nssd Corsair Mp510 256gb (os)\n\nssd Kingston a2000 1tb (games and temp)\n\nhdd WD Black 6tb (media)\n\npsu seasonic X-850 gold\n\ncpu cooler Id-cooling Auraflow X 240\n\nCorsair Airflow 4000d\n\n6 noctua NF-F12 industrialPPC 3000 pwm LOL\n\nmonitor LG 27gl650f 144hz (1080p, now wishing for a 1440p)\n\nkeyboard logitech g710+\n\nmouse logitech g502\n\nheadphones sennheiser hd 518\n\nSo now i'm all amd. I have to say, since I bought the gtx 680, I saw nvidia as a better choice, and this idea stayed with me in the following years, even when amd released good gpus.\n\nI have kept my gtx 1070 since 2017. I didn't need to upgrade to 16 or 2000 series from nvidia, when 3000 series came out, prices were impossible, even more here where I live. I had hopes for 4000 series, but they really screwed up , and meanwhile, I completely ignored amds offerings. I regret that, i could have purchased a new 6800 xd, 1 or 2 years ago..\n\nanyway, im super happy with my 6800 xt, performance is insane, coming from a 1070, and even more considering i have a 1080p monitor, maybe i'll look for a 1440p upgrade.\n\ncheers!",
      "Most people who spend more for nvidia gpu‚Äôs literally think amd gpu‚Äôs give you herpes or don‚Äôt run games.  Seriously, nvidia marketing has convinced people to spend more money for the same performance.  Crazy.",
      "nvidia has some nice features, and i think RT its gonna be a big thing in the coming years in most games, but i made the decision of having more raster performance, and if rt runs, ok, if it doesn't, also ok..",
      "RT wont be relevant until consoles themselves can do demanding RT. Consoles are the baseline.",
      "I love my 6800xt too. I use it for 1440p gaming, but also flight and racing sims in VR on a Reverb G2.",
      "Awesome! \n\nThat's quite a story of upgrades. Do you still use the original case?\n\nI'm on a 1070 and I decided to survive until RTX 5000/RX 8000. My backlog of older games is gigantic, anyway, lol.\n\nBut it's great that you made the jump already! Enjoy your increased framerate, the RX 6800 XT is strong enough for your future 1440p screen, too!",
      "i think rt is the way on, but ill be excited when it becomes mainstream, and not a privilege",
      "Nvidias cards are more expensive for their features. AMD cards are good for native, raster performance. But FSR is not great, and they handle ray tracing poorly.",
      "i omitted some upgrades details, like cases, ram, storage.. i had 3 different cases, currently in the Corsair Airflow 4000d\n\ni like any art stile game, but im a sucker for icandy haha",
      "Funny how RT is a nothingburger but only until AMD is at parity in your mind?  \n\nI think AMD \"parity\" on that would be fantastic for the games industry but it's also wishful thinking that would require the competition not continuing to make sizable improvements of their own.",
      "Shader compilation just goes away once it's completed. It resets after every driver reinstall or shader cache reset. Usually it goes away after 5-15 minutes of just playing the game.",
      "I just went from the 1070ti to the 6800 XT myself. Seems like a popular upgrade path. But I did the 5800X instead of the X3D.",
      "Rt is relevant if you feel like its relevant. Rt, especially path tracing, can make a huge difference. Metro Exodus EE is a very good example.",
      "...if you dont use an upscaler or rt.",
      "Good choice!",
      "My 6800xt may outlast my old 9700 pro max. I love this card for 1440p and 4K in some cases.  I went from 3600x to 5600x and now 5800x3d and uogrsded my vega 56 to a 6800xt and I'm blown away.  It runs even better since I tweaked it in the drivers.",
      "Retired my 5700xt to a 6800, what a fucking beast of a card. Undervolted I'm pulling the same as a 5700xt, but it is so much stronger.",
      "I went from 1070 to 6800xt also yooo. I upgraded to an x3d processor also on am4.",
      "I upgraded from a 1070 to a 6700xt and can't really say I've been super impressed. Destiny 2 stutters like crazy for me on the 6700xt where I have no issues on the 1070.",
      "lets go!!!"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800"
    ],
    "title": "Launch day AMD.com 6800 XT order \"lost\" at FedEx - You should check your tracking number(s)",
    "selftext": "Were you able to successfully place an order on the AMD site for a 6800 / XT on launch day? If so you may want to check your tracking number to see if it's actually showing signs of activity.\n\n&#x200B;\n\nIf you are like me, it has been \"stuck\" in **OSSEO, MN** since the day the order was placed. I called FedEx ( 1 (800) 463-3339 ) this morning inquiring on why that is. In turn they had that specific FedEx location call me back only to tell me the package was not in their database and it is now officially **lost**. They then instructed me to call AMD and have them file a claim.\n\n&#x200B;\n\nI then called AMD ( 877-284-1566 ) and after a few minutes on hold, was told that this was not their first call regarding lost 6800's. The person I spoke to said that plenty of others were complaining about it on social media sites (Reddit named specifically) and that they are aware of this problem. At this time it would appear they will contact you back in 2-3 business days. Most likely to issue you a refund since they have no stock with which to compensate you at this time.\n\n&#x200B;\n\n&#x200B;\n\n&#x200B;\n\n\\[edit\\]\n\nIt is now 11/30/20, 12 days since my order was placed. After 10 days of being in OSSEO, MN, the package arrived this afternoon. At this point I'm not upset but rather relieved that the worry is over and have been happily playing Death Stranding (fitting huh?) all evening.\n\nI'd like to thank those who have stepped forward with their stories. To anyone who has yet to get their card; no need to panic. I'm sure you will get yours soon enough. :-)",
    "comments": [
      "I'm sorry to hear it. Sadly delivery drivers with sticky fingers appears to be becoming more common.",
      "I got lucky with my 5950x amd direct order since I received it. Boy was I scared though after hearing about how bad Digital rivers is and reading google reviews about how the Osseo,MN FedEx warehouse is the Bermuda Triangle of packages. I wish you good luck and hopefully they happen to find and scan them in so you can get it.",
      "It didn't even make it to a driver from what I can tell :-(. It seems they \"misplaced\" pallets of 6800s, hence why I made this post to help others that may be wondering why they won't be receiving their cards. \n\nA quick cursory look at FedEx's Reddit and Twitter pages reveals that they are also catching similar heat with regards to stolen PS5s. I sure would hate to be them right about now.",
      ">Osseo,MN\n\nHOLY FRICK! You weren't kidding!  \n\n\n[https://www.reddit.com/r/FedEx/comments/jcz3z9/whats\\_up\\_with\\_the\\_osseo\\_mn\\_warehouse/](https://www.reddit.com/r/FedEx/comments/jcz3z9/whats_up_with_the_osseo_mn_warehouse/)  \n\n\nCalling them the Bermuda Triangle of packages is spot on. It does make me wonder if AMD / Digital River knew about this beforehand. If I were them I would have saved myself the headache and chose another shipper. Then again hindsight is 20/20...\n\n&#x200B;\n\nWhere are you when I need you... Bridges / Fragile Express? :-/",
      "A lot of people keep trying to blame delivery drivers. Seems to me that it is far more likely that it is anyone involved in the process who can't be easily tracked.\n\nObviously there is a small number of delivery drivers who are actually that stupid.",
      "Yeah, I dont think FedEx drivers would risk their job for a meaningless piece of computer hardware. Some of these delivery drivers make in excess of $70,000 annually, and I am sure they will rather keep their job than be fired for some random crap. People on this sub pretty much parrot what people on the playstation sub said. Lo and behold their package was just delayed a couple of days. Calm your tits folks",
      "Thanks to SoapyCristian, I was able to find a similar situation involving that [God Awful depot and NVIDIA cards](https://www.reddit.com/r/nvidia/comments/ixw4bq/3080_fes_stuck_in_osseo_minnesota/).\n\nIt would seem that this place doesn't do outbound scans and that they automagically appear at the destination days / weeks later. If you are on this boat with me; keep faith alive. Should anything new develop, I will update. The person I spoke to did say they didn't have it in their database after all and was declared lost.",
      "FedEx in Pacoima stole my PS5 preorder from Target form Sept 27th",
      "70 grand + a few more grand here and there...idk. I dont doubt it occurs, but the scale isn't mainstream.",
      "You would think that. But I have seen it before. Several years ago, I bought a custom order Lenovo W520. Got from China over to the western seaboard, and shipped all the way to my local depot. Where it was last scanned on the truck for delivery. Then \"it fell off\".\n\nUh huh.",
      "The driver's software tracks every movement they make, I think this would have to happen before last mile delivery",
      "I had some parts not get updated at the Osseo facility for about 3 days only to be delivered to be without notice to me in Seattle. I'm not sure what's going on with the employees in that warehouse.",
      "I watched as I was pulling up to my house a Amazon driver take a pic of my package pick it up and leave lol Amazon refunded me",
      ">It‚Äôs not just risking their job, it‚Äôs committing a federal crime.\n\nDepends.  FedEx isn't the Postal Service and isn't covered by the rather strict federal laws that protect mail.  Crimes involving FedEx aren't under the jurisdiction of federal law enforcement like the Postal Inspection Service.  \n\nFedEx is the carrier that as a merchant I've had the most packages disappear while passing through their warehouses.  From experience USPS is the best about not having packages stolen during transit or at least being able to actually retrieve them if lost... while UPS comes in a close second.  I suspect UPS is almost as good as USPS because their employees actually give a fk about their jobs due to like USPS having a living wage and benefits due to a strong labor union.  FedEx and Ontrac are the worst with employees that for good reason don't give a fk.\n\n\n^(edit:)\n\n^(Ofc... for a hefty fee FedEx has a high security option where they will guarantee packages aren't lost or stolen during transit.)",
      "The more I read into it, the more cases crop up like yours from that location. Most of them as recent as October but some of them go back a year. It makes me wonder how come no one has gone down there and straightened them out.",
      "After retailers mark stuff up because they can, you can't even guarantee you will get it anyway. If it isn't retail employees cancelling your orders and selling your stuff to others, or warehouse workers disappearing entire pallets of goodies, it's drivers getting wise and running off with packages.\n\nWhat a garbage year for building a PC.",
      "are they just shipping these things with the packaging visible?   how do people know what they are?  if they labeling is visible that its a gpu, thats just dumb.",
      "Yup, my 3080 FE was in Osseo MN for a solid week. It literally updated a few minutes before it was out for delivery. Good luck.",
      "Drivers are not stealing.  The products are scanned and loaded into each vehicle.  If it gets on the truck, UPS knows it and the driver is liable if things \"disappear\"",
      "Lmao, I ordered two 5700XT's from Amazon, both just had the shipping label on the actual box."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800"
    ],
    "title": "XTIA Xproto-N Build - 5800X3D with RX 6800",
    "selftext": "",
    "comments": [
      "Technically, your house is now a PC case, and you're living in your PC. And that's cool.",
      "Dude, I also rock the same chassis - word of advice, the standard upright position fucks with the operation of the vapour chamber cooling on your GPU. You can also place it on its side with the GPU in an upright position and it should drop around 10-30C off.",
      "Really enjoyed this build. I ordered the custom length cables from XTIA (White) as well as the USB3.0 Audio front bracket. Cable management is surprisingly easy with this case. XTIA made slots for cables exactly where you need them. Cables are all running through a completely open 3/4\" gap in the center. Odd thing about this case is that it's crazy quiet even at arms length. GPU junction temperature hovers around 77C with fans running around 1400RPM (very quiet). CPU temp during gaming hover around 75C with fan at 50% (very quiet).",
      "You should tell your kids in the future (unless u already have them) this was your phone in 2022",
      "30C that's pretty intense. I'm not noticing any GPU thermal issues. Seems to be on par or better than when it was in my NR200 but if I do I'll definitely try your advice.",
      "Yes, vapor chambers are usually pretty insensitive to gravity. https://www.1-act.com/resources/heat-pipe-fundamentals/different-types-of-heat-pipes/vapor-chambers/",
      "Depends on the design of the cooler.\n\nI have an older HP laptop that will run just fine upside down for about 10 minutes until the heatpipes dry out at the evaporator end, and then the CPU temp rapidly climbs to over 100¬∞C before it shuts down to protect itself.\n\nFlipping it back over brings the CPU temp down massively in just a few moments.\n\n(I had used it upside down because it was connected to a TV + wireless keyboard and mouse, and was on the carpet. The vents are on the bottom, so upside down seemed like a good idea...)",
      "Lol",
      "How are your cpu temps with that cooler? Looks cool mate",
      ">GPU junction temperature hovers around 77C with fans running around 1400RPM (very quiet). CPU temp during gaming hover around 75C with fan at 50% (very quiet).\n\nAlso, thank you. Never built with a case like this before it was a lot of fun.",
      "My RX 6800 XT would overheat in that direction in Xproto. How's yours doing? Turned out it's vapor chamber didn't work well in that orientation - over half of the radiator stayed cool to touch. Temps were  MUCH better when I put my Xproto to the side.",
      "Or warm depending on overclocks right?",
      "capable simplistic upbeat elderly water foolish sand escape cows automatic -- mass edited with https://redact.dev/",
      "only me or do they look like massive phones straight out the 90s",
      "Set it to Wumbo.",
      "Have you done any undervolting on the GPU or used curve optimizer to undervolt the CPU? Great build and good temps, just wondering if you tried bringing the temps down further with either of the above.",
      "Just for you:\nhttps://i.imgur.com/GHuV3OU.jpg",
      "Didn't realise the rx6800 came with metal razor blade fins. Careful OP",
      "Get an air blower and it takes 5 mins.",
      "Thanks, now I have to clean my monitor of coffee"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800"
    ],
    "title": "[HUB] Best High-End GPU of 2020, GeForce RTX 3080 10G vs. Radeon RX 6800 XT: 2023 Revisit",
    "selftext": "",
    "comments": [
      "The 6800xt is over 200‚Ç¨ cheaper than the 3080 in Germany. Prise wise the 6950xt is about the same as the 3080. How do these two compare?",
      "Nvidia 30 series has always been faster at higher resolutions relative to AMD 6000 series, probably because the two architectures simply behave differently. The vram mostly doesn't play a role because apparently 10gb is still enough, but in the 3070 vs 6800 video you can clearly see how much the 3070 struggles. The issue is certainly overblown, some people think the 3070 is now useless when in reality it's just a matter of adjusting a few settings and it can still play very well, but the real problem is Nvidia putting only 8gb of vram on a GPU of that performance class. In the long run it's going to severely impact the longevity of the card.",
      "See the interesting thing is that at 4k (where vram matters most) the margin widens in favor of the 3080. Also interesting to note is HU reported that in hogwars legacy the 3080 ran out of vram but the 6800xt didn't provide a playable experience either. Maybe, just maybe, the vram issue is a bit overblown? For the most part, the lack of vram is not what's holding these gpus back",
      "6950XT is basically a 3090 level of performance. That's a no-brainer, Radeon wins.\n\nAnd the 6800XT is an even better deal.",
      "I was expecting to see this sub complain about HUB using so many RT titles, therefore swaying the % differences in favor of the 3080. Glad to see that‚Äôs not the case, at least not yet. In reality, anyone who bought a 3080, like myself, was interested in RT, so it definitely matters between these 2 GPUs, but I have to admit I was hoping to buy a 6800xt until a 3080 kinda fell into my lap during the height of the pandemic for close to MSRP.",
      "The \"vram\" issue is only about the fact that in 2023 you should not buy cards with low vram and expect not to encounter issues in 2024 in various ports or AAA titles coming out.         \nCards will work, you will be still able to play simply low vram have huge chance to impact quality of graphics you can use. \n\n\"Developers should optimize their games\" ... yes they should, but they will not do it as this require time and time means cost so something investors don't like.          \nLets be honest new titles will become more vram hungry and everything below 16GB at this point will need to be replaced somewhere in 2024.    \n\nFact that we get \"new\" cards in 2023 that have less than 16GB ram and cost >300$ is pretty much planned way to force users to buy new cards \"soon\".\n\nUnless like me you play in stellaris ... and stuff like Serf City.",
      "> Maybe, just maybe, the vram issue is a bit overblown?\n\nI think it's mostly misinterpreted. \n\nIf you have a 3070 8GB or especially 3080 10GB you should happily keep using it until either performance or outright VRAM limitations keep you from playing games at acceptable settings. You'll likely be able to use that card even at 1440p with minimal sacrifices for a while to come and enjoy a smooth gaming experience overall even in recent and near future titles.\n\nWhat the 3070 vs 6800 video did highlight was that we are approaching a threshold where VRAM capacity in the order of 8 (or 10 for that matter) GB is becoming a reasonable limitation in performance especially in the near future, bottlenecking otherwise excellent performance. Nvidia is still releasing 12GB GPUs at a $600 price point and even at $800 with the 4070ti (cheapest pc part picker prices). When buying new at that price point, it's not a bad concern to have if (like me) you like to milk a GPU until the end.\n\nI've had VRAM run out well before performance did in the past with a 780ti, it's a waste.\n\nThe 3070 and 3080 are still great cards, but the VRAM limitation should be a consideration to those buying new, especially since 16GB AMD cards are so comparatively cheap.",
      "same in Croatia, that's why i bought 6800xt and will sell 3070 while i can get some decent money for it.",
      "I'm just here for the comments :)",
      "I picked the 6800XT over the 3080 and they were at the same price. No way Im buying a 10GB GPU in 2023.",
      "Peformance class\nPrice class",
      "As a 6800XT owner there is nothing wrong with using RT on. It‚Äôs a very relevant tech now compared to launch, and in basically any game that has RT except for Cyberpunk I turn RT on. I still get playable frame rates so I figure why not use it (Dead Space, Callisto Protocol, Doom Eternal, Control, all ran well enough with RT) but the fact is I‚Äôd be getting much better performance with a 3080 at those settings.",
      "I upgraded from an RX 480 to an RTX 3080 back in 2020 and was able to get my card for around MSRP.\n\n\nFor me it came down to \"bad RT performance and no DLSS forever\" vs \"potential VRAM issues between now and 2024\". I rolled the dice and went for the new tech over the VRAM and so far it's been fine. I think TLOU's horrible PC port is the only game where you can't reasonably tune around the memory usage (not that there are many games where it's even an issue). Is it a sign of things to come? Really too early to say. Cyberpunk with full on pathtracing uses less VRAM than TLOU and Hogwarts.",
      "Strix 970 to xfx 6800xt merc this past black friday weekend $549 new.\n\nSkipped 10 series, 20 was a joke, 30 unavailable until 2 years later above msrp, 40 an even worse joke than 20.\n\nSeems to be a lot of posts and comments like mine recently. To be honest I can't say Ive ever seen so many people posting \"Ive always had Nvidia but theyve overvalued their cards\" or something similar lately.\n\nBeen loving the card, and can't stress enough to anyone on the fence that the 6800xt and 6950xt are totally worth looking at with current pricing. The only reason I didn't go with the 6950xt was I would also need a new psu and I just didn't want to do it as of yet.\n\nAlso, nvidia could learn from Adrenaline, control panel has looked and functioned the same since windows 98, needs updated.",
      "Yeah this makes sense. If we start approaching the point where vram is the main limitation, then ofc nvidia is messing by not increasing the vram of their chips. \n\nBut more specific to this video, so far the 3080 has aged better than the 6800xt, in direct contradiction to what a lot of people said back when both chips released",
      "6800xt is way better than 3070",
      "I still believe at the time the 3080 was and is a better card for near the same price. People on here overblow the Vram issue by a mile. More Vram for a 1440p card is not worth the crappy encoder (RIP Quest Users), no DLSS, dogshit UE4 VR performance and no Ai broadcasting at all. The 6800XT is still an amazing card and with it being $200 cheaper in some places it is the better card today but when both were around $700 idk why anyone would give up all those features so that one random Vram heavy game might work better tbh. The 3080s also have a much higher resell value compared to the 6800XT. People are selling 3080 used for $500+ rn.",
      "> . People on here overblow the Vram issue by a mile. \n\nDozens of RT games: RT is still years away.\n\nCouple of games with VRAM issues: 12GB is literally unusable. I don't care it's better at RT, VR, upscaling, or productivity.\n\n-This sub.",
      "It's been around 2.5 years since the 3080 and the 6800xt released, and at that time there were a lot of people making this exact same point (\"buy 6800xt because it will age better than the 3080.\") Yet the 3080 is still doing fine",
      "Same.\n\nGot my 6800xt at launch.\n\nChillin"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800xt"
    ],
    "title": "First all AMD build since 2009- 5600X/6800XT/B550 Tomahawk",
    "selftext": "",
    "comments": [
      "You shouldn't use that daisy-chained GPU power cable. Run two independent cables.",
      "welcome to team red bro. sick rig.",
      "Have always had Nvidia cards (usually paired with Intel chips)\n\nTNT2>MX420>5200Ultra>6600GT>HD5770>GTX670>life gap>1660 Super>6800XT\n\nGoing from the 1660 Super to the 6800XT is like a quantum leap in not just speed, but driver capability. OC'ing straight from the drivers? Integer scaling is rad, and 16GB of VRAM means VR is actually playable.",
      "Agreed",
      "Just ordered a 6800xt myself. Was gonna go 3080 from EVGA. But hearing that news I can't buy a 3080 from EVGA, and I wouldn't have bought from any other company. \n\n6800xt seems to be better than the 3080 anyways, and it'll be my second amd GPU. Previous was rx580. \n\nAlso upgrade from my 5 2600 to a 5800x3d! Can't justify upgrading ram and a Mobo just for the 7000 series quite yet.",
      "Don‚Äôt mix brands though!  Learned that the hard way (specifically Corsair cable with a EVGA psu",
      "Wait, what? I have the RM850x and it came with two PCIe cables. You just need to connect both to the PSU, and only use the main cable, let the pigtails hang off. By the way I had almost the same build, 5600x and reference 6800, before upgrading to a 5950x and MSI gaming x 6800 (CPU upgrade cost me 180‚Ç¨ and GPU upgrade netted me 100‚Ç¨ hahah).",
      "I was thinking about that since the shrinkwrap looks terrible. But two 8-pin PCI-E connectors is about $60 from Corsair...",
      "Short answer is that each cable is certified to run 150 watts, as each 8-pin is rated at 150 watts. If you plug one cable into both you‚Äôre effectively running potentially 300 watts over a cable certified at 150 watts. Most manufacturers will account for it but it‚Äôs better to be safe than have a melted psu cable.",
      "Welcome to the club my guy. The 6800XT is a badass card very good choice",
      "congrats man, currently building almost identical build but with a b450 instead of the b550, I was very hesitant to get the 5700X instead to pair with such a powerful card, but actually went with the 5600X instead.",
      "Indeed, welcome to the family.",
      "Yes, there is a technical reason. I don‚Äôt know the specifics of the technicals, but I do know that using two separate cables will provide more consistent clean power to the GPU.\n\nUsing that setup, take for example the +5v pin, two wires for +5v are being merged into one +5v pin on the PSU side (unless this cable also splits on the PSU side; but I‚Äôve not seen that). \n\nWhile technically this does work and can work without problems, but if you decide to push the power limits and overclock, you could start to run to into some issues pretty quickly.",
      "Yeah, I have an AORUS 5700 XT which...Gigabyte pretty much floored the clocks on to max out of the factory, so that would be a good explanation for why my GPU at times seems to just...click off. Time to add that second cable tonight!",
      "unfortunately, my EVGA 850 also only came with pigtails. but I still used 2 individual cords and wrapped them together.",
      "Beautiful.",
      "Welcome back to the good side.",
      "The difference between 5600X and 5700X in gaming is basically non-existent anyway, so yeah",
      "Just these shrink wrapped pigtails",
      "For gaming, more often than not the 5800x 3D performs better - for non-gaming tasks, the 5900X blows it out of the water.\n\nI'm waiting for prices to drop on the 5800x 3D and upgrading my gaming rig's 5600x just for this reason - maximize my AM4 lifespan"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800xt"
    ],
    "title": "AMD Radeon RX 7800 XT alleged scores \"19K\" points in TimeSpy matching RX 6800XT - VideoCardz.com",
    "selftext": "",
    "comments": [
      "New gen is equal to last gen? Some fancy joke?",
      "Inflation hit their naming scheme this time, I guess",
      "Wasn't this obvious?\n\n7800xt vs 6800xt\n\n60 CUs vs 72 CUs\n\n2.4ghz vs 2.2 ghz\n\nSo 83% of the cores boosted by 10% more clocks and add in a little IPCs.\n\nThen you get 7800xt = 6800xt",
      "Not like this is three years later with the same performance ü§¶‚Äç‚ôÇÔ∏èü§∑‚Äç‚ôÇÔ∏è",
      "Can't wait for 2030 when we won't be deciding between 9700, 9800 and 9900, but between 9990xtx, 9990xxxtx and 9999xxxx",
      "The names mean nothing it's all about the price.\n\n7900XT is the replacement to the 6800XT.",
      "how dare you use math to predict things that are based on basic math!\n\n*obligatory /s*",
      "So 6950xt that i bought yesterday was a good deal :)",
      "Why is an expectation of IPC from a new architecture \"out of nowhere\"?",
      "This generation sucks. This is not a generational uplift, this is a product replacement.",
      "It‚Äôs really just the same price they were clearing out the last generation for. While it‚Äôs better than last Gen launch price it‚Äôs not as good as if they had launched in say March. It‚Äôs also a disappointing generational uplift.",
      "Don't be silly. Elon successfully trademarks the letter X in 2028 forcing GPU manufactures to replace them with exclamation points.",
      "Gonna be curious to see how reviewers treat this if it really only matches the 6800XT. 4060Ti got universally shit on and it at least beats out 3060Ti at 1080p and 1440p for the most part.\n\nAs everyone has said this really should've been a 7700XT at $450.",
      "No reason, this is just a replacement as 6800 XT stock is drying out. For newcomers, it's more power efficient and has the latest tech, better RT performance, and has AI cores.\n\nEdit: also AV1 hardware encoder/decoder - thanks hj17 for pointing it out.",
      "Whats the price uplift and performance uplift of such replacement respectively?",
      "Around %33 performance uplift for 38% price increase at launch.",
      "AV1 encoding, longer-lasting driver support, slightly lower power usage, and I guess that tech they announced at gamescom that's exclusive to 7000 series cards (Anti-Lag+? Or driver-level frame generation? Maybe both, I can't remember)\n\nNot really a compelling reason to upgrade if you already have a 6800XT in my opinion, it's probably more for the people who haven't upgraded their card in more than 3 years. I probably would have gone for a 7800XT if I hadn't just bought a new 6800 a month ago.",
      "Not great. I thought it would be closer to the 6900XT.",
      "Cause we already had Navi31 reviews including deep dives and micro-benchmarks so the performance of Navi32 is absolutely trivially easy to preduct.",
      "It's the naming that's changed. The 7800 XT is matching (and likely exceeding by a little) the 6800 XT with 12 fewer compute units, 64MB less Infinity Cache, 768 fewer shading units, 48 fewer TMU's and 32 fewer ROP's at 37 less watts, for $100 less. It's really what the 7700 XT should have been.\n\nPeople saying RDNA3 has no architectural uplift whatsoever are paying attention to names and nothing else."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800"
    ],
    "title": "Stealthy-er mATX Build w/ RX 6800 XT MB",
    "selftext": "",
    "comments": [
      "You didn't like the case so you figured you might aswell upgrade the GPU, CPU, and CPU cooler? PC building in a nutshell.",
      "A couple months back, I posted [this pic of my build.](https://redd.it/l8o8tl)\n\nAlthough it was nice, I wasn't a fan of the case (I hid it from that image as you can tell), and since then the 6800 XT MB had released. So I wanted to change those two things... but I ended up changing a few other things as well, resulting in my build right now :)\n\nPCPartPicker List: https://pcpartpicker.com/list/BwWqZZ\n\ncable management pics, for those who enjoy that sort of thing: https://imgur.com/a/accqgfH",
      ">\"Man, these headphones are trash, I need to get a new DAC.\"  \n>  \n>\"It just doesn't make sense to have a custom mechanical keyboard a Microsoft Mouse.\"  \n>  \n>\"Having *one* sleeved cable looks weird, maybe it's time to upgrade my PSU.\"  \n  \nEtc.",
      "mATX such an under rated form factor. Did you do anything to prevent GPU sag?",
      "because you can't put an ATX board in an mATX case\n\nwhy an mATX case? because I prefer the size",
      "https://www.reddit.com/r/Amd/comments/l8o8tl/stealthy\\_matx\\_build\\_w\\_rx\\_6800/gldjmdr/?utm\\_source=reddit&utm\\_medium=web2x&context=3\n\n>Managed to snag a RX 6800 off amd.com at MSRP! this is basically my end-game build for the next few years :)\n\nThat post of yours aged well haha",
      "Beautiful system but shame you can‚Äôt show off the motherboard üòÖ",
      "[here's a better look at the inside, yeah it is pretty hard to see the Mobo lol](https://i.imgur.com/8y3PCsN.jpg)",
      "Tried that case with a 5950X + 3080 too.   \nLooks clean, very small build, but holy shit with a NH-D15SE and max. fans used it really gets superhot. Had to change the case again.",
      "I actually have a mechanical keyboard and a microsoft intellimouse 1.0A, nearing 2 decades old, older than me. can't exactly afford a heavy enough mouse for me",
      "Nope, from what I can tell the GPU isn't sagging",
      "Personally I love MITX cases. I had a TU150 build last year but had to go full ATX because I like high end parts and it was just too small for the cooling I needed.",
      "Basically, yes lmao",
      "Which case did you move to?",
      "Yeah, I wrote that while knowing that my old, optical wireless Microsoft Mouse was superb in its simplicity.  It wasn't fancy or featureful, but it did the job, it was the Honda Civic of computer mice.  (I actually drive a Civic IRL, so I'm allowed to say that.)  \n  \nMicrosoft keyboards are reasonably user friendly, too.  They're not mechanical, but for most consumers that doesn't matter, and they always worked well for me.  \n  \nStill, any excuse to buy a new mouse, right?  \n  \n>can't exactly afford a heavy enough mouse for me  \n  \nDo heavy mice cost that much more?",
      "Very sleek. What did you use to paint the GPU shroud or did you just cover the red lines with something?\n\nNVM: It's the midnight black version (forgot those existed)",
      "Now we‚Äôre talking! Very clean and no rgb unicorn puke üëçüèª Have my upvote sir!",
      "I think temps are just slightly better on the D15, not sure why that is. They should be very similar, but the D15 is just slightly better from what I tested. Also, I prefer how the D15 looks",
      "ü§£",
      "Be Quiet Pure Base 500DX. It was near the top of the stack for thermals and I like how it looks. Lian Li Lancool Mesh II was another choice I considered wrongly with excellent thermals."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800xt"
    ],
    "title": "Sapphire 6800XT Nitro product page is up!",
    "selftext": "",
    "comments": [
      "There appears to be a second page:\nhttps://www.sapphiretech.com/en/consumer/nitro-radeon-rx-6800-xt-se-16g-gddr6\n\nImplying there is a special edition (SE) with RGB on the fans.\n\nEDIT: SE also has a USB-C port instead of a 3rd display port",
      "So no one here is going to talk about the 850w minimum recommended power supply?\nEdit: I misread it doesn't say recommended at all. It says minimum.\n\n*Does not support all features including but not limited to Hardware Raytracing\n\nSystem Requirement\n\nMinimum 750 Watt Power Supply",
      "Damn, why they have to make type-c premium",
      "I think some VR headsets",
      "Nope.. we simply do not give a shit anymore",
      "850W covers their bases in case you buy a $30 piece of shit PSU that can only output 400W safely.\n\nAlthough, because of how switch-mode power supplies work, you will get better efficiency if you spec your PSU to roughly double your system's power consumption. Peak efficiency typically occurs at 50-70% of rated maximum.",
      "My God, it's beautiful. I really want the one from sapphire, I like supporting them as a company. I might not be as big of a fan as you but I appreciate what they do. Thanks for the link and thanks for all of your videos. Your content is packed with great information and it is very digestible unlike some other technical videos.",
      "AMD AIB models markup are usually tighter compared to Nvidia's. Sapphire Powercolor, and XFX all made top-end 5700XTs within $50 of the $399 MSRP.  I *expect* the AIB cards to be within $100 of MSRP for the 6800 series.\n\nEven Gigabyte's 5700XT price was good.\n\nIt's the AIBs like MSI and especially ASUS that like to price their stuff wildly.",
      "there are also a number of monitors that support it as an input method as well since USB-c display output is very popular on laptops",
      "what type of display uses usb-c?  I‚Äôve only seen it on phones and some newer peripherals.",
      "I saw that and thought, ‚Äúit doesn‚Äôt require that‚Äù",
      "perfect yes, this way my girlfriend will have no suspicion!",
      "They can run fine off a 650W",
      "*Four years ago I bought a AX1200i, everyone called me a madman...*",
      "Yes the man himself, the legend, the ghost, the greatest Sapphire fanboi there exists",
      "VirtualLink is effectively dead after Turing; None of the HMD manufacturers supported it, so it never took off. I imagine that this USB-C is simply capable of driving a Displayport signal and maybe data transfer, but no powering devices.",
      "Nitro is the highest, also since you are new, usually Sapphire and their Nitro series are the best cards you can get.",
      "Recommended power supplies are pretty inaccurate.   They just throw a big number up there so that when someone tries to run it on a 500W and it performs poorly or, not all, they can say \"Well, we told you it would need at least an 850W.  \n  \nRealistically, 650-750W is more than enough, unless your'e running that toasty 300W 10900K",
      "I've a 750W Gold, hopefully It Will be good",
      "wattage requirements doh\n\nfor sure the reference 6800 non-xt will need only 650w"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800"
    ],
    "title": "Simulated Radeon RX 7800 XT GPU ends up 4% to 13% faster than RX 6800 XT - VideoCardz.com",
    "selftext": "",
    "comments": [
      "Yeah... both nvidia and amd seem to have a hard time beating the 6000 amd's series deals for low/med/high-end, unless you want to get the top of both current generations the rest looks like a waste of time. Even if this is still a rumor I doubt it'll end up any different. Probably gonna end up getting an rx 6950 xt like any sane person.",
      "If it doesn't have some crazy power efficiency, it's better for them not to even release it.",
      "Not even a good simulation lol. This is based on the assumption the Navi 31 70cu card will be 7800XT, when the leaked rumours indicate 7800XT will be 60CU N32 card.\n\nDoesn't make sense to equate the GPU to 7800XT. It's not like 7800X3D simulated graphs where we got near accurate simulations.",
      "Its not just about the value. If your sucessor (with almost same CU count of 70 vs 72) is only a single digits faster than the previous gen, \n\nThen you fucked up. Its the same with the 7600 vs 6600xt (both 32CUs). Its just sad at this point. Almost as sad as NVs milking of consumers this gen.",
      "Power consumption difference will likely be pretty large. The 6950 XT also went up in price recently.",
      "Has anything from this gen of AMD so far had impressive efficiency? It seems like they really walked away from efficiency this round.",
      "4 to 13%, like the 7600 was going to be 11% better than the 6650 xt? :(",
      "Same deal here for 3+ months and actually it went down by 20EUR, once you do some UV you'll have a much more efficient card and lose 5% perf. in the worst case. Unless the 7800 xt isn't 50/100 cheaper than the rx 6950 xt there is no reason to wait for anyone that has been eyeing the rx 6950 xt.",
      "RDNA 3 is a disappointment.\nHopefully, discounted 7900 XT down to $699 would fix this generation.",
      "I worry more about the price than the performance for cards these days. The problem is not the performance, they could call it a 7800 XT and it could be the same speed as the 6800 XT, but if it's $399 or $349 then it's a decent product. But if it's $599 or something, then it's DOA. There's no bad product, just bad pricing. Yes, even the horrible \"4060 Ti\" wouldn't of been canned it they named it appropriately, say the RTX 4050 Ti and sold it at $199 or $249.",
      "tldr; if you're waiting for 7700/7800, don't. just buy a 6800 XT or 6900 XT",
      "6950 XT is the goal, haha. If that's it but maybe 20 to 40% better on power, then we're good. There isn't much room between the 7900 XT to the 69\\*\\* series for a 7800 XT.",
      "It's just more proof that the \"7900\" products should have been named \"7800\". If anything, it is strange that AMD decided to play the \"one-up in naming\" game with the 4080 / 7900XTX and will probably do the same with 4070 / 7800, but *didn't* do the same with the 4060 / 7600.",
      "The 60CU N32 performance means it cannot be more expensive than a 4070, which means it'll be branded as a 7800 non-XT.\n\nSimilar scenario to the 7600.\n\nThe 7800 XT will either be this GPU or will not exist at all.",
      "Yuss :3  \nAlso the same hype predictions for 7900XTX and 7900 XT before they were even out.",
      "That argument has always been bizarre to me. \n\n\"Hey, if you wait a year or two, they'll sort the drivers out to the point that they should have released with!\" lol\n\nNvidia also does driver improvements over time, but tend to get most of the performance right out of the gate.\n\nSaying it's like \"fine wine\" is a weird take on unoptimized drivers that take years to fix.",
      "They're still efficient, but they're tuned in the other direction at stock. I took 35 watts off the top of stock 7950X settings and get higher Cinebench R23 scores, lower thermals, and better gaming performance. I'm running -24 all-core PBO and haven't even tested higher undervolts on the cheapest X670E board available.",
      "I'm gonna be pissed if it's just another 6950 XT.",
      "I was about to suggest power consumption might be a factor... but it's only about 10 watts of power difference... and for those 10 watts you get another 2 gigabytes of VRAM and 4% more overall performance... and you can undervolt...\n\nI'm actually curious as to why people are buying the 7600 when the 6700 has an identical price...",
      "6900XT in the US is hard to find, AMD replaced it with the 6950XT. I have a Red Devil 6900XT with minor coil whine but other than that I‚Äôm very happy with it."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800xt"
    ],
    "title": "5600X / 6800XT Nitro+SE",
    "selftext": "",
    "comments": [
      "The table being smaller than the PC is giving me hella anxiety, but she's a beaut",
      "ahah don‚Äôt worry it‚Äôs just for pictures \npc is safe on my desk now",
      "I'm not a lights in my pc kinda guy, I prefer a nice looking discrete case.\n\nBut this looks pretty badass dude",
      "behind the motherboard, case is a lian li o11 mini",
      "7 fans at 800 rpm and for aio both at 900rpm and i can‚Äôt hear them honestly\ncase is very quiet and temps are good while gaming",
      "Where's the psu?",
      "i trade him against a 3080 FE so 730‚Ç¨",
      "I disagree. More fans at low RPM works better than less fans at high RPM. I've got a 7 fan system that was originally 5 fans (just one at the front, now three) and it's quieter because of it. I'm running bequiet! Silent Wings 3 and they're great.",
      "Critical question, how much did you pay for that 6800xt?\n\nThe build is beautiful.",
      "I have 13 noctuas in my machine running at 30 to 40% I can't hear a thing.",
      "I got my 6800 non xt for $989 at Microcenter. Not much coverage on it from reviewers but I love this thing. It demolishes 21:9 1440p.",
      "depends on your aio, trust me i try but i can‚Äôt dot it properly",
      "aio is alpenf√∂hn 280mm white, amd plate is included",
      "i know but i can‚Äôt because gpu is too big",
      "haha.  It's a Lian-Li 011 Dynamic case....the PSU goes behind the motherboard.  The case is a bit wide as a result.",
      "This should'nt be a problem as long as the highest point of the radiator is located higher than the pump.",
      "Where did you get the amd AIO?",
      "thank you !",
      "The tempered glass is off the case, so the interior is exposed.",
      "Why would it make a difference to the lifespan of the cooler? Whether it goes up or down first, it still has to come back down (or up), and those neutralize each other."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800"
    ],
    "title": "High-end AMD RDNA 2 supply is dwindling ‚Äî RX 6950 XT, RX 6900 XT, RX 6800 XT virtually out of stock",
    "selftext": "",
    "comments": [
      "that tracks, our microcenter still has a bit, it was 25+ since last year, now its at 17, guess they ain't restocking no more. I'm hoping they will drop price to move inventory a good sidegrade from 6800xt assuming it goes down a hundred more\n\nhttps://i.imgur.com/rWgZNu1.png",
      "Tons of them left in Norway. The only one virtually gone with just a couple of overpriced units in stock is 6800 and 6800XT.\n\nEven the 6700XT is easy to get cheap, I'm really ashamed of how many green cultists there are in this country",
      "Yet the ancient RX580 is still plentiful.  What's your thoughts on that?",
      "brand new or second hand? cause all I see for Polaris are ex-mining card.",
      "elastic rob alleged plate longing snails lush zephyr cough tart\n\n *This post was mass deleted and anonymized with [Redact](https://redact.dev/home)*",
      "Cheapest RX 6800 XT cost 6600 NOK, you can get 7800 XT for 6700 NOK or a 4070 for 7000 NOK.\n\nI bought my 6800 XT used for 4000 NOK over a year ago ü§£",
      "Anecdotes be anecdotin': I've got a 6700 XT, *not* a high-end card at all, really, but goddamn does this thing **scream** at 1440p.  \n  \nRDNA2 is a really great value proposition, and we're kind of getting to the point in computer hardware that people don't need as much future-proofing as they once thought.  It's like what we're seeing with cellphones; new and improved hardware is coming out all the time, but for many of us the *old* hardware still does everything we need it to do and more.  \n  \n>\"My gaming computer has a CPU bottleneck.\"  \n>  \n>*\"But your game is running at 350fps!\"*  \n>  \n>\"Nevertheless.\"  \n  \nThis may not be good for AMD, or less than ideal, anyway, but at the same time I'm kind of pleased as an onlooker to see that consumer habits may be changing a little bit.  Not everybody needs a Hummer, y'know?  *Some* people can get the most out of buying a Hummer, but not most.",
      "6950 XT was available for a long time as a fantastic value 1440p gaming card. Now the 7900GRE is available at the same performance tier at a lower price and is less power hungry.",
      "Exactly, usually I don't keep a high-end card, generally I resell it shortly after the arrival of its replacement, an RX 7900XTX Sapphire NITRO+ model, really an excellent card very well cooled (despite its increased TGP from 350 to 430 Watts in stock setting), but for now I'm going to keep my \"old\" RX 6900XT from MSI Gaming \"Z\" Trio model, with \"Navi21XTXH\" chip instead of \"Navi21XTX\" (running at a stock voltage of 1.2v instead of 1.175v), rather than managing to sell it used for just over 400‚Ç¨/400usd",
      "afterthought escape square shy quiet door cake familiar depend outgoing\n\n *This post was mass deleted and anonymized with [Redact](https://redact.dev/home)*",
      "Brand new - Best Buy here are STILL selling XFX 580's.\n\nFunny thing you say about it being an ex-mining card.  Before COVID ruined everything, I bought a Sapphire Nitro+ RX 580 for $100 USD from r\\/hardwareswap that was an ex-mining card.\n\nThing is, the person was very transparent about how it was used.  Was in one of those mass-mining setups with an open bench.  24/7 AC-cooled room.  Underclocked at the beginning.\n\nI still have it to this day and I probably run it harder in a worse environment than he does (kinda dusty room, humid, gets warm during the day, etc) and it still runs like a champ.",
      "Yeah the 7900XT and XTX launched at too high a price and the 6950XT suddenly became much better value proposition.",
      "You might be on to something there.  I bought one a year or so ago as \"new\" on Amazon, and it turns out it had been (poorly) repasted at some point and was running hot.",
      "Sardo-what now? XD",
      "I bought my 6700 XT during the drought.  \n  \nI will not be answering any followup questions.",
      "what's wrong with sardines? :(",
      "[About that...](https://www.amd.com/en/products/graphics/amd-radeon-rx-7700-xt)",
      ">I'm really ashamed of how many green cultists there are in this country\n\nMore for yourself.",
      "Yeah it screams at 1440p in most games, but playing Horizon Forbidden West on my 6700XT makes it *cry* instead lol.",
      "100%.  I got a RX 6800 (non-XT) and loving it for 1440p.  Made the switch from Nvidia to AMD GPU for the first time in almost a decade and it has been great so far.  Bummed that I didn't wait a little longer now that models are as low as $380 but other than that no regrets."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800"
    ],
    "title": "[Digital Foundry] AMD Radeon 6800 XT/6800 vs Nvidia GeForce RTX 3080/3070 Review - Which Should You Buy?",
    "selftext": "",
    "comments": [
      "The answer:\n\nNeither until prices and availability become sane.",
      "It‚Äôs not a question of which one should you buy but which one can you buy?",
      "It's really interesting that Rich holds the unpopular opinion that 16GB isn't worth it for these cards. Around 17:00 he says that AMD could have gone in for the kill by cutting VRAM down to 8GB and taking a big price advantage.",
      ">unless you want to keep your card for 4-5+ years\n\nShockingly, not everyone does yearly upgrades for the heck of it",
      "This isn't particularly an unpopular opinion, neither of the next gen consoles can get more than 10GB of VRAM and with features like DirectStorage coming to the PC which will allow you to stream textures directly to the GPU memory from a PCIe storage device the VRAM isn't going to be a big limitation even for textures which are absolutely insane and well above the point of diminishing returns. \n\nThe next gen engines are essentially built around asset streaming where both textures and geometry is streamed from fast PCIe storage directly to the GPU.\n\nI really don't know why AMD went for 16GB of GDDR6, could be just a numbers game, could be that their DCC color compression is still worse (still no DCC on ROPs for example) and it also looks like they will not be supporting inline compression for DirectStorage so they might need to compensate for that.\n\nAnd before people say remember Fury that's not the same case, the issue with the Fury was more complicated.\n\nThe Fury came out when consoles could already allocated more than its total VRAM (at least on the PS4 which allowed VRAM allocation of upto 6GB) and if a game say had to use 1GB extra than what the Fury could support you would be at a deficit of 25% that's a lot to swap in an out, and much harder to optimize for than 12.5-10% of a 8/10GB VRAM GPU today.\n\nThe APIs at the time of the Fury X were also much worse in terms of direct memory management, with DX12 and Vulkan you can do much better fine grain allocation and control combined with essentially zero copy access to system memory and to any memory mapped IO address space and you get a very different situation than 5 years ago.",
      ">  the unpopular opinion that 16GB isn't worth it for these cards.\n\nProblem is 16GB of VRAM might not even matter with these cards. They live/die on whether the infinity cache is being effectively used. If something is too large that there are a ton of cache misses the thing starts falling on its face. There exists the potential that nothing will be able to actually leverage that 16GB without slamming into the infinity cache limits like a truck into a concrete wall.",
      "Game coverage is a more important part of their channel. And curently there are 3 new consoles out there with plently of games to test and compare. Basicly the most important time for a channel like they are.\n\nIm sure they will release some Zen 3 video's as they get around to them.",
      "The recommended GPU for 1440p at *ultra* settings without RT is a 2060.\n\nI'm not sure what framerate they're targeting there, but why does everyone seem to think that the game is the next Crysis?",
      "why would people NOT care about DLSS? Its free performance and huge difference",
      "Same, I am on a waiting list for the 3080 and 6800 XT. Right after the launch of the 3000-series I thought I would get the 6800 XT because its probably easier to get but now it looks like the opposite. If I cannot get a GPU before December 10th I will see if I can run CP2077 at 1440p on my GTX 1080. Spending ‚Ç¨800+ on a GPU seems pointless if it works somewhat decent on my current GPU.",
      "I think the 3080 is the better choice if you can get it. DLSS and better RT performance is worth it in the long run.",
      "How about we ask this question again sometime in March when there might be a hope of there being stock to purchase?",
      "Can't believe they would mention a new feature RDNA2 supports.  Insane.",
      "A game using more than 8 GBs of VRAM =/= a game actually *needing* more than 8 GBs of VRAM. Lots of engines will do the smart thing and pack whatever VRAM is there full because then its there for faster access, it doesn't mean those engines won't give good performance with identical settings on less VRAM. \n\nCould also be the reason for occasional stutters in Horizon Zero Dawn - game needs to load something, on systems with large amounts of VRAM available it can grab it faster. \n\nDoom Eternal runs absolutely fine maxed out at 1440p on 8 gig cards.",
      "Ill follow 3 bots and atleast in europe... 3080 and 3070 drop atleast 6x more often than amd cards...\n\nsadly around 60% of those cards at ridiculous prices",
      "also constant harassments by console fanboys takes toll on your work.\n\nJohn Linneman had to lock twitter account to get away from that",
      "Even assuming that happens... what makes you think Nvidia won't have significant advantage with ML upscaling performance like they do with RT? You can't ignore that Nvidia has dedicated hardware for those tasks.",
      "The trend for VRAM usage is going to follow console game development. The reason most games are using 4-6Gb of VRAM currently is because that is the limit available in the last generation consoles. If that trend continues, we will start to see 8-10Gb of VRAM usage at 4k instead of the 4-6Gb we see now. I would expect any games developed specifically for the PS5 or XSX to have high VRAM requirements for their max settings. Also, keep in mind PC versions often get an ultra texture pack.",
      "This guy gets it",
      "The people here rationalizing buying an AMD card this generation are absolutely ridiculous"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800"
    ],
    "title": "just got a used RX 6800 XT Sapphire Nitro for $260 USD in good condition",
    "selftext": "upgraded from a rx 6600, this card is a beast!\nundervolted at 950mv, it only use 215w of power.\nthe only complaint that i have is this card got some coil whine but that's okay, is it normal for high powered cards like this to have coil whine?",
    "comments": [
      "It's fine the coil wine won't affect anything other than give you a headache I suggest turning fans up so you just can't hear it",
      "Pretty sure 6000 series is known for bad coil whine. Mine also has it",
      "Set an FPS limit and the whining stops. As much as the monitor Hz. Although if your monitor is 144Hz or above it probably won't go away. The point is that the less FPS the card has to work at the quieter the whine will be or disappear.",
      "I can hear mine wail. It reminds me of my old Mac that I could hear as it was ‚Äúthinking‚Äù while in use.",
      "Mine is as silent as an owl diving for its meal. Red devil 6700xt.",
      "Iirc coil whine from the GPU can be caused by a mix of the GPU, PSU, and/or \"dirty power\".",
      "Ayyee I have this card!! Mine is whisper silent too!!",
      "Awesome price, gg üëè",
      "Wow, what is this cpu cooling? Looks super cool",
      "Oh man, what a similar issue!! \n\nThe new 6800XT wouldn't boot. I went further trying to figure out my issue with a backup card, a 5600XT I had. Would run for a bit and suddenly shut off. Week into using I deducted it was either mobo/PCIE or PSU.\n\nWas both 8 pins that were melted and just noticed 2 days ago that my power supply has burns.\n\nI have zero coil whine after getting a BeQuiet 1200 watt.",
      "Good score dude, coil whine is fairly common though. In my experience (XFX 6800xt swft) the sound level decreases with an undervolt and the pitch shifts with the set clockspeed.\n\nAs for fixing it, people say that different power supplies can help. Unfortunately that wasn't the case for mine",
      "You can use superglue on the chokes to stop/minimize coil whine.",
      "Sounds like a good deal to me.",
      "My 6700XT has pretty bad coil whine but I \"fixed\" it by underclocking/undervolting slightly.",
      "My 6600XT Gaming X doesn't have no noticeable coil whine.",
      "Luckily I hit the silicon lotto and my 6800 is silent",
      "Pretty sure it's just 2 rgb fans on a either side of a mounted air cooler",
      "Kinda silly nobody fixes this stuff at the factory",
      "What a coincidence! My issue was also the psu. First card I got worked perfectly, until my pc randomly shut off and refused to turn on in any way until swapping the gpu out. Second one wasn't stable at stock clocks for even a second, and the third worked fine except for very specific scenarios in very specific games where it would cause a system restart. Deduced it was likely the psu having poor transient spike response, it was a pretty cheap corsair 750 watt from 2017. Got a much better A tier 1000 watt psu and have never crashed since. Coil whine got better after swapping psu, but not by a whole lot",
      "Great find! I have the power color 6800xt‚Ä¶ I don‚Äôt know what this coil whine fear is, I‚Äôve never heard it on mine. People seem to make a big deal about it"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800xt"
    ],
    "title": "5800x3d with a 6800xt. Upgrade from a 2700x and 2070s, very big difference",
    "selftext": "",
    "comments": [
      "[https://www.reddit.com/r/Amd/comments/zzt6ze/my\\_entry\\_to\\_team\\_red\\_5800x3d\\_6800\\_xt/](https://www.reddit.com/r/Amd/comments/zzt6ze/my_entry_to_team_red_5800x3d_6800_xt/)\n\nIts fun to consider that whilst these two PC's look completely different, they're identical in performance. :D",
      "His probably costs a fortune less so props to him for knowing how to save üòÖ",
      "Ayyy I also have that lego set!",
      "Aww, such a wholesome response üòä",
      "These ‚Äúfluflu things‚Äù to make the setup more pleasant is super expensive not everyone can expend the time or money doing these things, just that PCI cable from this post is almost 100$, not even counting the NXZT things, for me, we have some brands that do the same costing half‚Ä¶ it‚Äôs not critique, this build is beautiful and congratulations, but I wish these things could be more ‚Äúaccessible‚Äù so everyone could have a good looking case. There is something special when you look to your setup that yourself build and it is good looking",
      "The theme is god damm good",
      "The build is fantastic but the photography is even better! Love it!",
      "It's not about the cost for me. I legitimately want a computer case that has no glowy bits and doesn't stand out. I want it to just be an unassuming box of some neutral color.\n\nAcoustics become my biggest concern after that. Get me some silent noctua fans and some water cooling to minimize the background noise.\n\nNothing wrong with wanting a pretty case to look at. When I was younger I would have loved something like OP made. Certainly way better looking than anything i've built. \n\nNow just give me a NR200 and no RGB on the internals and i'm happy. lol",
      "Lian li o11 dynamic mini",
      "Came here for this too just got it for Christmas mom wanted me to build with my little siblings but have something ‚Äúcool‚Äù to display still",
      "It‚Äôs a great case, surprising amount of cable management space especially if you don‚Äôt have a 2.5 or 3.5in drive. Really easy to build in too",
      "Now imagine he went 5800X3D",
      "[should have posted this earlier‚Ä¶](https://pcpartpicker.com/user/Romanoodles_/saved/#view=6nLRVn)",
      "Nice looking build dude. Is it possible to get the name of the case?",
      "Just helped my buddy go from a 1800x to a 5600x on the same X370 board. Crazy how much of a performance upgrade that was. From ~2fps in highly modded XCOM 2 to ~15fps. And the only change was the cpu.",
      "Welcome to Team Red ü¶æ GPU wise anyway :) \nWana sell that 2700x?",
      "Lian li sl120 fans and the table is the ikea karlby",
      "Yeah I do anyway because of the aio block, but I just didn‚Äôt have the money at the time to purchase two extra fans for the aio to make them all match, although I will be getting the matching fans soon",
      "Is that the one where the petals are little pink frogs? It wqs posted on /r/mildlyinteresting a few days ago",
      "thank you. much appreciated."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800"
    ],
    "title": "[HUB] Radeon RX 6800 XT vs. GeForce RTX 4060 Ti 16G, 40+ Game Benchmark @ 1080p, 1440p & 4K",
    "selftext": "",
    "comments": [
      "These comparisons will always be interesting, but at  the same time pissing in the wind \n\nThe 6800xt is undoubtedly the better GPU, but the 4060ti will be more popular and outsell it regardless",
      "tl:dr; RX 6800 XT is:\n\n* 19% faster on average @ 1080p\n* 26% faster on average @ 1440p\n* 32% faster on average @ 4k",
      "Which is a damn shame. The 4060 series cards this generation are absolute dog shit, but people are already buying them in droves based on the latest steam hardware survey",
      "We couldn't convince people to buy 570s over 1050tis back in the day when they would win in 100% of everything. No but.. raytracing dlss 3d modeling ai something something the 1050ti literally had 0 advantages and it way outsold the 570. Kinda hopeless hoping people buy more amd cards today when it didn't happen back then. I just want some real competition which ultimately benefits the customer but if amd sells faster cards and Nvidia sells just as many cards as before we won't be getting that",
      "Prebuilts.\n\nOnce you realize like 90% of PC gamers are buying prebuilts, you will see why the 3050 outsold the 6700/6650 etc whatever.\n\nThe 4060/ti is going to be a huge prebuilt card, it‚Äôs likely going to outsell all of RDNA2 and 3 combined lol.",
      "In Germany the cheapest 4060ti 16GB is 550‚Ç¨, while the cheapest 6800 XT is 530‚Ç¨. DLSS3/frame gen and powerdraw alone should never be enough to warrant paying MORE for 20% less performance...",
      "RX 6800 16gb would be a better comparison, its faster, cheaper and more similar in efficiency.",
      "Now that would be shocking, given it's an *incredible* 128bit interface, compared to the 256bit interface of the 6800XT (and 3060 TI).\n\nIt truly is the worst card released in years.",
      "Well, still not regretting getting my 6800XT a year ago and for less than they currently sell for even.",
      "They use different nodes so die sizes aren't comparable. When you look at transistor counts (22.9 billion on 4060 Ti and 26.8 billion on the 6800 XT) you see that the 6800 XT has about 17% more transistors and is about that much faster at 1080p and even faster than that at higher resolutions. So technically speaking, in this situation, at higher resolutions AMD has better performance per transistor than NVIDIA, mostly due to the small 128 bit bus of the 4060 Ti. Also of course the 4060 Ti is the more efficient product because it uses the better node.",
      "Then don't watch it? It's really just that simple.",
      "Fwiw, that's with RT included. For those who care, It's 23%, 30%, 37% without.  \n  \nWhat I found interesting is the 6800xt actually wins somewhat comfortably in most of the RT tests, but cyberpunk is notably where it loses badly. Not sure of the reasons (maybe it just does more ray tracing?) But now I'm realizing how often this game is used as a demonstration of the huge RT advantage Nvidia has, and - based on this data - it's actually an outlier. (Ie. AMD RT is obviously weak, but cyberpunk seems to exaggerate it)",
      "Literally no advantage?  How about power use?\n\nNormally that's not such a big deal, except the 1050 Ti can be entirely powered off the PCIe slot, whereas that's not possible for the 570.  That's a big difference for OEM builds where there's a premium just for a PSU that has a PCIe plug on it.",
      "I don't know, I do think it differs per region. In my area, the 4060TI 16GB is a cool 100 euro more than the 6800. That's not really a good comparison, as they are in a different price class.",
      "This is exactly why the 1050Ti did so well. It was the go to office PC upgrade card because it runs with no external power. \n\nI bought a 1060 6GB over a 480 8GB because the 1060 was marginally faster, used less power but also happened to be same price in stores! ~¬£230. \n\nIf you‚Äôre not winning the metrics you‚Äôve got to win on price or you‚Äôre just not going to sell in to a dominant market. It‚Äôs pretty frustrating. \n\nIf the 480 8GB had have been 199 in store it would have been a no brainer.\n\nMan I wish 60 tier cards still cost those prices üòû",
      "Ada is impressive technologically. A damn shame they are just selling 30% over what they should.",
      "No problem, I hope he enjoys it.  \nHis milking helped me to buy RX6800 non-XT over 3070 and now I'm really happy that I went with his suggestions to buy 16GB card.",
      "I think the point is you can get the 4060ti and 6800xt for about the same price.",
      "They showed a power consumption graph...",
      "Because they are similar in price maybe?"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800"
    ],
    "title": "Why is my RX 6800 pushing 330w?",
    "selftext": "",
    "comments": [
      "This is the game that killed those bad 3090s, right?",
      "Hi, a while ago [I made a comment on this here](https://www.reddit.com/r/Amd/comments/psjgfv/radeon_software_adrenalin_2192_release_notes/hdv9t4y/)\n\nit seems that Radeon Software and other applications like GPU-Z are reporting incorrect GPU power consumption figures on 21.9.2.\n\nThis cannot be observed on the 21.8.2 WHQL driver. I validated this with some benchmark runs (gaming and synthetic) and a socket wattmeter to measure any difference in total system power consumption (for which there was none between the two aformentioned drivers).\n\nI wouldn't worry - this isn't a case of new world bricking your GPUs like from a few months ago with those EVGA 3090s.\n\nHopefully this reporting bug can be fixed",
      "Did you increase the power limits?",
      "Its a stock card, fan curve has been changed to be more aggressive.",
      "No, every card has firmware/driver limits and New World shouldn't be held responsible for EVGAs failure.\n\nhttps://www.pcworld.com/article/3632091/evga-explains-how-amazons-mmo-bricked-24-geforce-rtx-3090s.html\n\nIt's bad form to have uncapped fps menus, but the cards dying was due to a defect, and triggered by a near firmware limit power draw. It's up to the manufacturer or AIB partner to ensure their limits and quality standards.",
      "The game did a thing that probably wasn't good (uncapped FPS menus).\n\nHowever, that shouldn't be capable of killing a GPU. Uncapped FPS Menus should be harmless, just a waste of electricity. Maybe make your PC kinda loud as all the fans ramp up to cool the GPU.\n\nIt was EVGA's fault that the cards _died_ due to it; because their firmware was incorrect. It's up to NVidia/EVGA to make sure that the firmware contains the proper power limits to prevent the card from self-destructing.\n\nThe game just happened to be the first time that conditions aligned correctly for the incorrect values in the firmware to actually cause _immediate_ hardware damage. It's entirely possible (if not likely) that under normal usage, those cards would have suffered an early death due to the incorrect firmware limits.",
      "Check HWinfo64.",
      "New World",
      "24 total EVGA cards died‚Ä¶And EVGA has fully admitted it was a manufacturing flaw.\n\nThat story is about the most overblown overreaction ever concerning pc flaws.",
      "Reference design or partner card?",
      "This. IIRC they even 'fixed' it by capping the menu items that were supposedly going uncapped.\n\nIt's kind of like the entire game engine is being developed as they make the game. lol",
      "This is post 21.9.1 driver \nThe cards are in fact pulling a lot more power than before \nMy 6800xt spikes to 370 during benchmarks after 21.9.1",
      "To summarize, yes this was the game lol",
      "Just use Radeon chill. Have mine set with lower bound of 119fps and upper limit of 164fps. This keeps it near the refresh rate without dropping so low that I'd notice it in games.",
      "No, the card should be able to go right up to the manufacturer firmware limits without dying. New World can't and didn't bypass these limits.",
      "Limit your fps.",
      "I generally observed a persistent offset but there were also reporting spikes. None of this was true to the power usage from the wall in any case.\n\nYour GPU won't be using more power under load on 21.9.2",
      "Games don't control hardware, they just contain instructions on how to render frames.",
      "This is untrue:\n\nhttps://www.reddit.com/r/Amd/comments/psjgfv/radeon_software_adrenalin_2192_release_notes/hdv9t4y/",
      "It *was* qualified as \"those **bad** 3090s.\""
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800xt"
    ],
    "title": "5600x and xfx merc 319 6800xt",
    "selftext": "",
    "comments": [
      "Merc gang represent",
      "Man that xfx card looks so good! I got a red devil 6800xt cause that's all micro center had. Great looking build!!",
      "There's one here ‚òùüèº",
      "I've been drooling over the MERC 319 since it was released. How do you like it?",
      "Hey, I love my 6900 red devil!!",
      "Still playing with toys aren't we?",
      "Its great except in RT like all the amds",
      "Yeah it's a cool build but idk why people put toys in their cases",
      "If you can get one, do it, but as a proud owner of the 3060 Ti, real time raytracing just isn‚Äôt quite ready yet for my personal usage: high frame rates at 4K is amazing (DLSS for my card gets me there easily), but I dip below 60 FPS with most RT on. \n\nNext generation will see AMD and Nvidia‚Äôs RT solutions hit the mainstream I think",
      "Oh don't get me wrong, I love the red devil card, it overclocks like a beast!",
      "I've had nothing but amd, but I'm kinda considering looking for a 3080 with the way RT helps with lighting it'll help me see better. I've got horrible vision so I can use all the help I can get",
      "I've always been an amd guy and this is the first time I went nvidia, I got a 3070, RT for me isn't the best feature of the RTX series, DLSS is, and it's fantastic, it will increase the longevity of the cards",
      "07",
      "I've got the same card and I absolutely love it, it's tank. Never seen a card fly up to 2550 and stay cool on air generally at about 280w. Amazing upgrade.",
      "great build!",
      "I'm a cool dad",
      "Dude, it stays cold... It's ridiculous!",
      "It's a nice card, surprisingly no sag either. It's very well built!",
      "I found someone locally wanting to trade my gigabyte 3070 for an xfx 6800xt‚Ä¶ till I found out the 6800xt is 340mm long, way over my cases 320mm max",
      "Why? I think it looks fine. The ones that I think are dumb are the ones that don't go with the color theme of the case. So many just put random shit in their case."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800"
    ],
    "title": "The 6800 / 6800 XT is set to launch at 6 am PT on 11/18 per NewEgg customer service.",
    "selftext": "",
    "comments": [
      "The real helpful portion will be if newegg sends out emails with links to the product again. Because last time those pages weren't showing up from searches.",
      "Here‚Äôs your email two hours after the stock is out, sir",
      "And they'll be sold out before anyone has enough time to watch a single review video.",
      "Good luck. I'm hoping that i can snag a 6800xt since i couldn't get my hands on the 5950x last time",
      "If AMD follows CPU review times which im sure they will. Then the GPU's and the reviews will lauch at the same time. Which is fucking stupid.",
      "And the motherfuckers will be on eBay by 6:01 for double the price.",
      "and here Amazon sent me two accidentally lol",
      "Just remember to look at Newegg's return policies and see if you're ok with being stuck with a launch day GPU's problems backed by that return policy",
      "I wish they'd copy NVIDIA and release the review embargo a day or two beforehand",
      "I'm going to upvote this for visibility as this question is being asked every 10mins at the moment.",
      "There was a big ad on the front page with direct links. That's your best bet if they make another ad.",
      "Fortunately their holiday return policy extends until the end of January.\n\nIf you file an RMA with them and they don't have any replacements in stock, they will offer you a refund.  They've done that twice for me before anyway.",
      "For the Ryzen 9 launch, I was seeing a patient at 8:55am EST and about to wrap things up when he decided to tell me his life story when I only wanted to know if he had any drug allergies. Missed my window to order it.",
      "Set to Out of Stock for 6am PT.",
      "PT = Pacific time? As in PST?",
      "That‚Äôs why I wouldn‚Äôt order cards from Newegg. Good chances you stuck with a heavy whine card",
      "They usually don't let you return GPU's for refunds.  If you want to return for replacement, they have a very narrow definition of what's considered a defect.  For example, they don't consider deafening coil whine to be a defect.",
      "Amazon had solid stock on all but 5950x for at least 5 minutes.  But you should absolutely stick around to see if units pop back into stock",
      "that's where you messed up. I was there the first 20 seconds too and I refused to believe they were sold out that fast. I refreshed the page for 15 minutes straight and that's when I got a \"see all buying options\" button. There was not even an \"add to cart\" button\n\nI sped through that checkout so fast.\n\nIt looks like those pages were just being DDOSed and the products were glitching in and out of stock, at least on Amazon\n\nWould explain why Amazon sent me two since that was probably a glitch thanks to DDOSing the page lol",
      "Like a rocket ship straight into the reseller's baskets."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800"
    ],
    "title": "[GN] AMD Radeon RX 6800 XT GPU Review: Gaming, Thermals, Noise, & Smart Access Memory Benchmarks",
    "selftext": "",
    "comments": [
      "TL;DR:\n\nStrong rasterization performance, trades punches with the 3080FE, SAM enabled does something, not in all games, RAGE Mode is useless. Raytracing performance is bad, pretty bad, and no DLSS alternative kills it if you want to play Raytracing enabled games at high resolution and graphic detail.\n\nGN says the stock cooler is mediocre, ~~but they do noise normalized testing~~ testing done with auto settings, LTT shows that it performs on par with Nvidia custom solution, but they didn't disclose noise levels or fan speeds.",
      "Ray Tracing performance is surprisingly bad. \n\nConsidering it's a big selling point for the consoles, I expect pretty much all AAA games to have some sort of ray tracing from now on. \n\nTo me, this makes the 6800XT not competitive at 10% lower price than the 3080.",
      "Nothing about this is shocking though. We knew the RT performance was pretty bad compared to Nvidia. It's their first generation, same as how Turing RT performance was terrible.  AMD is working on their own DLSS. And 4k difference comes down to memory bandwidth. I'm actually happy for the AMD crowd. It's about time there's a direct competitor to Nvidia. I'm a 4k player and have a 3080 but damn if this isn't exciting because it pushes Nvidia AND Amd to push the envelope. 1440p non RT performance is absolutely mind-blowing",
      "AMD is good for 4k too, just a little behind nvidia, only falls short on Ray Tracing and DLSS for gaming.",
      "TUF 3080 destroys the FE thermals at the same price",
      "So Rage Mode is pretty much useless then? Seems like OCing the card provides much better performance numbers.   \n\n\nI wonder if thats a software issue?",
      "Most of the AIB cards do not have worse cooling though, and they generally have parity with the FE in the non-OC editions. Many of the AIB cards (Gigabyte Eagle, Asus TUF, EVGA FTW3) have noticably better cooling than the FE as you can see in GamersNexus' tests.",
      "Those who are patient are now rewarded. The better value play here is the 3080 given these benchmarks given that it's only $50 more. People will buy whatever they can get their hands on, and if you're happy, great. But I think Nvidia's got my money for this round.",
      "The testing in the review was actually with auto settings, as we said, we didn't change the fan speed for those tests. That will be in our follow-up testing.",
      "This doesn't look like an \"Nvidia killer\" to be honest",
      "It only works with the game RAGE.  Every time you drop below 60fps you get a tweet from John Carmack calling you a filthy environmentalist.",
      "Man Nvidia was so smart with these founders edition cards.\n\nThere are hardly any of them. They sell them at barely a profit. AIBs cannot match the cooling performance of those for anywhere near MSRP.\n\nAnd yet every comparison ever is to the founders edition performance at MSRP price. When 99% of people owning 30X0 cards will have to pay more for partner cards of equivalent or worse cooling. Just to get parity with founders edition you have to pay $50 more for the best value AIB cards due to overclocks.\n\nThe channel, Moore‚Äôs Law is Dead was dead on about this. The FE price and thermal performance is locked in for reviews but most people will have to pay slightly more for either shittier cooling or a lot more for a card with parity. \n\nFor those lucky few getting MSRP FE 3080, it‚Äôs a great deal.",
      "As expected, similar performance between 3080 and 6800XT, except when it comes to Ray tracing (and DLSS of course).\n\nIf you care about those 2 things (I do!) Nvidia is the only option sadly. (I say sadly because we can all agree that more competition is better)",
      "what a dissapointment\n\nEDIT: performance is okay, but they butchered the prices.",
      "Rage mode is just a max power consumption slider. What were you expecting it to do?",
      "**RAGE MODE** makes the fans louder so you can hear the card **RAGE**, how's that not worth it?",
      "NVENC OP",
      "Yah he talks about DLSS and Ray tracing in a few games and as expected, Nvidia destroys AMD for real time Ray tracing (even without DLSS), and if you account for DLSS, it's not even a competition... So let's hope AMD brings something similar to DLSS soon!",
      "I'd say 'viable' for 4k, bearing in mind that it's impossible to expect more than \\~80 fps in any case for \\*generic new release\\* unless it has DLSS.",
      "And streaming."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800"
    ],
    "title": "PowerColor RX 6800 Red Dragon Review, Power, Thermals, Overclocking & Gaming",
    "selftext": "",
    "comments": [
      "I‚Äôve honestly stopped watching and reading reviews since there is basically zero stock. Perhaps in 6 months I‚Äôll watch some reviews, when the products are maybe in stock and price / performance can be considered. Right now the only relevant part of the review is where they sit in the stack.",
      "Remember when AMD made fun of NV and said they'd have more stock then they had less?\n\nFun times.",
      "For 500‚Ç¨, fantastic. For >1000‚Ç¨, not so much",
      ">AMD is an amateur company\n\nDumbest hot take I've seen on this sub since I created this account.",
      "\"*Hardware unavailable*\"",
      "AMD also said they'd help create an environment for AIBs to sell at MSRP. It's very difficult to take anything AMD says seriously anymore.",
      "There‚Äôs stock, it‚Äôs just 2-3x the price",
      "\"*pOoR vOlTa*\"",
      "it won't ever be 500, we both know that :D it won't ever be 600 either :(",
      "I‚Äòm sorry, but this is one of the worst takes I‚Äòve ever read, period. You lost me at  ‚Äûamateur company‚Äú.\n\nI hate to break it to you, but Intel/nVidia aren‚Äôt perfect either, far from it.",
      "Maybe there is stock in your area... but there isn't in most.\n\nIn Canada AMD 6000 line is 10x harder to find then RTX 3000 cards.",
      "00:00‚Äã - Welcome back to Hardware Unboxed  \n01:32‚Äã - A look over the graphics card  \n03:24‚Äã- Graphics card teardown  \n05:02‚Äã - Stock Stats  \n05:47‚Äã - Overclocked Stats  \n06:29‚Äã - Shadow of the Tomb Raider  \n07:22‚Äã - Power Consumption  \n08:02‚Äã - GPU Edge temps  \n08:18‚Äã - GPU Hotspot temps  \n08:31‚Äã - VRM temps  \n08:48‚Äã - GDDR6 memory temps  \n09:12‚Äã - Normalized GPU Edge temps  \n09:41‚Äã - Normalized GPU Hotspot temps  \n10:02‚Äã - Normalized VRM temps  \n10:17‚Äã - Normalized GDDR6 memory temps  \n10:30‚Äã - Final Thoughts",
      "How do they take themselves seriously?",
      "Yeah. HUB copies and pastes the timeline titles and sometimes forgets to edit some stuff.",
      "What are you expecting?",
      "I have 99 problems but a driver ain't one.",
      "Should add finding the card and paying for it to the review process",
      "Not sure if /whoosh on my part or what, but where the banner would usually read \"Hardware Unboxed\", it says that instead. I chuckled.",
      "tbh you shouldn't take anything ANY company says seriously\n\nall companies exist to make money, we are walking wallets to them",
      "For the same reason we watch natural history programmes about giant pandas or blue whales I guess."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800xt"
    ],
    "title": "Went from Vega 56 to 6800XT for a net of $350. The deals are real right now.",
    "selftext": "",
    "comments": [
      "Blown away by the performance of the 6800XT. I game at 1080p 144hz and this card handles ultra settings in everything effortlessly.",
      "Haha nice deal. Here where i live the cheapest is only 650-700‚Ç¨ üòù and the 6950xt is 900‚Ç¨",
      "got mine the 28th from Asus.com. 529.99 for a new 6800xt tuf",
      "If you ever want to, this card will destroy 1440p ultrawide like nothing and the visual upgrade is well worth it.",
      "I wouldn‚Äôt say destroy, especially depending on your settings and the game you‚Äôre playing. It‚Äôs definitely an awesome card though.",
      "Bruh 6950 for a 1080p display... feelsbadman. Get yourself a nice 1440p ultra wide lol",
      "This. I mean, destroy rocket league or fortnite? Sure. But not current and upcoming AAA games",
      "Nice one man!\n\nLooks beautiful.\n\nI upgraded my 580 8gb sapphire nitro+ to a 6800xt reference model, got it at launch for ¬£659.\n\nI know the net is 350...but how much was the actual 6800xt out of curiosity.",
      "Huge upgrade- congrats",
      "I got a 6800xt for Christmas, had the 2060 before. It‚Äôs a great upgrade. It destroys 1440 p also. Congrats man I see no need for anything higher when this card is a beast",
      "That's a screaming deal!",
      "7900xtx is around 1600 ‚Ç¨ here un Austria. That's 60% above MSRP.",
      "This looks like the french prices after spending 3 months looking for a deal on the 6800xt.\n\nBtw, be careful as there are some scammers on Amazon that proposes flash deals on 6800xt and 6950xt on Amazon France. Once you place your order, they cancel it and send you an email saying something along the lines: this promotion is only available for direct transfers. Here is our Spanish IBAN, please send the money and you will get your card.\n\nThey hacked the accounts of legit Amazon seller and do this kind of shit. So be aware :)",
      "I installed a red devil 6950 today, also upgraded from a vega 56 and playing at 1080 lol. It draws less wattage than the Vega did in the one game I play.",
      "1080p for a 3080 equivalent is wild, but glad your enjoying it. Might wanna invest in a 1440p 144hz monitor soon tho.",
      "It's impressive how much more efficient RDNA2 is compared to Vega.",
      "Thanks!",
      "Yeah that's my plan",
      "Yep, mine was like new. Wouldn‚Äôt have known it was used if it weren‚Äôt for the open box. Great deal for $475!!",
      "I had a 5700xt and sold it during the mining craze. I inositol bought a 3070 ti but couldnt reason spending so much so i sold it for the same price  basically. I ended up buying a 3060 which is similar to the 5700xt. I told myself i would upgrade when RDNA3/Rtx 4000s come out but the prices has been disappointing. So i sold my 3060 and bought a used 3080. Went from a 5700xt to a 3080 for a net price of $250."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800"
    ],
    "title": "Excellent news: Radeon RX 6800 XT is a horrible mining card",
    "selftext": "https://www.youtube.com/watch?v=HoMRPUAywkk\n\nEthereum:\n\nRadeon RX 6800 XT: 59 MH/s\n\nGeForce RTX 3080: 86 MH/s",
    "comments": [
      "Bro...why you have to go and say that..",
      "Yeah, because nobody has written an algorithm yet to exploit the 128MB 2TB/s cache",
      "Are miners still using consumer GPUs? I thought they have moved on to ASICs?",
      "Oh no, a miner won't be interested in my second hand card! That's awful.",
      "For Bitcoin yes. Other coins use different algorithms some of which are not good ASIC candidates.",
      "There are fewer things worse for the world than miners. Globally, they use as much electricity as a small sized first-world country and that electricity is being used to solve pointless equations.\n\nCrypto is a plague.",
      "Mining is DESIGNED not to work well with caches. It's one of the ways they make designing asic's difficult.",
      "No...\n\nMiners run 24/7, ‚ÄúGamers‚Äù go to sleep lol.\n\nAlso I get your point we waste electricity simply for entertainment.",
      "There is too much random reads on a huge dataset going on to make use of cache. This is by design.",
      "What about gamers? \n\nThey play a pointless game that has negligible positive effects on the world, if positive at all\n\nI am a gamer\n\nI get miners use a lot more power, but surely all gamers use more than them right?",
      "There are people that have mining farms that fill up a warehouse. Pretty sure it's a bit of a problem in China.  Or it was at one point at least.\n\nOptimized mining rigs can be efficient.  When I had a 6 gtx 1070 miner, its total power consumption was similar to my overclocked 4790k/980ti rig.  It was around 200Mh/s.",
      "it was sort of obvious that they'd write an algo to take advantage of that bigass cache",
      "Yep. But I mean, it's all a matter of time. Mining is a zero sum game, and if the margins get competitive enough, people will start R&D on ASICs.",
      "Many Coin dev dislike asics as they centralised the network and go against the ideal view of cryptocurrency. They change the algo to be asic resistant like monero did.",
      "Mining is bad. Crypto is not. They are not the same.",
      "GPU mining is actually quite profitable right now with ETHASH / Ethereum.  Even with this RX 6800, my calculations are that you can get back the cost of the card in 13-14 months depending on the electricity costs (65MH/s @ 250W is my guess on this card).   Which isn't bad.  What people don't know is that these algorithms are always improved upon, and when new cards come out, they are not optimized at all.  Plus,  hashrates+efficiency can improve when modded bioses are out for them (AMD cards only) and proper OC/undervolt tuning. \n\nIt's way too early to tell.",
      "When the hell is Etherium moving away from proof of work to proof of stake?\n\nWasnt that supposed to happen within a year or so?",
      "You don't buy tech for a resale purpose buddy",
      "Nah, that is literally not true.",
      "This is a dumpster fire of a comparison. At least gaming has provided value to the community. Bitshit hasnt."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "high",
    "matched_keywords": [
      "6800xt"
    ],
    "title": "Finally finished this buildü§© 5950x, 6800xt.",
    "selftext": "",
    "comments": [
      "Is your camera covered in Vaseline?",
      "Nice! I'm thinking of buying a 6800xt for my 5900x. Still waiting for a good deal on it.",
      "Never understood the logic of making your camera utter shit in the interest of it not breaking.\nWhy have a good camera in the first place?",
      "Lmfao no I have a lens protector on that makes videos look a little foggy in dark rooms",
      "I've got a rotated monitor. Devs love them as lines of code tend not to be very long, but you'll have a lot of them, so it's the optimum use of screen space.\n\nIn fact, I use it kind of as a measuring stick; if I have to scroll to see a whole line, that's a sign that I should think about what I'm writing and if it should be broken out a little bit more",
      "Got mine for msrp from a seller on marketplace that bought the wrong color. I was like ‚Äúdamn man must be nice to get one gpu let alone 2 bc you got the wrong color‚Äù",
      "I get you. I am a developer but I use 4k screens instead as everything fits on the screen. With c++ lots of lines are long but I have considered trying to rotate one of my 4k screens.",
      "Can you drop the primary monitor‚Äôs wallpaper?",
      "Thermal take p3 core",
      "You can get a 6900xt and 6750xt and 6950xt on the actual Amd website for msrp almost every day",
      "Nice, how does that rotated monitor thing work out? I've seen tons of people with setups like that but I never understood it. Do you use that monitor only for chat programs or something? How do windows work if you drag them onto there since the aspect ratio is opposite.\nDo you have to shrink web pages to make them fit properly? I use a triple 4k setup and my monitors support auto rotate, but I've never done it (and my cables would have to be lengthened) so I'm just wondering.",
      "I‚Äôm getting the 5950x soon what are your temps like?",
      "It's an animated version of this: https://www.pixiv.net/en/artworks/82269588",
      "They don‚Äôt auto rotate you have to go to the display settings and change it to portrait mode and yes I mainly use it for discord or when I run virtual machines I have Linux on one monitor windows on another, but yeah it‚Äôs just drag and drop",
      "The monitor in the center (the ultrawide) can you post the wallpaper you have on?",
      "My lense protector doesn't do this. OP probably has oil/finger prints on lense protector.",
      "Nice build! Which case is that?",
      "Samesiesss. All packed into a micro atx case too\n\nhttps://imgur.com/gallery/42J1QMq\n\nhttps://imgur.com/gallery/vYzxzLp",
      "Replying to check back later, want it myself too!",
      "In this case with a 240mm aio, I average around 60 when gaming. If I‚Äôm running cinnebench it gets up to about 70"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900xt",
      "6900"
    ],
    "title": "RX 6900 XT Launch went exactly as expected.",
    "selftext": "Not a single card.\n\n&#x200B;\n\nWhy do I even get my hopes up?\n\n&#x200B;\n\nCorrection: 1 was available, one of the watching discords found 1 whole card.\n\n&#x200B;\n\nCorrection 2: I spent 3 hrs trying to check out.....but ultimately failed. I had a 6900XT in my cart, I got to the \"Confirm payment\" page 100+ times.\n\n&#x200B;\n\nEdit:  Well this was originally intended to be a snarky post, but apparently it merited a gazillion reddit karma, I wonder if /u/AMDOfficial will come out of hiding to trade some of that internet karma for a graphics card, because they could sure use it right nowü§£üòÇü§£üòÇ\n\nAlso you jackwagons got my karma to 66.6k, /u/Tul-PowerColor does that net someone in the comment section a Red Devil Card? üòÇü§£\n\nIf I wasn't laughing, I'd be crying.",
    "comments": [
      "Can we skip the Redditor stages of grief routine, and go straight to acceptance?",
      "3080/90. Sold out immediately, Reddit bitched.\n3070. Sold out immediately, Reddit bitched.\n56/58/5900s. Sold out immediately, Reddit bitched\n67/6800. Sold out immediately, Reddit bitched.\nXbox. Sold out immediately, Reddit bitched but way less because they all want PS5s.\nPS. Sold out immediately, Reddit bitched.\n\nWhy change the amazing habit for the 6900XT?\n\nAt this point anyone genuinely surprised or angry should be wondering why they expected anything to be in stock.",
      "You don't even have to look at this launch cycle. 2080/ti. Sold out immediately, Reddit bitched. AMD 3900s. Sold out immediately, Reddit bitched. RX480. Sold out immediately, Reddit bitched. 1080/ti. Sold out immediately, Reddit bitched. \n\nReddit has the memory of a goldfish.",
      "don't see it even listed on Newegg yet\n\nEDIT: My bad. Newegg just didn't put the banner up like they literally always do. Cool, missed again",
      "Goldfish actually have decent memories. Check Mythbusters video on Jamie feeding them",
      "Checked Frank Azor's twitter page just in case he \"successfully\" ordered one. It seems he's been quiet for a while now, and his last tweet was on November 18 when he mentioned how he was able to successfully order a 6800.",
      "I CAME HERE TO BE ANGRY ALONG SIDE EVERYONE.\n\nMAD.",
      "Imagine that poor thing .. floating there .. all the sudden the vibrations around it are a deafening BOOOOOOM.. followed ..every day .. by the lifegivers blessing of food rain",
      "I work at micro center in byo department. First 2 people got in line not yesterday, but the day before yesterday at 4:30pm. I thought it was a joke at first but... they got a card. What can I say.",
      "That prick owes everyone a tenner.",
      "for real... micro center says they have 5 in stock at my local store but there is not why they will be there in the half hour it takes to get there. haven't seen any listings even online retailers.",
      "Ours learned that a tap on the glass means food",
      "Gotta get to Microcenter several hours before open for a chance to get a card on launch day. If you're not already there, you can bet there are at least 20+ people in line",
      "It's the journey, not the destination.  :)",
      "I'd imagine the eternal brrrrrr of the pump made them dead inside long before the tapping did",
      "What's weird is that it doesn't even show as an option on AMD's site, there's no 6900 XT listing.",
      "That‚Äôs because AMD put him in a timeout for successfully making a large group of customers quite irate at the company",
      "I mean when you have an AMD guy promising it wont be a paper launch... then surprise surprise it is one... I think that will piss off people more because they didn't temper expectation they flamed them",
      "holy crap. i got one. 9:13am EST. it was a newegg combo deal with a motherboard. i was like oh well crap. all sold out, for shits, i typed in 6900xt combo in the search and boom. it popped up. i even had to type my credit card info in twice bc i was rushing. lol.\n\nill just have to return the motherboard.",
      "LOUD NOISES"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900"
    ],
    "title": "somehow i managed to buy a rx 6900 xt on release day through the amd store. it showed up today! i didint think they existed until i had it in my hand.",
    "selftext": "",
    "comments": [
      "That's some fancy packaging!\n\nI love how they look like team rocket cards, too! lol.",
      "Super jealous of that packaging. I got the Powercolor 6900 XT, and that just came in a plain cardboard box with a red sleeve on the outside. As barebones as it gets.",
      "Full on gpu porn",
      "It's made of canvas? I've heard there are shortages...",
      "this porb the fanciest packaging ive seen on gpu",
      "lttstore.com",
      "They'll swap it for nylon and hope no one notices, the thieves.",
      "best strip tease ever",
      "I got a reference XFX 6800, same thing. Plain box with a foam insert to hold the card. Nothing else.",
      "I expected him to drop it or get trolled with a brick lol.",
      "Its CGI",
      "Yeah having unboxed the founders rtx cards this gen and amd, amd has a much nicer style and overall unboxing experience",
      "Same story, but a tier down. Showed up 1.5 hours early to Microcenter on 6800XT launch. Line was wrapped around the building with reports they were getting very low stock. No dice. Tried to get one online f5'ing Newegg, BestBuy, and AMD. I never even saw a single listing appear in stock. No dice. Showed up 3.5 hours early this Tuesday. (when MC restocks) No AMD anything on that morning's truck. Still no dice. Walked out with an EVGA 3080 XC3 Ultra.\n\nI know I'm lucky to have any card, let alone one of the few good models that will fit a mITX case, but it still hurts my soul a bit.",
      "clean that room, christ. it‚Äôs so dirty in there",
      "Dramatic unbox rofl",
      "My 1080 fried in early October, I have been on integrated graphics for that long...",
      "I love PowerColors box because it‚Äôs so simple and doesn‚Äôt stand out too much",
      "Since I'm buying the expensive (aka, high end) cards, it means I care about graphics quality, which means I definitely care about RT.",
      "I like simple boxes too, mostly because it's less trash to sort. Also more environmentally friendly. I still want it very clear what the product is though, OEM packaging is too far\n\n\n\nEdit: though",
      "why the mess on the floor my guy"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900"
    ],
    "title": "Finally got a 6900 XT!",
    "selftext": "",
    "comments": [
      "Always wanted to ask: Does the Mac Pro support the 6900XT and can it take full advantage of the card?\n\nEDIT- Oh, and how does it compare to the Vega II Duo Card?",
      "We installed a dozen these at work. I've never been a huge Mac fan, but these desktops are absolutely gorgeous inside. Very few surface mount components on the board, and oh so many pcie slots. Then they topped it off with matte black and no cable mess. If I had a bunch of disposable money, I would have no problem throwing Windows on one of these.\n\n[Inside picture from when I unboxed a new one.](https://i.imgur.com/UvWaDyG.jpg)",
      "The Metal benchmark from [GeekBench](https://browser.geekbench.com/metal-benchmarks) seems to show RDNA 2 being significantly faster than Vega.\n\nOne thing I am interested in though is ray tracing acceleration with Metal. I wonder if Apple utilizes the ray accelerators in RDNA 2 or is it still only available on the A13 and up?",
      "@johnnyphotog I actually like the Lego‚Äôs to hold it up",
      "There is rx 6000 series support since big sur 11.4\nBut some cards are not supported (I think rx 6700)",
      "Dell, Sony and so many other non-Apple laptop vendors got burned with with that generation of mGPUs, so nVidia deserves this blame.",
      "Because not everyone uses a graphics card for gaming.",
      "Depends entirely on workload. RDNA2 is better at rendering tasks, Vega has higher raw bandwidth but in some workloads RDNA2 can make up for it with infinity cache, Vega has better FP64, RDNA2 probably has more refined lower precision types and AI acceleration but that's not my area. The Vega 2 duo is also two Radeon VII dies crammed onto one board so that is heavily in its favor for compute workloads.",
      "Nvidia cost Apple a whole lot of money with MacBook GPU deaths, they‚Äôre not going to get into bed again anytime soon.",
      "I still can't unsee the back of a Dodge ~~Challenger~~  Charger on those cards. Well, in this post the car has flipped over, but that also happens.",
      "Nice! Is that a rack mount version?",
      ">redundant\nYou mean 'obsolete' ?",
      "I do video photography and graphic design on the Mac Side - dual boot into Windows 10 to separate NVMe - Shadow of the tomb raider is like Butter.",
      "Nope, that was entirely on Nvidia. The 8000m generation had high failure rates no matter which laptop vendor. It was a design fault purely with the GPU.",
      "I was thinking a smooth top to finish it off.",
      "Could use a half-height brick.",
      "Some people think stuff beside games don‚Äôt exist, never heard of video editing, photography, 3D modeling which also need a lot of processing power",
      "He needed a couple of Legos to support it, so not well apparently.",
      "Yep they're lovely machines, just a shame the CPUs have been made a bit redundant so quickly.",
      "‚Ä¶ so yea somebody actually does game on Mac"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900"
    ],
    "title": "7900 XTX sometimes has worse performance than 6900 XT in VR gaming in benchmarks",
    "selftext": "",
    "comments": [
      "Probably drivers, same with the 180w power draw at idle. Feels like AMD just rushed the launch.",
      "Amd drivers: Everytime you think you're out, they pull you right back in.",
      "Clearly. Classic cash grab before the holidays. Though, I still bought one.",
      "I‚Äôm gonna bet that it‚Äôs a driver issue which can be fixed. Sucks they don‚Äôt have a solid driver run that Nvidia tends to have on launch day",
      "The issue goes wayyyy back, example from 2002:\n\nhttps://arstechnica.com/civis/threads/my-final-word-on-ati-and-driver-issues.796575/\n\nAnother from 2000 https://www.anandtech.com/show/536:\n\n>While the MAXX performed much more competitively than the Rage 128 at its release, and while the MAXX did come out in a reasonable time frame, **the solution was plagued by the usual ATI driver problems**\n\nAs they say, driver problems were the \"usual\" even in the year 2000, lol.",
      "Shareholders do",
      "Or they didnt want to be called liars for not launching in 2022.",
      "Why is it when I bring up AMD driver issues, everyone loses their minds... but I see AMD driver issues brought up here, and no one bats an eye?\n\nHere's let's try it RQ:\n\n**AMD GPU Driver's are the companies #1 hindrance on Windows PC's.**",
      "At least one of them is definitely incorrect - the OpenVR Benchmark for the 6900XT appears to be another run of the VRMark Blue Room Score... that, or somehow the 1% lows for the 6900XT are higher than the 4090... and man, 6000+ avg fps :D",
      "PC gamers: *have you tried updating the drivers?*\n\nAMD owners: *too scared.*",
      "with elite it's almost certainly drivers. the *6000* series has been broken for months due to driver issues. 7000 series for sure is also impacted.",
      "What's the rush? Can't you just wait 5 years for Fine Wine‚Ñ¢ magic?",
      "From 2001 - Radeon 8500:\n\n\"All of the specs pointed at a higher performing product, but in the end  \n we are limited by what has been ATI's Achilles' heel: drivers.\"\n\nhttps://www.anandtech.com/show/836/16",
      "The 6800/XT had similar VR issues two years ago at launch.  It took awhile for AMD to sort them out.",
      "> AMD just rushed the launch\n\nHave they ever released a truly finished product? The fine wine technology is mostly AMD releasing unfinished products and completing them... over years",
      "This feels like a vega moment - card is power hungry, is underperforming, AMD's bet on new cache technology isn't showing true potential. Then there are drivers... \n\n\n100% rushed a product that isn't ready.",
      "Vega 64 was destroyed by a GTX 1080 Ti for not much more money.\n\nAny 3x 8 pin power AIB 7900 XTX OC'd beats a 4080 OC'd AIB and the 4090 is a thousand dollars more than a 7900 XTX, at least in Europe.\n\nThe drivers definitely need improving but it's hardly a failure like Vega was, as it's competitive in performance which Vega 64 certainly wasn't.",
      "Value in companies is a tad more complex, stock price is also based on a companies 'perception'\n\nA late launch is an indication to the stock market that AMD is not ontop of their R&D and delivery of goods, which can affect their stock price.",
      "What an excellent marketing gimmick when you think about it. \"Ah yes, but by the time your GPU is becoming obsolete... these babies will run smoooooth AF\"",
      "If it's drivers yet again then all I can say is AMD needs to seriously look at the driver team and get some new talent in. It's obvious they got some old timers leading the teams who are not that good."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900"
    ],
    "title": "Traded my RTX 3070 for a 6900 XT. Time Spy up 31%.",
    "selftext": "",
    "comments": [
      "Guy wanted my RTX 3070 + $80 USD for his reference 6900 xt. Looks like it was quite the deal!",
      "Said he did a bunch of emulation and wanted the broadcasting features. He got the reference AMD 6900 xt straight from AMD, so it actually goes for around the same price as the 3070 on the market.",
      "Damn that's an insane deal. Why did he trade a 6900XT for a 3070? I can't see any advantages of doing that at all.",
      "I've seen people offering reference 6900XT for 3080's or 3090's (or I guess 3080ti's now) because they needed the Nvidia ecosystem, but a 3070 is still insane. I don't know of anywhere where a 3070 would cost anywhere near as much as a 6900XT.",
      "Deals like these actually shows how much of a big deal features like the Nvidia Broadcast, DLSS and NVENC are. I still don't get why AMD is not trying to provide us any alternative to such features. Granted, that FSR is kind of an alternative to DLSS, but it still needs more work and proving to do, till it's accepted by the market, and the general populace.\n\nOn the other hand, AMD still has no answer for NVENC. Or Nvidia Broadcast which can be made to run on the GPU itself. Or even RTX voice.",
      "They're actually pretty easy to get off AMDs Canadian drops for $1228 CAD. Basically drop the exact same time every single week and are up for 20-30 minutes. Meanwhile if you check facebook marketplace you'll see the lowest priced RTX 3070s going for $1450 and near impossible to get since best buy canada stopped selling cards online and do in person only.",
      "> I still don't get why AMD is not trying to provide us any alternative to such features.\n\nIt's very simple: they can't at this point in time.",
      "I got my 10900 for $450 CAD brand new, the 5900x goes for $780 CAD. They perform within 5% of each other in games, def not worth it for me.",
      "now you need to trade your 10900 to a 5900 or 5950",
      "That's the beauty of cherry picking results, you can make it tell whatever story you want.",
      "This. People need to take a look at nvidia revenue vs amd and then remember the latter company also makes cpus‚Ä¶It‚Äôs actually unbelievable they compete at all. I fully expected the 6800xt to be no match for the 3080.",
      "ITT: people who think gaming is the only possible workload for a gpu",
      "Link the whole video, not one pic of DLSS testing. SMH...",
      "That is such a BS screenshot. You might as well show 6900xt with performance FSR and 3070 without and get another BS result.",
      "Nvidia just has so many more resources than Radeon does.",
      "Ah yes, the PCIe 4.0 that gives 0,7fps for your GPU is a game changer indeed.",
      "If you do things outside of gaming then CUDA and Optix can be huge upgrades",
      "Bro first off, I didn't ask about your setup. Second, I really don't care about min maxing useless benchmark numbers and spending hundreds and hundreds of dollars for no reason.\n\nIf you like to throw money down the drain then go for it, but for me there's no difference between the two in gaming. Period.",
      "https://static.techspot.com/articles-info/2160/bench/1440p_ACV.png",
      "I agree with you, it was just more a joke than actually an advice. Because you posted it on AMD subreddit lol"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900xt"
    ],
    "title": "After almost 5 years of service, goodbye 1060 and welcome 6900XT!",
    "selftext": "",
    "comments": [
      "Wait people (and not just bots) can actually win the AMD drop? Whole family has been trying for a year no luck! Congrats, nice to see a win for a real person!",
      "6900xts are pretty wildly available now for msrp or near msrp.  Newegg and microcenter have them.  They are third party cards. So a little more expensive than msrp but not bad at all for an aib.",
      "Thank you all, last Radeon gpu I had was a 9550 SE back in 2004! I've had the 6900 for only a couple of days but it really is a beast",
      "You will never see amd msrp again.  Unless you get a reference card.  Microcenter isn‚Äôt inflating the price, aib are.",
      "The packaging for the 6900XT from AMD is almost as nice as the card.",
      "Yep, managed to get it at msrp on the weekly amd drop (I'm in the EU). I tried for a while though but never got lucky and I've always had \"more than an hour\" in the estimated waiting time. But two weeks ago the queueing system put me in the top of the line ü§üü§ü",
      "How much are these cards? Were you able to get it msrp?",
      "Every Thursday, at around 16:00, the AMD store start a gpu selling event (each drop has a different number of cards available, sometimes not so many, other times, like last week, drops are more consistent)\nYou will be placed in a queue, with the position on said queue assigned randomly. If you are lucky enough to be on the \"front positions\" of this virtual queue, you will be able to enter the online shop and buy one gpu.",
      "That's gonna be a huge jump. I went from a 970 to a 3070 ti and the jump in performance was enormous. Games that used to struggle to get 60 fps at 1080p medium settings are now running at 1440p 144+ fps at high settings (plus ray tracing in some games) \nI mean a game like doom eternal struggled a lot with my 970 at 1080p medium and now with dlss I can run the game at max settings, 1440p with ray tracing and get 144+ fps.",
      "Yeah you will...because the vast majority of PC gamers will not pay $1500 for a mid range GPU. I know I sure as hell won't.  If the prices don't come back down to some semblance of normalcy after the chip shortage is over. You're going to see the death of PC gaming. I love gaming on my PC. But there's no way I could ever justify a $1500 or $2000 video card when I can get an XBox Series S for $300.",
      "Am I the only one who thinks the RX 6000 reference cards look orgasmically good?",
      "That's a solid upgrade. You just went from hardly being able to play VR to playing on high settings. \n\nStrongly recommend a VR headset for your next buy if you don't have one. Congrats!",
      "Went from an RX580 8GB Sapphire Nitro+ to a 6800XT reference model.\n\nStill have my rx580...could've sold it for 150-200% the cost I paid for it..but I dunno.. sentimental value.",
      "What's your in game mhz?",
      "I'm in the EU, as well. What is this weekly AMD drop you talk about?",
      "Yep they get regular shipments.  Multiple a week.  The only issue is AIB companies have jacked their prices up so high it‚Äôs insane.  Between the component shortages and tariffs, they really ran with the price increases.  But this affects Nvidia too.",
      "From what I understand they are mostly abandoning the idea of MSRP in the GPU business right now. They've completely surrendered to scalpers and others driving prices up and decided to join them instead. This is partly due to everyone competing for space at TSMC instead of manufacturing their own stuff.",
      "God a 1060, how antiquated, send it to me and I'll 'dispose' it responsibly (cries on 750 Ti).",
      "This right here. MC has reference PowerColor 6900XT, 6800XT, and 6700XT in bulk pack boxes even. The 6900XT is 1399, 6800XT is 1099, and the 6700XT is 799. Better than their non reference where a 6800XT is 1349. However however still a good 300-400 over what AMD direct reference cards are. Tides are changing though. They keep getting more and more cards in quantity and model across the board and they are sitting on the shelves. So either people are giving up and holding out for new model drops, miner demand is easing, overall supply chain logistics are calming down or combination of those. So they certainly aren‚Äôt unattanium anymore. However pricing hasn‚Äôt yet really shifted accordingly.",
      "Got a merc319 6800xt the day XFX released them for MSRP.  Card beats the hell out of the 2080ti it replaced."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6950"
    ],
    "title": "Is my brain working right? Is this what we're thinking in terms of performance for 7900 XTX? Assuming it is 1.5x-1.7x over a 6950 XT.",
    "selftext": "",
    "comments": [
      "No. This is right. This is what AMD claimed.\n\nWe can't tell how true the numbers are until we get to benchmark it ourselves, though. But it looks great.",
      "Use the Techspot / Hub chart instead. TPU tested with a 5800X which did cause some slight CPU bottlenecking at 4K with the 4090.\n\nTechspot had the 4090 scoring 144fps in the 4k 13 game average and the 6900XT scoring 77 fps. The 54% perf/watt claim was for a 7900XTX at 300W (sneaky bastards) so that gets us to 119fps @ 300W. The extra bit of wattage will allow higher clocks but I expect that causes the perf/watt to drop off (otherwise AMD would have just compared stock vs stock like in prior launches) so lets say that extra 18% power only increases performance by 10% (might be generous but I don't know). That gets us to 130 fps in Techspot charts. Their 6950XT scored 85 fps in those charts and 1.54x that is 131fps so it is close IMO.\n\nGiven that that would make the 4090 about 10% faster than the 7900XTX in raster.\n\nThe 4080 16GB in the NV slides was about 20% ahead (using fantastic eyeball maths!) of the 3090Ti. That card scored 91fps in the techspot chart so that puts the 4080 16GB at around 110 fps.\n\nSo stack will probably look as follows for raster\n\n* 4090        144 fps ($1,600)\n* 7900XTX  131 fps ($999)\n* 7900XT    115 fps ($899)\n* 4080 16   110 fps ($1,200)\n* 4080 12   90 fps ($900) - or whatever it renamed to\n\nFor RT it might be more like (I did raster * 0.65 for NV and raster * 0.5 for AMD here)\n\n* 4090       94 fps ($1,600) 66 fps with new scaling\n* 4080 16   72 fps ($1,200) 51 fps with new scaling\n* 7900XTX  65 fps ($999) 41 fps with new scaling\n* 4080 12   59 fps ($899) 41 fps with new scaling\n* 7900XT    55 fps ($899) 37 fps with new scaling\n\nSo if you want RT performance then 4080 16 is not terrible, about 10% or so more performance for 20% more money. If you want raster then 7900XTX or XT are both good. If you want both you spend the $$ and go for a 4090.\n\nEDIT. I went through and checked the RT scaling at 4K in the games techspot tested. 4090 came out at 0.46x and 6950XT came out at 0.31x. Assuming the 4080 and 7900XTX are similar to those numbers I have updated the numbers to reflect that. It pans out that perf/$ is looking to be about the same for RT performance between NV and AMD but AMD will hold the advantage in raster which might offset the features NV have for some people, time will tell.",
      "Remember they did not compare it with the 4090 on purpose very different form last time when they showed 3090 on the charts. The 70% improvement is likely very rare and in a select few games. Expect the averages around 40-60%.",
      "I think AMD has been pretty accurate in their performance claims these recent years. They also don‚Äôt shy away from showing negative results",
      "90% performance at ~85% power and ~$600 cheaper is still quite good tho.",
      "All the marketing bullshit aside its probably 1.5x. Still impressive fps/$.",
      "But the benches they showed were still accurate.\n\nJust like i  this they didnt show a 4090. But based on their claims we know it is right around a 4090 in perfor.ance (assuming it is accurate which is tbd)",
      "7700/7800 seem promising",
      "^By far the most reasonable comment on here, imo.",
      "Yeah, it's better to update the chart for those games they showed.\n\n* Cyberpunk the 6950 XT doesn't do too well [https://tpucdn.com/review/nvidia-geforce-rtx-4090-founders-edition/images/cyberpunk-2077-3840-2160.png](https://tpucdn.com/review/nvidia-geforce-rtx-4090-founders-edition/images/cyberpunk-2077-3840-2160.png)\n   * With 1.7x like they reported, we're looking more like 66.7 vs 71.2 for the 4090\n* Watchdog Legions [https://tpucdn.com/review/nvidia-geforce-rtx-4090-founders-edition/images/watch-dogs-legion-3840-2160.png](https://tpucdn.com/review/nvidia-geforce-rtx-4090-founders-edition/images/watch-dogs-legion-3840-2160.png)\n   * With 1.5x like they reported, we're looking more like 95.85 vs 105.2 for the 4090",
      "Its not right. This benchmark is using a 5800x which bottlenecks the 4090 even at 4k. The other issue is that AMD only showed 6 games and said 'Up to 1.5x and 1.7x the 6950' this is the best case scenario, not the average one.\n\nIf the 7900 XTX was faster than a 4090 or even a bit slower AMD would've given us detailed performance benchmarks, but they completely avoided it, just like they avoided comparing Zen 4 to the 5800x3D.",
      "‚Ç¨uro prices \n\n2400‚Ç¨ for a 4090\n\nGuestimate prices for AMD 1200‚Ç¨ for the xtx and 1100‚Ç¨ for the xt",
      "fucking insane value compared to the overpriced 4090",
      "It wasn't 8k, it was like 7600x 2100, so 8k cut in half is what they showed.",
      "Slow down buddy lol. You've got 14-30 days to reconsider your purchase. I'm aware this is a pro-AMD subreddit, but there's no sense in making split decisions without knowing how these cards compare. With that said, you could use the money saved to invest in a full AMD build that'll surely out-pace a 4090 FE üëç",
      "I hope the 7900XTX humiliates the 4080. On paper the 7900XTX should destroy the 4080 with ease. 12 billion more transistors, 20-30% more bandwidth, 4GB more memory.. Die size of the 4080 is just 380mm2. 7900XT is like 520mm2 with chiplets included.",
      "Yeah, I mean we're talking about a freaking $600 price difference. That's a whole ass 6900xt (current) price difference.\n\n&#x200B;\n\nI wish people had more sense than money.",
      "I mean that's not them being inaccurate, they just didn't make that comparison cause they didn't like it.",
      "Don't forget these are \"up-to\" numbers from AMD - not average like all other benchmarks.  The real average numbers are going to be much less than what the maximum frames are.  Even more so depending on your CPU.",
      "If you care about ray tracing a lot you should keep the 4090 order, a 60% RT gain over the 6950 XT won‚Äôt place the 7900 XTX anywhere near the 4090.\n\nIf RT isn‚Äôt a big concern however, it looks like AMD will be much better value at the top end."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6950xt"
    ],
    "title": "6950XT at $599 on Newegg!",
    "selftext": "",
    "comments": [
      "This is a great deal tbh, totally a card that's worth that.",
      "Do you let the 6600 watch?",
      "Bro I just got a 6900XT for the same price. Buy it!",
      "There goes any reason to buy a 4070 now.  Way to go AMD!\nGreat deal for this card.  Especially with how powerful it is.",
      "Just got this card for $649, replacing my RX 6600, and it _fucks_",
      "good card buy it if you have few gen old card or something",
      "oc the ram and u have a 6950xt",
      ">Could you elaborate?\n\nThe major difference between the 6900 and the 6950 is memory speed. So they're saying if you could overclock the 6900xt's memory to 6950xt speed, then you have a 6950xt. \n\nExcept the 6950xt can also be overclocked, and will go beyond what a 6900xt can do, so it's kind of a silly point.",
      "Didn't wanna make it feel inadequate. It served its purpose back when you couldn't get ahold of cards.",
      "At this price might as well get a new psu if you lack the connectors. It's gonna be worth the upgrade",
      "Keep holding lads, don't give into the temptation!",
      "I'm eying it was an upgrade for my rx480. Just wondering, if my PSU only has 2 8 pin connectors, could I still use it? Like is it safe to leave one out? 2x8pin should give 500 watts, I think",
      "As long as you can buy them for the same price, really no need to get a 4070. I‚Äôm team green because of the features I want, but a 6950XT ar $600 is worth upgrading a PSU as well over the 4070‚Ä¶",
      "what about em?",
      "\"I don't want to play with you anymore\"",
      "Yeah, the \"just oc to get X\" was never a good point for me, it isn't worth the power they're wasting imo comparing to stock",
      "Just use a saw to trim off the excess on a full ATX PSU.",
      "It honestly was a bit emotional. I had decided to build the first computer I'd built in probably 25 years. My ass didn't even know m.2 SSDs were a thing or that new Intel CPUs didn't have actual pins, and it was the only card I could get ahold of. She did her job valiantly.",
      "That's the ugliest GPU I've ever seen",
      "12GB VRAM is all I have to say‚Ä¶ I have a 3070 and it‚Äôs still chugging new games 60+ fps on high at 1440p, but obviously the low amount of VRAM will hurt these cards in the long run. \n\nBy the time I upgrade (about 6-8 months from now), the 4070 will be around $450-500 used here and I still won‚Äôt find a 6950XT at all, only new, so I‚Äôll most probably still buy a 4070, but this shit is getting on my nerves too. I‚Äôm not going to buy a 4080 for like $1200 for adequate amount of VRAM to futureproof my gaming experience."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900"
    ],
    "title": "RX 6900 XT render, I have few more, but can post only one :c",
    "selftext": "",
    "comments": [
      "Having to wait until the 28th is torture.",
      "I'm currently looking for tips on how to get into a coma for a short time.",
      "Don't fall into a coma right now, wait until after Lisa Su finished flexing on Thursday.",
      "GPU's are getting bigger and bigger instead of smaller and smaller üò©",
      "I mean you don't really just \"invent' a new way to disperse heat, not easily anyhow.  Water cooling is a thing, but you just introduce more points of failure into your system. Air works very reliably, and about the only thing that can go wrong is a fan stops spinning (which is easy to diagnose). Even then it's only posing a danger to the GPU really, rather than liquid cooling leaking in your system or something like that.\n\nAnd above all else, it's cheap and easy to manufacture. GPU's are already very expensive, not a whole lot of people will pay some massive premium for some revolutionary cooling solution that lowers their temps by 10C, and shrinks their card a few inches.\n\n&#x200B;\n\nEdit: Dumb typing mistakes and grammar",
      "this reminds me of 2017. Waiting for Vega...\n\ni do hope this will be a decent competitor",
      "Gotta keep ‚Äòem cool!",
      "You're damn right.",
      "[https://media.discordapp.net/attachments/469501377153073153/763104691252887562/rx6900xt\\_top.webp](https://media.discordapp.net/attachments/469501377153073153/763104691252887562/rx6900xt_top.webp)   [https://media.discordapp.net/attachments/469501377153073153/763104752929079348/rx59769.webp](https://media.discordapp.net/attachments/469501377153073153/763104752929079348/rx59769.webp)  \nTwo more here!",
      "Vega turned out great... For us who bought a V56 for less than the price of 5600XT, got Samsung HBM and flashed a Vega 64 firmware, then undervolted it and overclocked the memory. But seriously though launch time Vega was quite a disappointment. Way out of my price range for starters.",
      "Why haven't they invented better cooling technology as of yet? I mean we're in 2020 and we're still relying on air cooling fans to cool GPU's. There's gotta be a revolutionary idea thats better than the current setup",
      "Boy, do I have the product for you!    \n[https://www.youtube.com/watch?v=Dbr7B1OVa0g](https://www.youtube.com/watch?v=Dbr7B1OVa0g)",
      "Just a hint- instead of posting to imgur or discord, you can post to your own account, and then link it.",
      "That looks üî•. Kudos.",
      "The thing with engineering is that there's no need to change something if it:\na) works as intended\nb) is cost efficient\nc) is sufficient for what it needs to do\nThere will be no need to change the cooling method as long as it's the most convenient in all of those categories.",
      "+1 on launch Vega 56 with $100 discount day 1, flashed and all that. Most weren't that lucky though, waiting for partners cards, mining craze, no real use to HBCC and missing features. A mixed bag or even a disappointment for most but a gem for some of us, using Linux even more so.",
      "I'm looking forward for Devil version from PowerColor \\*-\\*",
      "Sapphire Nitro+ for me. Pretty keen to see what drops.",
      "Liquid cooling is still air cooling to be precise. The liquid is only used to move the heat.   \n\n\nThere will never be anything else. Heat is energy you just need to move and dissipate it. There is nothing else you can do.",
      "Damn that is sexy."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900"
    ],
    "title": "The biggest Swiss retailer to receive 35 Radeon RX 6900 XT graphics cards for launch",
    "selftext": "",
    "comments": [
      "Well, who will win?\n\nWill it be:\n\n    timidandshy\n    bot1\n    bot31\n    bot3_8\n    bot98\n    bot69\n    bot11111\n    bot666\n    ...\n\nOr any of the other 6731532 contestants?",
      "wow, remember how we were all expletive on nvidia and amd was bragging about how their stock would be better?",
      "Swear to god, feels like a bunch of edgy teenagers are incharge of radeon's marketing department.",
      "They will only send the cards to physical adresses and they will be signature only. They won't do pickup for the cards as you can buy multiple ones this way with fake accounts.",
      "I don't think you can ever prevent someone from reselling something they legitimately bought. The difference in this situation, is that you will have to jump through a lot of hoops AND get lucky to get your hands on several cards.",
      "The correct answer is sassy middle aged men are in charge of marketing.",
      "I wasn't even born 35 years ago.",
      "The best part is that they decided to make a lottery who can buy a card.",
      "I believe they do this for luxury clothing, bags and shoes too. Feels like the raffle system would do well for GPUs as well. At least real people will have an equal chance as bots lol\n\n&#x200B;\n\nEDIT: Thanks for the inputs, learned a lot from your comments. TIL a lot.",
      "Honestly, that's more than I expected for a country with <9.000.000 citizens.  \nBut if we extrapolate that, it means Germany is going to receive less than 350 units. :(",
      "What's stopping someone from using neighbours or still intending to resell at least one unit?",
      "Well, better odds than F5'ing and dealing with bots taking all the cards.",
      "You are extrapolating wrong. This is not the only retailer but the biggest. \n\nI agree though that it is not much, but more than expected.",
      "The Alienware kind.",
      "Is that strange? For example, my yearly income (after taxes) is ~1700 USD. The world is a bigger and more diverse place than most Americans think.",
      "Can't wait for Frank to show up and say it's not a paper launch because he entered the raffle and got the 35th card.\n\nWhat a joke of a launch.",
      "this is kind of a hilarious, 'enter a raffle for a chance to give us money'",
      "r/usernamechecksout",
      "It's pretty strange on a forum discussing pricey tech.  After food, shelter, clothing and transportation, not a whole lot of that 1700 left to go to tech.",
      "Finally a reasonable people."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900"
    ],
    "title": "AMD Radeon RX 6900 XT, RX 6800 XT and RX 6800 reference desings are being discontinued - VideoCardz.com",
    "selftext": "",
    "comments": [
      "Not surprising. Every AMD reference card disappeared when the AIB partner cards were ready.\n\n\nThe only downsides to this are the fact that the reference cards are thus far the most compact variants of the RX 6800/6900 series cards (they're shorter than all AIB partner cards and the RX 6800 non-XT refrence card is the only two slot card in the RX 6800/6900 series) and the fact that these cards were the safest bet if someone wanted to water cool theirs.",
      "Don‚Äôt blame yourself, sonny boy. You missed out on the reference card F5 bonanza. But I got some great news for ya! We have partner cards with your name on them, starting at just $899 + tax! Now, I know it‚Äôs not the same deal we talked about before, but don‚Äôt worry. Your computer deserves this card and so do you. Who cares about a couple hundred bucks here and there. So just enter your CC info today and you can have your card in time for Easter!",
      "Also makes it a nightmare for watercooling blocks. Means manufacturers like EK have to either not produce a waterblock or produce many different designs for all the different AIBs.",
      "So mrsp is literally a lie. Is there even any msrp 6800XT, if not this card literally isn't even a 650 dollar at all.",
      "So we are then stuck with overpriced AIB cards? Screw this... I was happy for GPUs to finally go down in prices and would have gladly payed 650‚Ç¨, but the AIB price markups are insane...",
      "So, AMD finally makes a competent reference design and they decide to discontinue it less than 2 months after their paper launch?\n\nlmao this is hilarious, I honestly didn't think AMD would manage to mess up their launch any worse than Nvidia did with their, but holy shit this is amazing.\n\n\nSo, what's the official MSRP of these cards now?",
      "so only 20 of each were ever made before discontinued. what is this, streetwear?",
      "Damn straight there mr salesman, i just dropped 1.5k new zealand dollars for a rx 6800 xt red devil card, pleasure doin' business with ya",
      "Are you fucking kidding me??? There was never even a chance to get one!\n\n>end of life\n\n?!?!!!",
      "Nvidia is still making FE months after launch while AMD‚Äôs reference production was basically dropped after 1 week lmao",
      "Oh it's not need. Air coolers are very good these days. Watercooling is purely enthusiast. But it is still a big market.",
      "They're not overpriced, the reference models were underpriced so that AMD could put a graph up to make the pricing look more competitive than it is.\n\nIt's an absolute disgrace, and I can't help but feel they'll do the same thing with the 6600xt and 6500xt, which are the cards I was actually looking forward to.",
      "so mr scott herkelman literally lied about saying the ref design will still be manufacturate until early 2021. it's not like i prefer the ref design or performance over aib models but aren't they suppose to exist to at least available at msrp ? aib models pricing is even worse than nvidia situation rn",
      "AMD is seriously becoming anti-consumer. I had high hopes and support for them through their dark times and now that they're even competitive with intel & Nvidia I thought only good times were to roll. NOPE! It's chuck \"fucking\" testa.",
      "Another downside is they are the only reasonably priced models.",
      "I wonder why you actually need a full GPU water block (except hard overclocking with powermod).\n\nI use CPU AIO on 1080 TI with a bracket. Sure it doesn't cover VRM or VRAM, but it has a 90mm fan that blows directly against main VRM. The I/O side VRM is a concern though, but all reviewers shown it's colder than with high-end air coolers.",
      "And 15 of them were sent to reviewers",
      "MSRP is also being discontinued with them",
      "Prices were a lie then and all reviews need to be redone without the fake US$649 price.",
      "According to what AMD told Hardware unboxed. Can we really take their word for it though?"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900"
    ],
    "title": "Upgraded from a GTX 1080 Ti to an RX 6900 XT. I can now say that I have an entirely Team Red PC. As I'm primarily a Linux user, this makes me super happy.",
    "selftext": "",
    "comments": [
      "‚ÄúOh sick PC. What games you play?‚Äù ‚ÄúWell, do you have a minute to talk about Linux?‚Äù Smooth selling point.",
      "I do play games :).\n\nI dual boot Windows 10 for games. Nvidia has been a rough ride on Linux for a number of years. Their drivers are solid, don't get me wrong, but they like to go against standards, so if Linux software starts trending a new direction, it takes quite a few years for the Nvidia drivers to get support. The AMD and Intel drivers support the bleeding edge of everything.",
      "\"F*** you, nvidia!\" - Linus Torvalds",
      "I wish I could make the switch to Linux.  My primary problem is that (and I've spent a lot of time looking) is that I can't get an equivalent keyboard layout to US International (which I've been using for yeas for easy access to spanish characters).  I tried switching to a few different layouts in Linux but just couldn't get used to them.  \n\n\nReally want someone to copy the US International Microsoft keyboard layout for Linux.  \n\n\nNice computer man.",
      "Dude you can rearrange Buttons however you want I. Linux with a pretty basic script. I put STRG on Capslock for my GF since she had Problems using STRG in DotA2  because of her short fingers.\n\nBy the way fellow Linuxuser who also got his hands on a 6900XT and is super happy!",
      "Basically a complete redesign of how the Linux graphic stack works has been done over the last 6 years or so. The Intel and AMD drivers have been modified to demonstrate the new process. Nvidia drivers work around the whole thing and break most things that depend on it.\n\nPreviously, pretty much anything related to more than text mode was handled through the X server (the GUI, essentially). 3D APIs, drivers, screen management, etc. were all added as plugins to X for the most part. A massive amount of work has been done to untie these from X and make them stand on their own.\n\nThis allows things like graphics outside of the display server, using 3D acceleration on a headless server, passing references to graphics buffers between processes without copying them to the CPU, etc.\n\nIf you've ever heard of Wayland, it uses all of these separated components to provide a modernized display server.\n\nThe Nvidia drivers pretend this all doesn't exist and doesn't support any of it. When Nvidia was asked to support the features that literally every GPU support by Linux except for Nvidia does, they said they didn't like how it was done and supporting it was too much work for them. Then they proposed their own method of doing it and tried to strong arm everyone into using it, a method completely incompatible with everything else.\n\nHence why there's a bit of distaste for them in the Linux community.",
      "In particular, Wayland. Wayland is mostly broken on nvidia, but it's wonderful on AMD and Intel devices.",
      "ctrl in German",
      "oh yeah, AMD is absolutely the way to go. They contribute a ton to linux, and are one of the main reasons you can actually game in linux. Check out the Proton DB for a list, but for the most part 75% of all steam games are playable under linux, sometimes with better performance than in windows!",
      "dafuq is strg?",
      "Sounds like Nvidia",
      "Wayland supports variable refresh just fine, certain compositors don't.\n\nThe desktop world is moving forward with Wayland, and Nvidia is holding things back.",
      "They support it because all those systems running their $10,000 Tesla GPUs run Linux.\n\nBut most of those are crunching numbers with CUDA and not being used for 3D acceleration, so desktop Linux is pretty much an afterthought for them.",
      "More like \"Fuck you, Linux!\" - Nvidia.",
      "I made the same upgrade about two weeks ago. It's been fantastic. And after living on nvidia drivers in Linux for the past few years, I'm glad to see the back of them.",
      "Care to elaborate on those trends you speak of?",
      "Stadia uses a Vega-based AMD GPU which is broadly comparable to the Vega 56.",
      "Man that tubing looks dope af",
      "I know the feeling, as an artist I can never quite leave windows behind thanks to adobe. But I've lost so much data thanks to microsoft's increasingly buggy updates.\n\nThese days, distros like ubuntu and opensuse are really user friendly and easy to install. Your set up is also perfect for doing gpu passthrough where you reserve an entire graphics card for VM use.\n\nIncidentally, I frequent a Linux support discord server, so if you need help installing or maintaining linux, I know a lot of people who can help out.",
      "really?? i'm Brazilian and use US int. as my keyboard layout  \n\n\ni 've used deepin, Debian, pop\\_os, Manjaro and Arch, and could set the layout in every DE\n\njust sometimes i would have problems with the cedilla if my locale was en\\_US (if it was pt\\_BR it would set the cedilla normally) but a line on a config file would solve it"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900"
    ],
    "title": "Since I can't buy one I made a vector drawing of the AMD 6900 XT instead",
    "selftext": "",
    "comments": [
      "damn it, you got me! nice rickroll in the QR code! :p",
      "Was hoping someone would try it! :D",
      "3D print it. Boom, you've got a brand new 6900 XT.",
      "Someone give this man a 6900XT!\n\nGoodjob on the Design OP! *Clap Clap",
      "You wouldn't download a card, would you?",
      "Made using illustrator and the amazing high res PCB shots from Techpowerup [here](https://www.techpowerup.com/review/amd-radeon-rx-6900-xt/5.html).",
      "Legend!",
      "One of the best way to include/hide rickroll.\n\nYou clearly deserve an award !",
      "fyi the traces going to from the PCIe connector aren't just 1 trace but 2 close together in a [differential pair](https://en.wikipedia.org/wiki/Differential_signaling)\n\nsome of the vias also don't look quite right, particularly the ones that don't go to a plane\n\notherwise it looks really nice, well done!",
      "Fuck you, I would If I could!",
      "Thanks for your feedback, great to get some from someone knowledgeable on the subject! I originally spotted the differential pairs in a few places but thought the double line was a bit much and wanted to keep it simple. Evidently that idea went out of the window as the drawing grew arms and legs so I guess there's no reason to have them left out. I don't know enough about the workings of the PCB with the vias to get everything quite right (and my patience was at its limit), but I put the extra traces back in for you [here](https://i.imgur.com/i4lQrEl.png).",
      "Thank you! It took a long time, I'm not quite sure how many hours. Probably about 15-20, but not all of it was that serious. Just some videos on and doodle away. It was never meant to get so detailed but I went a bit too far! I was able to use illustrators symbol feature thankfully to cut down on unique elements and just copy paste a lot of the parts.",
      "Nooo wayyy lmaooo",
      "I didn't know reddit supports vector images.",
      "Haha, I thought the same thing (in T'Challa's voice)",
      "Thanks for the feedback! Sorry, but I don't want to put the raw .svg up publicly as it took a lot of work and people can be a bit annoying stealing stuff. I am more than happy to make anyone a high res render with different backgrounds that they can edit.",
      "Very nicely done!\n\nHow long did this take?",
      "Oh ffs I didn't believe it and it got me",
      "Only $2,999.99 for the printable file.\n\nPaypal or Venmo only",
      "How's [this?](https://i.imgur.com/7wcziIX.png)"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900xt"
    ],
    "title": "My 8yo r9 290x is retiring today, replaced by 6900xt Aorus master. Goodbye old friend !",
    "selftext": "",
    "comments": [
      "R9 290x has done its job proudly",
      "It's been reliable for 10 years (unlike my GFs)",
      "It'll always be in my heart. And proudly displayed on my shelf !",
      "290x was a beast. Enjoy the upgrade",
      "And here I am still rocking my PC I built literally 10 years ago, almost to the day. FX-8350 / HD 7950.\n\n... I need an upgrade.",
      "This is an upgrade",
      "Now it can relax haha. I might let my RX 580 do the same soon.",
      "Also not true at all, my GFs have all been outstanding girls, I'm pretty sure I've always been luckier to have them than them to have me, I just liked the punchline haha",
      "I like to make it worth it haha",
      "290x can still game today.  On par with an rx480. About 1.5x a 1050ti.\n\nYou got amazing value buying that 290x.  \n\nThe 6900x is bonkers fast.  Huge leap.",
      "Damn my man rocking it old-school lmao",
      "+1 for that Vapor-X R9 290x ‚Äî beautiful and an absolute shredder of a card! o7",
      "I'm honestly amazed this hardware survived and stayed usable for as long as it did. Your 290x is only one generation newer than my card!",
      "What cpu you paring it with",
      "Lol",
      "I'm a bit on the fence, really. The 580 is still a good card for me, and the fact that the 6700 xt I've been eyeing is out of stock has been giving me some time to ponder it haha.",
      "It's actually not the vapor X, I modded it with some blue Warhammer paint haha",
      "Even if it was true, I'd understand it pretty well. Girls are VERY complicated.",
      "280 non-x, IIRC.",
      "Ye quantum physics level sht haha"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900xt"
    ],
    "title": "6900XT blew up",
    "selftext": "Big Bang and long hiss while playing Forza. PC still running, immediately jumped up flipped the PSU Switch and ripped out the Power Cord. Had to leave the room and open a window bcs of the horrible smell, later took PC apart, GPU smelled burnt.\n\nAMD Support couldn't help me. Using an insufficient Power Supply (650W) caused the damage. so no Warranty. Minimum Recommendation is 850W.. So i took of the Backplate and made some Pictures for you. SOL?\n\n(Specs: EVGA 650P2, 6900XT Stock no OC, no tuning, 5800X3D Stock, ASUS Dark Hero, G.Skill 16GB D.O.C.P 3200, 512GB Samsung SSD, 3x Noctua 120mm Fan) ...PC is running fine now with a GeForce 7300 SE\n\nhttps://preview.redd.it/fbdu6htus7oc1.jpg?width=2605&format=pjpg&auto=webp&s=2d1a1890b21c73eb135ca61d305172aeccc68229\n\nhttps://preview.redd.it/qedmbgtus7oc1.jpg?width=2979&format=pjpg&auto=webp&s=20a30c490580c6f5eb69748b9e3aaa140f3c8574\n\nhttps://preview.redd.it/pcjrrhtus7oc1.jpg?width=3547&format=pjpg&auto=webp&s=d139633edf2fc6872b99a7417d06f8bb256f7209",
    "comments": [
      ">Using an insufficient Power Supply (650W) caused the damage\n\nsays fuckin who? and furthermore, how the hell would that even work? \n\nthis is such a ubisoft support type of statement.",
      "650 vs 850 watt supply didn't cause this.\n\nCall back, tell them 850 watt was used. That's such a BS excuse of them to use to deny a claim.",
      "I might not be a professional in computer hardware, but I do have some experience building pcs, and even I know insufficient PSUs wouldn't cause shit to explode. The biggest problem it'd cause would be insufficient power (duh), causing the computer to suddenly turn off. You might also have problems like the leds being very dim, or fans running slower and or out of synch with each other.  \n\n\nI actually used to have a 600w PSU that was insufficient for my build and the most problems it'd cause is a few startup problems and dimmer leds. Once I upgraded to a 750w PSU all these problems disappeared. Never once did anything on my computer short out or explode because of the PSU.",
      "The biggest problem, besides instability, would be the PSU itself having an electrical or thermal issue as a result of handling an overspec load. Regardless, I still would expect the GPU itself to blow up, so we're all still in the same boat.",
      "Try contacting EVGA support. As the other reply said, PSU with insufficient power shouldn‚Äôt fry your GPU and the PSU manufacturer is responsible if it‚Äôs PSU problem.",
      "Indeed. As a computer engineer, I'm scratching my head at that one.\n\n\"My PSU's 12v rail couldn't provide enough amperage, which blew up the graphics card (???)\"\n\nThat is most definitely *not* what happened.",
      "All kinds of wild things can happen when a psu fails. Running psus to failure is a genuinely dangerous, bad idea.\n\nI actually had the same initial reaction as this thread, that the psu didn‚Äôt cause some random gpu failure, but when you point out that the gpu failed at the same time‚Ä¶ they‚Äôre actually right that this is a warranty issue for the psu vendor, they can‚Äôt make a gpu not blow up when you put 120v AC down a 12v DC cable‚Ä¶\n\n(and I‚Äôm guessing that the psu is probably old and out of warranty of course‚Ä¶ too much load on an old/crappy psu and when it goes bang it takes something else with it is a tale as old as time. It used to be *much* more common in the era when you got some junky ‚Äù500w‚Äù thing with your case.)",
      "Contact him, he may help you\n\n[https://www.youtube.com/@northwestrepair](https://www.youtube.com/@northwestrepair)",
      "If the GPU was \"starved\" of  the proper power, I would be surprised if the PSU didn't scramble and shut down.  I can't see a PSU continuing to run if it couldn't supply the needed power to the board, CPU, drives and GPU.  The CPU/GPU should run 550 watts, tops.  Not sure what else is drawing power, but a physical HDD runs about 5-10 watts/each drive.  Not sure about memory.\n\nI think AMD or EVGA is at fault for this one.",
      "It was prolly trying to pull more juice than what the PSU can handle, this happened to me back in 2013 running dual 5870‚Äôs in CF with a 3770K overclocked to the moon, all of this running on a CX550 until it blew up..",
      "Get your cousin Jim Bob to call and do a warranty claim. But instead say you have a 850 PSU.",
      "This man knows his stuff. See what he says but don‚Äôt expect miracles",
      "Hello, someone with engineering experience here -\n\nIt's not bullshit. The failure mode is pretty simple:\n\nPower = Voltage * Current.\n\nPower supplies provide a fixed voltage (12v). Card draws whatever current it needs to meet power demand.\n\nCard demand goes up. Card tries to draw more power than psu can handle. Psu begins to sag, voltage drops below 12v.\n\nCard has the same power demand, but is now being fed lower voltage. Power = Voltage * Current, if power is same and voltage goes down, current has to go up.\n\nCard draws more current to try to meet power demand. Psu sags more, voltage goes down, card getting less power per unit of current and thus increases current draw to make up.\n\nVicious cycle.\n\nUsually a psu's over-current protection will trip out and your rig will be safe.\n\n1. Not all psu's have good OCP.\n2. What happens if power demand is riight below trip point? Psu keeps running, but card is being undervolted and continues to draw higher than normal current.\n\nSo the card keeps running. But then, current through some component causes it to heat up too much. Component begins to fail, usually by becoming a short. Draws looots more current now and milliseconds later pops.\n\nEt viola, dead computer smell.",
      "I'm sorry for your experience. But that is definitely not what happened here. \n\nYour PSU and cabling might've overheated because of the high current that it couldn't handle, and that heat might've transferred to your GPU and done it in as well.\n\nWhat happened with OP though was the opposite. If anything it sounds like a short or overvoltage on the GPU itself, maybe it blew a capacitor as a result. You wouldn't see the type of failure OP saw from an overheat of the PSU due to a current level above its rating.",
      "wtf... whoever came up with the idea that a lower wattage psu caused your 6900 XT to explode should lose their job, that makes zero fucking sense, also amd officially recommends 750w and even then 650w is more than enough",
      "TL:DR: Most likely the GPU would work after you use soldering iron to remove the burnt component and cleaned with PCB cleaner. If they refused to pay for a warranty, i think it is worth a short in repairing this GPU.\n\nFrom the picture, it seems like a ceramic capacitor has exploded. My guess would be that the ceramic capacitor itself has some QC issue and it starts to degrade faster than normal and a leakage current started to flow through them. When the leakage current is high enough, it would burn. Since the package size is small (either a 0805 or 0603) ,even when it is \"burning\" there is still a relative small amount of current flowing through and i won't be worrying that the extra current would damage the large power plane inside the PCB. \n\n(I don't have the power ratings for ceramic capacitors, but usually resistors in that package could only handle 250mW before the burn, which is just a small fraction of power compared to 300W+ that the GPU would suck in)\n\nSince you said the GPU is still running when the component is burning. I think all the power rails would be working.\n\nIf you have a multimeter, you could use connectivity check function to check if there is a short circuit between the black capacitor with the lable C604 across it (should be the main power rail to GPU) and between the small across the brown capacitor C630 that is right beside the burnt component. If the power rail is not short to GND. I think it is very likely that the GPU could boot up again after the burnt component is removed with soldering iron and is properly cleaned. That ceramic capacitor should be used for filtering the 12V voltage right before the input of the buck converter.  Usually there are a surplus of them soldered on the board and missing a couple of them should be fine as long as the power rails are not short circuit to each other and the GPU + VRAM are still in working condition.\n\nAnother tip when asking for warranty is always play dumb. Always say that you used the recommended part and you have never touch any setting of the GPU and it just blow up on its own. The more specific info you provide, the more likely they would find a bullshit reason to refuse the warranty claim",
      "It‚Äôs an easy way out, if op didn‚Äôt say what was their psu, it would fine, any company will use anything in their favour  to deny warranty, happened to me with my car",
      "It took out one of the 5870‚Äôs as well, forgot to add that it also melted one of the power cables. Nothing major but the case was smoking for a good 10min. I posted this over in the AMD forums about a decade ago. If I find the post I‚Äôll link so you can see the damage.",
      "Switch mode power supply, MOSFETs could have failed to open for a brief period of time causing more than 12v to be fed into the gpu...\n\nThough I would have expected EVGA to have overcurrent protection to prevent this from happening.",
      "I agree with your general sentiment here, but from my reading of OP's post, the PSU hasn't failed. Moreover, his PSU looks pretty decent (650W 80+ Platinum). He said he swapped in a low-end GPU for the time being and the PC is working again. \n\nConsequently, I'd pull the blame away from the PSU and put it towards the build quality of the GPU. OP was running the GPU stock as well, so its electrical load under gaming (in combination with the efficient 5800X3D) should've been manageable by their high-quality PSU. \n\nWhat you said does make sense though, so I'm not discounting that. I just don't think that's the case here."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900"
    ],
    "title": "My black beauty. 5900x + XFX 6900 XT merc",
    "selftext": "",
    "comments": [
      "Your GPU looks to be sagging.",
      "Love a pure amd build.",
      "Of course there may be a small comeback. But remember that 5000 series was a \"reply\" to their previous gen. Intel releases mid year and then amd does their next year and destroy it again. Mind you from leaks we are seeing small gains only by Intel. 5-8% single.core and way behind in multi. Plus Intel is maxing out at 8 core as well.",
      "XFX really makes the best looking coolers imo",
      "Actually Intel seems to be ahead in SC only because of clocks. It's still behind in IPC and that shows in multi where clocks get limited by their ridiculous TDP.\n\nAnd don't get me wrong, Rocket Lake doesn't look like a bad arch, but they are way past the 14nm++++++ sweet spot",
      "NH-D15s is good too.",
      "32GB Crucial Ballistix 3200 CL16",
      "I want to go full amd so badly (3700x -> 5900x, 2070s -> 6800xt). But somewhere deep inside I‚Äôm being told that intel might make a comeback soon",
      "Especially the merc looks so nice. And oh boy is it a huge and heavy card",
      "Nice, I like the no RGB approach.",
      "I'm running full amd and it's killer so far. 3600 and a 6800xt.",
      "I have mounted the front fan a slightly higher on the cooler. You can see it in the picture if you know it. The front fan is mounted higher than the middle one. \nBut I am not sure if you could move it even more to fit the tridentz. Technical it should be possible, if you have a big enough case so that the fan is not in the way of the side panel. I have the Meshify 2 and raised the fan just slightly above the ram and I think between the fan and the side panel is very little space left. \n\nBut you could also use the D15S which comes with only the middle fan. It's as far as I know just a little bit worse than with two fans.",
      "What RAM are you running under the D15?",
      "Where is the ram?",
      "FIX DAT SAGG.. looks good tho",
      "It is hiding under the chonky Noctua cooler.",
      "Nice, I'm a big fan of plain cases with no rgb.",
      "So on Amazon it says that the D15, ‚ÄúIn dual-fan mode, the NH-D15 should be used with standard-height RAM (up to 32mm).‚Äù\n\nBut on the crucial website it says that the Ballistix is ‚ÄúCrucial's Ballistix memory modules are really space-friendly. The heat spreader doesn't add a lot of height to the memory module. Checking in with a height of 39.17mm (1.54 inches), we expect the Ballistix memory modules to fit under large CPU air coolers without hiccups.‚Äù\n\nHow did you accommodate that 7mm difference? I know it‚Äôs a tiny difference, but just curious. I have the G.Skill TridentZ and its 44mm tall and that‚Äôs the reason I haven‚Äôt bought a D15 yet. Buying just the D15 is fine, but buying the D15 and replacement RAM ain‚Äôt pocket friendly.\n\nEdit: meant to clarify that I have the G.SKILL TridentZ RGB",
      "nice build i also got fractal case but a smaller one, got 5950x and gtx970 haha did preorder sapphire 6900xt but ofc no deliverydate, 32gb 3600 ripjaw. also prefer non rgb stuff. hope the GPU will fit max gpu length is 310cm with fans which the sapphire custom card should have. [https://i.imgur.com/8nnMzW0.jpg](https://i.imgur.com/8nnMzW0.jpg)",
      "Maybe a custom bra can fix that?"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900xt"
    ],
    "title": "5900x and 6900xt",
    "selftext": "",
    "comments": [
      "The Monsta push-pull on the bottom looks massive.\n\nHow are your fan speeds/noise and gpu temps? And what fans do you use?",
      "If I ever get divorced this will be my mid life crisis.",
      "Not OP, but the fans are Corsair ML120 PRO LED White",
      "Shows just how much of an air cooled card is there for the air cooling.",
      "Honestly, they're not very good. Corsair's ML fans consistently perform worst or among the worst in any fan comparison between them andd other fans like Noctua A, Arctic P, Noiseblocker etc.\n\nCorsair's fan blade design just simply is quite poor, they have to spin much faster to produce decent airflow, which makes them noisy. I have a bunch of those ML120 fans gathering dust in a box because they were way too noisy while producing the same amount of airflow as my Noctua P and Silverstone fans.",
      "This lian li case has the psu behind the motherboard tray iirc",
      "Is that a massive radiator on the bottom!? If so, where is your psu?",
      "watercooled",
      "There's like $300 worth of fans alone in that case.\n\nThose are decent fans though.",
      "This is the way.",
      "Unless you have a water cooling loop don't \n\nThey're thick for a reason",
      "Corsairs are some of the worst rated fans in both performance and noise, yet they're the most expensive.\n\nLook up some YouTube reviews.... I have no idea why they're so popular",
      "Yeah but the RGB in that colour helps the cooling. It's been proven lol /s",
      "I feel like HR Giger would approve",
      "This is sick but I don't agree with the fan choice... I tried the Corsair ML120 Pro and thought they were unbearably noisy... unless you are just running them at low RPM.",
      "Literally got divorced recently spent 10k on a pc that is so stupidly overkill, can confirm it was a great idea.",
      "I wish more people knew about **Open RGB**, it controls pretty much all your RGB in one neat program, no need for multiple programs that may conflict or not even work properly in many cases",
      "Convection is not really a thing that helps in that scenario, because the fans push so much air through your pc case that the air get swapped every few seconds, so convection does not even has the time or the height to work",
      "Gamers Nexus did a video on this. Convection doesn't help.",
      "He probably keep those fans under 1000 rpms under load, with that much radiator volume."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900xt"
    ],
    "title": "First build! 6900xt Red Devil and Ryzen 7 5800x",
    "selftext": "",
    "comments": [
      "Mobo: B550 Tomahawk\nRam: 4x8 32GB Trident Z Royal Silver 3200Mhz Cl14\nCPU: Ryzen 7 5800x\nAIO: Nzxt x73 \nGPU: 6900xt Red Devil\nStorage: 1tb Samsung 970 evo plus/2tb hdd\nPsu: 850w Seasonic and Cablemod meshpro replacements\nCase: Meshify 2, replaced all fans with Nzxt Aer 2",
      "This shit's dope. \n\nCould you post the full specs?",
      "Ahaha yeah been getting that a lot, this beast runs cool enough though.",
      "[This](https://www.reddit.com/r/buildapc/comments/cicmc1/tutorialpc_stat_screen_and_how_to_make_them/?utm_source=share&utm_medium=ios_app&utm_name=iossmf) post should explain everything",
      "I have almost the same specs as you. Started to have some serious issues while overclocking, eventually computer started shutting down. Replaced the power supply with a 1000w platinum and it's running great again. I started with a Corsair 850 gold\n\nOn a related side note I'm super jealous that you have three power rails. The XFX Merc card only has two for some unfathomable reason. Built to overclock but doesn't have enough power delivery... Smh",
      "Looks like all your budget went to the pc...",
      "Samsung Odyssey G7",
      "Why everybody's first build is stronger and looks better than my 56th build? And I'm 32...  \n\n\nJust a joke, but really...",
      "This isn't RGB, it's the glowing red of overheated heatsinks /s",
      "Can you see enough light from the front fans inside the case?",
      "I had a build like that. FX-8320 at 5.0GHz. While running OCCT small data set,  it was pulling 500 Watts at the wall (around 400 at the CPU after PSU and VRM losses). Even a 360mm AIO could barely keep up. Add in 2x 290s and I had to leave the door open while gaming.",
      "Where else should it go? ü§™",
      "as long as you choose seasonic everything will be fine!",
      "Wow i never thought that monitor had black levels that bad, well cool setup then",
      "Thats so dope. Whats the little display setup?",
      "The monitor",
      "Damn - now you got me kinda worried with my 750w and 6800xt + 5800x!",
      ">Damn - now you got me kinda worried with my 750w and 6800xt + 5800x!\n\nyou'll be fine. I have the same setup, with a 850W but I run a helluva HDD, and it's overkill anyway.",
      "Thanks! The monitor's absolutely amazing I'm actually thinking of getting another one for a dual monitor setup!",
      "I have overclocked 6900xt merc black + 3900x with Seasonic 750w Gold, been running like this since february no problems. I think they add extra W to recommended because there are people that use cheap, low quality PSU."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6950",
      "6900"
    ],
    "title": "RX 6950 XT vs RX 6900 XT - as per AMD's site",
    "selftext": "",
    "comments": [
      "So this is basically like an \"overclock\" of the original ones? (Asking for a friend since he is deciding between the rx 6750 xt and rtx 3070ti, around 150‚Ç¨ difference in price)",
      "**FPS averaged:** 139.75 vs 134.125\n\n4.19% faster for $100 more while using 20% more power... AMD stole Nvidia's playbook.",
      "That black fan shroud though",
      "At MSRP there is not a lot of reason to look at the 6750xt vs the 6700xt.  If you can get the 6700xt for ~70‚Ç¨ less than the 6750xt I would be more inclined to go that route as opposed to the 6750xt (MSRP prices compared).  Now, if the 6700XT is around the same price as the 6750XT that changes things.  Performance difference is minimal (2-5% from what I have seen).\n\nAs far as either vs the 3070Ti, that is a personal value proposition.  The 3070Ti has much better performance in many games and doesn't really ever lose to the 6700/6750XT.  It also has better ray tracing and includes DLSS.  Is that worth the price difference?  Very personal question.  I recently went back and forth on the same thing, and decided to go ahead and get a 6700 XT from AMD Direct.  But that price difference was more like $200-300, which to me was not worth it.  \n\nCan your friend wait a few more months?  Prices are sure to go down more over time and new cards are coming.",
      "> This. Should have done a refresh like 2080->2080S than this garbage\n\nI hope marketing students use AMD and Nvidia as case studies, because this is a perfect illustration of how mindshare warps the reception of a product.\n\nThe RTX 2080 --> 2080 Super was a significant price increase. You got 10% more performance for 20% more money. The 2080 Ti should've been $700, the 2080 should've been $500, and the 2070 should've been $400. Instead, you people lapped up those GPUs like they were caviar. The 2080 Ti broke sales records for a $1200 GPU.\n\n* The 3090 Ti is 33% more money for 7% more performance than the 3090.\n* The 6950 XT is 10% more money for 7% more performance than the 6900 XT.\n\nThe same geniuses who gave the 3090 Ti 8/10 for \"being the fastest\" are now criticising the 6950 XT, despite it being the fastest at 1080p and (marginally) 1440p, and despite it being **significantly** better value per frame than the 3090 Ti. You get 3090 Ti performance for almost half the price, but this is apparently not enough.\n\nThe 3090 Ti ($2000) and 6950 XT ($1100) are neck-and-neck, yet Nvidia get praised while AMD get slated. That's the power of mindshare. It's every corporation's dream to charge double what the competition charge for the same performance, while getting praised.",
      "Wow 5 fps more. Let me just run to spend my money asap",
      "My hope is that these are binned slightly better. But in reality they are probably just a clock and power adjustment with a memory module upgrade.",
      "At least theyre honest",
      "Strange, I saw Gamer‚Äôs Nexus showing about a 10% improvement.  Granted I have no intention of buying one but probably within margin of error",
      "To be fair both cards are AMD",
      "Looks like an nvidia move, cringe",
      "the only difference",
      "In-stock right now still. If it sells out it wont be for long. The 6900 XT, their previous halo/flagship has been sitting on shelves for months at its MSRP. People dont see the value in these. The 3090 has workstation value, and the 6800 xt and 3080 has gaming value. The price per frame are too high for these for gamers",
      "der8auer tested exactly that in his review. Despite AMD locking the 6900XT VRAM to max. 2150mhz he managed to beat the 6950XT at stock.",
      "As if we needed further confirmation:  \n**Corporations are not your friends.**",
      "Welcome to the non-sense of a broken market, I've been watching 3070s teeters around 3070ti pricing, same with 3060 to 3060ti. No real reason, other than market abuse, especially if the 3070/3060 aren't LHRs.\n\nAlso would say the 3070ti is definitely worth only 50 or so more, as long as that's all you're paying extra.",
      ">The RTX 2080 --> 2080 Super was a significant price increase. You got 10% more performance for 20% more money.\n\nCan you explain this? The 2080 Super was actually $100 cheaper than the original 2080 FE so I don't know what you're referring to.\n\nIt seems like you're upset that people aren't praising AMD for raising prices for the same performance tier, but the same reviewers that are criticizing AMD the 6x50 series called out Nvidia for the 3090 Ti and called it a \"dumb\" and \"tone-deaf\" release. Yes, Nvidia does have more mindshare. It's not a new phenomenon. That's why it's stupid for AMD to release these at higher prices.",
      "Admittedly for the power I pulled reviewer numbers",
      "And these are AMD's cherry picked titles too.",
      "I'd trade a 6950 XT for a 6900 XT and 100 dollars easily lol. Negligible performance increase for \"just\" 100 dollars more."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6950"
    ],
    "title": "Family fight: AMD Radeon RX 7900 XT is up to 7% faster than RX 6950 XT but costs 28% more - VideoCardz.com",
    "selftext": "",
    "comments": [
      "Nice of AMD to literally say to not buy RX 7000 series. I thought those were some third party charts, but no, it's their own charts showcasing how shit value RX 7000 are. Weird marketing strat.",
      "That's why i am keeping my 6900xt for now",
      "You totally should. Upgrading every gen is never a good idea, unless you are moving from something like low-end to high-end. If you already have a last-gen high-end card, there is no point in upgrading to a high-end one this gen.",
      "It‚Äôs wild to me that people upgrade every year. I just built my first pc and I‚Äôm not touching it for at least 3 years",
      "Up to 7% is a lie. Takes a few second to find results that show far more than that.\n\nAnd costing 28% more well good luck finding that because i can't find a 6950xt that much cheaper than a 7900xt in my country.",
      "The only AMD marketing strat this gen had been buy AMD because AMD good Nvidia bad. And people listened because even thought a 7900xt doesn't anything for its price if you post that you bought one you get a slap in the back, if you buy a 4070ti all reditors go out of their dungeon to tell you how bad the 4070ti is.",
      "The problem is that (at least from what I can find) the 6950xt has been better priced. I missed out when 6800xt's were $550-650, so now a $700-750 6950xt is my best bet once I do have the money.",
      "Very few people do that tho. 3-5 years is typical.",
      "AMD says you're part of the ultra enthusiast if you buy the 7900 xt  \n[https://twitter.com/amdradeon/status/1618341553587494941/photo/1](https://twitter.com/amdradeon/status/1618341553587494941/photo/1)  \n\n\nSo you're actually paying premium to be part of their exclusive group.",
      "The strangeest part is that those are AMD's own benchmark. Showcasing worst gains than most third party reviewers.\n\nWell it's not strange because they picked up e-sport games where they are probably CPU limited, but that's a weird way to market your products.",
      "It's chip binning, nothing to do with the overheating issues.\n\nAll chip manufacturers do this. Intel doesn't actually produce loads of different CPUs. They make one product, the best performing get core i9 designation, next batch below are i7, then i5, then i3.  It's all about avoiding waste and minimizing production cost.",
      "The biggest con AMD & Nvidia has going is convincing consumers that the latest generation is worth what they're asking..",
      "The strategy of the 7900XT is to sell 7900XTX chips that have a manufacturing defect. That's the whole point of the chiplet technology.\n\nIt's like when AMD put out the 3300X: they just so happened to have a bunch of chiplets that had 4 good cores, so they slapped them onto a CPU and sold them until they ran out of stock. Or like the 4500, which is likely just a batch of leftover Zen 2 chiplets that had cache defects.\n\nThe 7900XT is both an attempt to recoup money on bad stock, as well as acting serving as the [\"decoy\"](https://www.businessinsider.com/how-medium-size-tricks-you-2014-5) to get you to either help AMD move more 7900XTX's (\"it's only $100-200 more!\") or clear old stock (\"the 6950XT is $200-300 less!\").",
      "https://cdn.videocardz.com/1/2023/01/RX7900-RX6000-FPS-PER-DOLLAR.png\n\nThat's just hilarious that AMD would use frame per USD like that. I mean I guess I respect the honesty?",
      ">Very few people do that tho. 3-5 years is typical.\n\ni did it every year simply because i could sell my old xx80 or similiar card and then buy the new xx80 for like 20-80‚Ç¨ on top \n\n&#x200B;\n\nbut yeah... a xx80 or similiar costs this gen from both companys WAY MORE.",
      "MSI 6800 XT occasionally comes around on NewEgg for around 540. Just got one two days ago.",
      "On here it seems like everyone has a 4090 but in reality they are the enthusiasts, and they're selling out everywhere because they barely make any. \n\nIt's good buzz and gets the \"Nvidia has the fastest cards\" mindset into the public discourse, even if it's not true for the price. It's the reason people buy a 3050 instead of the same price or cheaper 6600xt",
      "That 7% figure comes straight from AMD's own website, in case you didn't read the article. As does the 28% price gap.  \n\n\nIf you have results that show figures substantially better than 7%, I am sure AMD would be dying to see them.",
      "how is evaluating 90 class cards on 1080p fps/$ honest?   should have been 4k. Comparing 1080p is misleading, it's the same as using i9 and ryzen 9 cpus and run 4k performance, suddenly they are all the same.",
      "They are trying to sell all the RDNA2 stock I think."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900xt"
    ],
    "title": "My rx 6900xt finally arrived for my 5800x build, very satisfied with it and ready for legit any game for a couple of years.",
    "selftext": "",
    "comments": [
      "Clean built man!",
      "MAN... I am still struggling to see if i should get this GPU or not. It is the same price as my RTX 3070 in the scalpers market. I can sell my RTX 3070 and get the 6900XT for the same price. Maybe ending up spending $100buks more being my worst case. But..... still on the fence.",
      "One one hand, the 3070 has DLSS and that will make a big difference in games that use it. \n\nOn the other hand, the 6900xt is on average 35%ish faster.\n\nHere is some random yt video on it\n\nhttps://www.youtube.com/watch?v=xejgJADgf4o",
      "Are u serious? Im an nvidia fan but there's no reason to pick a 3070 over the 6900xt.",
      "Love my 6900 XT. Course I don't care about RTX or ray tracing in general, yet (for ray tracing).",
      "might upgrade when they release the ryzen 9 6900x\njust to have the NICE pc",
      "Thanks !",
      "The 6900xt is a fantastic card with great raster performance, no need to hype it up with objectively false claims about rt performance. It is not comparable to the 3080 or even the 3070.\n\nMake it clear what op will gain and lose, rt is definitely a loss for now.",
      "Consoles will put a limit on how demanding games will be. It‚Äòs all about them.",
      "I had the identical build, but I just upgraded to a 5900x. It's a really awesome build for 1440 gaming",
      "if rtx is not your most important concern, i'd say go for it\nstill good in rtx tho, sometimes beats rtx 3080 and most of the time the 3070",
      "The 35% more FPS will make DLSS irrelevant \n\nPlus, FSR is a thing",
      "Seconded. Sucks that false information gets upvoted \"because AMD good\". RDNA2 is a win, no doubt. But AMD is clearly behind the competition in terms of feature sets and ray tracing. I personally don't care about RT yet, but some people do. I have high hopes for FSR though.\n\nAlso, complete sidenote.... I'm more excited about the Lumens tech in UE5 than any current RT methods from AMD or NV.",
      "That video is literally bullshit lol",
      "The thumbnail literally shows red dead redemption with RTX on. Rtx for Red dead was announced a few weeks ago, while this video was uploaded 7 months ago in December of last year. Some other games in this video also didn‚Äôt have ray tracing when this video was uploaded. Such as doom eternal which it shows in the beginning of the video (again this video was uploaded LAST YEAR, doom eternal didn‚Äôt get raytracing until recently) So all those parts are just fake. Not to mention the uploader intentionally hid the like/dislike bar and literally all the top comments on the video is calling out all the fake benchmarks. Honestly no idea why that video is getting upvoted.",
      "The value of the 3070 right now is = to the 6900xt solely because or their mining performance being equal (but the 3070 is more efficient at it, so hence also valued more by miners). Imo when mining does die down, the card that will see its value decrease is the 3070 not the 6900xt",
      "got the card brand new on facebook marketplace for 50 canadian dollar over msrp",
      "That Fidelity Super Resolution could work for you. Its apparently super easy to implement so it should be in many games pipelines right now",
      "Half those games don't support ray tracing, yet he is claiming they do.\n\nAlso compare the results with other people and you will see they do not line up.",
      "Well there is, their feature set. As a current 3080 owner, yes I'd rather the 6900xt, but it won't perform as well with RT or use DLSS."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6950"
    ],
    "title": "Switched my RTX 3070 for a 6950 xt! With my 5900x processor, I'm full team red now",
    "selftext": "",
    "comments": [
      "NGL I've been tempted to make that same jump. But I am gonna hold out for the 7900xtx.",
      "Remember to enable AMD SAM in the drivers!!",
      "Thats a heck of a build my guy! What are your temps like with that cooler, been eyeing it for my 5900x as well",
      "Thanks for letting me know! I just enabled it in BIOS!",
      "I've been playing apex legends for about two hours now. My cpu is at 56.4 degrees Celsius with the die at 50.7",
      "That was my plan originally, but with the reference 7900 xtx at 1000 USD plus tax and everyone likely fighting over getting one on release, I thought it'd be better to just get the upgrade available now. For 770 USD, I thought it was a great deal on the 6950 xt. I did want to use it for gaming on ultra settings at 1440p now, since the 3070 just doesn't have the VRAM to perform at that resolution with those settings.",
      "I live in Peru in South America. I got the 3070 at msrp on release from the US for 550 dollars and I was able to sell it here in Per√∫ used for 400. I got the 6950 from Amazon for like 770 on black friday and a family member brought it for me here. So all in all, I've been really lucky with prices",
      "Same my man",
      "Dang that's some solid temps! Definitely will consider that cooler!",
      "Before/after benchmarks?",
      "Well, I play at 1440p. Before, with the 3070, I'd get between 110-130 fps on apex legends with everything on the highest settings and 110 fov. With thr 6950, it holds at 170 and dips to 169 periodically. 170 is my monitors refresh rate.\n\nThe main reason I was getting annoyed with the 3070 is because of the ram. With igb ram, I couldn't put games like resident evil village or steelrising in max settings.",
      "I'm hoping these cards drop in price with the 7900 series drop.",
      "Compatibility Support Module (CSM) it's kid glove mode, to ensure oddball hardware posts and at least sorta works.  When it's enabled many motherboard functions are substandard in their speed, bandwidth and overall performance.  It's a quick way to lose all your gains by leaving it on (or turning it on by accident)",
      "Congrats!\n\n\nJust want to say, there is no team \"red\" or \"blue\" or \"green\". These are not sports teams, or some charitable organizations. There's team consumer and team publicly traded for profit companies, when it comes to products. Consumers goal should always be to get the best value for the money. Companies goal is to get the best profit possible. Sometimes these 2 opposing factors align, sometimes especially nowdays not. Consumers should not be blinded by colors, marketing, fanboyism etc... cause if they do, they will get shafted.",
      "How much were you able to sell your 3070?",
      "If you're in Europe, it probably won't be happening\nAtleast not much. The 1000$ card is going to be around 1250‚Ç¨ here in the EU\n\nThe 1200$ 4080 is straight up 1550‚Ç¨ here\n\nOfc basically noone buys this shit\n\nThe 4090 is also straight 2K‚Ç¨",
      "The thing is that in my country, PC parts are super marked up. And, if I import it from the US, I have to pay 25% import taxes plus risk it getting damaged while it's shipped. So, I chose the 6950 xt in this case because it was a sure thing and it lined up with a relative being able to bring it to me.",
      "Ooh i understand, yes because of the resolution, same happens to me with rdr2 at max setting, plus i play on a Ultra wide screen 3440x1440 wich gives me even lower fps, I‚Äôm honestly waiting for the 79 series",
      "SAM is ReBar",
      "That Banshee though.\n\nBadass build!"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900xt"
    ],
    "title": "Resolved Coil Whine on 6900XT by Switching From EVGA to Corsair PSU",
    "selftext": "",
    "comments": [
      "Some people in this thread seem to have misinterpreted your post as changing the PSU solved the GPU's coil whine. Edit: Your title is bad.\n\n**The coil whine was in the EVGA PSUs**.",
      "Wow that is serious coil whine, I have a 6900 xt that has slight whine on higher FPS but not quite as extensive as that.",
      "This is probably result of using this particular card type with this particular PSU. The strongest coil whine will appear if card draws power at a pattern that happens to be a resonance frequency of the PSU coils. Probably both EVGA models were equipped with the exact same coil, resulting in whine.",
      "Update 1/19/21:\n\nEVGA contacted me regarding whether or not they could help with RMA. They said that since the 750W G2 Supernova Gold was purchased as an \"EVGA Certified\" product EVGA reduced the warranty from 10 years to 1 year which means that even though the product was like new directly from EVGA, the warranty expired a couple years ago. They count the day it became \"EVGA Certified\" as the first day of warranty and not the first day the consumer purchased the product.\n\nBackstory:\n\nI upgraded my GTX 1060 6GB to a RX 6900XT. For first time ever in rig I heard awful coil whine that could be heard in the room next door. I'm an RN and used my stethoscope from work to assess PC before I blamed the GPU entirely. Turned out almost all of the noise was originating from my EVGA Supernova 750W G2 Gold PSU.\n\nMy first thought was maybe the PSU was always bad but I never realized it because my 1060 never put that much load on it for me to notice. I went to Best Buy and bought a new EVGA 700W Bronze PSU to test and the noise was almost identical.\n\nI decided to try one more PSU but from whatever other brand Best Buy had. I exchanged the EVGA for a Corsair RM750W Gold and the PSU buzzing went away entirely. There's still a tiny bit from the GPU only, but it's enjoyable once again to play games/music at night in quiet room while the kids are sleeping.\n\nI hope this might help someone exploring the same problem.",
      "Most brands have high and low quality units. \nIn general, if you are seeing a particular wattage for much less than others (wow, saving ten bucks!) you are often going to end up with much less clean power. \n\nOne of the most consistent PSU brands is definitely Seasonic though.",
      "Do you think it has anything to do with the brand? Or is it possible I was extremely unlucky with two EVGA units?",
      "Seasonic as a brand is still top-notch, agreed. They also make a lot of OEM units for other brands. I think some (usually more expensive) Corsair PSUs are actually made by Seasonic as well.",
      "FPS limiter, it does wonders.\n\nYes, under load, coil whine sucks, not much you can do about it.\n\nBut have you ever heard a 970 doing 8000fps on main menus? Awful.",
      "This needs to be higher because this is actually the answer. A lot of people want to return their card when it has coil whine but they are looking at the wrong component.",
      "This response makes sense. I had two different GPU's on the same PSU with no issues. It wasn't until I installed the 6900XT.",
      "My 2011 vintage Corsair HX750i started screaming at the slightest provocation (even SSD load) before I replaced it with a Seasonic TX-750.  \n\n&#x200B;\n\nMy reference RX 6800 XT had slight bit of whine that got better after the first few days, but dear lord, if you put an EK waterblock on your card, and you opt to also put a backplate on, don't tighten down the central 4 screws, else the backplate becomes an emitter for coil whine that projects it across the house.",
      "Yeah the backstory made it more clear. I have coil whine on my 6800XT, my PSU is fine. It's an SF750 so it better be, since it's a 80+ Platinum :D",
      "Yes. I picked up an RM850i Corsair PSU, and it was refurbished, right from Corsair‚Äôs factory in Texas. You get the OEM box, instead of Corsair‚Äôs fancy box and it has a tiny Seasonic logo on it.\nPerfectly quiet PSU, btw.",
      "I have the XFX 6800XT 319 Merc. It uses the same PCB and power delivery system from a 6900XT. \n\nUnfortunately, it doesn't fit in my computer case so I am waiting for a new case to arrive. As a result, it's on my open test bench, about 6\" to the left of my keyboard. Fortunately, it's the very first GPU I've owned where I cannot hear the coil whine. My 2080ti FE, 1080ti FTW3, and GTX690 all screamed and whined like banshees and we're audible from inside their respective chassis.\n\nI've used Seasonic, SilverStone, EVGA, AND Corsair PSUs and it's never made a lick of difference in GPU noise. There was probably something else that changed in the power equation (i.e. surge protector or power cable).",
      "\"bequiet\" ironic",
      "ho jesus that actually happened to me! GTX970 going like 8000fps on the game Symphony on steam. This was my first time hearing such noise i thought my pc was gonna blow up!",
      "In my experience, it's just a tossup if a paired combo whines or not. For example:\n\nPSU1 and GPU1 has coil whine.\n\nPSU2 and GPU2 has no coin whine.\n\nPSU1 and GPU2 has no coil whine\n\nPSU2 and GPU1 has no coil whine.\n\n\nCoil whine doesn't mean the card sucks, or the PSU sucks, it just means that together they are causing those caps to resonate at an annoying frequency.",
      "> This is probably result of using this particular card type with this particular PSU.\n\nWe recently got back an EVGA 750BQ power supply from a client complaining about coil whine in the PSU. I tested it with a GTX 560 (my work computer) running the Heaven benchmark. Tons of coil whine and very noticeable, especially when it transitions between scenes. It was very similar sounding to the 700BR in this video.",
      ">But have you ever heard a 970 doing 8000fps on main menus? Awful.\n\nI have. And mine have been completely silent all the time I've had it. However, a friend recently borrowed it, and he called me to complain about the coil whine.\n\nSo I'm pretty sure it's the specific configuration, most like the PSU, that's the real culprit here.",
      "FPS limiter at for example, 300, has absolutely no downsides.\n\nAs long as it's slightly above the refresh rate, you're fine.\n\nI'm running a 70hz display and have a global FPS limiter at 100, and everything works well with no inputlag whatsoever. No tearing issues, either."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6950xt"
    ],
    "title": "Built my son his first PC last weekend. R7 7700X & 6950XT",
    "selftext": "The computer pic was pre cable management, but was just ready to show him his new PC nothing beat seeing how happy he was. Link to the parts used (via pcpartspicker). https://pcpartpicker.com/user/ITZJOSH33/saved/BR4YXL",
    "comments": [
      "I‚Äôm a 40 year old looking to be adopted. Do you need another son?",
      "Did he catch you browsing adult pages? He must have some kind of leverage lol",
      "That would be awkward as I‚Äôm not 40 yet myself üòê",
      "Lol you‚Äôd have to think so, but nah he‚Äôs been wanting his own after he seen me build mine.\n\nhttps://preview.redd.it/3a1gtbqfun2b1.jpeg?width=3024&format=pjpg&auto=webp&s=80b9a6eb6d84b4022b7d9d10482df1e39f62d490",
      "So let him adopt you lol",
      "Thermalright AM5 secure frame\n\nThey cost ~$10",
      "They do nothing other than look cool but I hear they keep excess thermal paste from getting messy.",
      "Some games if he wants to, we don‚Äôt always have the same taste in games. However I do enjoy gaming with him.",
      "What is that red thing around the CPU? Can it be bought? Thank you.",
      "I think it's more relevant for Socket 1700 (Intel) where the more rectangular shape is apparently causing CPUs to bend/damaging the socket due to the way pressure is applied from the coolers. Using one of these evens it out.",
      "You let me know what you need to make it work. If it helps I have a young face.",
      "Lucky man.",
      "Why do we need it for?",
      "Here‚Äôs the CPU temp screen\n\nhttps://preview.redd.it/pdj9lbx2xq2b1.jpeg?width=4032&format=pjpg&auto=webp&s=1fa033a2cc25d5cde6c38c5e1d42de19ff0fffd9",
      "They don‚Äôt. The IHS is thicker than Niki Minaj.",
      "Lucky son.",
      "Less damaging the socket and more the bending prevents the cooling solution making good flat contact with the CPU which affects performance.",
      "I‚Äôd have to see your list of qualifications. Also your list of hobbies/passions/ and sports teams.",
      "You might want to change the pcpart picker name list. I mean it's not particularly sensitive, but people can be weird. Great build, I wish I had a PC like that lol.",
      "Do you play with him ?"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6950xt"
    ],
    "title": "Ryzen 9 5900XT & 6950XT Sapphire",
    "selftext": "",
    "comments": [
      "Jesus is that a 4-slot card? Great big chungus.",
      "Have you seen the 4.5 slot 3070 lol",
      "‚ÄúZAMN!‚Äù MY DREAM BUILD\nBut HOLY SHIT BRO WHY IS THE CARD THICCC",
      "Asus x Noctua 3070, 3080\n\nhttps://i.imgur.com/ayEIhyH.jpg\n\nhttps://i.imgur.com/ihnNYr6.jpg",
      "3 slot but you get a gpu support bracket it‚Äôs a heavy boy makes it look like 4 üòÇ",
      "WHAT",
      "Jesus Christ",
      "It‚Äôs a THICCC boy I watched a tear down on it apparently it‚Äôs so thiccc to help with the cooling because it‚Äôs get toasty",
      ">Sapphire really overengineered that card\n\nThats basically a brand feature at this point.",
      "Love this look. Simple and futuristic at the same time. What case is that, please?",
      "5900XT , how? :P",
      "Excuse my language but what the fuck",
      "It‚Äôs the Corsair 5000d airflow",
      "Could you please add a few more fans?",
      "For that overkill the GPU better not be more than 50 degrees under 100% load lol",
      "I'm pretty sure it's a sag bracket under it but technically still occupying 4 slots",
      "Sapphire really overengineered that card, haha.",
      "that cooler on anything less than a 3080 is just silly lol",
      "Only going to get thicker  with new generations, specially with Nvidia. 4k series is going to output over 400 watts stock, so the cooler needed to keep that cool will be massive.\n\nWent from sli needing 5+ slots between 2 cards to one card taking all that up itself, lol.",
      "Deffo worth it I had a 6800xt and I sold and bought this beast"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900"
    ],
    "title": "Broken AMD 6800/6900 GPUs after driver update? Video in the description (not mine)",
    "selftext": "",
    "comments": [
      "Just in case you haven't heard of KrisFix and are questioning his expertise or motives:\n\nHe has been repairing a lot of GPUs on a very high level for a number of years so he knows what he is talking about. Just look at the videos on his channel, they speak for themself\n\nExample: \n\nHere he is reballing a 3090 chip + ram because the card was drenched in liquid metal: https://www.youtube.com/watch?v=6nQCj5N9fV8 (skip to the last third of the video to see the soldering)\n\nHe is not some random small hobby Youtuber trying to create drama for views. \n\nIf he says \"I see a pattern here\" then people should certainly pay attention to what he is saying",
      "XFX 6900xt on 22.11.2 and nothing weird on going for me.\n\n(Knock on wood. Fingers crossed. Toes crossed.)\n\n&#x200B;\n\nedited",
      "This is crazy. My RX 6900xt recently died. About a day after I installed the newest driver.",
      "`if (warranty > 24) {`\n\n  `execute = \"overvolt.exe\"`  \n  `greeting = \"Check our brand new 7000 series GPUs\";`  \n`}`",
      "Count mine in. I had to replace my 6900 xt a month ago. I upgraded to the newest drivers at the time.i also used the auto undervolt feature in adrenaline software. then, I  played Black Mesa with every setting on ultra at 144hz 4k for an hour. I shut the PC down. The GPU never came back on the next day.\n\nEdit - my GPU is a reference 6900 xt model. GPU died after I updated to 22.11.2 recommended whql. Never mined with it. Just benchmarking/gaming/productivity",
      "People replying should include which aib card they are using \n\nCould help isolate the issue",
      "Unfortunately it's going to be very hard to verify this, as I don't think there are many repair shops doing GPU board repairs, that also have a social media presence. \n\nAIBs would know due to warranty claims, but it's not in their best interest to tell journalists about abnormally high defective GPUs.",
      "JFC can we as consumers ever catch a freaking break???",
      "Same Here for me. Excact Same Symptom.\n\nPowercolor Red Devil Ultimate 6900XT",
      "Yeah Kris Fix is a professional. Love his channel.",
      "I suppose it's good that i'm still on ye olde circa may 2022 drivers because black screen crashes are the bane of my existence and I refuse to modify windows settings to compensate.",
      "My Gaming X Trio is working fine too. This shit is making me nervous tho lol",
      "No issues with my card (reference)\n\nLast driver 22.11.2 WHQL",
      "I like your funny words magic man",
      "*nervously walks behind you...\n\nThis is like a horror film, but first person.",
      "Out with the old. In with the new",
      "Technically you only have 1 year of hassle free warranty in germany where you can return the product for rma. The second year becomes a little more complicated because now you as the customer have to prove to the seller that the damage/fault was already there at the time of buying the product.\n\nSo if a component was maybe already faulty but did not immediately result in a failure for example.\n\nNormally you would expect them to be accomadating and still just give you a replacement unit but they could also refuse it and demand that you prove them that this fault was already there at the time you bought the product at. Which would obviously be quite difficult as a consumer to do so.\n\nMaybe that's why they just send it to a repair shop.\n\nEdit: Of course this is just the minimum warranty requiered by law but individual companies can extend this if they so choose to.",
      "Mit dem Angriff Medions wird alles in ordnung kommen!",
      "So you think exposing corporate failures constitutes a hit piece? The 7900 XTX was a clear manufacturing default, not a hit piece It's an issue they needed to be called out on because they were trying to hide it and disavow any liability until they were called out.\n\nThis issue has nothing to do with that but it's an issue nonetheless, so I guess if you think raising awareness for legitimate problems is a hit piece then yeah not surprised Germans are the ones leading the charge, as a nation they have a culture of calling a spade a spade.",
      "My god. If this is true, this is absolutely disastrous for AMD.  \n\nThe GPU world has been an absolute dumpster fire as of late. Both AMD and Nvidia dropping the ball again and again.  \n\nThat said, a botched driver update that bricks a bunch of previous gen cards absolutely takes the cake."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900xt"
    ],
    "title": "5950X x 6900XT LC ; First real build.",
    "selftext": "",
    "comments": [
      "Yeah your fan situation is honestly pretty bad. If you optimise it a little you‚Äôll see way better temps",
      "Nice build and congrats. Interesting choice on your fan orientation. How are your temps?",
      ">since warm air rises.\n\nConvection has **zero** effect against this many fans. Cold air is entering the back through the open pcie slots hes not starving the gpu of air at all, the dust you mentioned is evidence of that. he'll just have to clean his computer every other month.\n\nNegative pressure is totally viable and often has a positive effect on radiant thermals inside the case.\n\nEdit: Well then. Thanks anonymous, I'll spend them wisely.",
      "Newegg: how many fans do you want?\nOP is 21savage:alot",
      "LMAO this is a very interesting fan's configuration indeed.",
      "76 c under high load generally around 40-50 c",
      "A fan of fans should always have the fans fanning the right way",
      "just noticed the 4 dominator plat dimms lmao. what speed?",
      "Very very interesting lol turn those bottom fans around. You have too much negative pressure with all fans blowing out.",
      "I‚Äôm a big fan of fans for no reason",
      "Lets be honest, you did it like this because of the how the RBGs look on the fans. You can buy the corsair ones that look the same on the back and the front if it really matters to you. I think they're the QL series.",
      "And you still have 8 other fans blowing out, resulting in a lot of negative pressure. If you turn the bottom around, the pressure would be more even and allow much more air through your case. I have the same case and have done just about every fan combination.",
      "Unusual fan arrangement. Bottom fans pushing air out??",
      "It‚Äôs a backplate and the glass wouldn‚Äôt fit back on the case unless I did some hoopty shit lmao you right",
      "3600",
      "at 4.8 ghz?",
      "I clean my computer constantly but not because it‚Äôs dusty just because I don‚Äôt want dust to build up, and none of the fans not directly connected to components have been effecting my system at all negatively",
      "I almost never clean my computers, because I have 6 of them and its a hassle. maybe like 4 times a year at most because I keep a clean home and don't have pets or smoke indoors.\n\nPeople a weird about PC perfection and I think its stupid.\n\nAn oil refinery doesn't pay electricians millions to cable manage for looks, they do it to ensure reparability, safety and efficiency. The people who cry about \"messy AIO tubes\" are the same people who run unshielded data parallel to their 12vpower lines. Its dick measuring idiocy.",
      "I actually just keep a bunch of ice cubes inside my rig so it‚Äôs not an issue",
      "Awesome build! I have the 6800 XT variant of that same gpu with a 5900X it's great. Mounted mine vertically last week."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900xt"
    ],
    "title": "Here is my AMD build and battlestation - 5950X/6900XT",
    "selftext": "",
    "comments": [
      "It looks so clean and elegant. Nice station !",
      "I didnt built this in days or weeks, it took like months/years (im old and slow) and now I feel its 95% completed. Next update is probably 7900X3D/AM5",
      "Upvote for proper sound system, everyone skips that part for some reason üòû",
      "Cause headphones for the most part",
      "Never mind, I am young and slow. Took me a year to finish my build while new things on the tech market arrived hahaha ü§£",
      "I get that a lot of people use headphones. It is a relatively inexpensive way of getting a good sound. I have some Sennheiser HD380 headphones but hardly ever use them. For me, there‚Äôs something about the sound of a good speaker you just can‚Äôt beat when listening to music.",
      "When do you get the good headphones ? Heh",
      "Actually yes. It helps to keep positive pressure inside the case. It helps!",
      "Yes this is Ergotron LX",
      "Klipsch R-14PM",
      "I get that, but personally, I'll listen to my speaker setup on my tv instead of my desktop. My computer is just better to use with headphones with my use case",
      "Is that an Ergotron monitor mount? I‚Äôm considering one for Neo G9.",
      "With a build so powerful already I would recommend waiting a while on the upgrade. At least a few months while we make sure all of the kinks are ironed out with the new platform and we can see what motherboards work well, and likely DDR5 prices will keep dropping.   \n\nIf it was me I'd skip a generation (or 2).",
      "Nice build! I build my WC system too in Fractal case (Meshifi 2XL). You can see it in my profile :)\nWhat is model of 6900XT? I have Tuf version and it have bad coil whine. Do you notice coil whine of your GPU?",
      "Mmmm, fractal design. Delicious.",
      "I like Klipsch sound a lot",
      "So clean!\n\nDoes the foam help much with dust?",
      "That's what I thought when I saw this. Whole lot of horsepower to confine to one monitor lol.",
      "Depends on how nice the speakers are! Can‚Äôt tell the model but great speakers can provide just as good of a listening experience. Plus sometimes headphones just aren‚Äôt as comfortable üòÇ",
      "Yeah they make them powered and not. I have both. Love them."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6950xt"
    ],
    "title": "After 9 Years of service i wish my R9 380 a good retirement , and welcome my 6950xt in hope for the next 9 Years of gaming",
    "selftext": "Ngl i would stick to R9 if they still were updating the drivers otherwise it kinda forced me to upgrade",
    "comments": [
      "Sapphire - very nice brand choice of the GPU!!\n\nI would rank them among the top 3 in the AMD GPU maker's list.",
      "Are you me? I'm not upgrading again until Ryzen 16-core CCD. I came from 3570K and expect similar upgrade cycle",
      "Because Sapphire is the best?",
      "I can't wait to do the same with my RX 480s. They've performed extremely well for a long time but it's almost time to decommission them.",
      "Do u know why sometimes sapphire gpu models are most expensive ones and other gpus are cheapest?",
      "It depends du modele, sapphire produces the pulse and the nitro. The nitro is the more expensive",
      "Real",
      "I meant that one time sapphire model is most expensive one and sometimes its the cheapest",
      "This is the way",
      "The lack of new AMD driver software thing really stops you from newer titles even tho these cards still have some juice in them",
      "Awkwardly looking at this post while still using a RX 480 8GB and an i7 2600K‚Ä¶ üëÄ\n(I don‚Äôt game on my PC, which is why I don‚Äôt see a point in upgrading)",
      "/salute\n\nMy brother is using my old XFX HD 7950, still running smoothly.",
      "It's mid-range. RX6800 signifies the start of the high end cards on AMD.",
      "Low end is not much difference. High end theres a big difference ;)",
      "Toxic, highest",
      "I'm not only using pc for games i also do hobby style blender or video editing and i dont fear the power draw since you can always undervolt",
      "Did your fans die even once in 9 years? I actually had to jump from r9 280x to 1080ti beacause of fans dying.",
      "Good choice. I‚Äôm more a 3-5 year/2-3 gen GPU upgrader. Hoping my 7900XTX will age as well as the 5700XT thicc iii, Fury, 7970, 4870x2, 2900XT, X800XL and Radeon 64MB ViVo did.",
      "Nope i it was working fine all along",
      "Forced obsolescence FTW üòû"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900"
    ],
    "title": "AMD Officially Launches RX 6900 XT Liquid Edition with 330W TDP and 18Gbps Memory",
    "selftext": "[https://videocardz.com/newz/amd-launches-radeon-rx-6900-xt-liquid-edition-with-330w-tbp-and-18gbps-memory](https://videocardz.com/newz/amd-launches-radeon-rx-6900-xt-liquid-edition-with-330w-tbp-and-18gbps-memory)",
    "comments": [
      "The cooler is made of the high end Unobtainium + paper launch alloy, for never seen before level of performance!",
      "Just 10% higher TDP for 10% higher clocks? That's actually pretty good. Looks like it's not past its \"sweet spot\". Either that, or these chips are the golden samples and have better efficiency than the ones used in the regular 6900XT.",
      "Summary:\n\n\nClock differences vs ref:\n\n10% game clock, 7.5% boost, 11% memory.\n\n10% more power usage.\n\n2 slot design, expected June",
      "Launching Nevermber 32, 2021",
      "These chips are golden samples yes, XTXH instead of XT dies (just higher binned)",
      "Or a Radeon 6969 XXXTT",
      "Nice, can't wait to get my hands on one of these when I build my retro PC in 25 years from now",
      "For never well be seen level of performance",
      "I just want an entry-level GPU PLEASE",
      "They should have called the RX 6900XT the RX 6900.",
      "Samsung already produces 18gbps memory, it's probably more costly though",
      "I wonder how they got the memory that fast, that's almost up to the 3080ti/90 (19Gbps) think the OG is 16Gbps?",
      "It takes a while to build up a supply of golden chips to produce a binned product like this.",
      "*11,25% memory :P",
      "Their marketing department needs a refresh.",
      "It will be seen. Just not by Verified Actual Gamers (TM). \n\nThe 4 cards at launch will do a lot of heavy lifting sitting in some scalpers basement, listed on ebay for $6900",
      "Can't wait until December 64, 2021",
      "Almost definitely golden samples. But still pretty impressive though.",
      "RX 6969 XD",
      "RDNA2 getting wet"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900xt"
    ],
    "title": "Finally upgraded to 6900xt from Vega 56!",
    "selftext": "",
    "comments": [
      "That‚Äôs like triple the performance, enjoy!",
      "That case is HUGE.",
      "Phanteks 719, designed to be able to hold a full ATX system and an ITX system at the same time.\n\nedit: also the Phanteks Enthoo Pro 2, same design more airflow.",
      "Makes sense for streaming (streaming pc in ITX, main PC in ATX).",
      "Thanks, man!",
      "Have seen 1 or 2 couples come by in /r/buildapcforme that wanted it as a way to save space on the desk by putting both their machines in one case, but yeah pretty niche function.",
      "If you haven‚Äôt already, you should sell your Vega 56. It‚Äôs a beastly mining card with its HBM2 memory, (50MH ETH, 200MH ERG), you should get at least $800 for that card.",
      "Red Devil and Merc were my top choices but couldn't find any Red Devil here. They're both nice looking cards",
      "I like my Red Devil a bit better.",
      "Eh, as a former V64 owner it was starting to show it's age. Definitely a decent card still absolutely, but I have no regrets upping the ante to a 6800",
      ">Phanteks 719\n\nhey thanks for saying the name of my next case, didn't even know it existed and Obsidian 1000D is almost triple the price lol. getting it soon haha thanks m8",
      "I got $300 CAD for my Vega 64 when I sold in October 2020. I was a fool. :)",
      "Damn now I want to replace mine too",
      "Vega 56 enjoyer here. Maybe OP is going to play at 4K resolution. In that case, Vega 56 is not enough these days to properly perform on highly demanding titles.\n\nI'm playing at 1080p and still holds on incredibly well, though. Only thinking I bought it brand new 2+ years ago for a little more than 250‚Ç¨... I really dodged a bullet there, I guess.",
      "How much did you get for your vega56? 7-800‚Ç¨?",
      "A bit over double. Still solid AF :)",
      "All black system, very nice",
      "Got $350 USD for my Vega 64 in December. Also a fool.",
      "No... Not once you've experienced 1440p 144hz",
      "I've sold mine last week for 700‚Ç¨. Then got a 6700 XT for 700‚Ç¨..."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6950xt"
    ],
    "title": "6950xt OC FORMULA + 5950x",
    "selftext": "",
    "comments": [
      "Wtf is that ram cooler",
      "80mm noctua, dropped temps by 15 at max load (super stable), 3800 cl14 gets hot over 1.5v",
      "Huge gains in timespy benchmarks, as well as cpu intensive games such as Warzone (30+ fps increase compared to a 3200 cl16 kit)",
      "Solid 120 seconds per frame",
      "Well that's some oc... But does it improve the performance significantly?",
      "Wow @ the ram fan.  They included a sag bar for that gpu for a reason",
      "dips to 190 seconds per frame occasionally",
      "Installing it now‚ò∫Ô∏è",
      "Nice, what frames you getting in wz?",
      "I personally love how the honey comb mesh on the gpu matches the honey comb on the motherboard io side.",
      "Ah yes, swap out a $5 dollar fan for an $80 dollar fan just for aesthetic reasons",
      "Had to drop the resolution to 720p for a stable 60fps, but atleast it's playable üëç",
      "Saw your review on Newegg haha",
      "‚Ä¶Buuuuuut will it run minesweeper?",
      "That looks amazing. Which BeQuiet AIO is that? I didn‚Äôt know they had one with RGB on the pump head.",
      "Welcome to the club buddy https://imgur.com/gallery/PqMrEKT",
      "When stressing testing without a fan they will go above 50 celsius which causes instability, it maxes at 35-36 now",
      "I should of mentioned I also have 3800mhz CL14 ram in my rig.    Not sure for downvote but thought to give my fps to you since I have an identical rig has OP. 6950xt is probably a tiny bit better than the 3090 or on par with it",
      "üò≥  \nSexy.\n\nWhere'd you get those GPU cables?",
      "Honestly I prefer how mine looks, and it performs better than that!"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900"
    ],
    "title": "[Guru3D] Availability of the Radeon RX 6800 (XT) & 6900 XT Is Still Extremely Poor",
    "selftext": "",
    "comments": [
      "6800 2930 ordered 117 delivered\n\n6800xt 2513 ordered 42 delivered\n\n6900xt 354 ordered 0 delivered\n\nfor the 159 delivered: \"we did not expect so much demand\"",
      "ordered=from manufacturer\n\nnot by customers",
      "Saw the 6900xt on ebuyer today had it in my basket almost purchased it but then did a double take on myself like \"do I ACTUALLY need this? nope\" so gonna wait till stock normalizes I was only going to pull the trigger because of low stock like \"if I don't get one when will I?\" just gonna wait 6 month and see whats on sale then. Not going to be triggered to buy somthing because of low stock which I almost was.",
      "Are these numbers accurate? That just blows my mind. I‚Äôm one of the 2513 ordered and now I just feel like I‚Äôm never gonna receive it",
      "Honestly I feel that if it wasn't for the high level of demand for high end GPUs people wouldn't be as willing to buy an RX 6900 XT or RTX 3090. In a \"normal\" GPU market it simply doesn't make any sense to buy these cards unless you are using them for work.",
      "I was told by Canada computers that my 6800 XT will just never come in, so I can either wait for an AIB that they have no expected delivery date, or go to the back of the line for a 3080. Definitely a month of waiting well spent /s",
      "they said 2 months for availability, we are on month 1 + 5days and counting\n\nI said that it was a lie but.. who knows, I hope I'm wrong",
      "The 6800xt red devil variant from powercolor retails for 1197 USD. What is worse, I don't think this will go down any time soon",
      "Yeah thats the problem im having right now, I don't really need a 6800xt / 6900xt but currently running a rx 580 8GB and the games I play run fine so I don't \"NEED\" one of these new cards but I would certainly notice the difference.\n\nPersonally I wish there was more of a mid tier GPU available, right now 5700xt is about the price I want to pay, but fuck buying something like a 5700xt or anything not \"this generation\" for the IPC uplift.\n\nHoping next year AMD puts out some replacement for the 5700xt or Nvida up the amount of VRAM in their cards because I was even looking at the 3060ti etc but its like I am not going from 8GB VRAM to 8GB ...",
      "AMD confirmed that more reference cards will be made for all models. But given that at most AMD is only getting at most 60 GPUs per wafer and Nvidia is getting at most 50 GPUs per wafer for both companies largest dies, don't expect supply to normalize any time soon. Keep in mind that that's only 140,000 TSMC 7nm wafers processed every month in total. And AMD has between 44,000 and 70,000 of those (we know that no customer is over 50% and some customers have dropped without disclosing who the allocation went to). Nvidia is using Samsung 8nm and we aren't sure how many wafers they're buying or even how many wafers per month Samsung is making on 8nm versus their 7nm process. But total supply to Nvidia is likely between 100-300% of what AMD is using at TSMC for GPUs based on what numbers look like in wholesale channels.\n\nMy guess is that Nvidia probably has around 10k-15K wafers/mo for all of its Ampere products including the A100 which is currently out of stock with earliest possible delivery via air being listed as 3 weeks. And AMD is likely only dedicating 2-3K wafers/mo to their high-end GPUs with the vast majority of their TSMC 7nm wafer allotment being slotted for console APUs, processors, and low- and mid-range GPUs that are launching next year. Furthermore, AMD also is starting to fulfill CDNA which is a 120 CU  computer focused GPGPU solution for data centers which features better FP16, FP32, and FP64 performance compared to Nvidia's A100 and has already been ordered in bulk, along with the not yet publicly released new Epyc processors for the first two exascale supercomputers.\n\nOh, and to top this all off, we've had shortages of the following so far this year:\n\n* Screws\n\n* Shipping containers from China\n\n* Shipping containers to China\n\n* Air freight capacity due to decreased intercontinental flights and now vaccine deployment\n\nAnd all of that is affecting the ability to move produced products from Asia to the rest of the world. Not to mention the fact that shipping is taking longer due to COVID-19 mitigations that slow down the loading and unloading of ships, planes, trains, and trucks.",
      ">AMD confirmed that more reference cards will be made for all models\n\nAMD's word means nothing at this point.\n\nThey have said-\n\n- There would be more stock than nVidia launch - **false**, *nVidia had more cards - both sold out quickly but nVidia had 2-3x the cards available on launch day.*\n\n- There would be 5-7x the stock for AIB cards - **false**, *there were even less cards for the AIB models than reference.* \n\n- There would be a general availability and a return to MSRP within 4-8 weeks (still in progress, but considering we're hitting christmas, new year then chinese new year - we can do this one early, there won't be stock before march) - false",
      "No. The mining craze was way worse. I know it first hand because I bought my RX 580 back then and I remember that I had to wait for months to get it.\n\n\nIt eventually got to a point where the only card that was readily available was the GT 1030 (even the RX 550s were selling out immediately). At least currently I can still buy an RX 5000-series card or an RTX 20-series card if I needed to.",
      "AMD told Hardware Unboxed that in up to 8 weeks MSRP cards from AIB partners would be available so we will have to wait until mid-January to see if that ends up being true or not.",
      "My canada computers hasn‚Äôt told me this, but they have no idea when I‚Äôll get my card either",
      "I saw my first social media post about someone actually getting a 6800XT yesterday. It was a reference design from XFX. Compared to nvidia, I see maybe 5-10 posts every day of people getting 3080's and 3070's. \n\nI know this is far from a quantitative analysis, but this is a factor I've been using to judge availability for years and it has always worked for me.",
      "The fact they decided to keep the reference going means they might think this won't happen now.",
      "Nah its not that one dimensional, they do proper market research and much more to find out the demand but they also are restricted by foundry capacity.",
      "Weren't 580s and 1060s going for $500? That was super rough. A $200 msrp card going for $500 and what's worse is that eventually retailers started charging that much. It's even funnier that despite all that and despite 4-5 years, the msrp of the rx 580 hasn't changed (still around $180?)",
      "It‚Äôs so much worse than the 30 series. I‚Äôll grant them that they were released later but I‚Äôve seen basically no restocks of these cards.",
      "I got a 6900xt this morning at microcenter. Had to be there at 5:30am outside though to be one of the first 10 in the store"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6950xt"
    ],
    "title": "AMD Radeon RX 6950XT drops to $610 prior to GeForce RTX 4070 launch - VideoCardz.com",
    "selftext": "",
    "comments": [
      "It was actually $599 yesterday but it was a \"shell shocker.\"",
      "This is a good deal. I got the XFX 6950XT Merc Black about 2 months ago, and it's been great. I've been testing the shit out of it and comparing it to the new stuff. It's basically a 4070ti without the RT performance. It does light RT work like in RE4 really well. Runs way better in games than in benchmarks. You can overclock them high, too. These are the best of the best Navi 21 KXTX boards AMD is trying to get rid of",
      "RE Engine is properly optimized. The RT performance is actually pretty good on game engines that took the time to implement for AMD.",
      "Sigh. Nowhere close to in Europe.",
      "I got mine at $700. This is a good deal.",
      "I think most people from Europe, including me, tend to forget that the US Prices don't have the tax included... Cuz AFAIK in Europe the listed price includes tax.",
      "..what? I count 5 different countries in the EU that have one within 5% of the US's price when you account for tax, Germany has it for nearly an identical price.\n\n$610=554.75 euros, Germany's VAT: 19%,  554.75*1.19=660.1525.\n\nYou can buy a 6950XT in Germany for 659 euros.\n\nCountry|Cheapest 6950XT (Euros)|Country's VAT|US price converted|% Difference\n:-:|:-:|:-:|:-:|:-:\nBelgium|696.95|21%|671.2475|+3.8%\nFrance|684.00|20%|665.7|+2.7%\nGermany|659.00|19%|660.1525|-0.2%\nItaly|684.00|22%|676.795|+1%\nNetherlands|689.00|21%|671.2475|+2.6%",
      "It's a very large country, if you're in the western part life will be mostly normal where as in the eastern part you will find entire cities where not one building is still standing.",
      "700 usd weeks ago",
      "No. The 6800xt is the perfect 1440p card.",
      "Respect that you've got the restraint to wait for that last few percent off.",
      "6950XT way better and its not even close",
      "> and it speaks to how nice Capcom's shaders are even without RT\n\nOr how \"meh\" the RT implementation is.",
      "Waiting for a $750 type deal on a 7900XT and I'm jumping. Newegg has one for $779 and it's real tempting to go ahead.",
      "I picked one up last week for $650 lol I‚Äôm good with that price.",
      ">Im better buying it from the US, this is ridiculous, at least we have free healthcare.\n\nAs a US citizen, I think you get the better end of this trade-off.",
      "$900 in Ukraine, the cheapest I managed to find... Prices here are insane and always was",
      "Not sure why this is getting downvoted. AMD usually gets good RT performance in games with less robust RT implementations. Dirt had good RT performance but in that game RT is just shadows and you have to look with a magjifying glass to see it.",
      "Paid $680 for my 6900XT and I thought that was a bargain!",
      "at only rasterization.  The 6950xt also uses a lot more power.  This can be an issue if you are just upgrading a gpu. Its what made me choose a 7900xt over the 6950. I have a 650w sfx psu and was worried about the spikes that the 6950 has so instead of spending the money on a psu i used it to get a little more performance.  \n\nOf course at current prices, i could have saved like $50 even with a new psu."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900"
    ],
    "title": "Finally able to get a 6900 xt to go with the 5600x now that prices are down. Build complete. Black and silver all the way.",
    "selftext": "",
    "comments": [
      "Upvote for XFX 6900xt",
      "Nice.  After my first GPU, which was a Voodoo 2, I've had an unbroken run of nvidia cards.  The last was a 1080ti scored at a bargain price when the 3000s were announced.  But now, knowing the truth about that company, I want AMD to be my next GPU.  Please AMD, it's your best chance in your history to carpe frikkin diem.",
      "Looks clean. Enjoy!",
      "One of us ! One of us !",
      "Hey there bought it off Amazon for 729+tax. Can be found for cheaper off places like Newegg or micro center though. Check r/buildapcsales for deals as well.\n\nEdit: fixed subreddit lol",
      "Nvidia RTX 4000 GPUs are a scam and RDNA3 will be faster anyway",
      "They‚Äôre charging $900 for a rebadged RTX 4070",
      "Team red all the way",
      "Absolute monster of a card",
      "Oh most definitely will",
      "I can't even imagine how much of an upgrade that is. Can the GT 710 even play games?",
      "What is there to know?",
      "Lowest I‚Äôve seen it is $699 so that‚Äôs still really good. Congrats!",
      "Wow... I assume that's supposed to be the cheapest (FE). AIB's models will be more expensive... No way.",
      "Yeah, it's the first card I have that makes my NZXT Phantom 630 look ATX-sized lol\nIt matches that in power though, I have yet to find a game I struggle to run in 1440p with everything maxed out.",
      "Scam in what way?",
      "It‚Äôs refillable ü§∑‚Äç‚ôÄÔ∏è. Just preferences I guess",
      "There were murmurs over the years about a cringey, misogynistic culture there.  For example the geforce experience (GFE) was apparently a play on the girl friend experience, referring to a type of prostitution.  But until youtube became a platform for properly independent journalism they were just murmurs.  It's become clear (to me at least) in the last 5 ish years that nvidia are smiling, arrogant bullies with a toxic culture towards their customers.  The EVGA situation seems consistent with that.",
      "Most definitely do not check from /r/buildup/",
      "Oh, so 5% tax or wholly exempt. It must be nice."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900xt"
    ],
    "title": "I'm very satisfied with how my build ended up-- 5900X + 6900XT",
    "selftext": "",
    "comments": [
      "No RGB, just R",
      "Pretty sweet. Love the blacked out no RGB look. Happy gaming",
      "I‚Äôve sold all of my rgb after seeing this.",
      "Lol when I do have lights, I prefer them to be a solid color. So I am indeed a fan of this blacked out, solid color aesthetic.",
      "I always love seeing those chromax covers on the d15. You should consider sleeved cables to match the rest of the build!",
      "Solid color is the way to go imo",
      "tried kind of everything but a chop stick works best. definitely wouldnt recommend a screwdriver like my dumb ass thought",
      "*giggles* 69",
      "Brother!",
      "W\n\n\nJoin the gang of aesthetic simplicity and reduce your electricity bill",
      "Looking good! :)",
      "bequiet 500DX",
      "eh definitely not MSRP, although i dont even know what would be the correct pricing of the \"Ultimate\" edition Red Devil, i bought it since it was the only one in stock. i spent at the time around 1400 euros",
      "Solid color that is BARELY on. So dim that you think it's painted on.",
      "R",
      ":) ive been in team red all my life, my first build was a phenom II X4 paired with an HD 7870",
      "Ok thanks I'm looking to buy and everything is so overpriced. Great looking build!",
      "I simply added two 140mm fans, one in the front and one on top, as the case already comes equipped with three fans.\nI chose that case because it fits on my desk, i found later while working on it that it is very well engineered and everything would fit neatly. the RAM modules stand at 39mm i could lower the fan further but id be touching them and i wanted to avoid that",
      "Snug as a bug in a rug",
      "Eh depends on the lights. Some \"painted-on\" looks sometimes look way worse than others. Depends on the components.\n\nStill though, usually it's nice at 25 to 50% brightness (unless you have tinted glass, which would be best at 75 to 100%)."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6950xt"
    ],
    "title": "ryzen 9 5900x, sapphire 6950xt",
    "selftext": "",
    "comments": [
      "onlyfans",
      "if you added a windmill to the center of the case it could also be self sufficient",
      "You need more fans, until there is no air.",
      "Do I count 16 fans? There has got to be some diminishing returns on those fans, right?\n\nYou can't even see the RGB on the fans top of the rad",
      "At this point, I kinda wanna spam their subreddit with posts like this.",
      "19, if you count the gpu fans.",
      "Could you add a few more fans please?",
      "Needs more fans",
      "Looks great. That card has an amazing design thats different from the rest.",
      "I setup a push pull on my AIO rad. Maybe a 1-2 degree difference. So it‚Äôs negligible. \n\nSince temps weren‚Äôt any worse, I kept it cause I liked being able to see my fan LEDs on both sides. \n\nMy biggest temp difference came from moving the rad from the top to the front. \n\nRAM temps also dipped fairly significantly when I went front mount as well.",
      "This Pc might be running at 90 ¬∞C and still look like it‚Äôs cold AF",
      "Typically not much difference when doubling up fans from what I have seen.  At least on CPU.  I honestly have never seen a push/pull on a rad...",
      "Didn't that happen when they said they would ban porn from the platform?",
      "Where's the power supply?",
      "I'm not quite sure what the fans on the motherboard panel are supposed to do. What air they pushing to / pulling from. Are they put there just for the beauty of it? Are there ventilation holes behind the back panel?",
      "Looks good\n\nGot a question: looking at the topfans, Is it necessary to do Fan / cpu cooler / Fan or is it possible to do only Cpu cooler / fan?",
      "I'm not the biggest fan of lit cases, but this setup looks awesome! Something about the light gray/blue hues just works.",
      "If you look closely, you can see ventilation holes behind them. So technically they're pulling air into the case.",
      "Don‚Äôt judge and don‚Äôt be a gatekeeper.",
      "Gorgeous machine, wow"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6950xt"
    ],
    "title": "White full AMD build complete! 5800x3D + Nitro Pure+ 6950XT",
    "selftext": "",
    "comments": [
      "Idk how but you managed to make an ugly all white build. \n\nnot trying to be mean.",
      "That gpu is richonkilous",
      "I think it needs more fans.",
      "Probably just poor lighting in the picture",
      "At what point do you have a computer attached to your GPU instead?",
      "imo it's not the lighting but the different shades of white & the lack of a 2nd tone. The CPU cooler being the most obvious of them all when it comes to the shade, but otherwise it just looks boring.\n\nI'm pretty sure darker lighting in the room and non-white LEDs should pretty much obfuscate it though since it's going to reflect a lot of it, but just lighting in the room wouldn't fix it I don't think",
      "What cpu Fan is that?",
      "Deepcool ak620 I believe",
      "Given that the motherboard and GPU have a bit of black the fans probably would look more uniform with black fins and white frame.\n\nI think this thing would look better overall in person than in photos anyway.\n\nIt's a very clean build though. Tight cable management and everything looks like a collection of organized little boxes.",
      "This combo rips through any game I throw at it! With PBO tuner 2 and a slight OC on the 6950XT it is running like a stable and cool. \n\nPC components: \n\nCPU: Ryzen 7 5800x3D \n\nGPU: Sapphire Nitro Pure+ 6950XT \n\nMB: MSI X570S Tomahawk \n\nRAM: TFORCE XTREEM 3600 CL14 \n\nCPU COOLER: DeepCool Ak620 white \n\nCase fans: 7X Corsair AF140 Elite \n\nCase: Lian Li Air Mini - White",
      "First things I thought of when seeing this. Is a dark filled freezer with a broken light or a rubber crazy room. It's has bad lighting in the picture",
      "@u.ruined.the.joke.stupid",
      "I have the same case and same fan layout. Good choice, too many people put two top exhausts and that causes the one on the front of the case to suck up all the cold air and eject it before the CPU can actually be cooled\n\nI recommend putting some sort of small wooden blocks underneath your case feet to get more vertical space for the bottom intake. After I did that, my temperatures dropped decently because the fans weren't choked anymore",
      "All that effort to make it all white and to be honest it doesn‚Äôt look very nice at all.",
      "Nice build! But just a heads up, does vertical PCI-E power connectors can be a [fire hazard!](https://linustechtips.com/uploads/monthly_2020_12/IMG_20201227_110316.thumb.jpg.2fc97993a181ba8935a73c0f81a16da4.jpg)\n\nMore photos here:\nhttps://linustechtips.com/topic/1287646-psa-dont-buy-aliexpress-pci-adapters/",
      "I agree",
      "Sick",
      "Or perhaps Only Fans?",
      "GPU comes with a support bracket, but doesn't look like op installed it.",
      "What"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6950xt"
    ],
    "title": "AMD Radeon RX 6950XT drops to 599 USD, now at same price as RTX 4070 - VideoCardz.com",
    "selftext": "",
    "comments": [
      "only in US probably",
      "In Spain you can buy an 6950 XT new for 649‚Ç¨ which is 596 freedom units. Not bad.",
      "South East Asia: Best I can do is $1200",
      ">Peoples want AMD to be competitive so that Nvidia drop price‚Ä¶ to buy Nvidia\n\nfacts, even on reddit you so so many people cry about nvidia's pricing while they have flair with an RTX 3000 or RTX 4000 card. Like bruh.",
      "But why? \n\n4070 will sell more than the near 2 years worth of the 6950XT on shelves. They know it. AMD‚Äôs RDNA 2 **entire** lineup is a blip on market share. Low sales on Nvidia is still more than AMD. 4070 Ti, 4080 and 4090 are appearing in the steam hardware survey while none of RDNA 3 are. Those low sale Ada cards are still (last time I checked) up to 70% of RDNA 2‚Äôs entire lineup.\n\nPeoples want AMD to be competitive so that Nvidia drop price‚Ä¶ to buy Nvidia. This is inherently why we have these prices. Don‚Äôt buy these cards if you want to send a message.",
      "Only problem it's 400w+ card. Compared to ~200w. That shit adds up depending where you live, excess heat can also be annoying to deal with.",
      "650‚Ç¨ includes sales tax of 21% = 537‚Ç¨ before tax = $596 before tax",
      "Shows you how much profit they make on these cards . At 599$ they still profit",
      "VAT is included in the price...",
      "Your turn Nvidia..",
      "‚Ç¨649 for the Black Merc at Mindfactory.\n\nThats exactly $599+VAT.",
      "Exactly. I want them to sell them at  -50% loss.",
      "We have to pay insane amounts of import tax",
      "Amd cpus being more efficient than intel = Woahh amazingggg. Nvidia GPUs being more efficient = no one cares about power consumption",
      "It's a little deceptive, and not that straightforward. The material costs are probably fair bit lower, but you also have to account for the upfront R&D costs. They likely amortize this cost over a  number of months post-release - which leads to higher launch MSRP.\n\nOnce the R&D costs are paid off, you can reduce the sell price as their total costs have dropped despite material costs remaining unchanged.",
      "Meanwhile in my EU country prices for rx 6950xt still start from $700 up to $800.",
      "The 6800xt already competes with the 4070. This wont just compare, it will beat the 4070",
      "True, I have never seen such things that have bad pricing like AMD products in SEA, an used R5 3600 is around 90$, with 90$ I can even buy new 5600 on taobao.",
      "Chollometro team, right? Waiting for mine to arrive!!",
      "For the majority of customers, at least gamers, the drivers and value adds are good enough on AMD GPUs.\n\nNvidia's big market share is mainly due to brand recognition. The fact that some developers basically only work with Nvidia GPUs (hello CD Project Red) contributes to that.\n\nFor the informed user, AMD cards are amazing value. But the majority of users don't frequent communities as Reddit. They just buy the brand they know."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900xt"
    ],
    "title": "5900x, Sapphire Toxic 6900xt Extreme",
    "selftext": "",
    "comments": [
      "The incandescent bulb light color looks really neat",
      "Deus Ex vibes.",
      "OK, wow. First time seeing this AIO, and it is just beautiful. So is the GPU. \n\n10/10 build sir, well done!",
      "What fans are you using? I love the color you chose",
      "Lian Li AL120s",
      "Move aside RGB, we using BG now, black and gold",
      "In fact this is the first Toxic they made in years.  AMD finally has a gpu worthy of that brand.",
      "Thank you! Yeah this aio looks and performs excellently I'm surprised there aren't more reviews on it",
      "Could you provide me with the Hex for that color?",
      "It's the IN WIN BR36 360mm AIO with UMA Cooling Design https://www.amazon.com/dp/B096CBMD57/ref=cm_sw_r_apan_glt_fabc_9GBYEV0DKE25C788JRD9\n\nAnd the gpu has its own\n360 rad on the top",
      "Interesting question, found this page \n\n&#x200B;\n\n[http://planetpixelemporium.com/tutorialpages/light.html](http://planetpixelemporium.com/tutorialpages/light.html)",
      "Yes and it runs like a dream.",
      "God, the Toxic looks soooooooo amazing.",
      "Second this!",
      "Where did you hide the psu?",
      "What is that aio? Does it have dual 360 rads?",
      "OP reposted the pic, the previous post he said it was 255, 80, 0 in iCue",
      "Sapphire has been good with me when I had to RMA 2 times. First time, was quick and painless. I sent mine back and received one back. Second time, even quicker because I didn‚Äôt have to send my GPU back. They just sent me a new one. \nTurns out my GPU wasn‚Äôt the problem, so I had 2 good working 580s and I sold one to a friend.",
      "Makes sense. It looked like all four tubes were connected to the cpu pump/block. Nice aestethics in this build. I especially enjoy the coppery tint.",
      "No gfx card will ever be worth 2k"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900xt"
    ],
    "title": "Yesterday one person bought 79 x 6700XT and 14 x 6900XT during the EU AMD drop (no joke, with proof).",
    "selftext": "",
    "comments": [
      "I think that's the Dutch browser extension\n\nIt shares the unique queue ID between the subscribers, I saw that in many forums in the web since (at least) 3 months from now so I think AMD/digital river is well aware of that\n\nThat's the new era of scalping: scalp BEFORE the purchase",
      "That was patched months ago nowadays it's way more complex, the guy has thousands of instances open and the more people solve captchas the more different queue IDs are made, his script also has a priority list where people who haven't had a chance as much get picked first.\n\nI'm glad for his script as months of trying manually didn't lead to anything mostly because cards were gone in 2 minutes as the bots shared the same no queue ID but it felt scummy and most of the people in the forums where they discuss this are the scum of the earth\n\nFor those unaware one guy didn't farm 70 cards, those are divided by the people using a dudes paid script which has about a thousand users by now",
      "He sells subscriptions which gives people a position on his waitlist. You need to have PayPal to do this. Yesterday 93 PayPals bought a GPU through this system in 10 seconds making it nearly impossible for others to buy. Earlier this bot was succesful, but not this succesful now it's probably has become the only option if you wan't to buy a GPU from AMD in the EU.\n\nI say \"PayPals\" because there's a lot of people who sign up for this service with multiple PayPal accounts.",
      "Whoever thinks the same thing won't happen when the new gen is out, is out of his mind lol.\n\nThis is the future of pc gaming. Get used to it.",
      ">This is the future of pc gaming. Get used to it.\n\nOnly if people keep paying way over msrp for the cards. If the scalpers can't sell their product, they will stop buying it. Problem solved.",
      "So what you're telling me is that this guy has a better queue (at least from a consumer perspective) than AMD does?",
      "A year ago i subscribed by EVGA for a 3080 at msrp. Still waiting, and shops have plenty evga in stock. The reality is that manufactures want to sell fast at the highest possible price‚Ä¶ thats a part of the problem too",
      "Wouldn't he need a different address for each card?",
      "Except this mentality is part of why prices are still where they are, and if people continue paying the prices that's where it'll stay\n\nThe victims aren't the people paying scalped/inflated pricing (They can afford it) and are only paying the price due to their own impatience\n\nThe victims are those who can't afford the inflated prices and are priced out of PC gaming entirely",
      "people here can't get cards because of other bots and this kind of things\n\nDR must find a way to avoid that\n\nmaybe an early email subscription with lottery will be better than thousand of millions of people and bots going to [amd.com](https://amd.com) only in those 3 minutes\n\nif things will not change we will never be able to buy upcoming gpu",
      "Yeah definitely.\n\nSounds like his queue is super convenient and hassle free. Plus I think it's brilliant that customers who weren't able to buy a card the week before get increasingly higher priority the next round.",
      "This was always going to happen\n\nPeople have been paying scalped prices for years now, that is why scalpers are still here, they're opportunists, and they've been given this opportunity (They don't do it just because, they want to make money)\n\nAnyone who has bought from a scalper cannot be angry about this, because you helped create this situation in your own small way, And tbh it's your fault if you payed an inflated price because you chose to do it out of impatience \n\nThe actual victims are those who can't afford the inflated prices and cant build a PC now because they've been priced out",
      "this is what happens when AMD picks the worst unreliable partner to run theirs shop ...  \nfrom perspective of customer who attempted to buy anything via AMD shop in past 12 + months  \ni would never ever buy AMD product again ... so bad the experience was and is ...",
      "EVGA still has their queue and people have been waiting since launch to see their name pop up still",
      "It‚Äôs trivial to register a bunch of emails so scalpers still win in that case.\n\nIt‚Äôs not an easy problem to solve and no idea you came up with in five minutes is going to work, otherwise it would have been solved by now. It‚Äôs not for lack of trying, it‚Äôs really hard to do without some kind of external reputational signal. For steam, that signal can be your spending history and wallet, AMD doesn‚Äôt have that sort of data for you.\n\n(The one thing AMD/NVIDIA have access to that could legitimately be useful is driver telemetry data tied to your account but nobody wants to talk about that.)\n\nBut seriously, things that are not actually good ways to ensure one-per-person:\n\n* emails\n* credit card numbers\n* shipping addresses\n* billing addresses\n* names\n* phone numbers\n* ip addresses\n\nTime and again every baby redditor thinks they‚Äôve solved the scalper problem by ‚Äújust limiting one per credit card‚Äù or ‚Äúone per billing address‚Äù and they don‚Äôt realize the sneaker market tried that like 15 years ago and scalpers trivially worked around it and found a solution. This is big business, the people who sell the tools make hundreds of grand per year enabling scalping, they have worked around ideas you haven‚Äôt even come up with yet.",
      "Its been 2 years and everything still out of stock,i don't blame people for paying way over MSRP at this point",
      "Friend of mine got his 3080 yesterday from EVGA email listing, almost 9 months after he signed up for it.",
      "Definitely? How did you come to this conclusion because it definitely is not. He just doesn't have to deal with what AMD is dealing with. It does not solve anything: It's first come first serve and thats being botted as well. Of course once you're subscribed to his services you have a very convenient experience but that is not what you need to compare to the AMD queue.\n\nHe only let's about 50 people buy a subscription once every while (allthough he has strongly oversold because of technical issues). Combine that with a high successrate and yes, customers will be satisfied.\n\nIf this wasn't exclusive it would be the same mess AMD is dealing with now. The only thing he is doing is moving the issue from the AMD queue-it queue to the people paying him for a subscripion, he actually started using some \"bot protection\" himself because people (scalpers) want a subscription.",
      "I've been on there since later 2020. The cards I signed up for are discontinued so I guess I'm not in any sort of real queue anymore.",
      "This stuff is no joke - my brother-in-law quit his IT job to specifically do this with a few guys. Besides a combination of bots, they also take advantages of mistakes in services like shippd, and of course most store pick up employees are push-overs. They basically travel around FL, GA, SC, and NC collecting cards and then dropping them right outside the port of jacksonville to some russians in a container truck. I think it's ridiculously messed up and there is a special place in hell for him... but kind of fascinating."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900xt"
    ],
    "title": "Disabling Multi-Plane Overlay (MPO) fixed all desktop flickering/stuttering on my 6900XT",
    "selftext": "Been having flickering in varying amounts since driver version 22.2.2. The latest 22.10.3 improved the situation but it still came up from time to time (the Disney+ windows app was *especially* bad). Saw a mention of this being a fix elsewhere and tried it myself and suddenly.. everything is perfect.\n\nHere is how to disable it, courtesy of nvidia, where it *also* caused some flickering and stuttering issues: https://nvidia.custhelp.com/app/answers/detail/a_id/5157/~/after-updating-to-nvidia-game-ready-driver-461.09-or-newer%2C-some-desktop-apps\n\nThey provide a .reg file to make the change for you, but if you'd rather do it by hand the key is `HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\Windows\\Dwm`, create DWORD `OverlayTestMode` with value `00000005`.\n\nDisabling this *may* break some of the Windows \"fullscreen optimization\" stuff, but frankly that's always been kind of a nightmare anyway.",
    "comments": [
      "Thanks mods for not deleting this and threating this as tech support, this should really be stickied honestly until AMD and Microsoft fix this, probably more a Microsoft issue seeing windows 11 22h2 updates just got paused, altho if had blackscreens that disabling MPO fixes on 21h2 as well so its much worse then being reported probably by Microsoft.",
      "For anyone with a 6900xt and a 240hz monitor that would randomly get gray screens - this fix appears to solve that as well. I usually would get a gray screen within 45 minutes, but haven't for about 4 days now.",
      "On 6900 XT. This solved the driver timeout crash when I use Chrome as well. Thank you.",
      "This has reduced my flickering by like 95%.",
      "It's not from nVidia, it's a fix we used on nVidia GPUs too for a while üòÇ crazy if only Microsoft / Intel /nVidia / AMD all corroborated more on the software side of things, we might get much more out of all our hardware. But why do that, when they can sell us more of course.",
      "Maybe it‚Äôs time to switch to Firefox instead?",
      "Almost as if MS should allow us to disable desktop compositing fully.",
      "Three days so far on 22.10.3 from 22.5.1 after disabling MPO, I've had no driver timeouts or black screens no matter how much I threw at it. This is the longest I've gone error-free on anything newer than 22.5.1, this thread needs to be stickered.\n\nHALLELUJAH!",
      "That's actually been the final nail in the coffin for me when it comes to going with Firefox. That MPO issue drove me nuts as I thought that it was just AMD drivers being AMD drivers.\n\nTurning off hardware acceleration is not a workable band-aid at that. I was pulling my hair out from audio cutout when I watch youtube after doing that. I can now safely conclude that the whole thing about AMD driver sucks isn't really an excuse anymore.",
      ">while others, again using the same GPU and drivers etc\n\nThat doesn't even come close to covering all the possible differences.\n\nSome people for example fixed black screen issues by turning off their RAM overclock.   Just because an app crashes for some, and not others, could be hardware, but it could also be all sorts of other software.  MSI Afterburner for example was known to cause crashes for some.  Windows has bugs and features that are only active for some in some situations (e.g. only with multi monitor with different refresh rates but only if all support 10 bit color).\n\nSo \"one friend with drivers ABC and card X has the issue but the other does not\" is nowhere close to proving that it is bad hardware.",
      "the fact that the nvidia article is over a year old while AMD hasn't even been able to discover this issue for 10 months is like... bruh",
      "Just a warning, this is NOT a fix for everyone. I tried the MPO edit and it gave me intermittent screen corruption across all 3 screens. Like someone was fiddling with my display port cables, but it was across all 3 screens at the same time for 1 to 2 frames, then would dissapear.\n\nI was never getting driver timeouts, just the black screen flickering and video issues in other windows in chrome, what fixed me was using the #angle workaround in chrome.\n\nSince then, for me, its been perfect on 22.9.1, no issues AT ALL. Like zero. I have 2 sets of virtual desktops, one for work and one for personal stuff and games, hell i even accidently had hurtworld open in the background and then ran minecraft, still nothing.",
      "i read that in some other forums the other day.\nwhat EXACTLY is multi-plane overlay used for anyway? does someone know? what is the USE CASE",
      "I'm not a graphics developer, so this could all be way off, but my understanding is that it allows the creation of arbitrary render targets (planes) which can be displayed in arbitrary arrangements by overlaying them in the final display render. The advantage is that these new \"planes\" can be treated as exclusive fullscreen by an application without actually using exclusive fullscreen display modes.",
      "I found some use cases described here: [https://www.reddit.com/r/nvidia/comments/qffxcz/mpo\\_multiplaneoverlays\\_are\\_amazing\\_you\\_can\\_play/](https://www.reddit.com/r/nvidia/comments/qffxcz/mpo_multiplaneoverlays_are_amazing_you_can_play/)\n\nIncluding opinions from \"MPOs are amazing\" to \"MPO is pure garbage\".",
      "Well good thing we're talking about an issue affecting all Chromium things that use hardware acceleration then.",
      "It's 100% M$ fault.\n\nI haven't run in to this on my 6800 XT is it unique to 6900 XT?",
      "As if it was this simple. From Nvidia of all places, couldn't write it. Thanks OP",
      "I can confirm this. 6900XT. Dual Samsung G7 + another 60Hz screen. Would get gray screens about every 20 minutes because I alt-tab a lot.\n\nTried this fix and to make things worse I enabled hardware acceleration in both firefox and chrome. Haven't had a single issue for 4 days now. ZERO gray screens!",
      "What about Zoom, Teams, Skype, vscode, Steam, Epic Games Launcher, GOG, Discord?"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900xt"
    ],
    "title": "went a bit over board and now have the 6900xt paired with the 5950x.",
    "selftext": "",
    "comments": [
      "Overboard would be getting a vertical GPU mount.",
      "That's one way to suffocate a high end GPU.",
      "what's the rgb strip under the graphics card? built-in to the case or something else?",
      "If it could fit I would lol.",
      "Decent config for browsing the Internet.",
      "I had a vertical mount on my Strix LC 6800 XT but after upgrading from a B450/3700X to a B550/5900X I had to get rid of the vertical mount because it was pcie 3.0. They now have 4.0 extension cables and been meaning to get one. The Strix LC was made to be mounted vertically imo.",
      "Yea I think that's the move. Gonna return the 5950x for the 5800x to get $400 back.",
      "It would be a bracket so the fan won't be all up on the glass. But either way it's not happening.",
      "Great question! It's cooler master's rgb anti sag bracket.",
      "The 5950x was certainly an impulse buy. Still in the return window and debating if I should get the 5800x since my rig is primarily for gaming. I do on occasion edit large amounts of photos with lightroom and photoshop when I shoot weddings a few times a year. Maybe the 5900x is the sweet spot. That's why it's still kinda hard to get.",
      "Least powerful reddit PC",
      "Light room and photoshop don't really take advantage of the 5950X in the same way that video editing or music production would, so you might not even find a substantial difference between the 5800X and the 5950X in your workflow.",
      "Looks good man. I'm finding myself wanting to upgrade my 3700x to a 5900x but I think I'll wait for the XT refresh.",
      "Overboard would be going Threadripper pro on wrx80 or trx40. 16 cores is for peasants.",
      "Absolutley magnificent!",
      "It's no match for chrome though.",
      "thats a funny mesh front",
      "Thank you! It helps with airflow. Of course now they offer the 510 air version.",
      "It almost keeps up with roblox.",
      "I'm sure if I kept the glass front my rig would blow up! Lol! During my usual games both CPU and GPU are very low 70s average."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900"
    ],
    "title": "All AMD ITX build, Ryzen 9 5900X + Radeon RX 6900 XT OC Formula",
    "selftext": "",
    "comments": [
      "This makes me want to build a mini. Good job üëç",
      "/r/sffpc \n\nHere is some more influence to get you to spend way to much money on a PC.",
      "Is that an eInk display? Looks like no backlight, but very clean.",
      "Correct! It‚Äôs a xiaomi e-ink thermometer",
      "Parts:\n\nCPU: AMD Ryzen 9 5900X\n\nCooler: Thermalright Peerless Assassin 120 White ARGB\n\nMobo: Gigabyte B550i v1.1\n\nMemory: Gskill DDR4 Samsung D-Die 16G DR.\n\nGPU: Asrock Radeon RX 6900 XT OC Formula\n\nCase: Sama IM 02 white tempered glass.\n\nPSU: Corsair SF750\n\nFan: 4x Thermalright ARGB White.\n\n&#x200B;\n\nWorks pretty well together",
      "I went on that sub a few times, ended up buying a meshlicious and built another PC.\n\nSlippery slope lol",
      "whats that inside clock part called and where can i get something like that",
      "is that ram stick slightly bent?",
      "It's good, I tested with power meter on desk, full blown overclock of this 6900 XT under 3dmark Time spy is 620w.\n\nBeware its AC outlet reading, so the actual psu DC load is about 90% of it, thus 550w max. SF750 is build with around 950w transient power burst thus no problem to handle occasional spike.\n\nGiven games usually less demanding than Time Spy, and I'm under volt it with just 450w tops.\n\nmanufacture just want your psu not the last straw to cause problem because you never knew if the people buying your card gonna use on a Gigabyte garbage tier smoking one or top tier 80+ Platinum one.",
      ">degrees freedom\n\nIt use mijia home app through bluetooth control, app can change F or C and read historical charts of temp. you can check this video I was watching before purchase: https://www.youtube.com/watch?v=1WoIXFl3pQk",
      "Kinda looks like you built a PC and had no money left for a monitor lol",
      "So it is possible to fit a 120mm CPU cooler in an ITX case.",
      "It‚Äôs a Xiaomi Mijia Thermometer E-ink display I bought from aliexpress",
      "It's actually not an NR200. It's a SAMA IM02 (at least in the US, it's sold under different brands in different regions). I just built my cousin a PC in it yesterday. Honestly think it is the best gateway to SFF PCs, though many would say it doesn't count since it is 21L.\n\nThe case is relatively cheap (I got it for $60 on Newegg) and supports mATX motherboards and ATX PSUs, so you don't have to pay the SFF tax and can reuse parts from your previous build.\n\nThe one grip I have with it is there is effectively zero space behind the motherboard tray.",
      "Stunning!",
      "I believe it's the impression given by the LED strip's shape of the ram sticks. Looking below the base seems to be in the clear.",
      "that is a super beautiful ITX set up. mine doesnt look nearly as nice xD",
      "It's perfect. The OC Formula is such a sick card, and looks like a perfect fit!",
      "Is the Sf750 enough to power the 6900xt and 5900x?\n\nI'm thinking of moving my 6900xt red devil ultimate to my SFF build but can't find a suitable PSU since powercolor suggests >900w lol.",
      "That's very very broad but for this particular case (nr200) yes some 120mm air coolers do fit like this one, but not all."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900xt"
    ],
    "title": "5800x / 6900xt Liquid Cooled (AIO) Strix AMD Build *Red Glory*",
    "selftext": "",
    "comments": [
      "and they say money can't buy you happiness...",
      "Whoever said that must not have known anyone with an expensive hobby",
      "You ever see a sad person on a jet ski?  I rest my case...",
      "Ryzen 7 5800x, Strix B550-f Gaming Wifi, Strix 6900xt Liquid Cooled, Strix 360mm AIO CPU Cooler, Tforce 3600 CL18 (4x8GB), Cooler Master Cosmos C700P Black, Samsung 980 500 GB M.2 / Samsung 970 Evo 1TB M.2, ROG Thor 850w 80+ Platinum PS",
      "Looks hot",
      "that one guy from tiger king.",
      "I think they make nice hardware but I have no specific brand loyalty lol. My original Corsair CPU cooler was broken out of the box, RMA was going to take weeks and due to Covid I was unable to go to a store and get another one. The Strix one was available on Amazon. Originally wanted a 3080 but no luck there, this 6900xt fell into my lap through a friend and it was MSRP so I just grabbed it. The power supply which I originally purchased was a corsair 750w which had to be returned due to it not meeting the minimum requirements for the GPU. Kind of a shame the Thor power supply is hidden behind that shroud but oh well lol.",
      "You must really like Asus Rog products, but apart from that, looks real nice. That vertical gpu, especially with that specific model, just brings the build together nicely.",
      "*OUR* Glory",
      "Lol thanks. Kind of annoying the picture makes it look orange but it's a much darker red glow in person. And the tempered glass side is slightly tinted making it a bit darker.",
      "Thanks! The funny thing is this was not the original plan but due to unavailability of parts and a little luck this is what I was able to get. Took me 5 months to collect these parts without having to buy anything from scalpers.",
      "It was right around $5000 Canadian dollars. I'd have to ask my wife for the exact amount but she left. Lol jk but yeah I went over budget.",
      "$1699.99 in Canada",
      "Perhaps that's why I'm never happy with my PC.\n\n...or maybe it's just my monitor not being very friendly to my eyes",
      "I watched the Jayz video and gamers nexus about rad orientation and while i agree the hoses down setup is clearly the better option, as long as the rad is higher than your pump in a hose up situation it shouldn't be an issue. I was wondering how long it would take for someone to comment on that lol. Thanks!",
      "Lmfao, you're not wrong",
      "I bought an HDMI adapter to use my old VGA LCD monitor instead of the laptop screen. Best thing I've made so far, despite the lower resolution and color accuracy, the bigger size and overall clean look of my desk made the change worth it.",
      "Monitors are pretty inexpensive.  No sense in settling for mediocre when it is arguably the most important part of your rig.",
      "well I admire your dedication to not paying scalpers, and also patience",
      "That's a really nice looking rig, clearly thought out"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900xt"
    ],
    "title": "5950X-Red Devil 6900XT under water",
    "selftext": "",
    "comments": [
      "I'm a simple man, i see a red team build, i hit upvote !",
      "*Darth Sidious Voice* Good! Good!",
      "Bro, you Red Devil you. This is a computer I dream about, enjoy it!",
      "My man, appreciate it!",
      "Very nice my dude! The whole thing is on point, but great move with the clear liquid and the subtlety of the red next to (under?) the mostly black cables is chef‚Äôs kiss for me. I did red/black alternating sections with my 6800xt midnight black / 4000D blacked out build and I often think about going for all black sleeves. Great!",
      "Let the coolant flow through you",
      "Thank you. And nice job on getting that Midnight 6800XT, probably the best looking GPU from AMD, ever. I know lots of people think red and black builds are played out, but just can't get away from going red. And funnily enough I've contemplated going with the red and black cables often.",
      "Your RGB has made you powerful.",
      "Thanks! And the liquid temp stays under 30C, so the air isn't hot or anything.",
      "Clean af bro, i hope it serves you long and well brother ‚ù§Ô∏è‚ú®",
      "Thanks, and I suppose I should have done that from the start.\n\nSpecs: 5950X@4.9GHz CCD1, 4.7GHz CCD2  \nRed Devil 6900XT@2650/2750MHz, 2150MHz w/Fast timings  \nROG Crosshair VIII Forumla  \n32GB Trident Z 3800MHz CL14  \nHX1000i PSU w/CableMod Pro Carbons  \nThermaltake View 51 case w/ML120 Pro  \nEK Quantum Magnitude Acetal AM4 block   \nAlphacool Eisblock Red Devil block  \nEK Kinetic D5 Pump/Res  \n360x40mm top and bottom rads  \n360x55mm side mounted rad",
      "I cant get my pc to look good with rgb. Any tips?",
      "Kind words my man, truly appreciate them. The plan is to keep rocking this one for a long while.",
      "I usually keep my hardware awhile. Still have a 3950X/1080Ti office build, and my daughters rocking my old hardware as well.   \n\n\nSpecs: 5950X@4.9GHz CCD1, 4.7GHz CCD2  \nRed Devil 6900XT@2650/2750MHz, 2150MHz w/Fast timings  \nROG Crosshair VIII Forumla  \n32GB Trident Z 3800MHz CL14  \nHX1000i PSU w/CableMod Pro Carbons  \nThermaltake View 51 case w/ML120 Pro  \nEK Quantum Magnitude Acetal AM4 block   \nAlphacool Eisblock Red Devil block  \nEK Kinetic D5 Pump/Res  \n360x40mm top and bottom rads  \n360x55mm side mounted rad",
      "Clean AF.",
      "Looks great !\n\n...but .. aren't you blowing hot air off of the bottom RAD back into your setup?\n\nPotentially causing issues if RAM and VRM's get too warm? ..and/or negating some of your overall cooling ..?",
      "*Darth Sidious Voice* A powerful PC it shall become! I dub thee, Darth Peecious! Lord Peecious... Rise!!!",
      "I am using an O11 Dynamic XL, and I started naively by having all three rads sending air out, that the case was completely air starved to the point where temperatures would climb to +22C over ambient water temps.  \n\n\nI reversed the side rad fans to blow air in (now my HDDs are actually running lower temps too), and installed 3x Noctua NF-A14s at the front, and everything is fine and dandy.   \n\n\nWhat are your CPU temps in games that use CPU a lot and get high frame rates? The worst offenders for me up to now were Dragon Age Inquisition and Far Cry 5, and I'm at around 79C for the best two cores and in the 40s -60s for the rest of the cores. The 3090 has a big die so it stays at the 48-50C range, and even the hot spot doesn't climb above 60-62C.\n\nWhen AMD moves to 5nm they need to think of something for the tiny really hot spots these CPUs get.",
      "No issues, loop idles in the mid 20s, CPU and GPU idle right around that. Gaming temps the CPU is usually in the 40s-50s and GPU in the mid 30s.",
      "Too poor to up vote this"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900xt"
    ],
    "title": "Went to the red side. AMD 5950x and 6900xt",
    "selftext": "",
    "comments": [
      "You my sir are a mad lad. This is like the dream of every AMD fanboy gamer. \n\nAlso a very clean build, not my favorite color scheme but this build still looks amazing!!",
      "this is essentially an upgrade from my first PC build. started with a 3060ti and a 3700x\n\ncurrent specs:\n\nCase: Fractal Design Meshify 2\n\nCPU: AMD Ryzen 9 5950x\n\nGPU: Asrock 6900xt Formula OC\n\nMOBO: Asrock B550 Taichi\n\nRAM: Trident Royal Z 3600 CL16\n\nAIO: Phanteks Glacier One 240mm\n\nStorage:\n\n\\-Seagate Barracuda 2tb HDD\n\n\\-500gb Samsung Evo970 NVME\n\n\\-1TB Samsung Evo970 NVME\n\nSensor Display:\n\nGoverlay 3.5\" display\n\nFans:\n\nInwin Sirius Loop\n\nFractal 140mm case fans\n\nPhanteks 120mm MP fans for AIO\n\nRGB:\n\nPhanteks neon digital rgb strips\n\nPhanteks halos fan frames",
      "Looks Amazing!",
      "appreciate it! \n\nand I know its not for everyone.  Not completely happy with this fully, still trying to find something that I like for an everyday.",
      "What game or new monitor caused you to want to upgrade? Your old system handled everything already.",
      "I don't know. Just the hobby of it I guess.  I guess it's the same feeling as why mod your daily driver car to be faster. I didnt know what my end game was for my pc but I've Def got there.",
      "I upgraded from a 3700x to a 5950x *just because I could* (and I got it for msrp without even trying)\n\nI probably could‚Äôve gotten 10 years out of that 3700x with zero complaints‚Ä¶..",
      "some may say maybe too much...",
      "$2,000 for the cpu and gpu alone, unless OP somehow snagged the 6900xt for MSRP.",
      "thats the same exact boat I'm in and not even mad about it.",
      "inwin sirius loop",
      "You are welcome.\nBut if you are not fully happy with it, I take it happily  lol (joking ofc).\nMaybe the background on the display could have a more fitting design?",
      "Not red. More like neon purple mostly I looked at a lot of blurry neon like RBG.. This seems the most popular.",
      "yeah, I know been messing around with a few other stuff.  Its pretty much what I've settled on for right now. but still tinkering.",
      "How much does this system cost?",
      "What fans do you have? My favourite colour scheme is neon pink blue and purple so i just love it and these fans have really nice colour! Also that LED stripe at the bottom, looks very nice and very clean!",
      "thanks for the info about GOverlay. Never knew something like that existed. That will be a neat add-on to my build :)\n\nNice job on the build BTW",
      "goverlay.com",
      "Fractal meshify 2",
      "Well actually not, but at least it settles down to a certain point. I am wasting more time with configuring it than actually doing work on it lol"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900"
    ],
    "title": "6800 XT with 6900 XT/3090 Performance. Higher clocks do not always mean higher scores!",
    "selftext": "",
    "comments": [
      "TUF Asus Gaming Radeon Rx 6800 XT AMD Wattman Settings\n\n* GPU Clock Speed: 2350-2450 MHz\n* GPU Voltage: 1100 mV\n* Memory Timing: Fast\n* Memory Frequency: 2150 MHz\n* Power Limit: 15%\n* Smart Access Memory: Enabled",
      "Try 2120 on the memory. The VRAM automatically loosens timings above 2124 MHz, so you want to stay below that.",
      "6800XT is low key in the shadow of the 3080/3090 tbh. But it's a silent beast! Nice!",
      "vanish worthless wise frightening wide grandfather file point jellyfish spectacular -- mass edited with redact.dev",
      "Man I love my 6800xt but missing out on ray tracing and dlss kills me sometimes",
      "Is the same true with the 6900XT as well, do you know? Or is this just the standard enforced product segmentation in effect again?",
      "Nice, I'll see if I get a boost that way. I also haven't tried lowering the voltage even further, so I think I can get even more performance that way. I'll give this a shot when I get home from work and let you guys know how it goes! Let's see how far we can take this card!",
      "Mine clocked itself aroud 2730 mhz or so sometime.\nAll i did was undervolt... there was some artifacts, limites it to 2675 mhz and never had artifacts after this. Also saw some 327 watts consuption LOL. Now i limited it to 180 fps, consumes about 225 watts average whatever i do lol.",
      "only really in terms of ray tracing and 4k.\n\n&#x200B;\n\nif you're not on those trains, then its blow for blow pretty much and the 6800Xt is slightly ahead.  if you're into ray tracing and 4k, then its an obvious loss.\n\n&#x200B;\n\nnot sure why the 3090 is mentioned, it's not a competing card.",
      "At least it can run raytracing even if it's not amazing at it. If some super crazy RT game comes out there's the option to tweak settings until it's satisfactory. The 5700XT was the true dead end card since it offered great performance per dollar but lacked any future proofing.",
      "Yeah I noticed something funny with my gaming PC when I was tuning it for nicehash. Anything over 2120 on the memory was causing it to lose performance which I thought was weird. Your explanation would explain why",
      "Plenty of people would love to get their hands on a true dead end card given the insane inflated bubble we are in.",
      "All of us don't care about unrealistic benchmark scores either.",
      "Just picked on up a few weeks ago. They're a beast of a card. Ulgraded from a 980ti.",
      "dlss sucks in a lot of games man. 3090 here and i find dlss in cyberpunk unbearable, blurry mess even on quality. Ray tracing also feels like a single graphical setting, you turn it on and have to look for it. Most scenes in cp2077 are identical, but shiny glass is reflective. I painstakingly went back and forth in various areas turning RT on and off‚Ä¶long story short, youre missing very little. Check YT comparisons if you dont believe me\n\n\nIts not world shattering stuff. I firmly believe marketing has planted a seed in peoples heads its world shattering, and it really isnt yet. Amazing what adverts can do tbh, especially for cp2077",
      "It is. I have my 6900xt same settings",
      "The trick is to find settings where the card does not permanently hit the power target limit of 293W. My card's sweet spot is 2560 MHz @ 1030 mV and mentioned memory settings. The power consumption in Time Spy is  around 285W, the card constantly boosts to 2500 and my graphics score is well above 21,000 while my hot spot temp is below 95c (reference card). Since you have an AIB card and a Zen3 CPU, you should get even better results.",
      ">1.1V\n\nThat's a (very slight) undervolt too right? It's nice when you can get so much extra performance without having to worry about heat or voltage whatsoever. I have my (reference) 6800xt running at 1025mV with a cap of 2400mHz, but it generally stays in the 2200-2300 range (for power budget reasons I think).",
      "3090 is also double the price.",
      "It's your Motherfuckin cake day!"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6950"
    ],
    "title": "My first AMD card, Power Color 6950 XT to replace my old 1080.",
    "selftext": "",
    "comments": [
      "6950 XT makes most sense right now, congrats!",
      "Great looking build and awesome GPU! Just a little advice I would not use pigtail pcie cables with that high end of a GPU that draws a butt load of power. You have a decent PSU but you need to use a dedicated cable for each 8 pin connection and if you dont have that many pcie connections coming from your PSU you need to get a higher rated one that does. At the least you can lose performance (been shown on Jayz2cents and BuildZoid's channels) and at the worst you can damage your GPU and PSU.",
      "At 635‚Ç¨ was the best deal possible right now.",
      "Indeed, had some watercooled ones locally for 599‚Ç¨, was really tempted but kept my 6800 XT.",
      "This. 6950xt owner here it pulls over 400W at times.\nGet rid of that daisy chain ASAP if you can.",
      "I wasn't able to use each individual 8 pin cable because i only have two of them, but i'm gonna order 3 cablemods.",
      "Welcome to the gang. It's a beast",
      "They can pull so much more than that if it‚Äôs a good power supply. Corsair only use 2 for their 600w cable.",
      "With OP's Seasonic PSU, I wouldn't worry at all - it's built for this!\n\nLarger diameter cables and a matching internal design [single rail(!), bigger caps to handle transients, higher rated mosfets, thicker cables] make sure that drawing 300W and more over that daisy-chained cable isn't a problem. \n\nThe \"weak points\" are the connectors and those are also what's rated for those 150W each.\n\nHowever, an 8pin EPS is built the same when it comes to the physical pin design, i.e. thickness of the metal and contact area (only difference: EPS uses 4 12V pins instead of 3), is rated for 336W and regularily pushed higher in servers. Accounting for having one 12V pin less, a PCIe 8pin is still good for at least 252W.\n\nParticularily in OP's case, these two cables with 3 connectors can definitely and comfortably provide enough power for the GPU, AND have some headroom left. In cheaper built and multi-rail PSUs, having more cables is needed, but not here.\n\nI have also verified this with my HX850i by pushing a Vega 56 to 360W ASIC and now with my 6800XT. Performance difference: zero. EMI is reduced by using more cables though.",
      "Awesome! I would refrain hitting your GPU with a heavy work load until you get rid of that pigtail. From what users like the other commenter have noted 400W power draw from there 6900/6950xt's. The max rating of an 8 pin pcie cable 150w/12.5a, so with only 2 cables the most you can safely pull is 300w so you really need that 3rd cable stat!",
      "5800X3D with 32GB RAM CL14",
      "I've already undervolted miny, 1.1v with 2500mhz min and 2600mhz max. Great perfomance and it peaks at 320w.",
      "Check out Ancient Gameplays on YouTube. He's got a great beginner OC guide for the 6950XT. Are you using it for 1440p or 4K?",
      "$599 right now at Micro Center in the US, for the AMD model",
      "Awesome. Tick on the memory timings to Fast Timings too ‚Ä¶ it really gave me a nice boost in performance in benchmarks.",
      "Does not included tax. With purchase of any CPU processor. \n\nThey've been running that promo all summer long but the previous markdown was $650 (from $699).\n\nAlso in-store only\\*\\*\\* which is the standard for most things at Micro Center.\n\n&#x200B;\n\nIf you've never been it's literally heaven, but hell for your wallet.",
      "What CPU are you using bossman?",
      "Same cooler if it's the Arctic Liquid Freeze II. Except I did push pull. Slick build.",
      "Nice. That‚Äôs what I did too. You are going to love that card. Mine really loves an undervolt‚Ä¶ I can get it down to 300-320 watts without any real loss in performance FYI. Enjoy it!!",
      "Time Spy Extreme Graphics Test 2 will give you the most realistic max stress test on RDNA2. \n\nIf you're pulling 320W then it's not max stress. My MPT unlocked Red Devil pulls 550W at 1.164v (and was happy doing so with a Corsair SF750 with the 2nd & 3rd 8 pins pig-tailed)."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900"
    ],
    "title": "R9 5900X / XFX RX 6900 XT",
    "selftext": "",
    "comments": [
      "Oh shit, I‚Äôm sorry!  \n\\- Sorry for what? Our daddy told us not to be ashamed of our amd cpu and gpu, especially since they are such hot and need water cooling  \n\\- Yeah, I see that. Daddy gave you good advice!",
      "looks really nice, that XFX radeon card really looks good, wish I could get my hands on one. Is this your first watercooled build ? \n\nWhich way does the fluid flow out of the pump, is it going into that bottom rad first ?   \nOr is it hitting the right Monoblock inlet over the CPU first ?",
      "You clearly haven‚Äôt done a custom loop before . Been a part of and making custom loops on customers pc since 2007, and none of what you are saying is alarming and does little or nothing to the loop. If you want problems you do hard tubing .",
      "It gets hotter when I pull on it",
      "It would be if there was actually a problem. They've clearly never done a soft rubber water-cooling setup. Those ribs are longer than they need to be relative to their components, but they're not *long*. There's no risk here.",
      "No the dumbass you were commenting about",
      "That pump must be pretty powerful for 2 radiators in those positions",
      "Please do elaborate",
      "Is that cooling solution cum or monster energy zero ultra.",
      "Those sagging pipes are a very bad idea.\n\nSpeaking from experience...",
      "dangling your res over your gpu is more than i can handle",
      "You can get them at MSRP on Amazon (NE has them for that price as well):\n\n[XFX 6900xt at Amazon](https://www.amazon.com/XFX-Speedster-MERC319-Graphics-RX-69XTACBD9/dp/B08SVZNFWR/ref=sr_1_3?dchild=1&keywords=radeon+rx+6900+xt&qid=1635115253&qsid=132-8471457-8571065&s=electronics&sprefix=radeon+%2Celectronics%2C104&sr=1-3&sres=B08SVZNFWR%2CB09258PCFS%2CB08Q2R71CS%2CB096M7NPNP%2CB094DYSQQL%2CB08R81J62G%2CB093NBMV17%2CB093N3Q96N%2CB08R6M3JPS%2CB08W2GPR62%2CB08S6Z2HGW%2CB097FYBRXH%2CB083HZ3M1X%2CB09257F463%2CB08ZFYDH66%2CB097YWV6VP%2CB08QQFW9YS%2CB08Y934HZQ%2CB08TJ2BHCQ%2CB0966YJGLT&srpt=VIDEO_CARD)",
      "\"MSRP\" used to be $1400, which is what I got mine at..",
      "case ?",
      "Yes.",
      "He linked the Merc Black edition, which is like the XFX equivalent to EVGA's Kingpin line. They're extremely highly binned. If you managed to get the Merc Black for $1,400, though, then lucky you :D I paid about $1600 for my Merc Ultra (one step down in binning) back in January.",
      "Seriously wtf is this dude talking about and why has he been upvoted.",
      "I started with r/watercooling, spent a lot of time on EK, watching yt videos of cooling systems, checking out overclocking for their set ups (even though I've never been into OCing, shared setups). \n\nI also have an engineering degree and did very well in fluid mechanics, so the theory behind each part made sense and I can work out ideal rates for my loops, compare them to the measurements of my loop and empirically determined where I can improve it. \n\nI've stopped actually building WC loops because it's a lot of work and I'm lazy.",
      "Major gpu sag and three of the tubing runs are way way too long. Need to clean this up.",
      "[XFX Speedster Zero WB](https://www.newegg.com/xfx-radeon-rx-6900-xt-rx-69xtawbd9/p/N82E16814150863) \n\n1800$, take it or leave it."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900xt"
    ],
    "title": "AMD Radeon RX 6900XT drops to $630 for Black Friday - VideoCardz.com",
    "selftext": "",
    "comments": [
      "**Still no way near as good as 6800 XT for 515$ on Newegg, though.**\n\nRemember - the initial MSRP of 6900 XT was horrible compared to the 6800 XT which was almost just as good for 350$ less, do not let that fool you.",
      "Yeah BF prices have mostly ignored GPU's in Europe this year outside of small discounts here and there.",
      "It would be a great 1440p card too my man",
      "meanwhile the 6800 XT here still costs almost 800‚Ç¨",
      "I was really expecting some killer GPU deals this Friday since the new gen is coming but...zilch, really.",
      "Got the 6800xt and am very satisfied of my purchase. As a 1080p gamer, I don‚Äôt need more.",
      "Not worth the performance per price. Better get a 6800 xt or just wait for rdna3.",
      "Yeah. I'm here like... What the fuck.",
      "I mean there's XFX 6900 for 750‚Ç¨ on Mindfactory.de, and that's about right when you account for import taxes + margins for the store.",
      "That just shows how much profit they're making on us.  I can't imagine they're selling these at a loss.",
      "Personally, I believe 1440p + High is much better than 1080p + Ultra/RT, but to each their own.",
      "There is no national sales tax. Every state, country, and city picks their own sales tax rate, combining to a range of 0%-10.5%.  Most people live in areas with a combined rate around 7-10%.",
      "6800XT at 1080p? What do you have like a 480 Hz monitor or something?",
      "Meanwhile 6800xt 1k+ in canada",
      "‚Ç¨750 is ‚Ç¨635+VAT (=$660+VAT). So only a minor difference in price.",
      "Not to play politics, but the relatively low sales tax that the US enjoys come with a whole host of trade offs.\n\nIt's up to you whether you feel like the trade is even. I personally do not. \n\nAnd this is coming from someone with two expensive hobbies (PC gaming and MTB'in) and only average income ($50k a year or so).",
      "These are AIB cards so most likely they are selling at a loss.  They have no choice since the price will go even lower once 7900 cards drop.",
      "I would wait. It's not far off. The 7000 series GPU launch will force the 6800XT lower. Finding that for under $450 would be awesome. 6900XT under $600 would be good for the price per performance if 6800XT doesn't drop below $450",
      "Dumb question, but how much tax is on that when you buy it in the US? Because you can get a 6900XT for 750,- ‚Ç¨ and that includes sales tax.\n\n(https://www.notebooksbilliger.de/asrock+radeon+rx+6900+xt+phantom+gaming+d+16g+oc+grafikkarte+699111)",
      "6900xt has regularly been going on sale for $799 in Canada. \n\nhttps://reddit.com/r/bapcsalescanada/comments/z3uiv3/gpu_asus_tuf_gaming_radeon_rx_6900_xt_top_edition/"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6950xt"
    ],
    "title": "Upgraded from a ryzen 7 2700 and a rx 590 to a 5800x3d and a rx 6950xt",
    "selftext": "PC case and psu were also changed cause that 6950xt is a big boi.Pretty satisfied with how it turned out (except for those pcu cables being the way they are).I'm loving that I can still keep alive my am4 motherboard with that 5800x3d.",
    "comments": [
      "What ya gonna do with all that power, all that power inside that tower? üé∂",
      "Ima git git git get you frames, get you frames inside yo games",
      "My bump, my massive framerate bump, so smooth, no tear no jump...",
      "My fans are spinnin'. Check it out.",
      "CO for the 5800x3d helps with temps. \n\nI have the ezdiy U bend power adaptors for my 6900xt,makes clean cable paths easier.\n\nI started with 3600x, nice work milking 2700 this long and keeping AM4, I can't see any reason to upgrade soon.",
      "That‚Äôs a beastly upgrade my dude! Enjoy",
      "Thank you very much ! I'm indeed enjoying every moment of it.",
      "Definitely a good combo, I rock the same but with the red devil gpu. How's the temps with that air cooler? Got a 240mm aio before and never had issues.",
      "You're ballin' now Big Dog.",
      "To be honest I wasn't aware about curve optimiser(I hope that is what you meant)  ,will definitely give it a look.\nAlso about the PSU cables at first I gave a look at the cablemod site but 60‚Ç¨ for a combined 2*8 pin cable was a bit too much for me ,the u bend connector on the other hand seems like a pretty good alternative.\nAnd yeah the 2700 has served me well not a single complaint about it as you said I will not be needing any upgrade soon.Thanks for the info man!",
      "If we are talking about the 5800x3d idle is about 35¬∞C and  max temps  while gaming is about 72¬∞C but generally it sits around 65-70¬∞C,I haven't tried a lot of games (mainly god of war and warzone 2)so I have still some testing to do .The only lets say \"annoying\" thing is that on not constant load(lets say I just opened some tabs on chrome ) the fans ramp pretty aggressively but I guess that is a fan curve issue and not so much a CPU.",
      "nice!\n\nfrom a 5800X3D and 6950XT  fellow owner",
      "Curve Optimiser. Many of us can use -30 on all cores with 5800x3d as the silicone was cherry picked for the 3d cache. poorer heat dissipation but the best chips.\n\nJust the U bend adaptors, I don't go in for showy hardware, but the adaptors are a cheap way to get good cable management.",
      "All of you deserve medals... or an award or some shit.",
      "I just got a 5800X3D after my 5800X died. Do yourself a favor and follow this guide: https://github.com/PrimeO7/How-to-undervolt-AMD-RYZEN-5800X3D-Guide-with-PBO2-Tuner/blob/main/README.md\n\nMy temps are down by almost 12c, my PC is stable, and I'm still hitting max boost.",
      "I'm on a 5600x and 2080 super. I'm also going to with a 58003d and probably a 7900xtx at some point.",
      "I‚Äôm doing small upgrade from a 3600 to a 5600x on a 3060 ti.",
      "THEE value upgrade at the moment. You really dont need more at the moment imo, and i rock 2k ultrawide. Enjoy the buttery-smooth frames my friend",
      "2700x gang checking in",
      "Congrats"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900"
    ],
    "title": "This has to be my favorite AMD Radeon GPU. The RX 6900 XT Halo Infinite Edition! This is number 35 of 117 and I have a very awesome Halo Themed PC centered around this GPU!",
    "selftext": "",
    "comments": [
      "The only way to buy one is off of eBay. Since this card was only released as a giveaway item they were never offered for sale except for the ones that one it putting it on eBay :)",
      "Where does one buy these cards? honest question. Its awesome!",
      "I post stalked you just now and I see some of your other builds (eva etc)... do you have pics of your full Halo build?",
      "I have not done it yet actually :) still collecting all the parts to do it to be honest",
      "Thats a good deal for this limited edition, cheers!",
      "This one cost me $1200",
      "Well, if it makes u/PidgyPCs happy, then that is all that matters.",
      "great looking GPU, no fucking way I would've paid 2k",
      "Shiny",
      "Dang, how much did it run ya? If you don't mind telling.",
      "Thats what I said too! Salut",
      "‚ÄúBury my body, do not build any monument, keep my hands outside so that the world knows the person who won the world had nothing in his hands when dying‚Äú.  ‚Äì Last words of Alexander the Great.",
      "It does! I feel the $1200 was worth it :)",
      "neat! $1200 is still pricey, but as you say is an actual limited edition",
      "Exactly! Not sure if its the rarest GPU out there, but it says something with only 117 ever released LOL",
      "I didnt pay quite that much, I got this one for $1200 which is actually the most I would have spent for it. I find it worth it though to have 1 of few. If you look at my profile, I am not a stranger to Limited Edition products :)",
      "Ayy I‚Äôve got one as well. Love the card so much",
      "Right lol",
      "Be sure to share it with us when you do, Merry Christmas üéÑ",
      "It really is so cool!"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900xt"
    ],
    "title": "6900xt thermal paste swap.",
    "selftext": "",
    "comments": [
      "Thermal Grizzly kryonaut extreme, dropped me 20¬∞c and got me back to number one on 3DMark.",
      "Such a beauty. The pink part is the best",
      "Yeah the original mount may have been bad but all I did was remove the cooler, replace the thermal paste and reassemble.",
      "20???",
      "Wow, that's crazy tbh ahah",
      "Yeah MSI fucked the mounting again this gen. No wonder its so high temps",
      "Yeah I know I was hitting thermal limits trying to get to number one on 3DMark so thought I'd strip it down. It's the MSI gaming z trio so has the unlocked core.",
      "I got a MSI 6900XT Gaming Z and considering what it cost the thought of taking it a part is pretty shocking so bravo from me.",
      "Swapped with chewed bubble gum?",
      "All proven bullshit by gamers nexus, there's such a thing as not enough, no such thing as too much as for manual spread on CPUs and GPUs it's the way all the top hall of fame overclockers do it so I'll stick with the record holders as what's good practice.",
      "Honestly it's really easy worth doing it you want to OC as I was hitting junction temp limit.",
      "I used Conductonaut a few years back on my ryzen CPU, 2 months after application it decided I had applied too much and leaked onto the motherboard and gtx 1080. \n\nI have learned my lesson and stick with non conductive now.",
      "Well, not a good QC job from MSI if the mounting was causing you thermal issues.",
      "It's pulling 340w benching.",
      "Manual spread is the best method.",
      "Kryonaut Extreme is pink\n\nNormal Kryonaut is not",
      "ü§£ no some of the best thermal paste there is.",
      "Once you've stripped down a GPU once, you won't think twice about doing it again, it's quite fun and satisfying making your card run better.",
      "So do people manually spread paste on GPUs? I know it was considered bad practice for CPUs in the past. \n\nFrom intel website,\"Incorrect manual application can cause air bubbles to form in the paste, which can negatively impact the thermal conductivity.\"\n\nAlso Intel,\"Too much reduces the efficacy of the paste, due to the metal surfaces being too far apart.\"",
      "Look at gamers nexus, Jayztwocents, kingpin for overclocking, Jayztwocents and gamers nexus have a lot of extreme overclocking videos with water and LN2."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900xt"
    ],
    "title": "Finally got into the AMD Sale last week and picked up the 6900XT!!",
    "selftext": "",
    "comments": [
      "999 for 6900xt is a steal love this card. Wait‚Ä¶‚Ä¶.msrp is a steal? Yup it is",
      "Congrats! The box and packaging of the 6900xt is just as lovely as the card itself. Enjoy!",
      "Isn‚Äôt this the one that looks awfully suspicious when the fans are spinning?\n\nEdit: https://youtu.be/FzBzBruvkMY",
      "$1,000+shipping and handling\n\nNormally I wouldn't have considered this card as the 6800/XT are better values, but the state of the GPU market has those cards still costing more than I paid for this one",
      "I have been trying this for the better part of a year and still no luck for me, I am starting to think the queue is fake and these are just the bot posts.",
      "I checked out the bot posts and AMD did an exceptionally POOR job of stopping them. For weeks on end they'd boast about being able to open _hundreds_ of sessions and game the queue that way",
      "Oh yeah the packaging was amazing!",
      "It's not a bug, it's a feature.",
      "They finally started implementing anti-botting measures in January and it does help. Demand from mining is also way down currently. The 6800/6800xt sell out in the first couple minutes once the queue opens, you won't get one of those unless you instantly get in the queue, but the 6900xt was in stock for 10 minutes when I got mine from a 10 minute queue. There were 6700xt in stock 45 minutes after the queue opened last week so don't just nope out if you get a long queue time. Odds of getting a 6700xt are very good and will probably be even better next week given stock levels are similar.\n\nYou can open a few different browsers and queue up once in each one and it's \"in-private\" option. Don't refresh the page too quickly or you'll get softbanned when checking for the pre-queue to start. Scalping a 6700xt isn't worth it once you figure in your time and the small bit of profit you'll make after shipping/paypal fees. Newegg had some XFX 6700xt for $599/$629 last Friday and they were in stock for multiple hours.\n\nGood luck and keep at it.",
      "My arm after I saw this: üìà",
      "That‚Äôs a phenomenal deal on this market",
      "If you can get the 6800XT for a price near MSRP, I'd recommend it. The 6900XT is 11% faster, but like 30% more expensive.  So while I love my 6900XT, I'll be the first to say that it isn't worth the additional $300 odd dollars",
      "beasty boy! i just picked up an open box red devil ultimate for $1250 recently. they are great cards!",
      "Price?",
      "The AMD sale every Thursday morning",
      "Lol. I was looking at getting the 6800xt when prices fall a bit more.",
      "The only thing I'll give a 3080 TI over this card for is ray tracing, all the reviews say the 3080s do a lot. Much better job at ray tracing but for all the games in my library I only have like four that support it. So in my case no great loss",
      "If you don't want your keycap I'll buy it ;)",
      "from where did u get it",
      "Yeah it was my idea when buying the 6900XT.\n\nI wanted the 6800XT and it was more than enough, but no availability led me to the 6900."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900"
    ],
    "title": "Just got these custom back plate for my 6900 black limited edition :D",
    "selftext": "",
    "comments": [
      "God damn that‚Äôs beautiful man",
      "https://www.v1tech.com/",
      "One word.... WHERE CAN I BUY ONE.",
      "By the ancestors, thank you.",
      "Thanks alot!",
      "You‚Äôre joking right. They‚Äôre not even testing the right components. Ofcourse it‚Äôll have no effect on GPU temps the backplate never cools the GPU directly. It cools the VRAM and VRM which they didn‚Äôt test. Its acrylic. Its not gonna be a heatsink.",
      "Holy shit are these ever cool. Why have these not become a thing. I think I'm gonna order one",
      "Man I have this same card. I didn't l know I could make it look even better",
      "Because withthe cards being higher and higher TDP putting an insulator on the backplate which is usually used to dissipate heat is not such a great idea.",
      "It's indeed a hard task, the card looks awesome out of the box",
      "Those ssd covers they offer are amaze thanks for sharing",
      "Wish I had discovered this before buying a vertical GPU bracket! This looks so much more legit!",
      "Not gonna lie, it's fuckin sweet",
      "V1 coming in clutch I see. I love the look of these 6000 series XFX cards. Nice build, friend. Merry Christmas as well.",
      "I didn't know that \"WHERE CAN I BUY ONE\" was only one word.",
      "To qoute Gordon: F off will ya?\n\n\nlol",
      "sexy",
      "Ok you win.",
      "Has to be the dopest looking computer I've ever seen",
      "Cool"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900"
    ],
    "title": "No, it's not a console killer. CL530 w/ 5800X3D + 6900 XT",
    "selftext": "",
    "comments": [
      "Not a console killer- it‚Äôs even more",
      "Specs\n- CPU - Ryzen 7 5800X3D\n- CPU Cooler - ID-COOLING IS-60 EVO w/ NF-A12x25 & NF-A9x14\n- Motherboard - Gigabyte X570SI Aorus Pro\n- Memory - Corsair Vengeance LPX 32gb, 3200mhz CL16\n- Storage -\n - Crucial P5 Plus 2TB\n - Crucial MX500 2TB\n- GPU - Gigabyte 6900 XT Gaming OC\n- PSU - Corsair SF750\n\nThe 5800X3D throttles a little bit during all-core loads, but not too bad. It never throttles while gaming. Screenshot: https://imgur.com/NHBWLzG\nCinebench score: 14650\n\nGPU runs fine, topping out around 90c on the hotspot with an undervolt dropping its wattage from 300w to 240w\n\nPCPartPicker link for more details: https://pcpartpicker.com/b/T99NnQ",
      "Looks awesome, and I‚Äôm betting you look awesome too üòéüëâüëâ",
      "Undervolting is the best to do on all of the new hardware. Let it be GPUs, Ryzen 5000 or Intels 12000s.",
      "Your console vs the PC she tells you not to worry about.",
      "That things literally a beast in a briefcase lmao",
      "Yeah it‚Äôs a console serial slayer",
      "Yeah, I have the 5800X3D on a -30 CO as well. It helps a ton.",
      "Thanks dear",
      "Consoles don't actually do 4k most of the time, they use dynamic resolution and/or some sort of scaling. The framerate is often low too or at least not stable. Also, you can still do so much more with a pc.\n\nBut still, if you don't care about working on your pc, want something relatively cheap and very easy to use, a console is indeed the way to go.",
      "That's hot.... literally",
      "the worst part of PC gaming is how laughably big cases are. this definitely appeals to me. nice job OP",
      "never understood people calling pc's above 1000 dollars console killers, it's not very easy to just find a pc that can do ray tracing + 4k gaming(depends on game) at 500 dollars, let alone 300 dollars for 1080p no ray tracing 120fps(series s), Is it because of the size of the console or the general viability? it never made sense to me",
      "Its also way more expensive",
      "Yeah I‚Äôve got a regular 5800x & 5900x and curve optimizer helps a ton. My 5800x is an especially good sample in Cinebench it‚Äôll hit 16300 with curve optimizer or I can get about 16650 locking it at 4.8 all core but that hurts my gaming performance so I stick with curve optimizer.",
      "Have to take price into consideration, tbf. The 5800X3D alone costs 90% of a PS5.",
      "That is definitely a console killer the new consoles can still barely run anything above 60 frames.",
      "\\-30 ***all core***? No way that's stable.\n\nRun Core Cycler for a few hours, you'll find instability and low loads / idle.\n\n[https://www.overclock.net/threads/corecycler-tool-for-testing-curve-optimizer-settings.1777398/](https://www.overclock.net/threads/corecycler-tool-for-testing-curve-optimizer-settings.1777398/)\n\n[https://github.com/sp00n/corecycler](https://github.com/sp00n/corecycler)\n\n\nEdit: tagging u/exscape for relevant links ^",
      "Ran it for a few hours, 3 complete iterations: https://imgur.com/a/FzFpCbj\n\nNo errors, I might run it overnight for fun but I'm pretty sure its stable. Check the 5800X3D owner's thread at overclock.net and you'll see that -30 CO is not uncommon for this CPU.",
      "I have a 6900XT and 5800X in the same case and I believe the same cooler and I‚Äôve found the gpu stays quite cool but the 5800X throttles almost all the time. Waiting for the next Gen to come out to move on from the 5800X to something that runs a bit cooler"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6950",
      "6900"
    ],
    "title": "High-end AMD RDNA 2 supply is dwindling ‚Äî RX 6950 XT, RX 6900 XT, RX 6800 XT virtually out of stock",
    "selftext": "",
    "comments": [
      "Tons of them left in Norway. The only one virtually gone with just a couple of overpriced units in stock is 6800 and 6800XT.\n\nEven the 6700XT is easy to get cheap, I'm really ashamed of how many green cultists there are in this country",
      "that tracks, our microcenter still has a bit, it was 25+ since last year, now its at 17, guess they ain't restocking no more. I'm hoping they will drop price to move inventory a good sidegrade from 6800xt assuming it goes down a hundred more\n\nhttps://i.imgur.com/rWgZNu1.png",
      "Yet the ancient RX580 is still plentiful.  What's your thoughts on that?",
      "brand new or second hand? cause all I see for Polaris are ex-mining card.",
      "Cheapest RX 6800 XT cost 6600 NOK, you can get 7800 XT for 6700 NOK or a 4070 for 7000 NOK.\n\nI bought my 6800 XT used for 4000 NOK over a year ago ü§£",
      "elastic rob alleged plate longing snails lush zephyr cough tart\n\n *This post was mass deleted and anonymized with [Redact](https://redact.dev/home)*",
      "Anecdotes be anecdotin': I've got a 6700 XT, *not* a high-end card at all, really, but goddamn does this thing **scream** at 1440p.  \n  \nRDNA2 is a really great value proposition, and we're kind of getting to the point in computer hardware that people don't need as much future-proofing as they once thought.  It's like what we're seeing with cellphones; new and improved hardware is coming out all the time, but for many of us the *old* hardware still does everything we need it to do and more.  \n  \n>\"My gaming computer has a CPU bottleneck.\"  \n>  \n>*\"But your game is running at 350fps!\"*  \n>  \n>\"Nevertheless.\"  \n  \nThis may not be good for AMD, or less than ideal, anyway, but at the same time I'm kind of pleased as an onlooker to see that consumer habits may be changing a little bit.  Not everybody needs a Hummer, y'know?  *Some* people can get the most out of buying a Hummer, but not most.",
      "6950 XT was available for a long time as a fantastic value 1440p gaming card. Now the 7900GRE is available at the same performance tier at a lower price and is less power hungry.",
      "Exactly, usually I don't keep a high-end card, generally I resell it shortly after the arrival of its replacement, an RX 7900XTX Sapphire NITRO+ model, really an excellent card very well cooled (despite its increased TGP from 350 to 430 Watts in stock setting), but for now I'm going to keep my \"old\" RX 6900XT from MSI Gaming \"Z\" Trio model, with \"Navi21XTXH\" chip instead of \"Navi21XTX\" (running at a stock voltage of 1.2v instead of 1.175v), rather than managing to sell it used for just over 400‚Ç¨/400usd",
      "afterthought escape square shy quiet door cake familiar depend outgoing\n\n *This post was mass deleted and anonymized with [Redact](https://redact.dev/home)*",
      "Brand new - Best Buy here are STILL selling XFX 580's.\n\nFunny thing you say about it being an ex-mining card.  Before COVID ruined everything, I bought a Sapphire Nitro+ RX 580 for $100 USD from r\\/hardwareswap that was an ex-mining card.\n\nThing is, the person was very transparent about how it was used.  Was in one of those mass-mining setups with an open bench.  24/7 AC-cooled room.  Underclocked at the beginning.\n\nI still have it to this day and I probably run it harder in a worse environment than he does (kinda dusty room, humid, gets warm during the day, etc) and it still runs like a champ.",
      "Yeah the 7900XT and XTX launched at too high a price and the 6950XT suddenly became much better value proposition.",
      "Sardo-what now? XD",
      "You might be on to something there.  I bought one a year or so ago as \"new\" on Amazon, and it turns out it had been (poorly) repasted at some point and was running hot.",
      "Yeah it screams at 1440p in most games, but playing Horizon Forbidden West on my 6700XT makes it *cry* instead lol.",
      "Bought an rx6750xt recently for $330 to put in my AMD 7600 build. Gonna hold that mf until Doom can‚Äôt play on it anymore,",
      ">I'm really ashamed of how many green cultists there are in this country\n\nMore for yourself.",
      "100%.  I got a RX 6800 (non-XT) and loving it for 1440p.  Made the switch from Nvidia to AMD GPU for the first time in almost a decade and it has been great so far.  Bummed that I didn't wait a little longer now that models are as low as $380 but other than that no regrets.",
      "Different node.\n\nThere is a chance AMD had bought x wavers on the node (14nm Global Foundries), paid for it and didn't use them yet fully. There is a reason why the Zen3 compute die was on the same node family over at GF as well.",
      "[About that...](https://www.amd.com/en/products/graphics/amd-radeon-rx-7700-xt)"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6950xt"
    ],
    "title": "Build finally complete! Sapphire Nitro+ Pure 6950XT is a MONSTER gpu.",
    "selftext": "",
    "comments": [
      "Such a gigantic card. Looks lovely in there",
      "I got the sapphire nitro+ SE 6900XT and its a beast awesome looking card too,\n\nCan only run mine at 2650mhz so it really shows how well binned the 50 series is.",
      "Build Specs: \n\n-CPU: Intel 12900K \n\n-MB: MSI Z690I-Unify Mini ITX\n\n-RAM: DDR5 GSKILL 6000mhz cl36 Silver \n\n-GPU: Sapphire Nitro+ Pure 6950XT \n\n-CPU Cooler: DeepCool AK620 WH\n\n-PSU: Coolermaster SFX V850 White 850w\n\n-Case: O11D Mini white\n\nCase fans: Arctic P12 pwm pst - white/Arctic P14 pwm -pst",
      "Beautiful. May we share this on AMD social media?",
      "That is a cool 90 degree adapter you got there for your cables.",
      "Amazing build dude.",
      "\\*180¬∞ adapter.",
      "Ive got the same card and it's still a monster, it's at the point that the biggest bottleneck is trying to cool the damn thing in a 680x case",
      "Yes by all means!",
      "It performs almost on par with a Noctua nh-d15 but it's only $65.",
      "Oh shieet they released a white version of the CPU cooler?\n\nDamn might be getting that next then.\n\nHow is it noise level wise?",
      "Looks like the [DeepCool AK620 WH](https://www.deepcool.com/products/Cooling/cpuaircoolers/AK620-WH-High-Performance-CPU-Cooler/2022/15496.shtml).",
      "They were actually in stock.",
      "Looks crisp, good job üëçüèª what cpu cooler is that?",
      "How the Hell do some of you guys get these new cards so fast???",
      "OK... I don't usually say this, but OMFG that is a beautiful rig. Extremely well done, you should be proud. \n\nDo you have a build list of all your parts?",
      "Thanks!",
      "Yeah I had the nzxt h440i before my current case and temps were one to throttle temps,\n\nSo I bought the corsair icue 465rgb case and cooling is soooo much easier,\n\nMost games it stays under 85c games with raytracing it can get into the low 90s at times but ifs still 20c+ lower than my radeon 7 got to so much happier.",
      "achy bronto liphersoos arpregniator sarchosis inebriatolion\n\nOf course if you are aware, I forgive and to be onto it, I say, we eclkhath farsothey antoothrick.",
      "Your GPU is sagging a bit. It looks awesome having a beefcake like that but I would be concerned a tiny bit with the longevity of that PCIe lane."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900xt"
    ],
    "title": "Painted the 6900xt reference card.",
    "selftext": "",
    "comments": [
      "Literally every version of the reference cooler that I have seen has looked dope, but this one takes the cake, absolutely gorgeous!  \n  \nI kinda' bet your GPU would even look good in a horizontal mount, since the white shroud would contrast with the black heatsink, so you've got a twofer there!  \n  \nVery cool mod OP, thank you for sharing it with us!",
      "Not bad for a painting. Almost looks real.",
      "Thank you sir.",
      "I'm an industrial painter but damn even I'm impressed by how well you were able to match the whites so well with a spray can too.",
      "The bottom right fan is not aligned with the others. You have to fix it",
      "Yeah, bought new off a kid for $1100 last week. I've painted my last two cards no issues.",
      "Some 14 year old kid on offerup had it brand new 1100. Came up",
      "Yeah too bad he got the color of the card wrong\n\n/s",
      "Beautiful build!",
      "Just be happy for the man god damn. How do you get around thinking so negatively?\n\nIt looks sick. Even cooler than my white 6700XT Hellhound.",
      "nice",
      "How did you paint it?",
      "Plasti dip",
      "Well I have a white 2060s I'm selling. Pretty sure it voids the warranty. Pretty easy depending on card disassemble, and take shroud off or in this case tape off everything your not painting.",
      "I was thinking of doing this to my 6700 xt reference and this makes me really want to do it. It looks so good",
      "This has to be the most prolific pc case ever designed.",
      "You Monster!!\n\n&#x200B;\n\n&#x200B;\n\n...sorry, I was talking to the card.",
      "So is the bottom left fan ^^",
      "Thanks bro.",
      "Can you change the color of the RADEON ? Mine is red and doesn‚Äôt seem to be changed"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900xt"
    ],
    "title": "First ever PC build lemme know what y‚Äôall think. It‚Äôs got a 6900xt gpu, Ryzen 9 5900x cpu, 32 gb cl14 tridentZ neo ram, Samsung 980 pro 2 tb storage, rog strix 850w power supply, and a Phanteks 240m AIO. I also added a back case fan that didn‚Äôt come with the case.",
    "selftext": "",
    "comments": [
      "Great PC. Just don‚Äôt throw a dart through the case. ;)",
      "I'm assuming they're future proofing",
      "well someone didn't cheap out here.\n\ncables are a bit messy.\n\nyou don't want to daisy chain your gpu cables. try two separate ones.",
      "Thanks , I definitely won‚Äôt be using that dart board anymore until I move it üòÇ",
      "u/No-Tomorrow-9546 this is very important! Daisy chaining your gpu connectors can and probably will lead to a lot of issues, especially on a power-hungry gpu like the 6900xt. Pull another separate cable from your PSU to plug the other connector.",
      "Terrible term to use lol but yeah I agree. I always build a way over kill computer to last me a good 5-7 years. If not more. Just upgrade small things that break over time.",
      "Because modest builds don't get upvoted.",
      "Thank you. First thing that caught my attention was that dart board and your tempered glass panel. My anxiety is somewhat alleviated. üò±",
      "I just wanted to upgrade to 1440p now, and idk how expensive the new graphics cards and cpus are gonna be and if they are gonna be in stock",
      "Get both of them out to power one connector each, you can figure out how to make them look pretty later. Function over form always.\n\nThe pigtails on those cables are generally meant to only be used when you have 3 gpu connectors, you plug the first 2 connectors on one cable each, and for the 3rd connector you use the pigtail. [Like on this graph](https://hardforum.com/data/attachment-files/2020/10/388573_daisy_chain.jpg).",
      "Epic first build! \n\nHow much did ya pay for the 6900xt ?",
      "The problem with that is nothing you can build right now will run new games anywhere close to max settings at high resolution in 5 years.",
      "My first PC build was a beige case 386 PC.",
      "What would the equivalent of this be for the market 5 years ago? 1080 ti? Or was there a higher rated card",
      "I got a 6700xt on vacation for 500 I can't wait to go back and set it up ITS GONNA LOOK GOOD",
      "Mine was an off white 486dx",
      "Nice! Just got a Sapphire 6900xt toxic for 850$",
      "That‚Äôs some expensive ram",
      "oh and the motherboard is a Meg x570 Unify",
      "Thanks! $900"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900xt"
    ],
    "title": "AMD Advisor is a meme. 6900XT does not meet the min requirements for anything in my library.",
    "selftext": "",
    "comments": [
      "it is a glorified advertisement page disguised as an \"advisor\".",
      "Oh, you run a 5900X? You should go for a 5950X, just to be safe.",
      "Processor does not meet minimum requirements either. These tools are just garbage. Like with the Windows 11 upgrade advisor fiasco. Threadripper ain't enough but it will run on a potato phone SoC lol",
      "Only noticed when I was using game tuning that all my games had an X in them.",
      "It's the troll answer to the most frequently asked question in this sub. *will I bottleneck with a 5900X?*",
      "Weird I've noticed it because its been posted 3 times a day for the last 3 months",
      "Don't worry, I am sure with FSR you should be able to play at 720p low.",
      "Have you considered upgrading to an Rx 7900 XTX+ from Radeon's underground lab?",
      "Don‚Äôt you know, when your cpu and gpu are too fast, your games end up going backwards in time and makes them totally unplayable!",
      "Has this tool ever been useful? or has it always just been a way to trick users to upgrade their hardware?\n\nPretty upset i cant run wallpaper engine on my rig anymore. /s",
      "Yeah windows update tool said no too. But enabling AMDs TPM thing in the bios of my mobo made me pass it. Assume threadripper could do the same?",
      "Absolutely! When I built my computer last year, I wanted the most powerful AMD system I could get (because I'm a fanboi), so I went for an RX 5700XT, but I couldn't justify spending ¬£700 for an R9 3950 over just over 400¬£ for a 3900 (which is still oversized for most of what I do. So when the advisor war 'recommending' the 3950, I giggled.\n\nAt least the current 'recommendations' are for a more recent generation of CPU and GPU, not that I can put my hands on the latter at reasonable prices anyway (and I don't feel the need to update).",
      "No, it was never useful. It's just a marketing tool. No matter what game you're playing, what software you're using or what kind of performance you're getting, it'll always recommend the top of the line.",
      "mate it told me to upgrade my 6900xt and 5950x. guess I need epyc",
      "Reject windows, return to Linux",
      "I don't think it's ever been useful or ever been affective as a way to get users to upgrade. It *could* have been made both, if it provided real information, but it never did anything but offer the highest end CPU and GPU even when it did have something relevant to say about which games run on what hardware.",
      "This is one of the feature settings that you want to disable every time.",
      "I Just upgraded to a 5600x and sometime next year when GPU's are in stock I'll get a new one lol. It's crazy how much my Vega 64 sells for atm and if I could get my hands on a 6800xt or a 3080 (at MSRP or very close to it) I would sell it in a heartbeat and cover 75% of the cost of upgrading.",
      "Upgrade it to what exactly lmao",
      "AMD Advisor secretly works for the Star Citizen team."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900xt"
    ],
    "title": "Black and Red - 5900x paired with 6900XT LC",
    "selftext": "",
    "comments": [
      "Such a nice case. I have one as well.",
      "Because it is a stock cooler. Those 6900XT LC cards are absolute unicorns.",
      "I picked it up from from centrecom which is a local store here in Aus. It comes as an OEM unit so basic brown box with nothing else really. These 6900XT LC cards are certainly rare, haven't see many of them - was lucky enough to jump on one.",
      "Where‚Äôd you get that cooler?  I‚Äôve not seen a 6900XT that has a stock looking cooler like that. I love the LED cover portion.",
      "It is! I am really loving the meshify cases.",
      "When running stock which is 2250/2435MHz game and boost clocks with the default curve it stays around 76C.\n\nI have it running at 1675/2850MHz with memory at 2400MHz and power limit at +15% (400W), with a more aggressive curve and it is hitting around 83C.",
      "because the die on GPUs is 3x bigger than CPU dies, so more surface area to come in contact and cool the GPU more efficiently. Coming from car knowledge, larger rad does not mean lower temperatures, it means sustaining low temperatures for longer (e.g. the 120mm would heat soak faster than a 360mm), but that can be resolved with a faster fan. So even though you have a 360mm rad on CPU, it won't cool it effectively when there is only so much contact area (big cold plate, but small and dense CPU die).  My friend is cooling his 3700X with a 120MM AIO just as well as I am cooling my 3700X with a 280MM AIO, only in sustained workloads his system might be a bit louder and a bit warmer. Plus the GPU core is in direct contact with the vapor chamber of the cooler, not going through an integrated heat spreader, which would lose some efficiency in heat transfer any time you are going from one material to another.",
      "Yep, this is it, easy mistake. The Meshify 2 C has the following distinctions you can use to tell:\n\n* Slotted metal mesh pattern on rear/top/slots. Meshify C has hexagons.\n* No rubber mounting points for the glass. The M2C uses a toolless snap system (you can barely see the snap-in points at the top) whereas the Meshify C uses 4 thumbscrews to secure the glass panel.\n* Mesh panel is slightly more offset in the front panel since the Meshify 2 Compact's mesh front panel is a door that swings open.\n* Feet are different, M2C is blocky like this whereas Meshify C has smaller silver round feet.\n* Screws holding the top panel on instead of just rivets, since the top panel is fully removable now.\n* No branding on the PSU shroud.\n* Cutout in the PSU shroud is now two segments so you can remove only part of it for radiator if you wish.\n\nLooks very much the same but these little differences speak to how much thought was put into redesign work for this series. Many other small differences not visible in this image exist as well.",
      "Better question where did you he get a 6900xt?",
      "I have one of these LC cards and honestly the 120mm does a better job than I thought it would. I have it at 2750mhz and it stays at 60c edge/71c junction at 50% fan speed. Could definitely be better with a 360mm but still pretty happy with it.",
      "Meshify 2 Compact*",
      "Where are the PSU cables from? They look so clean!",
      "I love it! black and red's my fav combo too :D",
      "what case is it?",
      "I got them off Amazon, they are the 'EZDIY-FAB Sleeved Cable - Cable Extension' in Black. They are really good value, very happy with them.",
      ">6900XT LC\n\nSame here, I just feel that 1x 120mm is a bit of a letdown. I don't understand why for CPU we need 360mm rad and for a GPU with 2-3x the TDP we have a 120mm..",
      "Meshify C edit: see below",
      "I have the air cooled 6900xt and but dam i want the lc version so bad.",
      "Not going to lie, one of the cleanest builds I have seen, good job.",
      "how many livers and limbs for that GPU?"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900xt"
    ],
    "title": "Rx 6900XT is beast",
    "selftext": "",
    "comments": [
      "Use two independent PCIe power cables on that 6900xt...would hate for your build to burn up",
      "Tnx \n\nI changed it",
      "If by powerful you mean \"raw rasterization performance\" either card can come out on top depending on factors like resolution and the API in question, and even which versions of the card you're comparing due to differences in cooler designs.\n\nIf by powerful you mean \"an overall superior experience in Linux\" then the 6900 XT.\n\nIf by powerful you mean \"consumes more power\" then the 3090.\n\nIf by powerful you mean \"highest ray tracing performance\" then the 3090.\n\nIf by powerful you mean \"compute and productivity potential\" then the 3090, thanks to CUDA and it's wide adoption.\n\nIf by powerful you mean \"video encode/decode performance\" then the 3090 thanks to NVENC.\n\nIf by powerful you mean \"feature set\" then the 3090, due to DLSS being superior in general to FSR where both are implemented and comparable.\n\nIn short, the 6900 XT is a very niche GPU. It's a rasterization monster in the right circumstances, and there are a handful of situations where it is the fastest consumer GPU. But beyond it's limited use cases, it falls short of the 3090 in the majority of circumstances.",
      "Piggytail 8pin power connector detected on a 350 watt GPU, make sure you have a fire extuingisher nearby",
      "I have the exact same card. You really should use 2 independent pci-e power going into that GPU. But you do you üòÄ\n\nAnd get a gpu bracket. That card is massive and heavy \n\nupHere 5V 3PIN Addressable RGB Graphics Card GPU Brace Support Video Card Sag Holder,Built-in 5V ARGB Strip,Adjustable Length and Height Support,G276ARGB https://www.amazon.com/dp/B08YYJ8Z9W/ref=cm_sw_r_apan_glt_i_KVRZ5BPR8AHMZRS0R0VD?psc=1",
      "I really didn't know that\n\nTnx ....\n\nI changed it to 2 separate 8 pin connector",
      "I can smell the sweet burnt smell all the way here",
      "It's not going to burn up, it'll just limit the boosting behavior, since there's a wattage bottleneck. Well, it might, if you push it hard, I can't speak for every individual card, but the more stable voltage from 2 cables helps.\n\nThat being said, when I swapped from daisy chain to dual connectors, my \"game clock\" went from ~2350 mhz to ~2500 mhz.\n\nAlso, LPT, go into the Radeon settings, ***disable Zero RPM mode and set a more aggressive fan curve.***\n\nThe default makes it so the fans don't spin up until the card is already at 50¬∞C, and when I had it on the default, it kept crashing in more intense games or during spikes in the action. I changed it later on and it ended up becoming way more stable.\n\n[Mine is super aggressive](https://i.imgur.com/IqZRF34.png), but it almost never breaks 70¬∞C. The auto-boosting behavior is much better when it's running cooler.\n\nAlso, sometimes when the drivers update, it sets the fan curve back to default, so be sure to save your Tuning profile so you can easily reload it after each update.",
      "If you're asking about the 2-PCIe power cables, then yes. It's more to do with the stability of the power delivery.\n\nSpreading the supply of power across multiple cables reduces the overall wattage each individual cable has to carry from the PSU to the GPU, letting the GPU safely boost closer to it's actual limit rather than one imposed for safety purposes by the VRM or VBIOS.\n\nImagine trying to fill a bucket from 2 faucets rather than 1. If you're trying to fill a bucket once a minute, doing so from a single faucet will require you to turn it up so high that a bunch of water splashes out. If you fill it from 2, you get 2 neat, gentle streams, but they still fill in a minute, maybe even less.",
      "Now THIS is the kind of answer I come to Reddit for.",
      "Finally\nI build my dream pc\n\nCore i9- 12900K\nZ690 Rog gaming-A\nDeepcool castle 360\nRx 6900XT MERC black limited edition \n16 gig vengeance pro Corsair\nRog helios\nRog 1000w \n2TB crucial",
      "For a lot of things, yes.\n\nBut if you're chasing pure framerate on verylow/fillrate - 6900XT eats the 3080 for breakfast. Even the ref 6800 eats the 3090 for breakfast in fillrate.",
      "I have a 6700xt do I still count",
      "3090, but you'd be fortunate to get either. You get DLSS and their more mature Ray Tracing and Drivers.",
      "Really really tnx for your comment...\n\nI never knew that\n\nI change that to 2 separate 8pin connector",
      "I have a wooden shim holding mine up lmao",
      "Congratulations! This thing will be a beast! Im sure it will run well. May your temps be low and your fps be high.",
      "If you look at price or aftermarket price then the 6900xt should be compared to the 3070ti or 3080. People always compare it to the 3090 which isn‚Äôt 100 percent fair.",
      "Ok, if Nvidia wasn't pushing innovation, does AMD do?\n\n\nWhile Nvidia was packing it's software and hardware with new features, AMD was sitting back trying to catch up, they did innovate but only because Nvidia innovated something and they need an equivalent to it so they can still compete, amd SAM was one of the few times where AMD was ahead of Nvidia in adding a feature but even then SAM wasn't new or innovative.",
      ">A niche product is a product that only applies for very specific applications for a small group of people.\n\n\"If I use my own definition of a word then you're wrong.\"\n\nI don't care to argue semantics or definitions of words. I'm sorry that our definitions of niche don't align, but I can't do anything about that other than point out that my usage of the word was appropriate via the common usage definition of the word.\n\n>It has nothing to do with if one product is better than the other.\n\nWhere did I ever say that being a niche product makes it inferior?\n\n>No one is disputing that the 3090 is a better at certain applications than the 3090.\n\nIf you agree with my assessment other than the definition of one word you're hung up on, why are we discussing this?"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900xt"
    ],
    "title": "Diablo IV Beta showing some problems with FSR 2.0, particularly with fine lines. Taken using 6900xt",
    "selftext": "",
    "comments": [
      "beta is exactly the time to say when something is broken",
      "It's more specular shimmering. Maybe something the devs can address with better settings.",
      "I mean, im not sure a beta is the time to say its broken. Its likely not coded correctly atm, as im sure they put Nvidia features 1st. That being said, the beta is the tine to show this to THEM, not just shouti g into the void",
      "I'm ok with every game having FSR2. Some people need all the frames that can get.",
      "> not just shouti g into the void\n\nThis is literally the best way to report bugs to the big studios. If they don't see it on social media, it's not a bug and they don't care. Source: worked at big studio.",
      "yeah, I am not saying it's broken, just pointing out that there are some problems with it in the beta.  Not trashing the implementation at all.  I reported the bug.",
      "Horizon has FSR1, completely different algorithm as It is spatial and not temporal. It doesn't work well when the game's native antialiasing is badly implemented",
      "You are talking about Radeon Super Resolution which is technically powered by FSR, but is not the same thing.",
      "Wow. That shimmer is bad. Hopefully Blizzard addresses it.",
      "Even outside of frames, sometimes FSR2 Quality can be a good replacement for poor TAA",
      "cant please everyone.  Earlier someone posted screenshots that FSR2.0 was supported and people complained about no images, video, etc.  Just posting some things i noticed for people who are interested...",
      "You have misunderstood how to use FSR. OP did everything right.",
      "Why is FSR needed on Diablo? How many FPS you get in native resolution?",
      "recommended for what though.. if it's for 1080p60, that's a pretty old target\n\nalso iGPUs exist",
      "FSR has a lot of shimmer in Horizon Zero Dawn also",
      "The best AMD card out, at 1440p you get loads of frames? Colour me surprised.",
      "Yes it is but fully expect to see it go live with everything you reported unless it's a game breaking issue. Graphical artefacts? Ahhh we can patch that when it's live.",
      "7900XTX 1440P maxed out I get 250+ fps",
      "This is literally the whole point of beta testing. As long as people with this error report it properly then it can be addressed.",
      "Not much will change from Beta to Release, Betas are almost entirely complete games with some small fixes at best before release. It's very likely this will stay for release aswell."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6950"
    ],
    "title": "AMD Radeon RX 6000 Refresh Gaming & Raytracing Benchmarks Leaked: 6950 XT Faster Than RTX 3090 For $1099, 6750 XT Faster Than RTX 3070 For $549, 6650 XT Faster Than RTX 3060 For $399",
    "selftext": "",
    "comments": [
      ">The following results are based on AMD's official data which has been presented to the media.¬†\n\nWill probably need to wait till independent reviews come out",
      "Considering the regular 6600XT beats the 3060 and the non XT 6600 trades blows the 6650XT beating it for $400 isn't anything to write home about \n\n\nIf it beat or matched the 3060ti then that would be interesting but I don't think it will making a kinda obsolete product especially as stock is more and more readily available",
      "I'd like to see 6950xt vs 6900xt @ 1440p and 1080p",
      "RX 6650 XT vs RX 6600 XT = 2% Faster\n\nSo this justified a price increase according the AMD, ridiculous.",
      "Accurate isn't the same as representative.  \n\nCompanies pick benchmarks that show their products in the best light.  That doesn't mean they aren't accurate.",
      "Yeah, whatever, wake me up when anyone makes a video card under $200",
      "I know right. Never trust this until you get independent reviews",
      "Just look at those ray tracing results for the 6950 vs 3090. They're trying to give the impression that AMD 6000 series is a few % behind, or even trading blows with NVidia for raytracing performance. We all know that that is simply not an accurate summary. I think the article was EXTREMELY charitable to AMD when they stated:\n\n>...there's a reason why AMD didn't focus that much on raytracing performance...\n\nThey cherry picked the few results that show AMD cards in a decent light (pun intended) and attempted to pass that performance on as typical. It's disingenuous and just further reinforces the reality that none of these companies are your friend and they all participate in misleading marketing. Early/Mid Ryzen was such a breath of fresh air. A defeated AMD came out and said the truth: \n\n>We got these chips that are \\[OK to great, depending on the generation\\] for gaming, they're really great for productivity and multi-tasking, and we're sellin' 'em cheap enough to be compelling. Also, we're going to have 5 years of socket support so that'll be nice.\n\nThat was enough for me to buy a Ryzen 5 1600, Ryzen 5 2600x, Ryzen 5 3600, Ryzen 7 3700x, Ryzen 9 5900x, Ryzen 9 5950x over that period. The BS marketing is a turn off after being spoiled by a relatively honest 6-7 years from AMD.",
      "They're probably accurate - AMD's benches for the RX 5000 and 6000 GPUs, to date, have been accurate. It is, however, common sense that you wait for independent third-party reviews from people who aren't sponsored by the vendor.",
      "Or when any RT is used.",
      "Because there'd be a huge uproar of gamers who have pre-RT hardware. Considering the (admittedly recovering but still...) state of the gpu market it's good that hasn't happened yet.",
      "That'd be interesting but to be quite frank the 6950XT performs as well as I expect it to. The Infinity Cache does too good of a job that it's up to core clocks to make the rest.\nAMD's focus on memory architecture/hierarchy makes it easy to find where performance is limited.\n\nEdit: By performing well I meant the weak performance increase on the refresh. Memory was never a bottleneck for RX 6800 and up; just like the Radeon VII and R9 Fury series.",
      "the 6800 msrp was $580 and beats a 3070ti and AMD wants you to think a 6750xt which is supposedly faster than a regular 3070 is $550 is a good deal??  Literally I cannot stand AMD the past year",
      "Which makes sense, since it's the only AAA title so far which requires RT to function. Everything else just uses RT as optional window dressing for their rasters, rather than an integral part of the rendering pipeline.",
      "Correct. Fully raytraced lighting is actually simpler to implement and compute in realtime than the compounded layers required for a good raster. Adding RT effects on top of a good raster kills performance, but replacing the raster entirely improves performance on adequate hardware.",
      "To be fair, it‚Äôs looking like the 6650xt will hang with a 3060ti at 1080p, but it obviously will lose ground as resolution goes up.",
      ">Beats the 3090 at what though? At 4K? At 1080p? At ray tracing?\n\nCherry picked AMD sponsored games.",
      "At 3dmark. 3dmark loves RDNA2",
      "According to Hardware Unboxed , the RTX 3060ti and the RX 6700XT have around the same performance\n\nhttps://youtu.be/pnZRuY-jFVM\n\nI doubt that the RX 6650XT would match the RX 6700XT\n\nAlso , according to data provided to reviewers through AMD's official guide , the RX 6650XT is just 2% faster than the RX 6600XT on average\n\nhttps://videocardz.com/newz/official-radeon-rx-6x50xt-series-gaming-performance-leaks-out-rx-6950xt-is-4-faster-than-rx-6900xt",
      "Absolute trash. Raising the prices that much on cards that don't perform better than 5% on average than their older counterparts? Ridiculous AMD, absolutely ridiculous."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900xt"
    ],
    "title": "WOOO! Just achieved the second highest 6900xt port royal score in the world!",
    "selftext": "After the latest driver update I was finally able to push my 6900xt to the second highest port royal score in the world! Feels pretty good an I am extremely happy with the overclocking potential of rdna 2 especially if we are ever able to increase the voltage limit.\n\n[https://www.3dmark.com/search#advanced?test=pr%20P&cpuId=&gpuId=1353&gpuCount=0&deviceType=ALL&memoryChannels=0&country=&scoreType=overallScore&hofMode=false&showInvalidResults=false&freeParams=&minGpuCoreClock=&maxGpuCoreClock=&minGpuMemClock=&maxGpuMemClock=&minCpuClock=&maxCpuClock=](https://www.3dmark.com/search#advanced?test=pr%20P&cpuId=&gpuId=1353&gpuCount=0&deviceType=ALL&memoryChannels=0&country=&scoreType=overallScore&hofMode=false&showInvalidResults=false&freeParams=&minGpuCoreClock=&maxGpuCoreClock=&minGpuMemClock=&maxGpuMemClock=&minCpuClock=&maxCpuClock=)\n\nFor reference my build is\n\n\\-Reference 6900xt with ekwb custom loop\n\n\\-5950x on same loop\n\n\\-g.skills trident z 16 gb 4000 downclocked and tightened to 3600 cl14\n\n\\-2tb Samsung 970 evo\n\n\\-Gpu stats, 2740-2840 boost set, 1175mv, power limit increased to 365w max +15%, mem at 2124mhz fast timings.\n\nTo be clear I don't use those settings 24/7 I drop to 2700-2800 clocks and maintain around 2730mhz sustained 100%load in games, power draw around 330w. Still really happy with the score and hoping in the future we can get custom bios options to increase further.\n\n&#x200B;\n\nEdit - just to give everyone some more info, I made a post a while ago about my initial findings with overclocking the 6900xt. Those all pretty much stay true today. Basically if you have good cooling, maxing the voltage to 1175mv (which is what it runs stock btw), and upping your power limit by at least 50w or more through morepower tool should let almost every 6900xt perform about the same as me give or take. If you are power limited (like all stock cards) and you don't want to mess with morepowertool, then an undervolt will give you great results. and if you are thermally limited I'd do undervolt as well. You can see my post here with more details. There is a HUGE misconception that an undervolt with these cards is the end all be all. That is only the case if thermally or power throttled. [https://www.reddit.com/r/Amd/comments/kw0hos/some\\_info\\_learned\\_from\\_6900xt\\_overclocking/](https://www.reddit.com/r/Amd/comments/kw0hos/some_info_learned_from_6900xt_overclocking/)\n\nAlso a ton of people probably have an undervolt setting in place and don't even realize that it's not being used. The radeon software, or powerplay tables seem to do whatever the hell they want if they don't like what you put in. If you have say a undervolt to 1080mv it might not even be applied. To test this simply boot up your undervolt profile. download a program called gpu-z, most of you probably have that already. Launch your game or benchmark of choice that stresses the gpu 100% (this is very important). And then while it is running, launch gpu-z and navigate to the sensors tab, if it reads 1175mv for the gpu core your undervolt settings are being ignored.\n\nPlease be warned though, morepowertool goes past the power limits from amd and if you mess something up it can kill your card. I haven't heard of this happening yet, and it certainly hasn't happened to me but it is a possibility. Know the risk. The chances of it are very small I'd wager since amd tends to over engineer the boards a little but keep it in mind. ",
    "comments": [
      "OP  Nice.  I don't have one...lol   But brag away, thats a great achievement.  Yes I gave you gold because thats kick ass.",
      "Damn a lot of negativity in the comments.\n\nCongrats OP that's super cool! I got mine in the top 9% on air and called it a day haha. Should try again with the new driver.\n\nI really love this card from a pure hardware standpoint. I can't justify using it over my 3090 right now without a DLSS alternative but I very much prefer the 6900XT as a GPU. way less heat output, and OCing is fairly straight forward and rewarding, while for the 3090 wattage gets out of hand really quickly (I'm a SFF enthusiast).\n\nDo you by any chance have game benchmarks of your card as well? Shadow of the tomb raider for example.",
      "Thanks so much for the Gold! Really appreciate it, hopefully stock recovers soon and everyone who wants rdna2 can get it. They really are a great line up of gpu's if you can get them.",
      "That is literally a raytracing benchmark lmao. Though the amd cards simply cannot compete in raytracing, I personally don't care for raytracing so I'm very happy with my card.",
      "It's a raytracing benchmark",
      "Not that hard since 2 in total got produced",
      "Awesome dude.\n\nAlso, I‚Äôm impressed the #1 score is with a 5800X. That rocks.",
      "Thanks man, yeah I noticed quite alot of downvotes from this one lol. I imagine it's because so few people can buy a 6900xt let alone afford one. I totally get why some would be frustrated and maybe take my post as a way to brag(which it's not lol). I was just really happy with my luck and excited that amd is once again at the forefront with gpus. The results you can get on rdna 2 from overclocking remind me of the golden overclocking days 10 years ago. Congrats on getting both of your cards as well!\n\nEdit- also I don't own shadow of the tombraider, which I would be very interested in benchmarking since I know that game typically sees amd far in the lead. I could run through ac valhalla, cyberpunk, and a few others if it's really of interest to people.",
      "just look at all those ryzen cpus in top 50+ :D\n\nas for OP congratz, must be quite nice, how long did it took for you  to reach that score?",
      "lol I def Got lucky being able to snag mine when I did off Newegg. Coming from a vega 64 it made an insane jump that was badly needed for me.",
      "Darn it Ricky Bobby you right",
      "While we're making people feel shit about their purchases, lucky you spent so much on a 3090 so you could get the same score I got with my 3080.",
      "Port royal is a gpu exclusive benchmark, so cpus have little impact. However they probably do influence dropped frames and stuttering a bit so a 5800x with higher clocks than mine could influence the results, albeit only a small amount.",
      "I don't really understand your comment. Amd cpu's are now legitimately better than intel in every use case, hence the higher price now. They have also been killing intel in market share. If you are referring to the scores in port royal. 1. it's a raytracing benchmark and NVidia is way better at that, and 2. cpu really makes almost no difference in this test minus maybe a few percentage points since it's a gpu only benchamrk.",
      "Glad there are other that don't care for raytracing. Lol",
      "Hopefully the rumors are true and stock will start to stabilize over the next few months. But then again we've heard that one before...",
      "I know I can't compete with NVidia when it comes to raytracing but I just wanted to share my excitement from just how much I was able to push out of my card. Before I put a custom loop on it and upped the power, my reference 6900xt was around a score of 9500 in port royal. So it has improved a huge amount. \n\nCongrats on the 3090 btw, that's an amazing card as well.",
      "I wrote \"in the world\" because that's exactly what it is. The second best 6900xt score \"in the world\". I mentioned nothing about any other cards.",
      "Oh, no I wasn't talking about AMD vs Intel in normal desktop use. Hell, look at my flair, I have a 3900X in my own system. I was just more stating the fact that in overall scores, the XOC community seems to still prefer Intel.",
      "Hmm yes, I know some of these words. Congratulations!"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6950xt"
    ],
    "title": "AMD launches Radeon RX 6950XT, 6750XT and 6650XT graphics cards - VideoCardz.com",
    "selftext": "",
    "comments": [
      "Another difference is the price tag, but not in a favorable way..\n\nNotice how none of those charts AMD made actually compare against their predecessors?",
      "But where is the difference other than power draw and slightly more memory bandwidth?",
      "6650 xt for $400 and the 6750XT for $550\n\nLMAO.\n\nTHis means the 7700xt will be $550.\n\nThe 5700xt was $400 ffs.",
      "My 5700 non xt was 329 before tax. FFS. A full PCIE 4.0 16x card with 8 Gigs of VRAM that could drive anything at 1080p and most games easily at a 1440p. Compared to 2021 / 22 pricing, it seems almost insane.",
      "Its quite telling they are not comparing it to the regular 6600XT, 6700XT and 6900XT because the uplift is probably 5% at most and would make the price incease compared to the models that launched over a year ago comical.\n\nWe're probably in for a trashing in the reviews once the embargo lifts in a few hours.",
      "well ofc there's msrp bump, why wouldn't it be. That was whole point entire time. 18Gbps memory is barely more expensive - otherwise they wouldn't be putting it on RX 6500 XT.",
      "Sadly yes",
      "The MSRP reflects that AMD is in their position to keep increasing margins and milk the desperate consumers a bit more.\n\nAMD keeps pulling one highest profit year after another. Production costs increases are negligible, especially third year on the same GDDR, the same core fabrication which got cheaper with long ago not being the cutting edge node, and with yields continuously improving.\n\nThere's not a single proof manufacturing got meaningfully more expensive for AMD, inflation completely notwithstanding.",
      "Oh no, with his 6900 XT, what a nightmare.",
      "Buying a 5700XT for 400‚Ç¨ felt like the best purchase ever made. Strong card for comparably cheap price. I always thought it would be a stopgap for the next gen big card. Oh how wrong I was. \n\nI hope the 7700XT will be cheaper but I'd guess Nvidia is raising prices and for some reason AMD just doesn't want to compete on price.",
      "7xxx series will probably be positioned way higher performance-wise and price-wise. Only the 6950XT is probably in the same performance tier as N33, but others are higher.",
      "The pricing is likely reflective of what AMD views at the least medium term outlook for GPU pricing to be and they have much more data than consumers/media/etc. to work with. The rumored pricing of Intel's roughly 3060 competitor being $380 also supports similar predictions.\n\nThis means it seems like they feel that the RTX 3060 will likely stall around the $400 mark as opposed to falling down to MSRP range in the low $300s. Likewise the 3060ti will remain around the $500 mark versus falling down to the low $400s. In other words the overall downward price trend for GPUs has reached a stall point.",
      "Well... as nVidia, this is just a cash grab.\n\nI'm tired of this stuff.\n\nThe prices are still a joke, even for the older models...",
      "God, why is AMD so fcking shit again? Why do companies build their reputation up for years and then say \"You know what? Let's forget about that and take the most stupid business decisions we ever could\"",
      "I wonder if they gave salary increases relative to inflation to all their workersü§î",
      "topkek - poor AMD should launch Patreon, so people like you can give them all the money üòÇ",
      "The point is not the performance, absolutely isn‚Äôt. The ONLY point for their existence is to refresh the MSRP. No more, no less.",
      "The 6950 is actually up on Newegg for $1100. The cheapest 3090ti is $2000. I think it is a win simply based on being $900 cheaper for nearly the same performance.",
      ">Don't always whine about businesses\n\nWhat's with the boot lickers in this thread trying to sympathize with a multi billion dollar corporation and defend this blatantly obvious cash grab? We all understand how businesses work, no one expects them to be a charity. If I feel like I'm getting bad value for the price I'm supposed to pay, of course I'm going to point that out.",
      "One of the best purchases I made, gamed like all hell during the pandemic, bought a 3080 at MSRP and sold the 5700xt for like a grand during the craziness"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900"
    ],
    "title": "new chunga 6900 xt tuf vs my old 1070!",
    "selftext": "",
    "comments": [
      "Might be unpopular opinion but I don't like that cards are becoming this massive.  I like when a card can fit in my case without a need for a GPU brace.  Even more frustrating is when they slap those huge coolers on a 220w 3070 8gb  or something which seems like a massive waste",
      "Chonky",
      "I was like that with my new card. Had a 1080 zotac amp extreme and I was like \"Chonkyboi, surely ain't gonna get any bigger than that\". Cue the 6900XT Red devil ultimate...",
      "It's ridiculously big üòÖ",
      "Coming from r/sffpc I agree. Need smaller, shorter, thinner and more power-efficient cards!",
      "Feel ya.... Have the XFX Merc which is even bigger and heavier lmao",
      "As a owner of a TUF 3060 Ti, I happily paid 50 extra to get it to be as quiet and high quality as possible. So, it might be a waste, not for everyone though.",
      "That was my next pick, but I I liked the more plain look of the tuf cards.",
      "I'm into SFF PCs, it's even worse. And my case isn't even that small!",
      "Longest, thickest (after the Aorus Master...) and heaviest card",
      "Totally agree but the tdp of the 6900 xt and 3080 ti 0ull upwards 300 watts, it's either this or water for the higher tdp cards.",
      "Still in service best GPU I've ever had price performance etc, awaiting CPU and ram and I'm good to go.",
      "Isn't the Merc one of the longest cards?",
      "Wow 2kg is impressive",
      "why would you buy a 6600xt for $936? where are you lol \n\nThey were available easily under 600$ last week",
      "I bet that 1070 served you well",
      "> Even more frustrating is when they slap those huge coolers on a 220w 3070 8gb or something which seems like a massive waste\n\nBetter cooling and a lower noise level is not a waste. Hopefully we get more 5 slot cards where you can strap regular 120mm fans onto soon.",
      "> I had a 3070 xc3 which is a dual slot 285mm card and it never went above 66c.... There is no damn point, that is plenty of headroom to overclock.\n\nAt what wattage and fan speeds? The point is that you can adjust the fan curve to be quiet or you can go ham with overclocking. \n\n>If you're concerned about noise then people like you will just go water cooling anyways\n\nNope, it's a pain in the ass to assemble and service.",
      "Oh I agree, I'd already waited months. It was my 'retirement gift' build for myself but it took so long to get parts that it didn't get done until months after I retired.\n\nAt some point you just want it over with.",
      "Funny is also how even the TUF looks small when its side by side with the XGX Merc lmao"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900xt"
    ],
    "title": "Gaming PC with Radeon RX 6900XT GPU can still cost less than GeForce RTX 4080 alone - VideoCardz.com",
    "selftext": "",
    "comments": [
      "You can build a crazy good PC with a discounted 6700XT or 6800XT right now.",
      "I laughed so hard at [the video](https://youtu.be/UmjhPuMI9Es). He has great delivery.\n\nAs Tim of Hardware Unboxed said, the problem with the 4080 is that people with a lot of money will simply go for the 4090.",
      "Yup, just ordered an Asus TUF 6800XT for half the price of most 3080s in my area. Really excited to install it tomorrow",
      "Yep. If you get a 6800 XT right now you‚Äôre getting about 70% of the gaming performance of the 4080 for about 40-45% of the money. That‚Äôs absurdly good value.",
      "I can say that 6900XT has been a really good experience to me. It was a very expensive purchase at the time (with Brexit and Lockdown), but it was worthy.",
      "I just got all the parts for my son's first build.  5600G, 16GB ram, 6650 XT, 1TB nvme, 27\" 144hz freesync monitor, keyboard, mouse.  Everything.  For $500 (CAD) less than a 4080",
      "Yup, the funny thing is Nvidia is so overpriced that even in RT, AMD trades blows or narrowly loses with them.\n\n6650 XT vs 3050\n\n6700 XT vs 3060\n\n6800 XT vs 3070\n\nHell I saw a 6700 discounted to 300 yesterday, and it's like ~25% faster in RT than the 3050\n\nHowever we have started seeing the 3050 *finally* being discounted to 270. But even at that price the 6650 XT absolutely curb stomps it in raster and wins in RT.",
      "I truly hope NGREEDIA get shit on financially this generation. In Australia where I‚Äôm from, some of the high end 4080 cards cost as much or more than low end 4090 cards‚Ä¶. \n\n$3000 Australian for a Strix 4080, or $2950 for an Asus TUFF 4090 \n\nTime for nvidia to lay down the crack pipe, here‚Äôs hoping the 7000 series isn‚Äôt priced poorly and AMD wins this generation",
      "> For $500 (CAD) **>>>less<<<** than a 4080",
      "I guess there's always something newer and better around the corner. I don't need the best of the best since I'm always behind on new game releases and still mostly play modded Skyrim.The 2070S was overkill for my needs back when I bought it and so is the 6800XT. I don't know your situation, though haha",
      "dont forget to DDU nvidia drivers before installing AMD gpu",
      "The charts were my favorite part haha.",
      "2070 Super. Should give me a tiny little performance uplift ;)",
      "I would rather buy a 6900 XT then a 4080 despite having problems with AMD drivers, but please AMD fix your MPO issues already Nvidia fixed this 2 years ago....",
      "I paid far too much for it than I'd like to admit, but it was an excellent purchase. Cool, quiet and powerful. One of the best cards I've owned.",
      "Thanks for this video, that was really funny tho",
      "What are you upgrading from?",
      ">People rushing in to buy 4080\n\nDoubt almost every store in Germany has a large number of different models still in stock. When compared to 3000 they were basically out of stock everywhere for the first 2-3 months",
      "I somehow struck gold and saw a xfx 6800xt Merc at an online amazon returns auction last week. Won it for $280 and when i went to go pick it up it was sealed unused in the box. Much better than my 1080.",
      "I can find the RX6900XT for the price of an RTX3070 Ti and the RX6800XT for less than the price of an RTX3070.\n\nI really want to buy one of them but the RX7000 are just around the corner :("
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6950"
    ],
    "title": "My RTX 3070 Ti was struggling with 8GB of VRAM in some titles so I bought RX 6950 XT Red Devil for 709‚Ç¨ with The Last of Us game included. This thing is a beast and very quiet too after slight undervolting.",
    "selftext": "",
    "comments": [
      "Oh, the mighty Red Devil! Congrats bro! Enjoy your new GPU!\n\nI also got one recently, mine is a Sapphire Nitro and it‚Äôs been wonderful so far\n\nhttps://preview.redd.it/omwyohjgwova1.jpeg?width=3921&format=pjpg&auto=webp&s=0db60f7949dd14fe6979eb855a3caa058c6ca63b",
      "Seems many may be moving over to AMD from Nvidia . I made that move when the 1060 had 6gb VRAM and the 480 had 8gb",
      "Just out of curiosity, did you manually undervolt or did you leave it to auto-undervolt via the Adrenalin software? Build looks great, I love that all-black builds are making a comeback!",
      "Thanks! I just left core clocks to default which is 2669Mhz and lowered voltage from 1200mV to 1150mV. Any lower and I couldn't pass Time Spy stress test.",
      "It's 300‚Ç¨ more expensive in my country.",
      "Which titles gave you VRAM issues? I have a 3070Ti currently and I‚Äôm just curious where it starts to get bottlenecked in that area.",
      "I'll quote from another post I saw covering this topic, I think the redditor who made the comment nailed it on the head. \n> For years game devs gimped their own games to fit into 8GB VRAM, but now that PS4 support died they have collectively decided. nope. Textures alone will be 12GB or more.",
      "I find the whole VRAM situation pretty strange. I'm on 3060 Ti and I played through TLOU without problems, mostly 60 fps.",
      "Same here, but I got a 580. It really pulled out ahead of the 1060 later in its life.",
      "the 6gb version wasnt even the problem back then but the 3gb ... that card was so fucking shit",
      "With latest patch it's way better even if you don't have enough VRAM. Frame Time isn't great when you don't have enough VRAM, some stutters here and there can be felt. If you played at ultra settings, I doubt you didn't have any issues with a 3060ti, my friend had to lower textures on his 3070 for a stutter-free experience.",
      "Should be about 35-40% faster is raster and double the vram, so if you sell the 3070ti it‚Äôs a pretty solid upgrade.",
      "Are you being serious?",
      "Looks nice! You should adress the sag on the GPU though.",
      "In what way would this be a downgrade? 6950xt is on 3090 ti level performance",
      "Because it wasn‚Äôt comparable to the 6GB version even without taking the VRAM into account. It was such a scam",
      "Last of Us, Hogwarts Legacy and Dead Space Remake would all struggle with 8GB depending on the settings.",
      "A new PSU is not going to help with screen tearing, that's a monitor thing.",
      "I'm still rocking my Merc 319 6900 XT, very happy with it. Doubt I'll upgrade for the next 3-4 years, at least.",
      "I got the Nitro last week.\n\n10% more expensive than the other 6950s, but totally  worth it.\n\nThe overclock/undervolt potential is great so far."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900"
    ],
    "title": "Will my Thermaltake 700Watt 80+ White PSU be able to handle Sapphire Radeon RX 6900 XT Limited Toxic Edition?",
    "selftext": "",
    "comments": [
      "If you can afford that gpu you can upgrade your psu.",
      "Don't cheap out on the PSU for a beast like that sapphire. You'll run into problems.",
      "Buy a high quality 850-1000W unit if you're buying a $2k gpu.",
      "This.",
      "In this case it is far from flawed, that power supply is not a good unit, OP NEEDS to upgrade.",
      "Relevant: [https://linustechtips.com/uploads/monthly\\_2021\\_10/image.png.8cce558fcdfd2537514813b6089df2ec.png](https://linustechtips.com/uploads/monthly_2021_10/image.png.8cce558fcdfd2537514813b6089df2ec.png)\n\nAll Smart psu's from Thermaltake are trash.",
      "I'm not saying that because you can afford one thing you can afford another, I'm saying in this case if you can't afford a new power supply, you can't afford that graphics card. \n\nThat particular power supply is not good for 750 watts of load, it is a cheap unit with a big number on the side. OP needs a power supply, or they'll end up killing their current one and having to buy a new one anyways, or they'll kill the graphics.",
      "Yepp get at least an 800 watt or 850 watt and a quality one. Like a Seasonic Prime.",
      "If you want your $1500+ gpu to blow a cap trying to clean up sloppy input voltage it's getting from your psu or regularly trip OCP, possibly leading to you needing to power cycle it constantly, then go right ahead and fill your boots. Iirc, the minimum recommended spec is something closer to 1000 watts +, and you really shouldn't be cheaping out if you want your card's input filtering to last.",
      "I'll be short with you, 700 watts is probably enough for this GPU in some circumstances, but if you want this GPU to hit it's full potential in games, you're running a pretty high end CPU. 700 watts probably isn't enough and AMD recommends higher than 700 watts for a reason.",
      "700 still ain't enough for this card, I have a system with a 5800x and a 6900xt that pulls down 670 Watts in some situations.\n\nOh and it's a card with no overclocks, 700 isn't enough and you don't own the card to advise on this, I do.",
      "....Except a PSU is nowhere near the RRP of a 6900XT and they're directly related?\n\n\nIt's the same exact analogy as saying if you can't afford to maintain a vehicle, you can't afford the vehicle.",
      "I think the 6900xt is a lot more efficient than the 3090.",
      "What do you mean 'nope' lmao, even retail a 6900XT is $1000USD, a quality PSU is <$150.\n\n\nRegion and finances do not matter because power supplies are cheap relative to a literal top of the line GPU - hence why your argument is nonsense.\n\n\nIt's like buying a car that calls for premium fuel and putting lower grade fuel in it because you can't afford it lol, it makes absolutely zero sense.",
      "Okay so lots of replies here aren't going into _why_ the PSU is bad. \n\nThere are two reasons: (1) Brand and quality of components (2) The White rating is very low\n\nQuality of components means a lot more on a PSU than it does, say, a motherboard (though tbf it matters there too, the results just won't be as catastrophic). A PSU with low quality components can perform to _specifications_ (ie can it supply 700W peak) but the average capacity (RMS) will not be anywhere close to that. Which brings me to the White rating\n\nThe ratings of a PSU tell you how efficient the power supply is input vs. output. A higher efficiency (among other things) means less of your input power is wasted as heat. So if you have a super low efficiency PSU, your 800W at the load looks a lot more like 925W at the wall. Taking this (very oversimplification, apologies to any EE who reads this) toy example, we can estimate that 20% of the load (125W) is expelled as heat, resulting in 80% efficiency (the 80+ part). 125W of heat is more heat than your CPU TDP, and the PSU doesn't even have an AIO to keep it cool. So what happens when the PSU starts to get too hot? One of two things:\n\n1. The voltage is what it is and may droop a bit, but the current may be limited at the PSU causing a cascade of components to summarily reduce their performance because they can't draw enough power without reducing their own voltage. This could result in slowdowns or (more likely) hard resets if it happens very fast. \n\n2. The PSU components (being the above brand, this is likely) will fail and either (1) send a voltage spike through your system frying your $2k GPU/mobo, etc. or (2) melt and cause a short (shutting everything down), hopefully before reaching the flash point of any component at the short point and igniting something (or both of these could happen). \n\nMoral of the story, as others have said, if you have this GPU that's awesome, in this climate I'm sure you earned it. But please wait to put it in your system until you can get a better PSU. Patience may save you both money and your dwelling.",
      "Does this \"simple research\" include looking at the website for the actual card itself? Because if it does you need to take a look at your reading comprehension skills. Sapphire recommends an 850W PSU as a minimum. Could you theoretically run it on a 700W PSU, probably, if you use a low power CPU. Should you? Absolutely not, because your options are a) reduced performance/random shutdowns from lack of power, or b) reduced performance due to CPU bottleneck.",
      "Honestly, it probably could with a 65W TDP processor, but if you go all out on a GPU **don't cheap out on the PSU**.\n\n&#x200B;\n\nBTW, spending money on a bigger & better PSU is not a waste, rumors suggest crazy TDP numbers for new GPU's next year, you would need an upgrade anyway.",
      "If anyone thinks that running a PSU at its limit in the long term is a good idea for either the PSU or the expensive components that are plugged into it, then they do not know enough.\n\nEdit: Especially with an 80+ white rating",
      "You are a giant doucher, no doubt about that.",
      "How's this for your logic - if OP can afford that GPU but can't afford a PSU to run it properly then wtf is the point of buying that GPU in the 1st place.\n\nExactly..."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900xt"
    ],
    "title": "I just built my first all AMD build with a 5600x and a 6900xt and wow it‚Äôs amazing! My last pcs for the past 8 years or so were all intel/nvidia. Gaming at 4k with zero issues! (new cpu cooler coming soon)",
    "selftext": "",
    "comments": [
      "congrats... and im still frustated to build now or wait for ryzen 7000...",
      "just build now, you would need an overpriced gen 1 mobo full of bugs, as well as over-priced DDR5. Unless you like beta testing than go right ahead and wait. Leaks arent showing much of a jump worth waiting for anyways atleast not in IPC terms. The multicore jump is pretty decent though.",
      "I'm so proud that everyone going for XFX these days. They mastered the design for this generation.",
      "The 2x performance claims I feel are a bit overestimated. They said the same things about this gen and it turned out to be untrue",
      "They also claim the new GPUs will draw 600W on the high end. \n\n2x the performance for 2x the power‚Ä¶I‚Äôll pass and keep my room not a furnace.",
      "I feel you. I‚Äôm in the same place. \n\nI‚Äôm in no rush but at the same time I‚Äôm impatient lol.",
      "Someone offer me this specs for $1200, all parts is brand new, should i get it now?\n\n- Amd 5600x\n- Rog strix RTX 3070 \n- Rog strix b550 wifi\n- Samsung 970 evo 500g\n- Corsair ram 16gb 3600 RGB\n- Rog PSU 650w",
      "You don't need to upgrade to ZEN4 to run RDNA3. The cards are PCIE5 but you can run them on a PCIE4 slot without issue, they still won't saturate the bandwidth available. PCIE5 is more relevant to data transfer on storage.",
      "You can run a 6900xt on PCI-E 3.0 x16 without performance hits.",
      "that's gonna cost $2000 and use 2x the wattage though",
      "10% IPC and 10% clock speed gains is better than most.  Intel incremental gains every year, now we get competition and some real gains.  I really wish games became more multi-core aware.  I am waiting until bugs are worked out, so went ahead and grabbed a 6900XT when prices dropped.",
      "I have the same exact card. Love it.",
      "You have a tiny desk, yet you still put your tower on it. Seems reasonable.",
      "Same CPU/GPU combo with me. I‚Äôm grateful that I am blessed to be able to afford such a rig. Ultrawide 1440p gamer here.",
      "I have a nitro+ 6700xt and xfx are second on my list. I don't care for strix",
      "They are beautiful cards, this one is the merc319 black",
      "LONG LONG MAAAAAAAAN!",
      "Ah.  I was going to ask about that.  If that is the circumstance, it's probably worth it, by the time you put tax/shipping, etc., on there, then that is probably close it sounds like.",
      "Good combo. Have a nice gaming sessions",
      "I like looking at it lol"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900"
    ],
    "title": "AMD Radeon RX 6900 XT Scores Top Spot in 3DMark Fire Strike Hall of Fame with 3.1 GHz Overclock",
    "selftext": "",
    "comments": [
      "Honorable mention: The top 2 Time Spy scores are with 6900XT's in crossfire",
      "This in on liquid nitrogen. So not a daily overclock.",
      "to set new world records?",
      "It's technically not Crossfire (driver level multiple GPU rendering) but DX12 multi-GPU rendering (API level multiple GPU rendering.)\n\nBasically the game/program needs to implement DX12 multi-GPU, whereas Crossfire would be handled by the Radeon driver.\n\nCrossfire has indeed been phased out. Whereas DX12 multi-GPU is still a thing (however it's rarely implemented and only a few applications/games support it.)",
      "Jeeeeezzzz Im jealous.\n\n\nMy XTX only does 2,68GHz max lol",
      "i'm fairly ootl, but how do you xfire these cards? i thought the tech's dead and you'd need an xfire cable/bridge?",
      "Key to success for 24/7 OC is MorePowerTool - my 6700XT @ 2.8Ghz sustained is faster then my 2080Ti.",
      "It's like top fuel drag engines. They're basically good for 45 seconds of runtime.\n\n&#x200B;\n\nWait maybe it isn't. Top fuel classes have all sorts of limits and restrictions.",
      "Jzuz I thought 2.7 ghz is much on my 6700xt. I know they are using LN2 or liquid helium, but still RDNA 2 clocks are very impressive.",
      "remember playing rise of the tomb raider with dual rx 480s through dx12 mgpu. That worked quite well with good frame times but also one of the few implementations I can remember.",
      "I set my liquid Devil to 2800mhz and it will go higher but I don‚Äôt want to risk it.",
      "Yeah. That‚Äôs exactly right.",
      "Yeah, because the manufacturers have gotten much better at manufacturing and thus getting out the highest possible clock speed with no instabilitys. But I am just impressed by the gpu architecture itself, because despite of crazy clock speeds RDNA 2 is still more efficient than Nvidia at the moment.",
      "Yeah, you're not running liquid nitrogen cooling for any gaming session. These get turned off super quick after the benchmark is done because of the condensation that builds up on the tubes.",
      "I wanted to go team red so bad when I built my pc a few months ago. Got an opportunity for a 3060ti though after months of looking and had to bite the bullet.",
      "Honestly, compared to the good old days it's not even that much of an overclock over realistic 24/7 use.",
      "What are your settings? I have a red devil ultimate with an alphacool block on it. It runs cold asf but after 2650 it seems to be power starved. I can get it stable 2750 easy but it seems to perform worse because it needs more power. Im thinking I might need MPT?",
      "Its super simple:\n\n\n- 1st use gpu-z to save your current bios\n- run MPT\n- click import, select the bios you saved\n- go to \"power\" tab\n- change the power limit to what you want it to be\n- click write SPPT\n- reboot\n\nNow your card has an increased power limit.",
      "In this application it's crossfire over PCIe since it's a DX11 benchmark and AMD has been doing bridgeless crossfire since the R9 290 series",
      "I have almost the same setup as you. Red Devil (non ultimate) on an alphacool block. My everyday stable settings are: \n\nMPT:\n\n* 330 Power Limit / 350 TDC\n\nRadeon Software:\n\n* Max Freq: 2700 MHz\n* Voltage: 1075mv\n* VRAM: 2100MHz  w/ fast timings\n* Power Limit :+15\n\nThis is good enough for a 22,600 GPU score in Time Spy. \n\nI've read that there may be issues with clock stretching, so even though you have higher clocks, if there's no performance uplift, you're just unnecessarily making more heat for yourself.\n\n."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6950"
    ],
    "title": "[HUB] Radeon RX 6950 XT or GeForce RTX 4070, Which $600- GPU Should You Buy?",
    "selftext": "",
    "comments": [
      "Preparing for the war in the comments ![gif](emote|free_emotes_pack|flip_out)",
      "Especially since he recommends the 4070.",
      "I'm so incredibly confused. I was repeatedly informed by reddit that Steve was an AMD shill, yet he recommended a Nvidia product?",
      "Tbh the value play would be the 6800xt for $500 (While stock lasts)\n\nNot really a right answer between the two though, pros and cons to both\n\nI'd choose the 4070, getting DLSS and using 150W less is more important to me",
      "For AV1 and lower power draw, which given he streams kinda makes sense for that use case.",
      "Used 3090s average over $800",
      "I went from a 3070ti to a 6950xt. It might just be me but ray tracing isn't what others describe, could be my old eyes. I barely notice the difference in games that are supposed to showcase it like cyberpunk, metro, doom, or dying light 2. That could very well be different on the 40 series but I see no point in following ray tracing till it's more of a standard in games other than triple A titles. I noticed the difference in say Minecraft but that's really just Minecraft getting an update to old visuals. I play loads of single player titles and in every one of them ray tracing was a gimmick for a few things that just tanks fps. \n\nI'm pretty happy with my 6950xt but I also still have my 3070ti if I ever get the itch to stream, record, or play Minecraft with RT on. Similar story with DLSS vs FSR 2, FSR 1 wasn't great but 2 is good from a performance standpoint and I'll see what 3 offers but they all feel like gimmicks.",
      "and 3090s consumer up to 450w, while a 4070 sits at around 200w, not sure about him, but power bills have increased considerably in my country over the last few months.",
      "I haven't seen Intel/Nvidia Unboxed, but I have seen AMD Unboxed and Nvidia Foundry.\n\nFunny how they are fanboys of everyone depending on who you ask though.",
      "Did you play the normal version of Metro? Because Metro RT on vs off has HUGE differences with the Enhanced Edition where they rebuilt the lighting system completely. \n\nTake a look. Side by side it's a complete different game. Runs better than the raster version too (which is strange lol). You should try it, it's a great game\nhttps://youtu.be/pmpwMiSDYP4",
      "I can't even disagree. \n\nAfter using it, DLSS3 is an extremely compelling feature despite its flaws. Running around in RT overdrive at 80-90 fps in CP77 on a 4070 is something nothing from AMD can do (even if they get an FSR3 frame doubler the base RT performance isn't there on a 7900XTX. Maybe RDNA4 will get it right.)\n\nIt's a great experience for single player narrative driven stuff.",
      "I agree with him although the 6950xt generally performs better without RT. I don't think either is a bad choice though at the same price, maybe the 7800 series will be more competitive.",
      "It would have lined up perfectly if the the 7900XT was a 7800XT as it should have been. \n\nAMD wanted that sweet $ upcharge without having the performance/pricing gaps for the rest of the SKUs.\n\n7900XT at $900 was a big blunder. Period. Now it's dropped down to $750ish range headed towards $700ish and leaves little room for a 7800XT. Would not expect anything different from the AMD Radeon team tough. It's no wonder they took ATI's near 50% market share in this segment and pretty much nearly lost it all.",
      "None of the above. New 4070 costs similarly to a used 3090 (if you find a good deal it's within $50 in some cases). Except 3090 has twice as much VRAM and actually performs better in games (it also outperforms 6950XT).\n\nPersonally I **really** don't see a point of spending 600+ USD on a 12GB VRAM card that also happens to be the weakest xx70 in a looong while (compared to full sized dies). This thing is gonna be dead within a generation so there's no difference between it and outright buying a used card.\n\nIf it has to be AMD - there are thousands of 6900XTs on ebay often sold at below $500. It's going to perform almost the same as 6950XT.",
      "> (it also outperforms 6950XT).\n\nit doesn't. \n\nit also consumes almost double the power compared to 4070, and it is a potential risk to buy used due to VRAM temp issues they had. And 3090's are much bigger, so 4070 is more likely to fit your case and you don't have to have a really powerful psu like you do for 3090 thanks to power spikes.",
      "Or you don‚Äôt live in a country where electricity has skyrocketed in the last year.",
      "Majority of my time is spent in FS2020.  I'm leaning towards 4070 for DLSS3 and VR.",
      "I would too. 6800XT for $500 isn't that compelling, I'd rather spend the extra $100 for a 4070. Will make up the $100 difference power cost alone in next couple of years of using it.",
      "I really think a proper DLSS 3 competitor should be an all hands on deck situation for AMD. Doesn't matter if they can get a 15% performance advantage natively if Nvidia can just double or triple theirs at the quality DLSS 3 delivers. \n\nI'd go as far as saying anyone who dismisses the technology simply hasn't tried it.",
      "Why go either or when you can have both."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6950xt"
    ],
    "title": "First AMD build! 5800x3d, 6950xt, 32gb 3600mhz and of course, torrent:)",
    "selftext": "",
    "comments": [
      "I really want that case...but at the same time my 4000D Airflow was only $90 lol",
      "Yeh, i was between this and 4000 or 5000d. This one was around ¬£160 with discount, not cheap, but ƒ∞ really like its design and the airflow/temps are just crazy!!",
      "ƒ∞ mean, 5800x3d was not exactly cheap but i have the motherboard and the psu and the rams, so came cheaper if you compare it to building a new setup with ddr5 and 7000 series. And was lucky enough to got the 6950xt for ¬£815, even 3080tis was around 900.",
      "Fractal torrent. I have one. One of the best airflow cases on the market.",
      "Real value PC... Epic build My man!",
      "Yup. Like even now, for gaming, a 5800x3d system with a Decent B550 is half the price compared to a 7700x system. And the gaming performance is like equal or close to it.",
      "Exactly! 350 for cpu, 250 for new gen mb, 200 for ddr5 ram, thats 800 for the new gen. ƒ∞ paid ¬£400 for the 5800x3d, 150 for my b550 tomahawk, 100 for the ram, thats 650 and ƒ∞ spetlnt the extra 150 on gpu",
      "Its cheap compared to the shitty new overpriced AM5 stuff.",
      "Absolutely banger! All the hate towards amd, especially gpus and the software. ƒ∞ am coming from a 3060 build and let me tell you, ƒ∞ fucking love the adrenaline and 6950 is crushing whatever ƒ∞ throw at it",
      "Idk about value I'd call that a banger tho",
      "The torrent is truly a master class. I‚Äôd change a few things about it. Like maybe more metal, but that‚Äôs nitpick stuff. It‚Äôs beautiful, spacious, and feels premium even with some of it being plastic.",
      "Yeah, very overpriced and not that great of an improvement if you ask me",
      "What mb and psu is that? Nice build",
      "Is it better than the meshify 2? I'm in the market now for a quiet airflow case.",
      "My setup has x2 180mm fans in the front and three 140mm at the bottom, all intake. The cases usual setup is all intake. It looks like OP has exhaust but in my testing it was pointless. The PSU is mounted at the top and actually acts as an exhaust fan. Very old design, also very effective. You don‚Äôt see it a lot anymore.",
      "5800X3D is not a value cpu, neither is 6950. Step to 5700X/6800XT and you retain 80% average gaming performance but costs 40% as much.",
      "Agreed software is 100x better",
      "Yeah reusing parts you already have is the best part of AMD, my build has been upgraded from the first gen Ryzen AM4 launch in April 2017. If only the bios update came out sooner for my X370 crosshair VI hero I woulda kept using it to this day. Oh well I turned it and my old R7 1800x into a beast server.",
      "That is sweet set up. I really want to build in this case one day. Trying to talk my kids into one. Really like the looks and function of it. You set this up nicely.",
      "Building tmr the same build but in lancool 3 will post soon"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6950"
    ],
    "title": "Upgraded my 5700 XT to a 6950 XT last week",
    "selftext": "",
    "comments": [
      "You should definitely run two different pcie cables.",
      "Yeah I just made the switch after initially being stubborn about it with another redditor. Never knew that was a thing.",
      "That's around 100% performance boost dude enjoy.",
      "Why people hook hungriest gpu on single pcie cable?",
      "Yeah one of those cables is rated at 150 watts. You‚Äôre drawing over 300 on a single cable + the pcie slot itself. Better to be safe than sorry",
      "Its two 8 pins from single cable, even if its less power hungry than 3090, doesnt mean that single cable can provide enough power for the strongest 6000 series card",
      "If there‚Äôs more than one plug it‚Äôs good practice to always use different cables for each plug",
      "Eat my ass\n\n*With love <3, and a bit of jealousy*",
      "Well, if there's any weird instability you know a probable culprity. This is consided poor \"workmanship\" when building a PC, sometimes the single cable can't keep up with the transient loads and what not",
      "Im far from mad, im amazed how people can be stubborn and ignorant. You have advices from amd directly to use two separate cables instead of piggy tail back on 5700xt models which use half the power 6950x use. Good luck with another black screen/bsod upcoming post",
      "It‚Äôs just really nice to see people can actually buy GPUs at a reasonable price now, and the prices are still coming down too.",
      "A red devil red devil?",
      "You wont, wires and connectors need little time to wear off. Your weakest link is the connector on the right side on the gpu, since both wires from him and other one are in same place. Resistance is the biggest on joints and that will be the hottest part. Depending on environment temps, gpu usage and other factors its judt a time bomb when that one will start to melt. \n\nYou probably have another pcie cable in your psu box. Its 2 min job to hook another one and be safe.\n\nAlso you have bunch of videos on youtube from respective tech tubers, bunch of warnings and posts from both nvidia and amd in order not to use piggy tails on hungry gpus. 6950x even if its more efficient and less power hungry than nvidia conterparts, it still demands more than single cable for the gpu",
      "So much more gooder üëç I'll be going from a 5700 xt to a 3080 come Friday!",
      "That's not how this works at all.\n\nA single cable is rated for whatever the power supply rail it's attached to is capable of or the maximum you can draw using the connectors it has. A PSU designer wouldn't design something that can catch your house on fire for the sake of not adding a couple more cables.\n\nIf your power supply has separate rails to feed the different cables then it's a good idea, but if your power supply only has one cable or one rail then it's fine provided you aren't drawing more power than the PSU is capable of delivering. Even if you did overload the power supply all that will happen is your PC will shutdown.",
      "AMD just measures the GPU itself but not the rest of the card.",
      "It‚Äôs not bs. It‚Äôs risky to use daisy chain on a 3x8 pin gpu with high wattage like around 400-500 and sometimes spikes that are in excess of the limit. It can and has fried other peoples gpu because they didn‚Äôt use 1 gpu pwr cable per 8 pin connector. Better to be safe than sorry\n\nSource: https://linustechtips.com/topic/1277102-psa-do-not-use-daisy-chain-power-cables-for-3000-series-one-cable-per-8-pin-gpu-power-connection/",
      "You are welcome!",
      "And sorry for initially being stubborn about it",
      "Just did it, was relatively painless besides dealing with my shit cable management in the back that looks like Homer Simpson with his fat taped to his back."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900xt"
    ],
    "title": "Massachusetts people - MSI 6900xt for $630 at MicroCenter only 6 left!",
    "selftext": "",
    "comments": [
      "I have a feeling that new gen prices will be way better than nvidia.",
      "i have no confidence of that so i picked one of these up before any announcement. Since at microcenter you can return anything within 30 days ...  Its compelling to at least have this for now.",
      "AMD just needs to match or beat the 4080/4070 at a cheaper price.  Should just ignore the 4090 all together.",
      "XFX Speedster $650 on Amazon - https://www.amazon.com/XFX-Speedster-Radeon-Graphics-RX-69XTAQFD9/dp/B09M38TVL2/",
      "It's mad that there's still people paying more than this for a rtx 3070ti",
      "Doubtful. You'll probably be able to get a similarly performing card to the 6900XT for around this price but the top tier new card will be 1200+",
      "You can assign a dollar value to the enjoyment you received over the past year, if that will make you feel better.",
      "XTXH is a binned chip with the limitations on OC and power removed, so that you can benchmark for bragging rights with no practical real world application whatsoever.",
      "It's even a good one",
      "I am in Europe and found 6900xt for 740 euros (which is impressive), only if it was not a amazon 3rd party seller (they are usually shotty drop shippers).\n\nEdit: yeah, i only need a 6700xt, but‚Ä¶\n\nEdit: fuck me, i start to even lower prices, especially higher end cards. C‚Äômon i need a new psu then.",
      "i think they will be able to match it in Raster performance which is all that really matters, then they can undercut it in price and punish them.   They are cutting a big log slowly having something to keep those 3080s and 4080s of them in shelves will not be that difficult once if  they blow the performance and price out.   Nvidias mistake is not having a new gen card within 85% performance  of their flagship at $700 they  gimped the tiers below too much for their price.   Having a card perform better than the stock 4080 is the slot they should be aiming to take and then beating them to the market  with  4060 ti competitor which  will be the market share leader around a $450",
      "Just a little PSA - Trio Z is a guaranteed XTXH chip while Trio X is not",
      "Amazon also has their holiday return policy in place so you can return items until January 31st",
      "I bought my red devil 6900xt for $1800 a year ago fml...",
      "i guess they needs cuda? \n\n*if you are blender  artist, buy enviidiuhh*",
      "Thats what scares me. I jumped on a 6800XT new for $550, and sold my 2080 Super. After seeing Nvidias lineup and the awful price/performance outside of the 4090 (and thus the entire lineup), I pulled the trigger. I could definitely see the 7800 (non XT) being roughly equal to the 6800 XT, but do I see it being sold for less than $550?...If Nvidia can charge those prices, AMD would be downright dumb to leave hundreds of dollars on the table per sale (hyperbole but you get the point)",
      "Thats what drove me to overlook the sometimes-underwhelming drivers considering the cost, perf, vram relative to Nvidia stuff it made 0 sense.",
      "Merc has better heatsink and overclocks much better than swift. I believe Merc cards are also binned higher than the swift cards",
      "Just curious what does this mean? I did not know the chips were varied?",
      "So I could return it and upgrade to 7000 series after they release"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900xt"
    ],
    "title": "Ryzen 5950X | Red Devil 6900XT | P600S",
    "selftext": "",
    "comments": [
      "I just have one question.  Who did you have to blow to get your hands on all these parts?  Might be willing to do the same.\n\nEdit: I don't know why you guys are down voting OP for giving a sarcastic answer to my sarcastic question but stop it.  OP did answer the question seriously later in the thread.",
      "Well congrats on snagging some of the most difficult to source computer parts in modern history.",
      "*Ryzen 9 5950X 4.8GHz/4.6GHz@1.275v\n\n*Red Devil 6900XT 2745MHz@1175mV\n\n*ROG Crosshair VIII Formula \n\n*32GB 3800MHz CL14 Trident Z \n\n*EVGA CLC 280 w/Noctua's \n\n*Corsair HX1000i w/Cablemod Pro Carbon's.\n\n*Phanteks P600S case.",
      "Nice build my dude :)\n\nJust be warned, your GPU will get hot.\nI have the same case and although it has a built in capability for vertical mounted GPUs it is still too close the side panel.\nI bought the cooler master vertical mount V2.\nWay better temps",
      "Things usually work out better when you try and not tell others how they should have spent their money. But I'll keep it in mind next time I'm buying.",
      "ü§£ \"Only 32GB\"   \nAppreciate the laugh and downvote",
      "that guy wasn't an actual guy , it was Dbrand :/",
      "Hey I have a old 380 on the shelf.. just saying :)",
      "Appreciate it, took lots of checking and random Microcenter runs to acquire it all.",
      "Beauty of a machine. Black and not white. RGB if needed but not set to unicorn puke. Air cooled GPU because you'd gain very little from liquid. Quality fans. Nice case. Fantastic component choice. Very nice my good sir. Well done.",
      "Thank you, and they are 3600 CL15 DIMMs pushed a bit.",
      "My closest microcenter is about an hour away so it makes it almost impossible to just pop in to check stock.  Guess I'll just wait for things to get back to normal and keep using my R7 4800H 5600M laptop until they do.",
      "Jealous much?",
      "Thick. Tight. Solid. Ready and willing.",
      "Yep he's just mad",
      "The best AMD has to offer! (currently on desktop)",
      "Those are +600Mhz 3200 sticks? What an awesome build man.",
      "The classic \"it's not much but it's mine\" build. \n\nReminds me of that guy on Linus Tech Tips who asked them to build an illuminati pyramid computer with 4 2080 Ti's, a 64 core threadripper, and 256GB of RAM, which changed to 2 3090s and a 5950x. \n\nIt was clear that the guy just wanted whatever was the most expensive parts regardless of whether he'd have any use for it. \n\nTurned out in the end the guy just wanted to game and stream with it and that's it.",
      "It looks great, but what about sitting the GPU in an orthodox manner ?",
      "The case is huge. I was locked in with choices due to card length restrictions in my Meshify C and in this there‚Äôs still space for a melon after the card.\n\nEnjoy"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900xt"
    ],
    "title": "I consider myself very very lucky. 5950x and reference 6900xt. I managed to pick up both on their respective launch days",
    "selftext": "",
    "comments": [
      "It's sad when you have to use word \"luck\" when buying computer parts.",
      "Cables. Cables everywhere!",
      "Not sure why you watermarked your reddit username on the pic as no ones gonna wanna take it and pass it off as theirs due to the cable management upfront lmao\n\nEither way congrats as its a solid build!",
      "Truly",
      "Not your desk your PC... sorry but that's some of the worst cable management I've seen in a while. And the hoses... what was the point of getting the more expensive AIO with the digital temperature readout if you can't even see it?",
      "the hoses dangling in front of that Kraken Display is gonna keep me awake tonight",
      "Brother you probably had to move the whole PC to upgrade it, you should have vacuumed while you had it out   xD\n\nIt's too bad the hoses on the CPU cooler don't connect on the other side of the block so they don't block the display on it.\n\nSweet rig though.",
      "Yeah I'm not that happy about AMD and Nvidia! In fact they did a really poor job in 2020 plus you can't get anything for MSRP right now, who's idea was it to release consoles at the same time, that person should get fired and everything on 7nm TSMC ok Nvidia is on Samsung's 8nm but they probably couldn't get enough supply from 7nm TSMC so they went to Samsung which doesn't do much better right now! 2020 is the worst year ever to upgrade a PC or get a new console!",
      "Considering both are out of stock.",
      "The shit show is also caused by vendors not having queue systems, scalpers, and users willing to pay way too much.",
      "The cable management is hurting my eyes",
      "Why would anyone position it like that...",
      "Its one thing if your cable management looks like that and you have a solid case. But a case with a side window? c'mon",
      "Underside of my desk is indeed super messy",
      "Sorry to break it to u dude, general rule of cabling. They dont cross each other. 0 overlaps. Second thing, u can cable from behind the motherboard, or make more efficient routes for ur  cpu can fables cus they're noticeable if lifted off it. Third and most importantly, unplug the gpu and put it through the hole horizontal to ur gpu. U spent the money on a nice pc. Make it look classy üßê. If u need any help just post here and I can give u more advice on better runs for ur cabling. Behind it doesn't matter.",
      "What the fuck is wrong with you!?\n\n.\n\nWhere is the cable management? Also vacuum near those moldings.",
      "It's not like they \"just went with 8nm\". I don't think anyone could have expected this crazy demand we're seeing at the moment...",
      "I believe he means using 2 separate pcie cables, not just piggybacking the one.  Those cables can only supply so much current, so using 2 will give you headroom and avoid overheating the wire.",
      "Too much money.",
      "nice watch"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900"
    ],
    "title": "Can't wait to install my brand new 6900 series card! ;)",
    "selftext": "",
    "comments": [
      "i have 6950\n\nstill alive\n\ncan do 6970 flash no problems\n\nbut sitting in a shelf because rx560 is more then 3x more efficant with 20% more performance overall\n\nedit: PSU powering it with 6970 flash,OC and overclocked Q9550 to mere 3.6Ghz died because shit managed to hit 600w\n\nPSU in question was OCZ SXS 600w 80+ gold",
      "Hard to believe they had that puny fan for two gpu's",
      "I know those feels. My R9 290 was fun as heck but between it and my 8ish core bulldozer I did light a PSU on fire.",
      "According to the Anandtech tech review it ran at 94C with 77dba noise while running furmark.",
      "6990? That's at least 90% better than the 6900xt, cuz it's 90 more.",
      "Heck, I only retired my 290x last year, those cards stayed relevant for a *very* long time if all you needed was 1080p 60.",
      "Still running a 290x and a 4690k. Its pretty passable still honestly.",
      "I miss this card. I felt so elite having one but then i realized all i ever did was benchmark. Never played games lol.",
      "I was running a R9 280 with a i5-2500K until last month XD",
      "it has only 375W on 2 chips, thats about 40% less power consumption each chip than that 6900XT single chip hot garbage!",
      "I had a sapphire 6970. Was a beast for a long time",
      "Nice, I had a Gigabyte 6950. Two of them in crossfire actually! Boy was that a colossal waste of money üòÇ",
      "I'd probably still be using mine if I didn't get a 1440p 144 monitor last year.",
      "Something like that yeah",
      "Nvidia 3090 and 3080 says Hi :)",
      "the 2500k is a beast of a chip. Still running at 4.5ghz in my sisters living room PC after all these years...",
      "WTF are you serious? That‚Äôs louder than a vacuum cleaner.\n\nWhat is it with AMD and their atrocious reference coolers? Like every high-end card of theirs for the last 15 years has sounded like a hairdryer while just barely keeping the GPU cool enough to avoid emergency shutdown.\n\nAt least nowadays the 3rd party manufacturers can create a competent cooler. Back in the day, the only choice you had was which ugly-ass decal to get on the reference cooler.",
      "Late 2000s - Early 2010s - that was a good era for Radeon.",
      "I miss the GPU Artwork.",
      "They looked pretty damned sick, though, didn't they."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900xt"
    ],
    "title": "Managed to pick up an ASRock Phantom D 6900xt at MicroCenter for $702",
    "selftext": "",
    "comments": [
      "Notes:\n\n1. It was technically open-box but clearly unused. The original peels were still on the card!\n\n2. I realize I'm on the knife's edge with a 650W PSU though under full load I estimate my peak power draw at ~520W. Not efficient at all, but it works. I do plan to get a bigger PSU soon.",
      "Yep upgrade that PSU think 750 would suffice.\n\nCongratulations on the card! Very good deal. Your cable management made me rise my eyebrows tho.\n\nNot using closest openings for the cpu power and some others.",
      "congrats on the deal. \n\n&#x200B;\n\n650 watts is cutting it close although you should be fine as long as you undervolt.\n\nIf you are going to upgrade your psu I would suggest moving up to at least 850 watt gold to make it worth it in case you plan to upgrade your gpu again in the future or upgrade to any power hungry component(s).",
      "In 10 years it'll be $100.",
      "I love Microcenter open box deals! I'm picking up a Asus TUF 3080 12gb for $675 tomorrow.",
      "CPU: R5 5600x\n\nCooler: ID-COOLING SE-214-XT ARGB White. Neat little cooler I got off Amazon for $20. Works well enough.\n\nMobo: Asus B550M-A A/C\n\nRAM: 32GB G.Skill 3200 + 16GB generic 2666 stuff OCed to 3200\n\nCase: Lian Li Lancool 205 Mesh\n\nThe motherboard, CPU, and the generic RAM came from a PowerSpec G508 I bought at MicroCenter in 2020.",
      "Nice.  \n\nMy Sapphire Pulse 6800XT was 1042USD back in march.  Part of me is mad for not waiting just a couple weeks.",
      "Have you tried an undervolt? Might be able to save yourself another ~50W of peak power draw via Radeon Settings' undervolting, or some manual tuning.",
      "Yeah, I need to completely redo my cable management. I know it's inconsistent at the minute ü§£",
      "Open box deals at Microcenter are solid",
      "I've had my Phantom since Feb 2021 and I've had to get a support bracket as well as upgrade my PSU since at 750w it was cutting out under load. Just a heads up!",
      "Nice specs. \n\nYou got a bit lucky on that ram, OC'ing that far and there's at least a small amount of luck involved in a mismatched config like that working at all(there isn't supposed to be, but in the real world, there is).\n\nStarting with a prebuild and upgrading down the line is a great way to do things. \n\nYou got lucky with a cheap cooler too, one that cheap would scare me on a decent CPU but hey, if it works it works. Definitely consider an upgrade if you pull the trigger on a 5900 or 5950, more cores mean more heat. I've got an AIO on my 5950x and even in a stress test I only see a brief moment above 90C, and in actual loads I've never cleared 80.",
      "I got lucky indeed. I randomly saw the ram just sitting in a box and wondered if it would work. It's been rock solid stable, no issues.",
      "EXTRA LONG CABLES",
      "why not white?",
      "Yeah definitely go higher. I wouldn't even look at anything under 750 for that upgrade, and then only if you are at a hard budget limit. 850 should be the baseline you look for. You'd be using somewhere between 600 and 700W, so even in a money is no obstacle budget going past 1400 would probably be a waste(you'd go below the most efficient load percentage at that point).",
      "Thanks for the suggestion, I'll definitely be getting at least an 850 when I upgrade the PSU.\n\nI also do plan an upgrade to a 5900 or 5950x at some point, and my little 650W unit *definitely* won't be able to handle that.",
      "Solid advice there. Unless you are playing in 4K ultra, downvolting with little sacifrice on performance didnt hurt that much.\nAnd lower heating on the summer time",
      "Yeah, I picked up my RAM on one as well. Saved $40-50 on the kit I got a couple of years ago. Still running great!",
      "850 is a good choice but if ya can secure a good deal on a 1000-1500W one, ya golden :D\n\nMade that choice in 2018 after seeing the trends go up and up... Invested in a 1550W Thermaltake TF1 Titanium PSU.\nBest choice ever, basically has no noise whatsoever."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900xt"
    ],
    "title": "3700x Asus x570-P, With a Sapphire toxic 6900xt",
    "selftext": "",
    "comments": [
      "Loving everything about the build! And that monitor is absolutely gorgeous!",
      "I love orange :) This makes me want to swap my fans for orange RGB fans as well. Looks so good.",
      "Lol, for sure! \n\nI moved out to the boonies with the wife and kids and we have no cell service out here, so if the internet goes down we have no phone, so need a land line in case the office calls and we have to leave to move equipment.",
      "It does fine for the games I play, I am sure it would bug some people, but I am okay with seeing 50fps in some games. I grew up playing the old consoles where slow down was a added feature haha",
      "Yeah it‚Äôs real nice when contractors send me site plans and I can view the bigger picture.",
      "I went to visit family this Christmas and my dad had me use his 27‚Äù 4k monitor, I realized then that I could never go back to something smaller. \n\nFreesync, 144hz, and screen real estate is something you do not realize you need till you need it.",
      "Thank you!",
      "What monitor is that",
      "Samsung Odyssey g9 I believe, 3840x1080.",
      "In my experience the 3700x is a powerhouse and has no problem playing anything.",
      "Got the same monitor with a 27\" vertical next to it. Gaming and working are soooooo nice!",
      "Hmm I also have a 3700x and cyberpunk holds a solid 60 with everything maxed. It‚Äôll occasionally drop to 58 or 59 but that‚Äôs because of my GPU rather than CPU. These CPUs can be a little tricky to get max output though. Have you run cinebench on it yet?",
      "I love you have the most up-to-date godlike tech and a 20 year old phone right next to it",
      "I feel this is my go to color for most things, it‚Äôs not in your face and it‚Äôs pretty chill.",
      "I agree and also it fits nicely with black.",
      "Cyberpunk 2077 with everything maxed haha. \n\nI like to make my pc sweat.",
      "I work in IT on a level 3 team, so I've always got a LOT goin on my screens. I did have two 27\" monitors but it's just not the same as the 49\". I'll never go back",
      "God orange is my favorite color, but I'm rocking red RGB nice build though especially that widescreen monitor sheeeesh",
      "Love it. Can we share this on AMD social media?",
      "I actually don‚Äôt care for orange at all but this build is changing my mind. Absolutely rocking that orange, gorgeous build."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6950"
    ],
    "title": "After nearly 7 years of waiting and 2 children I had the chance to build a new rig. 5800x3d + 6950 xt.",
    "selftext": "",
    "comments": [
      "First Asus LC 6950 XT I've seen in the wild. Where'd you even get this thing?",
      "germany ![gif](emote|free_emotes_pack|sweat_smile) yeah I also noticed the lack of LC strix 6950 xt",
      "And soon those children will occupy the computer and game on it üòÇ",
      "Ahahah now you have to wait them to sleep for use it =D only parents understand you !!!\nMerry Xmas from France to your family and enjoy it <3",
      "Let me know the specs when you test it. Been looking at the 6950",
      "In Canada I've only ever seen it in stock on Amazon and they didn't have a large amount either",
      "It uses a flexible PCI Express extension cable to allow the card to be mounted outside of the motherboard slot. The case also has additional vertical slots and screw-down holes to secure it there.",
      "The case supports vertical mount next to the horizontal slots",
      "I will let you know!",
      "[3DMark for you. Is this enough or do you want specific test?](https://imgur.com/a/odT1BVQ)",
      "The real struggle! üòÇ",
      "How do you install the GPU in that orientation?",
      "Damn nice build. How much did you get for the children to build that bad boy?",
      "Mind sharing your bios/cpu settings? I have my 5800x3d scoring 10,7xx, and 6900xt scoring 22,5xx. I've only been able to score 11,5xx once, and I can't pin down the exact reason. Both on custom liquid loop.",
      "i was about to say the same thing lol, maybe 24/24? who knows",
      "For real. I should have waited to buy gpu cause I don't get to use it much.",
      "the specs are awesome! can only recommend so far :)\n\nhappy holidays!",
      "One reason we don't have much stocks here in canada, i noticed that almost everything has less stock compared to US or EU. My guess is that this country blocks the creation of large amount of stocks.",
      "Make sure you're on the windows balanced power plan.",
      "Just built the same spec system with a msi rx6950xt and r7 3dx. Its a beast of a system. Vr sim racing and flight Sims are mostly what I do and I can just about run max settings in everything besides MSFS. On my 1440p 144hz monitor I have everything maxed out and it runs flawlessly. Cyberpunk is the only game I get about 80 fps, everything else is over a 100fps."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6950"
    ],
    "title": "6950 xt + 5800x3d build done!!",
    "selftext": "",
    "comments": [
      "That AIO is in love with that 6950xt, its the glow in the eyes!",
      "lmao smiley face with tongue out",
      "Top1 cpu and top1 gpu\n\n&#x200B;\n\nClass",
      "hahaha it seems pretty happy indeed.\nuntil it starts to pump all that hot air on it that is‚Ä¶",
      "When the 2nd place is second by mere percentage points and costs only 2/3 as much or less, the \"1st place\" doesn't mean that much.",
      "pretty good it gets toasty at all cores load about 85 c\nbut when gaming its aboit 60-70",
      "Damn, that's quite the pair.",
      "How's that 240aio handle the 5800x3d?",
      "Looks like Arctic 240mm.",
      "What kinda GPU temps do u get with it?",
      "Looks happy anyway",
      "oc vbios edge temp 60-70 and junction 80-90‚Ä¶",
      "The 6900XT and up coolers are actually really good. Even pulling over 300w, the edge temp of my TUF 6900XT is only like 70c with the junction hitting 90c. This is even better compared to my old 5700XT, which pulled half the power and junction would be over 100 whilst edge temp was 70s with almost a 30c difference between them.",
      "That was a fast reply! Thanks for the info my guy",
      "What AIO is that?",
      "yup arctic",
      "Wait for what? To be disappointed in available stock?",
      "i have it on a 1440p screen for competitve games and a 4k tv for casual games",
      "If you undervolt or with CO maybe. At stock you don't get those temps on a 240 AIO unless you have 10C ambient. 85C CB R23? Yeah right.",
      "Niceee. Enjoy"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6950"
    ],
    "title": "Wow, massive improvement...upgraded GPU from RX 5700 XT Liquid Devil > Sapphire Nitro+ 6950 XT (water cooled w/ Bykski block)",
    "selftext": "",
    "comments": [
      "I‚Äôve looked at Bykski block for my 7900xtx. Where did you get the thermal pads from? That‚Äôs the only thing holding me back. Bykski is the only brand that makes a waterblock for my Gigabyte Aorus 7900xtx from what i can tell",
      "Thermal pads came with the block. There was only one little square I had to double up the pad to make contact. It wasn't RAM or VRM, though, so I'm not worried (although, I don't know what it was). The card is running like a champ.",
      "1. Air is not \"better\" if it comes with noise.\n2. The FPS increase of the 7800 or even the 9070 over the 6950 (non RT'd) at 1440p wasn't worth it when I already had the infrastructure for liquid cooling,  considering any reasonable generational upgrades that I could get a water block for were a ton more money.",
      "A water cooled vertical mount 5700?? What in the..",
      "that tube pathing is giving me anxiety. lol",
      "more room for error with elbows",
      "Hahaha then I had just the build for you. [enjoy¬°](https://i.imgur.com/LRI0kNT.jpeg)",
      "Fine wine pulled the RDNA3 cards up further from the initial launch where they had smaller gains. The XTX Nitro is up there with the 5080 and breathing on 4090 in native raster lmao.",
      "Not even close.  I keep my fans at a fixed 1,000 RPM for a whisper quiet rig.  Running Heaven (maxed out) and Prime95 (small FFTs)  simultaneously for 30 minutes results in the following:\n\n1. Max CPU temp: 72c\n2. Max GPU temp; 53c\n3. Max GPU hot spot: 69c\n\nHeaven + Prime95 is my go to for thermal testing.\n\nRunning more demanding games, my GPU barely reaches 60c and the hot spot never gets out of the mid 70c range, while my CPU is typically in the mid to low 50s.",
      "The backplate on the 6950 came with the block.  I got it from formulamod.  They were \\~$70 less than ordering on Amazon or directly from Byski.",
      "Plus it's a cool enthusiast thing to do.  ;)",
      "Interesting upgrade! Why go for a water-cooled 6950 XT when you could get something better on air? I get that pricing matters, but doesn‚Äôt water cooling add a lot to the cost too? Just curious.",
      "They're cable extensions purely for looks.  I'm using the Asiahorse ones from Amazon and have found them to be high quality compared to other brands.",
      "I ended up not needing it.  It turns out 360mm of radiator is enough for my situation.",
      "What are you talking about? More like 50-100%. I play at 5120x1440.  I'd say that's pretty massive.",
      "Good to know. Thank you for the response. Did the have an option for this back plate or is that from somewhere else?",
      "Nice! Thanks for the reply.",
      "Yeah 6950 XT is still a beast of a GPU.",
      "Exactly.  For pure rasterization, it's still really competitive with newer cards.  And it's even playable with RT if high FPS (>100) isn't important, like in racing games.",
      "Much appreciated bud üôèüèº"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900"
    ],
    "title": "Surprisingly good performance on a 6900 XT in Cyberpunk after 2.0 patch. Even running native with ray tracing on. Anyone else experiencing the same? 50-60fps stable at native 1440p with all graphics settings maxed and ray tracing enabled (except path tracing, lighting on Ultra).",
    "selftext": "",
    "comments": [
      "5600X and 6800 XT here.\n\n58-60fps in the city, 100-120fps inside buildings.\n\nCan't be more pleased. Already on my 4th playthrough.",
      "I dont get that big of a FPS jump using FSR or Intels upscaler when setting both to quality/high quality mode respectively. Goes from 50-60fps, up to about 60-70fps. Kinda surprised by the results, but definitely in a positive way.",
      "Its not. He's thinking RSR which is FSR1. FSR inside CP2077 is FSR 2.1 which is superior in every way.",
      "Wait, is this max graphics plus ray tracing at 1440p?",
      "Okay I tried it, a bit of tweaking like volumetric fog on medium and SSR on med-high plus FSR balanced at 1440p and I can get to 55-60fps on ultra RT. It's amazing because if I remember correctly I can only get to 30fps before with RT on",
      "Y'all. If you want good performance gains. With screen space reflections, go from psycho to ultra. It used to be like 40% performance impact.",
      "With my 6800 Xess UQ produces less frames than native",
      "It has stronger image reconstruction quality, but at the cost of extra compute time. The compute time can be long enough that the reduction in internal render resolution isn't enough to make up for the difference. It should otherwise be upscaling from the same resolution at the same quality levels.",
      "Yes, same with 7900 XTX\n\n7900 XTX ‚Äì Avg 63, min 49, max 84\r  \n7900 XTX ‚Äì Avg 71, min 54, max 94 (patch 2.0)\r  \nThis is with AMD 7700X, ASRock Radeon RX 7900 XTX Phantom Gaming OC 24GB\r  \nUltra settings, FSR 2.1 quality, raytracing all (normal) max, 1440p\n\nAlso testers show these results.",
      "Turn down a few settings and cap at 60fps for a fantastic experience!",
      "6700 XT here, playing at 4k stable 60+ fps with texture-related settings maxed out and others around low with FSR on balanced (with FSR 2.2 mod I'll probably do Quality). Using a 1080p monitor but 4k render is a day and night difference.",
      "I have to do RT plus FSR to get 60. What are your settings?",
      "I need 16k native path tracing at 480fps who is selling that product my budget is $300",
      "Xess definitely looks better than FSR, so I imagine it doesnt downscale much, if at all in the Ultra Quality setting compared to FSR in Quality. But I do still see a jump in frames a bit, 5-10fps.",
      "I‚Äôm genuinely so happy that the non-PT RT in Cyberpunk has been better optimized for AMD gpu‚Äôs. Several of of my friends have them, and I always felt bad that they could run games like Control or Metro Exodus with RT fine but Cyberpunk (a game more of them were actually interested in) completely destroyed their systems. Cyberpunk with RT Ultra on looks completely different than the rasterized version, just like Metro Exodus does. But one of those always ran at least okay on AMD gpu‚Äôs, and the other didn‚Äôt until now hahaha",
      "Makes me hyped for my first Cyberpunk playthrough i have planned",
      "This is not possible you must have had fsr on without knowing",
      "Not just you. I‚Äôm playing with RT on now. It‚Äôs not blow your mind good, but by comparison it‚Äôs great. FSR3 will make it even better and remove the dips to the upper 50s I get.",
      "Just an idea. I've heard that xess is better than fsr in this game so that might be worth trying out too",
      "I did noticed a big jump with my 6750 on High, RT OFF and Effects also off and FSR on quality."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6950xt"
    ],
    "title": "Since 6950XT is now $600, what will the 7800XT be?",
    "selftext": "The 7900XT cost $780.  \nThe 6950XT cost $600.  \nThe 7900XT is 30% more expensive than the 6950XT with current pricing.  \nThe 7900XT must be faster than the 7800XT obviously, but the 6950XT is already pretty close to the 7900XT in raster, so where will the 7800XT be compared to the 6950XT? Will it be slower in raster? For what MSRP, when the 6950XT is $600?",
    "comments": [
      "$499 with 6950xt levels of performance, with less power, and they have a home run on their hands.",
      ">\"6950XT is already pretty close to the 7900XT in raster, so where will the 7800XT be compared to the 6950XT?\"\n\nRelatively might be a bit pushing it a bit. \n\nIts about 15% faster at 1080p and the grap grows as the resolution increses to about 20% at 1440p and over 20% at 4K.\n\nI think its gonna land around 6900-6950XT raster performance so slightly faster than a 4070 but with worse RT. As for the price. Expect the usual Nvidia's price and subtrackt $50-$100. I'd bet on $550",
      "Keep dreaming, and let me dream with you for a while.",
      "My guess is it will match the 6950xt in raster while being far more power efficient and better RT performance.  \n\nI'm hoping this means 600-650 price tag but it will probably be $700 cuz reasons.\n\nI'd love to get a 6950 right now but worried about my PSU being a bit short.",
      "One does not simply leave money on the table.\n\nThat price is to get rid of the 6950XT stock so it will not be available by the time they release a new card with similar performance.",
      "I feel like the 6950 pricing is to clear out inventory before they are left with a lot of stock once faster stuff comes along. \n\nBecause the prices are great, but the power requirements, not so much.\n\nif you can give me card that costs the same or a tiny bit more, but i don't have to swap out my PSU, I'm way more inclined to buy it. \n\nThe 6950's audience are people with really big PSUs in their computer.",
      "Plot twist the 6950XT is the 7800XT because AMD doesn't actually have a 7800XT to release.",
      "Honestly history has shown that many people will buy Nvidia even if AMD is better at the same price point. What they need is mindshare.",
      "It doesn't need to be faster than the 6950. It just needs to be cheaper.",
      "I have a 6950xt with a cosair rm750x psu. Everything runs great and I OC my 5800x too.",
      "More important, when will it be released?",
      "Pointless, that's what it'll be, pointless.\n\nThere's not enough room between a 6950xt and 7900xt for a model.",
      "700$ would make it horrible, literally worse value than 4070.\n\nIt needs to be a more efficient 6950 XT for 599$ tops - and that's what I think it will end up - otherwise it's useless.\n\nBasically, you will get about 15% better raster and more vRAM but without \"nVIDIA\" and the better software stack. This should even things up nicely.",
      "As soon as the 6950 XT stock dries up. Probably in a few months from now.",
      "6950xt performance for $550 would be fine, for $500 would be amazing, for $600 would be boring, and for $650 would be awful/expected.",
      "6800xt was 16 vs 3080 10 and look how that went",
      "A 7800 XT performing the same as a 6800 XT would be a shambles of a product. There are generational and architectural improvements that go with such a new card that would mean something would have to have gone very wrong for them to release the next in the series at the exact same performance, whether it runs more efficiently or not.\n\nThankfully, all indications are that it'll run faster at somewhere around the 6900 XT with lower power consumption, better ray tracing performance and the bonus of AV1.",
      "This exactly. I don't wanna swap the PSU. Because if we did a 6950 + PSU we are in a 7900xt price range where we wouldn't need a new PSU.",
      "Still have a few spots left for dreamers to join if anyone wants in our club!!",
      "That's my point, it needs to be significantly better of a buy to start getting attention.  Like the 6600-6750 were way better price to performance vs NVIDIA and started to pick up momentum.  Still nowhere close to what it could be though. But honestly if it's $700 7800xt that is 10% better than 4070 it's got no chance.  90% of people will go to to 4070 ti or down to 4070, a lot of the rest will go up to 7900xt."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900"
    ],
    "title": "ASRock Radeon RX 6900 XT OC Formula Review - This Card is Fast",
    "selftext": "",
    "comments": [
      "Honestly it's gotten to the point where I dont even care about reading the reviews with the current GPU stock situation. \n\nIt's not like I upgrade more than once every three years or so, but the GPU draught has kinda killed my interest in following the industry since there's not even a theoretical possibility I could buy a gpu even if I wanted to.",
      "please correct me if I am wrong - but what is the point in having a theoretical 10% bios overclock, when a standard card with opened up power limit almost reaches the same clock speeds?  It¬¥s the same with ALL the OCSUPERPOWER cards, no matter which brand. \n\nIn that test, alone the fact that the spikes in power consumption are similar to a stock version shows me even a stock card is capable of drawing a lot of power if you let it. (for example, by raising the power limit in the driver...)  Yes, the asrocks components might be of higher quality, yes, the power delivery might be more stable in long term. but TWICE the price? Really?",
      "Yeah, even I sometimes feel like that \"what's the point writing this review, if nobody can buy it anyway?\"",
      "And a theoretical GPU",
      "2000 bucks? Double the price to a reference card, but not double the performance, so not worth it.",
      "I think the most important factor that is never the thing that gets the most attention is the cooler efficiency. I mean, 100% fan speed is nice but you would be going deaf with some fans and cooler designs if your pc were next to you on your desk. For AMD, Powercolor seems to do well together with MSI and Gigabyte, but it differs per 6700, 6800 and 6900, obviously.",
      "I mean, you're basically trying to buy your way out of the silicon lottery. You pay a (substantial) premium to get something OEM validated at those higher clocks with cooling designed to handle it. Is that worth the price? Well, if that's the question you're asking, then it's not an option aimed at you.",
      "Thank you for writing it still. I was interested to read up more on Radeon cards scaling well with core clock, your article kind of confirms it.",
      "The 6900XT already is a marginal upgrade over the 6800XT if you compare it to the MSRP increase.",
      "Not only is this card fast, it's invisible too!",
      "100% agree, the cooling / noise is what matters. that¬¥s why i bought a cheaper 6900xt card, added a water cooler. even less noise, comparable power and paid \\~500$ less. Even if you have no water cooling, adding a custom cooler or even a pre-build water cooler is not black magic.",
      "Stock power draw of 390w? ASRock basically set MPT for you, lol.",
      "Not a fan of the design nor the cooling solution on this card but the performance is impressive regardless. Too bad it will probably sound like a jet engine.",
      "It comes down to binning, the chips in these cards are the higher quality ones. In a lot of reviews and benchmarks the higher end cards are able to overclock higher than reference chips.",
      "Yeah, once you have read one review of a GPU you have basically read them all anyway. It's all mostly minor differences between all the versions and performance is fundamentally within the same ball park.",
      "It might seem counter intuitive, but waterblocks can lead to some surface components getting hotter than heatsinks since no air is flowing over the PCB.  Those components aren't usually super temperature sensitive, but I remember in the days of old when the first GPU water cooling efforts resulted in dead GPUs despite low temperature readings.  Modern blocks will make contact with everything that needs cooling and often will couple to the coils to act as another means for the PCB to shed heat.",
      "TFW: you get scalped by the manufacturer",
      "Yup. I agree 1000000000%",
      "Cool but im not paying $2000+ for a $1000-1500 GPU.",
      "Still not as fast as botters, miners, and scalpers.\n\nI can't be interested in current gen cards when you can't find litterally any of them in stock anywhere."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900xt",
      "6900"
    ],
    "title": "Any Particular Reason People Seem To Stay Away From The 6900xt?",
    "selftext": "Hey Ya'll\n\nEvery thursday I see a lot of posts about buying up cards, and see a lot of people avoiding the 6900xt or saying it's overkill or \"too much card\". And while I understand if you are strictly price driven, it is a decent chunk of change more, for only maybe 10-15% improvement over a 6800xt.\n\nHowever a strange thing I've been noticing is 6800xt's seem to be selling at times at the same price or even in some cases MORE than 6900xt's (on ebay mostly or second hand)! I don't know if people aren't aware of the economics of things, but if you're trying to get a card at MSRP, the 6900xt is about the only one you have a real shot at.\n\nAny reasons you guys think, or any particular reason (besides cost I suppose) that people are avoiding the 6900?",
    "comments": [
      "A reference 6900XT is a better deal than a partner 6800XT for now.\n\n\n\nIf you're only considering MSRP of the reference models, 6900XT is not very good on price to performance.",
      "Honestly the only thing I can think of is ray tracing. When they came out the raster performance was great but RT wasn't as good\n\nI'm very happy with mine!  Great Linux support and plenty of frames",
      "It's just mistaken stigma from its MSRP. If we're going by MSRP, it's not a great deal. However, for at least a year now, the 6900XT has **low key** been the **best value** high end GPU out of all cards of this generation if you look at all market prices from a **% of MSRP perspective**. Like you said, a lot of 6800XT's have been priced (scalper or \"official\" reseller, there is no difference) **higher** than some 6900XT's.\n\nPrices have come down a little bit in the last few weeks, but for the longest time it was something like:\n\n3070 $499 MSRP @ $1200+ (240%)\n\n6800XT $649 MSRP @ $1600+ (247%)\n\n**6900XT $999 MSRP @ $1500+ (150%)**\n\n3080 $699 MSRP @ $1800+ (257%)\n\n3090 $1499 MSRP @ $2500+ (166%)",
      "Calling a 3080ti or 6900xt a run of the mill graphics card is a hard fucking stretch",
      "Right now the 6900XT is price parity with the 3080 12GB, which is effectively tied in raster performance, and the 3080 12GB comes with a massively better feature set. It makes the 6900XT a hard sell. Watch HWUnboxed's 6900xt vs 3080 12GB comparison video, they come to the same conclusion.",
      "As big as RT is, it's not just RT.\n\nIt's also:\n\n* Tensor AKA Matrix accelerators (DLSS/DLDSR) - Not present on any current or even future announced AMD hardware, but a core part of Nvidia's Turing/Ampere/Lovelace architectures and Intel's Xe. Clearly the future of GPU's and already shockingly good.\n\n* DSR - Far inferior integration in AMD driver and perhaps hardware.\n\n* NVENC + related video capture API's (Nvidia paid developers to help the OBS team and other developers integrate these API's, AMD doesn't have the API nor the employees)\n\n* Reflex - Not present in AMD software, requires driver and game engine integration. Nvidia identified the need for the tech with a community member, created it, has a bunch of developers assigned to help companies integrate it into their games and engines and now it's in IIRC 8 of the top 10 FPS games and several of the most popular open game engines like Unreal.\n\n* Proper adaptive sync (incl. features like variable overdrive) - Hardware not present, essential for good VRR yet brushed under the rug because it makes them look bad. Third party reviews or Nvidia branding are the only reliable ways to know that your VRR display which VRR's with an AMD GPU will work even half decently.\n\n* OpenGL/DX9/DX11 api performance - been hammering them for this since the 7970 was the shiny new toy, it never happened. This matters to many people who play games like Minecraft, OSRS or generally older games. People are still upgrading their gtx970's to 6900xt's, losing 30-50% of their FPS and asking me why it happened.\n\n* Product support duration. AMD has recently rebadged old architectures as current gen over and over and over again, then dropped support for features that they could run perfectly while they were still being sold as new for no reason other than not having any employees to write the code.\n\nMost people care about at least one of those things, personally i use them all every week and most of them every day. More than a few are nothing short of revolutionary.\n\nIf they want to charge Nvidia pricing they need Nvidia performance, feature set and driver team. If you don't have parity, then every loss needs to be met with an equally sized win (which just doesn't exist) or with a discount. If their hardware was massively cheaper than Nvidia's for a given raster performance then i would recommend them carefully to a few people who don't care about these features, but that hasn't happened in a very long time and the list of people who don't care about any is getting smaller by the day.",
      "I‚Äôm building a computer now and am sticking with integrated graphics cause it‚Äôll be a cold day in hades before I pay upwards of fourteen hundred dollars for a run of the mill graphics card.",
      "For sure, totally agree with that.",
      "Yeah, I think RT is nice, but like I told another redditor, is it worth paying maybe 300-500+ more dollars for better ray tracing on an Nvidia equivalent card? It's one of those things they literally did a study and almost nobody could notice! The DLSS makes a bit more sense especially if you are trying to push super high frames, but AMD looks to be evening the playing field with FSR 2.0, so to me it's almost a wash at this point.",
      "I mean, it is though.  \n\nIt's a mass produced GPU for consumer PCs from one of the major companies that make them.  It's not something so unique that needs a 1000%+ profit margin.  I know AMD and NVidia want you to think so, but you don't need to pretend otherwise for their benefit.",
      "Yup.  Then you factor in the mostly unknown super die XTXH which could be had for an extra 50 bucks lol.\n\n&#x200B;\n\n[https://www.techpowerup.com/review/asrock-radeon-rx-6900-xt-oc-formula/](https://www.techpowerup.com/review/asrock-radeon-rx-6900-xt-oc-formula/)\n\n&#x200B;\n\nFrom the review:  \"Averaged over our 22-game-strong test suite at 4K resolution, the RX 6900 XT OC Formula achieves the unthinkable: It is faster than NVIDIA's GeForce RTX 3090. Long overdue, the day has finally come‚Äîan AMD graphics card is able to overtake NVIDIA's current-generation flagship graphics card! Who would have thought that just a year ago. This makes the ASRock RX 6900 XT OC Formula 7% faster than the AMD reference RX 6900 XT, 12% faster than the GeForce RTX 3080, and 13% faster than the RX 6800 XT. Very impressive numbers. There are still some RTX 3090 custom designs, like the ASUS STRIX and MSI Suprim, that are yet a little bit faster than the OC Formula.\"",
      "Absolutely, again I never thought in a million years I'd even consider a 1k GPU, but when I started doing the math and price shopping (and waiting in the queue) I decided it likely made the most sense to try and get a 6900xt.\n\nAnd to your point, for some crazy reason I have actually seen 6800xt's sell for more than 6900xt's in second hand markets, and considering I purchased a reference one barely used, for the cost of a new one with tax and shipping, it kinda proved my point.\n\nBut yes, the pricing is fucked and my concern is what the next gen of GPU's will be priced at. HOWEVER, I'm hoping there are either changes in ethereum or crypto in general that make the next gen less desirable, OR when they upgrade they flood the market with used 3090's and 6800's at ridiculously low prices in the next year. That could also force manufacturers to lower prices too once the miners get their fill. In late 2019 if you were patient you could find a Vega 64 for under 200 bucks, or a Radeon Vega FE for under 400, we will see that again.\n\nAnd for people worried about buying second hand, linus tech tips did a great video on how used GPU's rarely if ever under perform over their new variants. Especially the higher binned models as well!",
      "Just bought a 6900 xt from Microcenter for $1050 a couple of weeks ago along with a $249 Ryzen 7 5800X. Couldn't be happier!",
      "Let me see those RT Ultra FPS \\^\\^",
      "He explicitly specified in the video that reBAR was enabled for both cards, they changed their policy a month or two go. His benchmarks are also in line with basically every major review site, I just suggested the HWU video because it's a direct comparison.\n\nTy for calling me a gullible clown tho, very mature",
      "I think the prices are going to fall like stones when they finally are able to ramp up production.  I wanted a 6800 XT myself and waited a year for it--but finally settled on a 6700 XT (GB Eagle 6700 XT 12GB) when the NewEgg price dropped to where I thought the real non-shortages MSRP of an AIB card with a triple fan would be...about $100-$125 over AMD store reference design pricing--so I grabbed it.\n\nIt was kind of interesting that while I was completing the order, the Newegg stats said that there were 200 other people with the same GPU in their carts!  I can understand, since the price had dropped suddenly by almost $300.  Went back a couple of days ago and darned if the Newegg price of the same GPU hadn't been raised again another $200 over what I paid...;)  NewEgg must have received a big load of the Eagles and they priced them to sell quickly, which they did.  So, production is still not back to normal, unfortunately.  Let's hope things get back to normal soon.\n\nAnyway, I'm well pleased with this product!  GPU beats my 5700 XT at 4k convincingly, by up to 30-35% in most of my games!  And the image quality has definitely improved.  So, I'm pat on a GPU for a good while.  Next, I'll be looking at the 5700X/5800X or the 5800X-3dVcache!  I've got almost three years on my x570 Aorus Master and I can't see why it won't last another year or two...;)",
      "Those aren't at all close to the same concept. A 6900 XT is much more accessible than a Viper, which many theoretical buyers would have a disastrous time trying to drive. It's also much more bespoke (versus more mainstream Dodge vehicles of the time) than a 6900 XT. A 6800 XT is much closer to a 6900 XT than a Challenger is to a Viper.\n\nYou'd have a better chance at comparing AMD CPUs, putting a Ryzen 5 against a Threadripper Pro.",
      "It just depends on how important RT is to you, to be honest. Totally respect whatever decision people make, I run both AMD and Nvidia, and in many cases the 6900 can push as many frames as a 3090, there are cases where it outperforms because the 3090 has RT cores, whereas if you don't run RT, the 6900 has more dedicated cores meaning it can technically out perform a 3090 in certain use cases and especially if you're trying to push high frames.\n\nWith that said, buy what you want, and what makes you happy, makes no difference to me. JUST AVOID THE FUCK OUTTA SCALPERS AND SITES WITH TERRIBLE MSRP MARKUP!!!!!",
      "Really? In Germany I see the cheapest 6900XT for 1179‚Ç¨ and the cheapest 3080 12GB for 1149‚Ç¨.",
      "im sure Nvidia is just terrified while sitting in their Dagobert Duck vault fulla gold coins"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900"
    ],
    "title": "Tight all AMD build, 7800X3D and Asrock RX 6900 XT OC Formula in Fractal Design Ridge",
    "selftext": "",
    "comments": [
      "That's amazing, how are the GPU temps?  Looks like it might have trouble breathing, especially with low profile fans.  How are those being controlled?",
      "I‚Äôm setting 65w ecomode on CPU, fan setting 900-1200rpm, around 70c during gaming session on 4.8Ghz.\n\nAs for GPU, with the help of that dual 14mm intake, it‚Äôs actually very good, fan usually keep at 50% speed, core is around 70c and hotspot on 90c.",
      "I have the 6950xt version of that card‚Ä¶ if you ever get a wild hair put some PTM7950 on it‚Ä¶ dropped\nmy hotspot temp 20C plus.",
      "SFFPC builds always impress me; I *fight* to get mid-tower cases right, you guys are doing it on hard mode.  \n  \nAwesome work, thank you for sharing!",
      "What's 'silly high' idle temps? Because the 7800X3D is pretty trivial to cool even with PBO + 85 degree limit. A tiny SFF build like OP's is an extreme but a 360 rad should have no trouble.",
      "I'm going to need it for my 7900 XTX. Hotspot temp has increased around 12 degrees from first month of use. Howering around 94-101 now which is getting close.",
      "I can't believe that OC Formula actually fit in there! NICE BUILD!!",
      "Odd. I started a game just to remind myself what my temps are like on my 240 rad - 1440p 60Hz running a 3D scene in War Thunder it spikes to 60 before the fans turn on but then holds at 49 with low fan RPM. At medium load (1440p Ultra 165Hz) it likes to hover around 53 and has never exceeded 61. PBO + 85 degree limit, OS power management features disabled.\n\nIf it's fine under load who cares I suppose. The mounting frames are a gimmick when it comes to AM5, although I belive they're valid for some Intel sockets.",
      "I have the same case and CPU, but with a 7900xtx. It breathes just fine. It has fans directly blowing into it. \n\nThe cpu gets a bit less coolong than normal, but this is fine since the wattage is so low on that chip. No issues what so ever. I think I use a NH-L12S or something similar.\n\nFor larger cards, like the 4080 or 4090, the fans for the gpu is removed to make space. In this case it is not a problem also, since it basicly is an open rig with no filter. Air is pulled right through.",
      "You can also die handling a PSU, so ups and downs.",
      "On the plus side the frame can stop excess thermal paste from getting everywhere and they can look rather attractive :p\n\nAs a final Hail Mary before RMA: what are you using to measure temperatures? It's been a minute since I've used Windows but HWInfo was the gold standard for showing you every sensor's temperature, not just one number from who-knows-which sensor.",
      "Awesome, love a well done SFF build. ![gif](emote|free_emotes_pack|thumbs_up)How are temps and noise with the Ridge?",
      "Question, no issue putting the back the side pannel on the back, for the height of the heatsink of the nvme on the back of the motherboard?",
      "Looks awesome! What CPU cooler are you using?",
      "I regret selling my logi mx mech mini white so much üò≠ it's a shame but I don't use macs",
      "What‚Äôs the noise like? My PS5 is basically silent.",
      "That thing looks really cool.",
      "I ended up having to switch from the ridge to a bigger case. I had the same setup with those two lp fans in front of my asrock 7900xtx and the pc was an oven. 90c and above in pretty much every game I played. Lots of driver timeouts back then, I‚Äôm assuming it was hitting thermal limits.",
      "Yeah, it‚Äôs a really a tight fit for this card, spend some time to wiggle it in.",
      "I like it so much. Just use windows powertoy to swap windows and alt key, then it‚Äôs no difference than a regular keyboard."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900xt"
    ],
    "title": "Respect to the \"Apollo program\" :) Ryzen 9 5900X+6900XT",
    "selftext": "",
    "comments": [
      "It is really nice looking... But going with the 13... Don't forget to put socks on the air intakes ;)",
      "That thing has gotta have at most 32GB of storage to truly honour the Apollo program",
      "Good idea! :)",
      "This rig looks really cool dude",
      "Impressive aesthetics",
      "Nice rig :)",
      "People: ‚ÄûHow much fans do you need?‚Äú\nOP: ‚ÄûYes‚Äú",
      "The Apollo program was very important to me as a kid. I dreamed of becoming an Astronaut and traveling to the Moon, until my 1st grade teacher, during a period of asking a bunch of six-year-olds what they want to be when they grow up, summarily told me \"oh they shut down the Apollo program and astronauts don't go to the moon anymore\" before moving on to the next kid in line.\n\n&nbsp;\n\n^^It's ^^fine, ^^I'm ^^sure ^^it ^^had ^^no ^^lasting ^^effects ^^on ^^my ^^confidence ^^and ^^ambition ^^:\\^)\n\n\nStill, *Apollo 13* was, and is to this day one of my favorite films of all time though, so this is really special. I've been mulling over how to theme my next build, and now I'm wondering what it would take to create a white and gold satellite-themed project, or maybe white, black and orange after the Space Shuttle - my second love after the Saturn V.\n\nVery interesting OP, thank you c:",
      "Beautiful",
      "Someone needs to do an all stainless case + brushed aluminum backed motherboard. \n\nThe \"Starship\" version of this.",
      "Well my 5900X + 6800XT gets over 330 FPS in 1440p WoT in Ultra.",
      "Hello, of course! \n\nR9 5900X (4950MHz OC)\n\nRX 6900XT\n\nAsus B-550-f mb\n\n32 Gb ddr4 Corsair Dominator 3600MHz\n\nLian Li Galahad 360 AIO with AL 120 fans+6 more AL 120+ 2 SL140\n\nLian Li Strimer Plus cables\n\nPhanteks 4.0 riser cable\n\n2x1 Tb M2 SSD(3.0 and 4.0 gen)\n\n2x2 Tb Samsung EVO SSD\n\nEVGA 1000W 80+Gold PSU\n\nThermaltake Core P6 TG",
      "Nice",
      "Thin will go brrrrt",
      "Easily one of my fav pc builds",
      "Houston, we have a problem\n\n\nWhat?\n\n\nNothing\n\n\nPlease tell us\n\n\nI'm fine",
      "Love it",
      "Missing a Kerbal",
      "That's nice",
      "Now that‚Äôs a fucking build"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900xt"
    ],
    "title": "When you're green and blue... but ALL TEAM RED! Halo build inspired by the Halo 6900xt.",
    "selftext": "",
    "comments": [
      "What's this case?  \nedit: i guess it's corsair 280x with magnificient paint job",
      "Correct! 280x! :)",
      "Ok.... I need to know caps those are. :)",
      "I have that case with a 6800XT in it. Trust me and either go to the hardware store for some rubber grommets or 3d print the top glass risers to bring it up about another cm. It will do amazing things for the cooling power.",
      "Got it from ebay in the UK, reddit won't let me post a link! \n\nIf you can't see them on ebay, check etsy!",
      "Very nice. I wanted one for my gf's first build bought couple weeks ago but would've left it white. Couldn't find any at the time so just got her a white (as that and silvery are the themes) 4000D Airflow to contrast with my black one. It probably worked out better as the GPU and other parts I got might've been tricky to fit in a 280X though I still like that case a lot.",
      "I had to make a cut at the front to get my card in ü§£ü§£",
      "Do you have an AIO mounted in the same place?\n\nMy issue atm is that all heat kicked out from the GPU goes right into the CPU cooler!",
      "This thing is sweet!",
      "Also from the UK. Could you shoot me DM with the link to those key caps? \n\nCheers mate!!",
      "I have a 280mm rad in the top as part of custom loop. See pics in an old post on my profile. The rad can handle the gpu air better if the flow is more, so raise that glass some. Also foot extenders help.",
      "Ah I see, just saw your build (damn that thing is PACKED!)\n\nI have a hardware ship just 2 mins from me, I'll get some washers tomorrow!",
      "Rubber grommets not washers, like this but take one with you to check the size https://www.acehardware.com/departments/lighting-and-electrical/boxes-fittings-and-conduit/cable-protectors/3470051\nLet me know how it goes!",
      "Dope AF",
      "Sexy",
      "Wait, is that the face of cortana on your AiO?",
      "One of the few builds I'm actually jealous of. Well done OP!",
      "I wanna see your elite 2 halo edition besides this!",
      "Gorgeous build.",
      "Damn."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900"
    ],
    "title": "[Hardware Unboxed] Radeon RX 6900 XT Review, AMD's Fight For the Top",
    "selftext": "",
    "comments": [
      "AMD fans: ray tracing and DLSS don‚Äôt matter because not all games support them\n\nAlso AMD fans: 16 GB memory is a big selling point because it might someday translate to a meaningful performance advantage over 10 GB Nvidia GPUs in a few games.",
      "Ain't this the fucking truth lmfao",
      "But also kinda bad for $300 more than a 3080",
      "so you can run CSGO at 7000 fps",
      "[18-Game Average (4k)](https://imgur.com/9j5UiiW)",
      "Yeah, this card just makes no sense at all. If you play purely rasterized games the 6800xt is so much better bang for the buck especially overclocked.. If you do rasterized gaming and literally anything else get a 3080. And if you need a real workstation/gaming hybrid get the 3090.",
      "my man went from a 3090 to a 6900xt to a 3080 to a 3070 in one line.",
      "And he is absolutely right imho. RT is the future but the future isn't today, neither the SW, and especially the HW power is there, clearly. This hype train, given the implementations out there and the hardware, is yet another astounding success for nvidia's marketing. We're still at the \"preview\" stage at best, and so many people are treating it like nothing else matters. Complete bonkers.",
      "Imo the only reason why the 6800/xt have 16Gb is to try to justify their price, as it stands now 16Gb is overkill for 1440p, even for 4k but these cards are better suited for 1440p high refresh than 4k as the benchmarks show.",
      "Dude it‚Äôs the best card right now price to performance wise. Why the hell omit it because of the size of the graph? Omit other cards not the best one.",
      "at https://youtu.be/nxQ0-QtAtxA?t=799\n\nHe skips 3060 Ti in cost per frame or perf/dollar charts",
      "Whats the point of ray tracing as it stands right now?",
      "4k gaming? Ultrawide 2k? 144 fps on those monitors is really hard to hit",
      "Dirt has so minimal RT its a joke for comaprison",
      "I'm not sure if you are aware but Dirt 5 is a minimal ray tracing implementation. It has barely any features and is basically the least they could have done while claiming it has ray tracing",
      "Not that much better than 6800XT though. It's good but not $350 more than a 6800XT good.\n\nNow if the 6800XT is $800 \\*cough\\*Red Devil\\*cough\\* then might as well get a base 6900XT if you can find one at MSRP.",
      "Not bad for $500 cheaper. Now if only it were... You know... Available.",
      "Because games are more important to test than synthetics?",
      "No one should talk to those people about anything.",
      "Yes; the difference in not having enough and juuuust enough is huge; literally the difference between it works and it doesn't"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6950xt"
    ],
    "title": "AMD Radeon RX 6950XT to cost $1099, RX 6750XT $549, RX 6650XT $399 - VideoCardz.com",
    "selftext": "",
    "comments": [
      "AMD marketing : 7700 XT faster than 6950 XT for only $899.",
      "Bruh this gives me no hope for next gen. It‚Äôs sucks that the low mid range segment is basically gone. No more 200-250 dollar price to performance king",
      "I'm guessing this pricing model will reflect RDNA3?",
      "Finally GPUs were dropping prices and these companies start raising MSRPs again.",
      "I'm not buying any of this crap 100%",
      "This is literally exactly what I said and predicted would happen. So many posters over the past month or two were on this tangent about how prices would return to pre-2016 levels including the MSRP's and I knew that was never going to happen.\n\nThe mfg's know that people are more than willing to pay these higher prices for these cards, and they have perfect justification for the high MSRP's. Inflation, shortages, R&D costs for the process technology, etc etc. People need to stop buying them at inflated prices in order for the prices to drop, and you cannot get enough people on board with that for that the happen. What we are seeing now with the prices dropping is about as low as its going to get IMO. + or - 10% of the MSRP's until supply is used up before the next gen release.",
      "'budget friendly mid range offer!'",
      "$400, literally same MSRP of the 3060 Ti, for a x8 lane GPU. Can't wait to see this thing be torn to shreds in the reviews.\n\n$550, price is nipping at the heels of the RX 6800, which has 20 more CUs / RAs, 4 more GB of VRAM, a 256-bit bus, and 128 MB infinity cache. With this kind of pricing structure, will AMD stop production of RX 6800s and replace it with RX 6750s?\n\nThe 6950 XT already exists - 6900 XTXH models, which are being panic-sold for less than $1100 because GPUs are available again at sane prices.\n\nI think this is even worse than the Ryzen 3000 XT refresh.",
      "Looks like the gtx980/1060 performance tier is never going to leave the 200 dollar price point. I'd kill for even 2060 performance reaching down there now.\n\nWhen it possibly comes, it's gonna be on x2 and x4 slots, so I'll still end up getting the same performance. Remember when $400 was considered the most you reasonably needed? Now, it's the bare minimum.",
      "Terrible pricing, I thought these were supposed to replace the existing cards as refreshes? \n\n**Bad AMD, bad.**",
      "overpriced for the current climate.. \n\n&#x200B;\n\npeople are cutting spending and stocks are dropping like flies today..",
      "According to leaks , they are stopping production of RX 6700XT , RX 6600XT and RX 6800 . So , the prices probably won't decrease much",
      "Here is my opinion on these prices:\n\n6950 XT at $1099 is asking a bit too much for an overclocked 6900 XT. If AMD ships the XTXH chip for all 6950 XTs it wouldn't be horrible since the premium Navi 21 cards are already more expensive than this.\n\n6750 XT at $549 is BAD, really really bad. %15 price pump would only be justified by a 15% or more increase in performance, which is highly unlikely by only adding faster memory and high clocks without core count change. At this price, the card is approaching the current 3060 Ti market price, the 6700 XT competitor. NVIDIA's feature set is superior and makes a 6750 XT at the same price look very dumb.\n\n6650 XT at $399 is fine I guess. But again, this increase in price should be justified by a proportional performance gains.\n\nAnd a reminder, these prices as shown in the posters aren't \"MSRP\", but the price of the reference models, which definitely are going to be fewer in quantity than AIB models and certainly cheaper.",
      "Yup - looks like budget game is dead. Unlesss.... perhaps I could interest you in YET ANOTHER sub rx580 level performance budget piece of crap with gimped specs for only 250 dollars in 2022?????",
      "Was considering the 6750xt but $549 seems a little steep.  I was hoping for $500 or same $479 as the 6700xt would have been better.",
      "yeah, its a damned shame theres no budget friendly entry cards, if you want somthing \"okay\" for that price its secondhand market or nothing.\n\nYou could buy a xbox or ps5 for whats \"good\" right now and thats never been the case historically",
      "Even with MSRP 6750XT‚Äôs pricing doesn‚Äôt make sense.",
      ">will AMD stop production of RX 6800s and replace it with RX 6750s?\n\nYes. \n\nhttps://www.hardwaretimes.com/amd-radeon-rx-6750xt-to-replace-the-rx-6800-lower-performance-same-price-for-better-profits-report/\n\nObviously this is just info from an inside leak, but we've no reason not to believe it.",
      "That's ridiculous. Guess I'm gonna be using a 1070 for a decade..",
      "It's the same thing as the 3070ti, 3080 12GB, and 3080ti, now the GPU has higher yields they rebrand the card for an higher price and this way they can get more money out of that silicon"
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900xt"
    ],
    "title": "Woodlicious 5900x 6900xt",
    "selftext": "",
    "comments": [
      "I love how well the noctua colors fit",
      "First time in history",
      "Introducing the Woodlicious!\r  \n\r  \nThis build has been in the making for almost six months, partly due to the GPU shortage but I took my time with this build adding and perfecting mods the best I could. Finally purchased the GPU this January as it was the closest to retail price that I could find.\r  \n\r  \nAll the mods on the case are my own, the top panel EKWB block, PSU and RAM covers are all laser cut from European cherry wood, combined with 3D printing they slot on firmly. The feet are cast from concrete with added black pigment, it‚Äôs closer to anthracite but I love the organic look of wood, stone and copper.\r  \n\r  \nIn regards to the components I decided my build would be built around the 5900x and 6900xt both the CPU and GPU are performing admiringly. CPU temps are between 55-65 under heavy loads, and the GPU sits comfortably and quietly at 64 degrees.\r  \n\r  \nOverall I couldn't be happier with the build it‚Äôs been a long time coming and my 6600k was starting to show it‚Äôs age with only four cores. \r  \n\r  \nFeel free to ask any questions or critique the build, and thanks for stopping by.",
      "That is probably the only build in existence in which the noctua fan color actually looks nice",
      "Yup, came here to say this is the first and only build I actually like these fans in",
      "That is absolutely beautiful. The wood accents on the components looks phenomenal, you are really good at this. One of the favourite builds I've seen.\n\nPlease say you sell these",
      "madlad made a entire build so his noctua fans can blend in ü§£ü§£ü§£",
      "Yea, I've got a woody over this sexy beast!",
      "This is literally the best looking build I‚Äôve ever seen dude. Bar none.",
      "Finally someone posts a build I actually like.",
      "But‚Ä¶ why wood you do this?\nAlso, the lower back side needs some more lumber support‚Ä¶ \n\nOk, I‚Äôll see myself out now‚Ä¶ Great build btw!",
      "I was thinking the exact same thing!",
      "Yeah thought the brown and beige colour scheme would fit perfectly.",
      "I want it!",
      "I think everyone thought the same exact thing",
      "Gorgeous",
      "Your execution for the wood is amazing even before seeing the Noctua fans I thought this build looked Epic, then the Noctua fans only made it that much better! This PC is stunning!",
      "What case is that",
      "Budum tis",
      "Hey thanks for the kind words, and yes I do just pm me if there is anything your interested in."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900xt"
    ],
    "title": "Loving the upright GPU! (6900XT, 5950x, O11 Dynamic EVO)",
    "selftext": "",
    "comments": [
      "Sorry but upside down PCs give me anxiety lmfao",
      "Not my favorite thing. Lian li released a 600mm riser to route through the back, but wasn't available here yet",
      "As someone who builds PCs for a living I couldn't agree more with you. They just feel wrong to me, it's like one of those cooking videos where you see an Italian flipping out because someone is not following the traditional recipe.",
      "Ayo your computer is upside-down",
      "OP bought the most expensive parts he could find.  I don't think saving some cash on the CPU was really a concern.",
      "Does the gpu temperature get better that way?",
      "Heat only rises in cases with no fans.",
      "Why not?",
      "It definitely runs cooler than in the horizontal position, both in this case and in the Lancool ii Mesh that I was using before this. I've been able to dial back the fan curve on the GPU and still have it perform as good/better than before. Here's my latest Timespy run:\n\n[https://www.3dmark.com/3dm/74128017](https://www.3dmark.com/3dm/74128017)",
      "The fact that heat rises is irrelevant, considering the amount of fans, but I agree that the back fan is useless, in fact some of the fresh air from the bottom fans just goes out the back directly, not cooling anything.",
      "Yea, I had two spare Noctua NF-P14r that I mounted behind the GPU as intakes, so it's getting lots of air from the back. \n\nMost reviews I've seen have set it up with the side fans as exhaust in an upright GPU scenario. I might switch it up and compare, but I've been pretty happy with the results so far.",
      "Makes me feel dizzy",
      "I think jayztwocents  if I remember  correctly   could have been someone  else but either way they did a video of this case and he ran that riser cable behind the motherboard tray for a super clean look.  Might be something worth looking into",
      "This rig is üî•",
      "Does those PCIE extenders affect the performance at all? Especially the longer ones?",
      "I like it. Makes me want to swap out my O11 XL for the evo. Just waiting for an XL evo.",
      "Is upside down!!!! Back fan(exhaust) not doing much because heat rises. Is this intentional?",
      "So you moved your hottest component out of the way of all of that airflow you paid for.",
      "How TF is the monitor plugged in?!? The GPU's output ports are *inside* the case. If it's more than 15 C cooler under max load, I guess so. But those cables just hanging in the middle completely ruin the aesthetics. This is some /r/firstworldanarchists shit right here.",
      "At this length it should have negligible impact on performance. Lian-Li released a 600mm one that you can route behind the case and it is also supposed to be able to support the full PCIE4 x16. It gets sketchier when you daisy chain multiple short-length risers together (though they also sell a shorter riser that is meant to extend this one, and apparently still works fine).\n\nIn addition to the riser, I'm also running it at x8 speed due to the Thunderbolt card I added to the other x16 slot (AIO is blocking the other slots). Even with that, it's performing better than it did when I had it plugged directly into the slot, likely due to the improved thermals."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6950xt"
    ],
    "title": "AMD Radeon RX 6950XT, 6750XT, 6650XT RDNA2 refresh with 18Gbps memory now expected to launch on April 20/21 - VideoCardz.com",
    "selftext": "",
    "comments": [
      "More like 1st April.",
      "These are 7nm I presume (although they could be 6nm in which case a clock bump + memory speed bump would make a reasonable refresh with +10% perf or so).\n\nN31 is 5nm GCD + 6nm MCD so they are using different nodes which means they can be built alongside each other without really impacting on capacity.\n\nFurther if N31 is the 1st RDNA 3 part and 2.5x performance is true expect a new price tier for 79xx series parts rather than a replacement of the $1,000 tier 6900XT.",
      "Why, when the 7000 series is supposedly around the corner. With a chip shortage, isn‚Äôt it better to concentrate on getting the 7000 series out?",
      "Same chip, better memory ICs, this is not a new product, but a minor refresh.",
      "tl;dr: based on AMD's behaviour over the last 7-ish years of GPU launches, AMD will service lower price points with older cards based on RDNA2. RDNA3 will only be used for premium SKUs for maybe 6-12 months.\n\n---\n\nRDNA3 will probably follow AMD's tried and tested strategy of, when they have fast products which can compete with Intel/Nvidia, only having high-end and upper-mid range products at launch. They thus use last-gen parts to service the lower-end market segments for 6-12 months. Recent examples include:\n\n* Ryzen 3000 desktop (Ryzen 2000 was lower-end))\n* Ryzen 5000 desktop (Ryzen 3000 was lower-end)\n* Ryzen 5000U (Zen 2 based APUs were lower-end, not Zen 3)\n* Ryzen 6000U (Zen 3 based APUs were lower-end, not Zen 3+)\n* Threadripper 3000 (TR 2000 and the 3950X were lower-end)\n* Radeon RX Vega series (RX 500 series was lower-end)\n* Radeon RX 5000 series (this didn't even have a top-end, and Vega and RX 500 filled in the gap until the 5600/5500 series)\n* Radeon RX 6000 series (gaps filled by RX 5000, Vega and RX 500, until the 6600 / 6500 XT launched)\n\nAMD aren't Intel; they have about a quarter of the manufacturing capacity, so aren't in a position to flood the market with SKUs top to bottom. AMD have, in fact, not done a top-to-bottom SKU launch on desktop within a launch window since maybe 2010 for CPUs (Phenom II) and 2015 for GPUs (RX 300 series). Every other launch since has either been top-heavy (e.g. Threadripper 3000) or bottom-heavy with no real flagship that can compete against Intel (e.g. 1800X and 2700X were still far slower than the i7-7700K and i7-8700K in gaming).\n\nExpect AMD's late 2022 GPU product stack to look something like this:\n\n* Titan-class prosumer card: \"Rage Fury RX Turbo\" with 2.5x the performance of the 6950 XT\n* Ultra-enthusiast: \"7990 XT\" - 2.2x the 6950 XT\n* High-end enthusiast: \"7900 XT\" - 2.0x the 6950 XT\n* Enthusiast: \"7900\" - 1.7x the 6950 XT\n* Lower enthusiast: \"7800 XT\" - 1.5x the 6950 XT\n* Upper mid: \"7800\" - 1.2x the 6950 XT\n* Mid-range: no 7700 XT at launch, just a cut-down 6950 XT\n* Lower-mid: no 7600 XT at launch, just the 6750 XT\n\nProblem is, all SKU tiers will move up in price. I'd expect the 6750 XT, for example, to be far more expensive than the 6600 XT despite filling the same relative performance tier.",
      "new gen every 2 years\\~ish?",
      "Demand is still very high for these parts, new parts are a way off (six months or more), and releasing a very slightly updated existing product doesn‚Äôt detract from anything upcoming. It‚Äôs really just ordering different memory chips.",
      "Tsmc have a certain manufacturing capacity agreed with amd. That capacity needs to be met at all times for both companies profits and future business. Rdna3 may not have been in manufacturing when these refreshes began to be made. Stopgap cards like these arent just to fill a small hole in the market but a small hole in manufacturing capacity too",
      "What are the \"7000 is around the corner\"expectations that I see in comments based on?",
      "*excuse to raise msrps",
      "Around the corner probably means at the end of the year; October or later. Plenty of demand to fill in the meantime.",
      "They are only refreshing the highest SKUs of Navi 21,22 and 23. \n\n6800XT is a cutdown Navi 21.",
      "I don't see the point.  How much extra fps does 2 more gbps give?  My 6900 xt toxic LE is already 18 gbs.\n\nEdit:  That good silicon could be put to use on next gen or bettering the 6500 xt.",
      "5nm process, MCM, refinement of the architecture (RDNA3 is a bigger departure from its predecessor than RDNA2 was). Major improvement to perf/watt once again.\n\nThe 6900XT is a less than 300W card. Efficiency improvements brought by the process and the architectural changes could bring it down to 200-225W. Put two of them together thanks to MCM, and you're at 400-450W, for 2x the perf. And finally add the RDNA3 improvements and you get a 2.2x or so monster of a GPU. Really not inconceivable, it's just that years of +5% yearly by intel and +30% every couple years by Nvidia made us believe we had reached some sort of wall. That was never the case, the issue was always the lack of incentive for any of these companies to really push the envelope. Now we have AMD delivering on both CPU and GPU sides and look, intel just dropped one of the biggest performance leap in CPU perf of the past 5 years. Of course that wasn't just because of AMD, these architectures take many years to develop but it's no coincidence such a big perf jump happens when they have to defend their marketshare.\n\nNvidia Lovelace is also rumored to be a giant leap (but not quite to the level of RDNA3 because of the lack of MCM)",
      "The 6900xt is pretty much a 6800xt with faster clocks so it makes sense why there isn‚Äôt",
      "Navi 31 is projected to be 2-2.5x the performance of the 6900 XT. There's no way the 7900 XT will be $1000 (the same MSRP as the 6900 XT) unless the 7900 XT is only about 1.2x the performance of the 6900 XT.\n\nBeing realistic, the actual 7900 XT will be about $2000. 2.5x the performance, for 2x the price...",
      "This new trend of excusing price gouging with \"performance gains\" is the worst thing MLD unleashed on the technosphere. üò© If we normalize this, all tech products will forever increase in price, which is the reverse of how it has been historically.",
      "It's working for Nvidia with the 12GB 3080, 3080ti, 3070ti, and rumoured 3090ti.",
      "I have no such crashes with a 6800 xt. Their drivers have been solid, maybe try a clean install of them using DDU to remove the old.",
      "7900XT is enough for me, $999 only plz thanks. They have prosumer to take the higher brackets now, leave the $999 bracket for the 7900XT to pair with a Zen 4 7800X for maximum gaming."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900"
    ],
    "title": "Even AMD's $999 RX 6900 XT can't cope with Cyberpunk 2077's new Radeon ray tracing mode",
    "selftext": "",
    "comments": [
      "6900 XT? $999? Rookie numbers!",
      "Of course not, \n\nThe performance from Nvidia with dedicated rtx cores sucks with ray tracing. \n\nWe are years away",
      "Enable DLSS then. That's why it's there. Nvidia didn't implement both technologies simultaneously for no reason. RTX with DLSS should look better while performing the same as native without RTX.",
      "True, we are years away from uncompromised RT gaming.\n\nBut if we're willing to compromise a bit, RT does look good.\n\nI just lower down the resolution to 1080p, set RT to medium and use only Ray Tracing Reflection/Shadows, my 6900 XT can run it above 60 fps. Playable! Enjoyable experience even.\n\nWith a DLSS like alternative, it could be running at 1440p, 60 fps with more tweaks.\n\nI say it's better to have a choice to experience a bit of RT than not, on a Radeon card.",
      "For that money you can probably get the now familiar \"jpg file\" of a 6900 XT.",
      "I have only seen those obtainable for 1400‚Ç¨",
      "We always have to compromise, even with the best GPU.",
      "It doesn‚Äôt matter. If they can render the whole thing at 720p and upscale to 4k and it looks amazing then that is a victory not a concession",
      "Yeah, raytracing is still a looong way out. Looking forward to a DLSS competitor atleast, which is a little shorter of a wait üòÇ",
      "Says a person with R9 380.",
      "yeah playing at 1440p RT on and DLSS on my RTX 3090\n\nits sometimes hard to tell that DLSS is actually on and some games do even look better with DLSS on than on native resolutions as certain types of textures (e.g. with stuff written on) looks more crips and is more readable than on native",
      "Chicken and egg problem though. We have to start somewhere or we'll never get to the promised (ray-traced) land.",
      "And the higher quality png file costs an extra 250",
      "It's barely playable with a high-end nvidia card(2080s personal reference) with RT enabled, we already knew that AMD RT was lower performance.\n\nNobody should be surprised by this. And I would say RT is still not really ready.",
      "> which is a little shorter of a wait \n\n*Maybe*, AMD is as bad as Valve for timeframes, until it's released, I'm considering that it's canceled.",
      "I'm getting Ferrari / another supercar for a heck of a money, and then I feel cheated if it doesn't teleportate me anywhere",
      "Not always, depends on the quality setting. You could have 4k DLSS at 1080 or even 720.",
      "It doesn't. I suggest you look at OPs post history he has a massive hard on for DLSS for whatever reason and is down voted constantly for saying bs like this on a AMD sub (which according to him is from shills because if people down vote you for being an outright liar it's because they are shills....)\n\nOn top of that saying poeple who don't have an RTX card think it's flawless and then not having one and saying it's shit should be an indicator that the person is full of shit.",
      "Nvidia let's not forget also might raytrace at a lower resolution internally and use DLSS to upscale PLUS they don't have to do as many passes since they use the AI denoiser as well..AMD needs to catch up",
      "But its extremely playable with RT on nvidia.  Years away? What nonsense."
    ]
  },
  {
    "brand": "amd",
    "generation": "6000",
    "tier": "top",
    "matched_keywords": [
      "6900xt"
    ],
    "title": "Your 6800XT/6900XT is not going to die, chill",
    "selftext": "Made a video about for more explanation:\n\n[https://www.youtube.com/watch?v=GpbEAh\\_5fBc](https://www.youtube.com/watch?v=GpbEAh_5fBc)\n\na TLDW: It's not the drivers and what kris said was borderline insane. Think about it for longer than 10 minutes and you'll realize how ridiculous it is. When seeing news on videocardz and so on already taking what kris said as fact who literally made sht up that doesn't conform to reality and spreading fakenews is absolutely astonishing.\n\nI know kris probably didnt meant to cause such a ruckus and had all good intentions and probably only said those insane things because he probably overworked himself to try to get to the bottom of the defects but good lord did it produce a disaster.\n\nYou guys literally need to learn to process information and not take everything anyone says as a fact the moment you hear it without thinking for yourselves.\n\n**EDIT**: I want to make completely sure you guys understand, this refers to his **part2** video where he is talking about nonsense like he ***thinks*** all cards are from 1 miner and somehow humid and cold conditions somehow magicially blow up the GPU die because reasons. By that logic notebooks would have common blown up GPU and CPU die's and we would see tons of more posts where people report this issue, however we don't. As mentioned in my video, his theory is wild and nonsense, backed up with 0 proof.\n\n**EDIT2:** Because people seemingly cannot stop making dumb arguments about the humidity argument.\n\nIf you think storing cards in a humid enviroment did cause GPU cracking: [https://www.youtube.com/watch?v=V-4\\_uNE1tQU](https://www.youtube.com/watch?v=V-4_uNE1tQU)\n\n*Do you still think storing in humidity caused the GPU to break like kris showed?!*",
    "comments": [
      "Well, every stupid kid out there jumped on the clickbait headline train.",
      "I have had my 6900 XT for nearly 2 years.  I am not worried about this at all.",
      "Well it didn't help that other youtubers jumped on his news and ran to spread it for their own content. I would say they should have been a little more cautious.",
      "Thats what they shouldve asked too",
      "Mostly Nvidia fanboys honestly lol",
      "Click on the profiles of the people posting this stuff.\n\nIt reveals itself real fast.",
      "Hysteria gets views. Remember when AM5 launched and all the YTers had flaming CPU thumbnails over intended, perfectly safe behavior?",
      "What do you want a bar chart or a scientific study? From what I‚Äôve seen, it‚Äôs been mostly people that then go on to say how Nvidia is better etc.",
      "This situation wasn't helped with YouTubers like Jayz2cents jumping on the band wagon and putting vids out about it before anything was fully analysed. \n\nI wish these guys would control themselves instead of pumping out click bate trash.",
      "Ive had 6800XT Gaming X Trio for almost a year and it runs as good as the day I got it. I tested it extensively the last few days after seeing all the news and everything is still tip top.",
      "My comment for the video:\n\nActually, AMD has massively restricted the use of the SoftPowerPlayTables and thus indirectly also the MorePowerTool with the Adrenaline drivers from 2020\n\nWhat people do to overcome this is modifying entries in their VBIOS  So it becomes \"using modified VBIOS\" case\n\nAs for low temperatures, phone and laptop manufacturers usually specify allowed temperature range. Usually it's something like 0C - 40C.\n\nThese devices can work at lower temperatures but there's no guarantee they won't break. \n\nAs for the sealing, miner could clean cards in some sus way (with water), and re-seal them. Not exactly unheard or impossible thing.\n\nThe fact that all those cards don't have official warranty and didn't came from official distributor sorta confirms it.\n\nBasically KrisFix got all those cards in the first place, because they don't have official warranty.",
      "The # of manufactured controversies that all occurred right around the launch of Navi31 is telling. I mean this (driver hysteria), plus derbauer's explosive GPU, along with \"estimations\" on defective cards, plus an endless supply of vague comments from recently created users saying AMD cards just \"weren't for them\" or whatever. It's too much too close together.\n\nAnd this is not in any way a defense of the Navi31 launch which was clearly messed up. This is pointing out that there have been an unusually high number of manufactured controversies with no data whatsoever designed to discourage consumers from purchasing AMD cards. Also, last disclaimer, I've been using Nvidia cards for about a decade until last month, so no attempts to point out bias please.",
      "most sites that are proper news site said old mining cards stored wrong killed the cards",
      "the moment this news popped up i knew this was gonna be a shitshow\n\nthere is and was no way for the card to be killed by a driver because driver has no access to any controllers there\n\nyou would have to modify VBIOS in order to kill a card\n\nmining usually revolves extensive VBIOS mods which touch upon the way GPU core will function which can cause damage\n\npower play table mods or any power related mods are direct way of changing the way card behaves,kinda like changing A/F ratio or timing in engines which we know can absolutely cause serious damage\n\nthis is a warning that cards can and will blow up if treated like shit",
      "KrisFix shouldn't have run with the assumption.\n\nIt is bad science.",
      "define stored wrong and source such a newsite. \n\nIf they said something like \"Old mining cards stored while running in a dusty shed so they choke to death and kill vram\" then they'd be right. If they say deny basic physics and boom GPU die explosion because liquid can now deny solid matter and go whereever it wants, I'd question what you define as proper news site.",
      "That's for the 7900 AFAIK, and it's still a known issue in the driver notes.",
      "He should have tested it before making misleading claims.",
      "The problem is that the truth doesn't pay their bills - clickbait does.",
      "Nvidia pays well in marketing."
    ]
  }
]