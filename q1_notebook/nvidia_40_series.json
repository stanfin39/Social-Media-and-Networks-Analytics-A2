[
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "rtx 4060",
      "4060",
      "rtx 4060 ti",
      "4060 ti"
    ],
    "title": "[Gamers Nexus] Do Not Buy: NVIDIA GeForce RTX 4060 Ti 8GB GPU Review & Benchmarks",
    "selftext": "",
    "comments": [
      "60ti line up from best value product of 30x series, to the worst value product of 40x series. good job Nvidia.",
      "TLDW = Just overclock your 3060ti\n\nyou're welcome.",
      "I can‘t wait for the 4050 for my 720p Setup 👍",
      "well so far the only good value in the 40x series is the 4090, and it is damn expensive\n\nso nvidia went from buy whatever you want in 30x series to skip 40x series and hope for better price perf ratio in 50x series\n\nvery good job indeed",
      "Bro how can they make a card that barely competes with both their own hardware (3060ti) and AMDs last gen (6700xt).",
      "Generational non-leap",
      "This is E WASTE!!! Greta pls investigate",
      "New talking point for fanboys: nvidia gpus are so great theyre even outperforming nvidias own next generation replacement cards",
      "Greed",
      "RTX 3060 Ti was on GA104 and had a 256 bit bus width. RTX 4060 Ti is supposedly a cut down AD107 die with a 128 bit bus width.\n\nThey can call it whatever they want, but that memory bus screams 50 class card. Either ways, stop being poor, and pay $400 for 1080p medium gaming.",
      "Lol, it's barely a xx60 class card. Can't even handle 1080p with everything cranked up in some case.",
      "\"Runs quake 3 arena at a crisp 60fps\"",
      "4060ti is a 4050 all but in name.",
      "How could it be any worse. Its outperformed by the card its meant to be replacing",
      "Well nvidia PR said “ this is a 1080p card “ lmao 399 for 1080p in 2023",
      "Nvidia rly thinks we are stupid.",
      "man i expected worst but but dang it really  sucks lmao",
      "\"But, but, what about all the software we are getting, DLSS 3.0, Frame Generation?\" - Some idiot trying to justify a newer GPU with worse hardware than the previous generation offers.\n\nThis is 100% a skippable series, aint no way im gonna pay 400$ for same performance i could've gotten in 2020 for that exact amount of money, who is smoking crack at their HQ???",
      "Generational tip-toe",
      "just like the awful scam known as the RTX 3050 outselling all of RDNA2 + ARC combined (according to STEAM hw survey) i'm certain NVIDIA \"fanatics\" will make sure the 4060ti and 4060 are a sound success worthy or climbing the steam charts. PC gaming bleeds green after all.\n\n**Go GeForce, Go!**"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "rtx 4060",
      "4060"
    ],
    "title": "Gigabyte confirms GeForce RTX 4070 with 12GB memory and RTX 4060 featuring 8GB - VideoCardz.com",
    "selftext": "",
    "comments": [
      "Sooo the 4070 is effectively a 3080 12gb with a lower memory bandwidth",
      "And then Nvidia will point at the 3080 12 gigs stupid msrp and compare it to the 4070 and be like \"look how good this card is\" ignoring the 699 3080 10 gig card.\n\nThe 4070 better blow the 3080 10 gig out of the water but I don't think it will.\n\nAnyone else remember the days when 70 series usually matched the previous gen 80Ti flagships for way less money?",
      "Just makes the 3060ti more of a screaming value",
      "Such a joke, and I am sure the price would be also ridiculous.",
      "Nvidia is 100% losing business because of their SHIT vram. I game at 4k. I DEFINITELY would have bought a 4070ti with 16gb vram. 12 GB though? I'm now the proud owner of a 7900 xt and sitting at a cool 20GB and never have to even look at vram consumption.\n\nPaying 800$ for a card and worrying about running out of vram is an ABSOLUTE JOKE. The incompetency and greed is kind of infuriating.",
      "And ppl would still buy it. That's why Nvidia keeps doing it",
      "Then you realise 4060 has less VRAM than 3060",
      "4060 >= 3070 >= 2080 >= 1080 TI.\n\n1080 TI had 11GB of VRAM. 4060 has 8GB.\n\nWhat.",
      "Which is exactly what Nvidia wants as they still have a shelves full of them.\n\nWelcome to 2023 where the best deal is to buy 2,5 year old mid range card for 400$...",
      "Is there actually a reason the amount of vram has hardly gone up the past 7 years? It's so hard to justify their current prices with such low amounts.",
      "That's part of the joke, I say \"remember the days\" like it wasn't fucking 2 years ago lol",
      "Market segmentation. \n\nThey don't want people have access to lower cost cards that have over 10GB of VRAM.\n\nIt makes them very good for video production, academic deep learning uses and similar.\n\nThey could get away with it before because games would work but now they really don't so I think 4060 is going to be destroyed by reviews.",
      "They want the people that need VRAM to buy their pro cards",
      "Only on the Nvidia side of things. But then, Nvidia has always been holding back on VRAM compared to AMD.",
      "The 4070 has good specs but I’m still not going to pay $800 for a 70 series card. No way",
      "6700xt is ultra screaming value.",
      "I luv my 3060ti",
      "good choice really. Seeing how new games are trending, most of the Ada line up wiill have problems very soon. It's absurd that nvidia want $1200 for 16GB of VRAM.\n\nThey advertise these cards on the back of ray tracing and DLSS3, both of which take additional VRAM. 12GB should have been the minimum for this generation.\n\nYou pay that much, you should not worry about VRAM.",
      "if you want to play diablo 4, re4, hogwarts legacy, dead space, forspoken and probably more and more releases this year, do not buy a 8GB card.\n\nWhile they run, they won't run well and the hit to texture quality is the last thing you want to deal with, especially for a new purchase/upgrade it's plain unacceptable.\n\nOn your old card, it's reasonable to turn things down now after years of use but a brand new card that probably going cost around $500 and out of the gate has to lower texture quality and it's a 4GB regression from its predecessor no less, makes no sense. You are just throwing money away. \n\nI really like to see how this 4060 compares with 6700XT for example. That's like $350 right now. yeah AMD driver this and that, it's still going to be much better way to spend your money for the budget conscious.",
      "If you've got a GTX 1070 what are these people going to upgrade to? We have 2 manufactures and both are greedy, RTX 4080 is £1150 and the 7900 XTX is £1050, people have to buy one or the other.\n\nI waited for a whole year until I could get a FE 3080 for £649, even with patience now I could never get a 4080 for anywhere near that, nor a 7900 XT/XTX."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "rtx 4060",
      "4060",
      "rtx 4060 ti",
      "4060 ti"
    ],
    "title": "NVIDIA GeForce RTX 4060 Ti rumored to feature 4352 CUDAs, 8GB memory and 220W TDP",
    "selftext": "",
    "comments": [
      "RIP mid to low end. Clearly the pandemic didn’t screw us as hard as NVIDIA and AMD will this new gen.",
      "It's actually not all that surprising and we were silly to think it wouldn't be like this. When do companies, politicians, or anyone really, give up financial gains or power that was supposed to be temporary when that period is over? They never do. You give an inch or go along with it and that's it. This is why people should always push back at overreach and the like and say \"bullshit\" whenever they're told it is only going to be temporary. People never should have played the game in 2021 and early this year when it came to this dumpster fire of an industry. All it did was show these companies they could make those crazy scalper and allegedly low supply caused prices be the new normal and people would pay them. \n\nThe gpu industry needs to crash and burn.",
      "Seems a bit hard to believe it will come with 8GB. People already smash the 3060 Ti for having 8GB.",
      "The mid-low end is looking more and more terrible, this generation is either you get the high end or you just miss out and skip it completely, the value just isn't there.",
      "8GB on a card that will probably cost $800?\n\nYeah, no.",
      "8gb is the only reason I want to upgrade from my 3070.",
      "There is no way that memory configuration is correct.   As videocardz extrapolates those specs imply 288GB/s which is closer to the 3050 at 240GB/s than the 3060 at 360GBps.  Never mind the two 3060 ti configurations at 448 and 608.",
      "Feels good to see people finally embracing progress instead of parroting \"you don't need more than XYZ VRAM!\"",
      "Same. Can't tempt me with less than 12GB at this point, preferably 16.",
      "Plus people could stop being idiots and stop feeling as if they need to buy every shiny new product put in front of them. I buy a GPU and plan on running that beast till it's not up for the job anymore. My last decade of GPUs are below\n\nGTX 760\nGTX 1080\nRTX 3070\n\nThe 40 series can suck my nuts. What I've got now is more than enough for 1440p and it will remain. See you guys when the 60 series launches. Other than that I'm not interested.",
      "Nvidia low and mid end cards are horrible.",
      "But the chip physically supports up to 128bit bus. At 18Gbps, indeed 288gb of bandwidth.",
      "There is no logic behind a 4060 Ti costing that much. The 3060 ti was almost the best value card at $400.",
      "One theory that I have for why nvidia crippled their cheaper cards like this is the prosumer market. For davinci resolve or even machine learning you don't need the fastest GPU but you need VRAM. 3060 for example has been doing well even though it is really poor value for gaming, it is a good value for a workstation. Plenty machine learning papers were done on  1080Ti for example in my experience and this card is pretty similar if not better. It's great for a lot of people and what they do and easily accessible to buy. That's why they decided to nerf it with 8GB variant lol.\n\nI just don't think you are going to get 12GB or similar from nvidia on this class of card any time soon. It will cannibalize their other much more expensive cards.",
      "This wont get anywhere close to a 3080. It's just 34 SM lol.\n\nActually I think not even the rumoured 4070 with 46 will match a 3080.",
      "\"4060 Ti\"\n\nYou mean renamed 4050 Ti",
      "Hello stagnation. This generation is going to be a wash for everything under a 4090.",
      "That's a bit of an oof. 3060 Ti matches or exceeds the 2080 Super. Lovelace gen looking like another Turing.",
      "Again with the fucking 8GB of VRAM, such BS for a supposed 1440p card",
      "That's what they want you to think. \nFunnel of profit."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "rtx 4060",
      "4060",
      "rtx 4060 ti",
      "4060 ti"
    ],
    "title": "NVIDIA to launch GeForce RTX 4060 Ti 8GB this month, 16GB model planned for July - VideoCardz.com",
    "selftext": "",
    "comments": [
      "Why",
      "give us a 4070 16gb cmon",
      "nvidia is pulling a knee jerk reaction, first they made the 3060 12gb as a reaction to amd's higher vram cards because of consumer perception of more vram being superior, now they making the 4060ti 16gb as a reaction to slow/low sales of their higher tier models and current evidence of \\[optimized/unoptimized\\] games performing badly and/or crashing from lack of vram.\n\nThe product stack is becoming a mess, with the higher end cards getting the perception of being shafted with less vram compared to a mid range card having more vram. Yes vram isn't \\*everything\\*, but having more expensive higher tier cards being lopsided with \"less features\" than a lower tier card just seems wrong.  \n\n\nEdit: And they know they already partially screwed the product stack when they were forced to rename the 4080 to a 4070ti, every card under a 4070ti being released was meant to have a model name reflecting one tier up (4060ti was meant to be the 4070, 4060 was meant to be the 4060ti, etc).",
      "Games are using 12GB's+ on Max settings and 12.5GB's+ is where consoles are going to sit this Gen.",
      "A 16gb 4060ti but not 16gb 4070?",
      "AMD was selling 8GB cards for $250 in 2017. Why is nvidia bothering to offer 6/8GB cards in 2023? Profits and penny pinching and milking their market share/name brand from the casuals.",
      "with the current insane gpu prices, doubt u can buy anything at all for 300$. 1 gpu = 1 console right now",
      "A770 8GB's are 280 Euro in Germany, quite impressive considering it's fucking Europe.",
      "I'm so confused with all of this. Why even bother offering 6GB VRAM cards, then release 16GB, and the next graphics card will mostly be somewhere at 8GB VRAM?\n\nI am asking because I literally have zero idea what card to pick for building a superior high-end PC? Why do people even bother with lower VRAM graphics cards?",
      "I fully understand Nvidia has concluded it doesn't matter to their business, but imagine how much better their press would have been if the 70 cards simply had 16 gigs.",
      "4070 SUPER incoming!",
      "NVIDIA learned from the 1080 Ti that putting too much VRAM on a card makes people stick to their cards longer. They won't be making that mistake again. This generally only applies to affordable cards, people who buy 4090's will buy 5090's regardless.",
      "A 4070 ti with 16gb and I would buy it in a heartbeat.",
      "4070 16GB when?",
      "Yeah 3070ti 8gb user here, i just know something's off about my games. then hardware unboxed released that video comparing 3070 8gb vs 16gb 6800.\n\ntextures randomly not loading on 3070 because of severe lack of vram, on and off graphics quality. that's when i knew i was fucked by their planned obsolescence\n\njust over a year of usage and already underperforming; just wow, nvidia.",
      "Next gen will be 32GB 5060Ti, with a 10GB 5080Ti.",
      "More a programmed obsolescence, nothing else.",
      "This comment doesn't make sense to me. The 1080ti was the top tier card for the 10 series like the 4090 and 5090. There was no 1090. By your logic someone should have stuck with a 1080ti longer but also upgraded to a 2080ti and 3090 regardless.",
      "[https://twitter.com/kopite7kimi/status/1655823348411277312?s=20](https://twitter.com/kopite7kimi/status/1655823348411277312?s=20)  \n\n\nThere might be a AD103 4070 that could have more vram",
      "2017 GTX 1080ti 11GB owners still cackling to this day. How has it come to this?"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "rtx 4060",
      "4060",
      "rtx 4060 ti",
      "4060 ti"
    ],
    "title": "NVIDIA GeForce RTX 4060 Ti rumored to cost $399 (8GB) and $499 (16GB) - VideoCardz.com",
    "selftext": "",
    "comments": [
      "PCIe gen4 x8\n\nIs there no end to the trimming NVIDIA will do to Ada? So let’s recap. \n\nIt’s essentially a 3060ti “super” with a 128-bit bus, well over two years later and being sold to those with less money. These rumors about Ada being potentially spun on Samsung 8nm get more plausible with every product launch. What a joke this silicon is, in the face of what it could and should have been.  \n\nAnd the best part, all the 4070xx owners worried about vram now, bend over! Nvidia is ready for ya!",
      "I still find it how insane the upcharge is for 8GB of vram when the BGA chips themselves are like 6-8$  \nMicron  MT61K512M32KPA-24:U  is 40$ for  16GB GDDR6 and thats for a SINGLE 16GB FBGA chip, so a GDDR6X probably isnt that much more",
      "$499 4060Ti on its way to perform like a $499 3070 from 2 years ago and people will still gobble it up. Shits hilarious",
      "Suck my balls Jensen.",
      "So, they are just rereleasing a 3070 with twice the vram capacity with support of DLFG, AV1 and less power consumption for the same price after near 3 years??",
      "4th tier performance for a price that was once 1st tier. Hard no.",
      "Still too high. Need to shave $100-$200 more off.",
      "4090 vs 3090.. like +80%\n\n4080 vs 3080.. like +50%\n\n4070 vs 3070.. like +20%\n\nsee any trends yet?",
      "100$ for some vram. nvidia is forcing me to buy amd",
      "Ah cool so good to know the 4060ti has more vram then the 4070ti and the same amount as the 4080.",
      "You are not buying it for raw performance.  Just dlss3+FG.  If a game doesn't support those, these will be as good last last gen.",
      "How about $450 for the 16gb and no 8gb? What a joke.",
      "8 gigs of VRAM ain't worth 100 bucks especially considering the RX 580 8GB goes for just 70 bucks nowadays. Sure that's GDDR5 but it has a full GPU attached to it! This really is a disaster generation. If the 16gb variant was 349 then maybe, but nope...",
      "This is going to be a disaster of an upgrade 9-10% performance gain for the same money 3 years later. Thank you Nvidia!",
      "4070 TI is still the better GPU. More VRAM does not mean it's better.",
      "A 60-series Ti card in 2023 with 8GB of VRAM in 2023? Are you serious?\n\nDidn't the RTX 2060 Super have 8GB of VRAM? That was two goddamn generations ago.\n\nWith every new release the 11GB VRAM in the 1080Ti makes more and more sense",
      "DO NOT BUY THE 8GB model. This is what a corporation does when it tests the market if you buy the 8GB model you are sending a message that we do not need higher VRAM cards. The purpose of the 16GB model whether you like the 100 dollar markup is to see if there’s enough demand for clamshell memory GPU’s. They are testing the market if the demand is higher on the 16GB it sends a message that gamers want MORE VRAM. There’s a reason for the markup they are trying to maximize profits. Skip the 8GB model even if the 16GB model is overpriced.",
      "Still too expensive wtf are these prices",
      "This all goes back to us calling out the 4080 12GB for what it was, a 4070.  Ever since then, their product names and specs have been whack.",
      "$500 is DOA"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "rtx 4060",
      "4060",
      "rtx 4060 ti",
      "4060 ti"
    ],
    "title": "NVIDIA GeForce RTX 4060 Ti shows up on Geekbench with 4352 CUDA cores and 8GB VRAM - VideoCardz.com",
    "selftext": "",
    "comments": [
      "You guys are absolutely copious if you defend this card. This card should be max 4050Ti, calling it 4060Ti is absolute slap in the face for every customer, and defending Nvidia is showing how delusional you all are. Just look at the memory bus and the generational improvement over the last gen. \n\nHow come 4090 provides 60% improvement over 3090 and 4060Ti provides 9% over 3060Ti? This card is only called 4060Ti for Nvidia to justify their greedy pricing this gen and deserve to rot on the shelves of every store. It is absolutely disgraceful!",
      "Barely faster than a 3060ti? \n\nThats kind of lame for a double node jump worth of density improvement.",
      "3070 for the price of 3070 but 3 years later. Nice.",
      ">How come 4090 provides 60% improvement over 3090 and 4060Ti provides 9% over 3060Ti?\n\nLmao 9% improvement from one gen to the next is pure trolling on Nvidias part.\n\nYet fanboys will still lap it up",
      "A 4060 disguised as a 4060 ti that's why.",
      "Nvidia GeForce RTX 4060Ti \"4050Ti Edition\"....\n\n\nRemember guys gen on gen improvement is 74%. This gets you only 10-15% 60ti over 60ti.\n\n4070 is the true 4060ti and 4070ti is the 4070.",
      "GTX 1060 had 6GB of vram. 7 years ago.",
      "The 40 series will go down as the worst GPU gen of all time.",
      "You VRAM crazies really are losing it arent you",
      "This should have been at best called 4050 Ti but then the entire GeForce 40 series line up is a lie/cash grab except the 4090.",
      "Because AMD forgot to release any cards this gen.",
      "Dude, the vast majority of kids would be stoked to have a PC that capable. I think they'll get by if they have to turn settings down to high. That said, screw nVidia.",
      "9 PERCENT?? holy shit, that's DOA. what an absolutely garbage card",
      "It's a skippable generation. There's no course correction coming. Avoid it unless you have no alternatives.",
      "Its hard to justify an upgrade from my 1070Ti with these prices, and still only offering 8GB of VRAM (Looking at you, 3070)... Hopefully a 12GB model or something shows up at a reasonable price in the future",
      "Because they are following suit, plus AMD are only good at pure rasterization, but are lacking in other departments like CUDA, HW encoding, etc. That's what you get in a duopoly market. Let's hope Intel improves enough to really change the status quo in the GPU market.",
      "Damn this is garbage.",
      "Still cutting costs in VRAM, I see.",
      "The 980 ti had 6 gigs of vram. Like a decade ago idfk",
      "Stick to my 2060s for another 3 years, not gonna but any overpriced new card."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "rtx 4060",
      "4060",
      "rtx 4060 ti",
      "4060 ti"
    ],
    "title": "NVIDIA GeForce RTX 4060 Ti 8GB to launch on May 24th, a day before Radeon RX 7600 - VideoCardz.com",
    "selftext": "",
    "comments": [
      "400$ 8GB card incoming... 16GB will be 500$",
      "Are they banking on people not wanting to wait ONE day? lololol",
      "They're just banking on the 7600 also being terrible. Which it unfortunately will. 8gb of vram as well",
      "Good try but…\n\nhttps://videocardz.com/newz/amd-radeon-rx-7600-8gb-graphics-card-spotted-in-asian-store",
      "Why do AMD fanatics try to label people who buy Nvidia as making a dumb decision? Is it possible they value features differently? Is it possible they have different local pricing or availability?\n\nThe answer is yes. But AMD fanatics need to cope by belittling others' purchases as being made out of ignorance.",
      "this is said all the time here and elsewhere but man: The GPU market is absolute garbage rn",
      "That's definitely not terrible if it comes at a $250 MSRP. That's just a rumor now so we'll have to see if it actually launches at that price of course.",
      "Eh, what are people gonna do. Buy AMD cards? Lol",
      "Someone tell Nvidia ETH mining is no longer a thing.",
      "if I’m spending nearly $1000 on a GPU , I have to go Nvidia. thats just the reality of the situation.\n\nBut at the mid range, it makes no sense and hasnt really made sense since Pascal or MAYBE Turing.",
      "The video card market has been fucked since September 17th 2020.",
      "Or buy consoles instead of pc.    Actually a GPU alone is more expensive then the ps5 or xbox one X.  For a full upper range gaming pc capable of playing at a LG C2 55\" oled youre paying like 2k bucks.   PS5 + Xbox series x + TV + Gamepass for 2 years is less. Just saying (as a PC user who  paid like 1300 before covid)",
      "Unfortunately AMD has proven over the year they are not interested in making good GPUs, so why would anyone buy them?\n\nEven the AMD biased youtubers all have Nvidia/Intel builds lmao.",
      "It's a narrative pushed by AMD fanatics to try to justify AMD's poor market share. Instead of recognizing AMD's poor competition, they attack people for buying Nvidia. Anything but suggesting AMD improves.",
      "> 8GB is fine if your performance expectations are 1080p medium. Basically low end cards.\n\nJesus, this VRAM discussion has completely gotten out of proportion. My 3070 has 8GB and I game at 1440p180 on high settings just fine, granted that I don’t usually play games from the last 4-5 years which seem to be horribly underoptimized. War Thunder, PUBG, GTAV, even VR occasionally is what I run the most.\n\nNo, 8GB VRAM does not make a card “low-end” or set your performance target at “1080p medium”, that’s absolutely ridiculous. It does limit your options on games like RDR2 or AC: Valhalla, but as always it’s down to your preferences. If you’re not playing the ultra-modern, unoptimized AAA games, they are great workhorses.",
      "Well the 4090 was “only” $100 more than the 3090 at launch. But yeah for every other card they are way more expensive than the card theyre replacing.",
      "lol nvidia's ego is just unbelievable",
      "Argue with whom? You won't find to many people arguing the opposite.",
      "Nah its been screwed since late 2018. People love to forget that the power grab that was the RTX 2000 series existed.\n\nThat was the real time when Nvidia started their price gouging ####ery.",
      "Especially funny considering they haunt r/nvidia just to shit on Nvidia. I feel sorry for them. That kind of behaviour is not healthy."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "rtx 4060",
      "4060",
      "rtx 4060 ti",
      "4060 ti"
    ],
    "title": "Breaking Nvidia's GeForce RTX 4060 Ti, 8GB GPUs Holding Back The Industry",
    "selftext": "",
    "comments": [
      "How many videos do you want to make about this topic?\n\nHUB: yes",
      "Naming a 4050 a 4060 doesnt make it work like one? Damn, Jensen almost had a good plan there.",
      "Wow. Those comparisons are absolutely brutal. Nvidia should be ashamed of a brand new $400 GPU performing like this, just because they were too cheap to give it at the VERY least 12 GB of VRAM",
      "They have over a Million subs. If you want to see higher Vram on the 60 tier from Nvidia, it will take a lot of noise to make them even think about doing it. We need more large channels to over-push this as well.",
      "8GB cards in mainstream are damaging to gaming industry. HWU and other content creators should release more of these videos.",
      "xx50 performance/vram, xx60 naming and xx70 pricing. Gotta love it",
      "Don't forget pricing it like a 70 tier card as well!",
      "I'm happy he's pointing out insufficient VRAM causing some games to lower textures as some people love to copy paste the same charts comparing 16gb vs 8gb 4060ti which says they're mostly the same on average fps but doesn't say anything about texture quality.",
      "Until tech illiterate people on Reddit stop saying otherwise.",
      "Both are bad for the industry. I'd appreciate if my card had 12gb of vram",
      "I feel like you should be able to use a 400-500$ GPU at 1440p comfortably tbh. Also the GPU being capable of 1440p gaming but only being crippled by the vram buffer does leave a sour taste in the owners mouth",
      "3060 has 12GB VRAM, 4060(ti) holds back the industry by downgrading VRAM on the same tier of card. no sane consumer who did their research is going to spend over $400 on a GPU that has the same performance as a last gen GPU and less VRAM.",
      "8GB is a joke of course, 12GB for 1440p in 2024 should be the norm\n\nHowever ’holding back’: Per steam survey, most people are on rtx 3060 and stuffs like that, for a 4060 to hold back the industry you’d need far more people to actually purchase it..",
      "Look man, those leather jackets don't pay for themselves.",
      "For that price, then it should be 1440p capable",
      ">You don't need 12GB of VRAM\n\nUntil you do.  It's always a race how much raw fidelity can publishers shit out into their games which literally compromises everything about a game in favor of raw graphics.  The only stopgap is consoles which are the lowest common denominator that they set the graphical optimization bar for.\n\nThe moment that's gone though 8gb of RAM will quickly languish.  For a modern 400-500$ GPU that's fucking trash longevity, especially with 128 bandwidth.",
      "The combination of the  half pcie lanes and 8gb  is painful.  Feel sorry for people throwing a 60 class card in an old PC and not doing the research . Even then no one really highlights the issue as most people test on modern hardware  so it doesn't impact performance. Rumour say the 5060 would be better. Just unfortune for people buying this generation on an old platform.",
      "He did because so many people still buy them, and many pre builds that are also bought commonly have them. I'd bet it outsold the 7700XT by multiples sadly.",
      "Sure, but the 126 bit bus was a design choice. They could have used a different configuration, wouldn't even have cost them more than a pittance. \n\n\nStill l, pretty hilariously bad for a mid range card to have only 8gb in 2024. \n\n\nSometimes you don't even get what you pay for.",
      "Or that's how consumer advocacy works. Amazing how much Redditor's hate other people advocating for them as consumers."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "rtx 4060",
      "4060",
      "rtx 4060 ti",
      "4060ti",
      "4060 ti"
    ],
    "title": "Game Ready Driver 532.03 FAQ/Discussion",
    "selftext": "# Game Ready Driver 532.03 has been released.\n\n**Article Here**: [https://www.nvidia.com/en-us/geforce/news/geforce-rtx-4060-4060ti-game-ready-driver](https://www.nvidia.com/en-us/geforce/news/geforce-rtx-4060-4060ti-game-ready-driver)\n\n**Game Ready Driver Download Link**: [https://us.download.nvidia.com/Windows/532.03/532.03-desktop-win10-win11-64bit-international-dch-whql.exe](https://us.download.nvidia.com/Windows/532.03/532.03-desktop-win10-win11-64bit-international-dch-whql.exe)\n\n**New feature and fixes in driver 532.03:**\n\n**Game Ready** \\- This new Game Ready Driver provides the best gaming experience for the latest new games featuring **DLSS 3 technology including The Lord of the Rings: Gollum**. Additionally, this **Game Ready Driver introduces significant performance optimizations to deliver up to 2x inference performance on popular AI models and applications such as Stable Diffusion**.\n\n**Gaming Technology**\n\n* Introduces support for the GeForce RTX 4060 Ti (8GB)\n\n**Fixed Issues**\n\n* \\[Age of Wonders 4\\] Application stability issues \\[4101637\\]\n* \\[Bus Simulator 31\\] Ansel & Freestyle not working \\[4090979\\]\n\n**Open Issues**\n\n* Toggling HDR on and off in-game causes game stability issues when non-native resolution is used. \\[3624030\\]\n* Monitor may briefly flicker on waking from display sleep if DSR/DLDSR is enabled. \\[3592260\\]\n* \\[GeForce RTX 4090\\] Watch Dogs 2 may display flickering when staring at the sky \\[3858016\\]\n* Increase in DPC latency observed in Latencymon \\[3952556\\]\n* Applying GeForce Experience Freestyle filters cause games to crash \\[4008945\\]\n\n**Driver Downloads and Tools**\n\nDriver Download Page: [Nvidia Download Page](https://www.nvidia.com/Download/Find.aspx?lang=en-us)\n\nLatest Game Ready Driver: 532.03 WHQL\n\nLatest Studio Driver: 531.61 WHQL\n\nDDU Download: [Source 1](https://www.wagnardsoft.com/) or [Source 2](http://www.guru3d.com/files-details/display-driver-uninstaller-download.html)\n\nDDU Guide: [Guide Here](https://docs.google.com/document/d/1xRRx_3r8GgCpBAMuhT9n5kK6Zse_DYKWvjsW0rLcYQ0/edit)\n\n**DDU/WagnardSoft Patreon:** [**Link Here**](https://www.patreon.com/wagnardsoft)\n\nDocumentation: [Game Ready Driver 532.03 Release Notes](https://us.download.nvidia.com/Windows/532.03/532.03-win11-win10-release-notes.pdf) | [Studio Driver 531.61 Release Notes](https://us.download.nvidia.com/Windows/531.61/531.61-win10-win11-nsd-release-notes.pdf)\n\nNVIDIA Driver Forum for Feedback: [Link Here](https://www.nvidia.com/en-us/geforce/forums/user/15//519572/geforce-grd-53203-feedback-thread-released-52423/)\n\n**Submit driver feedback directly to NVIDIA**: [Link Here](https://forms.gle/kJ9Bqcaicvjb82SdA)\n\n**RodroG's Driver Benchmark:** TBD\n\n[r/NVIDIA](https://new.reddit.com/r/NVIDIA/) Discord Driver Feedback: [Invite Link Here](https://discord.gg/y3TERmG)\n\nHaving Issues with your driver? Read here!\n\n**Before you start - Make sure you Submit Feedback for your Nvidia Driver Issue**\n\nThere is only one real way for any of these problems to get solved, and that’s if the Driver Team at Nvidia knows what those problems are. So in order for them to know what’s going on it would be good for any users who are having problems with the drivers to [Submit Feedback](https://forms.gle/kJ9Bqcaicvjb82SdA) to Nvidia. A guide to the information that is needed to submit feedback can be found [here](http://nvidia.custhelp.com/app/answers/detail/a_id/3141).\n\n**Additionally, if you see someone having the same issue you are having in this thread, reply and mention you are having the same issue. The more people that are affected by a particular bug, the higher the priority that bug will receive from NVIDIA!!**\n\n**Common Troubleshooting Steps**\n\n* Be sure you are on the latest build of Windows 10 or 11\n* Please visit the following link for [DDU guide](https://goo.gl/JChbVf) which contains full detailed information on how to do Fresh Driver Install.\n* If your driver still crashes after DDU reinstall, try going to Go to Nvidia Control Panel -> Managed 3D Settings -> Power Management Mode: Prefer Maximum Performance\n\nIf it still crashes, we have a few other troubleshooting steps but this is fairly involved and you should not do it if you do not feel comfortable. Proceed below at your own risk:\n\n* A lot of driver crashing is caused by Windows TDR issue. There is a huge post on GeForce forum about this [here](https://forums.geforce.com/default/topic/413110/the-nvlddmkm-error-what-is-it-an-fyi-for-those-seeing-this-issue/). This post dated back to 2009 (Thanks Microsoft) and it can affect both Nvidia and AMD cards.\n* Unfortunately this issue can be caused by many different things so it’s difficult to pin down. However, editing the [windows registry](https://www.reddit.com/r/battlefield_4/comments/1xzzn4/tdrdelay_10_fixed_my_crashes_since_last_patch/) might solve the problem.\n* Additionally, there is also a tool made by Wagnard (maker of DDU) that can be used to change this TDR value. [Download here](http://www.wagnardmobile.com/Tdr%20Manipulator/Tdr%20Manipulator%20v1.1.zip). Note that I have not personally tested this tool.\n\nIf you are still having issue at this point, visit [GeForce Forum for support](https://forums.geforce.com/default/board/33/geforce-drivers/) or contact your manufacturer for RMA.\n\n**Common Questions**\n\n* **Is it safe to upgrade to <insert driver version here>?** *Fact of the matter is that the result will differ person by person due to different configurations. The only way to know is to try it yourself. My rule of thumb is to wait a few days. If there’s no confirmed widespread issue, I would try the new driver.*\n\n**Bear in mind that people who have no issues tend to not post on Reddit or forums. Unless there is significant coverage about specific driver issue, chances are they are fine. Try it yourself and you can always DDU and reinstall old driver if needed.**\n\n* **My color is washed out after upgrading/installing driver. Help!** *Try going to the Nvidia Control Panel -> Change Resolution -> Scroll all the way down -> Output Dynamic Range = FULL.*\n* **My game is stuttering when processing physics calculation** *Try going to the Nvidia Control Panel and to the Surround and PhysX settings and ensure the PhysX processor is set to your GPU*\n* **What does the new Power Management option “Optimal Power” means? How does this differ from Adaptive?** *The new power management mode is related to what was said in the Geforce GTX 1080 keynote video. To further reduce power consumption while the computer is idle and nothing is changing on the screen, the driver will not make the GPU render a new frame; the driver will get the one (already rendered) frame from the framebuffer and output directly to monitor.*\n\nRemember, driver codes are extremely complex and there are billions of different possible configurations. The software will not be perfect and there will be issues for some people. For a more comprehensive list of open issues, please take a look at the Release Notes. Again, I encourage folks who installed the driver to post their experience here... good or bad.\n\n*Did you know NVIDIA has a Developer Program with 150+ free SDKs, state-of-the-art Deep Learning courses, certification, and access to expert help. Sound interesting?* [Learn more here](https://nvda.ws/3wCfH6X)*.*",
    "comments": [
      "DPC LATENCY DPC LATENCY DPC LATENCY",
      "DPC issue still here. Enjoy your crackling audio people.",
      "DPC LATENCY DPC LATENCY DPC LATENCY",
      "Will keep this unofficial comment updated [like I did with previous driver](https://www.reddit.com/r/nvidia/comments/135l80f/game_ready_driver_53179_faqdiscussion/jik7in7/). \n\nEDITs section in footer can be used to track additions/updates.\n\n---\n\n**Notes**\n\n* Nvidia Gamestream is [no longer officially supported](https://www.nvidia.com/en-gb/shield/support/shield-tv-pro/gamestream/)\n\n* Security Bulletin issues updated by Nvidia on 30th March 2023 are addressed by 531.41 and later - https://nvidia.custhelp.com/app/answers/detail/a_id/5452\n\n* Solidworks Models may not render properly when \"Enhanced Graphics Performance\" is enabled from the application settings. Not a driver issue but a [driver workaround](https://www.reddit.com/r/nvidia/comments/135l80f/game_ready_driver_53179_faqdiscussion/jklm9ul/) is planned\n\n* LiveKernelEvent 193 error with MKV videos is a [Windows DWM bug](https://www.nvidia.com/en-us/geforce/forums/user/15//517277//?comment=3349257), not a driver bug \n\n* Recent Windows security update resulting in 'Kernel-mode Hardware-enforced Stack Protection' causing crashing/framerate issues with numerous games and applications\n\n* Series 30 and Series 40 GPUs HDMI audio may drop out on Sony Bravia TVs, Nvidia are working with SONY to resolve the issue \n\n---\n\n**Workarounds**\n\n* DPC Latency spikes with Series 30 and Series 40 GPUs potential workaround(s). Enable Message Signaled Interrupts (MSI / MSI-X) for the Nvidia HDMI and GPU instances, disable both [*'PEG - ASPM'* / *'PCI Express Clock Gating'* and adjust other related features (credit Astyanax)](https://forums.guru3d.com/threads/nvidia-geforce-531-61-whql-driver-download-and-discussion.447454/page-7#post-6123944) if supported in the motherboard BIOS. Disabling Hardware Accelerated GPU Scheduling (HAGS) may help on some systems but impacts DLLS Frame Generation feature. Setting Windows CPU Power Plan to 'Balanced Performance' or 'High Performance'. Setting Nvidia's 'Power Management Mode' to 'Prefer Maximum Performance' in the Nvidia Control Panel for each application/game impacted OR forcing higher VRAM clocks for P8 State may mitigate the issue. \n\n* Display blinking, try setting *'Content Type Detection'* in *'Nvidia Control Panel > Display > Adjust Desktop Color Settings'* to *'Desktop Programs'* if setting is available\n\n* NVLDDMKM / TDR issues, if troubleshooting (RAM/CPU/GPU overclocks, using [Nvidia Debug Mode](https://mostechtips.com/wp-content/uploads/2021/08/enable-debug-mode.jpg), voltage, memory timings, PSU, toggling Hardware Accelerated GPU Scheduling setting, disabling hibernation/fast startup etc) hasn't helped try driver 512.95, 517.48, 516.94, 522.25, 526.86, 528.49 OR recent *developer* drivers based on r526_25-xx (no VSR) branch such as 532.04\n\n---\n\n**Branch Information**\n\n* 535.50: r535_00-73 (Insider Build)\n\n* 532.04: VK526_25-32 (Developer)\n\n* **532.03**: r531_79-4 (Game Ready/Studio)\n\n* 531.79: r530_00-178 (Game Ready)\n\n* 531.68: r531_66-2 (Game Ready)\n\n* 531.61: r530_00-155 (Game Ready/Studio)\n\n* 531.58: r531_37-5 (Hotfix)\n\n* 531.41: r531_37-2 (Game Ready/Quadro/Studio)\n\n* 531.29: r530_99-18 (Game Ready)\n\n* 531.18: r530_99-13 (Game Ready)\n\n* 528.49: r528_37-5 (Game Ready/Studio)\n\n* 528.24: r528_10-7 (Game Ready/Quadro/Studio)\n\n* 528.02: r527_92-2 (Game Ready/Studio)\n\n---\n\n**Confirmed Additional Issues** \n\nThis section covers issues officially acknowledged by Nvidia that are not in the original driver [release notes](https://us.download.nvidia.com/Windows/532.03/532.03-win11-win10-release-notes.pdf) \n\n* [GeForce RTX Series 40] graphics cards running older firmware could experience blank screens on boot with certain motherboards in UEFI mode until the OS loads - https://nvidia.custhelp.com/app/answers/detail/a_id/5411/\n\n* [Halo Wars 2] In-game foliage is larger than normal and displays constant flickering [3888343]\n\n* [OCCT VRAM Test] event viewer logs nvlddmkm error at the end of the OCCT video ram test when memory is full [4049182]\n\n* [Surface Book/Surface Studio] dedicated GPU stuck at lowest clock speed when notebook is running off of battery [4063597]\n\n* [GeForce RTX 40 Series Notebooks] some notebook models may randomly experience a TDR/black screen [4024853]\n\n* [Chromium based applications] small checkerboard like pattern may randomly appear [3992875]\n\n* [Display Stream Compression (DSC)] some monitors may display random black screen flicker when using R530 drivers with DSC enabled [4034096]\n\n* [Control][DX12] Cut scenes and videos show tearing and partial jitter [4084000] Disabling ReBAR in the Nvidia Profile is a potential workaround (see [comment](https://www.reddit.com/r/nvidia/comments/13qkfnz/game_ready_driver_53203_faqdiscussion/jll0koi/) by /u/Horst9933)\n\n* [NVIDIA System Tray] in certain languages, the NVIDIA Control Panel option is missing when right-clicking over the NVIDIA system tray icon [4019721]\n\n* [Microsoft Flight Simulator] Game may randomly crash when playing in DX12 mode after updating to driver 531.41 or later [4051526]\n\n* [Fast Sync] caps the game FPS to the monitors maximum refresh rate [4114157]\n\n---\n\n**Unconfirmed Additional Issues** \n\nThis section contains issues not officially acknowledged by Nvidia but are reported across multiple forums:\n\n* [GeForce RTX Series 40 GPUs] stability/TDR/black screen issues. Check for a **motherboard BIOS** update that states '*compatibility updates for Lovelace*'. The motherboard update is in *addition* to any VBIOS update. Nvidia control panel setting *'Prefer Maximum Performance'* may mitigate idle/monitor resume/crashing issues (workaround)\n\n* [Microsoft Store/GamePass/Xbox Application] PC games may not have Nvidia 'game ready driver profile' settings applied due to the *APPID* not being present in the Nvidia game profile. **Workaround**: manually add the *APPID* to the Nvidia driver game profile using *Nvidia Profile Inspector* or similar tool. Please submit a report to Nvidia for games that have this issue\n\n* [EA Desktop] app driver profile incorrectly referencing PC Playstation Plus/Now executables (*qtwebengineprocess.exe*, *psnowlauncher.exe*, *agl.exe*, *unidater.exe*)\n\n* [Multiple Display] systems with three or more active displays (in mixed portrait modes?) may show very high GPU idle power usage with GSync enabled OR may crash with BSOD/bugcheck code on Windows startup/changing monitor modes (WINKEY + P)\n\n* [LG C2 Display] 120Hz/8bit/10bit/12bit HDMI handshake issues or screen artifacts when resuming from standby\n\nFor any issues not officially acknowledged by Nvidia please submit a report using the [official form](https://forms.gle/kJ9Bqcaicvjb82SdA). General guidance in [provide valuable feedback](http://nvidia.custhelp.com/app/answers/detail/a_id/3141) document. Display issue guidance in [collecting logs for display issues](https://nvidia.custhelp.com/app/answers/detail/a_id/5149)\n\n---\n\n**Resizable Bar (ReBAR) Support** \n\nNo ReBAR additions / changes  since the previous driver\n\n25 *unique* profiles out of 6707 profiles in the driver have official ReBAR support enabled, however restrictions apply based on CPU platform:\n\n* Intel CPU based platforms have ReBAR disabled for F1 2021, F1 2022, Hitman 3 and Horizon Zero Dawn\n\n* AMD CPU based platforms have ReBAR disabled for Dead Space (Remake) and Call of Duty: Modern Warfare 2 (2022)\n\n---\n\n**NIS (Nvidia Image Scaling)** \n\nThis driver still has an 8% to 10% performance penalty with NIS on Pascal and Maxwell based GPUs when compared to a custom resolution, older scaling or Turing/Ampere/Lovelace GPUs. Workaround is available that forces the older scaling and sharpening on Maxwell and Pascal based cards: https://www.reddit.com/r/nvidia/comments/tkca3g/game_ready_studio_driver_51215_faqdiscussion/i1sod9e/\n\nSee comment by /u/thrwway377 regarding [undocumented changes to NIS allowing it to be enabled on a per-app basis](https://www.reddit.com/r/nvidia/comments/yertoa/game_ready_driver_52647_faqdiscussion/iu4rmfl/) in driver 526.47 and above \n\n---\n\n**Benchmarks and Analysis**\n\nLovelace series 40 GPU Benchmarks and Analysis \n\n* /u/lokkenjp benchmarks and analysis at TBC\n\n* /u/RodroG benchmarks and analysis at TBC\n\nAmpere series 30 GPU Benchmarks and Analysis\n\n* /u/RodroG benchmarks and analysis at TBC\n\n* /u/ThatLonelyGamer01 benchmarks at https://www.reddit.com/r/nvidia/comments/13qkfnz/game_ready_driver_53203_faqdiscussion/jlfbsij/\n\n---\n\n**EDITs**\n\n01: tested 'NIS (Nvidia Image Scaling)' on Pascal / Maxwell GPUs\n\n02: added to confirmed 'Series 40 GPUs in certain motherboards that are in UEFI mode' issue \n\n03: added to unconfirmed 'Series 40 GPUs stability issues' including potential fix\n\n04: added to confirmed Halo Wars 2, OCCT VRAM Test, Surface Book/Surface Studio, GeForce RTX 40 Series Notebooks, Chromium based applications, GeForce RTX Series 40 laptops/notebooks, Display Stream Compression (DSC), Control DX12, NVIDIA System Tray, Microsoft Flight Simulator, Fast Sync issues\n\n05: updated branch information for 532.03\n\n06: updated ReBAR profile / count section\n\n07: updated Control entry in confirmed section\n\n08: added to notes 'SONY HDMI Audio, Series 30 and Series 40 GPUs' dropouts\n\n09: add to unconfirmed 'LG C2 Display resuming from standby' and 'Multiple Display' issues\n\n---",
      "DPC LATENCY DPC LATENCY DPC LATENCY",
      "upvote +1000000000",
      "> DPC LATENCY DPC LATENCY DPC LATENCY",
      "Please fix DPC latency and driver overhead, this is getting ridiculous.",
      "It’s been 2 months since [this tweet](https://twitter.com/pellynv/status/1638955853322526737)\n\nMaybe an update on what is the progress or if there is any progress at all? lol",
      "Strange how they condense the Open Issues into 5 bullet points above, and in their Release Notes doc:\n\n**Open Issues:**\n\n* Toggling HDR on and off in-game causes game stability issues when non-native resolution is used. \\[3624030\\]\n* Monitor may briefly flicker on waking from display sleep if DSR/DLDSR is enabled. \\[3592260\\]\n* \\[Halo Wars 2\\] In-game foliage is larger than normal and displays constant flickering \\[3888343\\]\n* \\[GeForce RTX 4090\\] Watch Dogs 2 may display flickering when staring at the sky \\[3858016\\]\n* Increase in DPC latency observed in Latencymon \\[3952556\\]\n* Applying GeForce Experience Freestyle filters cause games to crash \\[4008945\\]\n* Event Viewer logs nvlddmkm error at the end of the OCCT video ram test when memory is full \\[4049182\\]\n* Small checkerboard like pattern may randomly appear in Chromium based applications \\[3992875\\]\n* \\[Surface Book/Surface Studio\\] Dedicated GPU stuck at lowest clock speed when notebook is running off of battery \\[4063597\\]\n* After updating to R530 drivers, certain GeForce RTX 40 series notebook models may randomly experience a TDR/black screen \\[4024853\\]\n* Some monitors may display random black screen flicker when in Display Stream Compression mode when using R530 drivers \\[4034096\\]\n* \\[Control\\]\\[DX12\\] Cut scenes and videos show tearing and partial jitter \\[4084000\\]\n* In certain languages, the NVIDIA Control Panel option is missing when right-clicking over the NVIDIA system tray icon \\[4019721\\]\n* \\[Microsoft Flight Simulator\\] Game may randomly crash when playing in DX12 mode after updating to driver 531.41 \\[4051526\\]\n* Fast sync caps the game FPS to the monitors maximum refresh rate \\[4114157\\]\n\n&#x200B;\n\nProbably looks good in the share holder meetings.  Lol",
      "[Previous EPB](https://www.reddit.com/r/nvidia/comments/135l80f/comment/jimcddj/?utm_source=share&utm_medium=web2x&context=3) got released as this one came.\n\nUPDATE: I was doing the benchmarls today to release them tomorrow, only managed to do RDR2. There was a loud noise in my case and one of the fans of the GPU just fell off. The one on the far right...great. I have no idea what to do atm. I will, **sadly, have to pospone the EPB (Early Performance Benchmark) for the moment**. I'm so, so, sorry, people. I really wanted to be on time this time and this happens.\n\nTL,DR: Early Performance Benchmark is postponed due to GPU fan falling off and going haywire inside the case.",
      "I wish i had army of alts to upvote anyone mentioning it for more visibility.   \n\n\nTHIS SHIT NEEDS TO BE FIXED",
      "They can't hear you under the mountain of cash they dived into.",
      "DPC LATENCY",
      "I replied to his last tweet about this driver and asked too. I encourage people to do the same. They only acknowledged this issue because it finally gained traction, without it they wouldnt care.  \n\n\nIf its impossible to fix/needs some hardware fix then at least let us know so we wont wait like idiots and talk about this under every driver release",
      "Nvidia drivers take the CPU hostage for longer than anticipated causing other drivers and system functions to fall behind and cause slowness, audio crackling and stuttering.",
      "DPC LATENCY",
      "DPC FOKING LATENCY",
      "Another drivers with no DPC latency fix. I stop here since I don't want to swear.",
      "*CTRL+F*\n\n*\"DPC\"*\n\nYep knew it, knew it all along!\n\nCan anyone explain if the DPC Latency issues affects you if your audio is via a USB DAC amp?"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "rtx 4060",
      "4060",
      "rtx 4060 ti",
      "4060 ti"
    ],
    "title": "Which one should I buy - RTX 4090 24GB or RTX 5080 16GB? I only play at 1440p.",
    "selftext": "Hi y’all, I’m planning on upgrading from a RTX 4060 Ti 8GB and I’m wondering if I should wait for the RTX 4090 24GB to come back in stock where I live or if I should just get the RTX 5080 16GB. Both are pretty much the same price, with the RTX 4090 24GB being a bit more expensive obviously. I also only play at 1440p and don’t plan on playing at 2160p anytime soon. So what do you think? is the 16GB on the RTX 5080 not gonna be enough even if I only play at 1440p? please let me know what you think and help me decide. Thanks.",
    "comments": [
      "Where are you seeing 4090s only a little more expensive than a 5080?",
      "It's probably missing the GPU die and all the VRAM chips☠️",
      "Whichever is cheaper .\n\nEdit :just went from a 3080 to a 5080 and it was a huge upgrade for me at 1440p",
      "Piffle.\n\nPure piffle.\n\n\n1440p is not looked down upon by most people. I've never heard as much crap.",
      "4090 is still a much more powerful card than 5080, more vram, more cores.. 1440p is looked down upon with most people but its still quite demanding with ray tracing specially if u have a 21:9 monitor. Only card that is an upgrade from 4090 is a 5090",
      "5080 is better BUY, but 4090 is better CARD.\nIf prices are within 20% diff (new vs used) (4090 more expensive), I would go for 4090. Otherwise go for 5080.",
      "People be pricing the 4090 2k+$ and still buy them for some reason",
      "I went from a gtx 1080 to a 5080 🤟",
      "nVidia discontinued all of 40 series. You are not going to see a 4090 back in stock, and any that are still available will be way higher over MSRP price.\n\nMove on and get a 5080.",
      "4090 is a hell of a card, and will still be for the foreseeable future.",
      "It's the 2nd fastest consumer gaming GPU on the planet dawg",
      "This.\n\nPeople seem to refuse this truth for some reason.",
      "4090 is not coming back in stock. You can only get used ones and that's always a risk. Just get the newer card.",
      "I mean last I saw the 4090 was going for $2300+? So pretty dumb pricing there too.",
      "4090 has worse connector issues than 5080 lol",
      "people say anything without understanding context lol",
      "Meh, waiting is pointless unless you know the release date. And 24gb for 1440p is overkill, it would only be worth it if OP did a lot of AI stuff.",
      "According to the Steam survey, more than half of gamers are playing in 1080p.  This take is absurd.",
      "Or OP could wait for the 5080 Super. There is talk that it will have 24GB VRAM and be on par or maybe better than 4090 performance.",
      "3060ti to a 5080 and it's been such an amazing upgrade. I can do literally anything now it's insane. I can't imagine going from a 1080. Don't forget the extended Nvidia suite of features including RTX VSR and RTX HDR. I cant watch shows / movies / YouTube / anime etc without it anymore. It's *so* good."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "rtx 4060",
      "4060",
      "rtx 4060 ti",
      "4060 ti"
    ],
    "title": "Steam Hardware Survey - October 2024",
    "selftext": "https://store.steampowered.com/hwsurvey/\n\n1) NVIDIA - **77.37%**\n\n2) AMD - **15.00%**\n\n3) INTEL - **7.31%**\n\nThe above figures include igpus (I think).\n\n**Top 10 GPUs - % Marketshare**\n\n1) RTX 3060 - **7.46%**\n\n2) RTX 4060M - **5.61%**\n\n3) RTX 4060 - **5.25%**\n\n4) GTX 1650 - **4.71%**\n\n5) RTX 2060 - **4.33%**\n\n6) RTX 4060 Ti - **4.29%**\n\n7) RTX 3060 Ti - **4.26%**\n\n8) RTX 3070 - **4.23%**\n\n9) GTX 1660 SUPER - **3.77%**\n\n10) RTX 3060M - **3.65%**\n\n**Highest % change in month**\n\n1) GTX 1660 SUPER - **+1.83%**\n\n2) RTX 3060 - **+1.60%**\n\n3) RTX 4060M - **+1.24%**\n\n**Top 3 AMD dGPUs**\n\nRX 6600 - **0.98% (+0.25)** - 33rd\n\nRX 580 - **0.97% (+0.26)** - 34th\n\nRX 6700XT - **0.86% (+0.23)** - 37th\n\n**VRAM**\n\n4GB - **7.71% (+0.46)**\n\n6GB - **14.09% (+1.45)**\n\n8GB - **35.11% (-2.30)** \n\n12GB - **18.59% (-0.78)**\n\n16GB - **3.46% (+0.20)**\n\n**Display Resolution**\n\n1920x1080 - **57.32% (+1.59)**\n\n2560x1440 - **19.71% (-2.02)**\n\n2560x1600 - **4.26% (-0.04)**\n\n3840x2160 - **3.89% (+0.21)**\n\n**RAM**\n\n16GB - **46.75% (+1.43)**\n\n32GB - **31.61% (-1.78)**",
    "comments": [
      "There are more 4090 (1.17%) than 4080 or 4080 Super... or 3090 or even the 780M. Wow.",
      "1/\\~100 gamers has a 4090. Thats a shit tone of 4090s",
      "The average joe is using an entry lvl Nvidia GPU with 6-12 GB of VRAM, playing at 1080p. Weird how companies dont understand realize this. \n\nThe pricing for the 40 series is fucked when most people can only buy the 60 type card and nothing else",
      "I think the thing with 4K is you’re always going to be chasing that res with modern games. You need the best GPU each gen to keep up with the latest games if you want a high frame rate too. \n\nWith 1440p, you can be quite comfortable with mid-high end hardware at much higher FPS.",
      "It makes sense since Nvidia shafted the performance of the 4080s by so much",
      "Its default \"budget\" prebuilt GPU currently. Like 95% of offers have that GPU and overwhelming majority of people go for budgety prebuilts.\n\nJust type in google \"gaming pc\" or \"prebuilt gaming pc\" and see majority of offers having variety of CPU/RAM configurations and such but 95% of them have 4060 as GPU",
      "AMD is similar. For awhile the 7900XTX was the only RDNA3 card on the Steam Survey, and it’s still more than triple (0.50%) the next one (7700XT, 0.16%). \n\nI think there’s a point where, if you’re going to spend a large chunk of money on a card you might as well just save up (if you need to) and get the best in the lineup instead. AI might play a role, too, although this is Steam so they’re also gaming.",
      "People shit all over the 4060, but it's consistantly the second most popular card lol",
      "4090 is the best value card in the last 3 generations. At best contested by the 3080. \n\nIt’s weird, but it’s true.",
      "It sold really well. To this day, apart from those 3-4 UE5 games and path traced Cyberbunk, it just tears apart any game I throw at it.",
      "Because it's cheap, not because it's good, lol. It's taking advantage of a consumer base that isn't exactly up to date on the exact performance of every card. Most people just say oh 4060. Should be really good and way better than a 3060. Little do they know the difference between a 3060 and 4060 is negligible lol.",
      "Nice flex man",
      "Comes in a lot of prebuilts",
      ">The 3080 didn't age well due to VRAM.\n\n\nI would have to disagree with that as I still have yet to run into a game where the VRAM was an issue at all after 4 years of using a 3080 10GB. I play 50/50 1440p and 4K, though lately it's been mostly at 4K with Silent Hill 2 remake being the latest title I played.\n\n\n\nThere might be a few examples out there where 10GB is not enough but I have yet to see one myself, so from personal experience I think the 3080 has aged extremely well.",
      "The 3080 didn't age well due to VRAM. The 3090's VRAM advantage turned out to be a lot more valuable in the long run. \n\nI might be biased because I own one but I feel that the 4070 Ti Super will age really well relative to its price.",
      "Harder senpai",
      "i cant believe rx 6600 is just 0.98%",
      "1660 super owner for 5 years now and can play most games with good FPS on 1080p. Good to see this card holding up nice with the gamers.",
      "4K requires an insane jump in computation power for an almost irrelevant benefit at the normal viewing distance somebody games at. 1440p, however, I would expect to be higher than it currently is.",
      "Yea i should have just put out another $500 for a 4090 tbh."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "rtx 4060",
      "4060",
      "4060ti",
      "4060 ti"
    ],
    "title": "DLSS 4 is the savior for RTX 4060 and 4060TI with 8GB VRAM",
    "selftext": "Seriously the new Transformer Model is an absolute Game Changer for the 60 Cards from 40 Generation.\n\nSo far my 4060 TI could barely handle Raytracing at 1080p with Quality DLSS and it still looked like Dogshit in Cyberpunk 2077.\n\nNow with the new Transformer Model i can lower it down to Balanced on 1080p or Performance on 1440p with RT set to Ultra. Without Frame Gen its around 55-60 FPS now and looks almost like Native.  VRAM Usage hovers around 7GB only. With the addional Frame Gen it gets to around 110-120FPS and 7,2GB Vram usage. The Input Lag is almost non existant because of the good Base Framerate. With old DLSS to archive this quality i had to use Quality DLSS which gave me around 30Fps without and 55/60 with Frame Gen with a huge Input Lag.\n\nBefore Nvidia released DLSS 4 i was sure to buy the new 5060TI 16gig when it releases but now i will definatly wait for the 60 Generation because DLSS definatly gave the 60 Cards of previous Generation new Life for 2-3 Years for sure.\n\n  \nHow are your experiences with the 4060 and TI with DLSS 4 so far?\n\n  \nThank you Nvidia!",
    "comments": [
      "Why doesn't my nvidia app don't detect the new driver? \nIt's already released right? \nMine still said 566 is the latest.",
      "Yeah its released. The whole Nvidia App does have Trouble with DLSS4 right now. Best Thing U can do is uninstall everything with DDU and then manully Install The new Driver which includes The Nvidia App. And then activate DLSS 4 globaly with the Profile Inspektor Tool and The Tool DLSS Swapoer. Because some Games are still greyed Out for DLSS Oberried eben after fresh Install. The are plenty of Guides on YouTube in how to do it with Profile Inspektor and DLSS Swapoer.",
      "You Capitalise words In a Weird way.",
      "Dlss 4 saved 1080p gaming for me",
      "This guy ate all the marketing hype and is happy about it",
      "Ah ok just wanted to check your CPU wasn't bottlenecking you.\n\n\nI only recently upgraded from a 5 3600 to a 5700x3D and couldn't believe what a difference it made.",
      "Tbf, it's nvidia who had 8GB VRAM in a 400 dollar card",
      "I feel like it’s very heavy on compute, and could use a lot more polished, especially compared to DLSS 3. Currently performance mode is as heavy as balanced or quality upscaling using the old DLSS on a 4060. More powerful cards don’t seem to take as big of a hit. With the latest drivers it’s outright broken in Control. \n\nI can see it’s potential though. Tried it in Witcher 3, and the stability in motion is fantastic. Normally with TAA or any temporal upscaling, the image blurs significantly in motion. But with DLSS 4, things are very sharp, and that barely changes when moving around. Vegetation is a bit unstable though for some reason when standing still, and other artifacts show up.",
      "I got everything on very high and ultra If possible Not Just high ;) And i use a Ryzen 5600x",
      "They're not neglecting users using their cards for work purposes. They make an entirely different product line exactly for that use case.",
      "What CPU do you have? \n\n\n\nI have a 4060 (non Ti) and use 1080p Quality with RT and I get my 58 capped FPS pretty much consistently.\n\n\nI have every setting set to High, with RT lighting set to Ultra.",
      "This is black magic!  I'm suddenly playing CB 2077 in 1440p with RTX ultra and it looks and runs amazing on a RTX 4060.",
      "He's playing a single player game lol. Who cares.",
      "That's some serious copium. U have a 4060ti so almost the lowest of the lowest 40 series. U aren't hitting 100+ frames maxed out cyberpunk bro.",
      "My CPU is only bottlenecking in Dog town at The pyramid in Phantom Liberty DLC. But yeah Phantom Liberty DLC asks for 8core CPU and Mine is 6. I Plan on upgrading to 5700x3d too, awesome price to Performance and it gives me The two Missing cores and gives a few more years Out of my system. 5600x is great but The additional L3 Cache From 5700x3d is Just too tasty",
      "Personally i would Not have too much Hope for neural Rendering Being good right From The start. Nvidia Always pushes Forward with new technology (which is good) but at First it Always sucks. For example DLSS 1 on 20 Series when it launched was absolute Horrible. Frame Gen when it launched on 40 Series it Had many artefacts without Ray reconstruction. Physx Back in The day was way too Performance hungry when it launched many years ago. Neural Rendering might also have artefacts and needs Fürther improvements. For your Sake i Hope Not, but i wouldnt Count on a flawless experiance with it right From The start.",
      "The speed is the same, but I load 11 to 15gb vram easily in cp2077 going path tracing and forcing hires textures",
      "Ok i thought it was mine only.\nThanks 👍",
      "At least RTX Mega Geometry is promising in Alan Wake 2 the first game its in. \n\nThis feature is for all RTX gpus 😁",
      "I agree, I'll try it out too. I'm glad the feature isn't exclusive for 50 series"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "4060",
      "4060 ti"
    ],
    "title": "Putting Chat With RTX To The Test (Result: It Is Promising But Not Great)",
    "selftext": "I wanted to love Chat With RTX, but my experience with the new version of ChatRTX released a few days ago was unfortunately not great.\n\nI've written and published 25 novels at present. As I'm working on book 26 now, a sequel to Symphony of War, there's a lot to keep track of. J.K. Rowling said she used Pottermore when writing the later books to make sure she got the details right, and I wanted to do something similar; plug my book library into ChatRTX so I could ask it simple questions. Things like, \"What colour was this character's eyes?\", \"What religion is this character?\", \"Which characters were on the drop mission in Act 2?\", \"how did Riverby die?\", etc.\n\nI also had more grandiose plans, like asking it about plot threads I hadn't resolved or anything that I might have missed in terms of plot holes or anything... or even higher-level questions. But it never got past this first stage.\n\nThe install went fine, and to test it I pointed it to a single novel, just so it didn't get confused. I also only have a 3060ti with 8gb of vRAM, so I didn't want to stress it. With this in mind, I plugged in a single novel, \"Symphony of War\".\n\nUnfortunately, the LLM couldn't answer even basic questions about the plot, story structure, or events therein. \n\nIssues I observed:\n\n- Incorrect information and vivid hallucinations\n\nAsking simple questions like, \"What can you tell me about Marcus?\" [gave almost entirely wrong answers](https://imgur.com/vvJcXJn). He's not captured by the Myriad, he's not trying to form an alliance with them, his rock isn't magical. He IS afraid of seeming crazy because of the music in his head, but this is not related to the rock at all. The hatchery, takes place in Act 1 and is just one scene in the entire novel. And as for the fire breathing bit... that seems to be a straight-up hallucination.\n\nI asked it why it thought there was fire-breathing, and it backtracked. It was correctly able to determine that the broodmothers had turned on each other and were dead, but it appeared to have hallucinated the detail about fire-breathing.\n\n[In later questions, it was able to provide some right answers](https://imgur.com/7lSrVYo) (it correctly identified Beaumont used a flamethrower and Riverby used a sniper rifle), but it said that Stanford died after being stabbed by Rabbit, whereas Stanford was in fact squished by a massive falling bit of metal. It similarly said Riverby died by being electrocuted, but she survived that and died much later being torn to pieces by bugs. It correctly identified how Rali died though.\n\n[Weirdly, I asked it how Marcus died.](https://imgur.com/HHOOj36) He survived the book, but the LLM it hallucinated that he was \"shot by a bug\" (in the book, *he* shoots the bug) and then despite being dead, Marcus ran until he was killed by the pilot light on Beaumont's flamethrower. Beaumont too survives, but when I asked the LLM how she died, it told me Marcus shot her in the head which it seemed to pull from thin air. I asked it how Wren, who also survived the book, died and it said it was \"not clear\".\n\nIt said Beaumont and Riverby, both women, were men. I asked it how many female characters there were and it said none, despite there being many (Rali, Wren, Beaumont, Riverby, Felicity).\n\nIt correctly told me how many men were in a standard squad.\n\n- Confusing different characters\n\nSometimes the chat would get confused as to who the main character was, occasionally identifying Blondie as the main character. It also got confused and thought Marcus was an agent of Internal Security, whereas he was actually *afraid* of Internal Security and accused Blondie of being a member of IS.\n\nIt seemed to get the Lost and the Myriad, two different species, confused and assigned qualities of each to the other interchangeably.\n\nIn something that surprised me, it was quite good at identifying the beliefs of various characters. [It guessed that Beaumont was an atheist despite her never saying so, and pulled up quotes of hers to support that position](https://imgur.com/w7pGao6). It correctly identified that Blondie was sceptical of religion, Rabbit was an atheist, and Riverby's religion was not mentioned. It correctly stated Riverby was a monogamist who valued duty and honour. It was similarly excellent at describing the personality of characters, noting that Beaumont's attitude suggested she had a history of being mistreated, which is quite a complex analysis.\n\n- Profound inability to make lists or understand sequences\n\n[If I asked it, \"What was Blondie's crime?\" it got that information right, but when I asked it, \"List the crimes of every character\", it got confused and said there was no information about crimes committed by characters.](https://imgur.com/9lnAw8J) It was able to identify the novel as a story though.\n\nAsking it to \"list every named character in Symphony of War\" [produced absolute nonsense.](https://imgur.com/omxJdXV) Paragraph [after paragraph after paragraph of \"* 7!\"](https://imgur.com/9B1adZD), that went on for several minutes until it eventually timed out.\n\nIt also got confused about how many pages the story had. [It claimed to only have a few pages from the novel, but it was able to pull information from the beginning, middle, and end of it. When I asked how many pages the novel had, it said it had 1.](https://imgur.com/MoSrpDx)\n\nHowever, I asked it to pull up three quotes from each main character, and it was able to do it for Blondie and Beaumont, but not Rabbit or Riverby (both of whom have sufficient lines to supply three quotes). In fact, it identified one of Blondie's quotes as Riverby's, but that quote was spoken, Riverby wasn't even in the room or introduced as a character yet.\n\n[It was unable to summarize the novel's plot, saying there was insufficient detail.](https://imgur.com/6Up8z2h)\n\nThings I tried:\n\n- Cutting out foreword, dedications, even chapter headings. Everything except the text. This had no effect.\n- Adding more files, limiting to a short story set in the same universe, etc.\n- Changing between LLMs, noting that with 8gb of vRAM I was quite limited in what I could select. Changing to ChatGLM didn't produce much better results and injected Chinese characters everywhere which didn't work too well at all so I switched back to Minstral.\n\nFinal conclusions:\n\nThe potential is here, and that's the frustrating part.\n\nSometimes it got things right. Sometimes it got things so right I was almost convinced I could rely on it, but sometimes it was just so wrong and so confident in being wrong that I knew it wasn't a good idea to trust it. I genuinely couldn't remember which of Riverby or Stanford was flogged, but I knew it was one of them, so I asked the LLM, and it said Riverby. But when I double-checked the novel, it was Stanford.\n\nObviously, some mistakes are going to happen and that's okay, but the number of errors and the profoundly serious way in which it misidentified characters, plots, stories, and all these kinds of things makes it just too unreliable for my purposes.\n\nI was left wondering; even just having the application open consumes all available vRAM (and a smaller amount of system memory, 9gb overall combined). Could better results be achieved with more capable hardware? If I can cut down on the hallucinations significantly, buying a 4060 ti with 16gb of vRAM, or even a used 3090 with 24gb, is something I might be tempted by. Especially if it's able to give me the right answers.\n\nHas anyone else with more vRAM tried this, or is this just how it is?\n\nHardware:\n\n5800x3d\n32GB DDR4\n3060ti (8gb vRAM)\nWindows 10",
    "comments": [
      "You might get more responses in /r/localllama.\n\nYou also might want to try running some non-Nvidia models through LMStudio or KoboldCPP. The new Llama 8B is good and will fit in 8GB of VRAM. Let me know if you need more info on how to do that.\n\nIt's not designed for file processing like the Nvidia app is though (at least by default), more just ChatGPT-esque interactions, text completion, or roleplay.\n\nI have a 24GB GPU but haven't played with Nvidia's app. I have been following open source local AI for a while now though and mess around with all the new models and developments.",
      "This post will get bombed shortly by AIbros going on about how it will soon be revolutionized and all the fundamental shortcomings of LLMs will evaporate if it is just fed enough data or vaguely \"improved\".\n\nThe long and short of it is modern AI cant think. It cant perform logic on any level. It is just a very advanced pattern-matching and association system with zero ability to error-check or make common sense calls on something being obvious bullshit.\n\nIn your case, all it is seeing is words and associations, a lot likely pulled from secondary content to the book itself if it is not made up from nothing. It has no understanding of grammar and cant reliably parse what anything in the book actually means. It certainly cant read through it and count the characters, it is entirely reliant on cribbing that from someone else doing it previously, and barring that, making up bullshit.\n\nThis is why it is no threat to writing, programming, or other fields that have seen blather about it replacing skilled professionals. It simply cant do anything beyond remixing tiny snippets that are often nonsensical garbage.",
      "Hopefully the mods don't delete this. This is a great thread.",
      "ChatGPT's secret is the monstrous amount of data it is working with for it's model, mostly. It still spectacularly fails pretty often, especially with anything unusual or logically confusing.",
      "While the vast majority of this is true, it already has replaced people. \n\n\nBeyond text based AI, The Finals now uses AI voice actors based off of the original voice actors. It sounds like garbage but technically works.",
      "It was published in 2015 so no.",
      "Thanks mate!",
      "> Yeah, it sucks because ChatGPT 3.5 (which I have some experience with) was able to do this kind of stuff much better and with much greater reliability\n\nYeah because they aren't running their model in 8GB of VRAM\n\nYou need models that run on 48GB of VRAM+ if you want the decent models",
      "4090, I use it in a similar way, store tons of self written novels... then I turn my novels into a DIY Text MUD that spans multiverses... it's glorious. I freaking love it.",
      "Don’t delete this mods",
      "Yeah, it sucks because ChatGPT 3.5 (which I have some experience with) was able to do this kind of stuff much better and with much greater reliability, I just couldn't (for obvious reasons) copy and paste in a whole novel.",
      "Audio alteration is one place where it is better-off, it is not doing any actual creative or logical work by itself.\n\nAnd it still messes it up unless it is just tuning real recording.",
      "My understanding is that completely new voice lines are being generated. Is that really \"alteration\"?",
      "This is just (somewhat) uninformmed speculation from my part, but it could be a context size issue. You're giving an entire book to the LLM, the context size might not be enough, even if you use RAG.\n\nMaybe try to divide the book into multiple files, each file containing one chapter.",
      "Hmm, that's interesting. Could well be a combination of factors then.\n\nMy issue really is the hallucinations and wrong answers. I don't mind if the answers are limited (although obviously this is unideal), it just does have to be reliable.",
      "I've been tossing up between that and Google Gemini. Apparently Google Gemini is better for this because you can turn off the \"safety features\", and while it won't generate violent text I don't want it to generate anything, I only want its feedback and to question-answer things about the characters, plots, and the like.\n\nI tested paid Gemini and it didn't work too well until I turned off all safety features. It won't generate responses if the content violates that, but it will at least read and understand it, so you can query it. Like, \"Who shot Marcus by accident?\" is a question it will answer, even if it includes a bit about not wanting to generate violent imagery.\n\nIt also has a million context token inputs, with v1.5, so I was able to copy-paste the WHOLE FREAKING NOVEL into the chat window and it successfully understood it, able to intelligently answer questions and answers. It means I have to like... do a bit of preparation work per series, but that's okay. I'm honestly really impressed.\n\nIt works well but I'm open to trying new things. I've heard that GPT-4 Turbo is really aggressive with its censorship, though, and doesn't support anywhere near as many context tokens (which seems to be the big problem with novels).",
      "You can't do that in ChatRTX but you can with other local text generation applications.\n\n2x3060 is common on the budget end, 2x3090 is common on the higher end.\n\n2x3090 will give you fast 70B 4 bit generations which is where you get into the \"better than GPT 3.5, rivaling GPT 4\" territory.\n\n3 or more GPUs also works but it starts getting complicated with the power delivery, PCI slots/lanes, etc. It's like building a mining rig. There's also some efficiency loss for every extra GPU, and the lower end GPUs are of course slower even if they have the same total VRAM.\n\n1 or 2 3090s is probably your best bet if you want to get seriously into it for semi-professional use. They run about $600 USD each used. You'll need a big power supply too.\n\nOr just rent GPU time on RunPod or something.\n\nAnd seriously you should post questions like this in /r/localllama. Lots of the people there know way more than me and would be interested in your use case.",
      "The tool you are using might not be adapted to your use case. The results you are going to get depend on multiple factors and parameters:\n\n- The model used and it's context size\n- The RAG pipeline (document ingestion/retrieval): they probably have a generic chunking strategy that is not working well for your case (the \"slices\" that are put in context are not efficient for your data)\n- The prompt template and inference params\n\nTo control these you might need to go down the rabbit hole a bit. If you want to learn I can recommend to start trying other models with software like Ollama or Koboldcpp: those are easy to use. With your 3060ti you can run models in the 7b range, and there are some good ones like the new Llama 3 or Mistral fine tunes. To get a rag pipeline well adapted to your case this may take some work.\n\nDefinitely get a 3090 if you can: you will be able to run more powerful models. In your scenario I would try Command-r 35b, that has a great context window and is very good with documents, but it needs that 24Go of Vram at least..",
      "Hi David, I have a 3090 just wanted to note that I dont think the vram is one of the clear reasons from my initial testing but I would need same data to have more value here. My testing so far has yielded some similarities, one particularly has been the responses seem to limit the answers, for example I have hundreds of files and it correctly structures the results tailored to my prompt but stops at four rows (instead of listing them all).",
      "I'd definitely love more info about KoboldCPP or LMSudio. Especially if Llama 8B works in 8GB of vRAM and actually, you know, produces decent results."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "rtx 4060",
      "4060",
      "rtx 4060 ti",
      "4060 ti"
    ],
    "title": "ASUS RTX 40 Series Official Feedback Thread - Q&A",
    "selftext": "Hi everyone! I'm once again asking for your feedback :D\n\n&#x200B;\n\nAt this point, we've launched several model types across multiple tiers of the RTX 40 Series. Listed below each design will be the series it applies to since aesthetic design remains largely the same with only size changing between different tiers. Please take a look below at the designs and feature notes before leaving your feedback in the comments! Some notes, such as boost clock, will be listed only for a single tier as a reference comparison between the series. We'd love to know what you think of current designs, included features/unique aspects, and what you'd like to see as additions in the future!\n\n&#x200B;\n\n[ROG MATRIX RTX 4090 Platinum](https://preview.redd.it/6dfi9aenvrgb1.png?width=732&format=png&auto=webp&s=58c0f1aadcee54e69b5843d90951697f1cc59e42)\n\nThe main points to mention here are the use of a 360mm AIO and liquid metal to enable the highest out-of-the-box boost clocks. It's additionally one of our slimmest designs due to use of the AIO. Tubing is on the end versus the side of the card. RGB located around the edge of the frame and  with a semi-transparent cover to the cooling area.\n\n&#x200B;\n\n&#x200B;\n\n[ROG STRIX RTX 4090 LC](https://preview.redd.it/k87x2qfn0sgb1.png?width=732&format=png&auto=webp&s=f011e3ca0961cde6f7ed0e7209a99abc3989ac2e)\n\nA smaller 240mm AIO-based card that uses standard paste versus liquid metal. Also a slim 2.6 slot design. Has tubing on the side versus end. RGB located on \"front\" of card, side eye logo, and fans.  2640MHz OC boost clock.\n\n&#x200B;\n\n&#x200B;\n\n[ROG STRIX RTX 4090 - RTX 4060](https://preview.redd.it/jxw1wkhtvrgb1.png?width=996&format=png&auto=webp&s=c6525f2a34e9ccab171795871b84e425f08396a8)\n\n[ROG STRIX RTX 4090 & RTX 4080](https://preview.redd.it/cqfnk5nvvrgb1.png?width=996&format=png&auto=webp&s=8eb70315efe17f134913fce342e851d4fe752217)\n\n[ROG STRIX RTX 4090 EVA 02 Edition](https://preview.redd.it/ht3m88v2wrgb1.png?width=732&format=png&auto=webp&s=2582f9c3fc0aef7287a2d4a9fe9c900246c3a762)\n\n[ROG STRIX RTX 40 Series Backplate](https://preview.redd.it/90qxdvn4wrgb1.png?width=996&format=png&auto=webp&s=e3827be6666937de6fc29669f69abd06fed3e4b6)\n\nThe air-cooled ROG STRIX comes in 3 flavors; Black, White, Evangelion. It's a larger 3.5 slot design at the RTX 4090 level scaling down to 3.1 slot at the RTX 4060 level. RTX 4090 and RTX 4080 utilize an updated vapor chamber design with a milled heatsink. RTX 4090 to RTX 4070 uses a diecast metal frame and shroud. All versions have the FanConnect II feature with 2x PWM connectors on the end to attach additional PWM fans to controlled by CPU or GPU based temps. RGB accents on the end ring and ROG side text. Includes RTX 4060 Ti 16GB. RTX 4090 OC utilizes 2640 MHz OC boost clock.\n\n&#x200B;\n\n&#x200B;\n\n[TUF GAMING RTX 4090 OG](https://preview.redd.it/b4wj37tewrgb1.png?width=692&format=png&auto=webp&s=31265407a8c579f4abcfecfd8175f7d3cdec0cfd)\n\nThe main thing to point out is it utilizes the smaller RTX 30 Series cooler which measures at 325.9 x 140.2 x 62.8 mm VS 348.2 x 150 x 72.6 mm for the standard TUF GAMING RTX 4090. 2595 MHz OC clock speed.\n\n&#x200B;\n\n&#x200B;\n\n[TUF GAMING RTX 4090 - RTX 4060 Ti 8GB\\/16GB](https://preview.redd.it/5kjt1tftwrgb1.png?width=2400&format=png&auto=webp&s=f2c61b83280d0303ad184133f4652fdd7985c8dc)\n\n[TUF GAMING RTX 40 Series Backplate](https://preview.redd.it/2lk3c8hpwrgb1.png?width=2400&format=png&auto=webp&s=bb799a043dc092e27ca9d3eb9ac156f22b74da53)\n\nFull metal shroud. RTX 4090 uses a 3.65 slot design scaled down to a 3.12 slot design for the RTX 4060 Ti 8GB. Limited RGB. 2595 MHz OC clock speed.\n\n&#x200B;\n\n&#x200B;\n\n[ProArt RTX 4080 - RTX 4060](https://preview.redd.it/yegyhmokxrgb1.png?width=2400&format=png&auto=webp&s=51589206b2da3e90f1cd13bff8b26349f12692cc)\n\n[ProArt RTX 40 Series Backplate](https://preview.redd.it/uxobvi3txrgb1.png?width=2400&format=png&auto=webp&s=64ba210334dcb48a0cc89159dcd61d4a14902dca)\n\nLargest feature for this card is the 2.5 slot design used across all series that allows for either multiple cards to be used or access to the second PCIe slot for things like storage AIC. No RGB. It includes the RTX 4060 Ti 16GB.\n\n&#x200B;\n\n&#x200B;\n\n[ASUS RTX 4080 Noctua Edition](https://preview.redd.it/4mp0v0hkyrgb1.png?width=2400&format=png&auto=webp&s=5cfc5b1267ed2f968e68b490084a415f01ecb7c1)\n\n[ASUS RTX 4080 Noctua Edition Backplate](https://preview.redd.it/h9krar6myrgb1.png?width=2400&format=png&auto=webp&s=2bf7af3a18e5f85225a064e79f3399fee40961f0)\n\nThis card is all about the cooler. It's a 4.38 slot design measuring at 310 x 144.8 x 87.5 mm and focusing on temps and noise levels. It's a shorter but much thicker card compared to the ROG STRIX RTX 4080 which measures at 357.6 x 149.3 x 70.1mm. It comes in full RGBB, really great brown/beige.\n\n&#x200B;\n\n&#x200B;\n\n[DUAL RTX 4070 - RTX 4060](https://preview.redd.it/3c30m6twzrgb1.png?width=686&format=png&auto=webp&s=0e978679047f4f9f49d8be857cd44ba6780549dc)\n\n[DUAL RTX 4070 - RTX 4060 White Edition](https://preview.redd.it/evebueo30sgb1.png?width=2414&format=png&auto=webp&s=d235aeb92e80e1db88e1489f926951041412e9e7)\n\n&#x200B;\n\n[DUAL RTX 40 Series Backplate](https://preview.redd.it/ej6iceha1sgb1.png?width=2400&format=png&auto=webp&s=eb0bc9c08400df26b99cf01a1227fb608af6b181)\n\nMain points of note are the lack of RGB and smaller, dual fan cooler compared to other models. The size ranges from 2.56 slot and 267.01mm long for the RTX 4070 to 2.5 slot and 227.2mm long for the RTX 4060. It includes the RTX 4060 Ti 16GB.\n\n&#x200B;\n\n\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\n\n&#x200B;\n\nSo this wraps up the models and alternate colors for each. Special shoutout to the Asuka, I mean Eva 02 model. With the launch of 4060 Ti 16GB, almost all of our currently announced models are now available in the wild with the exception and MATRIX and Eva 02 which will hit shelves at some point this year. TBD on the exact date.\n\n&#x200B;\n\nSo with that, a few questions!\n\nWhat are your favorite(s) and lease favorite(s)?\n\nWhat do you like most or least from each design?\n\nHow do you feel the current designs or lineup compares to RTX 30 Series and RTX 20 Series?\n\nAre there features you don't care for or ones that are missing you'd love to see included in future cards?\n\nWhat matters most to you between noise, clock speeds, temps, and aesthetics?\n\nDo you overclock, undervolt, or leave it stock?\n\nIf you overclock or undervolt, what software, such as GPU Tweak III, do you use to do?\n\nWhat do you think about themed collabs such as the Evangelion series or Noctua card?\n\nIf you like themed collabs, are there any you'd love to see added?\n\nLastly, what games should I be picking up to try out?\n\n&#x200B;\n\nPlease feel free to leave any feedback or ask any questions! I'll do my best to answer them! And all feedback will be passed along to the team :D",
    "comments": [
      "For the love of god, stop putting tiny dual-slot brackets on huge 3–4-slot cards. It looks ridiculous and does nothing to help with GPU sag.",
      "yes, the card takes up 3-4 slots anyway..so why not make use of the otherwise wasted slots..it'll add more rigidity and could alleviate gpu sag even more.\n\nmight add another few bucks of manufacturing cost with extra steel but i think it'll be worth it.",
      "Hey there. I got ROG STRIX 4090 OC, and this is amazing card, but coil whine is just horrible. Stock settings. I dont use my headphones a lot, and i literally hear it loud from like 1 meter away, in closed H7 Flow case.",
      "Just to let you know, the only reason I didn't buy one of your 4090 cards is because of the coil whine, it's about time your company takes that issue seriously no?",
      "So my question is, when will Asus make more affordable GPUs?",
      "I really wish there were more options for water cooled cards.  At least EVGA started at the xx80 series.  After having a 1080Ti hybrid and replacing that with a 3080 hybrid, I can never go back to air cooled cards again, ever.  There's something about never breaking 53C (cooler than my air cooled 5800x) when your card is at full bore that just makes it great.  Specially with how hot climate change has made everything this year.\n\nWith the 5000 series, will you at least have more than 2 options for hybrid cards, with at least some being non flagship? (since 4000 series is probably not getting any new releases at this point)",
      "You’d prefer larger PCIe slot covers?",
      "Yes. NVIDIA and others have PCIe slot covers that are three slots wide. Honestly for such big cards I would consider that to be the minimum, given they also provide additional stability.",
      "I’ll pass this along!",
      "Owner of a TUF 4090 (non OC) - the big boy version- first off, very quiet, solidly built card no complaints. A little coil whine that seems to have mostly gone away with time. Or maybe I got used to it I’m not sure. \n\nComplaints: I will say I don’t like how you guys get rid of the non OCs (or make them hard to find) not that long after launch in favor of the more expensive (and at least for this gen non beneficial) OC versions.\n\n and i realize products change and maybe you were bamboozled on the tdp a bit by nvidia and I support being proactive and making the coolers smaller but it happening with no forewarning (so we couldn’t make a choice down the road if we wanted to) for the smaller card wasn’t my favorite business decision. Stuck with the big one. I’d highly prefer the “OG” version but it was far too late to swap when it launched, and I prefer SFF.",
      "We make MSRP models, so can’t really make more affordable than that unfortunately.",
      "Fix your damn coil whine. I've had 3x4080 TUF and 1x4090 STRIX, all with excessive coil whine. They were all returned back to the retailer. The STRIX was the worst of the bunch, it was so loud me and my brother had to hold our ears after booting the first game with it, I've never ever heard coil whine as loud as that.",
      "When will you get a grip on the coil whine? My 4099 TUF sings loud and proud",
      "Yes, those slots aren't being used anyway since the card is covering them. Might as well use them to add some structural rigidity.",
      "Asus has gpu's priced the same as stock already how can they make it cheaper? Nvidia has to do that. Unless the question is \"why don't you make more of the cheapest models, they are out of stock\"",
      "Fix the horrible coil whine on all of these cards and no, this is not normal. I have had 2 gigabytes 3090ti and 4090 without any coil whines so they have figured it out how to make 450w cards without coil whine but Asus hasn’t.",
      "Because it doesn’t work that way, unfortunately. Coil whine is far more complex and we already do a lot to mitigate it from manufacturing process to component choices. If it was as simple as  cheap glue, it’d already be resolved by all brands.",
      "I'll probably have more to add here once I install the 4080 Strix OC that arrived today tbh.   \nAs for priorities from most important to least: **Noise (Especially coil whine) > Clock Speeds > Temps > Aesthetics**. Themed collabs are great, I would have bought the Noctua edition 4080 if it wasn't an extra $600 AUD for me. I generally undervolt or leave stock, lost the silicon lottery on my 1080ti so it did not OC past factory settings well.   \n\n\nI'd prefer if the bracket took up more slots when the card is 3.5+, unless there's a specific reason to have it like this?",
      "much appreciated",
      "I got an DUAL RTX 4070 white a week ago. Everything was good until the coil whine hits...."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "rtx 4060",
      "4060",
      "4060 8gb",
      "rtx 4060 8gb"
    ],
    "title": "RTX 4060 8GB or the 3060 12GB? which one will you recommend?",
    "selftext": "they are both at the top of my price range (around the same price), and i don't want to get an AMD card. and i can't skip this gen too sadly...  \n\n\n12GB is more VRAM, but Banchmarks shows the 4060 is faster overall..  \nwhich card u think will last me longer for 1080P gaming at 120-144hz?  \n\n\nthx!",
    "comments": [
      "Gen on gen performance should never be so close that this is even a question, the sad state of affairs.",
      "rtx 4060 no good.",
      "Look, everyone is disappointed in the 40 series for minimal performance gains, but if the two are similar prices, the 4060 is just objectively the better GPU. It's around 20% faster in most games and has DLSS 3. At 1080p, theres really only one game where it loses to the 3060 due to VRAM (RE4 Remake). If you're gaming, it's not really a debate over which is the better card.",
      "Jesus...right?  This is reddit for fucks sake.",
      "They’re just renamed. They renamed a 4050 as an “RTX 4060”, a 4060 as an “RTX 4060 Ti 16GB”, 4060 Ti as an “RTX 4070”, 4070 as an “RTX 4070 Ti” but with slight bump in specs.\n\nWhile the 4080 and 4090 are fine, it’s just that the 4080 has a terrible msrp.",
      "Don't you come on here with your reasoned arguments.",
      "I know you're asking between these two cards, but I would recommend a used 3060 ti. It has better performance, and is great at undervolting if you care about power consumption.",
      "Yes, it does have more VRAM.  \n\n\nYes, it is going to be more future-proof outside games with FG.  \n\n\nYes, it is sometimes equally as fast especially in games like Last of Us where you need more VRAM and might even have issues due to the narrow bus.  \nBut this point is more debatable because it is generally at least equal or faster if not VRAM limited.  \n\n\nYes, it is generally cheaper after the 30 series price cuts.",
      "3060",
      "For 1080p gaming the 4060 will be the winner. If a game comes out that exceeds your 8GB of VRAM you can just lower a couple settings and be fine. It also has Frame Gen and runs lower power",
      "this is me doing it",
      "But the 3060 8GB was the ugly step-child to the 12GB card, with worse characteristics than the 1060 3GB to 6GB release. It was a complete cash grab by Nvidia during the peak of crypto for the consumers that didn't want to 'subject' themselves to a 50 series card.",
      "I can get 120fps in a lot of games on my weaker Rx 6600xt. I'm sure there is lot of games you can still get 120fps on with a 4060 of you turn ray tracing off, and textures down to medium-high.\n\nDLSS3 uses between 1gb and 2gb of VRAM it seems. So you have to turn your other settings down further to not get bad stutter from going over 8gb total usage.",
      ">Then listen to the answers you get.\n\nthis is literally the first comment to even try and explain to me why ex mining cards might be good, i just tend to no follow advice of \"just trust me bro\" without deep explanations like the one u have provided now.  \n\n\nsecond, my used market options are very scarce so i rather get a new GPU that won't need fans/parts changed i a year or might have problems from previous owners.  \n\n\nthird, i have yet to see a comment that explains 'with evidence' why the 10\\~ FPS boost of an 3060TI will be better than DLSS3+FG in 2-3 years that will jump my FPS much higher at 1080P.  \n\n\nim no ignoring data or comments' its just seems like most ppl here just come to clown on the 40XX cuz its hip to do rigth now, without ackollaging that there are not many batter alternatives that are as versatile as a 40XX card  \n\n\nim fully open to hearing such examples.",
      "Yeah there's a huge gap between 4080 and 4090 perf.\n\nThey'll bring out a 4080ti to slot in there at some point, where the 4080 should have been",
      ">if you plan to do stuff with AI than the 3060 for the vram but the 40xx series is faster with AI\n\nthis seems contradictory to me.. any chance u can rephrase that so i'll understand what u mean plz?",
      "Used cards are perfectly fine. I got a 3070 last month which was used for mining for about a year and runs perfectly fine no issues",
      "More VRAM, which means it's more future-proof.\nAnd it's about equally fast.\nAnd cheaper.",
      "Also worth noting if you plan on gaming with emulators the 3060 and 3060ti are better than their 40 series counterparts as the bus width gimps them badly in emulation.\n\nAlso depending on the models and platform some ai apps benefit from the larger bus width and greater vram.",
      "3060 if you plan on doing VR gaming, more vram is better for that"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "rtx 4060",
      "4060"
    ],
    "title": "RTX 3060 vs RTX 4060 - 12GB vs 8GB VRAM Utilization Comparison Benchmark at 1080p in Ratchet & Clank Rift Apart",
    "selftext": "",
    "comments": [
      "Anyone else remember when folks were trashing the 3060 for having \"too much\" VRAM? They were saying that Nvidia gave the 3060 more VRAM than it could use in order to scam people into thinking it was faster...\n\nEven now, we've got people who think 16GB is too much for the 4060Ti, that it doesn't have the bus width or some made-up garbage like that. The price may be terrible, and Nvidia may market it as a 1080p card, but the GPU is still roughly comparable to a 6700XT or 2080Ti at 1440p, provided it has enough VRAM.\n\nhttps://preview.redd.it/3ptuyq9635fb1.jpeg?width=565&format=pjpg&auto=webp&s=17f78c455e45f567a24a3e540b8d8820a1118b81\n\nWhen did everyone become completely ignorant of what VRAM does?\n\nEdit: For anyone thinking I made this stuff up, or that it was just one idiot on Reddit who got downvoted into the ground, here's J2C spouting this crap about cards having too much VRAM in his RTX 3060 review: [https://youtu.be/H1DApIvOCMw?t=61](https://youtu.be/H1DApIvOCMw?t=61)",
      "They get what they paid for (an shrinkflated 4050 renamed to be a 4060)",
      "We usually only see mid end card hit their limit after 3-4yrs old, not 1 month old.....",
      "4060 and 4060 Ti are trash",
      "Lowering textures is the last thing you want to do with a new graphics card.\n\nTextures can have a significant impact on visuals but have basically no impact on GPU performance... unless your card's out of VRAM, and VRAM is dirt cheap these days.",
      "My 3080 is even struggling. I get 30fps more when using medium texture vs high when I have very high ray traces reflection texture on. High ray traced textures are bugged and have artifacts so very high is only way.",
      "20fps vs 80 💀",
      "You're completely missing the point... This whole situation could have been avoided.\n\nInstead of ridiculing the 3060 12GB, gamers should have been demanding 16GB RTX 30 cards. \n\nThose 256-bit 8GB cards were basically built for mining, and unlike the GTX 10 series cards that got dumped in 2018, there were no long-term prospects for gaming on these new 8GB cards after the crypto market crashed.\n\nNow we still have 8GB midrange cards and 12GB high-end cards because consumers told Nvidia they'll buy cards with laughably low amounts of VRAM.",
      ">if you turn settings down \n\nPeople don’t want to drop $400 to instantly have to turn settings down at the card’s targeted resolution, that’s the problem",
      "I have a 2080ti and run into VRAM issues when playing on my TV. It's finally starting to look like it's time for an upgrade. And honestly, vram limits are the right reason to upgrade IMO, which is why they need to actually go up from time to time.\n\nEdit: 1060 (6gb) to 2060 (6gb) to 3060(12gb) is the correct procession. 4060 with a 192bit bus and 12gb of VRAM at 400 bucks is a decent card and you can probably do 18gb of gddr7 on the 5060 next year.\n\nThat's the right timeline right there.",
      "but.. but.. we need DLSS3, RTX....\n\nwelp.... turns out 3060 or Radeon equivalent will look overall better due to texture quality LOL",
      "paying $300 for a new card, getting excited to bring it home and try new releases and getting this. It gotta feel great right.\n\nHappened to me with Geforce FX cards. I was so mad how bad DOOM 3 ran lol. Learned my lesson then. Dont buy based on product name.\n\nedit: His PC does not support pcie gen4 so it's really extra bad for 4060. Se keep that in mind. Running out of VRAM is even worse when you cut down pcie bandwidth.",
      "Shit gpu.",
      "If you're talking about the 4060 vs 3060 being the same, that's because the GPUs in 8GB graphics cards in general are taking a \\~15–20% performance hit to avg fps in this scenario.\n\nThis is not isolated to the 40 series. The RTX 3070Ti (8GB) is only getting 79% the fps of the RX 6800 (16GB). Those cards would be margin of error if Nvidia had given the 3070Ti 16GB. But... bozos kept on paying a grand or more for 8GB cards, so Nvidia never saw the reason to break out their planned 16GB model when Micron's 2GB GDDR6X modules became available.",
      "FYI, the benchmark system is an i7-10700, which is PCIE 3.0 only. The RTX 4060 only has 8 physical lanes so the card's bandwidth gets halved. Benchmarks I have seen will show some games having a huge hit to performance from that alone. \n\nI still think the VRAM will be a bit of a factor, but this is a compounded problem in this video specifically.",
      "Jensen, is that you?",
      "Brutal",
      "I mean the 8G version matched by their previous generation counterpart.\n\nThat's really bad.",
      "They chose HIGHER prices and LOWER performance.\n\n![gif](giphy|YnkMcHgNIMW4Yfmjxr)",
      "Nah. People wanted an 8GB 3060. They thought 12GB was comically large and that it would never be useful in gaming.\n\nhttps://preview.redd.it/42v4msz60bfb1.jpeg?width=1080&format=pjpg&auto=webp&s=009d6f5327f78b1d388bbe254f10b3c2595e228b"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "rtx 4060",
      "4060"
    ],
    "title": "GeForce RTX 40 Series Laptop Launch Megathread (Giveaway Inside)",
    "selftext": "&#x200B;\n\nhttps://preview.redd.it/f9blkcqr2zga1.png?width=2382&format=png&auto=webp&s=386547f12eb5f14d77c1a0019fa81730a07784b9\n\nPowered by Ada Lovelace architecture, GeForce RTX 4090 and 4080 Laptops with DLSS 3 and 5th Gen Max-Q are here. This Megathread will serve as an information hub containing relevant information and reviews for various laptop models powered by RTX 4090 and 4080 Laptop GPUs.\n\n# GeForce RTX 40-Series Laptops GPU information:\n\n||**RTX 4090 Laptop**|**RTX 4080 Laptop**|**RTX 4070 Laptop**|**RTX 4060 Laptop**|**RTX 4050 Laptop**|\n|:-|:-|:-|:-|:-|:-|\n|**GPU**|AD103|AD104|AD106|AD107|AD107|\n|**Boost Clock**|1455-2040 Mhz|1350-2280 Mhz|1230-2175 Mhz|1470-2370 Mhz|1605-2370 Mhz|\n|**CUDA Cores**|9728 CUDA Cores (76 SM)|7424 CUDA Cores (58 SM)|4608 CUDA Cores (36 SM)|3072 CUDA Cores (24 SM)|2560 CUDA Cores (20 SM)|\n|Memory Interface|256-bit|192-bit|128-bit|128-bit|96-bit|\n|**VRAM Size**|16GB GDDR6 18Gbps|12GB GDDR6 18Gbps|8GB GDDR6|8GB GDDR6|6GB GDDR6|\n|**TDP Range**|80 - 150w|60 - 150w|35 - 115w|35 - 115w|35 - 115w|\n|**Price**|Starting at $1999|Starting at $1999|Starting at $999|Starting at $999|Starting at $999|\n|**Release Date**|TODAY February 8|TODAY February 8|February 22|February 22|February 22|\n\n&#x200B;\n\n# Reference Information:\n\n* GeForce RTX 40 Series Laptops Product Page -[ Click Here](https://www.nvidia.com/en-us/geforce/laptops/)\n* GeForce RTX 40 Series Laptop CES Announcement Article -[ Click Here](https://www.nvidia.com/en-us/geforce/news/geforce-rtx-40-series-laptops-available-february-8/)\n* GeForce RTX 40 Series Laptop Roundup - [Click Here](https://www.nvidia.com/en-us/geforce/news/geforce-laptop-40-series-partners/)\n\n# Reviews\n\n# Digital Trends\n\n* [MSI Titan GT77HX 13V - RTX 4090 Laptop](https://www.digitaltrends.com/computing/msi-gt77-titan-2023-review/)\n\n# PC World\n\n* [MSI Titan GT77HX 13V - RTX 4090 Laptop](https://www.youtube.com/watch?v=zgptkZkT9to)\n\n# Dave2D\n\n* [Razer Blade 16 - RTX 4090 Laptop](https://www.youtube.com/watch?v=WXXErAmuEzU)\n\n# Hardware Unboxed\n\n* [MSI Titan GT77HX 13V - RTX 4090 Laptop](https://www.youtube.com/watch?v=EkmxGhwltmU)\n\n# Hardware Canucks\n\n* [MSI Titan GT77HX 13V - RTX 4090 Laptop](https://www.youtube.com/watch?v=733SIf02QlM)\n\n# The Verge\n\n* [Razer Blade 16 - RTX 4090 Laptop](https://www.theverge.com/23588660/razer-blade-16-2023-review-specs-features-design)\n\n# Laptop Mag\n\n* [Asus ROG Zephyrus M16 (2023) - RTX 4090 Laptop](https://www.laptopmag.com/reviews/asus-rog-zephyrus-m16-2023-rtx-4090-is-the-real-deal)\n\n# Tech Spurt\n\n* [MSI Titan GT77HX 13V - RTX 4090 Laptop](https://www.youtube.com/watch?v=Vkw8yS04Ryw)\n\n# PC Centric\n\n* [ASUS ROG Strix Scar 18 - RTX 4090 Laptop](https://www.youtube.com/watch?v=MoneDpx7f9k)\n\n# Computerbase - German\n\n* [MSI Titan GT77HX 13V - RTX 4090 Laptop](https://www.computerbase.de/2023-02/geforce-rtx-4090-4080-laptop-gpu-gaming-notebooks-test/)\n\n# Hardwareluxx - German\n\n* [Razer Blade 16 - RTX 4090 Laptop](https://www.hardwareluxx.de/index.php/artikel/hardware/grafikkarten/60370-nvidia-geforce-rtx-4090-laptop-das-neue-mobile-flaggschiff-im-test.html)\n\n# Jarrod's Tech\n\n* [Razer Blade 18 - RTX 4080 Laptop](https://www.youtube.com/watch?v=7SHsJsAFadU)\n\n# Kitguru\n\n* [Gigabyte Aorus 17H - RTX 4080 Laptop](https://www.kitguru.net/lifestyle/mobile/laptops/luke-hill/gigabyte-aorus-17h-2023-laptop-review-i7-13700h-rtx-4080/)\n* Video Link -[ https://www.youtube.com/watch?v=vUN1EsBebKU](https://www.youtube.com/watch?v=vUN1EsBebKU)\n\n# Ultrabook Review\n\n* [Razer Blade 16 - RTX 4080 Laptop](https://www.ultrabookreview.com/62042-razer-blade-16-review/)\n* [ASUS ROG Strix Scar 18 - RTX 4090 Laptop](https://www.ultrabookreview.com/61998-asus-rog-scar18-review/)\n\n# r/Nvidia 40 Series Laptop Megathread Giveaway\n\nSee stickied comments for entry",
    "comments": [
      "My favorite feature of new 40xx laptops is how Nvidia labeled RTX 4080 as 4090 in laptops. This has to stop.",
      "# Asus ROG Strix Scar 18 \n\n&#x200B;\n\nBetter performance than my desktop PC with a 3090 LOL",
      "Lenovo Legion 7",
      ">. Make it comparable to M1 Macbooks, both in light and heavy load. Until that happens, I won't replace my Legion Y540.\n\nYour m1 mac is not going to run triple games A at 1440p 120fps or 4k 60 with high settings",
      "They've been doing this since forever",
      "Is there any news on Studiobook 16 3D OLED?",
      "Legion 7 from lenovo",
      "Lenovo Legion 7",
      "Lenovo Legion Pro 7i\n\nGet that sweet sweet dlss 3 for ultra settings smoothness in MSFS",
      "Lenovo Legion Pro 7",
      "I'm waiting for the Lenovo legion 7 with RTC 4090 laptop. Best laptop in the world as I have the RTC 3080 version.",
      "Lenovo Legion 7i pro bc the 30 series ones were great",
      "DLSS2 has been such an impressive change for everything I play and so I’m most looking forward to seeing what DLSS3 can do.",
      "It's a pain to setup, but if you want battery life, you need to disable the dGPU for every app that isn't a game. I went from 2 hours to 8 on my gigabyte aero doing this.",
      "# r/Nvidia 40 Series Laptop Megathread Giveaway (stickied comment)\n\n**How long will this contest run**: Starting today (February 8, 2023) through noon eastern time Sunday, February 12, 2023.\n\n**What do you need to submit:** Answer ONE of the following questions\n\n* *Which RTX 40 series* [*laptop models*](https://www.nvidia.com/en-us/geforce/news/geforce-laptop-40-series-partners/) *are you most looking forward to?*\n* *What are your* [*favorite features*](https://www.nvidia.com/en-us/geforce/laptops/) *of the RTX 40 series laptop and why?*\n\n**How to enter:** Reply to **this** **stickied comment** with your entry. If you are not replying to stickied comments, your entry will be void and will be removed.\n\n**How will the winner be determined?** This contest is run by[ r/NVIDIA](https://www.reddit.com/r/NVIDIA). We will be randomly picking the winner from the comments\n\n**What are the prizes:** NVIDIA is providing **3x $100 Steam Giftcards.**\n\n**Disclaimer**: This contest is open **WORLDWIDE** with[ exceptions for the sanctioned countries](https://www.export.pitt.edu/embargoed-and-sanctioned-countries)",
      "Lenovo Legion 7 or Razer Blade 16 would be on my short list.. ;)",
      "Razor Blade 16 \nBeing able to run DLSS 3 frame generation on a portable machine. Many many frames makes me happy 😊",
      "This thing is basically a portable 3090 ti which is insane!",
      "Asus ROG Strix Scar 18\n\nGreat DLSS3 performance gains :)",
      "Asus SCAR 16"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "rtx 4060",
      "4060",
      "rtx 4060 ti",
      "4060 ti"
    ],
    "title": "[Megathread] Announcing The GeForce RTX 5060 Desktop Family: DLSS 4 Multi Frame Generation, Neural Rendering & Blackwell Innovations For Every Gamer, Starting At $299; Plus RTX 5060 Laptops Available In May",
    "selftext": "**Full Article Here:** [**Click Here**](https://www.nvidia.com/en-us/geforce/news/rtx-5060-desktop-family-laptop-5060-coming-soon)\n\n# GeForce RTX 5060 Desktop Family - Blackwell RTX Now Starting At $299\n\nhttps://preview.redd.it/k402vqv4ixue1.jpg?width=3840&format=pjpg&auto=webp&s=fdb11f39b784a79027ce94f04b30dd62d82386af\n\nThere are over 50 million GeForce gamers using previous generation 60 Class and 50 Class graphics cards. For them, GeForce RTX 5060 Family graphics cards are a tremendous upgrade, bringing ray tracing and the benefits of DLSS 4. \n\nhttps://preview.redd.it/zdmq0iaeixue1.png?width=3840&format=png&auto=webp&s=cc75f6c6566f9c2a197c454b77e71fdc698e7f24\n\nThe 3 pillars of gaming performance are beautiful image quality, a high frame rate that perceptively feels smooth, and low latency.\n\nDLSS Super Resolution using our new transformer AI model ensures excellent image quality, and the advanced Ray Tracing Cores of the NVIDIA Blackwell RTX architecture allow GeForce RTX 50 Series gamers to be immersed by realistic lighting effects.\n\nDLSS Multi Frame Generation, DLSS Super Resolution, DLSS Ray Reconstruction, and other performance-accelerating technologies exclusive to GeForce RTX GPUs ensure frame rates are as fast and smooth as possible.\n\nAnd NVIDIA Reflex minimizes PC latency in over 130 games, including leading competitive titles such as *VALORANT*, working in conjunction with our optimized architecture and DLSS-accelerated frame rates to give GeForce RTX gamers the most responsive gameplay of any platform.\n\nBy ensuring image quality, frame rates and latency are optimized, GeForce RTX 5060 Family graphics cards deliver a substantial upgrade to tens of millions of gamers.\n\nhttps://preview.redd.it/s10k6p5tixue1.jpg?width=3840&format=pjpg&auto=webp&s=252677a436872b0d3fe9fe7253218cf77c3b3067\n\n# GeForce RTX 5060 Ti Gaming Performance\n\nUsing DLSS 4’s Multi Frame Generation, Super Resolution and Ray Reconstruction with transformer AI models, and NVIDIA Reflex, *Hogwarts Legacy* players get a perceptively better than native experience in all 3 areas, with improved image quality, higher, smoother frame rates, and lower latency at 1440p max settings on the GeForce RTX 5060 Ti.\n\nhttps://preview.redd.it/l2mmkfrkjxue1.jpg?width=3840&format=pjpg&auto=webp&s=db6cf90da951958e3ed9b69c572ccf65fcaece4b\n\nCompared to the previous generation GeForce RTX 4060 Ti, frame rates are doubled and latency is lowered in numerous games, improving smoothness, fluidity, and the feel of the gameplay.\n\nhttps://preview.redd.it/fozn48ixjxue1.jpg?width=3840&format=pjpg&auto=webp&s=7d733dc6832fa731662b4b2fc9aa5ac549b1b38c\n\nhttps://preview.redd.it/yb5j443rjxue1.jpg?width=3840&format=pjpg&auto=webp&s=42eab00593d2c67035fdadea92b7e7b84ec054cf\n\nhttps://preview.redd.it/ylio9z2rjxue1.jpg?width=3840&format=pjpg&auto=webp&s=22d7081d8651ff8dd99290d83daf963dbb9b8b1d\n\nThis trend continues across a range of games on the GeForce RTX 5060 Ti with Multi Frame Generation. And for some examples of performance in games that don’t support Multi Frame Generation, *A Plague Tale: Requiem* and *Delta Force* show roughly a 20% improvement with lower latency.\n\nhttps://preview.redd.it/ic2ww3c6kxue1.png?width=3840&format=png&auto=webp&s=eac781b85f4fe7917399bfcb1d2f7e7337b46289\n\n# GeForce RTX 5060 Gaming Performance\n\nArriving in May, the GeForce RTX 5060 boasts the same features, leveraging them to deliver over 100 FPS at 1080p in the most graphically advanced games, and super fast frame rates in multiplayer favorites like *Marvel Rivals*.\n\nhttps://preview.redd.it/wfaf1eslkxue1.jpg?width=3840&format=pjpg&auto=webp&s=ace81fa6d2d16990559ed677a946583dd21c2114\n\nStarting at $299, GeForce RTX 5060 graphics cards offer double the performance of the previous generation GeForce RTX 4060 in games with DLSS 4 Multi Frame Generation, and offer an even larger jump in performance and responsiveness for gamers upgrading from older GPUs such as the GeForce GTX 1660 or GeForce RTX 2060.\n\nThis leap in performance enables gamers to experience higher levels of fidelity, to max out ray tracing in leading titles, and play their favorite titles with more responsive controls.\n\nhttps://preview.redd.it/yek57jzrkxue1.png?width=3840&format=png&auto=webp&s=c00e5ff4eeccbeffb7d72f57b5e93e78c9e1bb0e\n\nGeForce RTX 5060 Family graphics cards feature the same hardware innovations as the rest of our GeForce RTX 50 Series GPUs. Leverage the latest Shader Cores, Tensor Cores, Ray Tracing Cores and superfast GDDR7 VRAM for the best experiences in games. Encode and decode video faster with the latest generation, best-in-market hardware that produces superior results than other platforms. And output all visuals to the newest DisplayPort 2.1 UHBR20 displays.\n\nhttps://preview.redd.it/5y5b90exkxue1.png?width=3840&format=png&auto=webp&s=ac9082cf002d1ffaa979955967c8d636644da662\n\n*Full specifications for the GeForce RTX 5060 desktop family are available*[ *here*](https://www.nvidia.com/en-us/geforce/graphics-cards/compare/)\n\nPrices for the GeForce RTX 5060 start at $299, compared to the GeForce RTX 3060 and GeForce RTX 2060 which started at $329 and $349 respectively, delivering more features, faster performance, and more responsive gameplay. \n\nThe GeForce RTX 5060 Ti, launching April 16th, is available in 8GB and 16GB configurations, starting at $379 and $429, respectively.\n\nhttps://preview.redd.it/yo7fswq8lxue1.jpg?width=3840&format=pjpg&auto=webp&s=20acfe270dc14049bba43e50baa7e46bc4265e66\n\nStock-clocked and factory-overclocked models will be available from top add-in card providers such as ASUS, Colorful, Gainward, GALAX, GIGABYTE, INNO3D, KFA2, MSI, Palit, PNY and ZOTAC; as well as from system builders. If you purchase one, download and install our new[ Game Ready Driver](https://www.nvidia.com/en-us/geforce/drivers/) to unleash its full potential on your system.\n\nhttps://preview.redd.it/9m24wa7clxue1.jpg?width=11288&format=pjpg&auto=webp&s=4584a836a94ea870d83f4c21bcbe44e92bfdf8e0\n\n# GeForce RTX 5060 Laptops Arrive This May\n\nThe same features, innovations and advantages of the GeForce RTX 5060 desktop family are coming to laptops this May, when GeForce RTX 5060 laptops arrive on shop shelves, starting at $1099.\n\nhttps://preview.redd.it/jqu8m50ylxue1.jpg?width=3840&format=pjpg&auto=webp&s=a2b0abed968112ff97a61fa569084aeb4185ac24\n\nThanks to DLSS 4 with Multi Frame Generation and NVIDIA Reflex, GeForce RTX 5060 laptops are more than twice the speed of previous-generation laptops, with enhanced image quality and low latency.\n\nhttps://preview.redd.it/e5z5bcb1mxue1.jpg?width=3840&format=pjpg&auto=webp&s=0cc62347c4e8d133244c6546045293d8039a02b6\n\nhttps://preview.redd.it/yi5crym4mxue1.jpg?width=3840&format=pjpg&auto=webp&s=fe386976e79cf0d88d93c1b1dcdda2745f204c65\n\nGeForce RTX 5060 laptops are coming from every major OEM starting in May, with a broad range of designs and sizes, as thin as 14.9mm. Check out their websites for further details.\n\nhttps://preview.redd.it/ui6lgif6mxue1.png?width=3840&format=png&auto=webp&s=6a7813ba62103d1e957bef44dc56761a1184ed69\n\n# GeForce RTX 5060 Family Is Here\n\nWith the launch of the GeForce RTX 5060 Family, DLSS 4 Multi Frame Generation, neural rendering and Blackwell innovations arrives for every gamer. Get the fastest frame rates possible, experience immersive ray-traced graphics in the biggest games, unlock new experiences with NVIDIA ACE digital humans, enhance image quality with DLSS transformer models, and make controls more responsive using Reflex.\n\nThe state of the art continues to evolve, and with a GeForce RTX 50 Series graphics card or laptop, you’re positioned to experience all of the newest innovations in the latest and greatest games.\n\nThe GeForce RTX 5060 Ti launches tomorrow, April 16th, and is followed by the GeForce RTX 5060 and GeForce RTX 5060 laptops in May.",
    "comments": [
      "Never buy a gpu with less vram than the current gen console.",
      "https://preview.redd.it/rusigct5d0ve1.jpeg?width=802&format=pjpg&auto=webp&s=889b518be918bf7f353d22e26f9817770ac0f47b",
      "5060Ti is, what.... about 20% faster than the 4060Ti in rasterisation?  \n  \n4060Ti was basically no faster than the 3060Ti. Realistically 5060Ti is competing with the 3070. Which launched at $499 in 2020!!!  \n  \nAnd they want $379 for it, with only 8GB of VRAM.  \n  \nAbsolutely disgusting.",
      "I don't get why they would even release the 8gb model",
      "5060/Ti with 8GB of memory in 2025.. what a waste of silicon.",
      "It's gonna be super awkward when the 5060ti 16gb can do 4k Indiana Jones and the 5070 can't",
      "As always, wait for 3rd party benches, as the slides shows 2xFG vs 4xFG so its misleading.\n\nAlso new driver probably today or tomorrow for support for 5060Ti and hopefully lot of bugfixes with it\n\nAlso, we'll see how the G7 memory will help the card. 4060Ti wasn't even on G6X, but on the standard G6.",
      "Ay iamma be honest i don't give a fuck. Where are fixes for shitty drivers ?",
      "8gb vram simply should not be a thing on new products in 2025",
      ">5060/Ti with 8GB of memory in 2025.. what a waste of silicon.\n\nhonestly what makes this whole situation even worse is that Nvidia put benchmarks with FG turned on in their 5060/Ti announcement when it's pretty much unusable for 8 gb cards due to the vram it eats up",
      "just remember.. when the AI stuff calms down. remember how nvidia treated its gamers XD...",
      "$50 for an extra 8GB is crazy",
      "If I buy two 5060s will I finally have enough VRAM?",
      "6090 performance for $299!",
      "Why are u lying? You are not gonna use multi frame gen on 8gb cards, pathetic",
      "So like where are all the posts about the 5060 review fiasco? are mods going full censor on this?",
      "They literally stated in the games that does not support MFG, the 5060 Ti is 20% faster vs 4060 Ti. Pretty in line with other 50 series improvements vs 40 series (30% for 5090, 15% for 5080, and 20% for 5070 Ti and 5070)\n\nYour math is most certainly incorrect.",
      "That latency is bad across the board.  It goes to show you really need a high end card to try and deal with it.  Only one title below 30ms lag, which is where I find it tolerable.  At 40ms or more it’s very obvious there’s a delay before your controls respond, like there’s something wrong with the game and monitor.\n\nThe 8 gig limit just shouldn’t be offered in 2025.  16 gig minimum, especially since ram chips just don’t cost that much to the manufacturer to the point of charging $50 extra to the customer.  This is reminiscent of Apple gating ram differences for $100-$200 when it doesn’t cost that much to manufacture.",
      "MSI, Gigabyte, Asus, Zotac are all up on New Egg now. All showing as sold out. Prices for the 16gb are all $479, 8gb are $419. I looked on MSI's store about 7am this morning and saw them there, but at that time I am pretty sure the, the 16gb was $429 (Nvidia's msrp), but now it is up to $479 there too.",
      "I guess it depends on the games you play or other use cases but I'd personally go for a lower end CPU e.g. 7700X and bump the GPU to a 5070"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "rtx 4060",
      "4060"
    ],
    "title": "GeForce RTX 5070 Ti Review Megathread",
    "selftext": "# GeForce RTX 5070 Ti reviews are up.\n\nhttps://preview.redd.it/rt7z75u3k3ke1.jpg?width=3840&format=pjpg&auto=webp&s=e7e929e87625c6e909d04c0472abaf71f65a5e00\n\n# Below is the compilation of all the reviews that have been posted so far. I will be updating this continuously throughout the day with the conclusion of each publications and any new review links. This will be sorted alphabetically.\n\n# Written Articles\n\n# [Babeltechreviews](https://babeltechreviews.com/nvidia-rtx-5070-ti-review-asus-prime-edition/)\n\n>The Nvidia RTX 5070 Ti is a well-balanced GPU that delivers strong performance, particularly at **1440p and high-refresh 1080p gaming**. Its **efficient design, improved cooling, and significant performance gains** over the RTX 3070 and 4070 make it a compelling upgrade for gamers still on older-generation cards. **DLSS 4 support** further enhances its longevity, allowing for improved frame rates in demanding titles, making it a forward-thinking choice for those planning to keep their system for years to come.\n\n>However, pricing and availability are the biggest concerns surrounding the RTX 5070 Ti. While Nvidia has set an MSRP of $749, market conditions, tariffs, and limited stock often push the actual retail price higher. With early reports indicating that some models will land closer to $899 or more, the value proposition erodes. There are cards at launch at the MSRP of $749.99 and if you can snag one, we would recommend it. At the higher price points, an RTX 4080—especially if discounted or available second-hand—becomes a better buy due to its **higher VRAM capacity, better raw performance, and increased longevity for 4K gaming**. The only other factor would be how important DLSS 4 is for you.\n\n>Gamers should truly evaluate their **needs, budget, and resolution targets** before deciding, as AMD’s offerings could provide **better price-to-performance in pure rasterized gaming scenarios**. It goes without saying that the inflated pricing right now should be a huge stopping point for many; if you can wait, it would be best to look for a card near MSRP and not pay the scalper pricing.\n\n>Ultimately, the RTX 5070 Ti is **a fantastic card, but only if it remains at or near MSRP**. If prices **creep toward $900**, it loses appeal, especially when AMD’s alternatives and Nvidia’s own **RTX 4080-class GPUs** offer **better raw performance per dollar**. Gamers should watch for sales, check AMD’s competitive pricing, and weigh whether DLSS 4 and ray tracing enhancements justify the cost over alternative GPUs.\n\n# [Digital Foundry Article](https://www.eurogamer.net/digitalfoundry-2025-nvidia-geforce-rtx-5070-ti-review)\n\n# [Digital Foundry Video](https://www.youtube.com/watch?v=NlWmYg7Vr3Q&pp=ygUPZGlnaXRhbCBmb3VuZHJ5)\n\n>With our testing complete, the RTX 5070 Ti does enough to earn a recommendation. In short, you're getting a 16 percent improvement over the RTX 4070 Ti for $50 less - in theory - or a more measly seven percent advantage over the 4070 Ti Super. Add on frame generation and a few other niceties like DisplayPort 2.1, and the value proposition has at least improved over the last-gen card... though it's clear that the revised design and GDDR7 don't account for anywhere near the sort of gen-on-gen boost you get from a more substantial change, such as a shift to a new process process node.\n\n>In terms of our table of overall performance from 17 games tested, it's no surprise to see the 5090, 4090 and 5080 at the top across all resolutions. There's not much to divide the 4080 Super, 4080 and 5070 Ti too, with the outgoing 4070 Ti Super being no slouch either. It's interesting to note that even at 1080p, the close grouping of products around the 5070 Ti remains in place - it's only really the 4090 and 5090 that lose ground.\n\n>In common with RTX 5080, we're looking at another upwards bump in pure performance terms, though this time the gap between the new card and its older counterpart is much tighter, so who would I recommend this product to? Well, depending on resolution, you're looking at anything from a 31 to 33 percent general uplift in performance against the classic RTX 3080. Combined with the extra memory and the features of DLSS 4, I'd consider that the kind of threshold that's worth an upgrade, especially as you'll be able to more easily migrate into the full RT path tracing experience on a number of games which will prove more challenging on 3080-class hardware.\n\n>In terms of recommendations, the same applies if you have any of the higher end RDNA 2 cards, like 6800 XT, for example. Similarly, if you're still on a Turing-class 20 series card, you'll see a gigantic improvement here from the likes of 2080, 2070 Super and even 2080 Ti.\n\n>The question is, of course, whether the value calculations we've made are actually applicable. Nvidia sent over a list of cards promised to be at MSRP in the US and UK - which we've duly reproduced on our \"[where to buy RTX 5070 Ti](https://www.eurogamer.net/digitalfoundry-2025-where-to-buy-nvidia-rtx-5070-ti-uk-us-links)\" page - but we won't know until launch day how accessible they'll be.\n\n# [eTeknix Article](https://www.eteknix.com/nvidia-rtx-5070-ti-graphics-card-review/)\n\n# [eTeknix Video](https://www.youtube.com/watch?v=I2dqGTJ_Hj4)\n\n>First and foremost, the RTX 5070 Ti is a big step up for those still on an RTX 3070 Ti, in some cases offering a massive 60–70% performance uplift in rasterisation and over 100% in ray tracing, making it one of the most substantial generational jumps we’ve seen for this class of GPU. More importantly, it doubles the VRAM to 16GB of GDDR7 on a 256-bit bus, solving one of the biggest complaints about the 3070 Ti’s limited 8GB frame buffer, which has clearly started to show its age in modern titles.\n\n>Compared to the RTX 4070 Ti and 4070 Ti SUPER, the 5070 Ti still brings noticeable improvements, but the margins aren’t as dramatic. With around 17% uplifts over the 4070 Ti and around 9% over the 4070 Ti SUPER, it doesn’t necessarily make those cards obsolete, but it does offer a meaningful performance-per-pound advantage—especially if you skipped the 40 series and are looking for the best bang for your buck in the 70-class segment. Though, as mentioned, pricing is a bit out of whack anyway, and that’s a sore subject.\n\n>The pricing should have made the 5070 Ti a killer option, and at the announced MSRP of £749, this GPU easily justifies itself, slotting in close to the 4080 series in performance while staying significantly cheaper. It also comes with NVIDIA’s latest technologies like DLSS 4 with multi-frame generation (MFG), which dramatically improves performance and, along with Reflex, reduces latency, but only in supported titles. Though you could argue that’s better than what the competition are doing right now by turning unplayable frame rates at 4K with ray tracing into something smooth and responsive, all while maintaining lower latency than native rendering.\n\n>Now, the big problem is that MSRP pricing never lasts, and NVIDIA’s recent track record with the 5080 and 5090 tells us that the 5070 Ti is unlikely to be found at £749 for long, if at all. We’ve already seen retailers listing it at £899, which puts it in a very different competitive position. If it lands closer to £899–£999, suddenly the 4080 series and AMD’s 9000 series cards become much more attractive alternatives. But even then, I, like many others, am frustrated. It seems long gone are the days where a 70 Ti class would cost you £599 like the 3070 Ti, and you’d get it for that price. That really is the frustrating part, as the 5070 Ti is a great GPU. It has strong generational performance if you’re willing to skip a generation, excellent ray tracing, if you’re willing to skip a generation, and better upscaling capabilities, but if NVIDIA adds DLSS 4 to the 40 series, then again, if you skip a generation.\n\n>Overall, its value depends entirely on real-world pricing. If it stays close to MSRP, it’s a good, solid upgrade for those moving from the 3070 Ti or even a 4070 Ti user looking for extra power without stepping into flagship pricing and wanting to harness the latest tech. But if inflated pricing and scalping take hold, it loses its edge, making it a tougher sell in an already crowded GPU market. And with AMD’s 9000 series on the horizon, NVIDIA and their partners, through both AIBs and retail, may need to do some rethinking.\n\n>For now, the RTX 5070 Ti delivers on its promise of being a strong next-gen option, and if you can get it at MSRP, it’s a solid buy. But as we’ve seen before, that’s a big “if”, and it’s something we’ll be watching closely in the coming weeks. Let me know what you think in the comments section below. Will you be upgrading from the 30 series? Are you already on a 40 series GPU and are looking to upgrade, but now maybe don’t see the point? Your feedback would be good to see.\n\n# [Guru3D](https://www.guru3d.com/review/msi-geforce-rtx-5070-ti-16g-ventus-3x-oc-review/)\n\n>The GeForce RTX 5070 Ti arrives as the third release in NVIDIA’s RTX 5000 series, highlighting a blend of raw raster horsepower and AI-augmented features like DLSS4 and Multi Frame Generation (MFG). Many gamers stay cautious about these AI-driven additions, preferring straightforward rasterization for a more accurate picture. This scepticism is understandable since the older RTX 4000 series, already equipped with DLSS 3.5, delivers solid frame rates and remains competitive. As NVIDIA moves deeper into the mid-range of the 5000 lineup, the performance gap compared to the previous generation narrows, making some wonder if an upgrade is worthwhile if they mainly value traditional rendering. NVIDIA continues to emphasize AI acceleration, a trend we mentioned with the RTX 5090 release. While this approach feels visionary, a sizeable portion of the gaming community believes it’s advancing faster than the market can fully embrace. Still, the RTX 5000 cards offer notable gains in Ray Tracing and the new Neural Shading feature, both of which boost lighting realism and render scenes at higher resolutions. In games like Cyberpunk 2077 and Alan Wake 2, Ray Tracing combined with DLSS4/MFG can drive frame rates to impressive levels. However, that performance can demand a lot of power and efficient cooling. Like its siblings, the RTX 5070 Ti needs a robust power supply and good case airflow. There’s also potential for manual tuning and overclocking, which might add around five percent more performance—though silicon quality and thermals can limit those gains. In raw power terms, the RTX 5070 Ti brings a modest boost alongside higher energy demands and a heftier price tag. For players who simply want traditional frame rates without AI enhancements, it might not feel like a huge leap over a premium 4000 series card. On the horizon, AMD has something new planned as well, leaving many to wonder how that will stack up. For now, the 4000 series remains a solid option, especially with DLSS 3.5 in its corner. NVIDIA’s challenge lies in convincing enthusiasts that AI-boosted frames don’t sacrifice image quality or add unwanted latency. MSI steps in with its Ventus version of the RTX 5070 Ti, featuring a reinforced support bracket for added stability and a 12V-2×6 adapter cable for power. The Ventus 3X cooler generally keeps noise(reasonably) in check, though actual temperatures vary per build. These partner cards rarely stray far from reference specs but can draw attention from buyers who prefer a specific brand or design. As for the rumored 749-dollar price tag, it’s unclear if that will hold once it hits store shelves, but MSI seems to have delivered a solid offering at that MSRP. In the end, upgrading from a 4070 Ti may not be necessary for most users. Those moving up from the RTX 3000 series or older, however, might find enough reasons to make the jump\n\n# [Hot Hardware](https://hothardware.com/reviews/asus-geforce-rtx-5070-ti-prime-review)\n\n>At this point, we suspect all of your understand NVIDIA’s M.O. with the GeForce RTX 50 series. Traditional rasterization performance was increased over the previous generation, but not to the same extent as past releases. The GeForce RTX 4070 Ti leapfrogged the RTX 3070 Ti with traditional raster, whereas the GeForce RTX 5070 Ti is about +/-30% faster than [the RTX 4070 Ti](https://hothardware.com/reviews/asus-geforce-rtx-4070-ti-super-review). When its new RTX Neural Rendering features and DLSS 4 multi-frame gen are employed, however, the GeForce RTX 5070 Ti can put up much higher framerates than any previous-gen card – look to our Cyberpunk 2077 benchmarks to see the upside performance that's on tap. Whether you count those generated frames as additional performance is up for debate for some of you, but that fact is, every GPU manufacturer is reaching a point of diminishing returns with traditional rasterization within the limitations of current manufacturing processes, so using [AI to generate frames](https://hothardware.com/news/cyberpunk-2077-multi-frame-gen-and-ton-of-fixes) has a much more significant impact on the smoothness of on-screen animation. This topic merits a deeper discussion on its own, and is something all gamers and enthusiasts should ponder\n\n>That said, the GeForce RTX 5070 Ti is an upgrade over the previous generation nonetheless. It’s faster across the board in our game tests and AI and creator workloads perform better on it as well. If you’ve got an RTX 40 series card, however, the significance of that upgrade is probably not motivation enough to take the leap. If you’ve got a mainstream RTX 30-series card, however, it’s a different story. The GeForce RTX 5070 Ti is a monster upgrade over the RTX 3070 Ti, not only for its updated GPU architecture but also for its 16GB GDDR7 frame buffer.\n\n>At an MSRP of $749, the GeForce RTX 5070 Ti arrives at a $150 higher MSRP than [the RTX 3070 Ti](https://hothardware.com/reviews/nvidia-geforce-rtx-3070-ti-review-and-benchmarks), but $50 lower than the RTX 4070 Ti. If you’ve got an older GPU and are contemplating an upgrade, but don’t have a G or more to spend, the GeForce RTX 5070 Ti is worth a look. It’s got a bleeding-edge feature set, it's likely highly tweakable for overclocking, and DLSS 4 with multi-frame gen will only get more pervasive over time. There are some other new GPUs on the horizon though, [from both AMD](https://hothardware.com/news/amd-radeon-rx-9070-launch-event-howto-watch-what-expect) and NVIDIA, so perhaps sit tight for a bit to better understand the entire consumer graphics card landscape before parting with your hard-earned cash.\n\n# [Igor's Lab](https://www.igorslab.de/en/msi-geforce-rtx-5070-ti-ventus-as-msrp-card-in-test-interesting-chip-for-gamers-but-ventus-comes-from-ventilator/)\n\n>The RTX 5070 Ti offers strong performance in current AAA titles and is particularly optimized for 1440p gaming, while still achieving smooth frame rates in 4K with appropriate detail levels. Without ray tracing, it is around 12% ahead of the RTX 4070 Ti Super in WQHD and offers sufficient reserves for memory-intensive titles thanks to the high memory bandwidth of 896 GB/s. In Full HD, however, the CPU is often limited, which puts the performance advantages over the previous generation into perspective.\n\n>With active ray tracing, the demands on the GPU increase considerably. In native resolution without DLSS, the frame rates in demanding games sometimes fall below the 60 FPS mark. However, DLSS 3 and especially DLSS 4 with multi-frame generation (MFG) noticeably improve performance. The latter not only provides additional frames, but also optimizes frame pacing, resulting in more harmonious image reproduction. The efficiency of the tensor cores, which achieve almost native picture quality thanks to improved ray reconstruction technologies, is particularly evident in combination with patch tracing.\n\n>The MSI RTX 5070 Ti Ventus delivers solid performance in classic raster graphics scenarios and is ideal for WQHD gaming. Higher detail levels are possible in 4K, but not always at a stable 60 FPS, which is why upscaling technologies are often required. Compared to the RTX 4070 Ti Super with a nice factory OC, there is an average increase in performance of around 12% (around 16% better than a MSRP card), with CPU limitations in lower resolutions partially reducing the difference.\n\n>With ray tracing enabled, the MSI RTX 5070 Ti Ventus shows its strengths in combination with DLSS 4. The new multi-frame generation and ray reconstruction in particular enable playable frame rates, even in patch tracing scenarios, without any significant loss of quality. Compared to the previous generation, there is a significant leap forward here, especially in 4K with AI optimizations activated. The Ventus cooler represents a compromise between cost and performance. While temperatures are well controlled, the noise level under load is higher than that of high-end models. Overall, the MSI RTX 5070 Ti Ventus as an MSRP card remains an attractive choice for users who are looking for a powerful mid-range GPU with modern technology, but can live with small compromises in terms of cooling performance and noise.\n\n# [KitGuru Article](https://www.kitguru.net/components/graphic-cards/dominic-moass/msi-rtx-5070-ti-ventus-3x-oc-review/)\n\n# [KitGuru Video](https://www.youtube.com/watch?v=BnHaarxf7pg)\n\n>As the third RTX 50 series GPU to hit the market, today we have analysed **Nvidia's RTX 5070 Ti**. It's been fascinating to see what sort of performance is on offer at the claimed £729/$749 MSRP, given the [RTX 5080](https://www.kitguru.net/components/graphic-cards/dominic-moass/nvidia-rtx-5080-review-efficiency-gains-but-a-performance-letdown/) and [RTX 5090](https://www.kitguru.net/components/graphic-cards/dominic-moass/nvidia-rtx-5090-review-ray-tracing-dlss-4-and-raw-power-explored/) are eye-wateringly expensive.\n\n>Its price – and name, of course! – means the RTX 5070 Ti is positioned as the direct successor to the [RTX 4070 Ti Super](https://www.kitguru.net/components/graphic-cards/dominic-moass/nvidia-rtx-4070-ti-super-review-ft-msi/), and the performance gains follow a similar trend to what we saw when comparing the RTX 5080 to the RTX 4080 Super. In short, we're looking at a 12% average performance boost at 4K, while it's 5% slower than the RTX 4080 Super and 7% faster than AMD's RX 7900 XT.\n\n>The RTX 5070 Ti is certainly capable of 4K gaming, especially if you enable upscaling, but it wouldn't surprise me if most prospective buyers were planning on pairing it with a high refresh 1440p screen. At that resolution, the relative gains over the 4070 Ti Super do shrink to just 9% on average, while it's 6% slower than the 4080 Super, but still faster than the RX 7900 XT by 5%.\n\n>When enabling ray tracing, the RTX 5070 Ti out-performs AMD's current flagship, the RX 7900 XTX, delivering performance that's 32% better, an expected result given Nvidia's dominance in this area. Scaling is otherwise very similar when compared to Nvidia's own GPUs though, as the RTX 5070 Ti is still 12% faster than the 4070 Ti Super at 4K – the exact same margin observed in rasterisation performance.\n\n>Those sorts of performance gains gen-on-gen are hardly cause for wild celebration, but I do believe there's more reason to be positive about the RTX 5070 Ti than there was for the RTX 5080. For one, this new Blackwell GPU is 15% slower than its bigger brother, yet the MSRP is 25% lower, so that makes the RTX 5070 Ti the best value 50 series GPU yet.\n\n>Additionally, it gets a lot closer to the RTX 4080 Super than the RTX 5080 did to the 4090. It's still not *quite* there, being 5% slower on average, but the differences are even smaller in certain games – and the thought of circa-4080 Super performance for £729 doesn't sound too bad.\n\n>However, I was surprised to see a backwards step when it comes to efficiency. Nvidia officially rates the RTX 5070 Ti for 300W, though over my testing it averaged 283W at 4K. The RTX 5080 only drew 10W more on average however, and in fact I actually saw higher power draw from the 5070 Ti in certain games. I'd theorise that, as a cutdown GB203 die, RTX 5070 Ti could be lower quality silicon so it requires a more aggressive voltage/frequency curve, but it's hard to say for definite.\n\n>In any case, power draw being so close to the RTX 5080 while performing worse means that efficiency has regressed, with the 5070 Ti offering performance per Watt that's 13% lower. It's not the direction we would expect, as usually the lower-power GPUs are more efficient, so it'll be fascinating to see how the RTX 5070 (non-Ti) performs in this regard.\n\n# [LanOC](https://lanoc.org/review/video-cards/9143-asus-prime-rtx-5070-ti)\n\n>For performance, the Prime RTX 5070 Ti trades blows with the RTX 4080 and 4080 SUPER depending on the type of test. My averaged in game results had it out ahead just slightly. But as a whole DX 11 and Ray Tracing/DLSS results will have the Prime RTX 5070 Ti faster and in base DX12 tests it will fall behind the 4080. I would have liked to of seen this be at least consistently ahead of both of the RTX 4080 models. Overall that still does translate to being able to throw anything at it at 1440p and you can play at 4k in some situations. The Prime RTX 5070 Ti cooler was impressive in its noise tests, punching way above its weight class there. For cooling it did okay but Asus had an aggressive fan profile to do that, thankfully given the noise performance they could do that without it being too loud. Like with the other 50 Series cards, DLSS 4 performance was impressive and the changes Nvidia has made to DLSS have also improved the smoothness and picture when gaming with DLSS.\n\n>For pricing, as always pricing at launch is subject to change quickly. The launch MSRP of the RTX 5070 Ti and with the Prime RTX 5070 Ti tested is $749 so that is what I have to go by here. But we all know that cards at those price points are hard to come by and the more expensive overclocked cards will be what you will more often find assuming you can find them at all. We have just had tariffs that have changed GPU pricing across the board and with that I have updated our 3dMark Time Spy Extreme score per dollar chart that is above. At the MSRP the Prime RTX 5070 Ti is about as good as you can get right now for anything targeting 1440p or 4k gaming. I know a lot of people will be looking at how the RTX 5070 Ti compares with the RTX 4080 and RTX 4080 SUPER and MSRP for MSRP the $749 MSRP is still much better than the $1199 for the original RTX 4080 and $999 of the RTX 4080 SUPER and frankly, both cards are even more expensive than that to get right now if you can find them at all. With that in mind, the Prime RTX 5070 Ti competing with those cards is an improvement at the $750 price point but depending on the price we see overclocked cards that can change quickly.\n\n# [PC World Article](https://www.pcworld.com/article/2612343/nvidia-geforce-rtx-5070-ti-review.html)\n\n# [PC World Video](https://www.youtube.com/watch?v=_v7KboWkdu0)\n\n>If you want a high-performance graphics card capable of flying through 1440p and 4K gaming, the GeForce RTX 5070 Ti is a no-brainer among currently available options. Gaming only gets better once you flip on Multi Frame Generation in 75 supported games and apps – the visual smoothness it provides is truly transformative, even if you’re coming from a 4080 Super already. Just ask Adam!\n\n>I wouldn’t recommend buying the RTX 5070 Ti if you’ve already got a comparable RTX 40-series card. But if you’re coming from the 30-series or prior, and willing to hold your nose over *how much more* graphics cards cost now – the [RTX 3070 Ti](https://www.pcworld.com/article/394671/nvidia-geforce-rtx-3070-ti-review.html) cost $600 and the [2070 Super cost $500](https://www.pcworld.com/article/397702/nvidia-geforce-rtx-2060-super-rtx-2070-super-review.html), before inflation – you’ll love the RTX 5070 Ti. The jump forward in raw performance alone is worth it, and then adding MFG on top (in dozens of supported titles) can make your games feel like a whole new experience.\n\n>With a roughly 25 percent leap in performance *plus* Multi Frame Gen, for $50 less than its predecessor, the RTX 5070 Ti offers a compelling all-around package – one that, unfortunately, the RTX 5080 didn’t quite nail. The GeForce RTX 5070 Ti is absolutely the enthusiast-grade graphics card I’d buy right now if I were shopping around… though you may want to see what AMD’s imminent Radeon RX 9070 XT offers when it hits the streets in early March.\n\n# [Techpowerup](https://www.techpowerup.com/review/msi-geforce-rtx-5070-ti-ventus-3x/)\n\n>At 4K resolution, with pure rasterization, without ray tracing or DLSS, we measured a 28% performance uplift over the RTX 4070 Ti, which is pretty good for a gen-over-gen improvement. While it's not as big as the RTX 5090, which is 36% faster than the RTX 4090, it's definitely better than the 15% that we got on RTX 5080 a few weeks ago. Just like with RTX 5090, NVIDIA achieves their \"twice the performance every second generation\" rule: the RTX 5070 Ti is twice as fast as the RTX 3070 Ti. This means the card matches performance of the RTX 4080 and RTX 4080 Super, and it's also beating AMD's Radeon RX 7900 XTX flagship by a wafer-thin margin. Impressive—NVIDIA's 3rd card in the lineup beats AMD's #1. And this is with pure rasterization—once you turn on ray tracing, the gap gets much bigger.\n\n>For this launch, NVIDIA provided us with the MSI RTX 5070 Ti Ventus OC, which, as the name reveals, is a factory overclocked card. This means that it has a small performance advantage—all the other comparison cards in our tests are clocked at reference. So, if you plan on buying a baseline card, subtract a percent or two from our performance numbers. Once cards appear in the market I will buy a pure base clock card, for comparisons in future reviews. There is no Founders Edition for the RTX 5070 Ti.\n\n>While RTX 5070 Ti is a very decent card for gaming at 4K, it's not a fire-and-forget solution. There are several titles that run at less than 60 FPS when maxed out (without RT and upscaling). I'd say RTX 5080 is a better choice for demanding 4K gaming, but considering the price differences, I think lowering details slightly or using upscaling / frame generation is a very reasonable approach. For 1440p, the RTX 5070 Ti is awesome, here it can achieve excellent frame rates and will be able to drive high-refresh-rate displays very well.\n\n>NVIDIA's MSRP for the RTX 5070 Ti Series is $750, which is very reasonable for the performance you're getting. Actually, this MSRP is $50 lower than the $800 price point that both the 4070 Ti and 4070 Ti Super launched at. There has been lots of controversy about fake MSRPs, and this has been going on for years now, so do expect higher prices in stores. The primary driver for this is supply and demand, if everybody wants a product, its supply won't be sufficient and prices will go up. For the RTX 5090 and RTX 5080 supply was very low, too, making the situation even worse. I've plotted various alternative price points in our price/performance charts, reaching up to $1100, which, according to some early postings might end up being a realistic price point. We'll know more tomorrow, when sales go up.\n\n>MSI's RTX 5070 Ti Ventus 3X is priced at the NVIDIA MSRP, which is nice (as long as it's true and there's supply). Since there is no Founders Edition this time, there really isn't a baseline to compare to. Today we also tested the Galax RTX 5070 Ti 1-Click OC, which is MSRP as well, but comes with a much better cooler and much better noise levels. Still, the Ventus is definitely not bad. It is able to deliver the full RTX 5070 Ti experience, just with a little bit higher noise levels out of the box. Considering that, I'm having serious doubts whether I would be willing to spend, +$200, +$300 or even more for any custom design—we've seen pricing like that on some RTX 5070 Ti cards! Maybe $50-70 for a better cooler that runs really quiet, but that's about it.\n\n>There really isn't any alternative to the 5070 Ti in this segment, and NVIDIA knows that, and they designed the card with that in mind. No reason to give you +50% of anything if there's no competing product. AMD's flagship, the Radeon RX 7900 XTX currently sells for $820, with less performance, especially in RT, higher power draw and no DLSS. The RTX 4080 and 4080 Super are priced at around $1000 these days—no reason to buy them unless they are heavily discounted and end up below 5070 Ti pricing. What else is there? RTX 4090? Super expensive because people buy them for AI. RTX 5080 and 5090? Sold out, scalped to several thousand dollars. Let's hope that supply of RTX 5070 Ti is better and gamers can actually get their hands on these new cards.\n\n>AMD is set to release the Radeon RX 9070 Series shortly, but it probably won't match the performance of the RTX 5070 Ti. Instead, it seems it will be more comparable to the RTX 5070, which is also expected to be released soon. While these new cards cannot rival the RTX 5070 Ti in terms of performance, they are likely to be priced more competitively due to increased competition in this market segment.\n\n# [The FPS Review](https://www.thefpsreview.com/2025/02/19/asus-prime-geforce-rtx-5070-ti-video-card-review/)\n\n>**In raster performance**: Alan Wake 2 11%, Black Myth Wukong 13%, Cyberpunk 2077 9%, Dying Light 2 16%, F1 24 3%, Horizon Forbidden West 7%, Indiana Jones and the Great Circle 6%, Kingdom Come Deliverance II 13%, Stalker 2 7%, Star Wars Outlaws 6%.\n\n>If we take an average of those percentages, then in raster the average uplift of the GeForce RTX 5070 Ti over the GeForce RTX 4070 Ti SUPER is **9%**. The highest peak was 16%, the lowest valley was 3%.\n\n>**In Ray Tracing performance**: Alan Wake 2 13%, Black Myth Wukong 14%, Cyberpunk 2077 11%, Dying Light 2 15%, F1 24 5%, Indiana Jones and the Great Circle 13%, Star Wars Outlaws 4%.\n\n>If we take an average of those percentages, then in Ray Tracing the average uplift of the GeForce RTX 5070 Ti over the GeForce RTX 4070 Ti SUPER is **11%**. The highest peak was 15%, the lowest valley was 4%.\n\n>We noticed a direct performance-to-power improvement from overclocking, meaning we got about a 9% performance increase from overclocking and about the same power increase. At 9% more performance, the ASUS PRIME GeForce RTX 5070 Ti was more competitive with the uplift over the GeForce RTX 4070 Ti SUPER.\n\n>The important part is the MSRP, this is a $749 MSRP video card, and you really want to stay within this range with the GeForce RTX 5070 Ti. If this card is available in stock, and at $749, it can provide a decent upgrade from generations of the GeForce RTX 30 series, and down the generations. If you currently have a GeForce RTX 40 series, it would only be an upgrade from a lower tier such as the RTX 4060. If you are in the market for a new GPU at the $749 price point, the [ASUS PRIME GeForce RTX 5070 Ti](https://www.asus.com/us/motherboards-components/graphics-cards/prime/prime-rtx5070ti-16g/) is a great option offering that just gives you that right balance of what you need out of a video card at this price range.\n\n# [Tomshardware](https://www.tomshardware.com/pc-components/gpus/nvidia-geforce-rtx-5070-ti-review-asus)\n\n>Nvidia's RTX 5070 Ti deserves plenty of accolades. It delivers solid high-end performance, taking over from where the 4070 Ti Super left off. It's not revolutionary, but at least it's (generally) faster and cuts the price by $50. There's still work to be done by Nvidia on the drivers, however, as there's really no good reason why the 4070 Ti Super and even the slower 4070 Ti should, at times, beat the new 5070 Ti.\n\n>While the more expensive RTX 5080 felt disappointing for only offering minor performance improvements over the existing 4080 / 4080 Super, and for sticking with 16GB of VRAM, the 5070 Ti can get away with 16GB by virtue of costing $749. It's only about 10–15 percent faster than its immediate predecessor, but it's also 20–30 percent faster than its direct namesake. And it has some extra stuff that the prior generation lacks.\n\n>Part of the difficulty with Nvidia's latest GPUs is that the names have shifted upward. The xx70-class GPUs at one point cost around $300–$400. Then they became $599 and even $799 parts. Now the 5070 Ti walks that back slightly with a $749 base MSRP. In a sense, it's actually carrying on from the $699 RTX 3080 and the $649 GTX 1080 Ti. Sure, the number has changed, but Nvidia has been trying to stretch the range of GPUs to much higher price segments and has changed the nomenclature as it sees fit.\n\n>The RTX 5070 Ti strikes a good balance between performance, features, and value. It's still an expensive high-end card, but it's certainly a better value than the RTX 5090 and RTX 5080. It's also not faster (most of the time) than the previous generation RTX 4080, at least not unless you want to factor in MFG — and perhaps you should.\n\n>Frame generation tends to be a polarizing topic, with Nvidia acting like it's the same as normally rendered frames. At the other extreme are the \"never framegen\" people who act like it has completely ruined every game that uses the technique. The reality falls somewhere in between.\n\n>MFG is not a bad option to have, is how we view it. On the right games, it can make them look and feel better. Sometimes, it breaks, and you need to tweak some other settings to get the desired result, but again, It's not bad to have options.\n\n>MFG is one more tool in Nvidia's bag of tricks, and it can be helpful in the right situations. It's just not universally better in all situations. It also tends to work and feel better when the baseline performance is sufficiently high. If the final performance is only 100 FPS, meaning a 25 FPS input sampling rate with MFG 4X, that might feel worse than the native 40 FPS to some people.\n\n>So, who is Nvidia targeting with the RTX 5070 Ti? People with an RTX 3070 to 3080 (or lower) GPU who want to upgrade will find plenty to like. It will be about 50% faster in raw performance, and the new features can make it feel like more of a step up than that. At least there are no glaring flaws with the product other than concerns with availability and the possibility of scalpers spoiling the party. But if you already have an RTX 40-series GPU, you should give this generation a pass until something truly compelling comes out.\n\n>We also need to see what actual pricing and availability look like. At $749, the RTX 5070 Ti represents a reasonable high-end graphics card worth purchasing. If the price climbs to $899 or more, however, it becomes far less compelling. We’ve heard there will be more 5070 Ti cards at launch than all the 5090 and 5080 cards that have been sold so far, combined. But there are no concrete numbers, and Nvidia has a tradition of selling out on just about every new GPU generation. The 5070 Ti will likely keep that trend going for at least the first few weeks of its existence.\n\n# [Computerbase - German](https://www.computerbase.de/artikel/grafikkarten/nvidia-geforce-rtx-5070-ti-test.91379/)\n\n# [HardwareLuxx - German](https://www.hardwareluxx.de/index.php/artikel/hardware/grafikkarten/65525-auf-niveau-der-geforce-rtx-4080-die-geforce-rtx-5070-ti-im-test.html)\n\n# [PCGH - German](https://www.pcgameshardware.de/Geforce-RTX-5070-Ti-Grafikkarte-281031/Tests/Release-Preis-Test-Benchmarks-vs-5080-1466041/)\n\n# [Elchapuzasinformatico - Spanish](https://elchapuzasinformatico.com/2025/02/msi-geforce-rtx-5070-ti-ventus-3x-review/)\n\n\\--------------------------------------------\n\n# Video Review\n\n# [Der8auer](https://www.youtube.com/watch?v=0bKu3O57OJM)\n\n# [Digital Foundry Video](https://www.youtube.com/watch?v=NlWmYg7Vr3Q)\n\n# [eTeknix Video](https://www.youtube.com/watch?v=I2dqGTJ_Hj4)\n\n# [Gamers Nexus Video](https://www.youtube.com/watch?v=PhtVic3Vm0Y)\n\n# Hardware Canucks\n\n# [Hardware Unboxed](https://www.youtube.com/watch?v=UMPK1SeMEZM)\n\n# [JayzTwoCents](https://www.youtube.com/watch?v=zhSA5LYA8XU)\n\n# [KitGuru Video](https://www.youtube.com/watch?v=BnHaarxf7pg)\n\n# [Level1Techs](https://www.youtube.com/watch?v=Gf6_Jjvik34)\n\n# [Linus Tech Tips](https://www.youtube.com/watch?v=NnhU2ZvHb10)\n\n# OC3D Video\n\n# [Optimum Tech](https://www.youtube.com/watch?v=tVK2FBWcnEo)\n\n# [PC World Video](https://www.youtube.com/watch?v=_v7KboWkdu0)\n\n# [Techtesters](https://www.youtube.com/watch?v=9GSCc98ZxmA)\n\n# [Tech Yes City](https://www.youtube.com/watch?v=C0bdO2SLA6c)",
    "comments": [
      "A 70 level card that doesn't even beat previous 80 card. WTF.",
      "TLDR: Good-ish card. 4080/4080 super level of performance. Worth at $750 but bad value at the current price most are being listed on so either try your luck with an msrp listing or wait till things calm down",
      "5070ti has 16gb of vram, the same as a 4080",
      "\"things calm down\" sir its been years",
      "I mean the 80 generation card barely beat the previous 80 card and sipped back an extra 40w to do it, what were you really expecting? \n\nThis whole gen smacks of 'we made a ton of new datacenter AI chips and tried to shoehorn them into rasterization to appease the peasant gamers - this is the best we got from cranking up the TDP and slapping more AI bullshit on'.",
      "\"an RTX 4080 becomes a better buy due its higher vram capacity\"\n\nWhat does this mean?",
      "Yes, thats the 5070, but this is about 5070 ti, which also has 16",
      "I might try for one.\n\nIf I can get one for $800, I will go for it, anything more and I will skip this generation.",
      "Are you implying they're being negative just to gain views?  Maybe it's because emotion is expressed better in video?  Read these reviews again.  While on the performance side it remains positive, on the price side, they all share the same sentiment.",
      "Objectively it's not great.",
      "50 series generation:\n\nBarely, if any upgrades in preformance...\n\n5090s are rarer the platinum, in addition to being basically a terse upgrade mostly helped by Vram\n\n5080s are the worst value card nvidia ever produced, and the first 80 series card to fail in comparison to the previous gen 4090s.\n\n5070s are (barely) okay, but hilariously overpriced.\n\nFake Frames\n\nBurning Cables\n\nAI NONSENSE\n\nPC gaming is dead",
      "Finding a lot of 4090s at $1599 are we? Because I haven't seen shit in over 2 years",
      "It's okay but it could be better I agree. I'd want high vram like this starting at $300. Once you hit $600+ I would probably want more yeah.",
      "> I wonder why video-reviewers would dislike the card more than written-word-reviewers.\n\nI mean I think Jay expressed it best : he knows most people don't even listen to them at this point and this launch proves it.\n\nMust be frustrating no one really cares about their hardest content to make vs say a case review where people will actually pay more attention to what the reviewer is describing.\n\nFor GPUs, people have always wanted the charts.  We don't need the editorial about your feelings.",
      "https://preview.redd.it/3439ehmqv5ke1.png?width=273&format=png&auto=webp&s=35bafc8a489ea54ba042a753d106b25851930622",
      "sir 4000 series was easily available at MSRP. But ofc people in this sub dont have the mental capacity ro realize that",
      "The weird obsession with decade old numbering system is... Called market expectation? You're rattling off numbers in such random order, make a table if you want to discuss that. I'm unable to do so on mobile. Let's hone in on 70 series.\n\n\n* 970 was 329 in 2014\n* 1070 was 379 in 2016\n* 2070 was 499 in 2018\n* 3070 was 499 in 2020\n* 4070 was 599 in in 2023\n* 5070 is 550 in 2025\n\n\nThey literally almost doubled since 2014 and were forced to retract the price back down to 550 because of how poorly the market received the 4000 series. All 4000 series cards ended up doing this. The goal posts are moving. Do not fall for it. \n\n\nOn top of that the MSRP is fake if you can't find a card at that price. If the 5070 is 10% behind the 5070 Ti you will absolutely see it at $850 despite it's MSRP of 550. If all it does is scale with the current MSRP gouging then we are looking at around 700 for the card. That would be more than double since the 970, and around 40% more than the price of a 70 series 6 years ago. Not 10%. And 10% over 6 years ago is misleading when you actually look at the trend. The 3000 series is when Nvidia started shifting the goal posts for the 70 series.",
      "Nice cherry picking only going back 11 years and 5 generations? No, as I stated I am on mobile and you are making me do all of the work to have this conversation. What would be cherry picking is if I pointed out that until the 3000 series aib partners often launched *even cheaper* versions of the card, while modern practice is that it is very rare for aibs to even match msrp. But sure let's keep going back.\n\n\n* 275 was 259 in 2009\n* 470 was 349 in 2010\n* 570 was 349 in 2010\n* 670 was 399 in 2012\n* 770 was 399 in 2013\n\n\nSo actually we have stronger data about how the price is trending up over time, and example data showing Nvidia overvaluing their 70 series on the past and course correcting with the 970 (albeit, with a major lawsuit involved for fake cram). \n\n\nSo adjusted for inflation, and cherry picking in your favor, the 470 would be $510.89 in today's dollars. That's a 7.8% price increase assuming a 5070 MSRP. There's also the increase in taxes that I'll ignore because I'm lazy and it varies anyways.\n\n\nBased on current data for 5000 series we can easily expect a 25 to 35% increase from MSRP, putting the card at about $715, which puts it at 40% over the inflation adjusted 470 msrp, which is exactly what I calculated before on a 970 (albeit without inflation adjustment).\n\n\nI haven't even touched on their scale in gross profitability since 2010. In 2010 they made $1.17 billion, $1.7 billion adjusted for inflation. Now in 2024 they reported $44.3 billion, but I'll be nice and use 2022 instead at at $17.475 billion inflation adjusted to $18.74 billion. \n\n\nSo depending on which side we get to cherry pick from the company has seen an increase of 11-26x gross profitability while raising the price of the 70 series price 8 to 40%. \n\n\nSo take your pick, I guess.",
      "It’s only getting worse, 10k$ for a 6090 wouldn’t surprise me at this point.",
      "> Alternatively you can also make clickbait titles and thumbnail and say it's the worst GPU ever.  \n\nWhich review did that?"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "rtx 4060",
      "4060",
      "rtx 4060 ti",
      "4060 ti"
    ],
    "title": "GeForce RTX 4060 Ti Review Megathread",
    "selftext": "# GeForce RTX 4060 Ti Founders Edition (and MSRP AIB) reviews are up.\n\n[GeForce RTX 4060 Ti Founders Edition](https://preview.redd.it/5iopxqeb9l1b1.png?width=6000&format=png&auto=webp&s=bdb071a1aaf274bc9c54f90c6d5301f4c68b62a5)\n\n# Below is the compilation of all the reviews that have been posted so far. I will be updating this continuously throughout the day with the conclusion of each publications and any new review links. This will be sorted alphabetically.\n\n# Written Articles\n\n# [Babeltechreviews](https://babeltechreviews.com/the-399-rtx-4060-ti-8gb-review-a-decent-buy-for-1080p/)\n\n>The RTX 4060 Ti is compact and amazingly efficient compared to the RTX 30 series and its 40 series brothers. The idle fan stop is huge for us, and support for AV1 encoding is stellar for a lot of streamers at this price.  \n>  \n>Not everyone cares about DLSS and its effect on an image. For this, he RTX 4060 Ti performed above the RTX 3060 Ti in most cases but barely at around 10% faster at 1080p. It was also well above the RTX 2060 but loses in almost every game to the RTX 3070 at 1440p.  \n>  \n>However, the RTX 4060 Ti user base will see enough significant performance gains on 20 and 10 series cards to be able to make this a worthwhile consideration.  \n>  \n>For a hundred dollars more you could buy an RTX 4060 Ti 16GB when it releases or a current AMD offering – for now but the rumor mill is swirling with a pending release. This would have been a slam dunk if there was no 8gb version and instead we had a $300-400 RTX 4060 Ti at launch. The lineup of cards would have been perfect and much more appealing to nearly every gamer.  \n>  \n>We do implore you to look at our upcoming DLSS 3 comparison of the current generation. This technology is finally allowing Nvidia to realize the dream that has been ray tracing. We can now maintain great performance while having the full suite of RTX features on an mid-level card. Safe to say, we give the RTX 4060 Ti a wait and see recommendation. The RTX 4060 Ti 16gb and normal RTX 4060 in July should be interesting to compare!\n\n# [Dexterto](https://www.dexerto.com/tech/nvidia-rtx-4060-ti-8gb-founders-edition-review-2152821/)\n\n>The RTX 4060 Ti 8Gb is a GPU built on compromise. It does offer good performance in many titles, and can even perform at 1440p. For $399, your money extends further thanks to the DLSS 3 technology and other goodies like AV1 encoding. However, you have to know exactly what kind of resolution you are targeting ahead of time. Things like the smaller bus width, 8GB of VRAM, and small generational uplift are disappointing. DLSS 3 does go some way to smooth those issues over, but it’s not the be-all-end-all for graphics cards.\n\n# Digital Foundry Article\n\n# Digital Foundry Video\n\n>TBD\n\n# [Guru3D](https://www.guru3d.com/articles-pages/geforce-rtx-4060-ti-8gb-(fe)-review,1.html)\n\n>Despite its high pricing, this card has commendable capabilities in the Full HD space. The 32L2 cache ensures that performance metrics are fully adequate for this specific monitor resolution. Nevertheless, NVIDIA appears to be increasingly reliant on technologies like DLSS3 and Frame generation. It's prudent to maintain some vigilance here as the pendulum seems to be swinging rather heavily towards AI solutions for enhancing performance. Regarding the shader rasterizer engine aspect, this card merely meets expectations. NVIDIA sets the card's price at $399, a price point previously seen with the 3060 Ti. However, this is a reflection of the cryptocurrency mining era where prices soared due to artificial inflation, and for some reason, they remain high. Despite this, the card's overall performance for Full HD resolution is satisfactory and with the aid of DLSS assist, it even excels. A simple manual tweak allows users to gain an additional 5% performance from the card. This more competitively priced graphics card is becoming accessible to a broader base of end-users. While NVIDIA strongly advertises the DLSS technology as a revolutionary tool, we hope they won't neglect the significance of raw rasterizer shader performance in their future offerings. Performance may vary in situations less dependent on the CPU, potentially being slower in DX11 yet quicker in DX12. When compared to the Radeon Series 600/7000, the RTX 4000 exhibits superior ray tracing performance, indicating noteworthy progress in this domain. Furthermore, the DLSS3 + Frame generation technology enables the GPU to achieve exceptional outcomes in compatible games  \n>  \n>As an objective assessment, the RTX 4060 Ti 8GB exhibits very respectable performance, especially within a Full HD and even 2560x1440 mindset. Its shader engine performance is satisfactory, and the addition of DLSS3 and frame generation aid substantially improves its functionality. NVIDIA continues to lead in raw Raytracing performance. This graphics card's 32MB L3 cache is particularly effective at this resolution, though cache misses can result in the system resorting to a narrower 128-bit wide bus with only 8GB of graphics memory. However, at QHD and UHD you're bound to run into memory limitations, also keep in mind that DLSS frame generation will consume VRAM when used. While this could potentially cause issues, the card seems to handle such scenarios well. The RTX 4060 Ti 8GB graphics card boasts enough performance, solid build quality, and appealing aesthetics. However, its pricing is a notable drawback. With a price tag of $399, it is considered far too expensive for a mainstream product. Considering the decline of the mining trend, many would expect a lower price point, ideally below $300, $250 even. But the regular 4060 will take that spot, we raise serious concerns as to what is happening with the graphics card market. Nevertheless, the RTX 4060 Ti series remains an attractive option for PC gamers. It delivers ample performance, particularly for QHD gaming when utilizing DLSS3 and Frame generation features. Additionally, it offers a mild overclocking capability. The founders edition showcases an appealing design, efficient cooling, and pleasant acoustics. Overall, it demonstrates commendable energy efficiency. Despite its strengths, the card's starting price of MSRP $399 is a deterrent for many potential buyers. The RTX 4060 Ti, positioned as a notable progression for users with significantly dated graphics cards, holds potential as an initial RTX choice for numerous gaming enthusiasts. While it is still a (barely) recommended choice for mainstream PC gamers coming from the GTX series, the disappointing price tag should be taken into consideration as a serious objection. \n\n# [Hot Hardware](https://hothardware.com/reviews/nvidia-geforce-rtx-4060-ti-gpu-review)\n\n>The MSRP for new GeForce RTX 4060 Ti 8GB cards starts at $399, which is on-par with the RTX 3060 Ti's launch price (and the 2060 Super's). In this price band, the GeForce RTX 4060 Ti is a clear winner. It's slightly more expensive than the typical Radeon RX 6700 XT, but offers significantly more performance. The GeForce RTX 4060 Ti is much lower priced than the average GeForce RTX 3070 Ti, however, despite competing pretty well with that card.  The 8GB of memory on this first GeForce RTX 4060 Ti will be off-putting for some gamers, but turning down some detail has always been a requirement for mainstream GPUs. And if that 8GB frame buffer is a deal breaker for you, the GeForce RTX 4060 Ti 16GB will be available in July for $100 more.  \n>  \n>All told, the GeForce RTX 4060 Ti isn't going to be a particularly exciting upgrade for anyone with an RTX 3070 or better, but if you're still rocking that GeForce GTX 1060 or an RTX 2060-series card, the GeForce RTX 4060 Ti will be a massive upgrade, not only in terms of performance but in power efficiency and feature support. If you're considering a mainstream GPU upgrade and have 400 bucks budgeted, the GeForce RTX 4060 Ti would be a fine choice. If, however, you can save up some additional coin, the [GeForce RTX 4070](https://hothardware.com/reviews/nvidia-geforce-rtx-4070-ti-review-with-asus) is a big step up in performance if you, can swing it.\n\n# [Igor's Lab](https://www.igorslab.de/en/nvidia-geforce-rtx-4060-ti-founders-edition-8-gb-review-with-160-and-175-watt-power-limit-plus-oc/)\n\n>Of course, an assessment is always subjective and the price will certainly have to play a role. But to put it emotionless: You almost get the gaming performance of a GeForce RTX 3070 with 75 watts less power consumption. The GeForce RTX 4060 Ti, which costs 439 Euros (RRP), also just undercuts the RTX 3070 with a current street price of 450 Euros. Whereas the RTX 3070 had an MSRP of 499 Euros at that time.  \n>  \n>The GeForce RTX 4060 Ti is at least 9 percentage points faster than the RTX 3060 Ti 12 GB and it needs 60 watts less than the predecessor. Which brings us to the demand that the cards should not only be faster, but also more efficient. This is exactly the case here. You save over 30 percent in electrical energy and are at least 9 percent above the performance of the old card, which had an RRP of 399 euro at the time, but currently costs at least 415 euro. Thus, inflation also has an impact. However, this makes the old card completely obsolete. And there is somehow a monetary standstill.  \n>  \n>The GeForce RTX 4060 Ti with the AD104-351 is a cleverly placed card in the lower mid-range that doesn’t have to fear any direct rivals from AMD in this generation, which is unfortunately also noticeable in the price. In terms of efficiency, NVIDIA once again sets standards that AMD really has to be measured against. If and when the RX 7700 series will come and if we will see 16 GB or 12 GB memory expansion again, that is still up in the stars. But gamers live in the here and now and there are simply no alternatives at the moment if you want the complete feature set including high-quality super sampling and AI. Because the Radeon RX 7600, which will be launched tomorrow, should be significantly slower (if the performance rumors are true)  \n>  \n>Except for the outdated Display Port connector and the meager 8 GB memory expansion, I hardly see any drawbacks that would speak against this card in the GeForce RTX 4060 Ti. Except for the price, but that is unfortunately exactly where the comparable offers are. Thus, the big miracle is once again missing. New costs almost as much as old and you have to look for the added value at the socket and can at least be happy about a bit more performance. That is something in today’s times, since the demands on sensations have already been reduced. The bottom line is that it fits and if the street prices come into play even more, it will even be considerably cheaper.\n\n# [KitGuru Article](https://www.kitguru.net/components/graphic-cards/dominic-moass/nvidia-rtx-4060-ti-review/)\n\n# [Kitguru Video](https://www.youtube.com/watch?v=R943CbDTq_s)\n\n>Just stopping to think on what this GPU is capable of gives me a tinge of regret. It's genuinely a technical marvel that Nvidia has been able to take the AD106 GPU, a die that's *less* than half the size of GA104, and yet it outperforms it while offering vastly improved efficiency. This could have been a fantastic entry-level GPU, as befitting its die size, but at £389, AD106 is in a different class entirely.  \n>  \n>At that price point, we may as well come out and say it – 8GB VRAM simply does not cut it anymore. We covered this topic extensively in our video review, but for this class of product, such a meagre frame buffer is an absolute dealbreaker in 2023. That's not to say 8GB VRAM is useless or won't run new titles, but the way the industry is going, 8GB GPUs really need to be considered entry-level in my opinion, RTX 3050-type products which target 1080p gaming at Medium or High settings. Not something that's almost £400 and in this performance tier.  \n>  \n>I also think it's important to distinguish between game benchmarks and the actual experience of playing a brand new title on day 1. Many reviewers, myself included, test more mature games that have finished their update cycle – this provides us with the stability we need when trying to benchmark dozens of GPUs, while also mitigating the potential of having to restart our testing due to a new patch that significantly changes our results. From that perspective, plenty of 8GB cards could still be considered viable, at least for 1080p max settings as indicated by the bulk of our benchmarks today.  \n>  \n>The real problem for 8GB cards has been well and truly exposed this year when trying to play a number of new titles on launch day. The Last of Us Part 1, Forspoken, Callisto Protocol, Hogwarts Legacy, Resident Evil 4 Remake… the list goes on. Poorly optimised ports or not, the fact remains there is a growing number of games where 8GB GPUs simply had a very rough time of things when trying to play at launch, and if this is happening *now* – what will things be like one, two, three years down the line?  \n>  \n>Unfortunately, I think this is a very straightforward review to conclude – I can't in good faith recommend the **Nvidia RTX 4060 Ti 8GB** at its current asking price of £389. It's barely an improvement over its predecessor in terms of raw performance, its narrower memory interface reduces performance at higher resolutions, and 8GB of VRAM is simply not enough. The RTX 4060 Ti needs a hefty price cut to have any chance of viability considering its limitations.\n\n# [LanOC](https://lanoc.org/review/video-cards/8738-nvidia-rtx-4060-ti-founders-edition)\n\n>As far as performance goes, the RTX 4060 Ti, when tested at 1080p which is where Nvidia is targeting, runs right with last generations RTX 3070 but from AMD the RX 6750 XT does have 5 FPS on it on average across our tests. The problem you will run into with the RTX 4060 Ti is that if you go beyond 1080p up to 1440p or 4k the performance in comparison to the 3070 or even the 3060 Ti drops. Ada has its huge L2 cache which takes a lot of load off of the memory bus and that works really well. But because of that they have gone down to a 128-bit memory bus which works great at 1080p but that and the 8GB of VRAM start to get to their limits at the highest resolutions. That isn’t to say that in our testing 1440p or 4k wasn’t playable, it was. But if you are looking longer term and considering upgrading to a higher resolution monitor before your next video card upgrade, there are going to be better options that will offer that flexibility better. That said 1080p is still the most popular resolution by a HUGE margin and that is going to still be the case for a very long time. The RTX 4060 Ti also adds in DLSS 3 capabilities which in our testing gives huge performance improvements in the games that support it. Even in older DLSS 2 games the 4060 Ti saw bigger improvements than last generation's cards. I was also surprised with the compute performance, I expected it to be similar to the RTX 3070 but in Blender and Passmark’s GPU Compute test, it was outperforming the RTX 3070 Ti and running close to the RX 6800 XT.  \n>  \n>In the end, the RTX 4060 Ti is in an interesting spot in the market. At its intended resolution it performs well. But like with the RTX 4070, AMD’s last generation of cards being marked down cause trouble when it comes to just per raster performance. DLSS 3 and its ray tracing capabilities help compete there. But once you get out past 1080p the performance drop brings this a little too close to the last generation 3060 Ti for me. That said for me, this might be the ideal card for my compact SFF LAN rigs. Its low power draw helps keep things cool and doesn’t require a giant card and I know for sure that I’m not going beyond 1080p for my LAN rig for a long time now because I don’t have any interest in dragging a larger monitor to events.\n\n# [OC3D Article](https://www.overclock3d.net/reviews/gpu_displays/nvidia_rtx_4060_ti_fe_and_gigabyte_eagle_review/1)\n\n# [OC3D Video](https://www.youtube.com/watch?v=etjw3cHZhuc)\n\n>So far all of the Nvidia 4000 series cards have proven to be an unqualified success. It doesn't matter which card you go for, you'll be getting the kind of performance, in every title, that will leave you grinning. We know that purchasing something as expensive as a graphics card is a mighty investment, and you never want to be left wondering exactly what your outlay has got you that you didn't have before. Until now it didn't matter what game you wanted to play, or what setup you had, you could grab one of the 4000 series and be pleased with your purchase.  \n>  \n>The RTX 4060 Ti is still good, but it's the kind of card that represents the tipping point where you have to have some qualifiers and caveat emptors that weren't there on the 4080 or similar. Price wise the RTX 4060 Ti comes in at around the same MSRP as the RTX 3060 Ti had at launch, and there is something of a performance increase just from raw hardware over that card, somewhere around the 8% mark. Not really enough to justify the outlay, particularly if funds are tight. Of course if you're running a RTX 2060 then you'll be blown away at how much faster the new card can run.  \n>  \n>Where the waters get cloudier, or at least where you need to pay closer attention, is exactly what you're planning to play on the RTX 4060 Ti. If it's a title that relies solely upon hardware horsepower, such as Horizon Zero Dawn, then you could come away from this latest Nvidia offering feeling a little disappointed. Certainly in comparison to the feelings we got once we'd finished with the RTX 4080 or even RTX 4070 Ti. But, and it's a big, world pie-eating champion sized but, if your title of choice supports DLSS 3 then the difference between the 4000 cards and the 3000 ones is stark.  \n>  \n>Now we know that it's difficult to say that the RTX 4060 Ti is a bad card as such, because it allows you to run those games which do support the newest Nvidia DLSS 3 and FrameGen technologies in all the buttery-smoothness you could hope to see. It's just that the list of DLSS 3 games isn't massive, and certainly there are some notable omissions, so if you're going to be just relying on the amount of oomph the card has just as it is, then you really need to pay close attention to the card you already own and how the RTX 4060 Ti compares.  \n>  \n>Clearly if you're looking to start your Gaming PC owning journey and want to do so without getting on your knees in front of your bank manager, then the RTX 4060 Ti is a great starting place. If you already own a recent-ish graphics card and have specific games in mind, then you need to look a little closer at the nitty-gritty of things, which is a first for the 4000 series of Nvidia cards which have, until now, been wholehearted recommendations. If you have got a PC already then the Gigabyte Eagle and its use of the PCIe 8 pin power input might be enough to tip the balance towards that rather than the new-fangled power connector on the Nvidia card. The RTX 4060 Ti is still good, though we're just reaching the point where Nvidia have trimmed the hardware to fit a price point so much it's not the quantum leap forwards that the other cards in the Ada Lovelace range have been when compared to extant cards.\n\n# [PC Perspective](https://pcper.com/2023/05/nvidia-geforce-rtx-4060-ti-founders-edition-review/)\n\n>Looking back only a few years, I think a card like the RTX 4060 Ti would meet expectations for a xx60 Ti card – which is to say that it effectively matches the performance of the previous-gen xx70 card, and adds current-gen features. But we live in the post-RTX 30 Series era now.  \n>  \n>While many actual gamers were left empty-handed during the dark times (f\\*\\*\\* Ethereum, anyway), the RTX 30 Series was a BIG upgrade over the RTX 20 Series, and *list* pricing was very good for the performance level.  \n>  \n>My favorite card last generation was the RTX 3060 Ti, and for its elusive MSRP of $399 it was the card I would have bought with my own money. Think about this: it was faster than the $699 (and up) RTX 2080, cruising past heavyweights such as GeForce GTX 1080 Ti and Radeon RX 5700 XT. And this begs the question, was the RTX 3060 Ti too good? It certainly set expectations for the next generation of GeForce cards **very** high.  \n>  \n>Seeing only modest raw performance gains over the previous generation xx60 Ti card here isn’t very exciting, but there are architectural improvements with the RTX 4060 Ti that stretch the lead to more impressive levels. I didn’t cover things like content creation, where this generation offers a better experience.  \n>  \n>This card wants you to use DLSS 3 + FG, and if you get it, use this. Regardless of what you’ve watched (or possibly even read) about DLSS 3 and Frame Generation, the tech does greatly increase the framerates and perceived smoothness of games, and in games that support the DLSS 3 + FG combination the RTX 4060 Ti crosses into enthusiast 2560×1440 territory – at least based on the FPS numbers I was seeing.  \n>  \n>Now, about that VRAM thing. 8GB is certainly a useful amount, but there have been multiple (and heavily-documented) examples of recent titles that want as much as they can get. I would love it if this card had 16GB, and while I could pontificate about public companies maintaining margins on products amidst rising component costs, the fact is that gamers don’t care about how well company X is doing. They all just want cheap GPUs with lots of VRAM, as far as I can tell.  \n>  \n>The fact that a 16GB version of the RTX 4060 Ti will be made available is definitely a good move, but it isn’t coming until July. I would have loved to see it launch alongside this card, but the additional $100 for the 16GB RTX 4060 Ti does push it into a different market segment. We will have to wait and see if AMD answers with something compelling, and creates some pricing pressure. I think we’d all love to see a price break on components for this increasingly expensive hobby.\n\n# [PC World](https://www.pcworld.com/article/1925928/nvidia-geforce-rtx-4060-ti-8gb-review.html)\n\n>It all depends on your answer to the question posed right up top: Are you willing to pay $400 for a 1080p graphics card with 8GB of memory in the year of our lord 2023?  \n>  \n>The GeForce RTX 4060 Ti delivers absolutely outstanding power efficiency, leading ray tracing performance, [modern AV1 encoding](https://www.pcworld.com/article/1375901/tested-nvidias-geforce-rtx-4090-is-a-content-creation-monster.html), and fast 1080p gaming for high refresh rate monitors, backed by Nvidia’s knockout software suite: [DLSS 3 Frame Generation](https://www.pcworld.com/article/1662185/what-is-dlss-3-nvidia-geforce-rtx-ai-feature-explained.html), [Nvidia Reflex](https://www.pcworld.com/article/393646/tested-how-nvidia-reflex-can-make-you-a-better-esports-gamer.html), [RTX Video Super Resolution](https://www.pcworld.com/article/1525299/nvidia-rtx-video-super-resolution-tested.html), and Nvidia Broadcast are just *some* of the killer features available to the RTX 4060 Ti, with DLSS 3 *only* being available on Nvidia’s newest GPU in this price segment. If you’re still on a GTX 1060 or RTX 2060, the RTX 4060 Ti will be a fantastic upgrade (albeit expensive).  \n>  \n>The RTX 4060 Ti is also a deeply uninspiring upgrade gen-on-gen when it comes to raw GPU horsepower, only besting the RTX 3060 Ti by 9 percent at 1080p resolution and 7 percent at 1440p. It has fewer CUDA, RT, and tensor cores than its predecessor, which is disappointing. It flat-out loses to the RTX 3070 at 1440p, which is even more disappointing.  \n>  \n>So: Are you willing to pay $400 for a 1080p graphics card with 8GB of memory in the year of our lord 2023? I’m not, especially with DLSS/FSR advantages minimized in this segment. (Given the RTX 4060 Ti’s overall performance, I don’t think the $500 16GB version will be very appealing when it launches in July either.)  \n>  \n>That said, I’d hold my horses if I could. Nvidia already teased a $299 RTX 4060 with DLSS 3, AV1, and extreme power efficiency for July. Plus, the [rumor mill is screaming](https://go.redirectingat.com/?id=111346X1569483&url=https://videocardz.com/newz/amd-radeon-rx-7600-gpu-specs-confirmed-navi-33-xl-with-2048-stream-processors-and-8gb-vram&xcust=2-1-1925928-1-0-0&sref=https://www.pcworld.com/article/1925928/nvidia-geforce-rtx-4060-ti-8gb-review.html) that AMD could launch a $300 Radeon RX 7600 any minute now. That price point is a lot more palatable for 1080p gaming on 8GB if you don’t need Nvidia’s deep feature set.  \n>  \n>The GeForce RTX 4060 Ti would have been more appealing if it offered 16GB of memory for $399 and ditched the 8GB option, or offered 8GB of memory with the same level of performance for $300 to $325. As it stands, Nvidia’s RTX 40-series upgrades remain uninspiring at best and this GPU sadly falls into a no-man’s land of sorts. Look elsewhere.\n\n# [TechGage](https://techgage.com/article/nvidia-geforce-rtx-4060-ti-creator-review/)\n\n>One thing to be clear about here is, the look we’ve taken at this RTX 4060 Ti so far has revolved entirely around creator. It may be that its gaming prowess is much more lucrative, and we do plan on investigating that more soon. A major selling-point of the RTX 4060 Ti is DLSS 3 + Frame Generation, and that’s one that doesn’t impact many on the creator side quite yet. Our experience with Frame Generation so far has been great, but as we called out in the intro, it’s best used when the baseline (+ DLSS) FPS is high enough that input latency won’t be a problem.  \n>  \n>When most folks seek out a new GPU, they want the satisfaction of knowing that it will last them long enough until a substantial architectural upgrade comes along. What’s frustrating, then, is knowing that your GPU is capable of more, if only it weren’t held back by its framebuffer.  \n>  \n>In this particular round of testing, we saw that the 8GB RTX 4060 Ti rendered Blender’s *Charge* project slower than the 12GB RTX 3060, but in scenarios where VRAM wasn’t an issue, it had the ability to inch ahead of the RTX 3070 Ti. We’ve seen in the past that even a simpler workload like Adobe Lightroom export can lead to the 12GB RTX 3060 outperforming technically superior (aside from VRAM) GPUs.  \n>  \n>We’re still trying to properly assess whether or not 8GB can be declared a real issue for most people in reality, because not everyone creates complex projects that actually uses so much memory. But if you *do* create complex projects, encode really high-resolution video – or just plan to in time – you’re going to want to do yourself a favor and opt for more memory if you can.  \n>  \n>We understand that GPUs are more expensive to produce than ever, but the RTX 4060 Ti feels more like a speed-bumped product than a proper upgrade, versus RTX 3060 Ti, and while Frame Generation is nice, it’s not going to matter if it doesn’t impact what you use a GPU for.  \n>  \n>Overall, the RTX 4060 Ti isn’t a bad GPU; we just feel like the only thing holding it back in creator workflows is the 8GB framebuffer. We feel like we’ve finally reached the point where 12GB feels like the new sweet spot for creator workloads.\n\n# [Techpowerup](https://www.techpowerup.com/review/nvidia-geforce-rtx-4060-ti-founders-edition/)\n\n>Averaged over the 25 games in our test suite, at 1080p resolution, the RTX 4060 Ti is able to match last-generation's RTX 3070 and the older RTX 2080 Ti. The gen-over-gen performance improvement is only 12%, which is much less than what we've seen on the higher-end GeForce 40 cards. Compared to AMD's offerings, the RTX 4060 Ti can beat the RX 6700 XT by 8%, even though that card has 12 GB VRAM. The Radeon RX 6600 XT, Red Team's \"x60\" offering, is even 37% behind. With these performance numbers, the RTX 4060 Ti can easily reach over 60 FPS in all but the most demanding games at 1080p with maximized settings. Actually, the RTX 4060 Ti will capably run many games at 1440p, too, especially if you're willing to lower a few settings here and there.  \n>  \n>As expected, ray tracing performance of RTX 4060 Ti is clearly better than its AMD counterparts. With RT enabled, the RTX 4060 Ti matches the Radeon RX 6800 XT, which is roughly two tiers above it. AMD's Radeon RX 6700 XT is a whopping 30% slower. Still, I'm not sure if ray tracing really matters in this segment. The technology comes with a big performance hit that I find difficult to justify, especially when you're already fighting to stay above 60 FPS in heated battles.  \n>  \n>GeForce RTX 4060 Ti comes with a 8 GB VRAM buffer—same as last generation's RTX 3060 Ti. There have been heated discussions claiming that 8 GB is already \"obsolete,\" I've even seen people say that about 12 GB. While it would be nice of course to have more VRAM on the RTX 4060 Ti, for the vast majority of games, especially at resolutions like 1080p, having more VRAM will make exactly zero difference. In our test suite not a single game shows any performance penalty for RTX 4060 Ti vs cards with more VRAM (at 1080p). New games like Resident Evil, Hogwarts Legacy, The Last of Us and Jedi Survivor do allocate a lot of VRAM, which doesn't mean all that data actually gets used. No doubt, you can find edge cases where 8 GB will not be enough, but for thousands of games it will be a complete non-issue, and I think it's not unreasonable for buyers in this price-sensitive segment to to set textures to High instead of Ultra, for two or three titles. If you still want more memory, then NVIDIA has you covered. The RTX 4060 Ti 16 GB launches in July and gives people a chance to put their money where their mouth is. I'm definitely looking forward to test the 16 GB version, but I doubt the performance differences can justify spending an extra $100.  \n>  \n>NVIDIA made big improvements to energy efficiency with their previous GeForce 40 cards, and the RTX 4060 Ti is no exception. With just 160 W, the power supply requirements are minimal, any beige OEM PSU will be able to drive the RTX 4060 Ti just fine, so upgraders can just plop in a new graphics card and they're good to go. Performance per Watt is among the best we've ever seen, similar to RTX 4070, slightly better than RTX 4070 Ti and Radeon RX 7900 XTX; only the RTX 4090 and RTX 4080 are even more energy-efficient.  \n>  \n>NVIDIA has set a base price of $400 for the RTX 4060 Ti 8 GB, which is definitely not cheap. While there is no price increase over the RTX 3060 Ti launch price, the performance improvement is only 12%, and the mining boom is over—these cards don't sell themselves anymore. To me it looks like NVIDIA is positioning their card at the highest price that will still allow them to sell something—similar to their strategy in the past. Given current market conditions, I would say that a price of $350 for the RTX 4060 Ti would be more reasonable. Still, such high pricing will drive more gamers away from the PC platform, to the various game consoles that are similarly priced and will give you a perfectly crafted first-class experience that works on your 4K TV, without any issues like shader compilation and other QA troubles. For GeForce 40 series, NVIDIA's force multiplier is DLSS 3, which offers a tremendous performance benefit in supported games. Features like AV1 video encode/decode and (lack of) DisplayPort 2.0 seem irrelevant in this segment, at least in my opinion. Strong competition comes from the AMD Radeon RX 6700 XT, which sells for $320, with only slightly less performance. That card also has a 12 GB framebuffer, but lacks DLSS 3 and has weaker ray tracing performance. I don't think I'd buy a $400 RTX 3070, or a $320 RTX 3060 Ti—I'd rather have DLSS 3. If you can find a great deal on a used card, maybe consider that. AMD is launching their Radeon RX 7600 soon, which goes after the same segment as the RTX 4060 Ti, if the rumors are to be believed, so things could get interesting very soon.\n\n# [The FPS Review](https://www.thefpsreview.com/2023/05/23/nvidia-geforce-rtx-4060-ti-founders-edition-video-card-review/)\n\n>If you are coming from an older GPU, such as a GTX-level video card, or a GeForce RTX 2060-level video card from 2019, the new GeForce RTX 4060 Ti is a good upgrade path for you. At $399 you are still shopping in the same price point you might have paid way back then, and will be getting a substantial upgrade in performance and features. If, however, you want to upgrade from a previous generation video card at this same price point, such as the GeForce RTX 3060 Ti, the new GeForce RTX 4060 Ti does not have enough meat on the bone at this price point.  \n>  \n>However, if you are coming from an equivalent video card from AMD in the last generation, such as the Radeon RX 6650 XT, then the GeForce RTX 4060 Ti offers a substantial upgrade. It will provide huge performance gains over the Radeon RX 6650 XT in pretty much everything. It will also provide playable and usable Ray Tracing image quality in games, something the Radeon RX 6650 XT could never deliver. It will also give you DLSS and DLSS 3 support, something that will be a big upgrade from any older GPU.  \n>  \n>Therefore, if you are rocking a GPU from AMD’s last generation, or several generations past on the NVIDIA side, then the GeForce RTX 4060 Ti could potentially be a good upgrade path for you. It just depends on what you have, where you want to go, and the price point you want to stay at.\n\n# [Tomshardware](https://www.tomshardware.com/reviews/nvidia-geforce-rtx-4060-ti-review)\n\n>Nvidia's RTX 40-series has been controversial for a variety of reasons, and the RTX 4060 Ti will continue that trend. It's not that this is a bad card, as the efficiency shows significant improvements over the previous generation. The price of entry, relative to the RTX 3060 Ti, also remains unchanged. The problem is that Nvidia's trimming of memory channels and capacity is very much felt here, and we can only look forward to similar concerns on the future RTX 4060 and RTX 4050.  \n>  \n>The performance ends up being a bit of a mix, with native rendering showing only relatively minor improvements compared to the prior RTX 3060 Ti. There are even some instances where the new card falls behind — specifically, any situation where the 8GB VRAM and reduced bandwidth come into play.  \n>  \n>Mainstream graphics cards are never the sexiest offerings around. In this case, we've had similar levels of performance from the RTX 3070 and 3070 Ti since late-2020 and mid-2021, respectively. Granted, those were both nearly impossible to find at anything approaching a reasonable price until mid-2022, so getting a replacement that's hopefully readily available will certainly attract some buyers. Just don't go upgrading from an RTX 3060 Ti, or you'll be very disappointed in the lack of tangible performance improvements.  \n>  \n>As we mentioned earlier, we'd feel a lot better about the RTX 4060 Ti if it had 12GB of memory and a 192-bit memory interface. Nvidia likely decided to go with a 128-bit bus and 8GB of VRAM around the time the RTX 30-series was shipping, but we still feel it wasn't the ideal choice. At least there will be a 16GB 4060 Ti in July, but the extra $100 puts you that much closer to getting an even better card like the RTX 4070. Or maybe AMD will have a new generation RX 7700/7800-series card priced at $500 or less by then.  \n>  \n>Anyone using a graphics card at least two generations old will find a bit more to like about the RTX 4060 Ti. It's not a huge boost in performance over the 3060 Ti, but it does come with some useful new extras, like AV1 encoding support. It's also a more compact card than a 3060 Ti, so it can fit in a smaller case, and it ran cool and quiet in our testing.  \n>  \n>The bottom line is that you could certainly do worse than an RTX 4060 Ti. You could also do a lot better, if by \"better\" you mean \"faster.\" Its just likely to cost you a whole lot extra to move up to the next faster Nvidia graphics card.\n\n# [Computerbase - German](https://www.computerbase.de/2023-05/nvidia-geforce-rtx-4060-ti-8gb-test/)\n\n# [HardwareLuxx - German](https://www.hardwareluxx.de/index.php/artikel/hardware/grafikkarten/61026-geforce-rtx-4060-ti-mit-8-gb-im-test.html)\n\n# [PCGH - German](https://www.pcgameshardware.de/Geforce-RTX-4060-Ti-8GB-Grafikkarte-279648/Tests/Release-Review-Benchmark-Specs-Preis-1419889/)\n\n# ----------------------------------------------\n\n# Video Review\n\n# [Der8auer](https://www.youtube.com/watch?v=SIugY8lDJhY&pp=ygUHZGVyOHVlcg%3D%3D)\n\n# Digital Foundry Video\n\n# [Gamers Nexus Video](https://www.youtube.com/watch?v=Y2b0MWGwK_U)\n\n# Hardware Canucks\n\n# [Hardware Unboxed](https://www.youtube.com/watch?v=WLk8xzePDg8)\n\n# [JayzTwoCents](https://www.youtube.com/watch?v=995Vu55tpfM)\n\n# [Kitguru Video](https://www.youtube.com/watch?v=R943CbDTq_s)\n\n# [Linus Tech Tips](https://www.youtube.com/watch?v=_B6vtMa-US4)\n\n# [OC3D Video](https://www.youtube.com/watch?v=etjw3cHZhuc)\n\n# Optimum Tech\n\n# Paul's Hardware\n\n# [Techtesters](https://www.youtube.com/watch?v=pfB-sZHumNo)\n\n# [Tech Yes City](https://www.youtube.com/watch?v=M1kQO1xseR4)\n\n# The Tech Chap",
    "comments": [
      "Waste of sand",
      "the reviewers who give the 4060 ti a good rating are out of their minds",
      "I see this as a good opportunity to weed out the dishonest outlets from my bookmarks.",
      "Jay pulled his video lol",
      "Unfortunately, it seems the 4060 Ti is a complete trash...\n\nI will wait once again for the next generation and hope the 5060 / 5060 Ti is a better deal than this one.",
      "Dishonest or incompetent, whatever the reason it's a good way to weed out the trash",
      "Silicone is a rubber-like substance, I don't think it's made from sand.\n\nSilicon sure is though!",
      "It's news to me that he has standards.  He took it down because of the incredibly negative response from reviewers that have credibility.\n\nLOL, this is a direct quote from his now-deleted video: \"Like Jay said at the unboxing, this card is doing great at 1440p.\"  He then goes on to praise NVIDIA's decision to use a 128-bit memory bus with the larger L2 cache.  The review concludes by stating that the 4060 Ti is an \"amazing card\" and has the \"potential to be the new GTX 1060.\"  The video honestly sounds like an advertisement NVIDIA paid them to produce.  Absolute trash.",
      "He's recovering from major surgery, didn't even host the video.",
      "Nvidia lost the budget market to AMD's previous generation of cards lmfao",
      "1080ti ganers, it is safe to upgrade to the RX 6700XT.",
      "This hurts his credibility since he can’t stand by his own opinion. Like can you really believe he didn’t read his data before recording a video?",
      "He said the 4060Ti is amazing value and will last you for years. Which is NOT true, considering it has only 8GB VRAM.",
      "I’ve seen you comment practically the same message over and over in this thread. It’s really weird to be a fanboy of a multibillion dollar company bruh. I promise you’re not getting a Christmas card from them",
      "Guru3d 's review is a perfect example of them being nvidia shills for quite some time now, the conclussions and performence charts from them were soo heavily in favour of nVidia while in reality its not that much of a difference between AMD and nVidia cards.... While GamersNexus basically mops the floor with nVidia... guru3d yet again provides userbenchmark levels of review.Thanks guru3d for reminding me why I stopped taking your reviews seriously",
      "I hate to use an overused meme, but the reviewers giving the 4060Ti positive reviews is huffing some serious industrial-grade copium.",
      "This feels like it should had been a 4050ti, but has double the price",
      "Practically every card this gen has been this way. The die size tells us everything.",
      "It is an entry level PCIE 4.0 8x card. A PCIE 3.0 motherboard will further reduce the performance by 5%, making it virtually identical to a 3060 ti at 1440p.",
      "a 4060ti is SUPPOSED to be faster than a 3060ti\n\nyou make it sound like that's a luxury"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "rtx 4060",
      "4060",
      "rtx 4060 ti",
      "4060ti",
      "4060 ti"
    ],
    "title": "nVidia GeForce RTX 5060 Ti Meta Review",
    "selftext": "- compilation of 16 launch reviews with ~6420 gaming benchmarks at 1080p, 1440p, 2160p\n- only benchmarks at real games compiled, not included any 3DMark & Unigine benchmarks\n- geometric mean in all cases\n- standard raster performance without ray-tracing and/or DLSS/FSR/XeSS\n- extra ray-tracing benchmarks (mostly without upscaler) after the standard raster benchmarks\n- stock performance on (usually) reference/FE boards, no overclocking\n- factory overclocked cards were normalized to reference clocks/performance, but just for the overall performance average (so the listings show the original performance result, just the performance index has been normalized)\n- missing results were extrapolated (for a more accurate average) based on the available & former results\n- performance average is (some) weighted in favor of reviews with more benchmarks\n- all reviews should have used newer drivers for _all_ cards\n- power draw numbers based on a couple of reviews, always for the graphics card only\n- performance/price ratio (higher is better) for 1440p raster performance and 1440p ray-tracing performance\n- for the full results and some more explanations check [3DCenter's launch analysis](https://www.3dcenter.org/artikel/launch-analyse-nvidia-geforce-rtx-5060-ti)\n\nNote: There are hardly any performance results available for the GeForce RTX 5060 Ti 8GB. Therefore, their performance was extrapolated for the overview table based solely on the difference between 4060Ti-8GB and 4060Ti-16GB, taking into account a small offset due to the different TDP (which does not exist for the 5060Ti).\n\nNote: Sometimes the following tables are become to big (wide) for mobile browsers on Reddit (last column is the GeForce RTX 5070). In this case, please try the [mobile version of 3DCenter](https://m.3dcenter.org/artikel/launch-analyse-nvidia-geforce-rtx-5060-ti/launch-analyse-nvidia-geforce-rtx-5060-ti-seite-2).\n\n&nbsp;\n\nRaster 1080p|76XT|67XT|77XT|78XT|9070|406Ti-8|400Ti-16|506Ti-16|4070|5070\n|:--|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|\n&nbsp;|RDNA3 16GB|RDNA2 12GB|RDNA3 12GB|RDNA3 16GB|RDNA4 16GB|Ada 8GB|Ada 16GB|Blackw. 16GB|Ada 12GB|Blackw 12GB\nComputerB|-|72.8%|89.0%|-|-|82.4%|-|_100%_|-|-\nCowcotl|77.8%|-|103.2%|119.0%|142.9%|85.7%|-|_100%_|115.9%|139.7%\nEurogamer|-|-|100.8%|114.4%|-|84.7%|85.1%|_100%_|-|134.2%\nGamersNex|-|75.0%|92.3%|107.9%|135.9%|83.8%|-|_100%_|108.8%|131.5%\nHW&Co|68.9%|74.7%|96.3%|-|139.1%|83.7%|85.1%|_100%_|112.2%|131.1%\nHWluxx|68.0%|-|91.4%|109.4%|133.3%|87.5%|-|_100%_|-|132.3%\nIgor's Lab|-|-|88.7%|105.5%|134.1%|-|85.1%|_100%_|-|119.2%\nKitGuru|69.4%|73.1%|93.6%|108.4%|139.9%|83.1%|86.8%|_100%_|115.6%|134.2%\nPCGH|72.2%|78.3%|-|-|143.1%|85.7%|87.7%|_100%_|114.5%|135.0%\nPurePC|-|-|93.3%|107.8%|141.1%|85.6%|86.7%|_100%_|110.0%|134.4%\nQuasarzone|-|-|98.5%|115.7%|-|88.6%|90.3%|_100%_|114.3%|135.2%\nSweClockers|-|-|95.6%|110.0%|144.4%|85.6%|-|_100%_|111.1%|132.2%\nTPU|71%|-|98%|114%|145%|88%|90%|_100%_|116%|134%\nTom's HW|69.2%|-|94.7%|107.9%|131.4%|86.0%|86.7%|_100%_|110.3%|127.4%\nTweakers|70.7%|-|97.0%|113.7%|137.5%|87.8%|-|_100%_|114.1%|129.4%\n**avg**|**~71%**|**~76%**|**96.1%**|**111.3%**|**138.0%**|**86.2%**|**87.1%**|**_100%_**|**112.3%**|**132.3%**\n\n&nbsp;\n\nRaster 1440p|76XT|67XT|77XT|78XT|9070|406Ti-8|406Ti-16|506Ti-16|4070|5070\n|:--|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|\n&nbsp;|RDNA3 16GB|RDNA2 12GB|RDNA3 12GB|RDNA3 16GB|RDNA4 16GB|Ada 8GB|Ada 16GB|Blackw. 16GB|Ada 12GB|Blackw 12GB\nComputerB|-|74.5%|95.1%|112.5%|143.1%|82.2%|-|_100%_|115.5%|136.0%\nCowcotl|72.4%|-|101.7%|120.7%|160.3%|84.5%|-|_100%_|115.5%|143.1%\nEurogamer|-|-|100.2%|116.1%|-|82.3%|83.9%|_100%_|-|138.1%\nGamersNex|-|76.0%|94.1%|112.5%|141.3%|80.7%|-|_100%_|110.9%|135.3%\nHW&Co|66.2%|73.6%|95.9%|-|143.3%|81.8%|83.8%|_100%_|112.2%|132.4%\nHWluxx|64.8%|-|91.5%|111.4%|139.6%|82.9%|-|_100%_|-|134.7%\nIgor's Lab|-|-|91.1%|109.2%|140.3%|-|84.1%|_100%_|-|121.5%\nKitGuru|67.7%|73.4%|95.1%|111.2%|144.6%|81.4%|84.1%|_100%_|133.5%|136.4%\nPCGH|70.8%|78.7%|-|-|147.8%|78.9%|85.7%|_100%_|114.6%|136.8%\nPurePC|-|-|94.3%|109.2%|144.8%|80.5%|83.9%|_100%_|110.3%|136.8%\nQuasarzone|-|-|99.0%|119.4%|-|86.3%|88.4%|_100%_|113.6%|137.8%\nSweClockers|-|-|97.8%|111.0%|148.4%|80.2%|-|_100%_|109.9%|133.0%\nTPU|68%|-|99%|116%|149%|87%|88%|_100%_|115%|138%\nTechSpot|-|-|96.1%|117.1%|138.2%|-|86.8%|_100%_|110.5%|130.3%\nTom's HW|68.3%|-|99.0%|112.8%|141.9%|79.4%|85.1%|_100%_|111.2%|132.0%\nTweakers|69.1%|-|99.3%|116.4%|142.3%|87.1%|-|_100%_|113.8%|132.1%\n**avg**|**~69%**|**~76%**|**97.5%**|**115.2%**|**144.6%**|**83.0%**|**85.6%**|**_100%_**|**113.0%**|**135.6%**\n\n&nbsp;\n\nRaster 2160p|76XT|67XT|77XT|78XT|9070|406Ti-8|406Ti-16|506Ti-16|4070|5070\n|:--|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|\n&nbsp;|RDNA3 16GB|RDNA2 12GB|RDNA3 12GB|RDNA3 16GB|RDNA4 16GB|Ada 8GB|Ada 16GB|Blackw. 16GB|Ada 12GB|Blackw 12GB\nCowcotl|67.9%|-|96.4%|121.4%|158.9%|76.8%|-|_100%_|110.7%|141.1%\nGamersNex|-|-|-|112.5%|144.4%|-|-|_100%_|-|136.6%\nKitGuru|65.1%|72.2%|94.6%|113.2%|148.5%|70.5%|80.0%|_100%_|111.2%|137.3%\nPCGH|66.6%|76.0%|-|-|151.4%|69.1%|82.3%|_100%_|110.1%|137.9%\nPurePC|-|-|90.7%|109.3%|148.8%|62.8%|81.4%|_100%_|108.1%|138.4%\nQuasarzone|-|-|97.8%|120.9%|-|79.3%|84.5%|_100%_|112.1%|141.0%\nSweClockers|-|-|96.7%|113.0%|154.3%|68.5%|-|_100%_|108.7%|135.9%\nTPU|66%|-|97%|118%|154%|76%|83%|_100%_|113%|142%\nTechSpot|-|-|97.6%|116.7%|145.2%|-|83.3%|_100%_|111.9%|135.7%\nTom's HW|64.3%|-|98.3%|115.3%|150.4%|59.8%|82.7%|_100%_|111.6%|134.6%\nTweakers|-|-|-|119.8%|149.3%|-|-|_100%_|111.3%|136.9%\n**avg**|**~66%**|**~76%**|**97.2%**|**117.6%**|**151.2%**|**72.5%**|**82.2%**|**_100%_**|**111.9%**|**139.0%**\n\n&nbsp;\n\nRayTracing 1080p|76XT|67XT|77XT|78XT|9070|406Ti-8|406Ti-16|506Ti-16|4070|5070\n|:--|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|\n&nbsp;|RDNA3 16GB|RDNA2 12GB|RDNA3 12GB|RDNA3 16GB|RDNA4 16GB|Ada 8GB|Ada 16GB|Blackw. 16GB|Ada 12GB|Blackw 12GB\nComputerB|-|62.7%|82.8%|-|-|67.4%|-|_100%_|-|-\nCowcotl|51.6%|-|75.0%|90.6%|132.8%|75.0%|-|_100%_|107.8%|134.4%\nEurogamer|-|-|86.6%|97.9%|-|89.3%|89.9%|_100%_|-|137.4%\nGamersNex|-|47.9%|65.8%|75.4%|119.8%|82.1%|-|_100%_|109.0%|130.6%\nHW&Co|47.4%|49.3%|70.1%|-|124.9%|81.0%|85.5%|_100%_|115.2%|132.3%\nHWluxx|39.0%|-|60.3%|69.5%|106.5%|77.5%|-|_100%_|-|131.6%\nKitGuru|43.4%|47.9%|66.5%|76.9%|115.8%|72.7%|87.0%|_100%_|118.5%|134.3%\nPCGH|55.9%|57.1%|-|-|130.5%|79.0%|90.2%|_100%_|116.3%|134.4%\nPurePC|-|-|65.6%|77.8%|120.0%|64.4%|82.2%|_100%_|112.2%|137.8%\nTPU|58%|-|84%|97%|140%|81%|91%|_100%_|119%|131%\nTom's HW|54.1%|-|86.1%|94.7%|131.3%|87.2%|86.9%|_100%_|113.2%|130.9%\nTweakers|-|-|-|91.9%|127.1%|80.9%|-|_100%_|120.6%|135.4%\n**avg**|**52.0%**|**~55%**|**75.7%**|**87.7%**|**127.8%**|**78.7%**|**87.5%**|**_100%_**|**116.1%**|**134.1%**\n\n&nbsp;\n\nRayTracing 1440p|76XT|67XT|77XT|78XT|9070|406Ti-8|406Ti-16|506Ti-16|4070|5070\n|:--|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|\n&nbsp;|RDNA3 16GB|RDNA2 12GB|RDNA3 12GB|RDNA3 16GB|RDNA4 16GB|Ada 8GB|Ada 16GB|Blackw. 16GB|Ada 12GB|Blackw 12GB\nComputerB|-|59.1%|81.2%|99.6%|139.3%|57.4%|-|_100%_|115.0%|130.3%\nCowcotl|52.6%|-|73.7%|98.2%|142.1%|68.4%|-|_100%_|108.8%|143.9%\nEurogamer|-|-|86.6%|98.9%|-|79.8%|88.7%|_100%_|-|138.5%\nHWluxx|35.7%|-|56.9%|67.8%|108.0%|77.4%|-|_100%_|-|132.7%\nKitGuru|41.2%|44.6%|62.2%|76.0%|117.8%|63.4%|85.4%|_100%_|117.6%|135.2%\nPCGH|53.2%|55.4%|-|-|131.1%|70.8%|88.7%|_100%_|115.7%|135.8%\nPurePC|-|-|67.4%|76.4%|121.3%|80.9%|84.3%|_100%_|111.2%|138.2%\nTPU|56%|-|84%|98%|145%|64%|91%|_100%_|120%|138%\nTechSpot|-|-|63.3%|61.2%|100.0%|-|87.8%|_100%_|91.8%|112.2%\nTom's HW|52.7%|-|87.5%|96.5%|137.1%|82.5%|87.1%|_100%_|113.5%|133.1%\nTweakers|-|-|-|93.6%|130.4%|78.1%|-|_100%_|121.6%|136.9%\n**avg**|**50.4%**|**~54%**|**75.3%**|**87.7%**|**130.2%**|**70.8%**|**87.2%**|**_100%_**|**114.4%**|**135.1%**\n\n&nbsp;\n\nRayTracing 2160p|76XT|67XT|77XT|78XT|9070|406Ti-8|406Ti-16|506Ti-16|4070|5070\n|:--|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|\n&nbsp;|RDNA3 16GB|RDNA2 12GB|RDNA3 12GB|RDNA3 16GB|RDNA4 16GB|Ada 8GB|Ada 16GB|Blackw. 16GB|Ada 12GB|Blackw 12GB\nCowcotl|54.9%|-|76.5%|105.9%|141.2%|62.7%|-|_100%_|113.7%|147.1%\nKitGuru|36.3%|34.6%|41.0%|73.5%|119.2%|43.6%|81.2%|_100%_|101.3%|109.0%\nPCGH|48.2%|49.8%|-|-|131.6%|63.9%|85.9%|_100%_|110.5%|125.6%\nPurePC|-|-|65.6%|76.7%|120.0%|64.4%|82.2%|_100%_|106.7%|135.6%\nTPU|52%|-|77%|95%|146%|46%|87%|_100%_|94%|108%\nTechSpot|-|-|37.0%|55.6%|81.5%|-|85.2%|_100%_|70.4%|85.2%\nTom's HW|49.4%|-|79.2%|100.4%|140.1%|66.5%|84.4%|_100%_|112.6%|135.3%\nTweakers|-|-|-|-|134.3%|-|-|_100%_|117.7%|139.4%\n**gemittelte 4K RayTracing-Perf.**|**46.3%**|**~48%**|**64.4%**|**87.3%**|**129.0%**|**55.7%**|**86.3%**|**_100%_**|**102.5%**|**120.3%**\n\n&nbsp;\n\nAt a glance|76XT|67XT|77XT|78XT|9070|406Ti-8|406Ti-16|506Ti-8|506Ti-16|4070|5070\n|:--|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|\n&nbsp;|RDNA3 16GB|RDNA2 12GB|RDNA3 12GB|RDNA3 16GB|RDNA4 16GB|Ada 8GB|Ada 16GB|Blackw. 8GB|Blackw. 16GB|Ada 12GB|Blackw 12GB\n1080p RA|~71%|~76%|96.1%|111.3%|138.0%|86.2%|87.1%|~_100%_|_100%_|112.3%|132.3%\n1440p RA|~69%|~76%|97.5%|115.2%|144.6%|83.0%|85.6%|~98%|_100%_|113.0%|135.6%\n2160p RA|~66%|~76%|97.2%|117.6%|151.2%|72.5%|82.2%|~90%|_100%_|111.9%|139.0%\n1080p RT|52.0%|~55%|75.7%|87.7%|127.8%|78.7%|87.5%|~91%|_100%_|116.1%|134.1%\n1440p RT|50.4%|~54%|75.3%|87.7%|130.2%|70.8%|87.2%|~83%|_100%_|114.4%|135.1%\n2160p RT|46.3%|~48%|64.4%|87.3%|129.0%|55.7%|86.3%|~66%|_100%_|102.5%|120.3%\nTDP|190W|230W|245W|263W|220W|160W|165W|180W|180W|200W|250W\nReal&nbsp;P.D.|190W|219W|229W|250W|220W|151W|~160W|~160W|163W|193W|230W\nE.Eff. 1440p&nbsp;RA|59%|57%|69%|75%|107%|90%|87%|~100%|_100%_|95%|96%\nMSRP|$329|$479|$419|$499|$549|$399|$499|$379|$429|$549|$549\nGER: Retail|327€|~330€|401€|477€|649€|~370€|~410€|389€|449€|~550€|590€\nGER: P/P 1440p&nbsp;RA|94%|104%|109%|108%|100%|101%|94%|~114%|_100%_|92%|103%\nGER: P/P 1440p&nbsp;RT|69%|73%|84%|83%|90%|86%|95%|~96|_100%_|93%|103%\nUS: Retail|~$310|~$320|~$420|~$500|~$650|~$400|~$450|$430|$500|~$550|$605\n**US: P/P 1440p&nbsp;RA**|**111%**|**119%**|**116%**|**115%**|**111%**|**104%**|**95%**|**~114%**|**_100%_**|**103%**|**112%**\nUS: P/P 1440p&nbsp;RT|81%|84%|90%|88%|100%|89%|97%|~96%|_100%_|104%|112%\n\nNote: RA = Raster, RT = Ray-Tracing, E.Eff. = Energy Efficiency, P/P = Performance/Price Ratio    \nNote: retail prices assuming real availability - for old SKUs, these are typically from the years 2023/2024; for the Radeon RX 9070 it's simple an assumption\n\n&nbsp;\n\n**On the performance of the GeForce RTX 5060 Ti _16GB_:** The card beats the GeForce RTX 4060 Ti with +14-17% more performance, in line with the gains of most other RTX50 cards. Another advantage of the GeForce RTX 5060 Ti is that the 16 GB version is now the primary version (in contrast to the GeForce RTX 4060 Ti) and also comes at no major additional cost. On the AMD side, the Radeon RX 7700 XT is only a suitable counterpart at raster rendering, but is clearly beaten at ray tracing - and of course also has the smaller amount of VRAM. At best, the Radeon RX 7800 XT is a passable opponent to the GeForce RTX 5060 Ti, but also costs a little more (in Europe). Unfortunately, the US prices are difficult to assess at the moment, as the US market is completely overbought.\n\n&nbsp;\n\n**Important note on the GeForce RTX 5060 Ti _8GB_:** The above performance evaluation based on average frame rates does not show the complete picture for this GPU. But even with average frame rates, it can be seen that the card lags behind in raster rendering from 2160p, but in ray tracing from 1080p. However, differences at average frame rates are always only the very last sign of too less VRAM. Long before that, there are already (sometimes considerable) disadvantages at the minimum frame rates as well as a declining image quality due to missing textures, delayed loading textures or even a generally lower texture quality. This was explained quite well in a video by [Hardware Unboxed](https://www.youtube.com/watch?v=AdZoa6Gzl6s), and is a known problem with too less VRAM. The GeForce RTX 5060 Ti 8GB is therefore already borderline even under 1080p and can therefore not be recommended with a clear conscience for a GPU purchase in 2025.\n\n&nbsp;\n\nList of hardware reviews evaluated for this analysis:\n\n- [ComputerBase](https://www.computerbase.de/artikel/grafikkarten/nvidia-geforce-rtx-5060-ti-16-gb-test.92119/)\n- [Cowcotland](https://www.cowcotland.com/articles/4571/test-gainward-geforce-rtx-5060-ti-python-blackwell-enfin-pour-le-plus-grand-nombre.html)\n- [Eurogamer](https://www.eurogamer.net/digitalfoundry-2025-nvidia-geforce-rtx-5060-ti-16gb-review)\n- [Gamers Nexus](https://www.youtube.com/watch?v=Cskegn1-D7s)\n- [Hardware & Co](https://hardwareand.co/dossiers/gpu/test-de-la-geforce-rtx-5060-ti-enfin-une-carte-blackwell-capable-de-faire-oublier-sa-devanciere)\n- [Hardwareluxx](https://www.hardwareluxx.de/index.php/artikel/hardware/grafikkarten/65938-geforce-rtx-5060-ti-mit-16-gb-im-test.html)\n- [Igor's Lab](https://www.igorslab.de/nvidia-geforce-rtx-5060-ti-16gb-im-test-sparsam-im-verbrauch-aber-nicht-ganz-unproblematisch-fuer-gamer/)\n- [KitGuru](https://www.kitguru.net/components/graphic-cards/dominic-moass/nvidia-rtx-5060-ti-16gb-review-ft-gigabyte-palit/)\n- [PC Games Hardware](https://www.pcgameshardware.de/Geforce-RTX-5060-Ti-16GB-Grafikkarte-281131/Tests/Release-Review-Preis-kaufen-Benchmark-Specs-1470373/)\n- [PurePC](https://www.purepc.pl/test-msi-geforce-rtx-5060-ti-gaming-recenzja-opinia-wydajnosc-cena-premiera-blackwell)\n- [Quasarzone](https://quasarzone.com/bbs/qc_bench/views/94640)\n- [SweClockers](https://www.sweclockers.com/test/41012-nvidia-geforce-rtx-5060-ti-mellankort-mellanpris-mellanbra)\n- [TechPowerUp](https://www.techpowerup.com/review/palit-geforce-rtx-5060-ti-infinity-3-16-gb/)\n- [TechSpot](https://www.techspot.com/review/2979-nvidia-geforce-rtx-5060-ti-16gb/) / [Hardware Unboxed](https://www.youtube.com/watch?v=B6qZwJsp5X4)\n- [Tom's Hardware](https://www.tomshardware.com/pc-components/gpus/nvidia-geforce-rtx-5060-ti-16gb-review)\n- [Tweakers](https://tweakers.net/reviews/13162/nvidia-geforce-rtx-5060-ti-haalt-de-lat-maar-die-lag-niet-hoog.html)\n\n&nbsp;\n\nSource: [3DCenter.org](https://www.3dcenter.org/artikel/launch-analyse-nvidia-geforce-rtx-5060-ti)\n\nPS: 3DCenter is free of advertising and is financed solely by donations.",
    "comments": [
      "Nvidia is really trying to make each new product a hard buy",
      "Only a 30% performance gain over the 3060 Ti after 4.5 years.\n\nI’ve become bearish on meaningful value gains in newer generations of hardware going forward. Not even a drastic node shrink (from Samsung 8N to TSMC N4), was enough to provide a meaningful cost-per-frame improvement from the 3060 Ti to the 4060 Ti. When the next node shrink occurs with the 6060 Ti, I expect Nvidia to pass very little cost savings to the consumer.\n\nPeople who expect good value gains will be waiting a looong time for a card that provides just that. It ironically makes the 16GB 5060 Ti a solid card to buy; it’s a card specifically designed for people who wait.",
      "I honestly think the x60 cards would be quite solid across the board if they weren't vram limited\n\nI rarely hit the limits of what my hardware can actually do, because I'm always running of vram and losing 70% of my framerate",
      "the 5060 ti 16gb is the only card worth it, and only for people who are still running 6gb/8gb versions of the older x060 ti cards\n\nit's not even something that shows up in benchmarks.\n\nthose 8gb cards absolutely shit the bed the millisecond vram starts paging, and they have effective \\~6.5GB because of what windows' compositor is always stealing.\n\nif you turn off dlss and frame gen you might get lucky and run with low enough vram usage to be stable.\n\nbut if you run with dlss and fg on, you're fucked. like with oblivion I used engine.ini edits to force the engine to limit its streaming pool and effects so that they only consume 70% of my vram, but the game isn't the problem.. frame gen is. turning frame gen on increases my 50fps to \\~80-100, sounds good, til you notice it also increases vram usage by 15% the second you toggle it on. then you start paging out of vram and it's stutterville at 20fps, frame gen just straight up disables, and if you disable dlss your native fps has gone from 50 to 14.\n\nbeen dealing with this since the 2060 series because I constantly end up with the low vram x060 ti card. this time around I threw in the extra $100 to get the 16gb version.\n\nI don't even care if the perf gains are minimal. you can give me 15% higher fps, but that extra vram meaning I no longer deal with incessant framerate drops in every single AAA+ makes it worth every penny",
      "Please never stop doing these meta reviews dude its awesome!",
      "drop texture res? Im running Oblivion with medium textures and I don't have any of the issues you're describing with FG on."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "rtx 4060",
      "4060",
      "rtx 4060 ti",
      "4060 ti"
    ],
    "title": "RTX 4060 Ti / 4060 Announcement Megathread",
    "selftext": "# This thread is best viewed on new Reddit.\n\n[GeForce RTX 4060 Family Image](https://preview.redd.it/uv1e9gfhmj0b1.jpg?width=1920&format=pjpg&auto=webp&s=77f014a17a7662c7bc0abfa8db51b63103e5bc4f)\n\nRTX 4060 Ti and 4060 have been announced here. The goal of this megathread is to provide everyone with the best information possible and consolidate any questions, feedback, and discussion to make it easier for NVIDIA’s community team to review them and bring them to appropriate people at NVIDIA.\n\n# GeForce RTX 40-Series GPU information:\n\n# [Official Spec Sheet Here](https://www.nvidia.com/en-us/geforce/graphics-cards/compare/?section=compare-specs)\n\n&#x200B;\n\n||**RTX 4060 Ti 8GB**|**RTX 4060 Ti 16GB**|**RTX 4060**|\n|:-|:-|:-|:-|\n|**GPU**|TSMC 4N AD106-350|TSMC 4N AD106-351|TSMC 4N AD107-400|\n|**Transistor**|TBD|TBD|TBD|\n|**Die Size**|TBD|TBD|TBD|\n|**Transistor Density**|TBD|TBD|TBD|\n|**GPC**|TBD|TBD|TBD|\n|**TPC**|TBD|TBD|TBD|\n|**SMs**|34 SM|34 SM|24 SM|\n|**TMUs**|TBD|TBD|TBD|\n|**ROPs**|TBD|TBD|TBD|\n|**Base Clock**|2.31 Ghz|2.31 Ghz|1.83 Ghz|\n|**Boost Clock**|2.54 Ghz|2.54 Ghz|2.46 Ghz|\n|**CUDA Cores**|4352 CUDA Cores|4352 CUDA Cores|3072 CUDA Cores|\n|**Shader FLOPS**|22 TFLOPS|22 TFLOPS|15 TFLOPS|\n|**RT Cores**|34 3rd Gen RT Cores|34 3rd Gen RT Cores|24 3rd Gen RT Cores|\n|**RT FLOPS**|51 TFLOPS|51 TFLOPS|35 TFLOPS|\n|**Tensor Cores**|136 4th Gen Tensor Cores|136 4th Gen Tensor Cores|96 4th Gen Tensor Cores|\n|**Tensor FLOPS (FP8)**|353 TFLOPS|353 TFLOPS|242 TFLOPS|\n|**Memory Interface**|128-bit|128-bit|128-bit|\n|**Memory Speed**|18 Gbps|18 Gbps|17 Gbps|\n|**Memory Bandwidth**|288 GB/s|288 GB/s|272 GB/s|\n|**VRAM Size**|8GB GDDR6|16GB GDDR6|8GB GDDR6|\n|**L2 Cache**|32 MB|32 MB|24 MB|\n|**Max TGP**|160W|165W|115W|\n|**PSU Requirement**|550W|550W|TBD|\n|**Price**|$399 MSRP|$499 MSRP|$299 MSRP|\n|**Release Date**|May 24|July 2023|July 2023|\n\n# Performance Shown\n\nBe sure to wait for independent benchmarks\n\n**RTX 4060 Ti vs. RTX 2060 SUPER**\n\n* 2.6x faster than RTX 2060 SUPER w/ Frame Generation\n* 1.6x faster than RTX 2060 Super in rasterization\n\n**RTX 4060 Ti vs. RTX 3060 Ti**\n\n* 1.7x faster than RTX 3060 Ti w/ Frame Generation\n* 1.15x faster than RTX 3060 Ti in rasterization\n\n**RTX 4060 vs. RTX 2060**\n\n* 2.3x faster than RTX 2060 w/ Frame Generation\n* 1.6x faster than RTX 2060 in rasterization\n\n**RTX 4060 vs. RTX 3060**\n\n* 1.7x faster than RTX 3060 w/ Frame Generation\n* 1.2x faster than RTX 3060 in rasterization\n\n# Power Comparison\n\n&#x200B;\n\n||RTX 2060 Super|RTX 3060 Ti|RTX 4060 Ti|\n|:-|:-|:-|:-|\n|Idle (W)|10W|12W|7W|\n|Video Playback (W)|15W|19W|13W|\n|Average Gaming (W)|168W|197W|140W|\n|TGP (W)|175W|200W|160W|\n\n&#x200B;\n\n||RTX 2060|RTX 3060|RTX 4060|\n|:-|:-|:-|:-|\n|Idle (W)|8W|8W|7W|\n|Video Playback (W)|14W|13W|11W|\n|Average Gaming (W)|138W|170W|110W|\n|TGP (W)|160W|170W|115W|\n\n&#x200B;\n\n# Power Supply Requirement (RTX 4060 Ti Founders Edition)\n\n[GeForce RTX 4060 Ti Founders Edition Power Supply Requirements](https://preview.redd.it/yt9g64ekmj0b1.jpg?width=1350&format=pjpg&auto=webp&s=44dc736df51136eef379cdf3d7d4487416fae581)\n\n# GeForce RTX 4060 Ti FAQ\n\nNvidia posted this FAQ on their forum. Link here: [https://www.nvidia.com/en-us/geforce/forums/geforce-graphics-cards/5/519266/geforce-rtx-4060-family-faq/](https://www.nvidia.com/en-us/geforce/forums/geforce-graphics-cards/5/519266/geforce-rtx-4060-family-faq/)\n\n**How does the RTX 4060 Ti perform compared to previous generations?**  \n\nThe GeForce RTX 4060 Ti is on average 70% faster than the RTX 3060 Ti with Frame Generation, and 15% without Frame Generation, across a suite of modern graphically demanding games at 1080p. Compared to the RTX 2060 SUPER, it’s 160% faster with Frame Generation, and 60% faster without Frame Generation.\n\n**How much power does the RTX 4060 Ti use?**\n\nRTX 4060 Ti is ultra-efficient - it has average gaming power consumption of 140 Watts, while the RTX 3060 Ti averages at 197 Watts when tested across 22 games at 1080p, 1440p, and 4K.  The recommended system power for an RTX 4060 Ti is 550W, although this may vary depending on graphics card model clocks and other components in your system.\n\n**Why does the RTX 4060 Ti have an option (16GB) with more graphics memory than the RTX 4070 & 4070 Ti (12GB)?**\n\nThis can happen occasionally based on the underlying GPU architecture; for example the RTX 3060 had more memory than the RTX 3070. With a 128-bit memory interface, it is not possible to outfit the RTX 4060 Ti & 4060 with 12GB of graphics memory. The memory configurations compatible with a 128-bit memory interface are 8GB and 16GB. However, the GPU itself is what mostly defines their performance, and that’s why GPUs are named the way they are. \n\n**Is 8GB VRAM enough for modern gaming titles at 1080p?**\n\nYes. GeForce RTX 4060 Ti and 4060 are able to run a wide range of modern games at over 100 fps at 1080p in our testing. In most games, both versions of the GeForce RTX 4060 Ti (8GB and 16GB) will deliver the same level of performance. There are a handful of games which play best at the “High” settings preset on the 4060 Ti (8GB) and “Ultra” settings on the 4060 Ti (16GB).\n\n**How does the frame buffer and memory subsystem on the RTX 4060 Ti differ from the prior generation?**\n\nThe RTX 4060 Ti has either 16GB or 8GB of graphics memory, compared to 8GB on the prior generation RTX 3060 Ti.\n\nThe RTX 4060 Ti’s L2 cache is 8x larger with a size of 32MB (versus 4MB on RTX 3060 Ti).\n\nThis allows us to store data much closer to the execution cores on a very high speed memory interface, with super low latency. This reduces the amount of traffic going across the memory bus to access the graphics memory.\n\nBy having a large L2 cache, we can get considerably more performance out of our GPUs without needing as wide a memory bus. Ultimately, the RTX 4060 Ti memory subsystem delivers better efficiency and better RTX gaming than the RTX 3060 Ti. \n\n**How can I measure the graphics memory usage of a particular game?** \n\nVarious tools attempt to measure graphics memory usage, but they don’t accurately report how much is actually needed to render a scene. Instead they are reporting how much memory is requested by the game, which varies for many reasons and shouldn’t be used as an indicator of how much the application actually needs. We’ve seen that games will request more memory on graphics cards that have more memory, simply because it’s freely available to them.\n\nInstead of using these memory measurements, we recommend looking at the “1% low” framerates instead, which more accurately convey the actual gaming experience.\n\n**What type of power connector do the RTX 4060 Ti and 4060 use?**\n\nThe RTX 4060 Ti (8GB) Founders Edition has a 16-pin PCIe Gen 5 connector. It can be powered by 1x PCIe 8-pin connector from the power supply to the adapter in the box.\n\nCertain partner models of the RTX 4060 Ti (8GB or 16GB) may use 1x PCIe 8-pin connector. \n\nThe RTX 4060 will be available in partner models powered by 1x PCIe 8-pin or 6-pin connector, or by PCIe Gen 5 connector.\n\n**How many NVENCs and NVDECs does RTX 4060 Ti and 4060 have?**\n\nRTX 4060 Ti and 4060 have one 8th Generation NVENC and one NVDEC.\n\n**Which games implement DLSS 3?**  \n\nFor a complete list of all DLSS supported games and applications, please refer to our official list that we regularly update here:  [https://www.nvidia.com/en-us/geforce/news/nvidia-rtx-games-engines-apps/](https://www.nvidia.com/en-us/geforce/news/nvidia-rtx-games-engines-apps/)\n\n# Other Announcements\n\n* **4060 Family Video**:  [https://www.youtube.com/watch?v=i0iC2VQgwes](https://www.youtube.com/watch?v=i0iC2VQgwes)\n* **A Deeper Look At VRAM On GeForce RTX 40 Series Graphics Cards**: [https://www.nvidia.com/en-us/geforce/news/rtx-40-series-vram-video-memory-explained/](https://www.nvidia.com/en-us/geforce/news/rtx-40-series-vram-video-memory-explained/)\n* **Win 1 of 460 GeForce RTX 4060 & 4060 Ti Graphics Cards In Our $150,000 Summer of #RTXON Sweepstakes**: [https://www.nvidia.com/en-us/geforce/news/win-rtx-4060-ti-graphics-cards/](https://www.nvidia.com/en-us/geforce/news/win-rtx-4060-ti-graphics-cards/)\n* **DLSS Brings AI-Accelerated Performance To Over 300 Games & Apps, Including D5 Render, Now Featuring DLSS 3**: [https://www.nvidia.com/en-us/geforce/news/300-dlss-games-apps-d5-render-dlss-3-update-available-now/](https://www.nvidia.com/en-us/geforce/news/300-dlss-games-apps-d5-render-dlss-3-update-available-now/)",
    "comments": [
      "Ok. I’ve read enough. Here’s my conclusion. If you NEED a GPU this year, ie: first computer, your GPU failed, your business is expanding, keep researching which 40 series is best for you. But, it your current setup works, wait. The incremental improvements just don’t matter.",
      "Half the 3060 Ti's die size and bus width for the same price. What a rip-off.",
      "I agree, I have a 3060ti and am not gonna fall for their frame generation bait. Give me a real performance increase",
      "NVIDIA, why are you not comparing the 4060Ti with the 3070? Hmmm",
      "Excuse me, but why would you go into this generation expecting that you should upgrade from 3060ti to 4060ti? At least wait one more generation if you're not going up the tier ladder, that's just common sense.",
      "nVIDIA loves people like you, who only look at the name instead of the specs.\n\nThis 4060 imposter is literally the new 1050 Ti specs wise, which was **139**$ back in the day.\n\nJust a hint: compare this to 4090 then the 1050 Ti to the 1080 Ti (the flagship back then) and tell me what you notice.",
      "$300 for an entry level, my oh my have the times changed. Such is life.",
      "Wow, those prices are bad. I bought the 4070 for a lower price than the 4060ti 16gb is supposed to cost.",
      "The ps5 can't run everything. \n\n\nIt uses upscaling just like pc gamers do.",
      "GN: https://www.youtube.com/watch?v=cQPGh2L6rB0\n\n\n\nHUB: https://www.youtube.com/watch?v=ocAi9y4n1UQ",
      "Because it's probably the same performance level for $100 less + DLSS 3 (for the 8GB version) or the same performance level with more VRAM for the same price + DLSS 3 (for the 16GB version)",
      "4060ti at 400 is no surprise. The 16gb version at 500 is ridiculous however. I thought Nvidia was responding to the criticism with the 16gb version, but they're not. They're either A. Afraid of consumers figuring out how much 8GB of VRAM actually costs them (20 dollars) or B. the 16gb version exists to upsell people to the 4070.",
      "Only non-Ti 4060 seems moderately interesting; 8GB Ti just feels DOA. 4060 at the very least seems like a decent choice for a new card for a first time builder whos planning out a mid range system, just that VRAM will always be the concern here.",
      "500$ for 4060ti 16 GB VRAM while there is RX 6800 16 GB that has been some time on the market for the same price and has more performance  . That is a huge rip-off from Nvidia side",
      "My problem with this cards: Nvidia is doing the same move they did for the other 40 series cards, they are calling the card as the card the tier above it (so calling a 50 card as a 60 card) and then pricing it as the tier above the name they assigned to the card (so the \"60\" card which should be a 50 card is also priced as if it were a 70 card).\n\nI find it very bad that the 4060 Ti and 4060 launched with 8 GB in the first place and it is even worse that the 16 GB 4060 Ti costs 100 dollars more than the 8 GB version, imagine paying 499 dollars for a what is in reality a 4050 Ti: that ain't good happen right? Well, this is the sad reality.",
      "\"The incremental improvements just don’t matter.\"\n\nWhat if your GPU still works but its something like a 1070 or older? The improvements should be good enought.",
      "Agreed. I upgraded my 1060FE to a 4070FE. Not everyone is sitting on a 3060 or better already. In fact, I'd argue 30 series owners shouldn't even be looking/commenting on the value of a single gen bump.\n\nFor the horde of 1060 and 2060 owners though, the 4070 or 4060 Ti 16GB are compelling. I'm inclined towards the 4070 for the performance bump, but the 16GB isn't bad if someone is worried about VRAM.",
      "I don't think you read their comment correctly. They are saying this looks like a good card to upgrade from the 10 series or lower. Not a good upgrade for 3060TI owners, nor potentially 2080+ owners.\n\nAs always, wait for actual tests to be completed/reviews.",
      "That's a tier up the ladder upgrade. Also, 3060ti was a lot better than 3060 in the 30 series generation.\n\nUpgrade from 3060ti to 4070 and that will be a decent upgrade as well. Or don't, because you should probably wait for RTX50 series instead.",
      "Keep simping for Nvidia and next time you'll get X107 die for 500$"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "rtx 4060",
      "4060"
    ],
    "title": "GeForce Beyond at CES 2023 Megathread",
    "selftext": "# This thread is best viewed on new Reddit.\n\nhttps://preview.redd.it/b9drnjddcv9a1.jpg?width=1200&format=pjpg&auto=webp&s=9bf011a436b65189d17cb29421eed93a57d51a15\n\nPowered by Ada Lovelace architecture GeForce RTX 40-Series laptops and RTX 4070 Ti is finally upon us. The goal of this megathread is to provide everyone with the best information possible and consolidate any questions, feedback, and discussion to make it easier for NVIDIA’s community team to review them and bring them to appropriate people at NVIDIA.\n\n# [GeForce Beyond at CES 2023 Keynote Link](https://www.youtube.com/watch?v=EWnD2zfa-F0)\n\n# GeForce RTX 40-Series Laptops GPU information:\n\n&#x200B;\n\n||**RTX 4090 Laptop**|**RTX 4080 Laptop**|**RTX 4070 Laptop**|**RTX 4060 Laptop**|**RTX 4050 Laptop**|\n|:-|:-|:-|:-|:-|:-|\n|**GPU**|AD103|AD104|AD106|AD107|AD107|\n|**Boost Clock**|1455-2040 Mhz|1350-2280 Mhz|1230-2175 Mhz|1470-2370 Mhz|1605-2370 Mhz|\n|**CUDA Cores**|9728 CUDA Cores (76 SM)|7424 CUDA Cores (58 SM)|4608 CUDA Cores (36 SM)|3072 CUDA Cores (24 SM)|2560 CUDA Cores (20 SM)|\n|Memory Interface|256-bit|192-bit|128-bit|128-bit|96-bit|\n|**VRAM Size**|16GB GDDR6|12GB GDDR6|8GB GDDR6|8GB GDDR6|6GB GDDR6|\n|**TDP Range**|80 - 150w|60 - 150w|35 - 115w|35 - 115w|35 - 115w|\n|**Price**|Starting at $1999|Starting at $1999|Starting at $999|Starting at $999|Starting at $999|\n|**Release Date**|February 8|February 8|February 22|February 22|February 22|\n\n**Claimed Performance (take with grains of salt):**\n\n* **RTX 4070/4060/4050 Laptop**\n   * RTX 3080 at 1/3 the Power\n   * 80 FPS 1440p Ultra\n   * 2.5 Hour Render in 10 minutes\n* **RTX 4090/4080 Laptop**\n   * 60 FPS Surround Gaming - 3x 4K\n   * 3D Collaboration at 4K60 in Ominverse\n   * 2x Faster Video Export\n\n# GeForce RTX 4070 Ti GPU information:\n\n&#x200B;\n\n||**RTX 4070 Ti**|\n|:-|:-|\n|**GPU**|TSMC 4N AD104|\n|**Transistor**|35.8 billion|\n|**Die Size**|294.5 mm^(2)|\n|**Transistor Density**|121.6 MT/mm^(2)|\n|**GPC**|5|\n|**TPC**|30|\n|**SMs**|60 SM|\n|**TMUs**|240|\n|**ROPs**|80|\n|**Base Clock**|2.31 Ghz|\n|**Boost Clock**|2.61 Ghz|\n|**CUDA Cores**|7680 CUDA Cores|\n|**Shader FLOPS**|40.1 Shader TFLOPS|\n|**RT Cores**|60 3rd Gen RT Cores|\n|**RT FLOPS**|92.7 RT TFLOPS|\n|**Tensor Cores**|240 4th Gen Tensor Cores|\n|**Tensor FLOPS (FP8)**|320.7/641.4 Tensor TFLOPS|\n|**Memory Interface**|192-bit|\n|**Memory Speed**|21 Gbps|\n|**Memory Bandwidth**|504 GB/s|\n|**VRAM Size**|12GB GDDR6|\n|**L2 Cache**|48MB|\n|**Max TGP**|285W|\n|**PSU Requirement**|700W|\n|**Price**|$799 MSRP|\n|**Release Date**|January 5, 2023|\n\n# Other Features and Technologies:\n\n* RTX 4080 Gaming Coming to GeForce NOW\n   * GeForce Ultimate Membership\n   * Same Price as RTX 3080 Tier - $19.99/month\n   * If you have RTX 3080 tier, auto upgrade to RTX 4080 Tier\n* New Games and updates with DLSS\n   * Throne and Liberty\n   * Warhaven\n   * Witchfire\n   * Atomic Heart\n   * Marvel's Midnight Suns\n   * Dakar Desert Rally\n   * The Cycle: Frontier\n   * COnqueror's Blade\n   * Tower of Fantasy\n   * ILL Space\n   * Dead Space\n   * Judgment & Lost Judgment\n* New Games and updates with Reflex\n   * Jurassic World Evolution 2\n   * Portal with RTX\n   * The Witcher 3: Wild Hunt\n   * Warhammer 40,000: Darktide\n* NVIDIA Reflex Comes to GeForce NOW\n* New 1440p 360 Hz Displays Now Available\n   * Acer Predator XB273U F\n   * AOC AGON PRO AG276QSG\n* More GSync Gaming Monitors with Reflex\n   * Alienware AW2524H\n\n# Links and References\n\n|**Topic**|**Article Link**|**Video Link (If Applicable)**|\n|:-|:-|:-|\n|GeForce RTX 40 Series Laptops|[Click Here](https://www.nvidia.com/en-us/geforce/news/geforce-rtx-40-series-laptops-available-february-8/)|[Click Here](https://www.youtube.com/watch?v=Vyq5rFuMEz8)|\n|GeForce RTX 4070 Ti|[Click Here](https://www.nvidia.com/en-us/geforce/news/geforce-rtx-4070-ti/)|N/A|\n|DLSS Updates|[Click Here](https://www.nvidia.com/en-us/geforce/news/ces-2023-rtx-dlss-game-updates/)|N/A|\n|NVIDIA Reflex|[Click Here](https://www.nvidia.com/en-us/geforce/news/ces-2023-reflex-games-1440p-360hz-monitors/)|N/A|\n\n# ",
    "comments": [
      "4070 Ti is in reality a 4060 Ti and you shouldn't pay $800 for a xx60 class card.",
      "Each generation, the top Titan card (or XX90Ti card) uses the full die. Then when they test the silicon that comes from the fab, they determine which chips have defects that prevent some of the cores from operating. They seal off those parts of the chip and sell it as a lower tier. \"Oh, this die can only really run 70% of the cores stably? Sell it as a XX80 card!\" (Technically, there are multiple dies and not every XX50 budget card was an XX90 that failed, but close enough.)\n\nOver the last decade, we're settled into a pretty consistent set of tiers:\n\nXX80 represents 65% - 80% of a full die\n\nXX70 represents 50% - 65% of a full die\n\nXX60 represents 30% - 50% of a full die\n\nXX50 represents 15% - 30% of a full die\n\nSo this leaves us with Ada Lovelace. The full die has 18432 cores. \n\nThe \"RTX 4080 16GB\" is only 53% (9728 / 18432 cores) and should be in the XX70 tier. \n\nThe \"RTX 4070 Ti\" is only 42% (7680 / 18432 cores) and should be in the XX60 tier.",
      "8GB 4070 lol.",
      "Even if it had true specs for a 70 Ti class card you should not pay 800 dollars for that.",
      "Chart for reference: https://i.imgur.com/LISgogs.png",
      "Very disingenuous of Nvidia to use an impossibly-thin 1.75 slot render when no Founder's Edition 4070 Ti exists.",
      "What's the UK price for this? Anyone knows?",
      "It wont be very common because there isn't an FE. \n\nI wouldn't put it passed them that this was intentional for them to close the gap in price for the 4080.",
      "I like that it's just a replacement for the 3080 tier too and every 3080 tier gets automatically upgraded",
      "Just sucks that they are gutting local GameStream to try and strongarm you into using this service.",
      "You might as well massage the numbers another way by looking at transistor counts of the top die (from wikipedia):\n\n    Series     Transistors (billions)  Gain from previous gen\n       9                   8            \n      10                  12\t                   1,5\n      20                  18,6\t                   1,55\n      30                  28\t                   1,50 \n      40                  76,3\t                   2,72\n\n(and 4090 in the last row is not even the full die)\n\nThere is no denying that the prices went way up but one can argue that it's the Titan being much more titanic this time rather than the rest of the stack being too small. The 3070->4070 and 3080->4080 gains would more than fine if the prices didn't simultaneously go up.",
      "£799, but realistically you won't see many if any units at this price. A small batch of GPUs might be dedicated to low end models to hit that price and cover their ass. Those lines will be retired for more expensive models immediately after the first batch sells out.\n\nhttps://www.nvidia.com/en-gb/geforce/graphics-cards/40-series/rtx-4070ti/",
      "How convenient that they discontinued nvidia gamestream at the same time too huh?",
      "Interesting metric. Yeah, I could see cutting the top card out of the equation entirely and just looking at gen-on-gen transistor (or core) growth within each tier. But honestly, with the shinanigans NV is pulling with the ~~4080 12GB~~ 4070 Ti as a distraction from the whole-stack tier bump while also setting scalper prices as MSRP in the post-crypto-crash market, I'm subjectively less willing to give them much benefit of the doubt. Transistor count is up, and TMCS wafer costs are up, but die size is way down and transistors are not 1-for-1 analogous to performance or value.",
      "I can't really argue with that. I know that if I could get an RTX 4080 16GB for $800, I would already have one right now.",
      "What are the chances that Nvidia throws a curve ball and the 4070ti is the lowest GPU that they release for desktop and the only way to get a 4050 - 4070 non TI will be laptop class GPU's lol",
      "Sintesis:\nThe laptop gpus are interesting.\nThe 4070 Ti should be named 4060 and regardless naming it should definitely be less than 799 dollars.\n\nCheers.",
      "Regarding the laptop line... That seems to be the way of it now.\n\nRTX 3080 = 8704 to 8960 cores\n\nLaptop 3080 = 6144 cores\n\nRTX 3070 = 5888 cores\n\nLaptop 3070 = 5120 cores\n\nWhat's interesting is that the 20-series and 10-series seem to have been consistent in core counts between Desktop and Laptop lines for the same model number, but since Ampere, that's no longer true. I'm really tired of Nvidia lying in new an exciting ways to squeeze an extra buck out of consumers.\n\nRegarding the ~~4070Ti~~ 4060, cough https://i.imgur.com/LISgogs.png cough",
      "My main concern as always is how common will the $799.99 price point be? I know we'll see some MSRP models at launch but outside of that I'm not too optimistic especially without a Founders Edition to anchor prices.",
      "there will be a few MSRP barebone models that will be perpetually out of stock"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "4060"
    ],
    "title": "I joined you guys after 10 years on red team",
    "selftext": "This new 4060 is my first Nvidia card since the GTX 600 series, where I've been on AMD cards. My RX 5700 XT started failing, so I went to Best Buy and bought their 8GB PNY XLR8 4060. It's good so far!",
    "comments": [
      "There are no teams,they're just gpus.No need to fanboy over them,just get what's currently better for the money you plan spending.",
      "congrats on the new gpu!",
      "Return dat shit! Jk lmao enjoy your card",
      "Hope you like some ray tracing, congrats!",
      "I also recently switched to a 4060 after six years on Red Team, and it's been a similar improvement so far as well.",
      "I hadn't even considered RT as a part of it! Now I'm double stoked!!",
      "I agree but not everyone has this mature of a stance.",
      "what made u change ur mind?",
      "Mainly power consumption. 50 to 100 watts vs the AMD option. That and the fact that Nvidia has DLSS and the like.",
      "It is an Aliexpress ordered one. They called it a \"Great Wall\" cooler",
      "8gbs is fine for 1080p and 1440p still.",
      "Sweet! Congrats! It’s an excellent card for the money",
      "Super happy to see people are shitting on you for buying a 4060 like most people on Reddit decide to do! Congratulations on your new card!",
      "Right on OP! I just upgraded from a 970 GTX to a 4060ti & it is surreal!! \n\nEnjoy the new card man!!",
      "It bothers me that the cooler is bigger than the gpu…",
      "What the heck is that CPU cooler?!?",
      "fanboism is in human nature, sometimes i think ))",
      "Thanks!",
      "VSR is pretty cool too!",
      "That's a great card! Have fun ☺️"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "rtx 4060",
      "4060",
      "4060ti"
    ],
    "title": "GPU brands outside the 'big names'",
    "selftext": "I've been asking around on other subs about an upgrade from my 3050 to a 4060/4060Ti. \n\nMy local pc store has 4 different 4060 cards in stock right now. \n\nINNO3D GeForce RTX 4060 Twin X2 OC, 8GB €395.00\n\nKFA2 GeForce RTX 4060 2X 1-Click OC 8GB €405.00\n\nASUS DUAL GeForce RTX 4060 OC Graphics Card €419.00\n\nKFA2 GeForce RTX 4060 EX White 1-Click OC 8GB €435.00\n\nWhat is everyone's opinions regarding the differing brands? I understand the core GPU die is going to be the same, with the supporting components and pcb down to each manufacturer. The specs are all there or there abouts, with clock speeds within 50mhz of each other.\n\nMy 3050 is an MSI Aero ITX 8gb, and I would have always gravitated towards the big brands I know, MSI Gigabyte Asus.\n\nThe list above I would gravitate towards the Asus because I know more of them, but it's not really a good enough excuse to discard the others is it? \n\nSecondly, the 4060 runs between €395~€435.\nThe 4060Ti is $505~€609.\n\nIs that jump in price worth the bump in performance?\n\nThanks everyone!\n\nUpdate; \n\nI popped around to my local store, the guy did me a deal on an Asus 4060, €380 down from €420. \nThe only AMD cards in stock were 6500xt and 7700xt. 7700 was almost €600. \nI compared the 4060 to my outgoing 3050 in gaming benchmarks and comparative specs, and since I wanted a gpu for my daughters pc anyway, it has essentially cost me €100 to upgrade (a 3050 is €280 here). \n\nI really do appreciate everyone's responses and opinions, and I took them all with great care. Ultimately the price was the main factor, with performance of Cuda cores in Blender, or other workstation applications for example the second most important consideration. DLSS brought up the final piece of the puzzle, as it will open up the option of 1440p later on if a dual monitor setup I'm planning works out to include them, or for something like Assetto Corsa or F1, DLSS for high frame rate 1080p. \n\nThanks again everyone! ",
    "comments": [
      "The inno3d should be fine. Brand does not matter much anymore.",
      "I'll just buy the cheapest. KFA2/Galax is a big name in other region.",
      "Nvidia is strict enough that any brand that severely underperforms won't get any cores to make the cards. You cannot buy worse than a pre built OEM machine from the likes of Acer or Dell.",
      "Been really liking Sapphire, XFX and Zotac. Not common brands here in Australia",
      "From that list, if you must, go for cheapest 4060. It's low power card anyways, it's not like it needs high quality cooling.\n\nUnless you absolutely need DLSS in your life, consider RX7600xt, it's the same performance level of 4060 but it has more VRAM and I think it will age better. Another option is RX6700xt which has more VRAM and is better performer than 4060. \n\nThird option is RX6800. \n\nThe new Nvidia kinda sucks in this class.",
      "No idea how the inno3d perform, but I agree brand means little this days I say jsut read review see how the noise levels / heat and see if it works for you.",
      "To add to this, KFA2/Galax/Gainward = Palit.",
      "Thank you!",
      "Zotac is pretty trustworthy",
      "Pick something other than a 4060 or a 4060ti, nothing but disappointment awaits. I hate the rx7700xt, but at this price range, I would consider it.",
      "Thanks!",
      "Is xfx any good?",
      ">GPU brands outside the 'big names'  \n>  \n>ASUS",
      "I've used XFX RX 6600 in two PC builds and haven't had any issues yet. Been a year now",
      "Video editing is fantastic in davinci resolve but it still has a long ways to go in 3D design and production. Unreal engine is great with AMD. Blender has implemented HIP but it is way slower than Optix and generates strange artifacts in certain conditions. Many offline render engines are CUDA only.\n\nIf you do any sort of 3D art and you are serious about it, best to stick to nvidia for now.",
      "My 3070 was a Palit. No issues. I currently have a Zotac 3080, no issues.\n\nMy brother has a Palit 4090, no issues. The Palit, converted to $, is $250 cheaper than the next lowest priced 4090 which is a gigabyte wf3.",
      "The 60Ti is available in 16gb, but I'm not sure on availability for me locally. \n\nThe 70 is quite a big leap in price, if I wait another while I might be able to stretch to it.....",
      "Xfx has some good prices in my country. Friend wants to build a pc so I suggested him xfx rx6800 for 385 euro. Seems like a good deal.",
      "Thanks for that great response. \n\nI've been learning Blender with YouTube tutorials, and going from the 3200g integrated graphics to the 3050 was insane. I do it for my own hobby, my own enjoyment, but I want it to be as good as I can make it. \n\nI've not dabbled with unreal yet, I downloaded it but not even opened a new project to see the interface yet....",
      "KFA2 is actually GALAX in western countries."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "4060",
      "4060 ti"
    ],
    "title": "Historical analysis of NVIDIA GPUs relative performance, core count and die sizes across product classes and generations. Why Ada feels the way it feels!",
    "selftext": "Hi! With how divisive the pricing and value is for the RTX 40 series (Ada), I've collected and organized data (from TechPowerUp) for the previous 5 generations, that is, starting from Maxwell 2.0 (GTX 9xx) up until Ada (RTX 4xxx), and would like to share some findings and trivia about why I feel this current generation delivers bad value overall. NOTE: I'm talking about gaming performance on these conclusions and analysis, not productivity or AI workloads.\n\nIn this generation we got some high highs and stupid low lows. We had technically good products, but at high prices (talking about RTX 4090), while others, well... let's just say not so good products for gaming like the 4060 Ti 16Gb.\n\nI wanted to quantify how much of a good or bad value we get this generation compared to what we had the previous generations. This was also fueled by the downright shameful attempt to release a 12Gb 4080 which turned into the 4070 Ti, and I'll show you WHY I call this \"unlaunch\" shameful.\n\n## Methodology\n\nI've scraped the TechPowerUp GPU database for some general information for all mainstream gaming GPUs from Maxwell 2.0 up until Ada. Stuff like release dates, memory, MSRP, core count, relative performance and other data.\n\nThe idea is to compare each class of GPU on a given generation with the \"*top tier*\" die available for that generation. For instance, the regular 3080 GPU is built using the GA102 die, and while the 3080 has 8704 CUDA cores, the GA102 die, when fully enabled, has 10752 cores and is the best die available for Ampere for gaming. This means that the regular 3080 is, of course, cut down, offering 8704/10752 = 80% of the total possible cores for that generation.\n\nWith that information, we can get an idea of how much value (as in, CUDA cores) we as consumers get relative to what is POSSIBLE on that generation. We can see what we previously got in past generations and compare it with the current generation. As we'll see further into this post, there is some weird shenanigans going on with Ada. This analysis totally DISCONSIDERS architectural gains, node size complexities, even video memory or other improvements. **It is purely a metric of how much of a fully enabled die we are getting for the xx50, xx60, xx70, xx80 and xx90 class GPUs, again, comparing the number of cores we get versus what is possible on a given generation.**\n\nIn this post, when talking about \"cut down ratio\" or similar terms, think of 50% being a card having 50% of the CUDA cores of the most advanced, top tier die available that generation. However I also mention a metric called RP, or relative performance. A RP of 50% means that that card performs half as well as the top tier card (source is TechPowerUp's relative performance database). This denomination is needed because again, the number of CUDA cores does not relate 1:1 with performance. For instance Some cards have 33% of the cores but perform at 45+% compared to their top tier counterpart.\n\n## The full picture\n\nIn the following image I've plotted the relevant data for this analysis. The X-axis divides each GPU generation, starting with Maxwell 2.0 up until Ada. The Y-axis shows how many cores the represented GPU has compared to the \"top tier\" die for that generation. For instance, in Pascal (GTX 10 series), the TITAN Xp is the fully enabled top die, the GP102, with 3840 CUDA cores. The 1060 6Gb, built on GP106, has 1280 CUDA cores, which is exactly 33.3% as many cores as the TITAN Xp.\n\nI've also included, below the card name and die percentage compared to top die, other relevant information such as the relative performance (RP) each card has compared to the top tier card, actual number of cores and MSRP at launch. **This allows us to see that even though the 1060 6Gb only has 33.3% of the cores of the TITAN Xp, it performs 46% as well as it (noted on the chart as RP: 46%), thus, CUDA core count is not perfectly correlated with actual performance (as we all know there are other factors at play like clock speed, memory, heat, etc.).**\n\nHere is the complete dataset:\n\n[Full dataset on relative CUDA core count across generations](https://preview.redd.it/dztxa213uykc1.png?width=2560&format=png&auto=webp&s=fa2fe7c2fc15f4faed4dae291f77660e40b0651d)\n\n## Some conclusions we make from this chart alone\n\n1. The Ada generation is the only generation that DID NOT release the fully enabled die on consumer gaming GPUs. The 4090 is built on a cut down AD102 chip such that it only has 88.9% of the possible CUDA cores. **This left room for a TITAN Ada or 4090 Ti which never released.**\n2. The 4090, being \\~89% of the full die (of the unreleased 4090 Ti), is actually BELOW the \"cut down ratio\" for the previous 4 generations xx80 Ti cards. The 980 Ti was 91.7% of the full die. The 1080 Ti was 93.3% of the full Pascal die. The 2080 Ti was 94.4% of the full Turing die. The 3080 Ti was 95.2% of the full Ampere die. **Thus, if we use the \"cut down level\" as a naming parameter, the 4090 should've been called a 4080 Ti and even then it'd be below what we have been getting the previous 4 generations.**\n3. In the Ampere generation, the xx80 class GPUs were an anomaly regarding their core counts. In Maxwell 2.0, the 980 was 66.7% of the full die used in the TITAN X. The 1080 was also 66.7% of the full die for Pascal. The 2080 and 2080 Super were \\~64% and again, exactly 66.7% of their full die respectively. As you can see, historically, the xx80 class GPU was always 2/3 of the full die. Then in Ampere we actually got a 3080 which was 81% of the full die. Fast forward to today and the 4080 Super is only at 55.6% of the full Ada die. **This means that we went from usually getting 66% of the die for 80-class GPUs (Maxwell 2.0, Pascal, Turing), then getting 80% in Ampere, to now getting just 55% for Ada.** If we check closely for the actual perceived performance (the relative performance (RP)) metric, while the 3080 reached a RP of 76% of the 3090 Ti (which is the full die), the 4080 Super reaches 81% of the performance of a 4090, which looks good, right? WRONG! While yes, the 4080 Super reaches 81% of the performance of a 4090, **remember that the 4090 is an already cut down version of the full AD102 die.** If we speculate that the 4090 Ti would've had 10% more performance than the 4090, then the 4090's RP would be \\~91%, and **the 4080 Super would be at \\~73% of the performance of the top die**. This is in line with the RP for the 80-class GPUs for the Pascal, Turing and Ampere generations, which had their 80-class GPUs at 73%, 72% and 76% RP for their top dies. **This means that the performance for the 4080 is in line with past performance for that class in previous generations, despite being more cut down in core count.** This doesn't excuse the absurd pricing, specially for the original 4080 and specially considering we are getting less cores for the price, as noted by it being cut down at 55%. This also doesn't excuse the lame 4080 12Gb, which was later released as 4070 Ti, which has a RP of 63% compared to the 4090 (but remember, we cannot compare RP with the 4090), so again, if the 4090 Ti was 10% faster than 4090, the unlaunched 4080 12Gb would have a RP of 57%, way below the standard RP = \\~73%ish we usually get.\n4. **The 4060 sucks.** It has 16.7% of the cores of a the full AD102 die and has a RP of 33% of the 4090 (which again is already cut down). **It is as cut down as a 1050 was in the Pascal generation, thus it should've been called a 4050, two classes below what it is (!!!)**. It also costs $299 USD! If we again assume a full die 4090 Ti 10% faster than a 4090, the 4060 would've been at RP = 29.9%, in line with the RP of a 3050 8Gb or a 1050 Ti. This means that for the $300 it costs, it is more cut down and performs worse than any other 60-class GPU in their own generation. Just for comparison, the 1060 has 30% of the cores of its top die, almost double of what the 4060 has, and also it performs overall at almost half of what a TITAN Xp did (RP 46%), while the 4060 doesn't reach one third of a theoretical Ada TITAN/4090 Ti (RP 30%).\n\nThere are many other conclusions and points you can make yourself. Remember that this analysis does NOT take into account memory, heat, etc. and other features like DLSS or path tracing performance, because those are either gimmicks or eye candy at the moment for most consumers, as not everyone can afford a 4090 and people game in third world countries with 100% import tax as well (sad noises).\n\nThe point I'm trying to make is that the Ada cards are more cut down than ever, and while some retain their performance targets (like the 80-class targeting \\~75% of the top die's performance, which the 4080 Super does), others seem to just plain suck. There is an argument for value, extra features, inflation and all that, but we, as consumers, factually never paid more for such a cut down amount of cores compared to what is possible in the current generation.\n\nIn previous times, like in Pascal, 16% of the top die cost us $109, in the form of the 1050 Ti. Nowadays the same 16% of the top die costs $299 as the 4060. However, $109 in Oct 2016 (when the 1050 Ti launched) is now, adjusted for inflation, $140. Not $299. Call it bad yields, greed or something else, because it isn't JUST inflation.\n\n## Some extra charts to facilitate visualization\n\nThese highlight the increases and decreases in core counts relative to the top die for the 60-class, 70-class and 80-class cards across the generations. The Y-axis again represents the percentage of cores in a card compared to the top tier chip.\n\n**xx60 and xx60 Ti class:** Here we see a large decrease in the number of possible cores we get in the Ada generation. The 4060 Ti is as cut down compared to full AD102 than a 3050 8Gb is to full GA102. This is two tiers below!\n\n[60 and 60 Ti class](https://preview.redd.it/45ozq506uykc1.png?width=2560&format=png&auto=webp&s=2fb67fd50af3deb97ee7be981acb2531fcde0c11)\n\n**xx70 and xx70 Ti class:** Again, more cuts! The 4070 Ti Super is MORE CUT DOWN compared to full AD102 than a 1070 is to GP102. Again, two tiers down AND a \"Super-refresh\" later. The regular 4070 is MORE cut down than a 1060 6Gb was. All 70-class cards of the Ada series are at or below historical xx60 Ti levels.\n\n[70 and 70 Ti class](https://preview.redd.it/qo0j17g7uykc1.png?width=2560&format=png&auto=webp&s=6449f4d2a70e4fc367bd789ddc4d11b5c92bcd91)\n\n**xx80 and xx80 Ti class:** This is all over the place. Notice the large limbo between Ampere and Ada. The 4080 Super is as cut down as the 3070 Ti. Even if we disregard the increase in core counts for Ampere, the 4080 and 4080 Super are both at the 70-class levels of core counts.\n\n[80 and 80 Ti class](https://preview.redd.it/7ac5ha99uykc1.png?width=2560&format=png&auto=webp&s=f882aeaeb05b3e2243e7d927ee269964747b4e27)\n\nIf any of these charts and the core ratio are to be taken as the naming convention, then, for Ada:\n\n* 4060 is actually a 4050 (two tiers down);\n* 4060 Ti is actually a 4050 Ti (two tiers down);\n* 4070 should be the 4060 (two tiers down);\n* 4070 Super is between a 60 and 60 Ti class;\n* 4070 Ti is also between a 60 and 60 Ti class;\n* 4070 Ti Super is actually a 4060 Ti (two tiers and a Super-refresh down, but has 16Gb VRAM);\n* regular 4080 should be the 4070 (two tiers down);\n* 4080 Super could be a 4070 Ti (one tier and a Super-refresh down);\n* There is no 4080 this generation;\n* 4090 is renamed to 4080 Ti;\n* There is no 4090 or 4090 Ti tier card this generation.\n\nAgain this disregards stuff like the 4070 Ti Super having 16Gb of VRAM, which is good! DLSS, and other stuff are also out of the analysis. However, I won't even start with pricing, I leave that to you to discuss in the comments lol. Please share your thoughts!\n\n## What if we change the metric to be the Relative Performance instead of core count?\n\nWell then, I know some of you would've been interested in seeing this chart. I've changed the Y-axis to instead of showing of much in % of cores a card has versus the top card, now it is the relative performance as TechPowerUp shows. This means that the 1060 6Gb being at 46% means it has 46% of the real world actual performance of a TITAN Xp, the top card for Pascal.\n\n*Note that I included a 4090 Ti for Ada, considering it would have been 10% faster than the current 4090. It is marked with an asterisk in the chart.*\n\nHere it is:\n\n[Relative performance chart and trends](https://preview.redd.it/c3pboskauykc1.png?width=2560&format=png&auto=webp&s=e3c949cca348cf92f85e0da0f4695fe8a0cea6f9)\n\nAs you can see, it is all over the place, with stuff like the 3090 being close to the 3080 Ti in terms of real world performance, and something like the 2080 Ti being relatively worse than a 1080 Ti was, that is, the 1080 Ti is 93% of a TITAN Xp, but the 2080 Ti is just 82% of a the TITAN RTX. I've not even put a guide line for the 80 Ti class because it's a bit all over the place. However:\n\n* As you can see, the 4080 and 4080 Super both perform at 73% of the theoretical top card for Ada, and looks like the 1080, 2080 Super and 3080 are also all in this 72-76% range, so the expected performance for an 80-class GPU seems to be always near the 75% mark (disregarding the GTX 980 outlier). This could also be the reason they didn't add a meaningful amount of more cores to the 4080 Super compared to the regular 4080, to keep it in line with the 75% performance goal.\n* The 70 and 60 class for Ada, however, seem to be struggling. The 4070 Ti Super is at the performance level of a 1070, 2070 Super or 3070 Ti, at around 62% to 64%. It takes the Ti and Super suffixes to get close to what the regular 1070 did in terms of relative performance. Also notice that the suffixes increased every generation. To get \\~62% performance we have \"1070\" > \"**Super** 2070\" > \"**Ti** 3070\" > \"**Ti** **Super** 4070\" > \"**Ti** **Super** **Uber** 5070\"???\n* The 4070 Ti performs like the regular 2070/2060 Super and 3070 did in their generations.\n* The 4070 Super is a bit above the 3060 Ti levels. The regular 4070 is below what a 3060 Ti did, as is on par with the 1060 6Gb (which was maybe the greatest bang for buck card of all time? Will the reglar 4070 live for as long as the 1060 did?)\n* I don't even want to talk about the 4060 Ti and 4060, but okay, let's do it. The 4060 Ti performs worse than a regular 3060 did in its generation. The regular 4060 is at 3050/1050Ti levels of performance. If the RP trend was to be continued, the 4060 should have performed at about 40% of a theoretical 4090 Ti, or close to 25% more performance that I currenly has. And if the trend had continued for the 4060 Ti, it should've had 50% of the performance of the unreleased 4090 Ti, so it should have \\~40% more performance than it currently does, touching 4070 Super levels of performance.\n* Performance seems to be trending down overall, although sligthly and I've been very liberal in the placement of the guide lines in the charts.\n\nIn short: if you disregard pricing, the 4080/4080 Super are reasonable performers. The 4070, 4070 Ti and their Super refreshes are all one or two tiers above what they should've been (both in core count and raw performance). The 4060 should've been 4050 in terms of performance and core count. The 4060 Ti should've been a 4050 Ti at most, both also being two tiers down what they currently are.\n\n**So what?** We're paying more that we've ever did, even accounting for inflation, for products that are one to two tiers above what they should've been in the first place. Literally paying more for less, in both metrics: core counts relative to the best die and relative performance, the former more than the latter. This is backed by over 4 generations of past cards.\n\n## What we can derive from this\n\nWe have noticed some standards NVIDIA seems to go by (not quite set in stone), but for instance, looks like they target \\~75% of the performance of the top tier card for the 80-class in any given generation. This means that once we get numbers for the 5090/5090Ti and their die and core counts, we can speculate the performance of the 5080 card. We could extrapolate that for the other cards as well, seeing as the 70-class targets at most 65% of the top card. Let's hope we get more of a Pascal type of generation for Blackwell.\n\nExpect me to update these charts once Blackwell releases.\n\n## Sources\n\nI invite you to check the [repository](https://github.com/BeautyFades/NVIDIA-GPU-die-size) with the database and code for the visualizations. Keep in mind this was hacked together in about an hour so the code is super simple and ugly. Thanks TechPowerUp for the [data](https://www.techpowerup.com/gpu-specs/).\n\nThat is all, sorry for any mistakes, I'm not a native English speaker.",
    "comments": [
      "I did. Automod (I think) didn't like it. Either that or the mods themselves didn't lol.\n\nI've sent a message but nothing yet.",
      "You should really post this in r/nvidia",
      "I don't think a stronger 4080 would be expected. It hits the \\~75% performance target NVIDIA seems to default to. However, I believe that yes, a lack of competition has led to them putting the original $1200 price tag on it. Even the Super at $999 is just \"OK\".\n\nI didn't to analysis for AMD, a bit short on time with my job but would love to tackle it at some point!",
      "Basically Nvidia knew AMD couldn’t compete with their 40 series so they never had to release a 4090ti, but they left the door open for one just in case.",
      "And it feels like them pushing the 16-pin power connector on all cards released in the future is a guaranteed way of just cranking up that power consumption to get all the performance they need to always be on top of the competition.",
      "I doubt they'll let you post it there. They pretty much remove anything critical of the brand.\n\nI think I saw this post on hardware. Great work.",
      "Thank you for the analysis. For me these are great info to understand the product that we buy are valuable or not. I wish you can do a similar analysis when RTX5000 series are out. This give us a clear insight on Nvidia's market strategy."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "4060",
      "4060 ti"
    ],
    "title": "An Impression of Micro Center's Refurbished RTX 3080 Ti FE: Becoming a Good Deal?",
    "selftext": "Hello all,\n\nMicro Center has been selling refurbished 3000 series Founders Edition cards for some time now and while the prices were questionable previously, the prices have started to fall (finally). Here I am writing a <24 hour impression with once such card I bought, a RTX 3080 Ti FE, and the condition of the GPU. The two-slot design of this card makes this particularly enticing for SFFPC builds.\n\nThe GPU was listed as open box for $424.96, \\~$450 after tax. The GPU comes in a nondescript cardboard box with adequate foam padding. Upon inspection in the store (which you are allowed to do on open box items, not for newly packaged items) the GPU was unopened from its antistatic bag and came with a newly packaged Nvidia-branded 12VHPWR adapter. I suspect this was a purchase and return.\n\nhttps://preview.redd.it/9oa4yplq5t2d1.jpg?width=4000&format=pjpg&auto=webp&s=09d38d24eb5b7f62234442871b903c4911b7be95\n\nDuring my inspection of the card I did not see any previous fingerprints, nicks, scratches, or other evidence of damage to the card shroud, suggesting that these are factory refurbished. I also did not observe dust or residue under the GPU heatsink that I have seen with uncleaned used and mined cards. The fans look brand new without signs of use or unevenness when spinning the fan blades. The 12VHPWR connector is clean without burn marks or melted plastic. The only evidence of previous use to these cards is at the PCI-e pins on the card, which do have marks on them. These observations do not exclude the possibility that these were previously mined on but they have at least certainly been given a good clean and treatment. I have not opened up this GPU to determine the condition of the thermal pads or paste.\n\nhttps://preview.redd.it/ovc2wx7s5t2d1.jpg?width=4000&format=pjpg&auto=webp&s=198a785498ecfa7bdfa7df188f59eee14c9f20a3\n\nhttps://preview.redd.it/vvhy59ys5t2d1.jpg?width=4000&format=pjpg&auto=webp&s=3a6159f2fd294729631116b9a2610a4284edbd88\n\nhttps://preview.redd.it/ymy8jrgt5t2d1.jpg?width=4000&format=pjpg&auto=webp&s=2519a0a34e7efbc93589e446e9aa0b45a527745b\n\nUpon stress-testing the GPU stabilizes at 81-82°C, reaching \\~1900 MHz core clock and \\~9500 MHz memory clock while drawing 340W of power. There is some minor coil whine that is drowned out by the GPU fan noise, which is at levels that I would expect from a reference design. Synthetic benchmarks reach levels around the median reported scores for other 3080 Tis, which is reassuring that this particular card has not suffered much degradation (and in line with testing from other sources regarding used GPUs). In my in-game testing with Tetris Effect and Battlefield 4 at 1440p I have not noticed any graphical glitches or defects. Overall performance is what I would expect for a new 3080 Ti FE.\n\nhttps://preview.redd.it/b70sbw8u5t2d1.png?width=1372&format=png&auto=webp&s=e0d0a1656c01c12a7288a12cc29f0a7fdf8b5d06\n\nhttps://preview.redd.it/x5hdt7zu5t2d1.png?width=1024&format=png&auto=webp&s=755c42dbc98638382d71e64da85a912dfa2ae351\n\nThese GPUs come with hassle-free 90-day warranty but can also have 2 or 3 year purchase protection plans where Micro Center will give you the amount in store credit. Whether or not the additional warranty purchase is worth it is up to user discretion. (I personally think that the imminent risk of hardware failure is low given that these cards are past the initial part of the \"bathtub curve.\")\n\nThe other closest competitors in this price point (after open-box discount in my case) and performance are the $400 4060 Ti 8GB, $550 4070 12GB, $600 4070 Super 12GB, and $480 RX 7800 XT 16GB. The pure rasterization performance, higher memory bandwidth on the 3080 Ti, and DLSS2 support are very compelling, especially for 4K gaming. High power draw and thermals is a big downside to these cards--but this is user-dependent, and as someone who doesn't game 24/7, the math doesn't add up in terms of power consumption. For me, at \\~4hr gaming/wk, it would take me 6.5 years for the electricity cost to surpass the price difference between the 3080 Ti and the cheapest but similarly performing 4070 Super, which could be further improved with undervolting. The other downside is the lack of support for frame gen and DLSS3, which also depends on the user as to whether these features are useful.\n\nI believe that the prices of this card will continue to drop given the high inventory in some stores. With further discounts or open-box deals I believe these refurbished GPUs should be given serious consideration for folks looking into FE cards for their build.\n\nEdit: Reddit's being dumb, images re-uploaded.",
    "comments": [
      "At $424 that is an absolutely incredible deal.",
      "That card is still worth 550-600 to a lot of people. Steal.",
      "Nice deal OP!\n\nI run a power modded 3080ti - really the only thing holding the FE is the size of the cooler, it will run hot all the time. They have a ton of OC headroom.\n\nHas been serving me great on a neo 4k for over a year and with free framegen mods, I really am not feeling and FOMO towards the 4000 cards.",
      "I wish but that deal was a pricing error by Newegg and is not valid.",
      "I love my 3080ti FE. I have no reason to upgrade to a 40xx series. I’ll wait for a 50xx or 60xx series. I only play Diablo games anyways lol \n\nOp, excellent review of this gpu.",
      "Love this. Buying used is the move. Feel like this sub, buildapc, and honestly most of Reddit tries to upsell everyone. \n\nWhen the 50 series comes out in very interested in seeing the price of 3080s.",
      "Considering what we were paying in 2020, it’s dirt cheap.",
      "Well from what I have heard and seen from my GPU it just runs cooler completely it doesn't even get anywhere near as hot as my 3080. My 3080 would get hot to the touch and my 4080 doesn't even feel warm. Both were triple fan units. My 3080 would even heat my room it got so warm which is the main reason I sold it because I couldn't even get inside to change the thermal paste and I wanted something cooler and my 4080 aorus master is the best gou I have ever owned. It has the same cooler and heating the 4090 uses though so it's cooling solution is much better plus the 40 series is just cooler all around.",
      "Seems like there’s an anticipatory drop in prices of used cards for the new gen, then a spike when new cards are unavailable. Once supply stabilizes they’ll settle into their 2-gen old price point until it happens again the following generation…hard to think of a 3080 coming in below $300 but it’s probably going to happen fairly soon",
      "There was some deals on brand new 4070 super for about $450 in the past week on buildapcsale. I personally would just return and try to grab these.",
      "That's a steal OP! Enjoy your hard find. Personally I'm looking to upgrade to 5070 next year, but tbh not sure if that's the best idea lol since even my current 3070 is still doing very well at 1440p 60+ fps with the help of DLSS. Got it used for $250 from a miner lol. These used 30 series cards are such good deals.",
      "Pretty solid buy at $425 like you paid - but your conclusion is spot on…better to get a current gen card overall. https://www.techpowerup.com/review/nvidia-geforce-rtx-4080-super-founders-edition/31.html (3080 Ti not shown but lets give it the 3090 numbers - it’s a cut down 3090 but it is close).\n\nThese are $500 - I’d rather spend $100 more to get a brand new with warranty RTX 4070 SUPER. The 90 day warranty is all you get on the 3080 Ti unless you spend considerably more for the MC warranty upgrade.\n\nThe used market for current gen is solid, too. Open box or used / refurbished is a goldmine.\n\nPaid $685 for a RTX 4070 Ti SUPER used and just bought an RTX 4090 for $1300 - all shipped / post tax.",
      "I just bought a 3080 FE from my local MC in Columbus this past weekend and it seemed in very good condition temp wise and hot spot all look good while running occt and fur mark but the memory temps slowly creep to 100c even while gaming and after I UV the card to about .850 mV at 1850mhz the mem temps still rise to 100c. I’m wondering if I got a dud that was used for mining..",
      "About to do the GPU-trade-in on the 3050 I bought from them during the gpu-depression, just gonna go up to a 3060ti and buff it out. I'm only gaming at 1080p but I'm hungry for those last few frames in games like Helldivers 2.",
      "I got a 4080 from a 3080 and the 40 series is remarkably cooler which is nice for people who live in hot environments. And the performance gain was great.",
      "I undervolted mine to 0.825V/1820MHz and it does decrease power consumption to \\~280W under load in games. Temps are about the same but I'm able to run the fans at a lower speed. Nvidia used pretty crappy thermal pads from what I understand on the FE cards so I wouldn't be surprised if that were consistent on these refurbished models.",
      "Really? Better fan? Better thermal displacement?",
      "Both AMD and Nvidia are going to have  lot of cards out on the street when $300 3080 ti / and 6950xts hit the market en mass this holiday."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "rtx 4060",
      "4060",
      "4060 8gb",
      "rtx 4060 8gb"
    ],
    "title": "RTX 3060 12 GB vs RTX 4060 8GB. Which should I get?",
    "selftext": "Hi, i am upgrading from a reaaaally old pc so it doesn't matter if its worth it or not. \n\nI can have only these two for reasons that are person-specific and extremely top secret so no other recommendations please.\n\nI game at 1080p and i'am fine with 60 fps, I really am okay with it.\n\nHowever i like having highor ultra setting and i really like having max draw-distance, anti-alliasing etc. Which one should i get for playing todays games at 60 fps and 1080p. Which one to get?",
    "comments": [
      "4060 is faster and it has dlss 3. i own a 3060 and theres only like 3 games thats gotten past 8gb of vram. it should have more vram but 8gb wont be a problem for 1080p.",
      "Don't listen to these consumerist shills. FG is totally a trap for lower tier 4060/ti card. You already need high fps (baseline 60fps) to notice any meaningful smoothfulness. Also extra vram load on using FG. You can get a RTX 3060 12gb for very cheap plus you can use the 12gb for AI models too! Save for next gen. No reason to buy now so late into 40 series.",
      "4060 will be the better choice if you are going for 1080p gaming",
      "4060/TI is a dogshit gpu in itself. if you are going to buy it brand new you will massively overpay. 400-500 eur for a 1080p card is ridicilous. at this point consider AMD 6750XT or 7700XT to have a stronger value card than this. at least you buy a card that is capable of running 1440p and 4k maybe.",
      "3060 because even at 1080p you can go above 8gb of vram. The people recommending the 4060 because of FG apparently forgot (or don't know) that FG uses even more vram which is not good at all if the card only has 8gb.",
      "A 6700xt",
      "They are referring to frame generation.",
      "Absolutely.  Even without DLSS 3, the 4060 (non-ti) benchmarks 20-ish% higher than the 3060.  And in DLSS 3, and it's huge.\n\nAnd yeah, the lower amount of VRAM might come into play at some point, but that's probably quite a way into the future.",
      "I'm sorry to say but to my eye even at 4k FSR 2 Looks terrible. Which is odd because I used FSR 1.0 at 4k for RE Village and it looked quite good. XeSS and DLSS are the only good upscalers right now imo",
      ">even better if you can get more vram\n\nWhat does that mean?",
      "Just download some vram",
      "I had the same conundrum a few weeks ago when upgrading, and with both cards at almost the same price, I went with the 4060. In most benchmarks it was better; has better dlss support; also way lower power usage.\nEven if more games start requiring 12g vram, the 3060 is a slower card overall",
      "Yeah I don't know why so many people are so ok with having to turn textures of all things down, they have a massive impact. \n\nI'm fine turning down shadow res or something else if need be, but textures can make or break a game. It's the reason heavily modded Skyrim still looks great. Play with stock textures, and all the other mods in the world will struggle to make the game look as good.",
      "4060. I have it. It’s good.",
      "Used 3070",
      "Texture quality is the most noticeable and less taxing upgrade to overall picture quality, if you have enough VRAM of course",
      "You mean the only 30 games that support FG?  The 3060 wins hands down on 95% of pc games. And now that FSR3 is out with it it easily destroys the 4060.\n\nSad to see that such a crappy card needs DLSS and FG in order to keep up. \n\nI'm assuming you bought a 4060. I feel bad for you bro. Don't worry, you can get a used 3060 for pretty cheap.",
      "The absolute state of the GPU market.",
      "3060. Idgaf what people say about DLSS 3, you will max out that 8gb real fast once you upscale and that 3060 will pull ahead.",
      "4060 is faster, draws less power, and supports new features like DLSS FG and AV1. There are a few scenarios where the 12GB card will perform better and have better frametimes, but not many at 1080p, just avoid ultra texture setting."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "rtx 4060",
      "4060",
      "rtx 4060 ti",
      "4060 ti"
    ],
    "title": "GeForce RTX 5060 Ti Review Megathread",
    "selftext": "# GeForce RTX 5060 Ti reviews are up.\n\nhttps://preview.redd.it/o8tj1mcz97ve1.jpg?width=3840&format=pjpg&auto=webp&s=9db65293bf4f1bb1a65229395bed6f01a05a496f\n\n# Below is the compilation of all the reviews that have been posted so far. I will be updating this continuously throughout the day with the conclusion of each publications and any new review links. This will be sorted alphabetically.\n\n# Written Articles\n\n# [Babeltechreviews](https://babeltechreviews.com/rtx-5060-ti-16gb-review/)\n\n>The **Nvidia RTX 5060 Ti** is a competent midrange GPU that brings incremental improvements over its predecessor, especially when leveraging **DLSS 4**. It performs well at **1080p and 1440p**, and offers solid gains if coming from a **30-series or older** card. Content creators also benefit from enhanced NVENC support for faster 4:2:2 video encoding. Its compact design, low power draw, and frame generation capabilities make it a practical choice for mainstream gamers and small form factor builds.\n\n>However, for a **new generation card**, the performance gains are modest—typically around **10–15% over the RTX 4060 Ti**—making it a hard sell unless priced at or below MSRP. If prices drift north of $449, **AMD’s RX 7700 XT or 7800 XT** become better buys with more VRAM and stronger raster performance. Ultimately, the RTX 5060 Ti is a **fine choice at the right price** but fails to impress as a major step forward. Wait for discounts or consider stepping up to an RTX 4070 Super or AMD 7800 XT if your budget allows.\n\n# [Digital Foundry Article](https://www.eurogamer.net/digitalfoundry-2025-nvidia-geforce-rtx-5060-ti-16gb-review)\n\n# Digital Foundry Video\n\n>With our testing complete, the RTX 5060 Ti 16GB is a tricky card to judge, given that its performance differentials can swing substantially based on the game and even game scene tested. \n\n>Based on *our* game selections though, the card is in the same territory as the RX 7800 XT, with an average 22 percent lead over the RTX 4060 Ti 8GB at 1440p. That's one of the biggest gen-on-gen gains that we've seen going from Ada Lovelace to Blackwell, but it's worth considering that the RTX 4060 Ti didn't really shift the needle when it came to beating its predecessor. \n\n>For those upgrading from prior cards in the same class, there's around a 37 percent increase over the RTX 3060 Ti from 2020. Meanwhile, versus the 2019 vintage RTX 2060 Super, you're getting double the performance. In both cases, the DLSS 4 feature set is appealing and I'd consider the RTX 5060 Ti a fine upgrade there. \n\n>Elsewhere, the RTX 5070 is significantly faster than the RTX 5060 Ti 16GB - to the tune of a mighty 38 percent. My results also see the RTX 4070 beat the RTX 5060 Ti by 11 percent, though overclocking can make up most of the difference in many games. \n\n>Based on the RTX 5060 Ti's overall performance, the card is solid enough but hardly spectacular - meaning that price comes into focus. Looking at dollars per frame based on MSRP, it's disappointing that the RTX 5070 offers better value - and I can't help but think there ought to have been a single 16GB or even 12GB model at $399. (Despite the 128-bit bus, 3GB memory modules do exist that would have unlocked 12GB as a potential option - though it's unclear whether they're available in the quantities and prices needed for a budget GPU.) \n\n>So as we keep saying, the RTX 5060 Ti is a bit tricky. The 8GB card on mixed benchmarks will provide better value than the 16GB version overall and compares more favourably to the RTX 5070. On the flipside, we just can't recommend the 8GB card given how often we're running into VRAM issues with many games, especially upon launch. \n\n>The 16GB version is the one to have then, but with the 5070 offering 35 to 43 percent better performance at \"only\" 28 percent more money, you're again funnelled towards the higher-priced offering - though $120 extra is a significant step up in this sector of the market. I just wish that Nvidia understood that value is supposed to increase the further down the stack you go - not decrease. \n\n>The PCIe situation is also not great, with the 5060 Ti's 8x lanes translating into some noticeable performance degradation on older PCIe 3.0 motherboards due to bandwidth limitations. While the majority of users will be using these cards with modern motherboards with PCIe 4.0 or 5.0 slots, these more budget-oriented cards are more likely to be used with similarly low-end or just antiquated motherboards compared to higher-end GPUs. Our testing shows up to a 20 percent performance drop in [Indiana Jones and the Great Circle](https://eurogamer.net/indiana-jones-and-the-great-circle-review) at 1080p, with less sizeable double-digit percentage drops in [F1 24](https://www.eurogamer.net/games/f1-24) and single-digit percentage drops in [Black Myth: Wukong](https://www.eurogamer.net/games/black-myth-wukong). \n\n>Ultimately, there are question marks over value, but the RTX 5060 Ti is worth taking a look at. \n\n# [eTeknix Article](https://www.eteknix.com/asus-prime-oc-rtx-5060-ti-graphics-card-review/)\n\n# [eTeknix Video](https://www.youtube.com/watch?v=fR5phLkePYA)\n\n>So, a bit of a tangent, but back on track. The 3060 Ti was a good card when it came out, but is definitely showing its age, and with the 5060 Ti sitting 29% ahead overall, there’s definitely a viable option to buy it, especially as 3060 Ti’s are still holding their price for some weird reason. The 4060 Ti however, sees the 5060 Ti around 19% faster and while, and I’m sure NVIDIA will be happy for me to say this, it has multi-frame generation upscaling which works some kind of voodoo magic, but people still aren’t sold on it, but the tide is turning somewhat.\n\n>If NVIDIA came in with a GPU that offered a 30% generation uplift or higher in rasterisation, and higher in raytracing gen on gen, plus MFG, then yes, I think it would be much better received, but that’s not the case, and instead, if you’re already on a 40 series card, I can’t say there’s an argument to upgrade to any 50 series, with maybe the exception being the RTX 5090, but that’s in a whole different league. Beyond that, people are looking for a reason to upgrade and I don’t know about you, but I’m getting a bit bored of saying things like “It’s good but…” or “You should buy it if you can get it for $X”. The argument is wearing a bit thin.\n\n>I will say that the 5060 Ti on paper, if you take pricing out of the equation, does come across as a good performer. It even sits ahead of the 3070 Ti, and that’s what we want to see. The other issue is AMD. At that price point, AMD are the better buy, but again, and I swear this will be the second to last time I say it, but AMD cards are inflated too, so I’ll leave you with one piece of advice, and it’s a big one.\n\n>Regardless, the 5060 Ti is good, but it feels like it’s much the same as we’ve seen with the rest of the stack. If the price is right, and you’re not already on a 40 series card, then there’s an argument, but if the price isn’t right and/or you’re already on a 40 series card, then maybe give this one a miss, unless MFG really tickles your fancy.\n\n>For now, that’s going to wrap up another 50 series GPU review. With a not-so-easy-to-understand conclusion, I’d like to think we’ve at least shown you the facts, and that you can make an educated decision as to what to do from there based on that all-important word. Price.\n\n# [Guru3D](https://www.guru3d.com/review/nvidia-geforce-rtx-5060-ti-16gb-review/)\n\n>The RTX 5060 Ti is built around a rasterizer shading engine and includes 4608 CUDA cores. It stems from the RTX 50 series, which introduces a new generation of Ray Tracing and Tensor cores positioned close to the shader engine. These RT cores never pause as they produce vivid lighting, shadow, and reflection effects. Although Tensor cores sometimes seem tricky to measure in terms of raw benefits, their influence becomes obvious when paired with DLSS3 and the updated DLSS4. The 50 series represents more than a mere upgrade; it stands as a leap forward that meets different gaming requirements. Whether someone is immersed in 2K (2560x1440) gaming or venturing into the realm of 4K (3840x2160), the RTX 5060 Ti adapts when you enable DLSS4/MFG. In baseline performance (depending on where and what you measure), expect reference cards to be \\~15% faster than the 4060 Ti, and OC models closing in at perhaps 20% for the fastest locked and configured models.\n\n>The RTX 5060 Ti steps onto the stage, immediately ingraining gamers with very decent frame rates. Sure, it might lag slightly behind some close competitors when it comes to standardized shading, but overall, the graphics performance is solid enough. What's interesting is that the improvement isn't uniform across all games. One title might skyrocket with huge frame rate gains, while another enjoys just a modest boost. But the real star of the show is NVIDIA’s heavy investment in artificial intelligence, deep learning, and neural shading technologies. Activate DLSS4 with frame generation set at 4x (if possible), and the difference is obvious right away—it feels like catching a glimpse of gaming’s future. Yet, there's a lingering question among gamers: Is the community ready to fully embrace these AI-powered enhancements? Technology evolves so quickly these days, and some players are hesitant to fully rely on machine learning to boost their gaming visuals and performance. However, early adopters aren't holding back; they're diving right in. As more players see what DLSS4 can achieve, particularly in new, visually demanding games, the excitement is sure to spread. There's no doubt about it—DLSS4 is impressive, and early performance data backs this up. Gamers using ultra-wide or 1440p monitors will especially appreciate how every pixel gets pushed to its limits. And those chasing ultimate 4K experiences will also find plenty to love. By combining the raw power of the RTX 5060 Ti with DLSS4's dynamic upscaling, games can now achieve frame rates that were once considered impossible. While some might label the RTX 5060 Ti as just a mainstream GPU, it’s actually much more versatile. It comfortably handles high-end AAA games without breaking a sweat, making it perfect for gamers who don't always need every setting maxed but still want smooth, impressive performance. Additionally, content creators and professionals using GPU-heavy tasks like video editing or 3D rendering will find the 5060 series quite capable. Its powerful CUDA cores speed up rendering, giving creators valuable extra time. Of course, true enthusiasts might already have their eyes set on the higher-end 5070 Ti or 5080 models, but the RTX 5060 Ti hits a better price point for most PC gamers\n\n>Priced around the $429 mark, the NVIDIA GeForce RTX 5060 Ti seems promising enough. Whether it becomes your next favorite GPU depends on how expensive it'll sell once it hits the shelves. But overall it's a product series that we can recommend if you're coming from the RTX 3000 or equivalent graphics card era.\n\n# [Hot Hardware](https://hothardware.com/reviews/msi-and-pny-geforce-rtx-5060-ti-review)\n\n>Like some of the other members of the [GeForce RTX 50 series](https://hothardware.com/reviews/nvidia-rtx-blackwell-architecture-overview), the new GeForce RTX 5060 Ti offers a modest upgrade in rasterization performance over its previous-gen counterpart If we don't factor in newer technologies and DLSS 4 with multi frame generation, the GeForce RTX 5060 Ti is about \\~20% faster than the GeForce RTX 4060 Ti. For the millions of gamers still using lower-end or older \"xx60\" class cards, however, GeForce RTX 5060 Ti would be significant upgrade. Not only is the GeForce RTX 5060 Ti much faster than older cards for gaming, but it's got better display output support, a more capable media engine, and its power requirements are modest enough that most folks won't need a PSU upgrade either -- just stick with the 16GB version if you've got the budget. 8GB cards are going to be much more limited moving forward.\n\n>With an MSRP of $429, the GeForce RTX 5060 Ti's introductory price comes in a bit higher than 8GB GeForce RTX 4060 Ti cards, but below 16GB variants that were introduced later. Assuming gamers will be able to get their hands on GeForce RTX 5060 Tis for prices approaching MSRP, it represents a good value and a significant upgrade for gamers and creators still rocking RTX 30 series, or older, cards in the same class. As we've mentioned with the other GeForce RTX 50 series cards, the GeForce RTX 5060 Ti is faster, more capable, and more power-efficient than its previous generation counterpart and anyone that likes tinker will have plenty of fun overclocking. Without leveraging DLSS 4’s multi frame generation, its generational performance uplift is smaller than what we’ve seen from NVIDIA in the past, though.\n\n# [Igor's Lab](https://www.igorslab.de/en/nvidia-geforce-rtx-5060-ti-16-gb-in-test-economical-consumption-surprisingly-fast-but-not-with-8gb/)\n\n>The GeForce RTX 5060 Ti 16 GB tested today marks the current entry of NVIDIA’s Blackwell architecture into the mid-range segment and takes on the established competition with the new GB206-300 chip. While the 8 GB version can hardly be meaningfully tested in modern scenarios due to the limited memory configuration, the 16 GB version is the focus of all meaningful analyses. The GPU is based on four 32-bit memory channels and uses the clamshell method to expand capacity, allowing a total of eight 2 GB GDDR7 modules to be used. Despite identical bandwidth to the 8 GB version of 448 GB/s at 28 Gbps memory clock, this results in improved suitability for memory-intensive applications, but without an increase in memory bandwidth.\n\n>The gaming performance of the RTX 5060 Ti 16 GB is convincing in current titles, especially when DLSS 4 and Frame Generation are activated. In a direct comparison with the RTX 4060 Ti 16 GB, the new card is 23 percent ahead on average with AI functions enabled, and still around 17 to 18 percent ahead without factory overclocking. The strong increase in minimum frame rates (P1 Low) is remarkable, where up to 36 percent lead was measured. This leads to a significantly more stable gaming experience, especially at WQHD resolution. Efficiency has been noticeably improved, as performance is clearly higher with comparable power consumption. Under full gaming load, the average power consumption is between 155 and 165 watts, while the power limit of 180 watts is generally not exhausted. Even under extreme conditions, the card remains thermally and electrically stable.\n\n>My test with the MSI GeForce RTX 5060 Ti Gaming Trio showed that high-quality board partner designs can exploit the full potential of the GPU. The card comes with factory overclocking, which results in around 2 to 3 percent more performance than a reference card. The cooling design with four heatpipes, a solid copper block and a fin array with a high air flow rate ensures low GPU temperatures of around 63 °C in gaming mode. The memory modules remain below 68 °C, also thanks to the generous cooling through the backplate and via separate pads. Acoustically, the card remains very quiet at around 31 dB(A) under load, with only a minimal audible whirring of the coils. The power supply via a total of eight phases delivered stable voltage values, even with manual overclocking.\n\n>All in all, the GeForce RTX 5060 Ti 16 GB can be characterized as a modern mid-range GPU, which is primarily aimed at users who do not want to do without the latest technologies such as DLSS 4, Reflex 2 and ray tracing, but do not want to spend 500 euros or more on a graphics card. With an RRP of 429 US dollars, the card is significantly lower than the RTX 4060 Ti 16 GB at market launch and also offers more memory, better efficiency and a modern architecture. It is a particularly attractive option for upgrades from the RTX 3000 or RX 6000 generation. The 8 GB version, on the other hand, should be viewed critically, as it quickly reaches its limits, especially in WQHD and memory-intensive scenarios, and cannot provide a complete picture of the performance of this GPU generation, even if you can perhaps save a one-off 50 USD. In other words, a card with two faces, where the only slightly cheaper offer is clearly the worse one. In view of the different markets, NVIDIA won’t care about this, only the customer should really be sensitized.\n\n# [KitGuru Article](https://www.kitguru.net/components/graphic-cards/dominic-moass/nvidia-rtx-5060-ti-16gb-review-ft-gigabyte-palit/)\n\n# [KitGuru Video](https://www.youtube.com/watch?v=ZLjLrDYcY70)\n\n>**Nvidia's RTX 5060 Ti** is the latest in a long line of Blackwell GPUs to hit the market, arriving in both 8GB and 16GB flavours. I was only sent 16GB models for this review and it didn't sound like 8GB variants would be particularly prevalent at retail upon launch – probably for the better considering a 8GB GPU launching at $379 sounds like madness to me.\n\n>But back to the 5060 Ti 16GB, it's a curious GPU that epitomises the term ‘mixed-bag'. On the one hand, rasterisation performance is solid for 1080p and even 1440p gaming, though the latter resolution becomes more of a challenge if you stick to Ultra settings.\n\n>However, compared to the RTX 3060 Ti, we're only looking at a 31% uplift for 1080p rasterised gaming – and that's a GPU which launched at the [end of 2020,](https://www.kitguru.net/components/graphic-cards/dominic-moass/nvidia-rtx-3060-ti-founders-edition-review/) almost five years ago! It's clearly underwhelming and exemplifies the struggle for meaningful performance increases that this market segment has been crying out for.\n\n>That said, in the context of *today's* market, I don't think the RTX 5060 Ti 16GB is a bad product. After all, it's still delivering circa 15% gains over its predecessor, the RTX 4060 Ti 16GB, which actually sounds decent compared to some other Blackwell GPUs like the [RTX 5070](https://www.kitguru.net/components/graphic-cards/dominic-moass/nvidia-rtx-5070-review/), which is just 1-5% ahead of the RTX 4070 Super. As much as we may want larger generational gains, that's just not the reality for the 50 series given it remains on TSMC's 4N node, so I do think we need to be realistic with expectations.\n\n>It also helps that the RTX 5060 Ti 16GB is launching with at the lower price point of £399/$429. The 4060 Ti 16GB initially hit the market at £479, though it did later drop below £450, but even against that figure we're looking at an 11% price drop. There is of course a fair bit up in the air around PC hardware prices right now, but I do at least have *some* confidence that this price point will be achievable after seeing the RTX 5070 in stock at MSRP over the last couple of weeks. Heck, it's even been on sale for [*less* than MSRP](https://www.kitguru.net/components/graphic-cards/matthew-wilson/rtx-5070-drops-below-msrp-in-uk/), so we'd hope for more of the same this time around.\n\n>Of course, the RTX 3060 Ti comparison gets much more favourable when looking at ray tracing performance, largely thanks to having double the VRAM. 8GB cards these days just cannot deliver certain experiences when ray tracing is enabled, resulting in the 5060 Ti 16GB being multiple times faster in titles like Indiana Jones and the Great Circle.\n\n>You could make the case that the RTX 5070 is the biggest threat to the RTX 5060 Ti 16GB – it's readily in stock at MSRP, offers performance that's some 35-40% better depending on the game, and it's not *too* much more expensive, sitting at £529. That said, it's priced high enough to still be out of reach for many, in which case the RTX 5060 Ti 16GB becomes the obvious choice around the £400 mark – for now, at least.\n\n>So no, it hasn't blown me away, and you can easily argue that the product itself is fairly underwhelming. But in this market segment, Nvidia's RTX 5060 Ti 16GB is our new go-to recommendation – just don't get the 8GB model, please.\n\n>A final word on the two cards tested today. **Palit's Infinity 3** is a capable model, it's clearly built to hit the MSRP and as such is fairly light on features, but it runs quiet and cool, so I can't really complain. **Gigabyte's** **Aorus Elite** is a much more premium offering, sporting RGB lighting, dual-BIOS and a metal backplate, while the cooler is more sophisticated, resulting in even lower thermals and noise levels than the Infinity 3. I don't have a confirmed price for it yet, but it's almost certainly going to come in *well* above MSRP, so as good as it is, be careful not to overpay as the 5070 could make more sense if the pricing creeps closer to £500.\n\n# LanOC\n\n>TBD\n\n# PC World Article\n\n# [PC World Video](https://www.youtube.com/watch?v=qF1xYjf3h_Q)\n\n>TBD\n\n# [Techpowerup](https://www.techpowerup.com/review/asus-geforce-rtx-5060-ti-tuf-16-gb/)\n\n>For this launch we've updated our test setup again and retested all comparison cards with the newest drivers. We also updated the BIOS on our 9800X3D and added several new games, like our first RT exclusive title Indiana Jones, and Path Tracing is now an additional section in all reviews. At 1440p, with pure rasterization, without ray tracing or DLSS, we measured a 13% performance uplift over the RTX 4060 Ti 16 GB, which is quite small. At 4K, the increase is bigger, reaching 20%. A gen-over-gen improvement of 13% is not much, but at least it's more than RTX 5080 which only got 8% at 1440p. The RTX 5090, 5070 Ti and RTX 5070 did better, giving you an extra 20% at 1440p. Compared to the RTX 3060 Ti from two generations ago, the performance uplift is only 31%, usually we expect a doubling in performance over two generations. With these numbers the RTX 5060 Ti ends up a bit faster than AMD's aging Radeon RX 7700 XT, 11% behind the RX 7800 XT, which is much more expensive of course. NVIDIA's RTX 5070 non-Ti is a whopping 39% faster. The RTX 5060 Ti does not catch last generation's RTX 4070 either, which remains 16% ahead. If you've seen our manual overclocking results, there is a ton of headroom, like +15%, so I have no idea why NVIDIA clocked their card so low, especially considering the fact that it's underperforming by so much.\n\n>The RTX 5060 Ti is a fantastic choice for gaming at 1080p Full HD, especially with a high-refresh-rate monitor. It also has enough muscle for 1440p gaming in most games at maximum details. Some of the most demanding titles, or when RT is enabled will require you to use DLSS though to get a good gaming experience.\n\n>Thanks to its factory overclock, the ASUS TUF OC gains an extra 4% in real-life performance over the base RTX 5060 Ti, which is small, but every bit helps of course. Competing cards achieve similar performance levels, with all cards hitting +3% or +4.\n\n>Power consumption of the RTX 5060 Ti is good. While some other Blackwell cards had quite high power consumption in idle, multi-monitor and media playback, this isn't a problem at all here. The extra memory chips do increase the power draw slightly, but it's not enough to worry about. In gaming, I noticed that all models reach around 160 W without ray tracing, which is well below the default power limit of 180 W. However, when ray tracing is enabled, power usage increases and occasionally reaches the power limit—still, the RTX 5060 Ti is definitely not power starved.\n\n# The FPS Review\n\n>TBD\n\n# [Tomshardware](https://www.tomshardware.com/pc-components/gpus/nvidia-geforce-rtx-5060-ti-16gb-review)\n\n>Nvidia's RTX 5060 Ti 16GB delivers a solid combination of performance for the suggested $429 base MSRP. However, as we've seen with every other GPU launch of the past five months, retail prices can be much higher. It's impossible to separate performance from pricing when looking at the overall value of a GPU, and the only thing concrete that we can point to are the MSRPs. Except those can run the gamut from being at least moderately accurate to being completely nonsense.\n\n>When the 4060 Ti 16GB came out a month after the 8GB variant, it felt severely underwhelming. Neither version was really designed to handle 4K gaming, but that was the only place where we measured a significant difference in performance. Two years later, things haven't changed *too* much, but the reduced $50 price gap (on paper at least) between the 5060 Ti 8GB and 16GB makes the 16GB a far easier recommendation. In fact, we'll go so far as to question why Nvidia even felt the need to create an 8GB version.\n\n>Yes, 8GB will be cheaper, and it will also be more limited due to the lack of VRAM. There are games (Indiana Jones and the Great Circle) where you can't even try to run ultra settings on an 8GB card. That's an Nvidia promoted game that simply crashes to desktop with a video memory error when you try higher settings on the 4060 and 4060 Ti 8GB GPUs, along with a bunch of other previous generation RTX cards.\n\n>The good news with the 16GB card is that memory bandwidth has improved thanks to GDDR7, so that it's not likely to hit VRAM capacity or bandwidth limitations. 56% more bandwidth than the 4060 Ti is a sizeable improvement. The fact that most games only show about 15% higher performance indicates that GPU compute is the limiting factor more than bandwidth, however.\n\n>But as we've already said numerous times, the price difference could very easily end up being more than $50. And factors like on again/off again tariffs, limited supply, product demand, and more could push the 16GB card to the point where maybe it won't be the better choice. The RTX 5070 still serves as a ceiling on how much more the 5060 Ti 16GB can realistically cost before it's \"too much,\" but with 5070 cards often listed for $700 or more, there's a lot of wiggle room right now.\n\n>Price and availability will be the key determiners of how good the 5060 Ti 16GB looks, and that will also vary by market. Europe and Asia might end up with a much different GPU landscape than the U.S. as far as graphics card values go.\n\n>What we can say is that the 5060 Ti 16GB isn't a massive generational improvement, but it *is* an improvement. It's also *supposed* to be less expensive than its 4060 Ti 16GB predecessor. Those are both good things, and stuff like neural rendering, DLSS 4, and Multi Frame Generation are merely extras that you can use as you see fit. Now we just wait to see what today's launch looks like, how quickly the 5060 Ti models sell out, and how high prices go.\n\n>Our score of 4-stars represents a \"best guess\" on what the 5060 Ti 16GB will look like in the current GPU market. Obviously, prices for all graphics cards, new and used, are all over the map. If the RTX 5060 Ti 16GB costs 50% more than the MSRP, and other cards *don't* show a similar markup, that makes it a worse value and a less desirable card and it would deserve a lower score. We can't predict where things will go, so pay more attention to the performance and real-world pricing than the single score that we've assigned, because uncontrollable factors play into the overall package.\n\n# [Computerbase - German](https://www.computerbase.de/artikel/grafikkarten/nvidia-geforce-rtx-5060-ti-16-gb-test.92119/)\n\n# [HardwareLuxx - German](https://www.hardwareluxx.de/index.php/artikel/hardware/grafikkarten/65938-geforce-rtx-5060-ti-mit-16-gb-im-test.html)\n\n# [PCGH - German](https://www.pcgameshardware.de/Geforce-RTX-5060-Ti-16GB-Grafikkarte-281131/Tests/Release-Review-Preis-kaufen-Benchmark-Specs-1470373/)\n\n# [Elchapuzasinformatico - Spanish](https://elchapuzasinformatico.com/2025/04/msi-geforce-rtx-5060-ti-16-gb-gaming-trio-oc-review/)\n\n\\--------------------------------------------\n\n# Video Review\n\n# [Der8auer](https://www.youtube.com/watch?v=NQ5HOxQFKkg&pp=ygUIZGVyYmF1ZXI%3D)\n\n# Digital Foundry Video\n\n# [eTeknix Video](https://www.youtube.com/watch?v=fR5phLkePYA)\n\n# [Gamers Nexus Video](https://www.youtube.com/watch?v=Cskegn1-D7s)\n\n# [Hardware Canucks](https://www.youtube.com/watch?v=ltc1Lzjfp-c)\n\n# [Hardware Unboxed](https://www.youtube.com/watch?v=B6qZwJsp5X4)\n\n# [JayzTwoCents](https://www.youtube.com/watch?v=vBVLnN5UGvk)\n\n# [KitGuru Video](https://www.youtube.com/watch?v=ZLjLrDYcY70)\n\n# [Level1Techs](https://www.youtube.com/watch?v=hMOqQS7ItXE)\n\n# Linus Tech Tips\n\n# [OC3D Video](https://www.youtube.com/watch?v=0R2eGg4wRvk)\n\n# Optimum Tech\n\n# [PC World Video](https://www.youtube.com/watch?v=qF1xYjf3h_Q)\n\n# [Techtesters](https://www.youtube.com/watch?v=AGBkWeGyUc4)\n\n# Tech Yes City",
    "comments": [
      "Wild seeing Gamers Nexus and HUB videos being downvoted so hard in this sub right now.\n\nOk maybe not wild. Fanbois out in full force today.",
      "Media blackout by Nvidia not sending samples and blocking partners from sending them.",
      "Yeah. Bad price to performance is now drama and sensationalism. You need to get out of the house more often.",
      "Huh. Hey, where are the reviews of the 8gb model?",
      "No, Nvidia simply did not send out 8GB cards at ALL.",
      "In what world is 15% uplift gen on gen good? Is there a good reason why this card comes with an 8GB VRAM version? What data is being twisted?",
      "I’m sorry I don’t speak fanboy. I’m still waiting for the data that was twisted for outrage. Take your own advice and stop drinking NVIDIA kool aid. What do you gain by defending shady practices from a multi trillion corpo is beyond me.",
      "No, reviewers couldn't even get them from board partners... Linus tried contacting everyone he could and got no response or told they don't have any to give him..\n\nI am sure he'd have bought one if he could have for the review to be able to do stuff with it but again, they are completely none existent if large tech media channels can't get them.",
      "Can anyone explain why there are cards at near MSRP and then others that are priced like 25% higher and practically 5070 price?",
      "lol nobody is buying these poorly performing, gimped cards and it's beautiful XD\n\nSo many stores have overstock. They're gonna be stuck on the shelves for months.",
      "I love Reddit hot takes like.. having cards to buy is a bad thing when we want it to be. Then 2 months later it shows up on the Steam survey. And later becomes the #1 card.",
      "It’s not really a bad price, considering that it would be equal to a 3060 Ti after adjusting for inflation. The issue is that actual performance has not increased enough in the 4.5 years since the 3060 Ti.",
      "Bro, that guy must work for Nvidia. 😂",
      "A color TV would cost today’s $14K USD in 1950 , but a 65 OLED TV is less than $2K. Inflation on GPU is comparatively less than other products like locomotives and groceries. This inflation is a stupid excuse. 25% faster than a 5 year old 3060 Ti is bad no matter how you flip it. Even NVIDIA knows that and hence the price reduction of both 4060 Ti and 5060 Ti. They even ordered AIB’s to not include 8GB version in review kits! Talk about scummy..",
      "So once more good card bad price",
      "OP, TechSpot publishes Hardware Unboxed reviews in written form: https://www.techspot.com/review/2979-nvidia-geforce-rtx-5060-ti-16gb/",
      "There are Dual and Triple fan models, plus OC and non-OC models of both.  So there is going to be a wide spread of prices.",
      "TechPowerUp has one up. \n\nPerformance at 1080/1440 seem pretty much identical",
      "I’m all for critiquing the card, the price point, etc, but let’s not exaggerate. These will still sell super well, especially since they’re the entry point cards for the 5000 series and less informed people (the majority of market) will just buy them.",
      "When you can buy a 5070 at £499 and some 5060Ti's cost more than that, it seems a bit odd for anybody to go for the 5060Ti."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "rtx 4060",
      "4060",
      "4060 8gb",
      "rtx 4060 8gb"
    ],
    "title": "RTX 4060 8gb or RTX 3060 12gb (long term gaming)",
    "selftext": "I'm thinking of upgrading my GPU for gaming to a RTX 3060 or RTX 4060  however I'm not sure which one to get as the 3060 has more vram. \n\nI know the 4060 has better performance but will the lower amount of vram mean it'll perform worse on future games or even some games now? \n\nIf anyone has any advice that be great.",
    "comments": [
      "blud thats 250+ dollars, thats almost the cost of a 4060 itself",
      "An RX 6700XT is significantly better value then both.",
      "Memory is more an issue at higher resolutions. Both the 3060 and 4060 are not designed to perform well at higher resolutions. Yes there are some edge cases where a 8gb limit has issues in some games today but those cases are currently few and far between.  \n\n\nI think what you need to consider is that neither of these cards are going to hold up for long term gaming. They both already struggle with higher resolution, and with more graphically demanding titles. In Hogwarts at 1080p ultra, the 4060 is only delivering 63fps average ([source](https://www.techspot.com/articles-info/2701/bench/Hogwarts_1080p-p.webp)). The next game that follows this will push this card even further and hitting 60 on ultra probably won't be possible. This is a worst case scenario today, but there are a ton of other titles where it's barely above 80, and you can bet next year most games will probably be closer to 60 on this card.  \n\n\nTo be clear I'm not saying these cards are bad and no one should buy them. They are just not long term cards, you're going to want to upgrade much sooner with either of them.",
      "If you can save up to get a 4070 I’d recommend that. 12 gigs and a 40 series. It does have the $50 price drop",
      "I love/hate how a lot of these comments go hard on throwing more money at the problem.\n\nMaybe OP has a strict budget.\n\nStill, I have to admit that for long term gaming with the current market options and game requirements, any X060 card is going to be quite underwhelming to put it nicely, not even on the long run but over the current year or the next one.\n\nGoing long term with a 60 card leaves you watching even consoles having way better graphics than you on triple A games, and for the investment you already  made on a whole PC... that leaves a rather bitter taste IMO.\n\nIf you really need to decide rn between one or the other, I would go with the 4060. If waiting and saving up for a 4070 is an option though, I would strongly suggest waiting.\n\n\n... So yeah, throw more money at the problem if possible. It's an expensive hobbie :c",
      "4060 is the better option. Disregard VRAM memes. 4060 outperforms 3060 by 18% even at 1440p.",
      "Heck, this person could get a used 3070, and it would have better performance than that 4060. Not to mention it would be cheaper.",
      "Both are bad\n\nNvidia is bad for entry level graphics cards\n\nBuy an AMD",
      "4060 ofc (for 1080p, right?), VRAM hysteria is overblown plus it doesnt matter how much VRAM you have if card is slow and doesnt have horsepower to make use of it.",
      "This is the answer. 3060/4060 are not worth it.",
      "I upgraded my kids' PC from a 3060 to a 4070 and the difference is insane.  You'd regret buying a 3060 today IMO.",
      "Yeah pretty much. Nvidia has really been struggling with their budget GPUs in terms of price to performance. Basically anything under the RTX 4070 is not worth buying unless you can somehow get them really cheap.\n\nNvidia effectively gave AMD the market for free, and now Intel is another company worth considering. For better or worse, this is how it is now.",
      "You should never think about “long term gaming” with a 60 series gpu. But whatever you want, it’ll be shitty at relatively the same time regardless of memory capacity.",
      "Overall i agree as well, however, are you sure 18% increase in raw performance without FG is correct here?",
      "With 4060 you have access for DLSS 3.5 and given this card is a 1080p card you could get good improvements from it. If you can wait a bit, maybe a used 4070 non super could arrive at a good price.",
      "I'd look at a 6700 XT or 6750 XT if I were you. If you can stretch to around $420-$430, a 7700 XT is great",
      "Still brings to 8GB problem, and 3070 is definitely too fast for 8GB",
      "It's still cheaper and better performing than the 4060.\n\nThe basic point is that that video card the 4060 Is just not a good option for the consumer. Lance , my vote of probably the most predatory card that was launched last year from the consumer standpoint.",
      "8GB is not as big of an issue as people tend to claim. You are not gaming in 4K on a 3070.",
      "I am, and if you are ok with 45 to 60 ish fps it can actually be a pretty good experience on a lot of games.\nOf course it's not the way to plan a build but it's actually pretty fine if you end up on that spot for some reason (I got a sweet deal on a 4k IPS HDR10 monitor when I had a 1080p)."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "rtx 4060",
      "4060",
      "4060 ti"
    ],
    "title": "GeForce RTX 4070 Review Megathread",
    "selftext": "# GeForce RTX 4070 Founders Edition (and MSRP AIB) reviews are up.\n\n[GeForce RTX 4070 Founders Edition](https://preview.redd.it/ja810v70yita1.png?width=720&format=png&auto=webp&s=1d565b7032c0967e5d4a093e26c8c7c7bfe28fe1)\n\n# Below is the compilation of all the reviews that have been posted so far. I will be updating this continuously throughout the day with the conclusion of each publications and any new review links. This will be sorted alphabetically.\n\n# Written Articles\n\n# [Babeltechreviews](https://babeltechreviews.com/rtx-4070-review-dlss-3s-amazing-potential-for-a-reasonable-price/)\n\n>This has been an enjoyable exploration evaluating the new RTX 4070 FE. Overall, it is the best 40 series value for your money if the current adoption rate of DLSS and DLSS 3 continues. The performance gain is stunning. Without this technology, we can compare the RTX 4070 to the RTX 3080 from the previous generation with very distinct differences. Nvidia has improved performance with supplemental tech like DLSS 3, the architecture, cooling, and most of all, the pricing.  \n>  \n>The RTX 4070 is compact and amazingly efficient compared to the RTX 30 series and its 40 series brothers. The idle fan stop is huge for us, and support for AV1 encoding is stellar for a lot of streamers at this price.  \n>  \n>The RTX 4070 performed above the RTX 3080 in most cases and well above the RTX RTX 3070. The gap widened significantly with frame generation/DLSS 3 – So much so that this is a no-brainer. However, this is not a “wow” with the raster performance jump over the previous generation. Instead, the RTX 4070 is more efficient, more compact, and has much better features especially if you are still on a 10-series card. This is a worthy point in time with a card that is finally available at a reasonable price as a poster child for the generational leaps Nvidia is making with its technology and DLSS 3.  \n>  \n>There is no early adopter woe here as there are many AAA titles to enjoy – right now – with DLSS 3 enabled, unlike with ray tracing at its launch. However, If DLSS 3 means little to you, we would hesitate to recommend upgrading from an RTX 3080 to an RTX 4070. However, the RTX 3070 user base will see enough significant performance gains to be able to make this a worthwhile consideration.  \n>  \n>For a couple hundred dollars more you could buy an RTX 4070 Ti or a current AMD offering – but there is no card currently in this class and price that comes close to competing. The value of your dollar here will make any gamer happy. Especially at 1080p and 1440p, this card is a beast ready to serve your needs.\n\n# [Dexterto](https://www.dexerto.com/tech/nvidia-geforce-rtx-4070-founders-edition-review-2105006/)\n\n>The RTX 4070 is notable for two things – cost per frame and power efficiency. Much like the RTX 40-series GPUs before it, the wattage efficiency gains when compared to the 3080 are nothing short of staggering. You get around the same levels of performance at 200W on the RTX 4070, versus the RTX 3080’s 320W.  \n>  \n>The RTX 4070’s costs-per-frame analysis also tells an interesting story of the higher-end RTX 40-series graphics cards thus far. To calculate this, we added up the average benchmarked framerates of all GPUs in our standardized tests and divided it by the MSRP costs of the GPU in order to get an average frame-per-dollar ratio.  \n>  \n>RTX 4070 – 3.0 frames per-dollar  \n>  \n>RTX 3080 – 2.3 frames per-dollar  \n>  \n>RTX 4070 Ti – 2.7 frames per-dollar  \n>  \n>RTX 4080 – 3.4 frames per-dollar  \n>  \n>Interestingly, we also compared this against the RTX 3080, if you were to pick one up brand-new today for $699, it ended up at 2.3 frames per dollar. While the RTX 4070 may be more expensive than its previous-generation counterpart, adjusted for inflation, the MSRP cost of the RTX 3070 would have been around $582 today.  \n>  \n>We were unable to add the RTX 4090 to the cost-per-frame calculations due to benchmarks not being as standard with our current testing system, therefore it would not be fair to compare the two.  \n>  \n>For those who have an older RTX 10 or 20-series graphics card, the RTX 4070 is an attractive upgrade, and offers great performance at 4K, 1440p, and 1080p. It is essentially an RTX 3080 with some extra VRAM and DLSS 3 goodies crammed into it. However, if you already own an RTX 30-series GPU, the jump in performance will be pretty disappointing.  \n>  \n>The RTX 4070 is yet another solid entry into the RTX 40-series lineup. It offers an accessible entry point and access to future-forward features like DLSS 3. However, its pricing remains key. At $599, it is a competitive GPU, at any price above that, you may wish to look at other options on the market.\n\n# [Digital Foundry Article](https://www.eurogamer.net/digitalfoundry-2023-nvidia-geforce-rtx-4070-review)\n\n# [Digital Foundry Video](https://www.youtube.com/watch?v=LVovUcHnwws)\n\n>The concept of value has come to define the latest generation of graphics cards, with consumers concerned and angry that this new generation of GPUs doesn't offer the same balance of price and performance as the last generation. Perhaps the blame for this can be placed on Nvidia's profit margins - but it's equally the case that we're living through a period of shocking inflation and a far higher cost of production on cutting-edge semiconductors.  \n>  \n>The RTX 4070 does compare favourably in terms of price/performance vs the RTX 3070 - you're typically getting in the region of 30 percent of extra performance for 20 percent more money, in addition to 50 percent more memory and access to DLSS 3 frame generation. It's just a shame that the 'more money' part of that sentence is in there - but this is not the first time we've had a price hike on a 70-class GPU. In fact, it happens more often than not. There was a real world price increase between GTX 970 and GTX 1070, and it happened again with the arrival of RTX 2070 which retailed for a baffling $529 back in 2018.  \n>  \n>Up against the RTX 3080, the new card is generally on-par or just a touch slower, but does have the odd surprise or two up its sleeve and of course, there's more memory, improved efficiency and DLSS 3. There is an increase in value then, but it's clearly nowhere near as dramatic as the RTX 30-series cards mentioned here were back in the day. I mean, the 3070 delivered nigh-on 2080 Ti performance - the $500 product replaced the last-gen $1200 offering. By contrast, we now have a $599 GPU effectively replacing last-gen's $699 offering, which represents a significant slowing of progress.  \n>  \n>Of course, the discussion here does overlook how consumers are likely to consider the latest graphics card generations. An owner of an RTX 30-series graphics card will likely hold onto it for a year or two more. It's the users of 10-series and 20-series GPUs that will be taking a look at this new offering. There, at least, there are big improvements to gaming performance. Even without factoring in DLSS 3, there's a circa 2x increase in performance (though gains vary more significantly when RT is factored out of the equation) - and unless AMD can come up with something more compelling, it's the defacto upgrade for owners of GTX 1070/Ti, RTX 2070 and 2070 Super and perhaps even the RTX 2080 - which launched at $699. We'll add that card to the benchmark tables in due course, but it's only a touch faster than the 2070 Super.  \n>  \n>It's perhaps difficult to rave about the RTX 4070 in the same way we did about so many of the Ampere cards of the last generation, but we are at least starting to see proportionately more value returned to the user as we move down the RTX 40-series stack. And to be clear, RTX 3080-level performance is still pretty incredible. A $600 GPU is basically giving you rasterisation performance around 70 to 80 percent better than a PS5 or Xbox Series X, and that's before you include DLSS, improved RT performance and frame generation. While we've benched this card primarily with 1440p high frame-rate gaming in mind, take a look at the 4K results, especially with DLSS 2 and DLSS 3 factored in - this is still capable of some exceptional performance on an Ultra HD panel.  \n>  \n>The RTX 4070 won't set the world on fire and it's hardly a love letter from Nvidia to the gamer - but it's certainly a capable piece of kit. In a world where RTX 3080 continues to hold its original 2020 pricing, the cost of the RTX 4070 is fine - if not exceptional - and its no-fuss form factor and frugal power consumption are positives too. And with the arrival of Cyberpunk 2077's RT Overdrive upgrade, there is the sense that PC gaming is once again reaching for the stars, and with decent settings management, RTX 4070 can still deliver a worthwhile experience.\n\n# [Guru3D](https://www.guru3d.com/articles-pages/geforce-rtx-4070-review,1.html)\n\n>The RTX 4070 is a graphics card that can waves in the gaming world due to its rendering quality and gaming performance when combined with DLSS3 frame generation. The RTX 4070 provides a bit more value for the money. It is a well-balanced card that can handle gaming at 4K resolution, although it is targeted towards WQHD. Compared to AMD's offerings, the Nvidia GPU struggles to keep up with the Radeon RX 7900 XT, but it still has many positive aspects. DLSS (3) and ray tracing features work exceptionally well, AMD cannot match Nvidia in this regard. The RTX 4070 is an excellent option for gamers who play at UWHD, QHD, and even UHD monitor resolutions.  \n>  \n>The old rasterizer engine breaks right through the previous limit of extreme performance. The RTX 40 series now has a new generation of Ray tracing and Tensor cores that are more powerful. So, do not let the specific RT and Tensor core counts fool you; it's all about how much performance one unit offers. Since they are close to the shader engine, they have become more efficient, which shows. Tensor cores are harder to measure, but from what we have seen, everything seems to be in good shape, as DLSS3 shows exciting values  \n>  \n>The GeForce RTX 4070 founder edition graphics card offers nice performance and visual quality, adding to that improved power efficiency and low thermals, making it an energy-friendly option. It effortlessly handles high-resolution gaming and creative workflows, the VRAM capacity (12GB) we deem is very acceptable. When choosing between the RTX 4070 and Radeon RX 7900 XT, it's important to consider factors such as raytracing performance and DLSS3, which the RTX 4070 excels at. However, a Radeon RX 7900 XT offers much faster rasterizer engine performance with an additional L3 cache, making it a strong(er) contender for the RTX 4070. The GeForce RTX 4070 is priced at $200 lower, so perhaps it offers more value. In this respect, we feel the card is competing more with the 6800/6900 XT than the 7900XT, though. Performance-wise, you can compare the card with RTX 3070 Ti / 3080 performance levels depending on where you measure. Overall, the RTX 4070 series edition is an interesting option for those looking for a visually appealing graphics card, as the founder editions sure look nice, also. This graphics card has plenty of oomph up-to even Ultra HD gaming (especially with DLSS3 / Frame generation enabled) with the option for a mild overclock. As such it comes recommended. Pricing, however, remains a sore point\n\n# [Hot Hardware](https://hothardware.com/reviews/nvidia-geforce-rtx-4070-review)\n\n>The MSRP for GeForce RTX 4070 series cards starts at $599, which is on-par with the RTX 3070 Ti, but $100 more than the RTX 3070. At that price point, the GeForce RTX 4070 will be battling a wide array of cards currently, from the 3070 Ti and 3080, to the [Radeon RX 6800 and 6900 XT](https://hothardware.com/reviews/amd-radeon-rx-6800-big-navi-gpu-review), give or take a few bucks depending on deals, rebates, and what have you. There’s definitely stiff competition in this price bracket and looking back through the GeForce RTX 4070’s performance it’s not likely to compel anyone with an upper-midrange GPU from the previous gen to upgrade.  \n>  \n>However, for owners of the GeForce RTX 20-series or older Radeons, the GeForce RTX 4070 is a relatively affordable way to get into an Ada-based graphics card, and better enjoy the benefits of ray tracing, DLSS 3, and other benefits of the architecture, like AV1 encoding. In our graphics and game tests the GeForce RTX 4070 was clearly superior to the RTX 3070 Ti, which is where you’d expect it to land, but it shined a bit brighter in the compute and creator workloads.  \n>  \n>For 1080p or 1440p gamers, the [GeForce](https://hothardware.com/tags/geforce) RTX 4070 is a relatively affordable, power-friendly way to score a current-gen GPU with a leading edge feature set. Its 12GB of memory may be a limiting factor in the future as games get more complex and visual fidelity increases, but as it stands today the GeForce RTX 4070 offers huge leaps in efficiency and good performance. If you’re looking to upgrade a previous-gen system with a modern GPU or are building a new, mainstream system, the GeForce RTX 4070 is a solid mid-range option.\n\n# [Igor's Lab](https://www.igorslab.de/en/will-ada-be-suitable-for-the-masses-geforce-rtx-4070-founders-edition-12-gb-review-with-200-and-220-watt-power-limit/)\n\n>The GeForce RTX 4070 is a highly interesting mid-range graphics card as long as you ignore the price. Therefore, NVIDIA has put some pressure on the board partners to also offer at least one model with a price that corresponds to the RRP. Of course, the shortcomings in the technical implementation, including the limitation of the power limit to 200 watts, can be argued about. Of course, you can easily do without RGB, light metal and other optical extras if the price is right.  \n>  \n>To play reasonably performant games, the 200 watts are also easily enough, because you can reach or even beat a GeForce RTX 3080 10GB, of course depending on the game and resolution. That’s the good side. However, the up to 20 watts more of an overclockable card are quite well invested money, because the 10% more energy can be converted into up to 10% more performance in some situations, such as DLSS, when the tensor cores are also fully utilized. However, the advantage in terms of screening performance is much smaller. However, the effects of the higher power consumption are also more noticeable in the Min FPS than in the pure average and that’s where it gets interesting again.  \n>  \n>The GeForce RTX 4070 is an excellent card in Full HD when it comes to highest frame rates and is also well suited for WQHD. However, smart upscaling will have to be considered in Ultra HD at the latest, and that’s where DLSS comes into play. Meanwhile, games like “The Last of Us Part 1” (TLOU) even subjectively look better in Ultra HD with DLSS than native Ultra HD. NVIDIA can definitely use its advantages here, which DLSS 2.x also offers purely optically. However, if a game supports DLSS 3.0 and you would be stuck in the unplayable FPS range without Super Sampling, then this can even be the lifeline to playability. You can’t improve latencies with it, but not every genre is as latency-bound as various shooters. For TLOU, I would have liked to see DLSS 3.0, but you can’t have everything.  \n>  \n>You get all the advantages of the Ada architecture starting at 659 Euros (MSRP cards) and could be quite satisfied with that in the context of the current price spiral, if it weren’t for the memory expansion and the narrow memory interface, which I had already noted in the GeForce RTX 4070 Ti. Yes, that might be enough for WQHD at the moment, but games like TLOU unfortunately show us that resources are being used more and more wastefully and the memory could be full faster than you can say pug. We can already see: So there is always something. Thus, you can currently still get along very well with it under WQHD, only in Ultra HD there are games that already consider the given 12 GB too puny due to various HD texture packs. This can be seen either way, but it could have been avoided if the AD104 had been designed differently. Two memory controllers are simply missing here, but who am I telling.\n\n# [KitGuru Article](https://www.kitguru.net/components/graphic-cards/dominic-moass/nvidia-rtx-4070-review-ft-gigabyte-and-palit/)\n\n# [KitGuru Video](https://www.youtube.com/watch?v=Zi3hdm_JZ8U)\n\n>Overall efficiency of the RTX 4070 is in-line with the RTX 4070 Ti. On average, at 1440p we found the non-Ti card drew 194.1W, so just slightly below its rated 200W TGP. That's about 80% of the power draw of the 4070 Ti, while offering 82% of the performance, so the 4070 is just a hair more efficient overall. It's not able to match the RTX 4080 in terms of performance per Watt, but against the RTX 3080, it offers similar performance for over 100W less power, resulting in a 67% boost to efficiency compared to that last-gen GPU.  \n>  \n>All told, my opinion on the RTX 4070 is generally pretty similar to that of the RTX 4070 Ti – it's a reasonable GPU, but it's hard to be more effusive than that. On the one hand, it offers similar gaming performance to the RTX 3080 10GB, but with a couple extra gigs of VRAM, significantly less power and with the bonus of DLSS 3 support.  \n>  \n>Then again, an extra 15-20% performance over the RTX 3070 Ti is hardly much to get excited about, in fact it is pretty lacklustre it has to be said. That's on top of an 11% price hike over the £529 MSRP for the 3070 Ti, negating a lot of that performance improvement. Cost per frame is just not moving forward from the previous generation, in fact several deals on RDNA 2 GPUs result in a *better* cost per frame for the likes of the RX 6700 XT and RX 6800 XT than what we get from the RTX 4070, though admittedly RDNA 2's ray tracing performance is a fair bit behind the 4070.  \n>  \n>We do have to wonder about the longevity of the 12GB framebuffer too. A lot has happened in the last few months and several titles – including The Last of Us Part 1, Hogwarts Legacy, and Forspoken – are now causing real problems for 8GB cards, including the 3070 and 3070 Ti. As more games shift beyond the cross-gen period, having large amounts of VRAM is only going to be a benefit as developers leverage what's available on the Series X and PS5. It will be interesting to look back in 2-3 years and see how the land lies with the 4070 and its 12GB VRAM.  \n>  \n>Ultimately, if you're hanging on to a 10-series or perhaps 20-series GPU and want to spend around £600 on a new card, right now the 4070 is probably your best bet – though we are yet to see what RDNA 3 will do in this price bracket. The 4070 won't go down as a classic, owing to the relatively weak performance improvement versus the previous generation, but it's an *OK* GPU. No more, no less.\n\n# [LanOC](https://lanoc.org/review/video-cards/8702-nvidia-rtx-4070-founders-edition)\n\n>The latest in Nvidia’s Ada Lovelace architecture wasn’t a big departure from the RTX 4070 Ti above it, mostly just cut down and with its clock speeds lowered. But with that what stood out to me more than anything in my testing was the power usage and overall efficiency of the card. You have performance that is competing with last generations RTX 3080 but power draw at its peak and averaged across a variety of tests lower than the RTX 3060 Ti. The performance-to-power comparison is only better with Nvidia’s highest-end cards, the 4090 and 4080. That efficiency helped them drop back down to a traditional card size, not the crazy size of the 4080 and 4090 Founders Editions. Even with the smaller card, however, the RTX 4070 Founders Edition impressed on all of its cooling tests and noise tests. Nvidia hit the sweet spot for performance, size, power, noise, and temperatures, and with that, this could be a great SFF card.  \n>  \n>The overall performance comparison is a lot more nuanced. Like I said before the 4070 does run right with the RTX 3080, in fact at 1080p in our tests it was a touch faster with the 3080 pulling away as the resolution goes up. But like with the RTX 4070 Ti, it is the ray tracing and DLSS performance that is most impressive. In games that supported it, the 4070 was about to step up and be very capable at 4k while running ray tracing even. To complicate things though, the competition (AMD) isn’t on the same level when it comes to ray tracing and their version of DLSS (FSR) but when it comes to raw rastering performance the 6800 XT which is priced less than the RTX 4070 is faster and the 6950 XT which is most expensive but still close in pricing is even faster than that.  \n>  \n>I’ve kind of touched on it already but let's get to pricing. The RTX 4070 Founders Edition and other stock-clocked cards will be hitting stores tomorrow at an MSRP of $599. On the AMD side, the 6800 XT is currently selling for $539-$579 and the 6950 XT are running $629-$679. On the Nvidia side, the cheapest non-refurb RTX 3080 on Newegg is $699 with most at $898 and higher. So if we only look at the RTX 3080 the new RTX 4070 is a great deal especially once you add in DLSS 3 which isn’t available on the 3080. The AMD cards however complicate things. For raw raster performance, those are a great value in comparison, but that is before you put a value on the ray tracing performance and DLSS. Overall I would love to see the RTX 4070 come in lower competing with the 6800 XT. But if ray tracing and DLSS/FSR are your main focus and I do believe in the future those are going to be key to gaming performance the RTX 4070 starts to become an option.\n\n# [OC3D Article](https://www.overclock3d.net/reviews/gpu_displays/nvidia_geforce_rtx_4070_founders_edition_review/1)\n\n# [OC3D Video](https://www.youtube.com/watch?v=oBy2Zoi_HME)\n\n>Whenever you look at a new graphics card purchase the main factor to consider is nearly always price. Nothing in your rig will give you such an obvious and immediate return than spending a little extra on your GPU. Faster drives eventually get slowed down by the OS. Faster processors only really show up in specific, heavy-loading scenarios. But graphical horsepower, that's instant, immediate and clearly noticeable in every gaming scenario.  \n>  \n>The pricing of graphics cards in recent years has been higher than Everest thanks to supply issues and the global financial crisis. Additionally some of the newer cards have so much new technology inside them that there is a level of early adopter cost built in too. The newest addition to the Nvidia 4000 series, the RTX 4070, is priced much more competitively than a lot of their recent launches, partly because the world has somewhat got back to normal, but also partly because Nvidia have designed it more for those of you who game at 1440P rather than 4K.  \n>  \n>That doesn't seem as crazy as it might. 4K gaming, whilst it's the buzzword for people trying to sell you new hardware, is still a rarity for the majority of people and 1440P is actually the sweet spot, where you get much higher visual fidelity than 1080P, without requiring a trip to Fort Knox to obtain the funding necessary to do it justice. Many people have a 4K panel and tolerate 40 FPS because that's somehow 'better' than running a less-kudos inspiring 1440P but getting 70 FPS average.  \n>  \n>For the sake of equality and an apples-to-apples comparison we tested the RTX 4070 FE on both 1440 and 4K, and our graphs are sorted by average FPS in the 4K resolution. That's something to bear in mind if you're the type of person to merely glance at our graphs. Even so we think the RTX 4070 is much closer to the RTX 4070 Ti than we expected it to be, especially given the price difference. Although it's not the be-all and end-all of gaming tests, we think the fact that this card, specifically not aimed at 4K gamers, still got over 60 FPS in Cyberpunk 2077 with RT and DLSS turned on speaks volumes about how good the underlying performance of the card is.  \n>  \n>If you've been itching to get on the DLSS 3 bandwagon with a 4000 series card then the Nvidia RTX 4070 FE is the perfect sweet-spot between price and performance. Very close to the RTX 4070 Ti but with a much more attractive MSRP of £589 and thus wins our OC3D Gamers Choice Award.\n\n# [PC Perspective](https://pcper.com/2023/04/nvidia-geforce-rtx-4070-founders-edition-review/)\n\n>NVIDIA has once again released a xx70 GPU that is about the equal of the previous-gen xx80 card, and it offers better RTX and DLSS support as well. The MSRP is $100 less than the RTX 3080 launch price of $699, but $599 for a xx70 card is still not going to have people dancing and singing in the streets. Or on TikTok or whatever. It has been more than 2.5 years since the RTX 3080 launched, after all.  \n>  \n>Inflation is real, people. I too remember a time when $600 bought a flagship. But we don’t live in that world anymore, and unless AMD releases a Radeon RX 7000 Series competitor at this price level we are simply looking at what the **current generation** has to offer at $600. The state-of-the-art, if you will. And art is subjective. Money is not.\n\n# [PC World](https://www.pcworld.com/article/1781139/nvidia-geforce-rtx-4070-review.html)\n\n>The GeForce RTX 4070 delivers exceptional 1440p gaming performance in even the most strenuous games, with best-in-class ray tracing performance if you want to turn those cutting-edge lighting features on. Nvidia’s killer software stack enhances every aspect of the GPU, from creation to streaming to gaming, with features like [Nvidia Reflex](https://www.pcworld.com/article/393646/tested-how-nvidia-reflex-can-make-you-a-better-esports-gamer.html), Broadcast, [RTX Video Super Resolution](https://www.pcworld.com/article/1525299/nvidia-rtx-video-super-resolution-tested.html), and [DLSS 3 Frame Generation](https://www.pcworld.com/article/1348123/nvidia-geforce-rtx-4090-review-ada-lovelace.html#toc-5) truly improving your day-to-day experience. If you found yourself nodding along to our [defense of the 4070 Ti by a 1440p gamer](https://www.pcworld.com/article/1502698/a-defense-of-the-geforce-rtx-4070-ti-by-a-1440p-gamer.html), you’re the prime audience for the $200-cheaper RTX 4070.  \n>  \n>The RTX 4070 also supports AV1 encoding, unlike previous-gen GPUs, while its incredible power efficiency let Nvidia make its Founders Edition model nice and tiny. It’ll fit into most any system.    \n>  \n>It’s not a slam dunk though. Nvidia’s decision to equip the RTX 4070 with a 192-bit bus and 12GB of memory prevent us from being able to recommend it for long-term 4K gaming, especially with memory requirements only rising in modern games. (We applaud the bump in memory from 8GB to 12GB, but $600 graphics cards really should have 16GB or more in 2023.)  \n>  \n>As I said right up top, the $599 GeForce RTX 4070 is the only current Nvidia 40-series graphics card potentially worth your money aside from the flagship RTX 4090. That’s because Nvidia didn’t jack its price as painfully as the [$800 RTX 4070 Ti](https://www.pcworld.com/article/1444726/nvidia-geforce-rtx-4070-ti-review.html) and [$1,200 RTX 4080](https://www.pcworld.com/article/1379747/nvidia-geforce-rtx-4080-tested-5-things.html), *not* because it’s a good value. The $599 RTX 4070 is $100 more than its predecessor, and $100 less than the RTX 3080. In most games, the RTX 3080 trades blow or is a handful of frames faster than the RTX 4070. Sure, the RTX 4070’s power efficiency and DLSS 3 Frame Gen features are deeply impressive indeed, but in raw gaming performance, Nvidia’s 40-series continues to offer stagnant gen-on-gen value, 2.5 years after the 30-series launched. Not every game will support features like DLSS or FSR.  \n>  \n>Buy the GeForce RTX 4070 if you want a reasonably sized, highly efficient 1440p gaming beast, complete with access to all the latest and greatest Nvidia software features—and if you’re willing to spend $600 on a graphics card like that. Avoid it for long-term 4K usage, and [comparison shop before you buy](https://www.pcworld.com/article/416006/the-best-graphics-cards-for-pc-gaming.html) as last-gen graphics cards may offer better value.\n\n# [TechGage](https://techgage.com/article/mid-range-ada-lovelace-nvidia-geforce-rtx-4070-gaming-review/)\n\n>Admittedly, we’d find ourselves more excited about the RTX 4070 if it did in fact retain the RTX 3070’s pricing. We remember the days when someone could spend the same general amount on a GPU from one generation to the next, and see a substantial upgrade. Today, it feels like all of that improved performance is locked behind a price premium instead.  \n>  \n>That all said, while we wish the price was a little more alluring to cater to more people, the RTX 4070 does have a few great things going for it over that last-gen RTX 3070 Ti. For starters, the frame buffer has increased 50%, to sit at 12GB, and (surprisingly?), the bandwidth is identical to the model above (both RTX 4070 Ti and RTX 4070 share the same 192-bit bus). It’s a hot topic right now that 8GB of VRAM isn’t enough to feel super-comfortable with in 2023, so it’s crucial that this RTX 4070 did in fact ship with 12GB.  \n>  \n>Another part of the upgrade comes by way of the Frame Generation feature in DLSS 3. While previous-gen cards can take advantage of other DLSS 3 updates, Frame Generation is exclusive to Ada Lovelace, and as we’ve seen in the few tests where we utilized it, the differences can be huge. We mentioned the caveat about retaining a good baseline FPS when using FG so input latency is kept to a minimum, and this RTX 4070 delivered that quite easily in *Cyberpunk 2077*, and *Dying Light 2*.  \n>  \n>Path-traced games, such as the newly-updated *Cyberpunk 2077*, are going to be best played on a GPU like the RTX 4070 at 1080p, although *Portal with RTX* is suitable enough for 1440p, given that it’s not a twitch shooter (note: we played through all of *Portal with RTX* ahead of this launch, and can say it’s definitely worth checking out).  \n>  \n>Whether or not the RTX 4070’s price tag feels worth it to you will depend on what you’re after. It’s *really* good to see 12GB included with it, and the Frame Generation feature is already supported in a whack of games, and is likely to become more prominent over time. We figure these two things factored into NVIDIA’s thinking on pricing most.  \n>  \n>That said, after looking over pricing ahead of this article, we found ourselves having a difficult time even deciding wihch competitive GPUs to include. Since we had yet to test Intel’s Arc in gaming, we wanted to have it included, and on the AMD side, we looked for the GPU nearest in price. The thing is, though, that last-gen Radeons are finding themselves well under SRP, while NVIDIA’s tend to hover *over* them.  \n>  \n>The Radeon RX 6950 XT tested here didn’t just beat out the RTX 4070, but also the RTX 4070 Ti. The downside? No Frame Generation, of course, or the leading upscaler, DLSS. The GPU also happens to use an additional 200W, *and* is much larger. But, it’s a good option when looking at the bang-for-the-buck angle, and it is sure nice to have those.  \n>  \n>We’re not sure whether or not NVIDIA will have a tough sell with the RTX 4070, but aside from its price, it packs a lot of performance in its modest frame. It uses reasoanble amounts of power (especially in comparison to the top-end Ada), and perks like Frame Generation alongside the 12GB frame buffer make it a worthy option.\n\n# [The FPS Review](https://www.thefpsreview.com/2023/04/12/nvidia-geforce-rtx-4070-founders-edition-video-card-review/)\n\n>The GeForce RTX 4070 is price competitive with the last generation’s GeForce RTX 3070 Ti. In our performance testing, the lowest performance uplift was around 13% over the RTX 3070 Ti, but for the most part, it was closer to 20% on average, with some outliers like 41% in one game. There was a slightly larger advantage over the GeForce RTX 3070, about another 10% added to that, or 30% total on average. The results actually are closer versus the Radeon RX 6800, as it was closer in several games in performance.  \n>  \n>When we enabled Ray Tracing the GeForce RTX 4070 did outperform everything very well. It allowed a playable experience with Ray Tracing at 1440p, except for one game, but that was expected. When things are not as playable, enable DLSS, and it’s more than fine. The GeForce RTX 4070 is flexible by allowing DLSS 3 Frame Generation, DLSS support, and FSR. The big walkaway is that the GeForce RTX 4070 allows a more than enjoyable gameplay experience at 1440p.  \n>  \n>Compared to the GeForce RTX 3070 Ti, at the same MSRP price-point, gen-to-gen, the GeForce RTX 4070 improves in the following ways. It provides DLSS 3 Frame Generation support, it has a higher VRAM capacity at 12GB versus 8GB, it provides better Ray Tracing performance, it provides AV1 support, and it is around 20% faster at the same price point as the last generation, and it is smaller more efficient and runs cooler.\n\n# [Tomshardware](https://www.tomshardware.com/reviews/nvidia-geforce-rtx-4070-review)\n\n>Compared to the previous-gen parts, the RTX 4070 ends up trading blows with the RTX 3080 across our test suite. There are times when it's 5–10 percent faster, and other instances where it's 5–10 percent slower. Of course, that's not counting DLSS 3, which can boost performance by another 30% or more. But as we've said many times, DLSS 3's Frame Generation doesn't directly translate into universally better performance. It can smooth out visuals, but it adds latency and still needs a decent base level of performance before it's acceptable.  \n>  \n>The most impressive aspect of the RTX 4070 isn't the performance or the price, but rather the efficiency. Even though it's not clearly superior to an RTX 3080, it's close enough that we'd give it the edge. The fact that it needs 120W less power to reach the same level of performance is just the cherry on top.  \n>  \n>Just don't go into the RTX 4070 expecting twice the performance for half the price. As Jensen put it last year, those types of gains aren't happening anymore, especially as we reach the scaling limits of Moore's Law (RIP). Instead, Nvidia is offering more of an alternative to the last generation's top GPU, the RTX 3080... now at a lower price, with significantly lower power requirements, and with some extra features like DLSS 3 and AV1 encoding support.  \n>  \n>If you were previously eyeing an upgrade to an RTX 3070 for $500, the RTX 4070 is a far better deal. It's 33% faster across our entire test suite, not counting DLSS 3, for a 20% increase in price. And you get to choose whether or not you want to turn on Frame Generation, plus the option to stream in AV1 if that's your thing.  \n>  \n>If you've been holding out for an affordable RTX 40-series GPU, the RTX 4070 is probably about as good as it will get in the near term. Sure, we'll see an RTX 4060, maybe even a 4060 Ti, and RTX 4050 as well. But we really don't like the thought of buying a GPU with less than 12GB VRAM these days, and it's tough to see Nvidia slapping more than 8GB on some of the upcoming models. Yes, they might cost less, but they'll require a lot more in the way of compromise.  \n>  \n>If you're a mainstream gamer still hanging on to an RTX 2070, or an even older GTX 1070, and you're finally ready to upgrade, hopefully, you can scrape together the $600 needed for an RTX 4070. Of course, we can always wish for lower prices and higher performance, but with the current market conditions, the 4070 is about as good as we're likely to get.\n\n# [Computerbase - German](https://www.computerbase.de/2023-04/nvidia-geforce-rtx-4070-fe-review-test/)\n\n# [HardwareLuxx - German](https://www.hardwareluxx.de/index.php/artikel/hardware/grafikkarten/60772-ab-659-euro-zwei-modelle-der-geforce-rtx-4070-im-test.html)\n\n# [PCGH - German](https://www.pcgameshardware.de/Geforce-RTX-4070-Grafikkarte-279578/Tests/Preis-Release-Specs-Founders-Edition-1417027/)",
    "comments": [
      "It will sell well for 2 reasons: Nvidia's mindshare and the fact that the value of the other RTX 40 cards is so bad that this card seems acceptable.\n\nHowever personally I see no reason to go for a 4070.\n\nHere in Europe the 6800XT retails new for 100 euros less than the 4070 Founders MSRP (669 euros) whereas a new 6950XT can be found for 650 euros... same or much better performance in raster for 20 euros less or same performance in raster for 100 euros less. And this is with a pinch of salt since the MSRP of the 4070 will probably be reached apart from the day 1 cards which will run out of stock only maybe in June if not in July here in Europe.\n\nI think that I may finally end up building a new gaming pc this summer during the Prime Day but I think that at my gpu budget of 600 euros I will get either a 6950XT or the 7800XT (if it comes out on time for that), unfortunately Nvidia's price to performance has been unacceptable with the 40 series thus far and that is a real pity since the 4090 has a 50 per cent improvement in performance over the 3090 which does not translate in a 50 per cent improvement in performance SKU over SKU for the non-90 class cards, all of that while the prices have been raised and not by a little bit.",
      "I've pulled the trigger on a 4070 to replace my launchday 3060Ti which has had its time. I strongly considered AMD, but I am an SFFPC guy who travels, so the smaller size and lower power draw of the 4070 swung it for me. Many of the SKUs which make the AMD 6000 series GPUs look like excellent value propositions, are large and just don't work in SFF cases.",
      "4070 is one of the best $600 GPUs you will be able to buy. AMD dropped prices on Radeon 6800 and 6900 because of it.",
      "I don't see the obsession with the 4070 not matching the 3090 in performance when the 3090 was only 10-15% ahead of a 3080. \n\nIgor's lab has some interesting results regarding latency. In Cyberpunk, a gpu with Reflex has under half the total system latency (33ms vs 71ms) as a gpu without Reflex when both are at 60 fps. While being more consistent in its latency with tighter 1% lows. Reflex is a feature that people really sleep on, or pretend it doesn't exist.",
      "A few reasons I went with it over something else. I like the raytracing, only game in 1440, not super competitive gaming just to kill time, didn’t want to spend over $1k, and I don’t like buying used pc parts",
      "It's 3080 but 2 years and a half later for 100$ less\n\nAMD is slacking so Nvidia is taking its sweet time to charge extra",
      "The power efficiency really cannot be understated. \n\nWe're talking sub-200w 4070 12GB vs a 350w 3080 12GB or 320w 10GB.",
      "I had the same thoughts, It's not a noticeable improvement from the 3080 and rasterization actually looks slightly slower but it's not garbage either.\n\nIt wouldn't be a good upgrade from the 3080, but it might be a better buy in \\~6 months because although rasterization is slightly slower it's got better RT performance, AV1 encoding/decoding, and DLSS frame-generation.\n\nI didn't do the most in-depth price comparison but I was seeing new 3080's in-stock for \\~$650, but chances are the 4070 will be out of stock for a few weeks and MSRP will be high for a bit.",
      "Thank you for this write up. I was able to grab an FE and should receive it next week. I’m upgrading from a non-super 2070 and only have 1440 monitors.",
      "Your Techpowerup link leads to the 4090 FE review. Looks like the blurb was taken from that review as well.\n\nTrying to figure out how Dexerto thinks the 4080 offers more frames per dollar compared to the 4070. It would have to offer more than twice the performance.",
      "Just upgraded from a 3060 and a ryzen 5 3600 to a 3070 founders paired with a ryzen 7 5800. The leap in performance is insane! (I play in 1440p this card is wonderful especially when with FG enabled!)",
      "How do you like it so far? I'm thinking of upgrading from a 2070S, and I'd like something future proof as I won't be able to upgrade for a little while after right now. I'm between the 4070 and a used 30 series card. All the YouTubers say it's a terrible value, but what's your experience so far?",
      "Im still holding onto my 1060 6gb which i bought at launch because i strongly believe that amd will make 7700 xt a little better than 4070 and a little cheaper",
      "Nah. I have a 4070 Ti here and a 4070 on the way. The extra $200US if you have it to spare, is worth it. Be nice if they tossed in 16GB for that, but if your PSU/case supports a 4070 Ti, I think it's worth every dollar. It has that little bit extra to make it a great 4K card. The 4070 will do it with more settings dropped but I wish my case could fit this 4070 Ti.",
      "I hope someone makes a mini card for these. 220W max is lower than even 1080 ti, and zotac had a pretty good 1080 ti mini",
      "Seems like it'd be a great option for small form factor builds. Much smaller and more efficient than other 40 series cards.",
      "Guys, should i pick 4070 over 3070ti?\nAnd is MSI ventus a good pick for 4070?\n\nWill play in 2k, i don't care for playing all in super ultra settings",
      "does nvidia rtx 4070 have light?",
      "I just checked in my country and 6800xt retails for 30€ more than 4070 and there is only 1 model available. So it's not universal across Europe. And the 4070 starts at 635€ with tax with like 15 models to choose from. So the AMD card is a really bad choice here.",
      "Must've missed it let me fix. TY!"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "4060",
      "4060 ti"
    ],
    "title": "Disregarding the price, does the 4060 Ti 8GB a decent 1080P card for me?",
    "selftext": "Prefers:\n\n-Power Efficient\n\n-Acceptable/At least Playable Ray Tracing Performance(in games like Cyberpunk)\n\n-Can handle the most demanding titles at decently high settings at 1080P.\n\nThere is a 16GB version. Does the extra cost of it worth the better lifespan or headroom for Ray Tracing+FG that uses a lot of VRAM? Or is sticking to an 8GB fine?\n\nAs much as I wanted to go to the RTX 4070 Super it's just too over the top for my resolution.\n\n\n",
    "comments": [
      "Things like FG, Ray tracing, and path tracing are pretty VRAM heavy. Ultimately, if you wanted to use those, I would start with a 4070s and up.",
      "The big issue people had with the 4060 and 4060 ti cards were pricing and positioning. The card is fine for 1080P, but at launch didn't offer any significant performance gain but a higher price tag. (IMO if nVidia had called the 4060 Ti the 4060, and the 4060 the 4050, then cut $10 off the MSRPs reviewers would have been taking about what a jump in performance they offered instead of how they were more expensive but performed about the same as the 3000 series counterparts.)",
      "IMO, 4060 class of cards are not really meant to do RT with extremely demanding RT games like Cyberpunk. FG also requires more VRAM on top of RT, plus, you must already be outputting more than 60 fps for FG to be not janky.\n\nDLSS, sure, but using DLSS on 1080p is less than ideal.\n\nAll in all, if you want to run very demanding RT games, 4070 is the absolute minimum I would get, with 4070s being a good starting point.",
      "30 fps with frame gen? So like 15 fps, the input lag is ridiculous at that point, plus FG has to many artifacts because each generated frame is staying on screen for too long, since the base fps are super low\nI’d say 50 fps is the least you want to get to activate frame gen.\n\nThis was really shitty advice, I’m not going to discuss if you enjoy it or not, but this you are describing is a really terrible experience for 90% of the people interested in a game like cyberpunk.",
      "Yes, they are VRAM-heavy, but at 1080p DLSS quality, 8GB is enough. I speak from experience; I play Cyberpunk 2077 with path tracing, ray reconstruction, and frame generation at DLSS 0.72 resolution (better than quality) at approximately 75 fps. As you can imagine, this is the most demanding game that I play, so everything else runs more than fine.",
      "Honestly, if you want to use ray tracing I'd recommend a 4070 super even at 1080p. Sure, 1440p is the optimal res for that card, but ray tracing is still really heavy even at 1080p.",
      "8gb is almost never enough for Raytracing",
      "8gb of VRAM is definitely not enough if u wanna play recent triple A games at max settings. Looking at the memory usage per process with MSI Afterburner, games like Ghost of Tsushima, Ratchet and Clank, and TLOU (though this game is severely unoptimized so imo it shouldn't rly be considered) are using up over 8gigs of VRAM.",
      ">PT \n\nNo way in hell PT works for you. It barely work on my 4090 at 1440p with DLLS SR and FG, and my GPU is over 6 times faster.",
      "What’s playable FPS to you?",
      "My 4090 works fine, it is even above average in Firestrike.\n\nKid me considered 12 FPS San Andreas \"smooth\", does not mean it was. If you play at 30-40 FPS you must be at 540p and use FG. FG adds insane lag and artifacting if you are at low FPS, is is unusable under 40.",
      "Well check the new system requirements for Star Wars Outlaws. It could be a good indication for the new coming AAA games. \n\nI recommend min 4070",
      "30fps is unplayable to most people, not even casual gamers. Bare minimum to cope for me personally would be like 45+ fps since at least as long as you aren’t turning your screen fast you can feasibly watch the environment as you stand still.",
      "Its not about what people like, the 4060ti is just a bad choice for a sub $350 GPU.  Raw raster will be better for cards in OPs price range. Once you start getting to the -70 seires and above frame gen and dlss3 really start to shine and make them the best choices. Every other commentor is telling them to just spend $200 more, and Id say to do so to, but if you really want a $300 gpu a 7600xt will be much better.",
      "I get 120FPS with those exact same settings on my setup...",
      "Nah it is. I work as a tech in a retail store. And even if I show people how much better the 7700xt is for the same price or cheaper, people will not entertain a Radeon card. Some ppl don't listen to reason unfortunately :(",
      "Do not forget that these are FG 30 fps, not real frames",
      "[https://www.youtube.com/watch?v=dDQav43OHtY](https://www.youtube.com/watch?v=dDQav43OHtY) here is some comparison in CP77",
      "Cyberpunk running at 1080p w/ RT Overdrive with DLSS Quality will get you framerates in the 40s. If I were you, I would upgrade to something that gets you **at least** 60fps, ideally more. It'd be a bummer to upgrade to something and games already don't run as well as you'd like.\n\nThe 4070 Super isn't overkill at all for that resolution",
      "I don't think people here like Radeon bro. It is the far better option in this price bracket but I'm assuming this guy wants to spend extra on a geforce card. But you are right, geforce starts getting interesting at the 4070 and above."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "rtx 4060",
      "4060",
      "rtx 4060 ti",
      "4060 ti"
    ],
    "title": "Upgrading from GTX 1070 to RTX 4060 Ti, good or bad?",
    "selftext": "So my current GPU is an ASUS GTX 1070 Dual OC 8GB, and I'm strongly considering upgrading to the ASUS RTX 4060 Ti Dual OC 8GB.\n\nI've seen a lot of threads and articles online saying that the 4060 Ti is just absolutely not worth it, and to buy a used 3060/70 (Ti), or save up for a 4070, instead. From my understanding, some of the new Nvidia features (Frame Gen mainly) will not be available on anything lower than the 40-series.\n\nOne of the big reasons why people say to go for the 4070 is because it'll be a lot better for 1440 gaming, but I'm not particularly interested in 1440 right now. Maybe I'll change my mind in the future, but ignorance is bliss, in this case.\n\nMy main dilemma is that I can just go and buy a new 4060 Ti right now and start gaming tonight, or I could spend a little bit less on a used 30-series card, but I'd probably not receive it until early January or end of December because of the holidays.\n\nSo am I being stupid for considering the 4060 Ti for 1080p gaming?  \n\n\nUpdate: I ended up getting the 4060 Ti. Thanks to everyone for the opinions and discussions!",
    "comments": [
      "I'm having a wonderful time with my 4060 Ti @ 1440p with g-sync. For 1080p it is close to overkill. People here have lost their touch with reality or take their hobby way too seriously.",
      "It has to do with the reality part. People often talk like anything less than ultra extreme - setting is crap and not worth even talking about.  From what I gather we live in a bleak moment in time when even the mighty 4090 can't run upcoming UE5 games right.",
      "I'm mainly going for 1080p, so that's very good to hear.\n\nIt can definitely feel like people talk down on the budget cards a bit more than necessary, but I can also understand where people are coming from when you consider cost-per-frame.",
      "I was considering it, but I decided against it for a couple of reasons.\n\nFirst off, the price is out of my budget currently. I was originally going for the regular 4060, and the 8GB Ti is already \\~€100 more expensive, at least at my local store. And then secondly, after looking at a couple of comparison benchmark videos, the performance difference between the 8GB version and the 16GB version for 1080p is literally like 2-3 fps in some games, which doesn't really warrant the extra \\~€100.\n\nI definitely wanted to go for the 4070, but it's just way out of my budget right now, and the 4060 Ti is already such a significant upgrade from my 1070 (\\~50% higher performance in most games that I've looked at) that it honestly doesn't matter all that much to me. I'm not looking for 4K maxed out settings, just something that's a bit more up-to-date and can run new games at 60+ fps.",
      "I have a founders 4060ti 8gb. My advice - dont bother with any 30 series card, the tech is outdated by the new frame gen. But lets address the elephants people have with this card. For me the 16gb card was not worth the extra money as its not a 4k card, its a 1080/1440p card and im nowhere near hitting 8gb with what i play. The 128 width bus does not need to be any bigger because this card is not about raw raster.. its all about dlss trickery + FG. Warzone with frame gen enabled + dlss sharpening with the latest drivers i get between 150-220fps, which are figures that my 2080ti couldnt dream of hitting. Also keep in mind im getting that fps  using a old 9700k, so those figures would be even better with a 13700k or 14700k. You also get AV1 encoding as an added bonus over a 30 series card\n\nSo to sum up... if you hear bad reports about this card they are most likely from people who have not experienced owning one, and are most likely going off yt reviews that are more about stats like bus width and vram and not actual day to day use. 40 series sold me over 30 series or AMD with frame gen. 4060ti is a killer card for £379 gbp and id advise anyone looking to upgrade from ANY series card to make this card the bare minimum in todays world. Frame gen is where its at going forwards",
      "For competetive shooters, 4060 Ti will be more than enough for quite a while.",
      "But again - it is Nvidias fault for pricing everything so high that if you want to enjoy games as they were meant to be, you have to spend a fortune.\n\nI am still on 1060 so I deffo dont fall in the group of snobs, but I still feel it is more complex problem and it is not just about “snobs” wanting to play games at max setting with all bells and whistles. When 1060 came out, it was able to use it to play basically almost any game at the very moment on full with that and easily hit 60 fps. Nowadays you pay double the amount of money for 4060 but it does not run everything on full. Who’s fault is that? Certainly not some snobs.",
      "Amen, it is crazy how because a few content creators said “your pc isn’t ready this game” everyone started feeling their hardware was obsolete.",
      "You don't need more than 8gb for 1080p gaming except for a couple of titles, and even then, a minor reduction in specific settings solves that without and noticeable difference in quality.",
      "I have a 1080ti and play at 1440 with no problems. I turn off antialiasing because at 1440 you don't need it. I turn off a bunch of other settings that I never notice, and boom, it's playable. \n\n100% people are out of touch. A 4060ti is faster than what I have and what I have is fine.\n\nI'm tempted to upgrade at least partially because my 1080ti is expensive to run and the newer cards are way way more energy efficient.",
      "If I were OP, I'd still get 8GB. There's no way that GPU won't get obsolete GPU-performance-wise long before hitting the VRAM limit at 1080p. That 100€ is better to be saved and put into the next GPU upgrade sometime in the future.",
      "4060Ti it is then.\nGet it tonight and enjoy it.\n\nI myself have a 3060 Ti for over a year now, and it's a good card for my 1080p monitor. Also, using DLDSR + DLSS helps a lot (upscaling to 1440p and using DLSS Quality is one hell of a black nagic).",
      "How about going with the 16GB version of 4060Ti?\n\nAlso, I think going from 1070 to 4060 Ti is not stupid at all. If you have the budget for 4070, go get that, but if not, then get the 4060 Ti right now so you can enjoy it over the holidays.",
      "Or are snobs regarding having to play every single game in the highest quality settings in RT and all the graphics bells and whistles enabled. I have the 4060 ti and no issues so far.",
      ">Do not consider DLSS upscale or DLSS FG in terms of performance, because one day you will find that the game you want to play does not support it and you will be sad, because it will be 30 FPS.\n\nThat's a really dumb logic. Absolutely consider the extra features, you'll be using them a lot if playing AAA games.\n\nNowadays games without native support soon get modded support.",
      "I'm not someone who absolutely NEEDS to max out every game I play. Especially in competitive shooters, I'm quite happy cranking down the settings to low-medium if it means the game runs as well as it can.\n\nI appreciate your input tho!",
      "Why it needs to be a snob? Like HDR, RT and other things really makes some games to stand out. Like Cyberpunk and others. And in the future we will see more and more of such games where visuals are half of the fun (this is kinda sad in some ways but thats another topic). Why should I be snob if I want to hit at least 120 fps stable with RT and other things turned on?\n\nWhy we are mad at people that wants to enjoy games at their best rather than being angry at Nvidia and AMD for pushing cards to the ridiculous price levels?",
      "So with the 8 vs 16 gbs it’s not so much a matter of today vs a matter of in 3 years from now. $100 today vs replacing the gpu 2/3 years earlier due to running out of vram on future games",
      ">bf 2042\n\nI saw my nephews playing Portal at 4K on their dad's TV and PC with a 1060. Does that mean 1060 is a \"4K card\" too?\n\nBecause I think you misunderstood what all those people meant.",
      "I'd get the 7700XT instead. About same price and a lot faster, plus more VRAM.   \n\n\nNow if you must buy a Nvidia card (which means you aren't buy for gaming, but for content creation - if you need a card for gaming, again, get the 7700XT), then get 4060Ti **16GB**."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "rtx 4060",
      "4060",
      "4060 8gb",
      "rtx 4060 8gb"
    ],
    "title": "RTX 3060 12GB or RTX 4060 8GB?",
    "selftext": "I'm looking to upgrade my 1660 super so I can run Jedi Survivor better, those 2 cards are the exact same price, so I don't really care if the 40 gen was a dissapointment, I just need to know which one is the stronger card, considering they are the exact same price in the store ",
    "comments": [
      "try to find used \n3060ti or 3070",
      "Honestly though? How about the 6700XT or 6750XT?  \nAt least give it a look to see the price and performance.",
      "Its ok for 1080p. Not for 2k though.",
      "I just mentioned it because, when I look at all the reviews, the 6750XT is way better than the 3060 and even the 4060 TI, and since the prices have come down quite a bit on AMD, it's worth a shot.\n\nThe only person who misses out if you don't consider all the options is yourself. I have an Nvidia card now, maybe I will again in the future, but whatever I upgrade to, it will be what I feel is the best buy at the moment.",
      "Don't be an idiot. Nobody needs to be a fanboy nor hater. 3060 and 4060 are both 300$ cards and 4060 is clearly the better choice. Why wouldn't anyone buy it?",
      "I have rtx 3070 and its great for 1080p.",
      "I understood it's disapointing because it's only slightly faster then 3060, even slightly faster for the exact same price is worth it, I see no reason in buying an older card for the exact same price of the newer if for my needs it's faster and it also have DLSS 3, I asked since I'm not a tech guy and I didn't really knew what 12GB mean, and I got an answer that it's for higher res which I don't use, so yes, 4060 might be only slightly better, but for the same price, it's a better choice for me, if that make me a fanboy, so be it",
      "I'm not against getting another company, I couldn't care less who make my card, this is also why I have both consoles, those wars are dumb, it's just for convienace, the same reason I keep buying Sumsong phones, it's easier to use interface of something you know, if my current card was AMD, I would probobly look for a new AMD first for the same reason, to get less confused with the interface\n\nAgain I'm not a tech guy so I use mostly Benchmark to test what parts are better, it showed that the 4060ti is better for that price, 6750 is better then 4060 but also more pricy, so between 4060TI and 6750XT it seem that I should choose 4060TI",
      "Jedi Survivor.\n\nYeah, 3060.",
      "4060 for 1080p definitley. 8gb is enough for 1080p. Only idiots, that don't admit that devs messed up in some badly optimised games say it isn't. The last of us, RE4, Hogwarts etc now work with ray tracing maxed on 1080p 3070 8gb no problem. It was just lazy porting.",
      "Just buy the freakin 4060. Those that say 3060 are nuts...",
      "I haven't checked non-Nvidia ones since I would have to get used to another interface, but those two specific cards don't even appere in the store page, there is a 6800XT but it's priceier then even the 4060 ti",
      "4060ti (8gb, not the upcoming 16gb), is 100 dollar more, while it might me 33% more in US prices, in Israel, 4060 cost around 600 dollars and 4060ti around 700 (AMD is also the same price range here and also other cards, for comparing,  4090 here is 2k at best and over 3k at worst), everything here is much more pricy, my PS5 was like 1k dollars, not scapled, store price\n\nWith Israel prices, getting 4060ti is better since the % of diffance is much lower, and is actully more avilable, the 4060 is only in 1 store",
      "this is no longer true",
      "Just save for 4070 or 7800XT. There is no point in squabbling over two bad options.",
      "Those idiots are making non-enthusiastic people to spend their money badly.  Don't let them fool you. They are just haters on a hype train. A company will always release their products. They may be good or they may be bad but its not our business. Yes we all would want a better 4060 but it is what it is.\n\nYou just need to care about your own money. If they're at the same price or close, you should by 4060(BTW just focus on the cheapest AIB models. They all perform same). Reasons? \n\n1- Faster gpu(actually this one alone is enough)\n2- 3060 consumes %50 more power(which means more bills and heat)\n3- DLSS 3(You'll use this more often than you think. It'll help a lot)\n4- Latest generation(Longer support and higher possibility to unlock more features in the future.)\n\nYeah there is a 4gb vram difference but these things I've mentioned are much more important than this. Especially if you play on 1080p. \n\nIts your hard earned money, be careful to spend it.",
      "rtx 4060 no good",
      "AMD is worse in ray tracing. If you plan to pay anything with RT don't go AMD since the 6750xt is slower than a 3060 in the vast majority games with ray tracing enabled.\n\nThere is a mod for Jedi Survivor for DLSS3 but I'm not sure how well it works. 4060ti is like 20-25% faster than a 4060 but usually costs 33% more.",
      "Neither, get a 3070 if you insist on NVIDIA, otherwise get AMD",
      "A 4070 costs more than twice as much as a 3060 so might as well recommend them a 4080 which is even better"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "4060",
      "4060ti",
      "4060 8gb"
    ],
    "title": "Is it worth upgrading from rtx 2060 super 6gb to 4060 8gb?",
    "selftext": "My current Pc(bought in January 2021) has died recently.  I wanna get a new PC. \n\nI am torn between 4060/4060ti 8gb and 4070 12gb\n\nIt's the price difference that is stopping me. I want to invest in one that can last me probably a good 5 years? \n\nI would like to game in 1440p this time. Ray tracing not important for me.  \n\nCurrently playing : Cs2 Val spiderman miles morales and red dead redemption 2\n\nI hope to be able to play The last of us and any upcoming AAA titles.\n\nMainly gaming probably 80%, 20% on netflix and normal usage e.g youtube/surfing net...\n\nThank you!",
    "comments": [
      "Definitely save up for a 4070 or 4070 super",
      "I wouldn't buy anything with 8gb vram if I wanted it to last me for 5 years.",
      "There’s no real way to know.",
      "I’d say the 4070 should be your minimum spec for 1440p of those options. If you’re strapped for cash though and RT isn’t important, the 7700xt is about $150 cheaper and only around 10-15% slower. Obviously based on your stated needs. If you need the Nvidia features, by all means go with the 4070.",
      "4070 or 4070 super or 7800xt or 7900GRE",
      "8GB in (mid) 2024:\n\n![gif](giphy|h5cDuyir8oLWxK2TTE)\n\nSave up for 12GB+ VRAM fam 🫡",
      "I just upgraded from my 2070 to a 4070. Saw jup from 42 fps in cyberpunk to about 95. Definitely worth it",
      "And it depends on your definition of fine. My 1060 3gb was enough for me for six plus years and it would’ve been fine enough longer if I didn’t have the money for it to be worth it to upgrade for mostly graphical reasons (the want to play games at near max settings at 4K).",
      "If you want 1440p, you should consider min 12gb vram, ideally even 16gb. \n\nFor nvdia, I’d recommend 4070 or the 4070 super if you can.\nIf not, look at the competing products like 6700xt (better than 4060) or 7800xt considering ray tracing is also not important for you.",
      "I’d recommend getting at least 12gb vram, 16 if possible. For now 8b will get you by, but that won’t last long.",
      "I did just that this past weekend. Went from a 2060 to a 4060ti. Huge improvements on all of my games. High/Epic settings are awesome. No more medium or semi high settings for me. Do it, but an fyi, depending on the game, 8gb of ram is not going to be enough :(, so you will have no choice but to lower settings.\n\n  \nEdit: Oh you want 1440p, yeah go with the 4070. 4060ti you will be lucky to even get 70fps on high settings.",
      "If you want 1440p, you shouldn’t be looking any lower than a 4070. Also the 4060 is shit so you shouldn’t be looking at it at all",
      "8 vram is a little low on 1440p. Try to aim for more. I have 3070 with 8vram i find that most games max out my vram and I get around 60fps with modern games.",
      "O have upgraded my RTX 2060 FE to 4070 FE and it feels right. 4060 won't be much more powerful than 2060",
      "I went from a 1660 super to a 4070, worth it.",
      "Because people are wierd",
      "i would keep the 20 this year, and see the upcoming gpus. But if you need to buy now, get a gpu that has at least 12-16 gb. You have plenty of options if rt isn't important.",
      "4060.IS.NOT.WORTH.IT.",
      "Everyone's definition of \"enough\" is different. Enough to game at 4k max settings path tracing? It can't do that today so no. But will it still run games with settings turned down? Probably, look at how many people are still using 10 series cards for games like cyberpunk. Sure they don't get all the new features, but the card still works.",
      "Does the 2070 super hold up today? \n\nYes….. \n\nIs it as good as when it released? \n\nNo….."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "rtx 4060",
      "4060",
      "4060 8gb",
      "rtx 4060 8gb"
    ],
    "title": "RTX 4060 8GB or RTX 3060 12GB for general/multipurpose use?",
    "selftext": "Hello.\n\nI recently got a pc (went with Ryzen 7 5700G as the cpu because I didn't have the funds to get a gpu at the time) and was looking for a good gpu option for general use.\n\nThe best options I have in my price range (as well as availability) are the 4060 and the 3060 12gb brand new.\n\nI don't play recent game releases that demand a lot of vram and only plan to play at 1080p at best. I'm currently playing Monster Hunter World at a low resolution with average 55fps but would like a higher resolution.\n\nI consider any fps past 60 as amazing.\n\nI'll be testing the gpu with Batman: Arkham Knight at max, maybe Control at whatever the gpu limits are at.\n\nI'll also be using it for stuff like video editing, UE5 (for mostly basic stuff since I'm just starting out), and anything else that would benefit from a dedicated gpu.\n\nFor the price range, the two are roughly similar in pricing and are available in the shop I frequently visit, and I don't plan on upgrading for a while since I'll be saving up for an eventual AM5 build which will definitely have high-end specs and gpu.\n\nThanks in advance.\n\n**Update:**  \nAfter reading and answering some comments, the 4060 looks to be the better choice.  \nI've also done a bit more reading myself and came to the same conclusion myself.\n\nI'll be checking the comments a bit more for the next few days then finalize my choice once I have decided when I'll buy the gpu.\n\nThanks everyone!",
    "comments": [
      "A cheap, maybe even second hand, 3060 will work until you do your planned new build.",
      "It seems like OP is sticking with 1080p. Does video editing at 1080p hit VRAM limits at 8GB? The 4060 supports AV1 video encoding and DLSS frame generation for gaming, so I think I’m leaning the opposite direction overall (assuming similar price).",
      "/u/CompetitionStatus646\n\n>The 4060 isn't much faster\n\nIt is, actually. It's faster in >85% of games, and in 1080p it is significantly faster across the board.\n\n>the VRAM really helps with your editing\n\nNo, it doesn't. It's RAM that matters, not VRAM. You can get away with 2GB cards if need be, though 4GB is recommended in general. The computing power of the 4060 *will* help, though. It's significantly faster in synthetic applications. It also consumes a third less power.",
      "Question: are the 3060 and 4060 you’re looking at close in prices, or are they both just in your price range with a gap? If they the same price, I’d actually recommend the 4060 for a few minor reasons (AV1 encoding for video, DLSS frame gen for gaming, etc). If there’s a price-gap between the two, then the 3060 is better. For general use, the extra features aren’t worth a premium unless you know a feature would be worth it.",
      "Thanks! I'll keep that in mind",
      "The 4060 also uses about 2/3 the power at full tilt, compared with the 3060. It'll probably also get new drivers for longer. \n\nFor an extra 20USD, it would be my preference.",
      "will the extra money spent on the memory be enough to push your options to a 4070? id rather have 16gb RAM with a 4070.\n\nif not, the 3060 is better now, but with how good framegen is becoming,  the 4060 might last longer just on feature set alone",
      "That is just plain misinformation. VRAM only matters in specific applications that need to load in a lot of data at once, i.e. Blender with a ton of assets or high resolution textures. That's pretty much the only scenario where a 3060 12GB can beat a 3060 Ti. What matters more in general is raw computing power, where the 4060 wins.\n\nAlso, you should read OP's post properly instead of skimming through it. They are playing older games in 1080p, in which case the 4060 shits all over the 3060.",
      "Ventus on 3000 series is pretty bad.\n\n4060 is a better GPU: https://www.tomshardware.com/pc-components/gpus/rtx-4060-vs-rtx-3060-12gb-gpu-faceoff\n\nBut the question is whether you think you can fit your work into 8gb of VRAM.",
      "You mentioned Control as an example game so I figured there was a chance you might play with some light ray-tracing in games, even if you’re not playing the most demanding ones. Regardless, DLSS features are nice because they help GPUs stay useful longer. A “less demanding” game 5 years from now might be equivalent to a “more demanding” game right now, ya know? Both GPUs get DLSS upscaling, but only the 4060 gets DLSS Frame Gen. If the extra latency isn’t an issue with the game you’re playing, Frame Gen probably preserves image quality better than upscaling at 1080p.\n\nUltimately, with a $20 difference, the main question is if 8GB is “enough” VRAM or if the 12GB 3060 would be better. If you’re sticking with 1080p for both gaming and video editing and you’re not planning anything super ambitious with UE5 (or Blender/etc) for now, I think 8GB should be sufficient. It’d also be sufficient for video editing small amounts of 4K footage - just not a ton of 4K.\n\nEdit: Apparently video editing either uses primarily RAM or VRAM more depending on the software/workflow. If your workflow uses RAM more, then VRAM is less relevant even with 4K footage.",
      "fair enough, but once again, at 1080p, the 4060 and 3060 are very, very close in performance,  but the 4060 has the advantage of framegen that will only improve. At 1080p the 8GB VRAM of the 4060 will not be an issue. personally, i would get the 4060 just because of DLSS3 and its long-term implications as well as extended driver support",
      "3060 12 GB has my vote. The 4060 isn't much faster and the VRAM really helps with your editing.",
      "The price gap is around 20 USD converted.\n\nI don't really see myself playing games like Hogwarts Legacy which need powerful gpus to make the most out of, and I'm not sure how much difference it makes when it comes to the 4060 features.\n\nBoth gpu options are MSI Ventus 2X, and changing brands will definitely make the price gap bigger.",
      "I read this all over this thread. Do people on reddit genuienly not know that the 4060 is faster than a 3060?\n\nRoughly 15%.",
      "The cheapest 4070 that the store is selling (MSI GeForce RTX 4070 Ventus 2X 12GB GDDR6X OC) costs around 300 USD more (actual cost is roughly 700, converted to USD), and the 16x2 ram that I plan to buy costs around 100 USD\n\n4070 simply won't be in my available budget for months, and I would benefit more from having the gpu as early as possible.\n\nWhich means the 3060 is the preferred choice by everyone so far\n\nThere's also the option of going for 7600XT 16GB for a bit more than the 4060 but idk how much difference it makes when it comes to my use case, and didn't add the option since r/nvidia",
      "Additional info that might help:  \nI have 16GB ram and I plan to add 32GB (16x2) the same day that I buy the gpu)  \nI have a 750W PSU\n\nUpdate: The GPU options are both MSI Ventus 2X with around 20 USD difference (converted)",
      ">Which means the 3060 is the preferred choice by everyone so far\n\nI would 100% go with the 4060. Even with 20$ price difference. It's genuienly wild that anyone prefers a 3060 actually. \n\nThe 4060 is 13-18% faster, has much lower power draw and more modern features.\n\n8GB is absolutely planty for 1080p gaming. It doesn't even matter for 4k right now. The difference between a 16GB 4060TI and the 8GB version is less than 1%. Tested with over 20 modern games. This is at 4k mind you.",
      "I have a rtx 4060 and at 1080p gaming it can run pretty much anything at ultra even with ray tracing. I don't know about the 3060, but the 4060 has dlss3 frame gen and it almost doubles your fps in some cases. It is a big advantage. I can never max out the 8gb video memory in 1080p. Neither in 1440p. Maybe there are some cases in 4k. I haven't yet used it for video/photo editing. I will do it in the near future. Is it a real worth buy.",
      "Go for the 4060.",
      "4060 is gonna be the choice I believe. The GB matters but it’s sort of deceptive at the same time in this circumstance."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "rtx 4060",
      "4060",
      "rtx 4060ti",
      "4060ti",
      "4060 8gb",
      "rtx4060",
      "rtx 4060 8gb"
    ],
    "title": "RTX 4060 or RTX 3070 - which one for my first budget gaming PC?",
    "selftext": "Hello, I have the option to buy a second hand gaming PC quite cheaply and I can choose between RTX 4060 8GB and RTX 3070 8GB for the same price and I would like to know your opinion which one would you choose?  I have been googling a lot however I found a lot of \"buts\", the 3070 seems quite a bit more powerful with like 10-20% more FPS, but the 4060 has the new DLSS3 frame generation pushing its fps all the way to rtx 3080 level, but there is apparently an input lag issue with dlss3, but nvidia reflex seems to solve it? I am quite lost here, if I want to play modern games in QHD resolution with the best quality possible at around 60FPS, does 4060 with DLSS 3 provide better experience than RTX 3070 with DLSS 2? Are there other things to consider? \n\nI will probably buy a 34\" ultrawide QHD monitor, but I havent made my final decision, would you also choose such monitor for best gaming experience if you had $300-400 to spend just for the monitor (plus $600 for the pc so $1000 limit for the whole setup, I really dont think I want to spend $200-300 more for RTX 4060ti or rtx4070 as the FPS with rtx4060 seems high enough for most modern games in QHD)? \n\nThanks a lot for your advice.",
    "comments": [
      "Go with the 3070. The 3070 performs nearly the same as the 4060ti. The 4060 is not powerful enough for a 3440 x 1440 monitor. The 3070 will be able to use DLSS and be just fine. Frame Gen is only acceptable if you are playing a single player game. FSR frame Gen works great with DLSS.",
      "What games can a 3070 not run? Personally the only games I've ever experienced issues with were a handful of VR titles. Everything else ran fine.",
      "The 4060ti also comes in a 8GB model which performs almost identically to the 3070.",
      "Yep. 4060ti uses 160W. 3070 uses 220W. Some 3070s have a power limit of 250W",
      "I don’t know if this helps but I have both 4060 and 3070 Ti. Games that support frame gen (let’s use Diablo 4) vs 3070 ti:\n\nUltra settings (1440p) / Raytracing OFF\nFrame Gen and DLSS (balanced) ON\n\n4060 (85W) 117-148 FPS\n\n3070 Ti (140W) 131-170 FPS (no frame gen support)\n\nOf course, this is paired with a 12700H (for 3070 Ti) versus 13620H (4060)\n\n\nAnother game: Assassin creed Valhalla:\n\nUltra settings / FSR ON\n\n4060 67-75 FPS\n\n3070 Ti 85-112 FPS\n\n\nIn general 30 series will have better raw power but it all depends on the watt variant of the 4060 to make it worth buying over a 3070 let’s say. They both support DLSS except frame generation is only on 40 series.\n\nInput lag is there and when frame gen is on, it feels floaty, almost like you aren’t playing the game during  frame loading? Hard to explain but latency is definitely there and idk feels off at least on diablo 4",
      "I traded my boys 3070 for a 2080ti due to Racket and Clank rift apart. If you didn’t play on low setting or Performance mode upscaling the game was almost unplayable due to the stuttering from a lack of VRAM. Plays fine now with all settings maxed out with DLSS quality.",
      "On ultrawide, it hit its limits on call of duty quite quickly so I had to use dlss performance and low settings to hit 120fps and it looked awful.\n\nFor normal games, I had to turn off all ray tracing and enable dlss to hit above 60. It physically can’t run stalker 2 above 5fps if you play at higher resolutions.\n\nIt’s doable if you don’t care for higher refresh rates or ray tracing and you don’t mind using dlss",
      "You won’t be able to run portal RTX on a 4060. My 4070 super only gets 30fps on it even with upscaling and it’s around 50% more powerful than the 4060 ti.\n\nFor anything less than a 4070, you’re better with amd because 8gb just isn’t enough.",
      "I currently have a AMD 5800x and a 3070, playing at 34\" 1440p. The 3070 can still get *decent* performance and visuals in games with DLSS, but I would not personally recommend it to someone looking for a GPU to last a few years at 1440p because of the VRAM issue, which I've ran into in games like Horizon Forbidden West and others. I wouldn't recommend an 8GB GPU full stop to anyone with a 3440x1440 display honestly, not unless that person was exclusively going to play smaller, less demanding games or old games anyway.\n\nAlso FSR3.1 support, which is needed for FSR FG + DLSS is not widespread still and the FSR3 FG mod, in my experience, is a bit dodgy with frame times in about half the games I've tried it in.",
      "In this exact situation. 3070, 3440x1440, use dlss with fsr fg on horizon forbidden west and am very happy with the performance except for when I run out of vram and it starts stuttering and loosing frames. It's never that bad though.",
      "Ye I think. But I think game devs work with 8gb. I've not had a problem yet",
      "4060 with FG will at the most match 3070 in real frames. Besides the latency I don’t like the extra smoothness it adds to the image in games. That will be even more noticeable in 1080p.\n\nBesides, I don’t think 4060’s 8GB buffer can keep up with FG demands in newer titles anymore. Especially not at 3440*1440, even with DLSS.",
      "Not Nvidia's framegen, which is somewhat better. But I agree framegen isn't worth the Nvidia tax alone.",
      "2080 ti is a pretty good buy as well only a few percent slower with more vram and about identical used pricing. Been trying to nudge my buddy Into picking one up to upgrade his 580 8gb he games on still.",
      "Also dlss 3",
      "3070 no questions asked, DLSS3 FG is useless when the card has 8gb of vram, check out videos by Daniel owen that show how the lack of vram causes FG to lower your fps that you start with\n\n\nIMO if you can get a 4070 or the 4070 super, go for it, you'll be thankfull for the 12gb of Vram (Hardware unboxed recently tested Stalker 2, all of 8gb cards run at 2 fps due to lack of Vram) and actually usable FG couple of years down the road as an investment, because with the 4060 and at a lesser degree with the 3070, you'll be looking at you next upgrade very very soon (unless you only play light or older games and don't plan to play the latest AAA games of course)",
      "4060 is a terrible 1440p card and so is 3070, grab 6750XT/6800 Nvidia has no good budget cards.",
      "Neither,  7700XT or 7800 at this segment.",
      "3070 all day.",
      "The problem is the 3070 has 8gb vram and can’t run some games whereas the 4060 ti has 16gb although its significantly slower"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "rtx 4060",
      "4060",
      "4060 8gb",
      "rtx 4060 8gb"
    ],
    "title": "Used 3070 vs New 4060 ",
    "selftext": "Wich has the best performance and is the best option for Unreal Engine 5 for someone pretending to make heavy scenes and projects:\n\n\n1 - Used RTX 3070 8GB\n2. - New RTX 4060 8Gb\n\nP.S - Same price on local currency, average $2.000",
    "comments": [
      "Of the 2 choices 3070 obviously a better value, if the card is from a reputable seller, however there are better cards with more memory to consider \n16gb would be the minimum in 2025 for 4k, 8-12 gb fine with 1440 and lower resolutions\n\n4060 is a non starter since the arrival of Intel Arc B580",
      "arc b580 seems like the logical thing to get now if you are tight on budget and looking for similar class of gpu.",
      "3070 if you trust the seller, otherwise 4060.",
      "Yeah 2 Thousand but not USD, on my country currency \nAround 330 USD",
      "ive tested the B580 in games as ild as the original Crysis, portal and even Half life 2. it beats the 4060 in all of those as well. the gpu doesnt only work on \"new unoptimized games\".",
      "Everyone keep suggestig the B580, but you all don't realise that that card is inexistent outside of the USA, or barely available for 420usd. And I'm talking about Europe, not an island in the Pacific ocean.",
      "The b580 is really good, but the 3070 still performs quite a bit better(15-20%). \n\nThe issue is VRAM, the b580 has the potential to perform better in games that require more than 8 gb of vram. Usually lower texture settings and resolutions helps with that. So it all depends on what games OP plays, whether they're keeping the GPU for a while, and whether they're okay with lower resolution and textures.",
      "Yeah but out of budget for a new one\nAlso can't find used ones of this, only TI of 8gb\n\nBest options I have are the used 3070 or a new 4060",
      "why not intel?",
      "3070",
      "3070 all the way",
      "$2000\n\nor\n\n$2.000 ? \n\nEither way crazy price",
      "I don’t know about your specs, but the on-board graphics of my cpu can easily handle any game before 2003.",
      "Yeah but get the 4060ti 16gb version",
      "You’re going to need the extra vram for your use case and I think a 3060 12gb might be best for you. I would recommend other cards if you can stretch your budget a bit but I really can’t think of something better.",
      "3070 is the better GPU, but both lack VRAM.\n\nI'd go for a B580 over either.",
      "4060ti performance but 8gb vram. I would go for 10gb vram *bare minimum*. Go for the RX6800 instead. Or a better idea is to buy B580 instead, 12gb vram and worst performance is 4060 and best is 4060ti with decent RT capability.",
      "Yeah, here the TI has a much higher price than the original 4060 and I don't know if the performance is that huge difference.\nOf course the TI 16gb is but also gets much much more expensive here in my Country \n\nI am not into RX and AMD because render software like V-Ray doesn't support AMD GPUs, gotta be Nvidia",
      "Can easily get a B580 for 310 euro here",
      "I totally missed that part sorry. Then there isnt any better option than 3070."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "rtx 4060",
      "4060",
      "rtx 4060 ti",
      "4060ti",
      "4060 ti"
    ],
    "title": "Good GPU Upgrade for 1440p",
    "selftext": "I purchased my current build used off a friend a few months ago, who themselves bought it as a pre-built (Thermaltake Genesis Xtreme V3) and replaced the storage, and it works well enough at 1080p, but I'm looking to upgrade to a 1440p monitor and planning to get a better GPU to support that. My goal is being able to get 1440p 60fps Ultra in modern games, with or without DLSS, although any extra FPS is a good thing. The current build is this:\n\nCPU: Intel Core i5-12400F with Thermaltake UX200 SE ARGB CPU Cooler\n\nGPU: NVIDIA RTX 3060 8GB\n\nRAM: Thermaltake TOUGHRAM Z-ONE RGB DDR4 16GB (2 x 8GB) DDR4-3200 CL16\n\nMotherboard: B660M Chipset (unable to check the exact model at this time)\n\nStorage: 4TB PCIe 4.0 SSD\n\nCase: Thermaltake V150 ARGB Breeze TG Micro Chassis Micro ATX\n\nPSU: Thermaltake Smart BX1 650W 80+ Bronze\n\nNew Monitor: 2560 x 1440 144-170Hz with Freesync (undecided on specific model)\n\nAnd these are the GPUs I'm considering (prices in AUD and USD).\n\nMSI GeForce RTX 4060 Ventus 2X Black OC 8GB: $509 AUD / $347 USD\n\nMSI GeForce RTX 4060 Ti Ventus 2X Black 8GB OC: $619 AUD / $422 USD\n\nASUS GeForce RTX 4060 Ti Dual OC 16GB: $759 AUD / $517 USD\n\nZOTAC GAMING GeForce RTX 4070 Twin Edge OC 12GB: $899 AUD / 613 USD\n\nASUS Radeon RX 7600 Dual 8GB: $459 AUD / $313 USD\n\nNote: the following two will both also require me to get a new PSU since they have a 700W minimum requirement compared to my 650W, which would up the cost by somewhere around $149 AUD / $101 USD for 750W Gold. \n\nSapphire Radeon RX 7700 XT Pulse 12GB: $769 AUD / $524 USD\n\nSapphire Radeon RX 7800 XT Pulse 16GB: $899 AUD / 613 USD\n\nOut of the following GPUs, which would be the best for 1440p performance at the best price? I'd rather not go for 7700XT / 7800XT just because it's a lot more effort to replace the PSU, unless they're leaps and bounds the better choice. Currently the 4070 is my ideal choice for performance and lower power usage, but if the 4060Ti 8GB/16GBcan do a good job at 1440p I'll consider that. The 4060 and RX 7600 don't seem like they add enough performance to be worth the cost, but throwing them in anyway.",
    "comments": [
      "Of your options the 7800XT is the highest performing in 1440p. Best used option would probably be a 6950XT.",
      "the 7800xt is obviously the best card here considering its about 5-10% faster than the 4070 while being able to be undervolted to run at 200w and still beat the 4070. if you wanna do a ton of rt and all the games you play support dlss the 4070 is also a viable option. either way the thermaltake smart series of psus are not good and should be replaced along with the gpu upgrade. use the psu cultist tier list to select a b tier or better psu and then choose your gpu. the other options you didnt mention which are faster and cheaper than the above 60 series cards including the tis are the 6700xt 6750xt 6800 and 6800xt along with the 6950xt which should be around the cost of the 4070. personally im getting a 6800 for around 400usd and a good quality 850w psu for future upgrades.",
      "The 4070 is fantastic. DLSS3 is soooo good and the card is incredibly power efficient. My PSU is only 550W and I have had no issues.",
      "I'm seeing used 6950xt local to me that are going for around $500~ US. This depends on region and all that good stuff, but a 6950xt for $500 is excellent value.",
      "Het the monitor and try it as it is first.",
      "Used: RTX 3080 (undervolt it a bit to save huge power on little performance loss)\n\nNew: RTX 4070/Ti\n\nThese should be good enough for High 1440p gaming for next 2-3 years",
      "Absolutely it is! Of course I am biased because I have one lol. But I found a barely used Founders Edition on my local Facebook Marketplace for only $400! Apparently the kid had convinced his parents to buy him a 7900XT for his birthday, so he was just getting rid of his old card for cheap… I felt like I was robbing him blind hahaha.",
      "I don’t know what games you are playing but other than the newest of the new AAA titles full of bloatware, the 7700xt will handle 1440 just fine.",
      "At Micro Center they have new 6950 XT for $550",
      "Why would you buy a new one if you only want 1440p 60fps?\n\nThe 3060 is perfect for this and 60 fps is no problem in Ultra Settings.",
      "For most ppl, Microcenter is a far off  fabled land, existing in an alternate plane of reality.",
      "Mate 60fps is nothing nowadays a 1080ti could do that and some.\n\nI have 12400 and the following gpu\n\n3070ti,  utilised@85% due to 12400 bottleneck\n\nI play 1440p setting high/max no rt\n\nApex legends  144fps constantly no drops\n\nPugb                 140fps constantly no drops\n\nAlso play cod warzone2 110fps constantly no drops \n\nThe 4070 is so much more powerful than your current impressive like 3x more\n\nIf you only want 60fps at 1440 1080ti equivalent would do it \n1080ti 2080 3060ti rx 5700.   Imo\n\nFor 144fps go for 3070 3070ti rx 6800 \n\nYou could have more fps By second hand you’ll save so much money.",
      "4060ti is power efficient."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "rtx 4060",
      "4060",
      "rtx 4060 ti",
      "4060 ti"
    ],
    "title": "[Techgage] NVIDIA GeForce RTX 4060 Ti 8GB Creator Review",
    "selftext": "",
    "comments": [
      "Cheers for sharing this. I can't help but wonder why it's getting downvoted to oblivion. Talk about a buzzkill after how much work it takes to put these articles together."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "4060",
      "4060ti",
      "4060 ti",
      "4060 8gb"
    ],
    "title": "European prices: 4060 8GB (329€), 4060 TI 16GB (549€) or 4070 12GB (659€) ?",
    "selftext": "Here in Germany the prices are a little different than US. All prices mentioned in title are Founders Editions for a better comparison. \n\nI am planning on upgrading from my recently build PC and only current on-board iGPU (i5 13600K, Intel UHD 770)\n\nI have a 4K 144hz Gigabyte M28U Monitor and I mainly play Fortnite and wanna do some Stable Diffusion and Cinema 4D work. \n\nI don‘t want to spend 1700€ for a RTX 4090 and all the other 40 series cards are also not good, price to performance wise, as I‘ve read here and other subs. \n\nI want to spend as little as possible until the 50 series releases and hopefully is better price to performance wise. \n\nWhich of those 3 GPUs would you recommend?\n\nI don’t know if a regular 8GB 4060 will be enough or if a 16GB 4060 TI is better for productivity then a 12GB 4070?\n\nPrice wise also, a 4060TI is so close to a 4070 that I would rather just get a 4070 but again the 4070 only has 12GB\n\nAlso made a post previously, where some where suggesting getting a 3060 (TI) but that was before the 4060 was official. \n\nWhat would you recommend, what would make the most sense? Price to performance wise and also maybe be enough for 4k 60fps gaming.",
    "comments": [
      "The 4070 is obviously much faster than the 4060Ti 16Gb in all practical gaming scenarios. There are some hypothetical situations in which the 12Gb may end-up being insufficient and the 4060Ti with 16Gb will push a few frames ahead, but when you get to that point, it is not like the 4060Ti will have enough raw power in its chip to run games smoothly anyway. It will be like the few odd instances in which the 3060 is better than the 3070 due to more VRAM, but neither will be running the games reasonably at that level anyway.  \n\n\nI would vote for the 4070 and the 4060 (vanilla). Both 4060Ti seem to be terrible cards for their asking price.",
      "Buy that 599€ 4070 (Gainward Ghost from Alternate, or 608€ Zotac Twin Edge OC from Mindfactory). It's subpar for 4k, but you wanted cheap until 50 series. Lower tier cards aren't notably better than 3060 Ti and it's quite painful to consider the idea of buying a 8 Gb 4060 when you can get much better performing 12 Gb 6700 XT at the same price.\n\nIf 4060 and 4060 Ti price difference is going to be like that, then Ti might be initially the worst deal of this generation.",
      "Yep, here in Europe we have higher prices than USA. Here in Spain we had an offer this week 619€ 4070, but I ended getting an RX 6950XT for 639€ with a free steam Last of Us key. \n\nI’ve lost a lot of RT performance compared to my 4080 (had to RMA it), but I can still play decently in my 4k display disabling RT. Also it’s 819€ cheaper…\n\nIt’s a temporal solution until 5000 series or 4000 series prices drop here",
      "Honestly, for 4k I wouldn't even look under 16 GB if you want any kind of future proofing (even though that term is funny nowadays). Maybe even one of the 20 GB AMD's. Or maybe I just went huge overkill and picked up 16 GB card for 1080p 144hz gaming.",
      "I just spent most of the day going mad searching all info about 3090 because there is a good offer for one at a shop. It doesn't mop any 40 series so far (it will mop the 4060s)\n\nIt goes neck on neck with the 4070 ti, game dependant if it stays tied or one of them has a little % advantage on the other one.\n\nIt is basically a tie with the 4070ti where one has to decided what is better double the vram vs all the fancy new software.\n\nThen the 4070 is slightly worse but could still be a good option depending on factors.\n\nSo no moping floors for the 3090 vs 4070 and 4070ti.\n\n4060s are hot garbage so my grandma could mop the floor with them if she was baking gpus instead of cakes. Problem is that 4070s  are pretty pricey and 3090s are difficult to find, even more difficult at a good price",
      "I purchased a 4070 a few weeks ago, I'll stick with it. I'll probably switch faster than time though (coming from a 1070).",
      "If you're lucky in about three years time there will be five games that use the neural compression and there's no guarantee all of them will even be worth your time, don't even think of banking on it as a way to save low VRAM cards from collapsing.\n\nThis tech is not coming to the market for a good while and even when it does it won't be widespread because why would it be?\n\nVast majority of game developers/publishers aren't too hot on the idea of doing more than bare minimum when it comes to optimizing the PC ports of their games, because it takes work and that makes them nauseous.",
      "But if it’s for the price of a 4070, a 3090 would fair much better.",
      "It rly depends on the games you are playing but you can play on 4k 60fps with a 4070.",
      "If you want my honest reply, maybe the 4070 Ti would be a good card for 4K 60 fps gaming however the bus and memory amount will be a limiting factor for it.  \nIf you have 550 euros to spend and want great performance and 16 GB of VRAM go for the 6800 XT as it is as fast as the regular 4070. The other option would be to wait for the 7000 series to see what AMD offers.\n\nUnfortunately in this 40 series unless you spend big and get a 4090 you won't get a great perf/euro value nor net performance as they have been calling every card like the one above (for example from the specs compared to the top tier card the 4070 should be called 4060 and so on and so forth) while pricing the cards to tiers above what their original tier price should be (the 4070 which is a 60 class card is priced like an 80 class card).",
      "In the US the 6700XT is like $80 less than the 4060Ti. \n\nUnless you really want that power savings or software features it's hard to recommend Nvidia at budget prices.",
      "The only viable cards at the moment for performance and futuribility are the RX 6000 series cards as the the 4000 series offers really bad performance per euro and performance in general for the resolution the cards should be aimed to.",
      "No gaming easy choice, mo vram mo betta, it means you can handle higher resolutions.",
      "Yeah but I also heard of AI infused drivers coming this year, also the neural compression seems to align well to that and is something they need now, not later.\n\nAdditionally we have 2 or 3 weeks without a new driver, I expect a new one with the aforementioned AI part to be released any time now.\n\nSo maybe it will work at the driver level and not require the games to implement it, perhaps?",
      "I'm gonna go against the flow and recommend the 4060ti 16GB for the simple reason that Stable Diffusion loves the VRAM.",
      "why not a 6700 xt or 6700 or a A770",
      "I think more vram is essential for your situation. 4k will gobble up any of these cards really. Wait for 4k benchmarks and pick either the 12GB or 16GB.",
      "I would say the 4070 now that a new way to compress textures will be out at some point (soon I guess).\n\nUnless that doesn't apply and they load uncompressed in VRAM. I'm not sure.\n\nCan someone shed some light here? Is the new neural compression a driver thing and all games will benefit? If that's the case then 12GB would be fine...or at least not such an issue.\n\nI think that's what NV wants to achieve right? Better compression and less utilized VRAM instead of having to provide more VRAM.",
      "Based on how the prices have been : It will be €359 for 4060, €479 for 4060 ti  8 GB and €559 for 16 GB",
      "How much are amd cards?"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "4060"
    ],
    "title": "RTX 3070 Still worth it in 2024?",
    "selftext": "EDIT 2: I've figured out my card is the Asus Tuf gaming 3070 ti, and I am no longer planning on upgrading for now  \n  \nhi, I've had this 3070 for about 4 years and recently upgraded to a 4k monitor, i bought this at the worst time in the market in late 2020, but I've seen videos on Pcs with 4060s and semi decent cpus for only about 700 refurbished, my pc costed about 2,200 CAD, and this was my first so i got a prebuilt, wondering if i should upgrade to a 4060 or should I stay, with my 3070,\n\nASUS TUF Gaming NVIDIA GeForce RTX 3070 OC Edition Graphics Card- PCIe 4.0, 8GB GDDR6, HDMI 2.1, DisplayPort 1.4a, (copied from what i think is my card off the internet, Idk if its an OC edition or a TI)\n\nIntel 10700k I7  \n(idk my motherboard)\n\n16 gb ddr4 ram\n\nI use this rig for gaming, music production, and video editing.\n\nEDIT: Most people have told me to wait for the 50 Series to Upgrade to a new card or for 4090 / 4080 prices to drop, which i will",
    "comments": [
      "4060 is a downgrade. \n\n4060ti is a sidegrade.\n\n4070 is an upgrade.",
      "4060 isn't even an upgrade, lowest upgrade I would target with a 3070 is a 4070 Ti Super (4070S wouldn't be bad but you want 16 GB of VRAM at 4k going forward)",
      "3070 performs better than 4060 unless you involve DLSS frame gen. But then you can just buy Lossless Scaling on steam to add frame gen to a bunch of games.",
      "Thanks! Think i will stick with my current since the card seems to be an uograded version",
      "what are you even ranting about.. 3070 is solid gpu",
      "Just wait for the 5000 series at this point. Not long now.",
      "Not when fsr3 is a thing. 4060 is much slower in raster and not every game has frame generation. Its a downgrade",
      "Oh thats why they were so cheap",
      "I'm still rocking a 3070 and have no issues at 4k 60hz medium-high settings",
      "4060ti is a straight up downgrade at 4k",
      "I dont know much about it, thats why i came here for more information",
      "You would have to upgrade to at least a 4070 ti super (~800) to really have a big jump in performance. I suggest waiting for the 5070 around early next year.",
      "are you sure? when the 4000s were released i could have easily walked into best buy and picked one off the shelf any time i wanted",
      "you can use the fsr frame gen mod in certain games is you really want to, but I really wouldn't consider dlss frame gen a feature worth \"upgrading\" for.",
      "The 3070 launched in October 2020, so yeah coming up on 4 years ago. The only new generation since then has been 40 series which came out in 2022. The 4070 from that stack actually launched later than the 80/90 launching in April 2023 so it's only just over a year old at this point. So even though your PC is coming up on 4 years old, it's still really modern.  \n\nCheckout the techpowerup page for the 3070 [here](https://www.techpowerup.com/gpu-specs/geforce-rtx-3070.c3674). Scroll down to the relative performance section and you can get a quick estimate to how it stacks up to other cards. The 4060 is only 79% of a 3070, so that would be a downgrade. The 4070, is only about 20% better than a 3070, so not a huge uplift either. If you didn't have a GPU, neither are bad options, but given that you already have the 3070 both seem like bad value. You mentioned in another thread that yours is an OC model or upgraded model, and while sure it might be a few mhz higher than a stock card, those for the most part are marketing gimmicks and can mostly be ignored. A 3070 will perform within 1-3% of any other 3070 on the market. An Overclocked (OC) 3070 is still a 3070, so you won't see any huge gains over the stock performance.  \n\n\n50 series is rumored to debut in the final quarter of this year. It will most likely just be the top tier skus like the 80/90 but the 70 will follow eventually. When that generation drops, it might be worth evaluating again if you want to upgrade.",
      "60hz it’s great for single player..\n\nBut 144hz would be noticeable difference those those demanding multi player games like COD, Tarkov, Fortnite, ect",
      "A 4060 isn't really an upgrade over a 3070, so I wouldn't do it.",
      "I got a 3080 FE and 3060 ti for MSRP in 2020 and the 4080 was available everywhere here because no one was buying them for £1200.",
      "Not long? LMAO. You will only see 5090 and 5080 this year and they will be priced at 2000/1200 dollars and up.\n\n5070 and 5060 won't come anytime soon. Nvidia faces no competition and has 99% focus on AI.",
      "Yeah Ill be sticking my 3070 atleast till the 50 series"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "rtx 4060",
      "4060"
    ],
    "title": "RTX 3060 or RTX 4060?",
    "selftext": "I currently have a GTX 1660 and want to upgrade. Currently I’m looking at an RTX 3060 or an RTX 4060 since they’re both $300 but stuck on what to get. I’m leaning towards the 4060 since it’s the next gen and performs decently better than the 3060 but the VRAM for the 3060 is 12gb while the 4060 is only 8gb. A lot of people say I should prioritize the amount of VRAM since games now a days take up a lot but I’m not sure.",
    "comments": [
      "i’d take the 4060, dlss 3.5 and power efficiency is a plus, assuming you’re not cranking everything up to the max or turning rt on, you’d be fine with 8 gb in most games at 1080p",
      "- IMHO the AMD RX 6700XT offers better performance for the money than both GPUs.    \n- Nvidia at the moment offers a better featureset with DLSS 3 and frame generation    \n- Looking at Techpowerup's review of the RTX 4060(https://www.techpowerup.com/review/msi-geforce-rtx-4060-gaming-x/31.html), the average FPS:   \nAt 1080P:   \nThe RTX 4060 8GB averages 96 FPS   \nThe RTX 3060 Ti 8GB averages 106.4 FPS   \nThe RTX 3060 12GB averages 81.3 FPS   \nThe RX 6700 XT 12GB averages 110.1 FPS   \nAt 1440P:   \nThe RTX 4060 8GB averages 69.6 FPS   \nThe RTX 3060 12 GB averages 60.4 FPS    \nThe RTX 3060 Ti 8GB averages 79.5 FPS   \nThe RX 6700 XT 12GB averages 81.9 FPS    \n- Look at the data and make up your mind.",
      "sure, but if game supports dlss and reflex, nvidia will perform better",
      "That’s what I originally thought but I keep finding websites and forums that contradict each other with some saying 8gb or enough for most games at 1080p and then other sites saying 8gb at 1080p has become not enough",
      "there are a handful of unoptimized games and playstation ports that require, for God knows what reason, a whole lot of vram at the highest settings, you should be able to play majority of the games with 8 gb of vram, for those handful of games, you can just  lower the settings",
      "I'm using 8gb for 1440p. Maybe I'm doing something wrong, but I am yet to run into any issues",
      "They're the same price. With 6700 XT you get 13% more raster performance but it has 80% higher power consumption and you're losing DLSS. For new games with DLSS the 4060 is gonna be better and for older games its not that relevant because they both can run it well.",
      "At the same price?  The 4060 is better.  Yes the 3060 has 12GB of VRAM but it was originally designed for 6GB of VRAM but when that proved to be useless in practical ray tracing applications they just doubled the quantity without making the bus any bigger -- you're not going to actually break 8GB in practical use at the kind of resolution the 4060 is designed to crank (native 1080p but full feature set).",
      "Tbh you can go way further, im playing cyberpunk path tracing a 1440p with texture resolution in medium, you could crank it up to high with 12 or 16gb.\nFramegen really makes it worth it, im averaging 55fps with it on",
      "AMD drivers were very bad until rx6000 series. They are making okay drivers for last 2 years now. Just stay away from Beta drivers and you would be fine.",
      "I have 3 PC at home, 2 with AMD (7800XT and 7900XTX) and one with RTX 4080. Never had issues with them. Drivers are much better than was like 3-4 years ago",
      "Tons of click driven misinformation from the major YT channels on 'VRAM'. No need for more than 8gb - even if the game 'provisions' more than that....it's not actually using it and if a given card has lower VRAM than what the game technically can provision for it will still play totally fine. Don't believe me? Just watch the videos comparing the 4060ti 8gb vs 16gb. \n\nI would definitely get the 4060 for the latest features that come with the GPU",
      "I have nothing against AMD I’ve just heard a lot of negative things about their gpu’s. What would you say about them?",
      "Me too. Rtx4060 1440p everything and no issues at all",
      "4060 as frame gen is crazy good",
      "Save a bit longer and get a 16gb 4060.\nYou will get a few extra years out of it this way.",
      "The 8gb of vram is fine for ultra max settings plus Ray tracing @ 1440p dlss and I can confirm that because I’m actually playing everything max ultra @ 2560x1600 resolution which is slightly higher than 1440p on Our Acer Predator Helios 16 laptop with 8gb Rtx 4070 and I’ve never hit the vram limit even in unreal engine 5 games like Remnant 2 or Fortnite all epic settings plus epic lumen global illumination & reflections with virtual shadows on epic and hardware Ray tracing enabled…….. \n\nI’ve played other games like lies of P at native 2560x1600 all max best settings, and same thing nowhere near using 8gb, and I’ve also played doom eternal all ultra max settings plus hardware Ray tracing enabled, and nowhere near 8gb……\n\nKindly Excuse the copy & paste as I’m only trying to help !",
      "you mainly need gigantic amounts of vram to power through unoptimized game launches like star wars jedi survivor, play cyberpunk 4k ultra or load streets of tarkov ~ though setting textures to medium helps in tarkovs case. \n\nthese are not necessarily 4060 use cases.\n\n\nusing dlss decreases the vram usage too though which is helpful! \n\n\nif you are on an old mobo with PCIe 3 for some reason, the 4060 will be bottlenecked because it doesn't have x16 lanes \n\n\nbut yeah just get a 4060, if the vram problem becomes a real issue the card will be obsolet",
      "Get [THIS 6700XT](https://www.newegg.com/asrock-radeon-rx-6700-xt-rx6700xt-cld-12g/p/N82E16814930056) for 299$ , perform almost like an RTX3070 / RTX4060 ti",
      "8gb is fine for ultra max settings plus Ray tracing @ 1440p dlss and I can confirm that because I’m actually playing everything max ultra @ 2560x1600 resolution which is slightly higher than 1440p on Our Acer Predator Helios 16 laptop with 8gb Rtx 4070 and I’ve never hit the vram limit even in unreal engine 5 games like Remnant 2 or Fortnite all epic settings plus epic lumen global illumination & reflections with virtual shadows on epic and hardware Ray tracing enabled…….. \n\nI’ve played other games like lies of P at native 2560x1600 all max best settings, and same thing nowhere near using 8gb, and I’ve also played doom eternal all ultra max settings plus hardware Ray tracing enabled, and nowhere near 8gb……"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "rtx 4060",
      "4060",
      "4060 8gb",
      "rtx 4060 8gb"
    ],
    "title": "Should I buy a rtx 3060 12gb or a rtx 4060 8gb",
    "selftext": "As the name suggests I am wondering whether I should by a 3060 or 4060. I plan on mostly using it for gaming but also for some school work.\nJust curious about what the main benefits to each are.\nThanks",
    "comments": [
      "1) FYI, it's best if you post your full system specs in order to get better advice. Also what is your target resolution and FPS?   \n2) If you look at Techpowerup's review of the RTX 4060 8GB (https://www.techpowerup.com/review/msi-geforce-rtx-4060-gaming-x/31.html) :    \n- At 1080P the 4060 8GB averages around 96 FPS and the 3060 12GB 81FPS.    \n- At 1440P the 4060 8GB averages around 69 FPS and the 3060 12GB 60 FPS.   \nIMHO it's not worth getting the RTX 4060 GB. A used RTX 3070 Ti or RX 6800 would be a better choice.",
      "why tf would you be doing pathtracing on a 4060??",
      "I’d honestly lean 4060. The 12gb of Vram wont make much of a difference probably down the line with a card of that caliber plus you have access to DLSS3",
      ">24 gb ddr4 RAM\n\nAre you running 3 sticks of 8GB? If so you're losing performance. You've got a 2-channel memory controller so the number of sticks you're using should be a multiple of 2: 2 sticks, or 4 sticks. If however you have 4 sticks set up in 8-4-8-4 fashion, then you're good :)",
      "if OP is only gaming and doesn’t care about RT performance, which is kinda pointless at that performance tier anyhow, it’s a valid recommendation. if OP needed Nvidia for specific workflows tho that’d be another thing",
      "Ok, so where is he going to find a 2080 Ti for 250 dollars Canadian when the cheapest on eBay is 400 dollars Canadian, and also because the ones that say 250 dollars are for parts only.",
      "None, dont do it. Dont know how possible it is for you to to get a 3070 atleast but aim for that. 50 bucks here and there will leave you happy",
      "24 gb ddr4 RAM\n\ni7-11700 processor \n\nMy target resolution is 1080x1920 And fps being 120-165 fps\n\nSorry didn’t think about putting my specs there",
      "Hey asshole, try not being an asshole lol.",
      "word, i’m running 16 GB w a 5600X. might be time to upgrade my RAM. and hell yeah will do 😹🫡",
      "If you absolutely must choose between those 2, I'd say go for the 4060. It's more powerful and uses less power and also gets to fully utilize the frame generation of DLSS3. In that case, you will probably be able to use either DLSS3 or FSR3 on almost all games which will extend the life of the GPU while the 3060 would be locked out of DLSS3 (well the frame generation part).\n\nIf you don't mind getting a used card, just go for a 3070 which should be cheaper than both 3060 and the 4060 bought new and straight up annihilates them.",
      "Everyone has access to DLSS 3/3.5 with an RTX card. Only Frame Generation is locked to 40 series cards.",
      "Alright thanks",
      "are u sure that’s with the full pathtracing mode n not just regular RT? i have a 3080 12 GB, and, at 1440p with ultra RT lighting and RT reflections on, i’m getting 60-70 fps using DLSS quality. i don’t think i’d even get those frame rates using the path tracing preview preset using DLSS balanced",
      "It’s path tracing, ultra settings, 1440p DLSS BALANCED. 28-65fps (middle of city versus closed quarters).",
      "damn i might have to give it a try n see what frame rates i get then. that’s good to know. are u running 16 GB or 32 for RAM. i’m wondering if that or my CPU might be holding me back somewhat",
      "32gb ddr4. 5900x ryzen 9.\n\n\nGive it a try. You won’t be able to go back. Turn off the HUD (leave the map). See you in a week xD",
      "4060 for frame generation alone specially if your only doing 1080p as VRAM.\n\nIf you're not in a rush hangfire see if the cards drop further specially if you wanna run 1440+ later.",
      "Just go for what benefits you more, whether you need more Vram or DLSS 3.5.",
      "Get 4070"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "rtx 4060",
      "4060",
      "rtx 4060 ti",
      "4060 ti"
    ],
    "title": "Would the 4060 Ti be worth getting in this scenario (jump from GTX 970)?",
    "selftext": "Hey everyone!\n\nI have heard a lot of things about the RTX 4060 Ti GPU, and most of them (if not all?) were not good. A friend of mine is looking to upgrade his GTX 970 (yes, you have read that right) and unfortunately the 4060 Ti seems to be the best choice without breaking the bank (at least here in Brazil).\n\nI told him about alternatives, such as the RTX 3080 or maybe an AMD RX 7 series card, but they are unavailable or much more expensive.\n\nSo I wonder if the 4060 Ti would still be a bad purchase if you are making such a giant leap (from GTX 970 to RTX 4060 Ti) and if you cannot get anything else at a similar price. FYI he would mostly play the upcoming Dragon Ball Z Sparking Zero game on a 4K TV. But of course, it would be good if the GPU was useful for upcoming games.\n\nOne thing that caught my attention (negatively) was that by searching for Brazilian stores, I could only find the 8GB VRAM version of the 4060 Ti. This is definitely a deal-breaker to me, since my understanding is that 8GB of VRAM could not be enough to max some current games - imagine ones in the future.\n\nThanks a lot!!\n\n",
    "comments": [
      "4060Ti for 4K? Hardly",
      "If he intends to play the latest and greatest games on a 4K TV, he will need to get better than a 4060TI if he wants to be able to turn settings up and play at a decent frame rate.\n\nThe 4060 TI will do what he wants, just not very well",
      "I'd go with the 3080 or a 4070 over the 4060 ti personally. DLSS3 aint worth that much raw performance difference, plus FSR 3 is out so thats prolly gonna be implemented in many games as a decent alternative if you want the 3080. The 4070 speaks for itself. EDIT: Neither the 3080 or the 4070 are what you would consider a \"4k\" card but I assume availiability and/or pricing hinders you from getting a higher tier than that.\n\nBut if pricing or availiability is an issue you've already got your answer with the 4060ti. It's definitely not what you would consider a 4K card, but I would wager that with the DLSS 2 on performance mode you could run DBZSZ at decent enough framerates.\n\nHow good is this card for the future at 4K? Not very unfortunately, low VRAM and overall performance (same level as 3060ti basically but with DLSS3).",
      "Lowkey if it’s the only option get it. 8 gbs will be fine if he’s only playing games like",
      "I've got a 3070 which is similar in raster performance to the 4060 Ti and game on a 4K TV. In modern demanding games it won't handle modern AAA titles at native 4k too well or even upscaled, the 8GB VRAM is a big bottleneck in both cases.\n\n1440p fares much better as a base resolution but the heaviest games like HFW and Black Myth Wukong require DLSS Quality (960p render resplution) on top of that and optimised settings to get a stable 60 FPS\n\nSubjectively 1440p even with DLSS Quality still holds up reasomably well on a 4K TV but it won't offer a top end experience by any means\n\nOlder (pre-PS5 era) or less demanding games run fine at native 4K though",
      "> his GTX 970 (yes, you have read that right) \n\n\nHey man, I'm still trucking on with my GTX970 that I bought exactly 10 years ago. (Waiting for 5080 now)\n\n\nIt's good enough for many games still. Not the newest stuff, or the highest settings.",
      "I mean, it will be a huge leap from a 970, but he'd do better looking for one of the higher tier 30 series on the second hand market if he wants to do 4K.  The 4060-Ti is great at 1080p, mostly fine in 1440p and not suitable for 4K unless it's eSports.",
      "I just got a 4060TI, and it's a great card. I can play space marine 2 at 70-80 FPS on high on a 1440p monitor. \n\nWe wont be able to play games at native 4k, with a high FPS, but it's still a great card, and much better than his 970. Also it's very power efficient, if he did get a 3070/3080, they use a lot more power, so he may need to also upgrade his GPU",
      "I would only get 4060ti if it's the 16gb version, personally I wouldn't bother with anything less than 8GB.\n\nYour beat choice to to either find a better card used for the same price as a new 4060ti or wait for new GPUs to be released",
      "This is just theory. I'm on MSFS 2020 @4K and, at least actually, frame gen gives almost same quality as normal frame gen probably due to improved AI in this tech . This based on screenshots comparisons.\n\nMy choice is: 45 to 65 fps with Quality DLSS or 90-110 fps with frame gen and, as when I'm flying or playing other games, my attention is mostly on the game and not on the single pixel's correctness. My choice is then always on frame gen for higher fps (by my point of view a flight sim should be not least than 50-60fps) as my display also supports gsync 60/144 hz.",
      "The only thing not good about the 4060 seriess in general is the price not what it actually can do. Yall seem to get that confused. The 4060 ti is a great lower end gpu that performs well. 4k? No you can upscale for sure it def out performs what users not using it think. But no it's not a 4k card. You can do all games 1080p maxed out and some 1440p gaming.",
      "Tem 3070 ti usada aqui no brasil pelo preço de 4060ti ou mais barata",
      "Please confirm the target resolution. For 1080 yeah it’s just right. For 1440 the 4070 and the biggest one if you can afford, and for 4k 4080 or4090",
      "4060ti is intended for 1080p first and most. It’s decent on 1440p with the help of DLSS and FG. What it’s not is 4k. It’s like having 12 size foot and wearing 11.5 size shoes. Yes it can work but sooner than later pain will take over.",
      "The new graphics drivers made performance suck ass. Nvidia does this shit on purpose and its irritating AF. Thats why I didn't download the past 2 until I finally decided to put some faith into their honesty/ability and welp, turns out to be the wrong move. Thanks nvidia",
      "Get a 6750xt.\n\nIt's cheaper + has 12gb of VRAM and is slightly faster, and even though it sucks at RT, he wouldn't be touching RT anyways at 4k at this price point.",
      "I would recommend he just save up more and grab a RTX 4070 Super. Honestly I'm pretty sure the new DBZ game isn't going to be that demanding, even at 4K. So a 4060 Ti probably would be fine for it, but if he wants to play newer games at that resolution, then the 4070 is way better for that. \n\nAn AMD RX 7800 XT would be a great value option since it's cheaper here in the US, but I don't know the Brazilian market to say the same for you.",
      "If you’re willing to wait a few more weeks, you can possibly find deals on 4070ti super or even a 4080S. Gpu deals usually happen just before Black Friday.",
      "add a 10 to it then we're talking. best performance-to-price as well.",
      "It absolutely can do it IF you have the 16GB variant.\n\n\nThe 8GB variant will do 4K for all 8th gen games, though."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "rtx 4060",
      "4060",
      "4060 8gb",
      "rtx 4060 8gb"
    ],
    "title": "RTX 4060 8Gb solid for most games?",
    "selftext": "I just recently bought a pre-built with this graphics card and want to see if it will run most of the games I play with ease. I play a lot of warzone and open world games like rdr2 and so on. I currently have a 2060 and it seems to skip alot graphically when I play these games so I'm hoping I didn't just waste my money on  this new pre built",
    "comments": [
      "There aren't bad GPU's... just badly priced GPU's.",
      "They are literally the best value gpu from the 4000 series.\n\nPeople here really so obsessed with their anti nvidia narratives that they ignore all facts and make up their own reality, it is insane.\n\n\\+ the product they are directly competing against is the 7600 that is 10% cheaper but also 2% slower without RT and 20+ slower with RT(making the use of RT in 1080p possible) while having worse power consumption and worse features.",
      "4060 is about 50% faster than 2060. Really underwhelming performance improvement if you consider it is a 2 generation jump.",
      "When that happens the 3060 is running at 30 fps and consuming a lot though, so what's the point?",
      "I'm 1080p ultra yes. Maybe 1440p with some graphics downgrades",
      "4060 and 4060ti 8/16gb are really bad value for price to performance. Hopefully you did get it at a good price. It is quite a bit better than your old 2060. I will say it will give you decent performance for most games but demanding games you will need to turn down settings for 60fps.",
      "i have the rtx 4060 ti and i use it for 1440p.  yes the card is about 20% faster than yours but they both can utilize the latest dlss and frame gen from nvidia.  as long as you dont want to push ray tracing you will have a good experience in 1080p and probably 1440p 60 fps in games that allow you to use the tech in your card (frame gen and dlss).  i play games on ultra well over 60 fps without dlss except starfield.  that was which was running about 45-70 until i installed the dlss with frame gen that i was talking about, then this:\n\n[https://cdn.discordapp.com/attachments/233376294207750144/1149143958098812969/image.png](https://cdn.discordapp.com/attachments/233376294207750144/1149143958098812969/image.png)\n\nwith dlss most games will get me 120 fps and with frame gen if a game is struggling it is like magic.\n\n**so dont feel like youve wasted your money.  if you can upgrade and want 120 plus consistent in 1440p you might want to see if they can let you upgrade the prebuilt with a 4070.**  i of course would recommend any rtx 40xx series card and tell you to determine what value means for yourself.  if you appreciate frame gen and dlss you get that plus low power draw and max settings 1080p with your card if that is your native resolution.  you dont need to worry about vram unless your concern is max settings (ultra graphic textures, hbao, ssr, ray tracing) 120 fps consistent for the next 4 years - then you'll need a 4070 ti or 4080 in that thing and the price starts to creep.  if you want to do all that with ray tracing in 4k well that's a 4090.  try it and see how it goes my dude.",
      "It's good for 1080 if you got it at a decent price. I have it in my rig and have no issues at 1080. Works with ultra maxed out on some games. You can always turn off ray tracing and the DLSS will do the rest. 16GB VRAM plus is the future",
      "Well...don't feel bad. Just keep in in 1080p low/medium settings/dlss on for recent released 3A games. Older games you might get away with 1080p high settings but as soon as you toggle that RT on, everything is gonna tank.\n\nJust keep gaming in 1080p and play around the settings in between low to high and try to get 60fps. \n\nIf you want to game in higher resolution and higher graphic settings, you need at least a 3070ti with dlss on to feel somewhat adequate in 27'' 1440p. \n\nIf you wanna go Ultrawide, 4080 minimum, recommended 90 series moving forward.\n\nIf you want 4k, 90 series moving forward.",
      "25% each gen isn't the worst ever but it should be a $250 card at most",
      "# bro, you have RTX 4090 AND dare to say the RTX 4060 runs at low/mid it can run almost all games at ultra settings RTX off with respectable frames at 1080p and 1440p 💀",
      "People like you need to stop spreading misinformation, it is the best value 4000 gpu. It is objectively the best value gpu of the 4000 series if you consider price/fps ratio",
      "Because it gets beaten by the 3060 when it runs out of vram lol",
      "For reference look at 2070 to 4070 100% performance jump and +2gb vram albeit with 20% more price. Another point to be made is whether 50% performance jump is worth it to upgrade your gpu.",
      "What is your respectable frame rate and time?\nThis answer was posted when star field was released I believe and you tell me if 4060 could run that game well in max setting with no dlss. \n\nMy standard is run games on the ultrawide max settings natively and have at least 90fps and above on the 1% lows.",
      "$200 would be fine",
      "Not really. 3060 Ti actually performs much better, despite having the same price. It will probably be serviceable for a year or two at 1080p, but many games are already running away from it.",
      "Thanks man this really put my mind at ease, appreciate the advice",
      "What drivers do you recommend for it? Seeing issues with every driver released since the 4060Ti came out!",
      "this is some real bs rtx 4060 does ultra 1080p 60fps+ on 99% percent of the games\n\nyes rt is gonna tank because its a rtx 60 series card it has always been tanking on those\n\nalso lets just ignore starfield alright its a unoptimized garbage mess the community is doing patches on it already"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "rtx 4060",
      "4060",
      "4060 8gb"
    ],
    "title": "Replacing my 1060, RTX 4060 and RTX 3060 are selling for the same price. Which should I get?",
    "selftext": "As per title. I was going to actually stretch my 1060 for another couple of years and get a 6060 (I was weirdly invested in keeping it going for ten years :P :V) , but it caught fire in a freak accident and I need to buy a new GPU (alongside a completely new system).\n\nRight now, in my country, the 3060 12GB and 4060 8GB are selling for about the same price. Which would this sub suggest I purchase?",
    "comments": [
      "4060, easy choice. More DLSS features, more efficient, a little faster. 8 GB is embarrassing for them, but realistically if you're playing on lower resolutions it's not that big of a deal.",
      "4060",
      "40 series for the added benefits of DLSS and frame generation would be my choice.",
      "Common sense getting upvoted? Is this Reddit?",
      "*benefit of frame gen. Rest of DLSS features, as in upscaler and RR denoiser, are awailable on all RTX cards.",
      "3060 for 12GB of vram\n\n4060 for Frame Generation and better power efficiency \n\nFyi, there are games where the 4060 loses to the 3060, and the 4060 only has 8G  of vram, so keep that in mind.",
      "Yeah, I'm sticking to 1080p for the medium term because I just don't have the cash to upgrade to a 1440p or 4k monitor, and tbh even if price wasn't an object, I'd still stick at 1080p because I value frames over resolution.",
      "The 4060 isn't a terrible card (it's not good, that bandwidth is trash) but it's the pricing that's a doublewhammy of garbage.",
      "WaIt UnTiL tHe 5060 lAuNcH\n\nIn all seriousness the 4060 is still the better choice if the price is the same, it got shit on at launch since it was more expensive and basically the same performance without dlss etc.",
      "I have a 3070 with 8 gb. You'll be absolutely fine for 1080p, none of my games struggled to run",
      "If the 4060 and 3060 are selling for the same price, it’s a no brainer to get the 4060. Even if it’s 8GB compared to the 12GB 3060 it still gets outperformed by 4060",
      "At 1080 and even 1440p the 4060 isn’t a bad card. Its actually pretty solid, but It’s just not the best card you could get for the price and performance. That combo has given it a bad reputation.",
      "Well, it's not 'marketing', but 8gb is plenty for a low end 1080p card.",
      "Yeah I'm gonna have to disagree on the 1440 part.\n\nIt's one thing if the generational uplift is bad but that in some cases a 3060 ti can be on par with it even if early in launch is seriously trash especially when you can note the smaller bandwidth - very clearly cheapening out was occuring.\n\nNot only that but the 8gb versions very obviously suffer from performance issues when VRAM is maxed out.",
      "to be fair, I don't anticipate ever progressing beyond 1080p gaming for a **long** while.",
      "I actually have a 4060 and have tested it. Obviously it’s not going to be a perfect 60fps playing online fps games, but It can indeed do 1440p with story games. No offense but I find people who speak about what the 4060 can’t do have never actually used one and are really just guestimating based on what they’ve read online.",
      "4060 easy choice, why?\n\n1. More efficient  (performane Per watt)\n2. Frame Generation feature (better than FSR3)\n3. 15% better performance",
      "I would agree. I just upgraded to a 4060 from a 1060 6gb and it's night and day. But I'm old and still do 1080",
      "As long as the v ram is limited under 8 it can run any game 🏃...just have to tweak some unwanted settings, that have little to no effect to game quality....(For 1440p/1600p)..@ 1080p won't lack vram as of now.",
      "Yea I meant it as satire as people will tell you to wait.\n\nPersonally I'm also waiting for 5070/5080 depending on price/performance but going half a year or more without a gpu to save a couple bucks and gain a bit of performance isn't worth it. Just get it now and enjoy it!\n\nBut good on you for not upgrading every release, it can be very tempting."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "rtx 4060",
      "4060",
      "rtx 4060 ti",
      "4060 ti"
    ],
    "title": "Community are not happy with the RTX 4060 Ti's measly 8GB of VRAM",
    "selftext": "",
    "comments": [
      "I feel like the only reason this exists is to normalize the 500 dollar price of an xx60 ti. Push people to consider the other one with 16GB RAM that's coming out later. 500 should not be a mid-range price. Maybe I'm cheap or something but sheesh.",
      "Don’t buy shit, won’t be shit.",
      "Some people are still buying cards to run 1080p.",
      "Sure but it's expensive for what it is.",
      "I'm sure people are still gonna buy them no matter what because nVdIA",
      "that makes a lot more sense now. i assumed USD not european currency my mistake.",
      "I would not even be that mad about the 8gb so much if it at least had a decent amount of performance over a 3060ti, but its laughable even in that respect.. then to add 100$ for another 8gb is just stupid..",
      "The narrow bus width is another complaint. They say: oh look! We added a ton of cache and then crippled it by narrowing the bus width.   The thing falls down on its knees at 4k. My 3070ti actually outperforms this card. Lol.",
      "Ah but I'm in Europe... it's going to be hella expensive for us.",
      "4060ti 16gb is $500, 8gb version is $400. It was officially announced last week.",
      "4060ti 16gb is $500, 8gb version is $400. It was officially announced last week.",
      "4060ti 16gb is $500, 8gb version is $400. It was officially announced last week.",
      "Well I did say 'dollar' to be fair. I still think it's pricey for Americans to begin with. And then when it gets converted to the weaker Euro, they usually also make it extra expensive on top of the difference as if nobody here would notice, lol.",
      "it's $400 not $500, 16 gb i heard was $470 not horrible prices honestly even if could be better."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "rtx 4060",
      "4060",
      "4060ti",
      "4060 8gb",
      "rtx 4060 8gb"
    ],
    "title": "Upgrading from 1070. ",
    "selftext": "So, it's about that time again and I've held off as long as I could.  \nI'm way behind in knowledge so I'm asking for advice.  \nI've been playing Rocket League and OSRS forever and didnt need to upgrade until now.\n\nI've been playing 7days to die which is not optimized and currently to get 60fps i need to set all settings to low... I would like to play on ultra with 60fps.\n\nI don't care for 4k  \nI'm running this monitor: [Acer Nitro ED343CUR VBMIIPPX 34”](https://www.newegg.com/acer-ed343cur-vbmiippx-34-0-uhd-hdmi-3440x1440-100hz-dp-3440x1440-165hz-va/p/N82E16824011448?srsltid=AfmBOop3q5gJMAdzZHVr1kA0MrdZ1Mh8APCV9jT4NauSoj7qGMeNWSX5)\n\nThis is my build: [PC Part Picker Build with GTX 1070](https://pcpartpicker.com/list/d2PwxG)\n\nMy inquiries:\n\n1. Would a RTX 4060 8gb get me what I want?\n2. Should I bump it to 4060ti?\n3. I read 8gb isnt much of a difference to a 12gb\n4. 2 fans or 3 fans. I heard if its 2 big ones that's better. idk\n\nThanks for your opinions!\n\nEDIT: Found this [ASUS ROG Strix GeForce RTX™ 4060 OC](https://www.amazon.com/ASUS-Graphics-DisplayPort-Axial-tech-Technology/dp/B0C7FNSHMQ/ref=sr_1_1_sspa?crid=16CD00LM3BXFN&dib=eyJ2IjoiMSJ9.tDG8t2Qu7V8LBiyGXyzmSHPFZqjVNNs-AM6jjO-_whMDnsJ7OKLyOL0eYo3cqkDcoDsnQHjeMxfqxb-ogD8fSYfMSiDZBw6GSt8zRwCjhqIjsnS1LAA_AOEUOePO0DzMm2e8DVStCERbxybR_WtHdneGmBoqhzD2DMztvXTkCl7rb817yaTHvHa4zT9mGT6Ythe7eL33YoylZmR0Fum3eWZ73Xhn3yc68BAB5eQH4g0.jRHX9Gn4_W1Tbs9cDP1a2ngCVUFtVfhVWE3YQQBsawg&dib_tag=se&keywords=rog+strix+4060&qid=1724880000&sprefix=rog+strix+4060%2Caps%2C147&sr=8-1-spons&sp_csd=d2lkZ2V0TmFtZT1zcF9hdGY&psc=1)  \nFound from someone online, newly sealed in box for $250. Yes, he said he would open the box upon arrival. Will update later.\n\n2ND EDIT: I picked up the GPU above, yea, no real noticeable differences but I'm happy that I'm sort of up to date now. I'll be able to also connect. Next computer will probably be a completely new build with a 12gb GPU for sure. ",
    "comments": [
      "4060 might be fine, myself i would go for a 4070 super. And also just a suggestion but second hand 30 series might be good aswell!",
      "dont listen to anyone who says to wait for next generation. everypne who wait will have to deal with supply issues. + scammers and scalpers in the mix. + potentially price increase because novelty and nvidia can do it\n\ngo for current gen for sure.",
      "Save more and go for a 4070 super if you upgrade the gpu every 6+ years.\n\nI know it's more expensive but it will be worth it.\n\nFor 8GB vs 12GB, you'll be totally fine right now with 8GB, but in a couple years you'll probably wish you had 12GB\n\nAs for fans, in some ways, yes 2 big ones can be better than 3 smaller ones because they spin a bit slower. Their pitch will be also be a bit lower which can be less annoying.",
      "> I read 8gb isnt much of a difference to a 12gb\n\nIf you're using your cards for so long, you definitely need 12+GB. And an ultrawide 1440p monitor surely would benefit from a 4070.\n\nIf it's too expensive for you, maybe wait for the next generation.",
      "That CPU heavily bottlenecks a 4070 super, so unless they are planning a full upgrade I think a 4060 is the best, anything more is wasted.",
      "Technically, you could wait till 5000 series releases and grab one for cheaper, or you could go for used 3080. Its still a beefy gpu, costs less, and absolutely obliterates 4060ti. If you dont care about dlss frame gen and your psu is good enough, go for 3080. I heard it can be modded to have fsr frame gen instead so you might not loose too much for not having dlss frame gen. I personally plan on buying one for myself, putting my trusty gtx 1080 to its earned rest. Still, I'd wait for 5000 release since the prices will drop even further, might as well snatch a 3080ti for same price.",
      "ill save this info for next time, thank you!",
      "To get the most out of a 4070 Super though you'd need to upgrade your CPU which would require a motherboard to match the CPU chipset aswell. Otherwise you'll be bottlenecking it a whole lot.",
      "Go at least for 4060 Ti. But if you go for 4070, maybe 4070 SUPER or better, you will benefit from your monitor resolution.",
      "never go lower than 4070.",
      "3440x1440p is demanding (60% of the way to 4k), i would never even consider a 4060 for it, due to how gimped it is. The Ti makes little difference.\n\nA 4070 would be massively better just due to the performance difference, and the (faster) VRAM.",
      "For just 7 days to die, you might be better off upgrading cpu and ram.  I used to run a 1080ti, switching to a 4070ti super didn’t gain me much in just that game.",
      "thanks for the heads up! edited original post",
      "Thank you for the advice! edited original post",
      "OP is looking at low end cards like 4060.\nThe 50xx series is launching say Jan but like previous gen only the high end is coming out next Jan. So unless OP wants to spend $1000+ for a 5080 there is no point waiting.",
      "2 years doesn't bother me, I have been using a 1070 for over 6 years now. I'm not trying to dish out more than $350.",
      "This made me check what CPU OP had (7700k) and I agree. I upgraded 2 years ago from a 6700k and 2070, and the 6700k was causing me to drop frames at 4k60 where it's more likely to be GPU bottlenecked.\n\nUpgrading to the 13700k with new RAM but with the same 2070 pushed the framerate back to a consistent 60 FPS.",
      "Ah u are right, my dumbass though it was a ryzen 7700 lol",
      "For gaming the GB of vram are bullsh*t. And for your monitor I'd recommend u a 4070 super since you have a 1440p monitor, but the 4060ti is a 1080p card that can let u try the next resolution (1440p)\n\nWith your rest of your pc, I'd say you need to upgrade too, hopefully to a 14400f is enough, 32GB of ddr5 ram (two sticks for higher and more stable frequencies) at 6000MT/s, and an ssd is enough tbh, even for the 4070ti super since this gen isn't that pc dependant",
      "Honestly if you're shooting for 60fps the 7700k should be fine. Esp if you crank the settings a ton. I would at least wait for the AMD 9000x3d chips to get released before thinking about that upgrade."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "4060",
      "4060 8gb"
    ],
    "title": "Rtx 3060ti vs 3070 vs 4060",
    "selftext": "Im looking to replace my 1660 super, my current options are:\n3060ti 8gb 240eur used,\n3070 8gb 300eur used, \n4060 8gb 350eur new.\n\nThe used cards are out of warranty and 2yrs old",
    "comments": [
      "3070 is the strongest so, i would choose this one. 4060 is very efficient and supports frame gen so it would be my second choice.",
      "3070 is beating even 4060ti on fhd. Difference gets bigger with higher resolution like 2k. 4060 is a waste of money at 350 euros.",
      "The 3060 ti would be good choice here price-performance-wise. To be honest with the level of performance of these cards, you won't need more than 8GB of VRAM. The 4060 is only on par with a 3060, so don't chose that one, unless you prefer new cards with 3 years warranty.",
      "6700xt",
      "Doesn't mean much when its the newest, just dlss frame gen is worthy mention, and even then, most games don't have it.",
      "The better choice would 100% be the 3070. Still beats the 4060ti in raster by a LONG shot. You’ll also be getting fsr fg once it come out. (Not saying it’s better than dlss fg. Just adding it as a plus)",
      "He’s considering the 3070, so I doubt he’s worried about power efficiency. Buying a worse performing card just for a feature that has been barely implemented in games is a terrible choice. Plus, it’s much cheaper",
      "Most new games will have it though, either out of the box or confirmed to be added",
      "Why not 4060ti? Cuz it performs like 3070....more efficient and has frame gen.....what's the price of all the gpu's mentioned at your place?",
      "I had the same debate for two days and settled around 4070 - non ti.\n\nI would upgrade from 3060 12 Gb and wanna future proof 1080p for the next 5 years.\n\n3070ti is better than 4070, but the arguments were, lower power consumption = no need for extra cooling solution, runs quiet, stays cool, smaller (will fit in my current case), just one 8 pin connector (will run with current power source) for 1080p it will be a walk in the park.\n\n3070 would be an upgrade to 3060 (non ti) for about 2 years from now.\n\nAs per nVidia lore 4070 ~ 5060ti ~ 6060 so yeah, two generations will bring more power but with 1070 you can still play some games today, hopefully ...",
      "3070 is the highest performing out of those. 4060 is the most power efficient. Also if you're playing a new ray tracing game like CP2077 then frame gen is only supported by the 4060.",
      "For a future card that is going to last past the next couple years you are going to want to have more the 8gb of vram. A lot of games already require it.",
      "Get the 3070",
      "which games do you play or are interested in playing?  \n\n\nAlso resolution...current CPU, motherboard, PSU case etc etc",
      "> by a LONG shot.\n\nWell not really. More like within 5% while being way more power efficient and supporting FG:\n\nhttps://tpucdn.com/review/nvidia-geforce-rtx-4060-ti-16-gb/images/average-fps-2560-1440.png",
      "To be honest not much: fsx, cod, I do plan on trying  hogwarts legacy. I do more fusion 360, solidworks, autocad, revit, archicad, twinnotion, blender, rhino…\n\nDisplay is 100hz 3440x1440, ryzen7 3700x, 32gb ram 3600 cl16, 970evo plus 1tb, asus prime x570-p, bit fenix formula 80 plus gold 650w, nzxt h510",
      "I understand, that’s why im considering the 3060ti so I wouldnt spend too much much on a 8gb card, the 4060ti 16gb would cost me 500eur.",
      "You are welcome, did you look at 6800/6800xt used prices? How are those?",
      "Alright this is gonna hurt...but I wouldn't recommend anything below a 4070 nor above it due to power draw and the price gouging of everything 4070 and above.  \n\n\nNow you could totally undervolt the 3080 and limit the power draw slightly to keep about 85-90% of it's performance and hover around 250 watts instead of the stock 325 or so, but if you do the same tuning to a 4070, you can get that down to about 130 watts.\n\nIf you 're dead set on going a 3080 or 3070 at a good price...well here ya go:   \n\n\n[https://www.zotacstore.com/us/promotions/open-box](https://www.zotacstore.com/us/promotions/open-box)  \n\n\nSince it seems you spend a lot of time on your computer, i'd personally recommend a 4070 for 550 USD since it's basically the same performance as a 3080, but with like 55% of the power draw and you have access to FG and path tracing if you ever wanna mess with those features in the future.  \n\n\nThe 4070 comes out to about 100 USD more, but you get 2 more gigs of vram and you'll make up that price difference within a year of using the product in saved electricity as much as you'll be on your PC.  \n\n\nAlso in case you didn't know...for CAD based machines, never use Radeon products...they perform terribly with them compared to Nvidia.  \n\n\nLet me know whatcha think!",
      "no ai, but I do like to render stuff"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "rtx 4060",
      "4060"
    ],
    "title": "RTX 3060 12GB vs RTX 4060",
    "selftext": "Hey all,\n\nLooking to get a card later tonight. Both the 3060 12GB and RTX 4060 are similar in price currently in my region, and I was wondering what the general opinion is on the 2 now that the dust has settled. The 4060 has the clear performance edge in non-edge case scenarios at the present time (VRAM limitations, but I’m a settings tweaker by nature), and the efficiency gains are appealing to me with the hotter summers. The 8GB is my only concern for what’s amounting to a $400 card. \n\nThe other option is getting a 7600 for ~$10-15 cheaper, or a Mech 6750XT for $50 more, which is stretching what I’m looking to spend. \n\nEdit: Use case is mostly backlog clearing, 1080p e-sports, and some modern games (BF2042 the most recent AAA install). Have a Series X for most of my AAA needs currently. \n\n2nd Edit: Ended up settling on the 4060. The outright efficiency and cost ended up being the kicker for me. Ended up getting a 2TB SN850X for about ~$50 more than the 6750XT would’ve been by itself. \n\nThoughts? Cheers!",
    "comments": [
      "This is one of those questions that is hard to answer, 4060 doesnt provide a noticeable jump in performance, less vram but has DLSS 3.0 with FG and more power efficient.\n\nConsidering your use cases, I would personally go for 6750XT, not only it excels at your target esports games, its also 30% faster than the 3060, its a very decent card for all games and gives you a better experienece overall than xbox.",
      "This is the thing about your question and why its hard to answer, want RT and DLSS then 4060, but again the vram thingy, which is fine at 1080p so far, but no one knows if it will be a bottelenck in future games even at 1080p. So ditch the 4060 for 12 GB 3060??  you lose DLSS 3.0 with FG and more power draw.\n\nSo 4060 Ti 16GB?!? It's $500, and that price is so bad.\n\nThere is no clear winner without giving up something else, unfortunately.\n\nTo be honest, Nvidia fucked up a big time with the 8GB shit and made it so confusing to decide, let alone the pricing as well.",
      "Went from the 980 Ti to the aforementioned 4060. Shaved ~80W at peak for double the performance and finally have hardware decode without turning in my iGPU. For a bit more than the difference to the 6750XT I ended up grabbing a 2TB SN850X, so now set for whatever new games await!",
      "8GB < 12GB",
      "get at least 3060ti or used 3070.\n\nDont buy too weak GPU. \nYou will be stuck with stuttering in and modern AAA games.\n\nex. Cyberpunk 1080p\n3060 50fps vs 3060ti 65fps.\n\nthose 30% 15fps make huge difference. dont care or notice if its 200fps vs 260fps. its same 30%. But it makes huge difference on low end.. from frustrating stuttering to smooth.",
      "Yeah I agree with most of what you’d said. I personally see the 6750XT as equal to the Xbox, and have a bit of buy-in with the Gamepass Ultimate deal (3 years), so will likely continue my AAA experience over there. The big reason I’m shying away from that card is that the majority of the purchase will be with money I was given, and the extra to jump to the card is what I thinking of getting a 2TB 850X with  Likewise, I do have a bit of FOMO desire to experience some of the Nvidia features I’ve missed out on sitting on an old Maxwell card I bought used.",
      "That assumes good AC / indoor temps, and PSU to match. OP will decide on their own though\n\nTLDR Heat is a bitch and lower TDP is well justified in the right places.\n\nHonestly any of the cards will be plenty performance wise. I would consider the secondary benefits, like lower power draw, noise, heat\n\nYou don’t experience those looking at benchmarks, but in person, especially in a hot room, it makes way more difference.\n\nAMD is cheaper per fps gains, but also hotter and noisier due to more power draw. This is usually fine in a well conditioned room and a tolerant ear / muffled case… but that isn’t always the case. Small room? Poor acoustics case? Coil whine bothering me? I would return and nope out.\n\nI wouldn’t do it in a hot summer climate. YMMV. I don’t like being cooked.",
      "Nice 50% jump in performance and less power usage = less heat.",
      "oh! I am in a similar situation. Hot and humid country throughout the year. Am also looking to upgrade from 1660 super (GPU potentially failing) to rtx 4060 (8GB). \n\nHow has your experience been so far with the 4060?",
      "Yeah that’s the way I was looking at it. ~215W just to play Battlebit at 144hz was wild when it’s 30C out and I’m in a decently small room. Now I’ll be sub-100W in a lot do the games I play while having all the new goodies to enjoy.",
      "What GPU do you currently have?",
      "Stretch for the 6700XT/6750XT",
      "4060 is a complete joke, hardly any uplift from 3060, LESS VRAM and lower bus width. You can't even take proper advantage of frame gen because the VRAM is so low and narrow for frame gen + RT.",
      "I'd go with the 4060 and just accept that you're going to have to play most new games with Textures set to Medium on 8GB VRAM instead of High with a 12GB card. \n\nIn all other regards, the 4060 will outperform the 3060, including raster (\\~18%) and ray tracing, provides access to DLSS3 Frame Gen, and runs cooler and quieter at lower wattages. \n\nI love my 3060 12GB but, if I was buying right now, I wouldn't choose it over the 4060. Being able to choose High Textures over Medium is great but this card will begin to fail to meet the demands of next-gen games sooner than the 4060 will. \n\nAlternatively, buy a 6700 XT/6750 XT. It's probably the better buy anyways, if you don't need access to CUDA and Nvidia's other proprietary technologies.",
      "So even if you find yourself with both at the same exact price, would you still choose a 3060 12gb over a 4060? Asking because it is at the point i'm in right now.",
      "Your reasoning sounds based, but if the 4060 has to go at lower settings, won't it fall sooner because of more vram requirements in a future?",
      "20% more performance is worth It imo. Specially at 1080p",
      "Not the guy your replying to but from what I've seen the 3060 will be too weak to take advantage of the extra 4gb of vram. The 3060 is already getting to the point where you have to lower setting to get 60+fps and some of these games are only using 6gb or 7gb of vram.\n\nAs much as I dislike the fact that the 4060 only has 8gb of vram I do feel like DLSS 3.5 and frame generation will help the card age better than the 12gb of vram on the 3060. In say 3 years time you'll probably get a much better experience with the 4060 on medium and high settings with DLSS 3.5 and frame generation than you will with the 3060 on medium and low settings with DLSS 2.0.",
      "This seems like a group that knows what they are talking about (I do not). I am looking at purchasing a laptop to run a golf simulator on and keep reading that it should be 3060 or higher with at least 8GB RAM but 16GB would help future proof it for the foreseeable future. I am looking at buying something currently on sale and here are the specs:\n\n*  12th Generation Intel Core i5-12500H Processor,\n*  NVIDIA GeForce RTX 4060 Laptop GPU (8 GB GDDR6 dedicated)\n* 16 GB RAM with 2 accessible slots\n* 512 GB PCIe Gen4 NVMe M.2 solid-state drive 512 GB PCIe Gen4 NVMe M.2 solid-state drive\n* Windows 11 Home\n* Wi-Fi 6 and Bluetooth 5.3 wireless card\n\nWill this be good enough for running GSPro or any other golf simulator software? The thing I don't understand is it says 16 GB RAM but it also says only 8 GB are dedicated to the graphics card? So is this really only a 8 GB device and they have a creative way of making it look higher end? It's originally a $1100 laptop but on sale for $700 right now. Thanks for any guidance you can provide!",
      "Thanks, ended up with the 3060 as I found it 80€ cheaper, at 270€ and glad I did, there is one flight sim I play where for rendering objects far away it will go up to 11gb and sometimes it even surpasses the 12gigs and I have to dial down. All within 60 fps. As I wanted an Nvidia card, the next card that has 12 gb or more is either the 3080 or a 4070 which were too far from my budget."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "rtx 4060",
      "4060",
      "4060 8gb",
      "rtx 4060 8gb"
    ],
    "title": "Gaming & Deep Learning: RTX 4060 8GB or the 3060 12GB?",
    "selftext": "Hi Im considering both of these cards for both gaming needs (mainly for Starfield at above medium graphics) and deep learning e.g. finetuning quantised LLMs. \n\nBecause of the increase VRAM of the 3060 I was thinking its the better card despite it being slightly (?) worse for gaming.",
    "comments": [
      "You might be one of the few people who the 4060ti 16gb is for lol",
      "The large VRAM needs of machine learning demands 12GB as a minimum.\n\nThere is the 4060ti 16GB for more breathing room.",
      "Definitely go for more vram =atleast 16gb. It will keep you sane while working with big models. Anyway, probably better to just buy gaming card and do your training on cloud. This way you can game while you train your model.",
      "8GB is just not enough for ML, it's the bare minimum and in most cases you'll just need a little bit more or your model will crash, because it immediately crashes after it takes more VRAM than it's available.  Also it's much better to use your own GPU than to use some online service. Most of them are too expensive I've used such services before I bought my 3060 and I think it's much cheaper to use your own hardware. For ML,  RTX 3060 it's just the best bang for buck. Also you can play games pretty decently, you'll just change the settings a little here and there and every game will run with descent performance and max settings. \n\n I also intend to play Starfield and I think it would run if not at max settings it'll run close to max settings. \n\nAlso there's soon going to be DLSS 3.5, which will include all RTX cards. \n\n Don't make that mistake to get 8GB card and then not be able to run the models, on games you can change resolution and other settings, but you can't run some models at all if you don't have enough VRAM. \n\n It seems most people who answered your question saw only the \"gaming part\" of the question, because getting a card with 8GB is bad advice for ML card.",
      "4060 doesn't have a 16 GB variant does it? Ti does",
      "Tbh, I don’t see either of these cards running Starfield above medium settings. At least with the 12gb 3060 you could turn textures to ultra, then use DLSS to boost fps. 1080p DLSS quality isn’t nearly as bad as people say it is.",
      "I'll check this one out",
      "It's a poor suggestion vs the RTX 3060 for your use case scenario. \n\nYes, the 3060 Ti is quite a bit more powerful than the vanilla 3060 (\\~25-30% increase), but the non-Ti variant having 50% more VRAM is going to be far more beneficial for machine-learning purposes. \n\nIf your choices are exclusively the 4060 8GB or the 3060 12GB, go with the 3060. However, I'd also suggest looking at the 4060 16GB variant. At $500 USD it's generally considered poor price-to-performance but - for you - VRAM is king and there aren't any better 16GB options from Nvidia near that price point.",
      "3060 with 12gb VRAM.\n\nYou're gonna need the VRAM w/ the way stuff's going these days.",
      "Is that even a question?\n\n3060 is better here especially for LLM. I use 3090 that have 24gb VRAM can handle something like 4bit 30B param model",
      "Get a 3090Ti/3090 for ML. 60 class is not meant for these applications",
      "If you get a 3060, buy it used, and buy two of them. 24GB total isn't bad, even though the speed isn't the best.\n\nAlternatively if you have the budget, buy a used 3090.\n\nThe 4060ti 8GB won't do much, the 16GB costs more than two used 3060s, and the 4080 costs more than the 3090.\n\nQuantised models are nice to have, but there's a point where if you go too low you lose more than you gain from having high parameter count. Grab yourself some more VRAM for a bigger model, you'll thank yourself later.",
      "If you care about deep learning you may want to ask on a r/deeplearning and say what you want to run. Or more dedicated forums like [https://forum.level1techs.com/t/mi25-stable-diffusions-100-hidden-beast/194172](https://forum.level1techs.com/t/mi25-stable-diffusions-100-hidden-beast/194172) \n\nNo one knows how Starfield will run yet, you will have to wait for benchmarks.",
      "They said Chinese companies buy a lot of 4060 ti 16gb for ML.",
      "Yeah good point, in that case would you recommend the 4060?",
      "Why do you recommend this one?",
      "We really need companies to start pushing for higher vram capacities. 16GB RTX 5050, 24GB RTX 5060, 32GB RTX 5070 and so on",
      "Is there a source stating this? Genuinely asking out of curiosity",
      "🫡Thanks.\n\nGonna get more ram with the money saved.",
      "both of these are so slow for LLMs that I question what you're planning on doing with them. If you just want to play around then it depends on dataset size (obviously more vram for larger sets).\n\n4060 will be faster until you hit larger than 8GB buffer load requirements and the 3060 will be faster at > 8gb. Both will be pretty slow, but the 4060 will be faster for most current games. This may not be the case for starfield since its an open world game by Bethesda and may eat VRAM for dinner."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "rtx 4060",
      "4060",
      "rtx 4060 ti",
      "4060 ti"
    ],
    "title": "New Rtx 4060 Ti 8Gb (465$) vs Used Rtx 3080 (600$) 12Gb for casual gaming at 1440p",
    "selftext": "As it's said in the title, I'm stuck between choosing a New Rtx 4060 Ti or a Used Rtx 3080 since:\n\nThe Rtx 4060 Ti is less power hungry, Has newer Dlss 3.5 with frame generation and ray reconstruction and since more games will be better with the Dlss and will be using them instead of optimizing their games, and the Rtx 4060 Ti is new and cheaper than the Used Rtx 3080, but i don't know if it's good for 1440p and not mentioning the 8Gb of Vram that will Surely backfire, also The 16Gb of vram version of it costs 100$ more for slightly 10% more performance or 5-6 more fps\n\nWhile the Used Rtx 3080 has less technological features, more power hungry and depends on raw performance more and it's better for 1440p But I don't if it will be good for the upcoming games that will be more dependent on Dlss than normal performance.\n\nSo i don't know which one to choose for playing games like Alan wake 2, re4 remake, cp 2077, etc...\n\n\nP.S Before someone tells me \"get this or get that instead\" The Rtx 4070 costs (800$) in my country so it's out of my budget and there are no AMD GPUs available in my country.",
    "comments": [
      "3080 12GB is about 33% faster and has 50% more VRAM. At the pricing you're seeing, it's a perf/$ upgrade and it will last longer at 1440p by about a generation.",
      "3080. The 4060ti isn't powerful enough to utilize those \"new features\" to their fullest potential",
      "Fr, 4060ti cant even use FG in Horizon due to vram",
      "If you can spend $600 then get a 4070 super, it’s better than either suggestion.",
      "They said they can’t in their post",
      "3080 for sure. Costing about 22% more, you'll be anywhere 27-33% more performance at 1080. \n\nFG and dlss 3.5 is great and all but consider what games you're playing and which ones utilizes it. There's also mods to enable 30 series.",
      "The 4060ti isn't even worth considering unless it's very cheap, so the obvious choice here is the 3080.\n\nRemember, OP is running 1440p, and 8gbs of VRAM is barely enough for that.",
      "3080 12GB? Those are rare.\nGet it. Much better.\n\n\nWhen it launched, 3080 was a beast. Any game 4K max. \n\n\nToday, Alan Wake2 and CP2077 are the few very demanding games that even 4090 cant max out.",
      "And plus 4070 super you I’ll bit performance and power efficiency",
      "29% price increase for ~40% more performance and more VRAM, it’s actually better value and will last much longer at 1440p.\n\nThe tradeoffs are no Nvidia frame gen, AV1 encoding or warranty and it’s double the wattage. Still more than worth it IMO, unless those things are highly important to you. Both cards have ray reconstruction btw.",
      "3080 12GB for sure. Pretty big performance difference there, and while it's not quite as good as nvidia's native implementation you can use the fsr3 framegen mod to achieve similar results in any title that supports framegen.",
      "OTOH it's 360w power draw for the 12gb 3080 vs 160w power draw for the 8gb 4060 Ti - more than double.\n\nNot sure what country he is in, but depending on electricity costs, that may make a dramatic difference in overall cost of ownership - especially if you are doing anything 24/7 with it like Folding, mining, AI workloads, etc.",
      "You can always undervolt…",
      "If your buying the 308 for 600 you might be able to find a 4070/4070super for ~600 but if it's between the 2 you picked 3080 for sure.\n\nEdit: didn't read description. Go with the 3080 any day. More vram + performance",
      "If you're worried about power usage, just set an undervolt curve.  My 3080 12GB utilizes between 200-265w depending on the game I play at 3440x1440.",
      "You can use the fsr frame gen mod on the 3080, undervolt it by a significant amount, has more vram, and it is just much much faster.",
      "Real life experience:  \nI bought a rtx 4060 for 560$ to game at 1440p.  (horrible performance).  \nHad to trade it in and get a rtx 3080 ti (used) putting like 300$ on top of it.",
      "I see, thanks for telling me.",
      "No no those mods are terrible and not worth any ones time /s\n\n-Nvidia subreddit",
      ">Today, Alan Wake2 and CP2077 are the few very demanding games that even 4090 cant max out.\n\nAt what framerates? And is that including DLSS and frame-gen?\n\nIn Alan Wake II, at 4K, with DLSS Quality and Frame Generation on, I can max out all the graphical settings and still get about 110 FPS.\n\nI haven't tried without DLSS and frame-gen though."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "4060"
    ],
    "title": "I have a computer and I wanna upgrade but i genuinely don’t know shit about computers",
    "selftext": "I’m thinking of getting this specific gpu but is it good? is it an actually 4060 or is there something i’m missing\n\nMy computer is a pre built acer nitro 50 with \na 1650\n16gb of ram\nan intel core I5 \n1tb hdd \n\nAnd i don’t know what i should upgrade, I already added 8gb ram to make 16 and Im thinking of a new GPU or a new processor, but i dont know what i should do. My budget for both of them is 1000$ all together.\n\nI dont know if the gpu i put a picture of is good and i dont know if its worth 400 dollars so I want to ask what i should upgrade to run games like palworld or modern warfare on good graphics. \n",
    "comments": [
      "NO, its NOT WORTH $400\n\nBut thats a good GPU, a huge leap from a 1650.  \nHere's a trustable \"rank\" of current GPUs, they also include a link with that same GPU for less than $300 [https://www.tomshardware.com/reviews/gpu-hierarchy,4388.html](https://www.tomshardware.com/reviews/gpu-hierarchy,4388.html)\n\nYou should be able to run all modern games with that GPU paired with your 10400f (I believe thats your CPU).\n\nAn easy way to help you decide on a GPU is checking youtube, all modern gpus have videos running lots of games, you can also try r/buildapc, its way more populated and youre more likely to find answers there",
      "I would strongly recommend just updating to an SSD. Then weigh your options.\n\nAn SSD alone will offer a huge performance boost for a much much lower budget.",
      "I was in the market for a GPU recently and did a lot of research, I too was looking at the 4060 first as well, it seems like a good choice on the surface but then you realise it's way overpriced especially because it only has 8GB vram too.\n\nI ended up going with RX 6750 XT which was a little more expensive £329 vs £279 but I think it was worth the extra. Seems to be one of the best GPU's for bang for your buck.",
      "SATA3 SSDs are actually a game changer upgrade compared to classic HDDs, but  NVMes are then BLAZING fast.  If you upgrade, the first time you boot into windows you will get shocked with the difference, it's night and day and you can still make use of that HDD for massive bulk storage.",
      "Just get an xfx speedster RX 7600 10Gb, its bout $350, and it's better than a 4060 8gb",
      "Check out gpuprices.xyz, there’s helpful pricing info there",
      "300 canadian sorry😭😭",
      "I second this.\n\nI got the 6750 XT (it was same price as the 6700 XT) and it's an amazing card, really good price to performance and it annihilates 1080p ultra settings, I see it performs well at 1440p too. I have mine paired with a 5600G which I got with my motherboard and getting full GPU utilisation.",
      "Honestly are SSD’s that fast ?",
      "I have nvme",
      "This right on the money. Upgrading to an SSD should priority before all other components, unless you have less than 8gb of ram. The cost efficiency is too amazing",
      "👍",
      "Do NOT get the 4060. A 3060 is better than that."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "rtx 4060",
      "4060",
      "rtx 4060 ti",
      "4060 ti"
    ],
    "title": "Today's 5 Best RTX 4060 Ti GPU Deals 2023",
    "selftext": "ZOTAC Gaming RTX 4060 Ti 16GB AMP Spider-Man: Across The Spider-Verse Inspired Graphics Card Bundle, $419.99 (w/ $30 coupon)\n\nZOTAC Gaming RTX 4060 Ti 8GB Twin Edge DLSS 3 8GB Graphics Card, $369.99 ($30 Off)\n\nASUS Dual RTX 4060 Ti OC Edition 8GB Graphics Card, $379.99 ($20 Off)\n\nGigabyte RTX 4060 Ti Gaming OC 8G Graphics Card, $379.99 ($20 Off)\n\nPNY RTX 4060 Ti 8GB XLR8 Gaming Verto RGB Triple Fan Graphics Card DLSS 3, $379.99 ($20 Off)\n\nand many more\n\nsource - [https://twitter.com/HelpMeFindDeals/status/1707046570380988812](https://twitter.com/HelpMeFindDeals/status/1707046570380988812)\n\nThanks",
    "comments": []
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "rtx 4060",
      "4060",
      "rtx 4060ti",
      "4060ti"
    ],
    "title": "Is 8gb vram enough in RTX 4060 laptop and 4070 laptop to be in balance with their performance? I ask because normal RTX 4060ti will probably have same amount of vram and be faster than 4060 laptop and possibly 4070 laptop card. I wonder which one to chose between these two.",
    "selftext": "If 4070 laptop power is unbalanced relative to vram size I don't want to overpay unless there would be  chance to buy it cheaper.",
    "comments": [
      "8GB is plenty VRAM for 1080p and most 1440p games. I've had 8GB cards for over 5 years. Sure some games will want more for settings maxed out or RT turned up but you can always dial settings down a bit if you need to. Or some games are just really poorly optimised. 4060ti won't be faster than 4070, they don't make cards that way. Laptops cards are limited compared to desktop ones though. Less VRAM, lower performance chips",
      "8GB is NOT enough ram for these 30-and-40-series GPU's. The 8GB 3070 chokes to 20 FPS at 4K max in some titles when it shouldnt. There is a video circulating of a 16GB mod for the 3070 that improves performance by almost double. The cost choke on these cards in production, are the vram modules. They are the most expensive part and most readily clipped by manufacture. If the 3070 16GB mod is to be believed, its safe to assume its the same way with 4060 and 70. The laptop versions are probably better off with the cut-back design, 8GB probably fits their feature-set more closely.\n\nBut no. 8GB is not enough vram for modern games. AT ALL.",
      "Lately there are more and more voices that 8GB is not enough anymore. [Quick google search.](https://www.google.com/search?q=8gb+vram+enough&sxsrf=APwXEdeQDvH4IVhU8TBt3sXnt4VD4T_vkg:1682374235354&source=lnt&tbs=qdr:m&sa=X&ved=2ahUKEwiyv7W1xMP-AhWjCRAIHTgcCsMQpwV6BAgBEB0&biw=1920&bih=975&dpr=1)  I don't need power that my laptop can't properly use because of lack of VRAM. And some people says that 8GB soon can be to low even for high details in 1080p. Times  changes, thats normal, but I don't want to spend additional money if benefits won't be large enough.   \n\n>I've had 8GB cards for over 5 years.\n\nWell, that was golden years for 8GB, but I think that since there is new generation of consoles now games requirements can change fast in next 2-3 years.",
      "I've had 8gb for 5 years too and been following the news pretty heavily. I haven't heard of 1080 ever being an issue yet, but I only pay attention and run 1440. \n \n\nThe next graphics card I'll get will be 12gb+. Currently there is nothing even close to worth the price to upgrade. Hogwarts is the first game I won't consider because of the vram issues. I haven't looked for an update either since release either"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "4060",
      "4060 ti",
      "4060 8gb"
    ],
    "title": "RTX 3060 vs 4060 if both are 40% off",
    "selftext": "Looking to upgrade my 1060 6gb I've had since 2016. Currently there is a sale on and I can either get a 3060 12gb or a 4060 8gb for a similar price (40% off). The 4060 Ti, 3070, 4070 and AMD cards aren't on sale so would be double the cost. I have a 1080p monitor, 16gb of RAM, core i5-10400F, PRIME 410M-K motherboard and a 450 watt PSU (Gigabyte P450B). I don't want to change the rest of the build as much as possible, especially the PSU.",
    "comments": [
      "4060, especially if you don't want to change PSU since 3060 is a lot more (relatively) power hungry than a 4060 while having worse performance.",
      "At same price 4060 is better, it's not really debatable. Otherwise the 3060 would have been better than the 3060 ti, which it obviously wasn't.",
      "Cooling performance and warranty.\n\nSeeing how Leadtek 4060 is not even listed here: https://www.techpowerup.com/gpu-specs/geforce-rtx-4060.c4107\n\nI would go MSI, even if it is a bit more expensive.",
      "Vram really isn't going to be a concern at the 1080p these cards target, there's a ton of hype around the topic but 8gb is fine for 1080p or even the majority of 1440p games, the few that exceed it just means you'll either run into some \"hiccups\" if you're playing on ultra or you can turn the settings down slightly. As someone using an 8gb card (4070) to game primarily in 2880x1800 resolution, I haven't ran into a single game the card has struggled to run (other than Cyberpunk or Alan Wake 2 when maxing out setting with path tracing) and even those are very much playable when things are adjusted a bit. Modern games tend to release in a state that leaves a lot to be desired in regards to how well they run, but generally receive a number of patches after release and are in a very different state after 3-5 months. With all that being said, frame generation and power efficiency make the 4060 the better buy over the 3060",
      "4060 since it uses 115W and has dlss3",
      "40% off from what price?",
      "Ok, thanks. One last question, is there any difference between the MSI 4060 and the Leadtek one? The Leadtek one is about 10% cheaper.",
      "I don't live in a western country and we have pretty pricey components because of import duties and taxes. I'm speaking in relative terms. With the discount, the 3060 and 4060 are basically the same price and are half the price of a 4070. I can't afford anything more, I just want to know which of the two cards I should go with and didn't want people telling me to go for a 4070 or AMD card.",
      "I doubt you have found a gpu at 40% off. Sounds too good to be true especially with the demand.",
      "4060 is the only choice at same price as 3060, works cooler, spends much less energy and has all the dlss tech available, framegen will definitely come in handy in some of your situation for sure.",
      "For the same price I'd get a 4060, especially if you game at 1080p. I have a 3060ti which performs closely, and have no problems with gaming (even 1440p with Dlss is ok)",
      "Go for 4060 especially for the better frame generation option experience !",
      "4060 is better, just for the framegen feature alone.",
      "used 3080/3080ti? 4060 is a scam card\n\nwill 5060 be a scam too? find out on the next episode of dragonballs Z",
      "That 8gb vs 12gb VRAM is really throwing me off. 8gb is barely an upgrade over 6gb",
      "TIL laptop 4070’s only have 8gb vram, I always thought they had 12",
      "12gb would be nice, but we make due with the 8gb we have",
      "I think a lot of people overstate the importance of vram. If you end up putting your settings up to the point of being vram limited, you’d have likely been getting less than 60fps anyway",
      "Wait for the reveal of Intel B570 and B580 later today, could become the new budget king if Intel has finally gotten its GPU drivers right.",
      "Well. Neither. The 4060 would be s great card if it wasn't crippled by 8gb of VRAM. Buying a 3060 new now simply doesn't make sense.\nIntel, amd and Nvidia will launch new gpus within 2 months. Especially amd (and who knows, maybe Intel) are rumoured to launch good cards in that price segment.\nJust wait a bit"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "rtx 4060",
      "4060",
      "4060 8gb",
      "rtx 4060 8gb"
    ],
    "title": "RTX 3060 12gb vs RTX 4060 8gb for product visualization",
    "selftext": "I'm currently doing 3d modling.I'm gonna get into product visualization. My main software is blender3d. when the rendering part came in Im gonna do it on blender it self ,but I wanna try render in Unreal engine 5. According to blender official benchmarks 4060 is better than 3060,but when it comes to UE5 everybody keep saying on internet 3060 is better for the UE5. I think they said it bcz 3060 have more VRAM. As I know more VRAM is good for more complex object scenes but product visualization regularary works with the minimal object count. So is it really matter to me for the go for a 4060 bcz I'm not gonna use UE5 for game development. But some of them saying using shaders and high quality textures requires more VRAM. Whats your opinion about this guys?Whitch gpu better for me?",
    "comments": [
      "3060 is better if you need more VRAM but that doesnt apply in all cases, 4060 is more powerful even if its not a huge different. 4060Ti is much better option especially if you can get the 16GB variant as its a good mix of both VRAM and speed (and if course 4070 and up)",
      "For the budget I have 4060 or 3060 is the only option.I hope to go for 4070 after a year!  \nI seen 3060 have more 400 cuda cores than 4060. how can not be not effect to performance?",
      "The cards use different architectures so the cores arent directly comparable and 4060 runs at higher core and memory clock speed.  \n+ more cache",
      "ok bro thanks",
      "thank u!  \nI seen 3060 have more 400 cuda cores than 4060. how can not be not effect to performance?",
      "For the budget currently I have, 4060 or 3060 is the only option",
      "The 3060 hay have more cores, but the 4060 has newer ones, and for tensor cores they double the performance of last gen, but again, you can't compare two microarchitectures like apples to apples, compare them with real benchmarks, not by arbitrary things like core counts, bus width, vram, and the list goes on and on",
      "3060 then",
      "What ppl say is bs, trust the numbers, blender is a good startpoint, the 4060 if super good for that usecause, but if u need a bit more oomph there's the 4070 super",
      "3080... 3090...?"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "rtx 4060",
      "4060",
      "rtx 4060 ti",
      "4060 ti"
    ],
    "title": "RTX 4060 Ti Ghost running better after 26.10.2023 update?",
    "selftext": "I've played A LOT of Starfield the last month, and it's been a really good experience. Before the game came out I bought an RTX 4060 Ti Ghost card (8GB), and I've felt it was a good buy. I'm running a computer from 2017, so I was a bit interested to see how it ran. I've got 32 GB RAM, Skylake-6700, and m2 discs. Resolution is 1440p. ( **2560 x 1440** )\n\nNow the game has been running on full graphics (I have bloom off / grain filter on 50% because it looked the best to me) for 40 FPS (and up), but after this latest update it feels like the biggest cities in the game are running more smoothly. Maybe the FPS is still pretty low, like 30-40 FPS, but it just feels smoother. Some games might freeze a little bit, or feel choppy, but even though with a lower fps, it's not feeling choppy anymore. The game has looked amazing from the very start.\n\nI posted this only to give people some information related to the graphic cards, but I don't mean to spam anything. Just felt like doing it. I mean a lot of people wouldn't want to play the game with such low FPS, but for me it was important to be able to play this game with full graphics, and a decent FPS. It saved me the cost of a new computer, and a new GPU with costs up to $2000. Post is for people who concider upgrading, but are unsure. This would work out for the time being.",
    "comments": [
      "13th gen intel is identical.performance to 14th gen (practically) but theyre cheaper on sale.  And play the cpu you own, dont upgrade cause reddit tells you to",
      "It’s that thing where the fps is only part of the story. You might be getting 40 fps but if the timing between those frames is too variable it’ll “feel” stuttering. So if they put in the work to fix frame timing this is a good thing.\n\nThey’re going to be adding frame generation support soon and that thrives on good frame timing. So this is exactly what you’d hope for!",
      "14th of November NVIDIA driver's for RTX 4060 Ti Ghost made the game worse, and it's lagging like mad now. I also activated BETA (DLSS) for Starfield days before, and it was completly fine. Now the graphics are glitching, stuttering, blinking and everything seems to run slower.  \n\n\nExample: Wind turbine blades in an Outpost will change colours of the blades from white to yellowish, and it's kinda blinking. Went to some places, and the background is also blinking etc. Wasn't like that with the old driver before 14/11/2023.",
      "I'm getting a new computer when I need one, and it's not gonna be cheap xD!",
      "DLSS official support is supposedly coming in a few days",
      "DAYS :O?! Do you think the game will drop in fps with DLSS?",
      "What? Why would it drop in fps with DLSS on?",
      "What? That was a yes or no question. Why would it be hard to answer yes or no?",
      "Get a 14 gen or amd 7xxx gen processor, also you can use the mod to get DLSS3.5 frame gen for nvidia gpus"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "rtx 4060",
      "4060"
    ],
    "title": "RTX 3060 TI or 4060 for same price? Upgrading from 1060 6Gb",
    "selftext": "I need nvidia card for some of the applications I use, so RX 6700XT is not an option otherwise I would probalby pick that.\n\nAs the title says I am looking to upgrade from 1060 6Gb. My PC is starting to become my secondary device as I bought an M2 pro Mac recently, but still would like to upgrade my GPU for some occasional gaming (1080p), photo and video editing and experimenting with Stable Diffusion.\n\nThe rest of the PC is not a beast either:\n\n* MSI B450 TOMAHAWK MAX\n* AMD Ryzen 5 3600\n* G.Skill Ripjaws V 16 GB (2 x 8 GB) DDR4-3600 CL16\n* PSU Corsair RM650x 650 W 80+ Gold\n\nThe cheapest cards I have found are:\n\n* PNY GeForce RTX 3060 Ti 8GB VERTO DUAL FAN LHR\n* Palit GeForce RTX 4060 Dual 8GB GDDR6\n\nBoth around $340 after taxes (I am in EU, so prices are usually a bit higher than in US). I have looked around the used market, but not much worth considering (ppl want to sell for new card's price their 2-3 yrs old GPUs).\n\nLooking for some advice on the topic.",
    "comments": [
      "Between those two cards, the 3060ti is going to be the faster card in all situations, but the 4060 does have DLSS3, but this is only supported by a handful of games and has its own drawbacks. I would get the 3060ti, imo. The 3060ti has higher memory bandwidth and a wider bus, it will excel in productivity compared to the anemic memory configuration on the 4060.",
      "I have no idea why every thread here is answered with \"4070\". It's just foolish.",
      "As someone that has a 3060 12GB, my advice is whatever one has 3 fans. Some recient game demos get my GPU to 83C and I am not comfortable with that. Thankfully I have another case I can swap to, to see if that helps. Before now I have always had 3 fan cards.  \n\nOf the 2 I would go with the 3060ti if you are doing the stable diffusion as the bus and bandwith is better on it vs the 4060. Either are better than my 3060 12 GB so for me either would be good as I am at 1080.",
      "3060ti for sure",
      "Thanks, it makes sense. 3060 ti beat 4060 in all the benchmarks I could find too and I'm not too worried about the higher power consumption either.",
      "This",
      "Thanks, however I am not looking to spend more. If the consensus is that neither cards worth the $340, I am ok to keep the 1060 for longer. Eventually when I replace it, it will go into another PC I have that justs lacks a GPU but otherwise ready to be used, for my wife to play Sims every once in a while, haha.",
      "83C is the temp limit if I'm not wrong. Might worth to test with a slight undervolting.",
      "My 3060ti never goes that high, but 83 is still fine tho",
      "A 4070 would be better for 1080p & 1440p gaming & video. Also 3060ti only has 8GB a 4070 even the non-ti has 12GB & its more like a 3080. Costs twice as much but I think it was worth it."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "4060"
    ],
    "title": "Nvidea 4060 w 8gb ram vs 3050 with 12 ",
    "selftext": "Hey everyone. Wondering peoples thoughts on  which of these is the best value way to go. I have about 500 canadian to spend on a graphica card, give or take a few bucks and am currently rockong a 1080ti.\n\nI was wondering if it would be better to go with an older card with more vram like the\n\n \"MSI Gaming GeForce RTX 3060 12GB 15 Gbps GDRR6 192-Bit HDMI/DP PCIe 4 Torx Twin Fan Ampere OC Graphics Card (RTX 3060 Ventus 2X 12G OC)\"\n\n or just say screw it and go with a newer model woth less vram\n\n\"ASUS ROG Strix GeForce RTX™ 4060 OC Edition\"",
    "comments": [
      "Neither. Both are bad. Get a 6750xt or b580",
      "I’m not sure what kind of “upgrade” you’re looking for, or why you need a new graphics card, but the 3060 performs marginally worse than the 1080 Ti, and the 4060 is less than 10% faster.\n\nIf you *need* an upgrade right now for ray tracing, or new features that isn’t offered on the 1080 Ti like better video encoding, or working on 3D rendering on a budget where every second counts, then I would suggest waiting and trying to get an Intel Arc B580 at MSRP. It has 12GB of vram, and is cheaper than a 4060 while performing between a 4060 and 4060 Ti.\n\nOtherwise, I’d wait until either you save up more money, and/or there’s better value cards on the market. Because either way any upgrade in this price range from a *1080 Ti* is going to be pretty low, and definitely not worth the money spent.",
      "Its ultimately going to come down the games you play and the features you want in those games. I'll get downvoted into oblivion for saying this, but there IS a reason that AMD GPUs cost what they do compared to Nvidia. You'll have plenty say \"it's due to greed\" but regardless, there IS a reason they're considered the best and offers features the other simply are incapable of. Ultimately, none of that matters if you don't have any interest or need in dlss/ray tracing, and related technologies. Just for the sake of \"full disclosure\" [go to 7:35](https://youtu.be/Yja6zDbnNv8?si=RWwA0m4LG09VwEpj) to see how AMD's absolute BEST offering handles something like Alan Wake 2 with path and Ray tracing, even using FSR to \"offset\" that cost. Its not popular to discuss anything but rasterization and \"price to performance\" but the majority of those videos tend to completely neglect showing what these features, that AMD realistically isn't capable of performing in any meaningful capacity add in regards to value. Like it or not, ray tracing and related ARE the future and have primarily been stunted by the current console generations, which compromise the largest gamer userbase, being incapable of actually utilizing these features in any meaningful capacity\n\nI realize a lot of that is off topic from your question, but again, it comes down to features. Sure, there are a few, rare, scenarios where the 3060 can outperform the 4060 due to the vram differences, but [there are a majority of games where you see numbers like this](https://youtu.be/E1sY_b__Gcg?si=GgRxHVf83EIQFQj7) (obviously a \"biased\" video, but it does make the differences very clear)",
      "People are still rocking 1080ti’s go with the latest gen for driver support also hear good things from intel’s new lineup. It’s a card don’t over think it. 8gb of ram is fine for 1080p gaming. In short, unless you want a 3070 or 4060ti keep the 1080ti",
      "Slow load times are likely because of your drive, not necessarily your gpu.",
      "Keep using the 1080 ti till you can afford a used 6800 xt or used 3080. I prefer the 6800 xt personally because the 3080 only has 10gb of vram and some games are using more than that. Some are using 12gb+, but they're more rare. Games are just chugging vram nowadays",
      "Amazing reaponse btw. Thank you for the time spent doing it.",
      "Thanks for all the feedback and recommendations. Seems what i thought was good these days is not. Im just feeling the loading times and the experience isnt what it ised to be on the stuff coming out now. Was thinking about maybe some vr in the future to so wasnt sure where to go without blowing over 1,000",
      "And suggestions on an amd or intel series or range that would be a go to  starting point for my budget currently? Im feeling the loading screens. Ill look at them in general but worth an ask.",
      "You're welcome!",
      "If loading times is the problem, then do you have an SSD? If your OS or games are installed on a hard drive, then that would be the main contributed to that problem. Just get an SSD, *that’s* a really cheap upgrade.\n\nThe 1080 Ti is perfect fine for VR, you don’t have to upgrade. In fact, *don’t* upgrade until you’re already having trouble running things that you want to run. What CPU do you have?",
      "Intel b580. Find the manufacturer you want and set notification on the new egg app to alert you when in stock. They’re sold out now, but don’t buy 3rd party. They’re doing ridiculous mark ups. Snag one when you can at msrp. You may also want to look into used cards.",
      "Thanks ill keep poling around",
      "If you’re on a budget, skip NVidia. Their worth lies in their high end cards. Get an amd or intel card."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "4060",
      "4060 ti"
    ],
    "title": "Looking for benchmarks of RTX 4070 at 160W TDP vs 4060 Ti",
    "selftext": "Has anyone seen tests of RTX 4070 power limited to 160W which is the TDP of 4060 Ti? How do these cards compare in this case?\n\nThe reason I'm asking this is because 200W power dissipation is too much for my case to handle and 4060 Ti 8GB doesn't seem sufficient, while the 16GB version is too expensive for the performance it offers.",
    "comments": [
      "Found a couple of videos, at 160W (specially with UV) it should be nearly as fast as at default 200W:\n\nhttps://www.youtube.com/watch?v=wG22iFuOCyw\n\nhttps://www.youtube.com/watch?v=HpXjj0-qoxs\n\nhttps://www.youtube.com/watch?v=zqDNEiCYTw0\n\n\n\nAnd a couple of Reddit posts:\n\nhttps://www.reddit.com/r/nvidia/comments/137xxzv/rtx_4070_undervolt_950mv_25_power_decrease_from/\n\nhttps://www.reddit.com/r/nvidia/comments/12pihwo/rtx_4070_efficiency_undervolting/\n\n\nCase solved.",
      "Control panel has the option. Also I can simply plug the monitor to other card. I will do tests at 100w, 130w, 160w, 190w when Im at home. (About 10 hours later)",
      "I have both cards installed. What do you need? I can do when  Im home from work.",
      "4070 will still be faster than the 4060ti. It likely wont be that much slower at 160w compared to at 200w",
      "Please run any 3D benchmark when 4060 Ti runs by default and 4070 is limited to 160W TDP. That's it. Thanks!\n\nNo idea how you make games use specific GPUs when you need it ;-)",
      "Computing stuff like massively parallel simulated annealing.",
      "Note that if you undervolt, you will get better performance than by simply setting a lower power limit. I recall reading that someone undervolted their 4070 and it ran at approx 155W (maybe 154?) peak and saw little performance loss.",
      "https://www.reddit.com/r/nvidia/comments/15nlwsb/gigabyte_4060ti_gaming_oc_cheapest_4060ti_vs/",
      "TechPowerUp has detailed power consumption graphs, not 160W TDP (that's quite specific), but they have one test with a 60fps cap to get an idea of efficiency on this page:\n\nhttps://www.techpowerup.com/review/nvidia-geforce-rtx-4060-ti-16-gb/37.html",
      "I run my card at a 925mv under volt and get stock performance with 150w. The card is crazy efficient.",
      "Why do you have thwm both?",
      "Unfortunately UV (or any core voltage adjustments) is not available under Linux which is my primary OS.",
      "Thank you!"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "4060"
    ],
    "title": "Legion Slim 5 or Legion Pro 5 (any help choosing is appreciated)",
    "selftext": "Legion Slim 5 Gen 9 AMD (16″) \n\nMemory\r\n32 GB DDR5-5600MHz (SODIMM) - (2 x 16 GB)\n\nSolid State Drive\n1 TB SSD M.2 2280 PCIe Gen4 TLC\n\nDisplay\n16\" WQXGA (2560 x 1600), IPS, Anti-Glare, Non-Touch, HDR 400, 100%sRGB, 500 nits, 240Hz, Narrow Bezel, Low Blue Light\n\nProcessor\nAMD Ryzen™ 7 8845HS Processor (3.80 GHz up to 5.10 GHz)\n\nOperating System\nWindows 11 Home 64\nOperating System Language\nWindows 11 Home 64 English\nMicrosoft Productivity Software\nNone\n\nGraphic Card\nNVIDIA® GeForce RTX™ 4060 Laptop GPU 8GB GDDR6\n\n\nLegion Pro 5 Gen 8 AMD (16\") with RTX™ 4060\n\nSystem Specs:\nProcessor\nAMD Ryzen™ 7 7745HX Processor (3.60 GHz up to 5.10 GHz)\nOperating System\nWindows 11 Home 64\nGraphic Card\nNVIDIA® GeForce RTX™ 4060 Laptop GPU 8GB GDDR6\nMemory\n16 GB DDR5-5200MHz (SODIMM) - (2 x 8 GB)\nStorage\n1 TB SSD M.2 2280 PCIe Gen4 TLC\nDisplay\n16\" WQXGA (2560 x 1600), IPS, Anti-Glare, Non-Touch, 100%sRGB, 300 nits, 165Hz, Narrow Bezel, Low Blue Light\n\n*Can someone help me choose a gaming laptop? I don’t know a lot about how to choose based on specs.",
    "comments": [
      "I'd say the slim 5 is superior. New CPU generation and twice the ram, with an HDR display which should look a lot better that the other.\n\nIf you can upgrade one of these to a 4060Ti or a 4070, I would. 8GB ram is somewhat limiting in demanding games. But rest assured, legions are absolutely amazing products in any case. I writing this comment from one at the moment!",
      "Okay that’s good to know—I can upgrade the Slim on Lenovo’s site (but not the Pro) to 4070 for +$300 if it’s worth it(?) I am glad to hear from a  Lenova user ☺️",
      "300$ is A LOT. A 4060 will still be good, especially if you play in 1080p for example, a 4070 will be a bit more future proof IMO. Both have DLSS and frame gen so it should be pretty easy to get nice framerate in most games, as long as you forego with Ray tracing, which does not add that much in most cases (Cyberpunk and Metro Enhanced Edition have the best implementation by far, the rest is a lot more tame in terms of addition).\n\nCheck all the legion models with 4070, some are actually pretty cheap pre-built, and might be cheaper than the one you are looking at. Also, go on [Rakuten.com](https://www.rakuten.com/?msockid=35a29e5a12246f67313c8a9213f26e56) and create an account there, and then go to the Lenovo website from Rakuten, you will get a 9/10% cashback on your purchase, which it's a pretty significant when buying a computer! It's also available in Canada if you are living there. That cashback might push you to go for a 4070 which will be more comfortable with more demanding games. Or keep the 4060 which will still be good if you don't want to push graphics to the max and keep a significant amount of money for something else :p",
      "Okay, that is amazing. I will do that. Thank you so much for your help—I appreciate that you took time to share your knowledge as I was in the dark!"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "rtx 4060",
      "4060",
      "4060 16gb",
      "rtx 4060 16gb"
    ],
    "title": "If you didn't build the pc, is there an easy way to tell if the GPU is 8gb or 16gb??",
    "selftext": "Hi there,\n\nI bought a pc with a RTX 4060 16gb card. I've looked at the display option and it only shows 8gb dedicated memory. Is this right?",
    "comments": [
      "It sounds like someone may of screwed up. There's two versions 4060 8gb and 4060 ti 16gb. If there isn't a ti after the 4060 than you just have the 4060 8gb version.",
      "[https://www.techpowerup.com/download/techpowerup-gpu-z/](https://www.techpowerup.com/download/techpowerup-gpu-z/)\n\nA must have app for PC enthusiasts of all spectrums.\n\nEdit: Also task manager performance tab.",
      "4060 is 8GB VRAM",
      "Thank you, I'll give this a look through over the next few days. \n\nHave a good Christmas.",
      "Regardless of it being a 16gb version, sorry I'm a complete noob at this.",
      "You too, have an awesome holiday.",
      "Actually, there's 3. 4060 8gb, 4060ti 8gb and 4060ti 16gb",
      "I appreciate the correction! Cheers!",
      "There are no 4060 12gb GPU"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "4060"
    ],
    "title": "Help please",
    "selftext": "Really need some advice. I need to get my son a gaming laptop as his has died. I really need to keep costs down with it being near Christmas etc. Where would your money be? He really only plays Roblox, fortnite, Sins of a solar empire and star trek online.\n\nThe Acer is £599 and the MSI is £769. Not a massive jump but would like to spend as little as possible. Is the step up to I7 and 4060 really worth it?\n\nThanks for any help you can offer\n\nhttps://preview.redd.it/e6vmwxvwxisd1.png?width=1003&format=png&auto=webp&s=7dddb55351cf73e2dd594969e8a63b91e2701355\n\nhttps://preview.redd.it/is2hwlvwxisd1.png?width=1510&format=png&auto=webp&s=1f4df8cacda414e797b844bf84376ce903728665\n\n",
    "comments": [
      "-Edit\nI think the 4050 isn’t a bad choice but you must get that ram upgraded. 8 gb isn’t enough in 2024, it’s super easy to upgrade ram. Also if your son is older and mature he will understand that money is tight and shoudd be more then happy with that laptop I know I would be.",
      "I have a cheaper msi gf63 thin as a backup PC incase my rig shits out. Cost me $400 usd used, put a new battery in it and it runs good as new. They’re cheaper but they do ok for what they are.",
      "Really appreciate the feedback. Ive found a crucial ram upgrade that checks your computer and tells you which ram is specific to your device so will be the first thing I'll be doing. Thanks again"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "rtx 4060",
      "4060"
    ],
    "title": "Will a rtx 4060 be good enough for 1080p gaming for the near future?",
    "selftext": "My gtx 1080 just died on me. I was hoping it would survive another year or two until I could afford to do a full rebuild and get a new monitor.\n\nI'm wondering if a rtx 4060 would be a good choice for gaming at 1080p and at least 60fps locked? I mostly game on my old plasma tv that doesn't have any free sync/gsync. I'm hoping to get a year or two out of this card and be able to play new games at 1080p/60.\n\nI know the 4060 has pretty shit VRAM at only 8gb but are there any new games that would be pushing that 8gb at 1080p?\n\nI can get an etc 4060 for around $400 CAD  plus we have no federal tax right now. So looking to take advantage of that and get a card before the 5060 series is released.\n\nIs a 3060 with 12gb VRAM better than the 4060, considering 1080p gaming? They both cost pretty much the same right now.\n\nI have an i7 6700k 4ghz processor and 32gb ram.\n\nThanks in advance for any recommendations.\n\n",
    "comments": [
      "B580",
      "Also, 12gb of memory and it's faster than a 4060, at 250$. You literally cant beat that.",
      "We can't tell the future but 4060 was DOA for being weak and having almost no generational uplift. It's like buying a 3060, so you are basically 2 generations behind out of the gate.",
      "I tested out the Monster Hunter Wilds beta on an old GTX 1660ti 6gb and on low medium settings the game already took near 8gb vram. The 8gb is already on its way out before it even got time in the spotlight and the 16gb 4060 is even less of a value. \n\nAs many have stated the b580 from intel seems to be aiming at the 4060 crowd and has better specs. You can also wait a month and see what AMD is going to reveal of you are not in a rush.\n\nEdit : typos, curse you smartphone touch screen",
      "The reviews are saying they’re much better than previously. Maybe not up to nvidia scale, but getting there. It’s a new card against a card that’s two years old.",
      "The new Intel GPUs require resizable bar which I don't think my old asrock z170 pro4s mobo supports.",
      ">but are there any new games that would be pushing that 8gb at 1080p?\n\nYES! lots.\n\nlots and lots of videos about this.\n\njust one released 2 days ago, that goes over the vram issues especially at the beginning:\n\n[https://www.youtube.com/watch?v=Non4TSo-jEw](https://www.youtube.com/watch?v=Non4TSo-jEw)\n\nand there have been a bunch more videos from hardware unboxed and daniel owen showing the vram issue and how it is getting worse and worse.\n\nyou absolutely want 12 GB vram minimum today.\n\na 3060 12 GB is a better buy than the insult, that is the 8 GB 4060.\n\nand even an intel b580 IF you can find it at 250 us dollars (or whatever the theoretical european msrp is) would be the vastly VASTLY better buy.\n\nthis is quite hard though, because intel doesn't want to sell to many of those cards.\n\nthe cards to look at as you need one NOW and can't wait, which is sad, because new cards release in q1 from amd and nvidia, although i expect the 5060 to be another insult at least, either way the cards to look at are:\n\nrx 6700 xt, rx 6750 xt, rx 6800.\n\nrx 7700 xt, 7800 xt, 7900 gre maybe., maybe there is a sale on one, probs too expensive, but worth a look.\n\nnvidia rtx 3060 12 GB.\n\nactually thinking about the intel b580. the cpu + motherboard may not be able to enable \"smart access memory\", which i think would make the intel b580 worthless, because intel REQUIRES pure uefi mode running sam, otherwise performance breaks. that was the case with alchemist and from what i heard is also the case for battlemage.\n\nso IF you could find an intel b580 at msrp, check if the motherboard supports sam and if you are running fine in pure uefi mode.\n\nand if you're wondering: neither nvidia or amd cares about running sam or not. as in it runs fine without. losing like 5% performance without it on average or sth. meanwhile without sam the testing of intel alchemist saw frametime graphs and averages go insane without sam.\n\nif you have no idea what any of this means and you don't want to research it, AVOID INTEL GRAPHICS CARDS.\n\nand the best options new are probably: rtx 3060 12 GB, rx 6700 xt, rx 6750xt or a super lucky rx 6800 for a good price if they still got them.\n\nand avoid the 8 GB 4060 like the plague, that it is.",
      "Now that I'm looking into it, I don't think my motherboard will be compatible with the b580",
      "An i7 6700k. Definitely gonna be bottlenecking any high end gpu",
      "uh, yeah",
      "OP please [see for yourself ](https://youtu.be/R_wfUTlf5Ns?si=09T-29O0RErwyuc7) the performance difference between the 4060 (8gb) and the 3060(12gb). Yes, there are a few very specific scenarios where ppl have shown the 3060 doing slightly better due to the vram in games newly released, that haven't yet been patched and had their performance corrected, like always happens with new games. The 4060 is a stronger card than a 3060. Vram is NOT the \"end all be all\" in determining how a GPU performs. This comparison is also before taking into account things like DLSS frame generation, which only the 40xx series GPUs can use",
      "You can get a high tier card but you may only be able to utilize half of the power. Your CPU will be bottle necking you hard. I have a i7 7700k and recently upgraded to a 6700xt and I have a 90 percent bottleneck on my CPU using Black Ops 6 benchmark tool.",
      "Yes",
      "The 1070 released with 8gb of vram, so did 4060. \n\nAre games still using that little of vram at 1080p? NO.\n\n12GB vram minimum for \"future proof\" @1080p \n\nbut I've been at 1440p with a 1080TI for 6+ years, get a card with 16gb like a 7800XT and upgrade to 1440p monitor brother. (Upgraded to 7900XT last year)\n\nIt will be okay at medium textures, for example the new Indiana Jones game: the rtx 3080 is beaten by 3060 12gb... At 1080p. But there's much better same cost options : 6700xt / 6750xt / 7600xt / 7700xt + Intel arc new GPU's.",
      "Thanks for the recommendation. Been hearing about those Intel cards. How's the driver support for the Intel cards? Will they only work for dx12 games, or are older games fine?",
      "You can't even acquire these for under $400 anymore. While the 4060 is still readily available for under $300",
      "Yeah that's what I figured. I don't even have PCIe 4.0 so anything above a 3000 series is gonna get throttled.",
      "Appreciate the input. I'll look at some AMD options. The 7800 is almost double the cost of the 4060 which is way outside my price range. I'd rather put that money towards a new build and get something that will hopefully last me a year or two at 1080p.",
      "The 7700xt and 6800xt are both 2-300 dollars more expensive than a 4060 or 3060 12gb.  \n\n\n I would strongly consider the b580 but it requires resizable BAR and I don't think my old asrock z170 pro4s mobo is able to do that.",
      "Yeah looking on PCpartpicker CAD prices are rough at this budget, only a 7600 an option and that's a bit cheeper for technically slightly better, but for DLSS which you will rely on, id go with Nvidia. \n\nId wait for next gen in Jan though March , more budget options available, in Canada we don't get a large amount of GPU's in, so stock changes alot and so does price. \n\nOnly thing I noticed when actually buying my build, the sites in CAD are not updated on PCpartpicker very reliably, some sales straight up didn't get updated on PCpartpicker. \n\nId check, Memory express, PC-Canada, Canada computers...\n\nNewegg.ca is \"ok\". Ive gotten good case, CPU and PSU sales, like really good. But if you don't film while unboxing, or if you have to ship anything for repairs - Good luck!!"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "rtx 4060",
      "4060",
      "rtx 4060ti",
      "4060ti",
      "4060 8gb",
      "rtx 4060 8gb"
    ],
    "title": "Which graphics card is better?",
    "selftext": "I am custom building my own PC for the first time and need help - let's just say it's safe to say that as soon as numbers and letters started coming out, I thought I was reading latin.\n\nMy options for graphics cards are:\n\nNVIDIA RTX 3050 8GB\n\nNVIDIA RTX 4060 8GB\n\nNVIDIA RTX 4060Ti 8GB\n\nNVIDIA RTX 5070 12GB\n\nNVIDIA RTX 5070 Ti 16GB\n\nI do not understand the difference between 4060 and 4060Ti, obviously I can assume the higher the number, either the more recent or better the graphics card is. I also do not want to spend a lot of money on something that I will have to end up replacing relatively soon because it's not the ideal card for my build.",
    "comments": [
      "Ignore Nvidia rtx it's just branding\n\nThe first two digits represent the generation of the card. In the same way that iPhone 11 is one generation ahead of iPhone 10\n\nThe second two digits represent the model. Loosely think of '60' corresponding to an Audi whilst '90' corresponds to a Ferrari. The higher the better.\n\nSo comparing a 5060 to a 4090 is like comparing last year's Ferrari (4090) to this year's Audi (5060). Of course last year's Ferrari will outperform but as the generations go by a given year's Audi will start catching up to a Ferrari from a number of years ago.\n\nThink of 'Ti' almost like going halfway. So a 4080Ti is somewhere between a 4080 and a 4090",
      "If your budget for the entire PC is $2600 then get 5070 Ti. \n\nIt's the fastest of the bunch.",
      "What are your objectives with the device?  What resolution, frame rates, etc?  Will you insist on max settings?  Will you do any productivity work with the GPU?",
      "No problem. Btw the Gb figure is how much Vram the card has. Think of it like how big an engine the car has. Generally you would expect a Ferrari to have a way bigger engine than an Audi. But sometimes the Ferrari doesn't have as big an engine as people would like, this happened with the recent 5080 card. It has 16Gb VRAM meanwhile my 1080ti which is ten years old has 11Gb. Now the 1080Ti was freakish for it's time but you can debate whether that extra 5Gb is too low for a ten year upgrade, even though it's performance will still be way better due to other factors\n\n\nBut it's a fine tuning thing honestly you can follow the high level rules I stated before and the pricing to pick the right option",
      "> NVIDIA RTX 5070 Ti 16GB\n\nThis would be the best option.",
      "Their list doesn't have a 3090 in it",
      "Need your budget, resolution, and target frame rate.",
      "higher the number the better. The ti is better than non ti.",
      "this makes so much sense, thank you!!",
      "my budget for the entire PC is about $2,600 (which i am well within range with any of these options). i don't really know much about resolution or frame rate, i just like my games to look pretty and to not accidentally fry my graphics card. if it gives any insight, the games i've been playing are BG3, DBD, and Oblivion Remastered on high graphics and they've been working just fine, but my brand new prebuilt PC just crashed when i tried to download Sims 4 and the company isn't fixing it, just told me to return the PC, so i am looking to just build my own at this point.",
      "If you do not wish to replace anytime soon then I would strongly recommend the 5070ti. That one was within my budget compared to the 5080 and 5090. I paired it with a Overkill cpu (to be honest) and it runs like a dream on 1440p UW. If you combine with dlss and when necessary frame Gen then it can push some pretty decent fps in both competitive games and graphically intense games. I play mostly the latter on the highest settings.",
      "The ti stands for titanium I believe usually a faster card",
      "Bases on your $2600 budget, get a 5070Ti",
      "5070Ti. If it’s an option for you - get it.",
      "You have a pretty big budget. Go for the 5070 Ti",
      "Your list is in reverse order, best card at the bottom worst at the top. Get the best one you can afford",
      "I am only ranking his list. Of course a 4090 would have been better.",
      "The highest number with a Ti is the best (5070ti)",
      "This isn’t true , a 3090 will be a 3080ti for example"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "rtx 4060",
      "4060",
      "4060 8gb",
      "rtx 4060 8gb"
    ],
    "title": "RTX 3060 12GB or RTX 4060 8GB?",
    "selftext": "I'm upgrading my pc and don't know which video card to choose. I've heard so many opinions and I'm actually so confused. I will be using it for a 1440p monitor. If it runs at 100-120 fps on mid-high graphics on 1440p I'm more than happy. *Also one of my biggest fears is Medal.tv recording in lag, since this is the biggest issue (Medal.tv is a recording + streaming software that uses the unused or excess VRAM to record, so idk if 12GB is worth it)*",
    "comments": [
      "You'll be fine for those games for either GPU. For CS2, the 4060 8GB gives you ~20 more fps and uses barely more than 5GB of VRAM apparently at 1440p. \n\nhttps://www.techpowerup.com/review/counter-strike-2-benchmark-test-performance-analysis/5.html\n\nI am not too familiar with medal.tv but I would imagine you're fine.",
      "> If it runs at 100-120 fps on mid-high graphics on 1440p I'm more than happy.\n\nAs always, what are you playing? Games that are hard to run like Cyberpunk 2077 and other ray-traced titles, or games like Persona 3 Reloaded, Final Fantasy XIV, Counter-Strike 2, or Borderlands 3 that really don't need a whole lot to run? \n\nHonestly, go look through some Gamers Nexus charts or something to get a better idea. VRAM matters but at these levels of cards it's not nearly as drastic. They are both better suited for 1080p but can handle lighter 1440p titles just fine. Hell, even a GTX 1080 (not quite 3060 12GB performance) can still handle it's own in a good chunk of 1440p titles. \n\nhttps://gamersnexus.net/gpus/best-worst-gpus-2023-gaming-100-2000-video-cards",
      "A question as old as time.\n\nDepends if you're ok with with settings that use less VRAM and getting more fps, or if you'd rather crank everything until it uses 12gb and are ok with lower fps.",
      "My rtx 3060 is great but tbh all that vram is a little bit overkill I only play on 1080p though",
      "Hey, thanks for answering. Mostly I play CS2 and Roblox. Do you think I'll be able to have 120 fps and medal.tv running smoothly + recording in 1080p 60fps?",
      "or a rx6750xt, cheaper and still faster than 4060",
      "I don't know. I've never heard of that. this says it takes up VRAM, but the developers say it's a bug. Probably fixed by now, but even if it's not longer leaking unlimited memory, it'll still use *some* VRAM.\n\n\n\nSo maybe it's better to get the 3060 12GB. It' should generally be around $10-20 cheaper these days as well if there is still stock available.\n\nEDIT. The 4000 series has AV1 encoding so maybe that's important for Medal as well, but I have no idea.",
      "As I said, not super familiar with it, but your CPU might come into play as well. \n\n\nI'd also ask around on some medal.tv subreddits or forums as well for people that are more knowledgeable unless someone chimes in here. The system requirements page for medal.tv was pretty barebones, just labelling \"GPU\" as a requirement.",
      "Not sure if price is the issue but how about 7700XT\n, it comes with AV1 encoding and can easily get those fps u want.",
      "Both of those cards are better for 1080p and probably won’t be able to get 120 fps in 1440p. For the price, an amd card (and they normally have more vram) but if you want to go nvidia a 3070 ti or a 4070 (super or not) would be better for 1440p",
      "My 4060TI with 8GB vram is running cyberpunk great with DLSS 3. I’m able to have all of the settings maxed out and still consistently run at 2K 60+ FPS.",
      "Hmm... But if I get the 4060 w/ 8GB VRAM do you think it will be enough for medal.tv to record w/out a problem? (record in 1080p 60fps",
      "Thanks!",
      "Price isn't the issue, I'm mainly searching for nvidia cards but I might give amd cards a try. Thanks!",
      "Thanks",
      "Basically an OBS that records 24/7, and with the click of a button it automatically saves the last 120 seconds (can be changed to more or less) of your gameplay. I currently use it on 1080p 60fps for recording, but are you sure 8GB is fine for gaming and using medal?",
      "Thanks, really appreciate the help!"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "rtx 4060",
      "4060"
    ],
    "title": "I found a rtx 3060 and a rtx 4060 at the same price. Which lasts longer?",
    "selftext": "\nTL;DR - 4060 and 3060 are at the same price. Which is more future proof while giving good performance (1080p@60)? \n\nI finally saved up some money for my first desktop pc ever. \nI'm looking to play at 1080p@60, but may in the future do 1440p as well (hopefully @60 aswell). \nI've seen that, at 8gb of vram, the 4060 outperforms the 3060 while also being more power efficient. \nHowever, my main fear is that 8gb may not be enough in the future. \nMight aswell add that this pc isn't 100% gaming focused. I'm going to use it throughout university in Software Engineering, and I've seen some people say more VRam is better than more raw performance in that department (although I'm not 100% sure). Also, because of that, I'm not looking to buy an AMD card.\nMy budget is 370€ with IVA included (they're both at that price). \n\nWhat do you think? Is the rtx 4060 more worth it over the rtx 3060 12gb?\n\nLinks:\nThe rtx 4060: https://switchtechnology.pt/produto/placa-grafica-asus-dual-geforce-rtx-4060-oc-edition-8gb-gddr6/ \n\nThe rtx 3060: \nhttps://switchtechnology.pt/produto/placa-grafica-asus-dual-geforce-rtx-3060-12gb-gddr6-oc/",
    "comments": [
      "I'd say 4060 8GB, it's well above capable of \"1080P@60\" and more efficient, and assuming you aren't gonna be cranking games to their max, VRAM shouldn't be a worry. Then again this comes down to the games you play and at what settings and as well the programs you're gonna be running for your class, so you should probably look into that ( ex: benchmarks). Regardless both cards are more than enough for a nice gaming experience, but without details, I say 4060 :)",
      "answer what is being asked, he can buy this or that he is not asking that.\n\n3060 and 4060 both at same price, which one should he buy.",
      "12GB > 8GB",
      ">it uses a x8 interface \n\nIrrelevant, this has no impact on performance. \n\n> uses a 128 bit bus rather than 192 bit bus on the 3060 \n\nCorrect, however, the 4060 has massively more L2 cache so we could also say the 4060 is much improved in that aspect vs the 3060. The effective bandwidth is higher than the 3060's. The 4060 is truly a faster card, as confirmed in reviews. \n\nI wish folks would stop jumping on the hate bandwagon, for 1080p 60FPS , which is what OP wants, its kind of the perfect card. Super efficient, supports all the new tech, DLSS 3, Frame Gen and AV1. \n\nThe only singular benefit of the 3060 is that it has 12 GB VRAM, that is it. In every other way the 4060 is faster and more efficient and for 1080p, I would chose a 4060 over a 3060 all day long.",
      ">The 4060 is a bad value, it uses a x8 interface rather than the traditional x16, uses a 128 bit bus rather than 192 bit bus on the 3060\n\nThis is all pretty meaningless. The actual problem is that the 4060 is 8GB, when it could have benefited from 16GB. Despite the 128-bit bus, it's comparable to the 256-bit A770 16GB at 1440p.",
      "3060 12GB.",
      "3060 12GB vs 4060 8GB but more cache.",
      "if graphics card is itself weak then that extra vram won't get you anywhere. \n\n4060 is stronger GPU than 3060 and also has dlss3 \n\neven with 8gb ram 4060 will beat as 3060",
      "Doesn’t make sense.  The extra memory is doing little good for a 3060.  It’s a much slower card to boot.",
      "And yet is much faster than the 3060.  Why would one purposefully buy a worse card at the same price?",
      "hahahaha",
      "because some people are sheep brained, they follow the masses and keep repeating same things, 12gb 12gb 12gb. If card is itself is weak 12gb wont help.\n\n4060 is good card with latest tech, only 8gb is drawback but it is stronger than 3060.",
      "Maybe but even 12gb is not enough then I mean TLOU can barely run with 12gb and dont even get me started on RE4 Remake that somehow cabt even run on 16gb... Unoptimized games are the problem not the 8gb itself.",
      "Pretty sure you can find a 3060ti in portugal for that price and less . Much better than both cards",
      "None of them will last 1 year,  UE5 games coming.",
      "4060 of course it's better than 3060 12gb and from 4060 u can enjoy the new tech dlls3",
      "4060, better in everyway except 8gb ram but 12gb ram on weak card means nothing",
      "The 4060 is a bad value, it uses a x8 interface rather than the traditional x16, uses a 128 bit bus rather than 192 bit bus on the 3060 - honestly should've been used as the 4050. ( Which is projected to have even lower specs.)",
      "Yeah, if staying at 1080p, 4060 is more than capable. Especially if OP finds jt at same price as 3060.",
      "Which NVidia card should I aim for then?"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "rtx 4060",
      "4060",
      "4060 8gb",
      "rtx 4060 8gb"
    ],
    "title": "3060 or 4060?",
    "selftext": "For a gaming pc (aorund 900$) does the   \nGigabyte GeForce RTX 3060 Windforce OC 12GB  \nor the  \nMSI (or Gigabyte idk) Ventus 2x OC GeForce RTX 4060 8GB  \n\n\nMany sources say the 3060 isn't future proof so idk. I'm coming from a GTX 850M so I don't mind but on pcpartpicker they're the same price (as of sending this) which one do I need? I also use Blender",
    "comments": [
      "Maybe look to AMD or Intel before buying in that segment. I would consider Nvidia more for cards one tier above (xx70 and above).\n\nEdit: I'm answering in the context of games. I do almost no productivity.",
      "Even at 70 tier, I would strongly consider an RX 7800XT with 16GB. As for productivity, none of the xx60/xx70 cards can really hold up as there VRAM is even more important.",
      "Good thing 6750XT is 40% faster than 3060 and hence its as fast if not faster native than 3060 with dlss.",
      "for 900 dollars you'll be pretty hardpressed to get a gpu with more than 8gb of vram. everyone is reccomending the b580 but from what i have heard it really sucks in blender, with something like a 4060 being much better for non-gaming. nvidia does better than everyone else for blender sadly.\n\nif you can stretch it, a used rtx 4070 or maybe a new rx 7700 xt would be a good pick. there are also new AMD cards releasing soon, though the pricing is currently unknown. might be worth waiting to build.",
      "If you look at reviews: Don't buy a 8Gb VRAM card in 2025. To cite Hardware Unboxed from their current Podcast Episode: \"The 4060 is a piece of crap and it still outsold anything that AMS had to sell. The 4060 is an abomination it's so bad.\" and I fully agree. They also said the same about RX7600 and again I agree. Go with an Intel B580 or an AMD RX 6700XT or 6750XT. With 12GB they are miles better than any 8GB card.",
      "Yeah, the low VRAM is really something to be aware of, isn't it? I would not suggest a 8gb card to anyone today. If a 3060 or 4060 fits the budget, you should go for something with more VRAM than 8.",
      "There's some mixed opinions but yall said 8GB is too little the 30 card is better?  \nAlso I can save money on the motherboard if I pick the 30 instead of the 40 but all the newer ones wont be compatible. I mean anything will be better than my current one so I don't really care to get the newest ones lol",
      "Neither of those are future proof, but 8 vram isn't enough anymore",
      "nvidia does a lot better in productivity afaik. even a 4060 will be a 7800xt in blender.",
      "8 GB VRAM can’t play any games in 2025 I agree, just buy 16 GB 7600 XT if your broke",
      "Pcie is backwards compatible, you can use 16x5.0 card in 16x3.0 slow with a mere 1% performance drop",
      "hell nah, in some price brackets, AMD cards are so much faster, its not even valid to look at Nvidia cards (4060ti vs 7800XT) for gaming. Remember, you still have access to XESS, and FSR 3.1 upscaler is decent at 4k at least. I have a 3090 and my wife has an XTX, and in Palworld, Quality mode DLSS looks similar to me as Quality mode FSR 3.1 at 4k using the Optiscaler mod.",
      "Both of those don't hold up, get a used 4070.",
      "would still go for the 3060 instead of the shit amd products due to the superior upscaler on the 3060"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "rtx 4060",
      "4060",
      "rtx 4060 ti",
      "4060 ti",
      "4060 8gb",
      "rtx 4060 8gb"
    ],
    "title": "GeForce RTX 4060 Review Megathread",
    "selftext": "# GeForce RTX 4060 reviews are up.\n\nhttps://preview.redd.it/feh5topurr8b1.png?width=3840&format=png&auto=webp&s=2177556375d8124a438ac965c7b027ca8f74e303\n\n# Below is the compilation of all the reviews that have been posted so far. I will be updating this continuously throughout the day with the conclusion of each publications and any new review links. This will be sorted alphabetically.\n\n# Written Articles\n\n# [Babeltechreviews](https://babeltechreviews.com/the-299-rtx-4060-review/)\n\n>This has been an enjoyable exploration evaluating the new RTX 4060. Overall, it is the best 40 series value for your money currently available but only if you are completely new to PC gaming and want to build a great 1080p machine right now. This is only if you want to enjoy the software offerings of Nvidia, with DLSS 3 and AV1 included in the 40 series, then its obvious that is biggest story here. Pricing is off and Nvidia is relying on its software to entice gamers, and it will for many. However, it truly depends on the games you play. If you are playing games that do not take advantage of DLSS then we suggest waiting or using your budget on an 30 series card with higher amounts of VRAM.  \n>  \n>The price – has – to come down in order for to outright recommend this to anyone brand new to PC gaming, or current owners of the previous generation. It is easy, at 1080p, to suggest an upgrade for 10 and 20(60) series owners if you need to upgrade at this time.\n\n# [Dexterto](https://www.dexerto.com/tech/pny-nvidia-geforce-rtx-4060-review-2191426/)\n\n>There are a wealth of reasons not to buy the RTX 4060. Some might say it does not have enough VRAM, while others would claim that the reduced die size compromises the GPU, and, those are all pretty fair observations. The generational shift in pure rasterization performance is equally unimpressive. However, the efficiency attained on the cut-down GPU is indeed positive for the graphics card.  \n>  \n>But, by the same token, the RTX 4060 is a workhorse GPU that offers better performance than its previous generation counterpart, at a lower price point, to boot. Though it’s not perfect, the RTX 4060 is a perfect upgrade for those still hanging on to older cards like the GTX 1060 and delivers adequate performance at both 1080p and 1440p.  \n>  \n>The RTX 4060 is a solid graphics card, with barely any frills to speak of. Its performance won’t blow any minds, but its value proposition and power efficiency are undeniable. While it would have been nice to see an expanded pool of VRAM and more pure rasterization performance, it’s a solid upgrade for those still using older GPUs.\n\n# [Guru3D](https://www.guru3d.com/articles-pages/asus-dual-geforce-rtx-4060-oc-review,1.html)\n\n>The GeForce RTX 4060 graphics card delivers useful gaming performance and good rendering quality overall at a Full HD resolution. At full HD, modern games will manage 60+ FPS, with older titles quickly reaching 100 fps on average.  Overall, the GeForce RTX 4060 8GB makes sense at resolutions as high as 1920x1080/1200 and sometimes up to WQHD if you use a DLSS assist; frame generation really will help, but again at the valuable cost of VRAM utilization. The card is \\~18% faster than the RTX 3060 but almost 25% slower than the 4060 Ti.   \n>  \n>As a Full HD card, the card works out well. But as an upgrade the 4060 series remains to be a hard sell. The new 4060 8GB is an entry-level to mainstream card. NVIDIA, however, barely gave it enough shading horsepower and leans too much on dependencies like DLSS3 and Frame generation. While we like these technologies, DLSS does not work out well, specifically in 1920x1080 and lower as the engine learns and upsamples from lower resolution content (less data to work with). That will inevitably degrade image quality. Frame generation we like very much, but here again the choice in 8GB is a inadequate one, considering frame generation will at away in that graphics memory budget as well, leaving even less to work with. To compensate for that and when factoring in the narrow 128-bit wide memory bus, NVIDIA added 24MB of cache. That cache works out great until it dries out and cache misses kick in. Then the card will drop down in performance big time and things become a stuttery mess.  \n>  \n>If this card would have been $199 then these would have been acceptable compromises; however, at $299, my eyebrowes frown a bit. I mentioned this before; we raise concerns as to what is happening with the PC Gaming graphics card market, as graphics cards (and PC components) are getting too expensive. Loads of end-users will flee towards consoles ar streaming services, so defacto, this market is slowly destroying itself. Ultimately, the GeForce 4060 delivers just enough performance to justify Full HD gaming. The DUAL GeForce RTX 4060 OC edition also delivers acceptable overclocking performance in a compact form factor. The design of the card emphasizes thermal efficiency and relatively low noise output. We're not sure what the actual street price for this model will become yet but ASUS reassured us this product will be based on MSRP making it the best of the 4060 pack, but even $299 might limit the market reach of this product.\n\n# [Hot Hardware](https://hothardware.com/reviews/nvidia-geforce-rtx-4060-review-with-asus)\n\n>MSRP for new GeForce RTX 4060 cards starts at $299, which is about $30 lower than the RTX 3060's launch price and $50 below the RTX 2060's. It's also about $30 more than the [recently-launched Radeon RX 7600](https://hothardware.com/reviews/amd-radeon-rx-7600-mainstream-gpu-review). At its expected price point, the GeForce RTX 4060 represents a decent value, especially in light of its all-around performance and low power consumption. As was the case with the first wave GeForce RTX 4060 Ti cards, the 8GB of memory on the GeForce RTX 4060 may give some gamers pause, but turning down some detail has typically been a requirement for mainstream GPUs, and the bottom line is at 1080p, the GeForce RTX 4060 outperforms its competition more often than not. If that 8GB frame buffer is a deal breaker for you, however, the GeForce RTX 4060 Ti 16GB will be available in a few more weeks, and [prices on Radeon RX 67x0 XT](https://amzn.to/3pp7Bhh) cards have dropped significantly as of late.  \n>  \n>Although its not a barn-burner, the GeForce RTX 4060 is a good option for gamers with 1080p monitors, that don't have the budget for a higher-end card. It isn't an upgrade for anyone with an RTX 3060 Ti or better, but if you're still rocking that GeForce GTX 1060, RTX 2060, or even [a 1600-series card](https://hothardware.com/reviews/nvidia-geforce-gtx-1660-review-and-benchmarks), the GeForce RTX 4060 offers significantly more performance, power efficiency, and all of the cutting-edge features of NVIDIA's Ada architecture, like DLSS 3 and AV1 encoding. If you're shopping for a mainstream GPU in the $300 price band and game at 1080p, the GeForce RTX 4060 will serve you well. As is always the case in this crowded segment, however, if you can pull together some additional funds, there's significantly more performance on the table for a modest additional investment\n\n# [Igor's Lab](https://www.igorslab.de/en/nvidia-geforce-rtx-4060-8-gb-in-an-objective-review/)\n\n>I’m not entirely sure what NVIDIA was thinking in detail with this card, but when it comes to the mainstream, they seem to have been in quite good spirits until the launch of the GeForce RTX 4060 Ti. They certainly didn’t expect all the headwind with the 8 GB VRAM back then, so I’m not surprised that such marketing pirouettes were performed and marketing stunts were celebrated in the run-up to today’s launch.  \n>  \n>I will certainly not go into the always soggy memory now, because then I would only repeat myself. The GeForce RTX 4060 8 GB also has positive sides, but you have to be able to accept them. It is almost 11% faster in Full HD than a GeForce RTX 3060 12 GB, and it is still 8% faster in Ultra HD. That might not sound much, but I used a gaming mix that is less prone to cherry-picking. So, the 11 percent is always in there in Full HD, even outside of the ordered YouTube show.  \n>  \n>The GeForce RTX 4060 8 GB is a card for Full HD when it comes to higher frame rates and is also conditionally suitable for WQHD. But then you will have to think about smart upscaling because it gets a bit tight in places even in QHD without DLSS. NVIDIA can definitely use its advantages here, which DLSS 2.x also offers optically. However, if a game supports DLSS 3.0 and you would be stuck in the unplayable FPS range without Super Sampling, then this can even be the ultimate lifeline for playability. You can’t improve the latencies with this (they stay the same), but not every genre is as latency-bound as various shooters.  \n>  \n>Thus, you get all the advantages of the Ada architecture starting at 329 Euros (MSRP cards). However, the outdated memory expansion and the narrow memory interface are disadvantages. The 8 lanes on the PCIe 4.0 are completely sufficient, but when the card has to access the system memory, it gets very tight on older systems with PCIe 3.0 at the latest. Then the 11 percent advantage over the RTX 3060 12GB is gone faster than you can say pug.  \n>  \n>And if you ask me for a personal conclusion: It turns out slightly different than what was ordered in advance by certain YouTubers. Not absolutely negative, because I have mentioned the positive sides. But it is not really euphoria, because the card simply costs too much and does not quite deliver what was promised in advance. Drivers can be fixed, no problem. Only VRAM and telemetry are a bit more complicated.\n\n# [KitGuru Article](https://www.kitguru.net/components/graphic-cards/dominic-moass/nvidia-rtx-4060-review-ft-msi/)\n\n# [Kitguru Video](https://www.youtube.com/watch?v=JNZJpmBDWU4)\n\n>Despite all that, I do think the RTX 4060 isn't quite as bad as the RTX 4060 Ti. For one thing, it's 26% cheaper but only 20% slower, so that results in a small improvement to cost per frame. Primarily though, the fact the RTX 4060 only ships with 8GB VRAM is easier to forgive at the £289 price point, as end users would be more willing to accept image quality compromises with the RTX 4060 than you would with the £389 RTX 4060 Ti.  \n>  \n>That being said, in no way, shape or form do I think 8GB VRAM is a *good* amount for the RTX 4060. My RTX 4060 Ti video offered numerous examples where 8GB VRAM is clearly a limiting factor, all of which apply to the RTX 4060, and we also saw a couple more in this review with the Cyberpunk 2077 and Spider-Man Remastered results. Again, if all of this is happening *today*, it does not bode well for things in one, two, three years down the line.  \n>  \n>The 8GB framebuffer situation is also made worse for the RTX 4060 when we consider the fact that its predecessor, the RTX 3060, obviously launched with 12GB VRAM over two years ago. Of course I understand from a *technical* perspective that 12GB VRAM is not a viable option for the RTX 4060 due to its 128-bit memory interface, instead it would need to have either 8GB or 16GB. The reality is, however, that *neither* of those are good options for this class of hardware, whereas 12GB VRAM would suit this GPU perfectly – something we had with the last generation xx60 SKU, but have since regressed on, and that's never a good look.  \n>  \n>If you're just wondering about who has the upper hand between the [AMD RX 7600](https://www.kitguru.net/components/graphic-cards/dominic-moass/amd-rx-7600-review/) and the RTX 4060, I'd say Nvidia has the stronger – or perhaps more accurately, the less weak option. Yes, the RX 7600 offers equivalent rasterisation performance [for £40 less](https://www.overclockers.co.uk/sapphire-radeon-rx-7600-pulse-gaming-8gb-gddr6-pci-express-graphics-card-gx-02y-am.html), and for some that might be all that matters. However, the 4060 is far superior when it comes to ray tracing, while also offering support for DLSS 2, DLSS 3 and significantly better energy efficiency.  \n>  \n>Neither are impressive though, so if you're looking for a new graphics card, I wouldn't position the RX 7600 as the main contender to the RTX 4060. The [RX 6600 at £180](https://www.overclockers.co.uk/asrock-radeon-rx-6600-dual-8gb-gddr6-pci-express-graphics-card-gx-00t-ak.html) is more of a threat in my view, coming in over £100 cheaper while still offering decent gaming performance, and of course the 8GB framebuffer stings a heck of a lot less at that price point. Or you could go the other way and look at an [RX 6700 XT for £340](https://www.overclockers.co.uk/powercolor-radeon-rx-6700-xt-fighter-12gb-gddr6-pci-express-graphics-card-gx-1a5-pc.html), a GPU that's 18-20% faster while also offering *50% more VRAM*, giving you more longevity at Ultra settings. The main drawback to that RDNA 2 GPU is power consumption however, as it pulls almost twice the power as the RTX 4060.  \n>  \n>Ultimately, the **Nvidia RTX 4060** is another very underwhelming launch. Real generational gains for this class of hardware just don’t seem to be a thing any more, and while it is slightly more palatable than the RTX 4060 Ti, it's still very hard to recommend outright, at least not without a reasonable price cut.\n\n# [LanOC](https://lanoc.org/review/video-cards/8777-asus-dual-rtx-4060-8gb)\n\n>Looking beyond Asus’s design to the RTX 4060 itself. This is a card designed for 1080p which the 8GB memory is designed around. Like with the RTX 4060 Ti, if you have plans on upgrading to a higher resolution monitor during the time you have this card, this isn’t the card you should be looking for. But with 1080p having the largest number of users it makes sense for Nvidia to target the resolution. With that 1080p performance in all of our tests was great, and 1440p wasn’t too bad as well with the average across the games tested at 95 FPS. I know a lot of people are concerned with the lower memory, especially when you compare it against the 3060 which had 12GB. Nvidia’s larger cache does seem to help alleviate some of the load there with the 4060 outperforming the RX 7600 and 6500XT at higher resolutions while both of those cards have the same VRAM and are faster at 1080p. But we also know that some extra demanding applications like some emulators will struggle and for those the 3060 is still going to be the better option.  \n>  \n>Overall the RTX 4060 does replace the RTX 3060 as the go-to card for 1080p gaming at a value except for emulation. Like with previous 4000 Series cards, the 4060 does struggle to keep up in overall value when it comes to just raster performance compared to the similarly priced AMD cards. Ray tracing performance and DLSS both help even that out assuming the games that you are looking to play support them and that list is getting longer almost daily. In the end, Nvidia faithful who loved their GTX 1060 or similar card are going to love the upgrade but they will pay a premium for the Nvidia-specific technology. Value-focused customers who blow whichever way the wind is blowing however will have to figure out if the games they are planning on playing have or will be getting DLSS and/or ray tracing, without that those customers are going to be looking at the lower prices and better rater performance at 1080p from the RX 7600 and the older RX 6650XT while it is still available.\n\n# [OC3D Article](https://overclock3d.net/reviews/gpu_displays/nvidia_rtx_4060_with_asus_dual_and_gigabyte_windforce_review/1)\n\n# [OC3D Video](https://www.youtube.com/watch?v=kz0vVh4hcBo&pp=ygUIUlRYIDQwNjA%3D)\n\n>The Nvidia Ada Lovelace range was already full to bursting, and here we are with yet another model in the range.  \n>  \n>Like any new graphics card, where you fit in the target audience is very important as to how useful this particular card will be to you. With the price point and level of performance on the RTX 4060 that's not the matter of a moment to work out. It certainly stands in stark contrast to the majority of other cards Nvidia have with a 4000 tag. The RTX 4090 and RTX 4080 are easy enough to delineate; regardless of what you currently own they'll be a stunning upgrade if you can afford them. The RTX 4070 Ti fits in that meaty mid-market segment, perfect for those without unlimited funds who still want to be able to play all the latest titles with everything cranked up. Then we come to the RTX 4060 Ti, a recent release which is aimed at those of you who largely game at 1080P, and here there is enough performance, particularly in DLSS supported titles, to make it a suitable upgrade for those with limited funds and older cards.  \n>  \n>Naturally there is only so much you can trim off of a cards hardware before you start reaching a point where any comparison will come with asterisks and caveats, and the RTX 4060 is one such card. Nvidia themselves point at the Steam hardware survey and how the most commonly used cards on Steam are, in descending order from 1 to 5, the GTX 1650, GTX 1060, RTX 3060, RTX 2060 and GTX 1050 Ti. Those of us with cards which sit above those are very much the lucky ones in the minority. Of those cards, any of the GTX ones or the original affordable RTX card, the 2060, will find the RTX 4060 a more than great upgrade. The extra performance from the RTX 4060 is significant, and in DLSS 3 supported titles there is enough performance to render the aforementioned cards almost obsolete. Only the RTX 3060 is in the spot where it's a less obvious upgrade, and that's just as much to do with the 12GB of GDDR onboard and the recency of the Ampere architecture as it is anything else.  \n>  \n>So assuming that you've decided your creaky old system could do with a new graphics card, which of today's two offerings should you opt for? After all, when working in a tight budget even a microscopic difference in performance or efficiency is magnified in a way that it isn't at the top end. There might be 10 FPS difference between different RTX 4090 cards, but all of them are so capable that you can go with either the most affordable one, or the brand you like, and you won't be left feeling left out. But here, where 10 FPS can be the difference between playable and jerky and where there isn't any lighting to control to make you sway towards one brand or another for system harmony reasons, any difference is stark.\n\n# [PC Perspective](https://pcper.com/2023/06/nvidia-geforce-rtx-4060-review-featuring-asus/)\n\n>If you are looking for a GPU at this price level, the only competition from this generation (forgetting the mountain of previous-gen cards in the pipeline) is AMD Radeon RX 7600, and the Intel Arc stuff I didn’t test as I was running behind schedule. If we are talking rasterization, AMD is winning the sub-$300 area this generation, but the 4060 is an RTX product, and that means ray tracing and DLSS.  \n>  \n>Naturally, DLSS with the RTX 40 Series means frame generation, and frame generation means higher perceived FPS on top of the performance gains from DLSS. AMD is apparently trying to thwart NVIDIA’s DLSS advantage by blocking the feature on games in which they are partners ([see Starfield drama](https://videocardz.com/newz/amd-dodges-questions-about-fsr-exclusivity-in-amd-sponsored-games)), but many, many titles do support NVIDIA’s upscaling tech. And, honestly, if you’re buying a 4060 with 8GB of VRAM, you should use DLSS.  \n>  \n>I just can’t help but think that if this product had been called the RTX 4050 Ti – even if it was launching at the same price (though that wouldn’t go over well at all) – there would still be room for a cut-down AD106 product between this and the RTX 4060 Ti 8GB. And *that* product could have been the RTX 4060. Product names and pricing might be all we talk about when we look back on this generation of NVIDIA GPUs, years from now. \n\n# PC World\n\n>TBD\n\n# [TechGage](https://techgage.com/article/a-look-at-nvidias-geforce-rtx-4060-8gb-rendering-performance/)\n\n>While a creator angle of any GPU is going to involve more than just rendering, rendering is one of the best types of workloads to showcase what any one GPU can do against another. After poring over these results, we can see that the new RTX 4060 easily beats out its RTX 3060 predecessor, and often surpasses either the RTX 3070 or RTX 3070 Ti, depending on the render engine.  \n>  \n>When we compare against the last-gen parts, the RTX 4060 looks quite good, in some cases even able to match the RTX 3070 Ti, which SRP’d for $599. That said, there are are variations in performance strengths of the RTX 4060, with it out-performing the RTX 3070 Ti one moment (in Arnold), while other times slides in behind RTX 3070 and just ahead of RTX 3060 Ti.  \n>  \n>One performance gain that stood out was with Blender. In both of the Cycles renders, the RTX 4060 leaped quite a bit ahead of the RTX 3060. Note that we didn’t have the full set of last-gen Ampere-based cards in those charts, but results from those [**can be found here**](https://techgage.com/article/blender-3-5-performance-deep-dive-cycles-eevee-viewport/).  \n>  \n>One thing we didn’t talk about yet – and it’s largely because we haven’t tested it hands-on – is that the RTX 4060 is spec’d for far less power usage than the RTX 3060 – a difference of 110W vs. 170W. Power use might be one of the least interesting things about a new GPU launch, but we *love* seeing components improve performance while using less power – it’s a win-win.  \n>  \n>For now, this is all we can really say about the RTX 4060. First impressions are good overall, although we know that on the gaming side of the fence, the *pièce de résistance* is going to revolve around DLSS 3 and its frame generation feature, which can boost the overall and percentile frame rates with the help of AI. This feature is best used when the base-line (with DLSS, but not FG) FPS is suitable for regular play, as a 100 FPS game with 30 FPS input latency is going to feel disjointed.\n\n# [Techpowerup](https://www.techpowerup.com/review/asus-geforce-rtx-4060-dual-oc/)\n\n>Averaged over the 25 games in our freshly updated H2 2023 test suite, at 1080p, we find the RTX 4060 just 4% ahead of the recently-launched AMD Radeon RX 7600. This means that RTX 4060 isn't able to beat last generation's RTX 3060 Ti, which remains 10% faster. The gen-over-gen performance gain is only 20%, at least more than what we saw with RTX 4060 Ti vs RTX 3060 Ti. Compared to the RTX 4060 Ti, the performance difference is 20%. AMD's Radeon RX 6700 XT 12 GB is 13% faster than the 4060, the Radeon RX 6600 XT is 10% slower. NVIDIA's aging RTX 2080 offers roughly the same performance as the RTX 4060, and the gap to the four year old Radeon RX 5700 XT is 20%. Intel's Arc A770 is within 5% of the RTX 4060, the A750 is 12% behind—not much. If Intel can bring their pricing down, they could steal some sales from NVIDIA and AMD in this segment. With these performance levels, RTX 4060 is a solid choice for gaming at Full HD—you'll be getting 60+ FPS in nearly all titles at maximum settings. Gaming at 1440p is in reach at decent FPS rates, too, but you'll have to reduce settings in some games, or enable upscaling with DLSS/FSR.  \n>  \n>While I think that ray tracing isn't the most important technology to have in this segment, it's still some extra eye-candy that a lot of games come with these days. However, enabling ray tracing significantly impacts performance, which can be troublesome if you're struggling to maintain a frame rate above 60 FPS, even with RT off. On the other hand, in games where you have extra FPS to spare, activating ray tracing can further enhance the visual experience, beyond classic \"ultra\" settings. NVIDIA has been the leader in ray tracing for years and RTX 4060 isn't any different. While AMD has to execute ray tracing in their shader cores, NVIDIA has dedicated hardware units, which can take over that task. Compared to AMD's Radeon RX 7600, the RTX 4060 offers 22% better RT performance and is even able to beat the Radeon RX 6700 XT with its 12 GB framebuffer.  \n>  \n>GeForce RTX 4060 comes with a 8 GB VRAM buffer—4 GB less than last generation's RTX 3060. This is a total non-issue though. Even in the worst-case (The Last of Us, a known memory hog), at 1080p, the RTX 4060 is still 8% faster than the RTX 3060. While it would be nice of course to have more VRAM on the RTX 4060, the 128-bit bus design limits the memory choices to 8 GB or 16 GB. With this test suite we do have all the new games and I find it very hard to spot significant FPS issues with the RTX 4060. No doubt, you can find edge cases where 8 GB will not be enough, but for thousands of games it will be a complete non-issue, and I think it's not unreasonable for buyers in this price-sensitive segment to set textures to High instead of Ultra, for two or three titles. If you still want more memory, then NVIDIA has you covered. The RTX 4060 Ti 16 GB launches in July, for $500, and gives people a chance to put their money where their mouth is. I'm definitely looking forward to testing the 16 GB version, but I doubt there will be enough of a difference to justify the cost.\n\n# [The FPS Review](https://www.thefpsreview.com/2023/06/28/asus-dual-geforce-rtx-4060-oc-edition-video-card-review/)\n\n>We found that the video card performed well in games, as described above. It allows you to enjoy games at 1080p at maximum settings, with playable framerates. We did not need to enable upscaling to enjoy gaming at 1080p. Though we were certainly able to improve the gameplay experience by enabling DLSS in games, further giving us better gameplay. We were also able to turn on Ray Tracing and enjoy it in many games at 1080p. A few were demanding, but DLSS came in to save the day.  \n>  \n>In the games not playable with Ray Tracing, DLSS provided the means to make them playable. In addition, DLSS 3 Frame Generation is a new feature only the GeForce RTX 4060 can provide at this price. DLSS adoption has been fast and swift, and there are just hundreds of games now with DLSS, and a good chunk with DLSS 3 now as well. With growing support, the future is only looking brighter for DLSS 3.  \n>  \n>The ASUS Dual GeForce RTX 4060 OC Edition is a very power-efficient video card, and in our testing used the least amount of power. Even when overclocking, the GPU only sips power. This really is the most power-efficient GPU in this price range. The ASUS Dual Axial fan cooler worked extremely well and keeps this GPU cool and quiet. The video card is compact and will fit well in any small build where space is tight. We were also impressed with the overclocking potential of the ASUS Dual GeForce RTX 4060 OC Edition. We achieved a very high overclock, and it was pretty easy to achieve. Enthusiasts should have fun with this video card.  \n>  \n>Overall, for $299 the ASUS Dual GeForce RTX 4060 OC Edition is a video card you should keep your eye on if you are in the market at this price range.\n\n# [Tomshardware](https://www.tomshardware.com/reviews/nvidia-geforce-rtx-4060-review-asus-dual)\n\n>The RTX 4060 isn't a terrible card by any means. Some people will probably say it is, but across our benchmark suite, it was universally faster than the previous generation RTX 3060 at every setting that mattered (meaning, not counting 4K ultra performance, where neither card delivered acceptable performance). There will be edge cases where it falls behind, like *Spider-Man: Miles Morales* running 1440p ultra, where minimum fps was clearly worse than on the 3060. But overall? Yes, it's faster than the previous generation, and it even cuts the price by $30 — not that the RTX 3060 was available for $329 during most of its shelf life.  \n>  \n>There are other benefits, like the power efficiency. The RTX 3060 consumes about 35W more power than the Asus RTX 4060, for example. Better performance while using less power is a good thing. Other architectural benefits include the AV1 encoding support, and features like Shader Execution Reordering, Opacity Micro-Maps, and Displaced Micro-Meshes might prove beneficial in the future — we wouldn't be heavily on those, however, as they're all exclusive to the RTX 40-series GPUs right now and require API extensions.  \n>  \n>The saving grace for the RTX 4060 is undoubtedly its price tag. AMD already has cards that deliver generally similar performance at the same price, but there are a lot of gamers that stick with Nvidia, regardless of what other GPU vendors might have to offer. Now you can get a latest generation RTX 4060 for $299, with better performance and features than the RTX 3060. Just don't expect it to behave like an [RTX 4070](https://www.tomshardware.com/reviews/nvidia-geforce-rtx-4070-review) that costs twice as much.  \n>  \n>A more benevolent Nvidia, flush with the cryptocurrency and AI profits of the past two years, would have made this an RTX 3050 replacement. With the same $249 price, it would have been an awesome generational improvement, as it's 66% faster than the 3050. That's basically what Nvidia did with the RTX 4090, which is up to 60% faster than the RTX 3090 for nearly the same price. But every step down the RTX 40-series has been a tough pill to swallow.  \n>  \n>The RTX 4080 is about 50% faster than the 3080, yet it costs 70% more. The 4070 is 30% faster than the 3070 and costs 20% more. The 4060 Ti has the same launch price as the 3060 Ti, but it's only 12% faster. Now we have the RTX 4060 that undercuts the price of the 3060 by 10% while delivering 20% better performance. That's better than most of its siblings, and maybe there's still hope for an RTX 4050... but probably not.  \n>  \n>As with the last several graphics card launches, including the [Radeon RX 7600](https://www.tomshardware.com/reviews/amd-radeon-rx-7600-review), [GeForce RTX 4060 Ti](https://www.tomshardware.com/reviews/nvidia-geforce-rtx-4060-ti-review), and [GeForce RTX 4070](https://www.tomshardware.com/reviews/nvidia-geforce-rtx-4070-review), we end up with similar feelings. It's good that the generational pricing didn't go up with the RTX 4060. For anyone running a GPU that's two or more generations old, the RTX 4060 represents a good upgrade option. But we're still disappointed that Nvidia chose to use a 128-bit interface and 8GB of VRAM for this generation's xx60-class models.\n\n# [Computerbase - German](https://www.computerbase.de/2023-06/nvidia-geforce-rtx-4060-test/)\n\n# [HardwareLuxx - German](https://www.hardwareluxx.de/index.php/artikel/hardware/grafikkarten/61339-5x-geforce-rtx-4060-nvidias-kleinster-ada-ableger-im-test.html)\n\n# [PCGH - German](https://www.pcgameshardware.de/Geforce-RTX-4060-Grafikkarte-279649/Tests/Geforce-RTX-4060-Preis-Release-Benchmarks-Test-1422644/)\n\n# ----------------------------------------------\n\n# Video Review\n\n# Der8auer\n\n# [Digital Foundry Video](https://www.youtube.com/watch?v=BQ3u5bWMf_M)\n\n# [Gamers Nexus Video](https://www.youtube.com/watch?v=WS0sfOb_sVM)\n\n# Hardware Canucks\n\n# [Hardware Unboxed](https://www.youtube.com/watch?v=7ae7XrIbmao)\n\n# [JayzTwoCents](https://www.youtube.com/watch?v=WmcrikP7ALA)\n\n# [Kitguru Video](https://www.youtube.com/watch?v=JNZJpmBDWU4)\n\n# [Linus Tech Tips](https://www.youtube.com/watch?v=O0srjKOOR4g)\n\n# [OC3D Video](https://www.youtube.com/watch?v=kz0vVh4hcBo)\n\n# Optimum Tech\n\n# Paul's Hardware\n\n# [Techtesters](https://www.youtube.com/watch?v=F7ehpiBaudI)\n\n# Tech Yes City\n\n# The Tech Chap",
    "comments": [
      "LTT called it a \"wet fart of a GPU\" and were pretty scathing, basically saying what we've all known for years which is nVidia hates its retail customers and board partners, and love their AI-chasing corporate partners.",
      "The problem is that x60 buyers benefit from really good cards in this segment and the 4060 is not one of them. The 1060 lasted so long cause of its big VRAM buffer and very solid performance for a reasonable price. The 1660 Super was sort of that as well, but nothing since has been a really good deal on the Nvidia side.",
      "Hardware Unboxed regarding 4060 = more trash",
      "I don't think negativity is being removed on this sub. I honestly just think everyone is apathetic about the whole thing, nobody has fuel in the tank to hate this anymore it's just whatever.",
      "Igor's Lab review in regards to power consumption is quite interesting. It seems there are no voltmeter components on the pcb, so the power draw shown in software tools, which is around 115 watts, isn't actually measured. The 4060 uses over 130 watts instead. So, those nVidia marketing slides will probably produce some backlash. And unless the 4060 is a strong undervolter the gap to an undervolted/overclocked 3060 in power consumption will be only a few bucks a year.",
      "This is a piece of crap card. It can’t even beat a 3060Ti, has a 128 bit memory bus and x8 PCIe for $300? I’m not sure why people wouldn’t hate it, it’s a 4050 for $100 over what it should be.",
      "There is a clear disconnect between consumers who buy a $300 GPU every four years and those who preorder every xx90 series card as soon as they can.  One group views the card as being about what they expected and the other sees it as little more than e-waste.  I'm not sure how the two sides can ever have a reasonable discussion about GPUs like this.",
      "I'm not really sure that's how it is as the 90 class card was the only card to get a performance per dollar boost over it's 30 series counterpart. \n\nSure, people who just need a GPU will take what they can get at the moment and typically people on a GPU subreddit will be more enthusiast but a lot of enthusiasts still can only afford 60 class cards and this gen has left no real improvement. We can sugar coat it with power and DLSS3 but in raw raster it's a bit of a nothing burger.",
      "The 3060 was a worse card relative to the rest of the 30 series.  In this case the 4060 is basically just \"fixing\" that issue and putting the perf/$ back where it belongs in line with the rest of the 40 series.\n\nWith no context, yes it looks like the 4060 is a better value.  In actuality it's the reverse:  the rest of the 30 series was just a better value.",
      "We can literally summarize the aggregate of all these reviews with a single emoji:\n\n💩",
      "Well I was wrong, expected it to hit 3060 Ti levels (or at least really close) but it actually seems to be about 10% slower.",
      "I'm more in the first section, but would still consider this e-waste. The 300-400 price range offerings have been utter crap for 4-5 years now.",
      "Shadow banned maybe?",
      "A wet fart is a great way to talk about all the new series of GPUs currently except maybe the 7900XTX, 4080 and 4090, at least eprformance wise. Prices are another story.",
      "You were the first to respond.",
      "Is this card actually a bad value for 1080p? I made a table based on Hardware Unboxed's numbers and it still gets beat by AMD, but it becomes the best nvidia gpu. With dlss and the efficiency, I feel like it's at least worth considering.\n\n|**card**|**fps**|**price**|**cost-frame**|\n:--|--:|--:|--:|\n|6600|71|200|2.817|\n|6600xt|80|230|2.875|\n|6650xt|85|250|2.941|\n|7600|88|270|3.068|\n|6700xt|103|330|3.204|\n|4060|91|300|3.297|\n|3060|79|270|3.418|\n|3060ti|102|350|3.431|\n|4060ti|111|400|3.604|\n|6950xt|168|630|3.750|\n|3070|112|425|3.795|\n|6800|127|520|4.094|\n|4070|143|600|4.196|\n|7900|179|800|4.469|\n|4070 ti|171|800|4.678|",
      "From Tom's HW review: \n\n\"The RTX 4080 is about 50% faster than the 3080, yet it costs 70% more.  The 4070 is 30% faster than the 3070 and costs 20% more. The 4060 Ti has  the same launch price as the 3060 Ti, but it's only 12% faster. Now we  have the RTX 4060 that undercuts the price of the 3060 by 10% while  delivering 20% better performance. That's better than most of its  siblings.\"\n\n&#x200B;\n\nLook this card isn't amazing, but it's weird that this one is the one everyone decided to hate. The rest of the 40 series releases have been worse, but it feels like y'all are just waking up now and realizing this gen is bad.",
      "yes, HU refuses to show its RT or DLSS performance",
      "17 minutes and 0 comments? I suspect that there have been some but they have got removed.\n\nHow could anyone be positive about this card (and generation overall).",
      "And it can’t even match the 3060Ti in performance. It’s literal e-waste at its price."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "rtx 4060",
      "4060"
    ],
    "title": "Whats the best 4060 to get?",
    "selftext": "Im looking for budget options to upgrade my current pc. For the graphics card i was thinking the MSI VENTUS 2X BLACK OC GeForce RTX 4060 8 GB graphics card but I’m asking if i should go for something better. There is 2 asus dual fan 4060 I’m looking one is like ten dollars more (ASUS Dual GeForce RTX™ 4060 EVO OC Edition 8GB GDDR6 ) and the other is 100 dollars more",
    "comments": [
      "Just get a RX6700XT or 6800 instead of this crap",
      "Asus dual OC. But, a 6750xt or a used 2080ti would be better.",
      "Xess, but yeah they are back to fumbling drivers, i rolled back cause the latest ones cause stutters in darktide. But at the price range amd options are still a lot better, 4060 doesn't really give you the vram for frame gen, amd also has frame gen.",
      "Also looking for ram, is this ram good? The Timetec Pinnacle Konduit 64GB KIT(4x16GB) DDR4 3200MHz PC4-25600 CL16-20-20-40 XMP2.0 Overclocking",
      "Ventus cards tend to overheat, so I would probably go for asus, but as 4060 draws next to no power so overheating may not be as much of a problem.\n\nAnd for f sake people answer the question OP asks, don't recomend him another card/s.",
      "6800 is a beast for budget 1440p",
      "Ill think about the 2080ti, its a little better but not by much for the 200 minimum i would have to spend for the 2080ti",
      "Looks good cl 16 3200mhz is sweetspot. Why 64gb though? Could half it and put it towards a better gpu.",
      "Thanks alot ill probs get the asus than. My pc doesnt have the best cooling so good looking out",
      "It is but im tryna stay under a certain budget so i can get everything quicker",
      "Used 3070 or 3060ti. Also what programs and res?",
      "why?\n\nis there any actual software or other reason, that you prefer an nvidia graphics card?\n\ndo you ABSOLUTELY NEED cuda?\n\nbecause if the only reason you prefer nvidia graphics cards is their mindshare and nothing else,\n\nthen you are shooting yourself in the foot as a customer.\n\nthe 4060 8 GB vram card is a literal insult of a card. it is inherently broken.\n\nit is actually far worse than the 3060 12 GB card, which you can look at here:\n\n[https://www.youtube.com/watch?v=8KuxORuIQGI](https://www.youtube.com/watch?v=8KuxORuIQGI)\n\nresident evil 4 1080p max.\n\n1% lows, 3060: 57 fps 64 average\n\n1% lows 4060: 10 fps.... 70 average\n\ngraphics card suggestion, if the ONLY reason you want nvidia is mindshare:\n\n6700 xt or 6750xt: cheaest version 6750 xt 270 us dollars on newegg. they have 12 GB vram.\n\nbroken 4060 btw cheapest is  290 us dollars on newegg.\n\nor if you want to spend a bit more the rx 6800 costs 350 us dollars on newegg.\n\nthe rx 6800 is 52% faster, but that was when hardware unboxed only had one game in the testing, that ran out of vram on the 4060. NOW it is way worse than that :D\n\nand the rx 6800 would only cost 20% more than a 4060.\n\nand again it isn't just that the rx 6800 performs that much better, but the 8 GB vram 4060 is BROKEN in lots of games due to missing vram.\n\ni guess the best question to ask is:\n\ndo you want a working graphics cards, or do you want an nvidia card?",
      "It also has 11GB of VRAM.",
      "Its 100 bucks for this ram, i could do a 4x8 ig but i would really only be getting an extra 20 bucks at most",
      "Good choice, hope the upgrade goes well :)",
      "I could get a used card but i personally haven’t had the best experience with buying new stuff it’s kind of a gamble. \n\nI got a windows on my pc with a 1080p main monitor and a 720p both 24 inches .Looking to upgrade too two 27 in 1440p and the side monitor 1080p soon though and my pc has been slowing down for a while now. I tried cleaning my pc to. It also could be a hard drive problem idk. But i think its just time to spend some more money upgrading",
      "you're really suggest 8 GB vram cards in 2024?",
      "Thansk for all the tips, honestly im open to the cards ive just so used to nvidia geforce that honestly im a little scared to switch and geforce cards are just the cards ive researched.",
      "DLSS is the best invention for pc gaming in quite awhile. Gaming without DLSS? No thank you.",
      "you could just get another 2x 8gb of the same ram seeing as you already have 16gbs, unless they are discontinued or just really slow. Honestly unless you have a specific need 16gb is fine for gaming."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "4060",
      "rtx 4060ti",
      "4060ti",
      "4060 ti"
    ],
    "title": "ASUS Dual 4060 Ti SSD Review",
    "selftext": "When building a PC, what's the first thing you decide? Do you go for performance, aesthetics, or both? Do you go for a small form factor system or do you go for a full tower? Are you brand loyal or do you go for feature sets on the components regardless of brand? All choices are not a bad one when it comes to a PC that you are building for you or somebody else. In this review we are not only going to go over the ASUS Dual RTX 4060Ti SSD that ASUS sent me, but also the system I decided to build around it. YouTube build video link will be down below for this system as well as pictures.\n\nLet's first get into the 4060Ti. What are some questions you have about this particular GPU? Hopefully I can answer them for you in this post. First things first, let's get into the PC build specs.\n\n* **Motherboard**: ASUS TUF Gaming B760M - Plus WiFi D5\n* **CPU**: Intel Core i5 12600K\n* **CPU Cooler**: ASUS TUF Gaming LC II 240 ARGB\n* **RAM**: TeamGroup T-Force Delta RGB 32GB (2 x 16GB) 6000 CL38\n* **SSDs**: WD\\_Black SN850x 1TB x3\n* **GPU**: ASUS DUAL RTX 4060Ti 8GB SSD OC\n* **PSU**: ASUS TUF Gaming 850w 80+ Gold\n* **Case**: ASUS Prime AP201 TG\n* **Case Fans**: ASUS TUF Gaming TF120 x4\n\nThe first question I am going to answer is probably the biggest about this GPU, what do the temps look like? The temps are actually very good. When doing a temp test on this GPU, I wanted to do something synthetic as that will be the absolute worst you can have. To achieve these temps, I ran a Furmark for 10 minutes to get the baseline for both the OC profile and the Silent profile. After I got my results for those 2, I flipped the switch back to OC and ran that Furmark for 10 minutes, but also ran a Crystal Disk Mark test on a 32GB file 5 times. Here are my results from both of those tests:\n\n* **OC Profile**: 62°C\n* **Silent Profile**: 63°C\n* **OC With SSD**: 66°C\n* **SSD**: 56°C\n* **GPU Hotspot**: 77.4°C\n* **SSD Read Speed**: 6,928\n* **SSD Write Speed**: 6,380\n\nWhat's the next big question… Performance in terms of FPS? Happy to report, this GPU did very well in that aspect as well. I ran a 1080P, 1440P, and 4K benchmark in 8 different games to get a baseline of what kind of FPS performance you can expect. All benchmarks were run at absolute max settings, Ray Tracing turned off, and DLSS turned off as well.\n\n**1080P:**\n\n* **Assassins Creed Valhalla**: 129 FPS\n* **CyberPunk 2077**: 96 FPS\n* **COD MW III**: 125 FPS\n* **Forza Horizon 5**: 90 FPS\n* **Hitman III**: 235 FPS\n* **Mafia II**: 71 FPS\n* **Shadow of the Tomb Raider**: 174 FPS\n* **Red Dead Redemption 2**: 105 FPS\n\n&#x200B;\n\n**1440P**:\n\n* **Assassins Creed Valhalla**: 93 FPS\n* **Cyberpunk 2077**: 59 FPS\n* **COD MW III**: 90 FPS\n* **Forza Horizon 5**: 68 FPS\n* **Hitman III**: 148 FPS\n* **Mafia II**: 64 FPS\n* **Shadow of the Tomb Raider**: 125 FPS\n* **Red Dead Redemption 2**: 81 FPS\n\n&#x200B;\n\n**4K**:\n\n* **Assassins Creed Valhalla**: 93 FPS\n* **Cyberpunk 2077**: 22 FPS\n* **COD MW III**: 55 FPS\n* **Forza Horizon 5**: 74 FPS\n* **Hitman III**: 74 FPS\n* **Mafia II**: 61 FPS\n* **Shadow of the Tomb Raider**: 64 FPS\n* **Red Dead Redemption 2**: 50 FPS\n\nWhat is the price for this GPU? This 4060Ti comes in at $429.99 which is a $30 premium over the regular DUAL 4060 Ti 8GB OC model. But with that $30, you get an additional SSD slot for your system if it can utilize it. More on this in a little bit.\n\nSo what are my impressions of this GPU? Very positive. There isn’t much out there in terms of performance baselines regarding the 4060Ti much less the SSD version of the GPU, so I am hoping I answered questions regarding that. I know this card isn’t the first choice when it comes to buying a GPU for a gaming system, but I wouldn’t take it out of the running. In my testing, the GPU did very well in 1080P gaming and also in 1440P gaming with the vast majority of games hitting over that 60FPS mark. Now we know this card isn't designed for 4K gaming, but I wanted to see what it would do.\n\nWhen it came to building with this GPU, it was very easy. The GPU does come with an instruction card, screwdriver, thermal pad, and hardware to make the SSD install as painless as possible. Installing the SSD into the GPU is just as easy as installing it into a motherboard. Just make sure you have the included thermal pad installed on the GPU side, flip the face of the SSD so it's facing toward the GPU, slot it into the channel, push the SSD down into the thermal pad, and turn the Q-Latch to retain the SSD. Once that is done all you do is install the SSD cover. Installing the GPU into the case was really nice. With GPUs getting larger and larger in size, handling a 2 slot card again in a smaller chassis makes it nice. I did run into issues on the hardware side, but that is my fault.\n\nWhen selecting a motherboard for this GPU, make sure it supports PCIe Bifurcation. Currently when it comes to the Intel boards, only the Z series motherboards support this function. AMD motherboard however, both the B series and X series support it, just make sure you check the ASUS webpage regarding this GPU and make sure your motherboard is on the list. You also need to make sure you are up to date on your BIOS file. If using an Intel Z series motherboard, also verify your M.2\\_1 slot. In most boards when you have a SSD populated in that slot, the PCIe lane count drops to x8 for the GPU. Now normally that wouldn’t be a big issue for this GPU as it only runs in a x8 configuration, but when adding the M.2 to it, you will need those additional lanes. To test the thermals of the GPU with all options, I had to slot it into a motherboard that supported PCIe Bifurcation. Luckily for me it was inside the same case, just a different build.\n\nWhen it came to what I wanted to build around it, I wanted to go for a Small Form Factor build. Obviously I needed to make it entirely ASUS so that way it appeases my OCD in terms of components. I also didn't want to go extremely high end for the PC. I do wish I chose a motherboard that supported the function of this GPU, this way I could have all 3 SSDs installed in this PC at 1 time.\n\nIn conclusion, I feel this GPU adds something new to PC building. When you are looking at smaller motherboards or systems in the Mini ITX / Micro ATX form factor, they don’t include as many SSD slots like you would find on full size ATX and E-ATX motherboards. Even some full size ATX motherboards only come with 2 SSD slots, so adding one more to the system is awesome! I feel the ones buying this GPU are looking for something that can not only game at 1080P, but also add an additional storage slot to their limited motherboard setup. As DirectStorage will start becoming more and more of a thing, I am sure this GPU will benefit greatly from that as well.\n\nLet me know your thoughts about this GPU and the build!\n\nBuild Video: [https://youtu.be/iiocrWygM5Y](https://youtu.be/iiocrWygM5Y)\n\n&#x200B;\n\nhttps://preview.redd.it/etzemspebgfc1.jpg?width=6960&format=pjpg&auto=webp&s=886ee18ceea179e88d9fe481453ec1e8e3101f44\n\nhttps://preview.redd.it/prdkptpebgfc1.jpg?width=6960&format=pjpg&auto=webp&s=acf1272a2da7c095ff235ce66e4e266be220fcb7\n\nhttps://preview.redd.it/tc3tmupebgfc1.jpg?width=6960&format=pjpg&auto=webp&s=bafdbb2ca4226bcda865b9f3b1b6872e3923f63a\n\nhttps://preview.redd.it/6lqayopebgfc1.jpg?width=6960&format=pjpg&auto=webp&s=dabb9a432821d5d00ed2cb7f4c5673c416b7afb4\n\nhttps://preview.redd.it/4d0791qebgfc1.jpg?width=6960&format=pjpg&auto=webp&s=78b0a1f8ec544fad1a64f12df4d011989c955838\n\nhttps://preview.redd.it/6eyibypebgfc1.jpg?width=6960&format=pjpg&auto=webp&s=5a1bf8692ce76a3c35eabfc3453b1a7d95e149ea\n\nhttps://preview.redd.it/xejz0zpebgfc1.jpg?width=6960&format=pjpg&auto=webp&s=aa34384d752a20e7b10ab72e7df63afe14f36c05\n\nhttps://preview.redd.it/u0x6uypebgfc1.jpg?width=6960&format=pjpg&auto=webp&s=8571a2d2d85700c9367bc5cc3bdfe26acbbaad7c\n\nhttps://preview.redd.it/7prh9rpebgfc1.jpg?width=6960&format=pjpg&auto=webp&s=f95e22f1e685bae910e2808b3a4735ae01c58e75\n\nhttps://preview.redd.it/j788c0qebgfc1.jpg?width=6960&format=pjpg&auto=webp&s=012d8eb9fbe1f6567b153227937742b682743407\n\nhttps://preview.redd.it/n9k4jfgjbgfc1.jpg?width=6960&format=pjpg&auto=webp&s=25a6059dcb6c8a9bf10e1cebaeefd537059988c2\n\nhttps://preview.redd.it/uehi2jgjbgfc1.jpg?width=6960&format=pjpg&auto=webp&s=b65377d704ce60c3a08209dc124ffab1eff25133\n\nhttps://preview.redd.it/vm6czhgjbgfc1.jpg?width=6960&format=pjpg&auto=webp&s=bc1d26a62ec248129bfb3d57660579ed3970179a\n\nhttps://preview.redd.it/51gv7hgjbgfc1.jpg?width=6960&format=pjpg&auto=webp&s=d71a7e42677ebadfcc21fa18542bf6ad1d17eeac",
    "comments": [
      "That’s sick. I wonder if there’s a 16gb version too",
      "Great review thanks.  Wonder if it works on AR900i? Then you get five nvme SSD on an Itx platform",
      "Thanks! As far as I know just 8GB at this time"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "rtx 4060",
      "4060",
      "4060 8gb",
      "rtx 4060 8gb"
    ],
    "title": "Rtx 3060 12 gb vs Rtx 4060 8gb what should i buy",
    "selftext": "for gaming and video editing what is the best choice  \nthe price difference isn't that much its just 25 dollars so i can easily afford the 4060",
    "comments": [
      "I'd probably go 3060 in that case. The 12GB will server you much longer than the 8GB will.",
      "perhaps, but the 4060 is not a large improvement on the 3060, and the 12GB will be better for the Video Editing that OP mentioned.",
      "You are already being bottlenecked by the 8gb of vram, even on a 4060.",
      "That's tough. Video editing would likely benefit more from 3060. If you're mainly gaming, 4060 is slightly faster and compatible with new tech like frame generation.",
      "4060 no question, not sure why another commenter even suggested a 3060. you'll get around 20% improved performance over the 3060 for 25$ bucks.",
      "I’d rather go a 6700XT or 6750XT for gaming, but Im quite clueless on how good they are with video editing",
      "Nah. You can lean on DLSS hard. But 8gb will bottleneck a 4060 especially if you try to use frame gen.",
      "So here’s a point of comparison between 2 extremely demanding games. Alan Wake 2 runs way better in the 4060. 4060 also has frame gen for that game. Hellblade 2 had massive stutters when running above low textures, which still look fine obviously, but the 3060 didn’t due to the 12 gb vram. 4060 is going to perform better but there will be a few random games with vram issues that will give it a hard time. I got these 2 examples from digital foundry, but I personally own a 4060 and have not ran into any issues.",
      "You can never have enough VRAM so go for 12gb",
      "3060, I have a 4060 and the vram get sucked up like nothing",
      "Just check the VRAM usage and set textures detail levels accordingly and you'll be fine.\n\nRightfully people would expect to set everything to very high on a 60 series for 1080P and it play 60+ fps with good lows.. but this just isn't the case with 8GB cards. Manage that and it'll be a decent upgrade but 4070 and above is the ideal choice this gen.",
      "I had same question for 3 months. I did through research and found out 3060 is better for my needs as I do 3D rendering and benefit from extra Vram.\n\n4060 is 5-20% faster in different scenarios but I don't think its beneficial when you play graphic intensive game. I played Hogwats legacy and found it was using 9 GB in average on ultra setting without any frame drop which simply isn't possible with 4060.\n\nIf you only game then go for Amd. If productive work you do then 3060. If you want new tech then go for 4060.",
      "3060, you won't be able to use FG with 8GB memory anyways.",
      "I would go with the 3060 with 12gb.  That will make a bigger difference than the minimal performance gain between the 30 and 40 series processor.  I don't want to diss on anyone with a 4060 but it didn't get good reviews from trusted sites like gamers nexus.",
      "In this case the 4060 is a downgrade so buy 3060 12GB regardless.",
      "I see used ones go for $225-250ish",
      "3060",
      "Actually your question is pretty simple. If you dont have rtx 3060 buy rtx 4060 instead. Cuz its new tech. In the end you will have a brand new gpu. But if you have rtx 3060 then you keep it. That simple.",
      "https://gpu.userbenchmark.com/Compare/Nvidia-Titan-Xp-vs-Nvidia-RTX-4060/m265423vs4150\n\n\nCough cough.\n\n\n\n\nTitan xp for sale at 200 at mercari.com rn, IIRC.\n\n\nJus sayin",
      "Do you mainly game or do you do productive work"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "rtx 4060",
      "4060"
    ],
    "title": "Upgrade from GTX 1660 SUPER",
    "selftext": "I was thinking on upgrading my gtx 1660 super to Gigabyte GeForce RTX 4060 Eagle OC 8GB GDDR6\n\n  \nCPU: Ryzen 5 3600\n\nMotherboard: MSI b450 gaming plus max\n\n  \nShould I upgrade my CPU too?\n\n  \n",
    "comments": [
      "I don't think it's worth upgrading to a 4060. That card is way too limited.   \nYou should get a 3070 if you can and pair it with a 5800X3D as Saoirseisthebest said",
      "4070 super (performance now 🔥) or 7900 gre (performance later 😒)",
      "history forgetful combative materialistic detail desert plants hateful practice slimy\n\n *This post was mass deleted and anonymized with [Redact](https://redact.dev)*",
      "Either wait for a potential good valur 5060/5060ti, or go for at least 4070\n\n\n4060 and 4060ti are simply not worth it unless you're getting them at insanely low price",
      "Go 4070 during Amazon prime day sale",
      "Do it. The 4060 8GB gets a lot of hate, but it's not rational feedback. Not trying to be showy, but I have a 4090, which is some kind of strange aberration, and also the ASUS 4060 Dual OC. Sure it's like comparing a Bentley to a Camry, but Camrys are perfectly fine. You'll get 4K 60 in low to medium with DLSS performance regularly with the 4060, or 1440p high with DLSS balanced. It is NOT a 1080p card. None of the modern ones (most recent) are. Of course if you can afford a 4070, that's good. 4080 is a waste of money, go for 4090 if possible. Avoid the 10 series. DLSS is worth it big time.",
      "Also, keep in mind the 4060 shines when paired with a capable CPU (I have a 7700X) and sufficient RAM (64GB).",
      "Depending on your location for pricing and what games you play, a 4060 is a pretty nice upgrade over a 1660 Super; I did this last month. I only really play fighting games and it handles Tekken 8 way better than the Super did, especially with the ability to use dlss.\n\nI was able to get a 4060 new for just under $400CAD pre tax, which I'm happy with. For comparison, a 3070 here is $720 new, a 4060ti starts at $550, and a 4070 starts at $800. Could have gone used for cheaper I'm sure, but I like the experience of buying new. If all I'm going to be doing is playing fighting games and the occasional flavour of the month game, the 4060 is great at the price, but your mileage may vary.",
      "I think you should just wait for next month and spend more on a better gpu and put off the CPU for later. Had been on a 2600x for a while just fine with the exception of like Helldivers which was really bottlenecked by my CPU.",
      "Is that post taxes? $390 sounds too expensive for the 5800x3d.\n\nI would rather buy a 4070 Super and leave the cpu upgrade for later.",
      "Only for competitive gaming I'd consider upgrading the CPU right now. If not, I'd upgrade the GPU and let the CPU be.",
      "If you can grab the 5700X3D it much cheaper. Aliexpress has them so cheap",
      "upgrade ur cpu first. i had to keep my i5 10400f when i upgraded from a 1650 to a 4060 at it does struggle a little bit on 1080p",
      "Get 5700X3D and 6700XT / 3070\n\n4060 is at a bad price point",
      "My gpu sounds like it's going to die soon so probably will go with it.\n\nCould upgrade my CPU to 5800x3d next month i guess.\n\n  \nCan get both for 689$"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "rtx 4060",
      "4060",
      "4060 8gb",
      "rtx 4060 8gb"
    ],
    "title": "HP 3060ti vs Zotac 4060",
    "selftext": "Hi everyone,\n\nI have the option of getting one of the following GPUs for free from a friend of mine. \n\nOption 1: HP RTX 3060ti 8gb. It is has no beading on it at all and is from an HP Omen 30L from a few years ago. It has been used moderately in the time period. \n\nOption 2: Zotac RTX 4060 8gb. It has never been used and is brand new. \n\nMy CPU is a 13700F and I use a 1080p monitor to game. I mostly play WoW but occasionally will play shooters like Destiny 2. \n\nWhich is the better GPU for me to choose?\n\nThanks",
    "comments": [
      "3060ti is faster and can use amd fg now in conjunction with dlss upscaling. Its just better. I would say the only reason to pick 4060 here is the fact that its new with warranty. And thats very good reason",
      "Why go for old if you can get brand new + warranty + new tech such as dlss 3.5 and FG which more and more games will support",
      "Go for the 4060, newer technologies through DLSS 3 and better RT, has never been used by your friend, still has a good warranty on it.\n\nSure the 3060 ti beats the 4060 by 5 to 10 frames in raw rasterization, but this doesn't matter. One, this is mostly negligible (90 fps vs 100 fps) and second the 4060 is better with DLSS upscaling and frame generation.\n\nSummary: 4060 is better for longetivity (new, has warranty). 3060 ti is not (used for few years, little to no warranty). Performance difference in raw rasterization is minimal, but with the new DLSS the 4060 is better. Also the 4060 has a much smaller energy consumption and is much more efficient with a tdp of 115 watts, while the 3060 ti has a tdp of 200 watts.\n\n4060 easily",
      "Go for the 3060 ti, those gpus are close but the 3060 ti has the lead in raw rasterization.",
      "- Looking at Techpowerup's review of the RTX 4060(https://www.techpowerup.com/review/msi-geforce-rtx-4060-gaming-x/31.html), the average FPS:   \nAt 1080P:   \nThe RTX 4060 8GB averages 96 FPS   \nThe RTX 3060 Ti 8GB averages 106.4 FPS   \nThe RTX 3060 12GB averages 81.3 FPS   \nAt 1440P:   \nThe RTX 4060 8GB averages 69.6 FPS   \nThe RTX 3060 12 GB averages 60.4 FPS    \nThe RTX 3060 Ti 8GB averages 79.5 FPS   \n- I would get the 3060 Ti.",
      "He's getting them for free. Get the 3060ti as it has better raw performance and you won't be able to raytrace/dlss on a 4060 without poor results"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "rtx 4060",
      "4060",
      "4060 8gb",
      "rtx 4060 8gb"
    ],
    "title": "Upgrade advice ?",
    "selftext": "Hi everyone , currently i have an old midrange pc as i think with R5 5600 non x and gtx 1660 non super on aorus b450 elite \nI want to upgrade my graphic card without need to upgrade PSU so I'm between 2 choices \nRTX 4060 8GB \nRTX 3060 12GB \nBoth are Zotac \nCan someone tell me which one should i get ?",
    "comments": [
      "So what should i do stay with 1660 wtf , give md a recommendation at least",
      "It's a tough one for 1440p you really need 12gb of vram but the 40 series has frame gen and better features. I think I would go the 40 series and drop some settings down if I need to.",
      "That's why I say people with gpu swapping in future to not skimp below 600-650watts PSU's. It makes it very hard. Are you using productivity or non gaming applications? Because I would definetly check 6700xt or 6800 locally 2nd hand. their performance is 3070 equavalent without even needing dlss that's the best bang in the market right now even with the feature deficit you pointed.\n\n But secondarily. 2070 Super/2080 duo 2nd hand should be a substantial upgrade over your 1660 with the nvidia feature set (a bit old but has Dlss2.0) and will be enough for you Psu power budget. also you can get 3060-3060ti 2nd hand if its close to prices rtx 20 series are going for. You have to look for prices all the time to grab a deal.",
      "What resolution do you play on ?",
      "Hmm very hard choices indeed. 1440p upgrade is imminent you said so we should take cpu bottleneck away. But 4060 and 4060ti's 1440p performance is meh at best. forget 3060 its still selling at MSRP for old gen bad deal even with VRAM. Whats your PSU? If its 600+ we should be good for 4070 Super. spend or save money to last you even longer in the future rather than get a bad deal. If not I would go for rx6800 non xt (2nd hand Amazing deals) or 7700xt",
      "4070 super or amd 7900 gre.",
      "neither...",
      "1080p but planning to upgrade to 1440p soon",
      "Its 500 watt unfortunately if i go for other choices i need to save for psu and gpu as well as the monitor i dont think i can afford that\nI'm not a fan of amd gpu tbh and i like the features with nvidia software \nThank you for sharing your thoughtful with me tho much appreciated",
      "even if i'm able to save more to get them i will need to save even more to change the psu i don't think i will be able to",
      "either look at 4070+ or wait to see what 5000 series bring\n\n3060 is OLD now... and 4060 are bad deals",
      "Thanks for sharing your opinion with me i think i will do what you said prob"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "rtx 4060",
      "4060",
      "4060 8gb",
      "rtx 4060 8gb"
    ],
    "title": "Rtx 3060 12gb or Rtx 4060 8gb?",
    "selftext": ".",
    "comments": [
      "I had the same question a year or 2 ago when I built my pc I went with the 3060 for the vram and dlss my uncle went with a rx 6700 xt has better raw performance but no dlss (I almost always use it) 1080p my 3060 runs everything 90+ fps",
      "8gb vram is enough for 1080p casual gaming, +25% performance is very noticeable at this gpu tier, newer technology is better supported on newer hardware i.e dlss4",
      "Maybe wait for a 5060 or 5060ti if you can get it at msrp if this is a new build or go amd",
      "25% is definitely not minimal. I'd rather have 60fps than 45fps.",
      "Strictly between the two? 4060, unless 3060 is a lot cheaper.",
      "I went 4060 & learned that it also will use your system ram if you exceed the 8gb limit on the ddr6 4060 card so anytime it needs more than 8gb it will use a portion of my 32gb ddr5 system memory & there for the 4060 is not limited to only 8gb of GPU ram like most everyone quickly dismissed the 4060 but I run everything at max and haven't had a problem plus it over clocks to 2710 stable. 4060>3060 ti",
      "(Short Version)\n4060 8GB all day everyday\n\n(Long Version)\nI have owned both of these cards because I had the same question.. I bought the 3060 12GB and I wasn’t really impressed in the performance over a 2060 super it seemed about the same..\nI was looking for a 4060ti 16GB which I finally own now but I couldn’t find one at the time so I got a 4060.\nI really had low expectations from reviews and comments but I have been extremely impressed by this thing.. \n\nthe problem with the 3060 is by the time u turn the settings down enough for the game to run properly then you won’t be using the 12GB.. That leads me to believe it was made more for AI or neural networks than it was for gaming.. \n\nThe 4060 on the other hand is on par with a 1080ti or a 2070 super a lot a lot less power draw and with a lot of additional features.. It’s a very easy choice because on the new or the used market their prices are about $20 - $30 apart.. Also nvidia will support the 40 series for longer period with driver updates than the 3060 because it’s newer.. \n\nIn summary, from personal experience, it’s a very easy choice to make the 4060 wins on every aspect except maybe with neural rendering which I have no knowledge or experience in.. There may be limited times the 3060 wins due to the extra vram but those limited instances don’t make up for the overwhelmingly majority of the time the 4060 will do amazingly better.. new market they are both around $300, used market around $200-$250 where I live anyways.. I highly recommended the very slept on 4060",
      "yeah trade of between more power gpu vs more vram. Depends on the price i would guess\n\nsince the new DLSS model decreases FPS it would be iunteresting to see how much the difference is on 4000 and 3000 series cards is.",
      "Depends on the game, but most heavy AAA titles wont be able to run above 60fps on 1440p. I suggest you check 3060vs4060 game benchmarks on youtube to have a better idea.",
      "No problem bro.. whatever u decide on check back in later and let us know how it works out..",
      "You'll have to turn down texture settings to medium or low so the card won't choke. \nIt all depends if that's enough of a problem to you or not.",
      "What about 1440 can 4060 run it?",
      "Thanks man you summarize many things at me",
      "Are 8 bad or just not enough on future?",
      "Amd is good but I probably take nvidia",
      "I'd rather have 45fps than the 0fps or ctd you'd get when you run out of vram.",
      "4060 win btw but that not big different about 2-9 fps in game on 1440p",
      "Youre dumb dont talk to me please.",
      "HHAHAHAHA",
      "Save yourself future headaches and get the 12gb gpu. Perfomance difference is minimal."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "rtx 4060",
      "4060",
      "4060ti"
    ],
    "title": "Looking to upgrade GPU, I think I have an ok understanding of GPU shopping but I've seen a lot of good help from this community, figured I would ask just in case.",
    "selftext": "Looking to upgrade GPU since mine seems to be struggling with frames in some newer games and even modded skyrim.\n\nHi guys! Here are my current specs:\n\nGigabyte X470 Aorus Ultra Gaming mobo\n\nAMD Ryzen 9 5900xt 16-core\n\n4x  G Skill Trident Z DDR4 8gb 3200mt/s (w/ XMP)\n\nNvidia RTX 2060 super Gigabyte Gaming OC White 8G\n\nI do have 2 nvme WD black ssds that I run most of my recent games on, and 2 seagate HHDs I run older games on. I only play 1080p with 2 144hz monitors, and I dont think I'll be pushing into 1440p or 4k until years from now when I can afford a new build in general. I was looking to upgrade to a 4070 super, but I think I was getting a little ahead of myself since I think think I'd need 12g of Vram for 1080p gaming. So was interested in what anyone on here had suggested. I am open to Intel Arc cards, I was looking at the Arc B570 recently and 4060ti 8g. But if anyone has any personal experience with AMD, or how confusing looking at the RTX 4060 cards, I would appreciate the input. Thanks you guys!",
    "comments": [
      "I've just grabbed a 4070Ti Super as an upgrade from a 3070 and what a card it is. It's taking a maxed out Cyberpunk at 1440p at high frame rates. I'd imagine a 2060 -> 4070Super path at 1080p would tide you over for a LONG time!\n\nMy only experience with AMD was the 5700XT and it was the biggest mistake - constant driver crashes, and then when you went to forums, the community would blame you and not the drivers themselves. It was all instantly fixed with the 3070 so I'd personally avoid AMD for GPUs. Their CPU division is the bees knees tbf",
      "For 1080 4070s is about as high as I would go. Its kind of an overkill, but that just means its future proof. 4070s is one of the best value cards of 40x generation and I don't think you'll regret the purchase. I don't think 12gb of vram are going to go unspent in modern AAA games either.\nBase 4070 will serve you about as well, while working colder and drawing less power.\n\n\n4060 ti cards are a very easy skip if gaming is your priority. The 16gb version is okay for AI and 3D software.\n\n\n4060 was not that bad when it came out but it's aging rapidly. Some modern games already outpace it at 1080p ultra or high (ff16, Alan Wake). Not the worst pick if budget constrained I guess, but it might be worth it to wait for 50XX cards. The additional uplift of 20% or whatever it ends up being might be the difference between playing new games and not, once new console generation comes out.",
      "Ya I tried AMD way back with the 580 and 590, and they were awful for me. Sounds like Ill just have to watch prices for the 4070 type cards and hope they die down sometime. Thank you",
      "4000 series Supers cost more than the 5000 series, and doubtful that price will ever drop since there is no more production",
      "I might just keep an eye in the base 4070 sounds like or hope for the best with the 5070 if I can actually get my hands on one. I havent seen any performance videos yet on yt, they they look positive I may just try to get it. Thank you",
      "Ya I noticed. Seems they were really popular. I recall trying a 3080 in my pc at somepoint and it seemed to perform worse than my 2060s with the games I played. Thank you."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "4060",
      "4060 ti"
    ],
    "title": "Hear me out. I might need to upgrade to a 4060 Ti",
    "selftext": "I have a RTX 3050 and it’s struggling to drive CyberPunk at 1440p. I’m willing to upgrade at this point but I’m limited to something that will fit in my case, small form factor 222mm max length. Anything more than 8GB VRAM I’m basically limited to RTX 3060 which is pretty good value but not enough of an upgrade from a 3050 then there’s couple models of 4060 Ti with 16GB that will fit. At $500 launch would be a hard no. At $450 that they are now it’s not great but I was really disappointed by the 7700 XT pricing. Should’ve been $399. And AMD’s cards besides their x600 series do not support SFF. Before you ask, no I’m not willing to change my case, it’s whole reason I built this PC. Besides the bad wrap the 4060 Ti gets there are real reasons one might choose this card. It’s not like putting it in my computer will cause it to blow up right?",
    "comments": [
      "You said “small form factor”, I assume you have a large case but a small form factor motherboard, or is the motherboard small form factor but the case is big enough to accommodate a larger card?",
      "4060 isn't a great 1440p card, but it's better than your 3050 by a good bit, I'd definitely get the Ti if you can.  4060Ti is similar to a 3070, a little better in features and a lot better in heat/power for a SFF.\n\n8 vs 16 gb isn't a big deal since the gpu isn't incredibly powerful you'll probably be lowering textures anyway before you run out of vram.",
      "r/sffpc",
      "I think the only low profile 40XX series gpu is the 4060 (unsure if it also applies to the 4060 Ti).\n\nor if your feeling daring and your psu has enough juice and the PCIe power cables, you could get a PCIe riser, remove the side of the case, and have a large gpu in the riser on top of the case, It’ll be risky (might knock the gpu off of the case, it won’t be protected as well as if it were inside the case, etc) but it is possible",
      "Honestly I don't get your gripe about the price of the 7700XT given the scenario you've painted. Just eyeballing 4060ti pricing on pcpartpicker I can see that the cheapest 8GB model that would fit in your case is $399.99, and the cheapest 16GB model that will fit is presently about $722. The 7700XT costs $450, and should have launched at $400, I agree... But the 4060ti should have been the 4060, should have come with at least 12GB memory, and should have been $300-$350..\n\n&#x200B;\n\nThe 7700XT costs $50 more than it should have, and we agree on that -but the 4060ti is similarly if not more overpriced for the performance tier it's at. At least the 7700XT has 12GB without charging you an extra $100 for more than 8GB memory.. A more reasonable argument would be that you can't find one that's small enough to fit in your case lmao (I looked and didn't find any small enough).\n\n&#x200B;\n\nAll that aside, the 4060ti is a fine card -it's just a shit price. It's got great power-efficiency and is a good option for a SFF build -it just costs a stupid amount of money for only having 8GB memory on the base model and offering no performance improvement at the price-tier it's in vs last-year's cards. The 16GB model being $100 more baseline is just absurd.\n\n&#x200B;\n\nAMD seem allergic to making shorter cards so they've removed themselves from the equation and the 4060ti looks like the highest-performing card you can get to fit. I personally find PC aesthetics to be completely meaningless and would have absolutely zero issue slapping my build into a $60 case that would fit a GPU that's significantly more powerful than a 4060ti for about the same price (6800xt's been dropping to $429 all week). But if you must keep your case your best option is the 4060ti -it makes me uncomfortable saying that, but it's the truth lol.",
      "I think they are looking for a 2 or single fan card.",
      "I'm in the same boat but im limited to 195mm. Best gpu ive found is the Palit 4060ti single fan.",
      "Low profile not a concern. My current card is 2.5 slot",
      "If it being low profile isn’t a concern, I’d look for a better gpu, the 4060 (from what I see) is only good if you need a low profile card and/or only have a x8 PCIe slot available. You might want to get a low/mid tier RTX 30XX series gpu as it has similar performance to the 4060 Ti",
      "I think thickness isn't a concern OPs issue is length of the card",
      "I would just save a little more for a 4070. Lots of people have said it’s a beast at 1440 and 12gb is plenty in most use cases."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "rtx 4060",
      "4060",
      "rtx 4060 ti",
      "4060 ti"
    ],
    "title": "RTX 3070 8GB (440€) or RTX 4060 Ti 16GB (495€)?",
    "selftext": "Both are around the same price, but I've heard a lot of people not recommend the 40 series cause of its price and lack of 16 GB. Now this one's price is fine and it has 16 GB, is it still not worth it? (Upgrading from a GTX 1080 btw, my processor is an i7 8700k)",
    "comments": [
      "Frame generation is a game changer. 4060ti for sure",
      "No such thing, it's confusion of how Nvidia name things (calling FG DLSS 3.0) probably just meant the FG part.",
      "Depends on what resolution. 1080p I go 4060 ti. 1440p, I go 3070.",
      "why tho? Isn't 16 Gb vram helpful for upper resolution?\n(I'm sorry i really don't know)",
      "Yes, it is. My guess of the rationale is that the lower memory bandwidth of the RTX 4060Ti does hurt it at higher resolutions.",
      "Wdym better dlss?",
      "That was not my question",
      "I would choose 4000 series. Because it will support FG and better DLSS",
      "Are you interested in playing CP 2077 Phantom Liberty, Alan Wake 2, Portal RTX or the upcoming Half Life 2 RTX? Are you interested in older games that will eventually be remade in RTX Remix? If the answer to any of these questions is yes, then go 4060Ti. If you’re more interested in games like Destiny 2, Apex Legends, Fortnite, Warzone etc. then I’d say save the money and go 3070.",
      "I would go for a 4070 personally if you can stretch your budget a bit more.",
      "Unfortunately all the rx 7800 xts I can find are triple fanned, my pc case can only fit two",
      "go with 4060 ti ofc. 16gb vram vs 8gb men :D",
      "I got the 4060Ti 16GB myself and im super happy with it, especially in 1080p. If you want to play in higher resolutions you should buy a 4070 at least. The 16GB Vram of the 4060ti are really helpful, for example Diablo 4 in 1080p, DLAA, Framegen and Textures in Ultra takes up around 14GB of Vram.",
      "While it is easy to recommend the 4060ti I wanted to say *don't rule out the 3070 just because it's old*...\n\n- a difference of 55€ on the 4060ti is 12,5% more money... it's not a small margin.\n\n- on benchmark sites the 3070 is actually rated better for raw power than the 4060ti (of course the new nvidia techs will reduce the advantage)\n\n- at 1080p 8gb of vram is just enough and even if you need a bit more there is a way to use more vram then available (I can't remember the name but you are basically using ram as vram)\n\n- in games without dlss support the 3070 is actually *much better* than the 4060ti... are you going to play such games?",
      "Why is this?",
      "Perfect answer",
      "Yeah  I'm more interested in phantom liberty n all, thanks!",
      "rx 7800 xt",
      "go 4070 and you might not need to look back for another extra year.",
      "Lol I absolutely love my 4070 ti OC"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "rtx 4060",
      "4060",
      "4060 8gb",
      "rtx 4060 8gb"
    ],
    "title": "RTX 3060 12GB or RTX 4060 8GB?",
    "selftext": "Hey Community,\n\nim wondering which one I should get? Both would run fine with my system. The RTX 4060 with 8GB Ram or the 3060 with 12GB Ram. It's mainly for gaming. :)\n\nBest Regards!",
    "comments": [
      "What’s the prices? Have you looked into AMD or are you only going for Nvidia? I would say 12GB is the minimum in 2025",
      "The 12 GB. one",
      "Im hesitant with AMD, never had anything from AMD always Intel / Nvidia. I don't know any cards, or compatibility etc. Both cards are roughly the same price 4060 and 3060. 4060 is like 10 eur more.",
      "Alright, well it also depends on the games you wanna play. 8GB is really hard to recommend for big titles in 2025. It’s fine for esports at 1080p. I would at least get 12GB. I’d recommend to look into RX 7700 XT if you are willing to try AMD with the best performance per euro. 4060 with DLSS will give you nice gameplay in lighter titles. Recommend you to watch some videos on the games you plan to play with both cards\n\nHope you’ll enjoy whatever you get 😄",
      "8gb is fine if op plans to play games at steamdeck resolutions",
      "Thanks a lot Torey! I might look into AMD! :D",
      "How much are the 4060 ti 16GB's in your area?",
      "7800xt :) plays everything I've played on 2k very well. Super easy drivers. No issues. Better bang for your buck than Nvidia unless you need ray tracing",
      "What resolution do you play games at?\n\nWithout more information, between those two I'd personally take the 3060 with 12GB.  It's slower, but it's hard if not impossible to work around insufficient VRAM.",
      "Ive had a 2080, 3060 ti, 3060 mobile, 6800xt, 7900xt, and I currently have a 7900xtx. I've had no issues with *any* of these cards and they've all been great.",
      "U make no sense. U r tryna tell someone who uses an 8gb card that it's not enough when I physically use one. The only game that seems to struggle is cyberpunk in dog town I have to turn some things down. But that's more due to my CPU still good but starting to show it's age. Remember u don't need everything maxed out all the time. Rarely do I not have things maxed with a 3070. Stop just preaching what u hear from others. Rarely do I go below 60 fps in graphically demanding games at 1440p",
      "12 GB isn't the minimum for 2025 8 GB is still fine. As someone who uses a 3070 it's enough, tho it's starting to not be for maxing out games on 1440p. But u don't always need to max them out really. Vram isn't the only thing that matters in a GPU"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "rtx 4060",
      "4060",
      "4060ti",
      "4060 ti"
    ],
    "title": "RTX 4060 vs 4060 ti 8gb vs 4070 for 1080p 75fps",
    "selftext": "Hello, as in the title. Recently I've purchased rtx 4060 and I like it but... I'm just worried about it being future proof in my, I'd say pretty specific case.. In my country I paid 339EUR for 4060 OC, 4060 TI OC 8GB is 456 eur and 4070 is 630 eur. And I can't make up my mind when it comes to this choice. (3 fans versions as I'm very irritated by sound of those with 2 fans, heard how it sounds like at friends setups)\n\nMy CPU is 5800x3d ryzen.\n\nI play only 1080 p and 75hz without any plan of ever upgrading, it's enough for me that's why I think 16gb 4060 might be an overkill and a memory which I won't use.\n\nI want to return my 4060 just to exchange it to 4060 TI because main game that i play - final fantasy xiv, is having a graphical update in the summer, and I'm afraid I won't be able to get 75fps+ all the time - and I mean all the time (I have autism and if I get under 75fps and some choppy stuff I just refuse to play and I don't ugprade my pc to play on medium settings).\n\nCurrently before update (people assume we have to divide fps by 1.5) and now with max settings i get in a place full of people 91 fps, assuming those calculation peoples have are true I would fall under 75fps in that situation. Currently game chops up 2.4gb vram - so i doubt they will ever go to like 8 to be a danger even in 10 years that's why I don't consider 16gb version - I would take 4070 just to be at peace and to have more futureproof outlook but... that seems like an overkill for 1080p 75fps for almost any game + my psu is 550 w and reocmmended for this gpu is 650, i don't want to risk it.\n\n4070 is already on the border of what I can pay so upgrading PSU is out of the question, I just upgraded CPu and rams and I think my CPU might bottleneck 4070 either way, so it seems like 4060ti is the best GPU i can get for my set and PSU - what do you think?\n\nSorry for asking such, probably stupid question and being so picky but can't change my mind. T-T",
    "comments": [
      "Can't you just lower some settings to keep getting stable 75 fps in the future?\n\nPaying extra for 4060 Ti is not wise - this card is overpriced.",
      "Your CPU only draws \\~110w at max, a 4070super is like 225w. Toss in 50w for everything else and that's like 385w. Your 550w should be fine. As long as it's decent quality.\n\nHonestly if you're just gaming you're probably going to be running closer to 275w, anyway.",
      "4070 (super). Best value",
      "These cards are basically overkill for 1080p",
      "Yeah like I'm going to play strategy games, dwarf fortress and mmos on console.",
      "Yeah 350w GPU which spikes to 400+w on a 550w PSU. great logic!",
      "Why are we laughing at that? A lot of people can't afford better, and a lot of people are perfectly fine with 1080p ~75 fps. \n\n\n\n\nPersonally I'd take 1080p 75 fps PC gaming over console gaming any day of the week, simply because PC is a far superior platform as a whole.",
      "I was in a similar situation and went with the 4070 instead of the 4070s, as it's expensive where I live, around $200, and that's a lot in my currency. The 4070 was a huge upgrade over the Rx570 and never goes above 180W. I do use it for 3D rendering as well, and there isn't much difference between super and non-super; it's around 10-12 seconds faster, which doesn't justify the extra $200.",
      "Why not wait till the update releases and check for yourself? Prices may even come down and perhaps you won't even need an upgrade at all. Just wait and see.\n\nBy the way in all MMOs I played a place full of people will impact your CPU more than your GPU: You may be CPU limited at 91 FPS, check again with shadowplay advanced performance overlay (or rivatuner or whatever tool you like) If GPU isn't at 90~100% usage then you are not GPU bound and that \"divide by 1.5\" rule won't affect you in this scenario.",
      "Get the best GPU and CPU your wallet can afford...",
      "Just get a 7800xt instead.",
      "4060 ti is not future proof with 8gb vram on 128 bit bus! 4070/4070 super is the real upgrade from 4060.",
      "I mean you can buy an older card but a more powerful even radeon card if you don't care about rt.",
      "If you can replace it still you should replace for 4070 imo but that means you gonna need new PSU some reliable brand 750w or 850w to be safe next 10y.\n\nOfc you can go for 4060Ti but not worth maybe. You must pay difference and you gonna be more worried if your old PSU can hold.\n\nThe difference between 4060 and 4060Ti is not big enough to justify. Same if u are with 4060Ti and you want 4070, maybe to 4070S can be more justified but idk depends what games u playing.",
      "shouldnt have a 550w psu to begin with if he wants to build a good pc judging by that 5800x3d. buy a 750 and be future proof for many years. this trash psu is the source of his problem",
      "Flipped around you mean? His 4070s won't really be able to stretch its legs at 1080p. At 4k he'd be hitting a gpu bottleneck.",
      "Do you have some examples? Best one I've found iss Alan Wake 2, but I haven't been able to really find any CPU tests on it (everyone is focused on GPUs).",
      "https://youtu.be/OKRMqGXXjOg?si=-zIQm62RowJJnjTo\n\nAll games tested are current gen titles other than RE4/CoD which are crossgen. Maybe arguably Cyberpunk, but I'd argue other than asset quality it's basically morphed into a completely different game visually than when it launched as a crossgen title. \n\nGives a much better look into the card as someone buying a GPU to play games released recently.\n\nSpoiler: to what should be no shock given the titles benched, the only game in Owen's released recently testing where a 4070 is CPU bound at 1080p is Baldur's Gate 3.\n\nNow, what are people buying a 4070 more likely to be playing now and in a years time: Shadow of the Tomb Raider, or StarField? Hitman 3, or STALKER 2 (runs on UE5)? \n\nI mean, I get the old games have their place on a benchmark, but if Im buying a GPU with that amount of horsepower, I'm going to be playing the recent games. Who cares that shadow of the tomb raider is running at 170 fps on a 4070; I'm not buying a new GPU to play shadow of the tomb raider...",
      "just purchase whatever best card you can get in your budget for gpu...in this case if u can afford 4070/super in ur budget go for it",
      "My honest suggestion would be to just upgrade your monitor....\n\nIf you insist on 1080p 75hz then 4070 is the best value you are going to get."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "rtx 4060",
      "4060",
      "rtx 4060 ti",
      "4060 ti"
    ],
    "title": "RTX 4060 Ti 8GB GDDR6 White OC Edition? for multitask",
    "selftext": "# ASUS Dual GeForce RTX 4060 Ti 8GB GDDR6 White OC Edition\n\ni want in the future use my other 3 (one of them are CRT monitor that i found in the garbage and its work great)\n\nhere are the parts i gonna buy\n\nCPU: AMD Ryzen 5 9600X 3.9GHz AM5 - Box (i dont hate intel, but AMD got better)\n\nMotherBoard: ASUS ProArt B650-CREATOR AM5 AMD B650 DDR5\n\nRAM: Corsair Vengeance 2x32GB DDR5 5600MHz CL40\n\nGPU: ASUS Dual GeForce RTX 4060 Ti 8GB GDDR6 White OC Edition\n\nSSD: Kingston NV3 PCIe 4.0 x4 NVMe M.2 2280 1TB SSD\n\nPSU: Asus ROG STRIX ATX 750W Gold Aura Edition\n\nCase: Corsair 4000D AIRFLOW Tempered Glass Mid Tower\n\n  \nEDIT:\n\ni ask this for youtube tasks\n\nMonitor list\n\n1: 1080p (LENOVO) \n\n2: 1366x786 (UNKNOWN) (Adapter Required \\[DP TO VGA\\])\n\n3: 1080P (MAG) (Adapter Required \\[DP TO VGA\\])\n\nCrt: unknown (LG) (2006) (Adapter Required \\[DP TO VGA\\])  \n",
    "comments": [
      "i am also make youtube videos",
      "a… CRT monitor?",
      "yeah a crt monitor (i think its cool)",
      "For those who want the least amount of display lag",
      "Probably the 4060ti with 16GB will be better",
      "We still don't know what are u going to use it for, but 3 480p monitors are good, or 3 1080p monitors, just remember that for modern games just play on 1 monitor"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "4060",
      "4060 8gb"
    ],
    "title": "Bang for buck rtx card for archviz rendering ",
    "selftext": "I’m not interested in gaming performance.  I play games, but it’s not a factor in this purchase.\n\nI’m learning Twinmotion (related to Unreal Engine) and need an RTX card for path tracing renders.\n\nI’ve spent a while researching, and it seems that VRAM is king for this task.  A 4060 8gb will render simple scenes faster than a 3060 with 12gb.  However as soon as the scene exceeds 8gb of vram, the 4060 is just going to hit a wall while the 3060 chugs on and remains useable.\n\nAm I correct?  My budget is limited.  I can afford the $300 CAD required for a used 3060 in my market.  I could maybe stretch to around $400 for a 3070 or 4060 but everything is a step backwards in vram unless I double my budget.",
    "comments": [
      "Used 2080Ti",
      "Good shout didn’t know about that one ty"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "rtx 4060",
      "4060"
    ],
    "title": "500w psu enough for RTX 4060?",
    "selftext": "I’m thinking of upgrading my gpu from gtx 1660 super to rtx 4060 which has a similar TDP. I don’t encounter any problems running with my gtx 1660 super for 2 years. \n\nMy current specs:\ni3 10100f\n8gb x2 ram\nCooler master elite 500w \n2 SSD\n1 HDD\n\nI’m gonna use it mainly for 3D modeling and rendering (sketchup, lumion, enscape) and some fps games. I’m working on my budget, and i’ve been craving for a new nvidia gpu that fits my rig.",
    "comments": [
      "Yes, that's plenty enough for 4060",
      "Thanks! Hoping that the rtx 4060 will become cheaper in a few months",
      "For your system with a new rtx 4060 graphics card, even a power supply with an honest 300 watts will be enough."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "rtx 4060",
      "4060",
      "4060 8gb",
      "rtx 4060 8gb"
    ],
    "title": "RTX 4060 or 4070 for CAD work",
    "selftext": "im planning to buy the asus zephyrus g16 for autocad, revit, matlab, solidworks.... and there are two models available one with Nvidia GeForce RTX 4070 8GB and the other with Nvidia GeForce RTX 4060 8GB. i honestly have absolutely zero idea what that means but there is a 300$ difference between each. which one should i get if im not really into laptops but i want my apps to run smoothly without lagging? the salesman said that the rtx 4070 is 25 % faster but idk if its true  ",
    "comments": [
      "Go for the 4060 if you aren't doing any gaming. \n\nThey both have the same memory setup and you will only really notice the 4070 extra grunt if you are gaming or doing things that use the extra hardware. Save the $300.",
      "Mobile 4070 is roughly 10% faster than a mobile 4060. Don’t believe the salesman and look for benchmarks yourself. It’s upto you to decide whether 300$ is worth the performance difference now ."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "rtx 4060",
      "4060"
    ],
    "title": "Is the RTX 4060 a good card?",
    "selftext": "So I have a GTX 1650 super (4gb) and ive had it since 2021 when i got my pc and i want to upgrade it, i saw the 4060 has a good price and also that it has 8gb so it should be a good upgrade right? i dont know much about graphics cards so i dont know if its a good card\n\nmy pc specs (if it matters)  \nwindows 11  \nintel core i5 10400F 2.9 ghz  \n16gb of ram  \n2560x1440",
    "comments": [
      "Any 8gb vram GPU for over $300 is a bad GPU\n\n12gb vram GPU's is what id look at MINIMUM for your 1440p monitor. \n\n6700xt / 6750xt / 7600XT / 7700XT / 4070. -Would be my first choices\n\n4060 is a 1080p card, and only an \"ok\" one. Low performance high cost.",
      "I have a 4060ti been running it for a few months now. I haven't ran into any issues with it. Runs every game I play nice and smooth. And usually at about 120fps. I have it paired with a 12700kf i7 and 32gb of ram. The card stays nice and cool even under full load. Never gets above 65c. I play black ops 6 and no mans sky and death stranding on it with all the graphics set to max.",
      "the 4060 is a great card for what it is.  Realistically, $250 would be a better new price for it but Nvidia always commands a premium.",
      "Maybe wait for the 5060?",
      "if upgrading from 1650s, you will definitely get very noticeable performance difference. and it is not overpriced. as long as you play on 1080p and even some latest games at 1440p medium graphics, it is a very good card",
      "Suggest u to buy a used card, heres a quick perfomance overview:\n- RTX 4060 (66%)\n- RTX 2080 Ti (85%)\n- RX 6800 (96%)\n- RX 7700 XT (100%)\n- RTX 3080 (111%)\n\nThe price range is 250-350€ while almost getting x2 perfomance.\n4060 starts at 290€ new in my location.\nI guess the 6800 is your best bet.\nWouldnt suggest you to get a 8GB card for 1440p but its up to what you play.",
      "im planning to get it in the summer so since it will be out by then ill look at it as well thanks",
      "I personally think its a good buy and a substantial upgrade from your current build. Something more powerful would run into bottlenecks on your CPU.  Get the 4060 and you wont regret it.",
      "Bought  4 of them over the yearsfor different builds. The extra ram really helps, and I'm a 1080p gamer, so It works very well.",
      "Would not recommend it, 4060 is kinda weak to be honest, especially for 1440p now, when people are starting to have doubts about 12gb vram being enough. Do yourself a favor and get 5070ti.",
      "Id wait for a rx 9060 or rx 9060 xt, 4060 isnt a good value gpu",
      "okay so im seeing lots of mixed replies and i know graphics cards are expensive but honestly i dont have that much money to spend on a card so if there are any arround that price range that are better let me know please",
      "Upgrading from what you have yes. The 4060 will give you a lot more performance than your old 1650.\n\n\nIs the 4060 good value compared to other cards currently available?... Not really. It's a bit expensive for the level of performance in today's games.",
      "It's an okay card, the problem is that it's priced wayyy too high for what it is, and it also has 8GB of vram which is starting to be an issue today and will only become more of an issue as time goes on.",
      "It's an okay card, the problem is that it's priced wayyy too high for what it is, and it also has 8GB of vram which is starting to be an issue today and will only become more of an issue as time goes on.",
      "Yes a 4060 is good enough for decent settings (not MAXIMUM + PT) in any game with DLSS Performance.",
      "At 1080p. Don't forget to mention that. It's not running those games at 120fps max settings at 1440 like OP is looking at.",
      "Just dont pay $1000 for it.",
      "It probably could to be honest. It's got a good bit of head room. I run ray tracing on a bunch of stuff too.",
      "It runs no mans sky in vr at max settings."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "rtx 4060",
      "4060"
    ],
    "title": "Upgrading from GTX 1650 Super - best choice on a budget?",
    "selftext": "Hey there everone!\n\nSo I've had a prebuilt PC from HP for a while (mid-budgety) which has done the job for me since I don't play a lot on PC these days (mostly on PS5) but once in a while on occasion I hop into a game here and there on PC, could be Battlefield 1, Delta Force, GTA V or something similar. Recently I've been considering upgrading my GPU since that's my current bottleneck and even though I don't play too much at the moment, an upgrade would definetly be both needed and something to make it more possible exploring games I've avoided previously due to my limited PC. \n\nSo to my question where I would like some assistance, what would be a good card to aim for in terms of upgrading? I'll list my current specs below and I don't want to spend that much since PC is currently not my main source of entertainment (but you never know). What route should I take here and what card would give me the best bang for buck? Would prefer as cheap as possible but under 300$ (Sweden).\n\nAny thoughts or perspectives are appreciated! I won't be playing for example Alan Wayke 2 on highest settings with Ray Tracing but still want to be able to have good quality in the games I play with solid FPS in1080p, but also 1440p here and there (not the most demanding ones). \n\nBeen looking at RTX 3050 DUAL OC 6GB , RTX 3060 Ventus OC DUAL 12GB, RTX 4060 V2 OC 8GB.\n\nSpecs:\n\nProcessor: AMD Ryzen 5 5600G 3,9GHz\n\n16GB RAM GDDR6\n\nGPU: Nvidia Geforce GTX 1650 Super 4GB\n\nCurrently have a motherboard from the prebuilt: 8906 Erica 6 SMVB HP.\n\nI know I'll need to upgrade PSU as well, so I'm counting on a PSU of around 650W.\n\nThanks! :)",
    "comments": [
      "Definetely not 3050 or 3060 at this point. RTX 4060 will be good choice but I'd upgrade or trade 5600G with 5600 too.\n\nRyzen 5600 has twice L3 Cache, PCIe 4.0 support, much better single/multi core performance compared to G. Also you probably won't need upgrade PSU. I mean 5600 & RTX 4060 combination can work easily with 400W PSU too. 1650 Super and RTX 4060 has similar watt usage.",
      "I upgraded my gaming laptop with 1650 mobile to a desktop with 4070 ti super. Crazy performance! A completely different world!",
      "Thanks, much appreciated! \n\nDon't think I'll be able to upgrade the cpu just yet but will aim for that next! Should still be a sizeable upgrade with the GPU? :)",
      "Your total power consumption won't be more than 200W, like same as your current components that's why HP used small PSU. Can you use 5600 & 4060 with it? Yup. But will it be better if you upgrade some time later if new PSU going to hurt your budget now.",
      "It'll be night and day",
      "Awesome, then I'll start with the GPU! Appreciate it truly! Any other tips that might be useful?",
      "Well if we speak about RTX 4060 and its counterpart RX 7600 I pick 4060 without thinking twice. DLSS, NVIDIA Frame Gen and that cards efficiency much better than what 7600 offer.\n\nIf you want give a shot to Radeon consider RX 6600 XT, 6650 XT even maybe 6700 XT from **second hand market**. You can find qutie cheap prices. But it's must to upgrade your PSU if  you consider one of these Radeons. You don't need rush PSU upgrade with RTX 4060, it consumes only 90-110W in games.",
      "Sometimes overlooked but choose a psu with cybernetics certification, any brand can slap a 80+ something sricler and thest may vary from manufacturer to any lab, so it's better to have a 3rd party with ppl who have worked for a long time on power supplies to test them.\n\nSince you may have an oem device it may be hard to replace the psu, but it's nice to know.\n\nRecently a youtuber I follow releaced a hell of a video, 6 hours long, explainign every little detail of pc building. It's in spanish but with auto translated subtitles from yputube you'd be able to understand most of it, take a look https://youtu.be/rBMR59Un3EA?si=KF6Wyl3nihsU8W1Z",
      "Great one, will check it out! You explain it well of you ask me, but just for my own clarity, what's the oem device you mentioned that I may have? Something about my PC being prebuilt perhaps? \n\nLooking to find a good deal but might as well at least look for a cpu as well during black week",
      "Rtx 4060 for sure or a used rtx 2080(s) or used rtx 3070",
      "It doesn't matter, your cpu will bottleneck any gpu liek crazy, it has reduced pcie lanes, upgrade your cpu to a 5600x and a 4060. Even with the 4060 you can play alan wake 2 with rt hahaha. The 4060 recomended psu is 550W so you're fine with it. Also upgrade to 2x16GB ram kit if u can in the future, to reduce latencies and stuttering\n\nHere, have real benchmarks with all the technologies on, getting your money worth of the gpu, unlike what other youtubers show you on the internet.\nhttps://youtu.be/nMT0OU7-Jtk?si=cl77MKJU195R8x9A",
      "Currently only have 310W for whatever reason I'll have to ask HP about",
      "Thanks! Do you think I should go Nvidia or Radeon by the way? Hears good things about both",
      "Thanks for the input! My current PSU from the prebuilt only offers around 310W, think that would be enough? Would be good of course but I'm surprised that low even manages my current setup haha.\n\nInteresting to hear about the Radeon ones, which of the last you mentioned are better by the way? Not sure of the real differences between them, RX 6600 XT, 6650 XT, 6700 XT?",
      "The RX 6600 draws less power than the 1650 super afaik, it's probably your only option. It is really solid though",
      "Yeah, OEM is those pc's that are pre built from big companies like hp or alienware, I've seen many times that the hardware inside is propietary and cannot be changed, but if ypu can upgrade it go for it!",
      "Haven't found anything about not being able to upgrade so far, upgraded my RAM with no issues, but are there any specific ways to confirm that? Contact HP I guess?",
      "Follow up question, I've seen a lot of praise for the Radeon cards, could it be worth looking into those if I can find good prices perhaps?",
      "Yeah that praise comes from not understanding anything of how gpu's work, a quick reading to nvidia's whitepapers show how superior their gpu's are. Since 20 series memory on their gpu's has been compressed instantly once it's allocated and uncompressed once the data is read. Now with 40 series they shifted the architecture too to be cache dependant, it will read data first on cache and then vram, plus cache grew 400% compared to 30 series, so it has better use of their resources, ppl only see 8GB and will cry like a baby, but can't comprehend that dlss, the data compression, fine tuning of vram clocks, cache dependancy, and working closely with vram manufacturers makes the gpu good for it's designed resolution (60 class for 1080p, 70 class for 1440p, 80 class for 4K). For example the 4060ti with 8GB and 16GB, the 16GB model was said from nvidia to be a budget option for AI training, it does not perform better than it's 8GB variant since the GPU die itself doesn't benefits from more vram. Vram calculators in game settimg gives an estimate but they can't acces the real % usage of memory, again, rtx cards are cache+vram, not only vram, and data is compressed, so games give an inacurrate %.\n\nDlss on the other hand works with the tensor cores, ppl deactivate dlss, thus running the gpu only with the raster cores, that's like running a ferrari only with the 1st gear, it's stupid, ypu pay for the whole gpu die, dlss is part of the hybrid rendering pipeline designed by nvidia, you can't just disable it to make it \"fair\" for amd because they don't pump money into r+d."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "rtx 4060",
      "4060"
    ],
    "title": "Looking to upgrade from GeForce 1070ti to GeForce RTX 4060",
    "selftext": "Hey all,  \nI wanted to ask if this upgrade is worth - there is a black friday deal on [ASUS GeForce RTX 4060 DUAL EVO 8G OC](https://www.amazon.co.uk/gp/product/B0CVQLKYSK/ref=ewc_pr_img_1?smid=A3P5ROKL5A1OLE&psc=1) I was wondering if i should switch my current [MSI GeForce GTX 1070 Ti GAMING 8GB](https://www.scan.co.uk/products/msi-geforce-gtx-1070-ti-gaming-8gb-gddr5-vr-ready-graphics-card-2432-core-1607mhz-gpu-1683mhz-boost)?\n\nAll seems like an upgrade but a friend mentioned that it may not be worth due to the bus-width bitrate.\n\n  \nReally appreciate any advice!",
    "comments": [
      "This is a Fakespot Reviews Analysis bot. Fakespot detects fake reviews, fake products and unreliable sellers using AI.\n\nHere is the analysis for the Amazon product reviews:\n\n>**Name**: ASUS GeForce RTX 4060 DUAL EVO 8G OC Gaming Graphics Card - 2535MHz Boost Clock, GDDR6X, PCIe Gen 4, DLSS 3, 3x DP v 1.4a, HDMI 2.1a (Supports 4K & 8K HDR) \n\n>**Company**: ASUS\n\n>**Amazon Product Rating**: 4.7 \n\n>**Fakespot Reviews Grade**: A\n\n>**Adjusted Fakespot Rating**: 4.7\n\n>**Analysis Performed at**: 10-05-2024 \n\n[Link to Fakespot Analysis](https://fakespot.com/product/asus-geforce-rtx-4060-dual-evo-8g-oc-gaming-graphics-card-2535mhz-boost-clock-gddr6x-pcie-gen-4-dlss-3-3x-dp-v-1-4a-hdmi-2-1a-supports-4k-8k-hdr) | [Check out the Fakespot Chrome Extension!](https://chrome.google.com/webstore/detail/fakespot-analyze-fake-ama/nakplnnackehceedgkgkokbgbmfghain)\n\n*Fakespot analyzes the reviews authenticity and not the product quality using AI. We look for real reviews that mention product issues such as counterfeits, defects, and bad return policies that fake reviews try to hide from consumers.*\n\n*We give an A-F letter for trustworthiness of reviews. A = very trustworthy reviews, F = highly untrustworthy reviews. We also provide seller ratings to warn you if the seller can be trusted or not.*",
      "100% worth it . What CPU do you have ?",
      "Take the money and buy used 3080. Will rape that 4060",
      "Intel - Core i5-8600K 3.6 GHz 6-Core Processor",
      "Bottleneck checker shows a 10% bottleneck on the 8600k on a 4060. No that big of a deal as you can always upgrade that later. I would putt the trigger , the 4060 is great for 1080p"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "rtx 4060",
      "4060"
    ],
    "title": "Should I upgrade?",
    "selftext": "Should I keep using my 12gb RTX 2070Ti or upgrade to a 8gb RTX 4060? Obviously I’m lowering the memory I want but since the 4060 is a newer card, should I upgrade?\n\nEdit: Guys I made the post super late and was tired. I realized my mistake. I meant 2080 Ti. Mistakes happen bro 😭. But for those actually replying genuine answers, the play seems to wait. Definitely interested to see what the 50xx series has to offer. Thanks everyone!",
    "comments": [
      "ive never heard of a 2070 Ti 12GB GPU? \n\n2070 and 2070s exists but both have 8GB. Did you perhaps make a (multiple) typos? \n\neither way, The 2070 is so close in performance to the standard 4060 that its not necessary to upgrade. The 4060 does have the benefits of FraneGen that will give it a longer life than the 2070, but , you might as well just save what you would have spent now on a side grade and get what ever the new ××60 class GPU would be, that will most likely have better performance at the same current price",
      "2070 TI 12GB doesn't even exist??\n\nEither way, you won't gain anything by getting a 4060, minimum you should be getting is a 4070 or 7800-XT",
      "Look at benchmarks & work out if the gain in FPS is worth it for the cost.\n\n[https://www.techpowerup.com/review/msi-geforce-rtx-4060-gaming-x/31.html](https://www.techpowerup.com/review/msi-geforce-rtx-4060-gaming-x/31.html)\n\nThe 4060 is about 4% faster than a 2080 & 22% faster than a 2070.\n\nTo me it's to close, id want 40% more FPS min gain but that's me.",
      "oh yeah, then i would definitely keep the 2080 ti. its better than the 4060 and has more vram. the only downside is no framegen.\n\nbut, you can save the cash you would have spent for another year or 2 and get the xx70 or xx60 gpu as an upgrade rather. 2080 Ti is still great for 1080p",
      "\"4060 is roughly 30% slower than the 3060 \"\n\nI am very interested, where did you get that information. Could you share it?",
      "Didn't know kids were allowed on Reddit",
      "I meant 2080 yeah. Was super tired after work and realized my mistake",
      "Brother, I’m still on a 970. You can definitely hold on to that 2080 Ti for a couple of more years probably.",
      "Only 4070+ for you my man, otherwise wasting money",
      "Just wait for 50 series, that's a good gpu",
      "Personally, if the 2070ti works for everything you want to play then you should keep it and wait for a more significant upgrade",
      "Wait for 5000 series to be released probably later this year and reevaluate again. Than go for 4070+",
      "Save for a 4070 super and just keep rocking DLSS on your 2080ti 11gb, thats a pretty damn solid card still.",
      "Wait for 50 series and save up more money in the meanwhile to not have to get a 60 class GPU.",
      "A 2080ti is 11GB…",
      "I wouldn't bother. Find yourself a 3070Ti, 3080 or a 4070. Check out the second hand market.  \nIf you can wait a bit prices for 4070s should drop a bit when the 50 series comes out.",
      "Why would anyone make such weird choices? Invest in better card and then you probably won't come back with any buyer remorse",
      "Tbh either wait for 5000 series or get a 4070 or better, a 4060 is not a good value card especially you already have a 2080ti which has a respectable amount of vram",
      "not worth, save for a 4070 super or 4080 super for the long run",
      "A new series is around the corner, who knows what they gonna make exclusive this Time, if u don't want 40series specific extras then I'd suggest waiting"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "rtx 4060",
      "4060",
      "rtx 4060 ti",
      "4060 ti"
    ],
    "title": "RTX 4060 Ti - Is the card really not worth looking at?",
    "selftext": " I'm considering buying an RTX 4060 Ti, but every time I go online I see people's hatred of this card.\n\nIs really 8GB VRAM so little for \"new\" games ? (This is the version I plan to buy, because watching tests in games the 16GB version usually achieved 1-3 FPS more (high graphics settings in \"new\" games). I also plan to buy a monitor - only 1920x1080.\n\nThe versions of the card that interest me cost in my country 485-555$\n\nAlternatives are:\n\n4070 - 770-820$\n\n3070 Ti 600-620$ and its still 8GB\n\nDo you think it's better to stay with the 4060 Ti or pay the difference in price to the 4070 (50-60% more)?",
    "comments": [
      "For $400+ you can get much better cards with much more vram",
      "Much better Radeon RX6700xt or RX7700xt",
      "If you plan on spending 400 US dollars or more, why are you even considering buying anything that only has 8 GB of video memory? The options you should only consider are those products that have 12 GB or more, because all 8 GB products are having a difficult time at 1440p resolution for new games.\n\nShould you decide to get any 8 GB card, if you use it to play Starfield the game, you will be lucky to get over 45 FPS. I'm willing to conjecture that you won't even get 40 FPS with the RTX 4060, with the RTX 4060ti you might get 45 but no way in hell are you going to get 60 FPS, because the RX 7900XT and the RX 4090 cards are getting only 60 to 100 FPS at best.\n\n\nHere's a review of the game in comparison to various video card performances.\n\nhttps://www.youtube.com/watch?v=vTNiZhEqaKk",
      "The rx6950xt out preforms 4070 and 4070ti and it’s only 620$ keep in mind Black Friday is coming in 3 months so the price could change from 620 to 450$ it’s original price a month or 2 ago",
      "u mean AMD cards? because Nvidia card in my country with more GB:  \n3060 with 12 GB (335$)   \n4060 Ti with 16 GB (600-670$)  \n4070 Ti and 4080 are way too much for my budget",
      "i will check them, thx",
      "Well, i plan to buy only 240 Hz monitor with 1920x1080 resulution 24\" for Valorant (played on bigger and it was to big for me and I like to have monitor closer to my face), so 1440p is not a problem for me.  \n\n\nAs in another comment:  \n3060 with 12 GB (335$)  \n4060 Ti with 16 GB (600-670$)  \n4070 Ti and 4080 are way too much for my budget  \n\n\nI don't know much about AMD, but I am worried (like about 4060 Ti card) for their performance in Valorant (bad drivers sometimes?)  \nIn addition to Valorant played mainly coop games with my brother, in general I count myself as a boomer :P Therefore, I do not know if I will play Strafield or similar new games",
      "It is very possible that the price in September/October (more than 30 days before Black Friday, due to the European Union law that requires displaying the lowest price from 30 days ago) will increase, in order to return to \"normal\" on Black Fiday - I am no longer deluded, this is not a good country when it comes to electronics. But thanks for your comment, and I'll be happy to check the prices of the different versions (as long as there are no availability problems like with the 6800 XT)**.**",
      "Keep in mind the RX 7800 XT will be released in a couple of days. I would wait to see how that performs before making a decision",
      "From my understanding Valorant and many games like it have CPU heavy workloads, which means your performance will greatly improve more with a faster CPU rather than a GPU once you pass a certain graphics limit.\n\nMore than half the RTX 3060 12 GB cards in North America that are on the Amazon and Newegg website has the products priced between 270 and 310 dollars. This might be the best option to play games that are more E-sport and independent game titles. The money you save should be held to buy a new computer setup that is a magnitude better in every way next time you buy a system. I suspect that in two to three years, AMD will provide an APU or CPU-iGPU setup mini-box computer that will cost less than 400 dollars that will come close to outperforming an RTX 3060 sometime after 2025.",
      "Yes, I have read about CPu in Valoranta and so I choose them for the planned computer.  \nAs for the card, it's the final battle that will be between 3060 12GB, 4060 Ti 8 or 16 GB and RX 6800 XT (the problem is that only one version of this graphics card is profitable in my country - of those that settle good results).  \nThe biggest problem lies in the graphics card market. I live in Poland, most of the cards or good versions are not available or cost much more than better cards ( just more popular ) - often an inferior card costs more by $250-300 and is sold only by one store or by \"suspicious\" stores only.  \nThanks for your comments."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "rtx 4060",
      "4060",
      "rtx 4060 ti",
      "4060 ti"
    ],
    "title": "Low/Mid Tier graphics card enough for levelbuilding/scene building and rendering in Unreal Engine and some gaming in 2023?",
    "selftext": "Hello, iam planing to upgrade my old rusty RX 5600XT 6GB graphics card to something more adequate and capable to work and render in Unreal/Blender and some ray tracing gaming in 1080p-1440p 40-60fps ultra in 2023     \n\nso far my best adepts are - RTX 4060 Ti 8GB, RTX 3060 Ti, 8GB, RTX 3060 12GB\n\n or wait, and invest tad more on the RTX 4060 Ti 16GB that comes out in July \n\nthe dilemma is that my current 6GB VRAM is abyssmaly low just as it sounds but although in general use like gaming all of the above options are marginaly better in speed than what i currently have, 8GB doesn't exactly seem to be that much improvement in long run if iam to pay 400-500€ for a graphics card id be happy if it lasted at least 2-3 years.. i know they are not the best for rendering but iam not exactly picky about performance and iam used to work in 20-30 fps or less as long as i can get the job done\n\n Id love to finaly get to use some ray tracing, path tracing, nanite and other goodies that new unreal engine delivered but iam unfamiliar with how the current gen AMD cards perform in these task as my old warmachine runs like sh\\*t in all of them or doesnt even support things like path tracing.. so if they perform well iam wholeheartedly open with AMD suggestions aswell. The graphics card shouldn't be longer than 290 mm and consume arround 200W, less better",
    "comments": [
      "You'll be fine with a 3060. You will find it very useful to invest in a good cpu  tho (minimum a 12700/13700 or their amd equivalent) and lots of ram (64 to 128).",
      "The gaming performance of a 6800XT is on par with a RTX 4070 while RT performance is that of a RTX 3070. Blender is more of a mixed bag with performance ranging from that of a 3060 to a 3060Ti. However recent vulkan updates apparently have improved performance further but I was unable to find any comparison videos made after the same. \n\nRendering comparison: https://youtu.be/3r6TasObpRU\n\nGaming/UE5 performance: https://youtu.be/WPE_CvvqJpY\n\nWhile rated for 300W, the 6800XT consumes around 280W maximum while gaming with RT enabled and 100% GPU utilisation. Rendering uses lesser power. A decent quality 650W unit should be able to run it. \n\nPersonally I recommend Nvidia for productivity applications (I am a 3070 user myself) However, since you're looking to spend a decent chunk of money on a GPU, you might as well make the most of it. The trade-off with the 6800XT is better gaming performance at the cost of inferior RT and rendering performance. But considering the 4060Ti/3060Ti is a tier lower to begin with, the 6800XT might match them or offer a similar ballpark performance in productivity. \n\nThis comparison will have more clarity once the 4060Ti 16GB releases. Who knows? The 6800XT might receive a further price cut. Nvidia is the \"safer\" option, but I'd recommend checking out relative productivity performance of both cards before making your decision. For Gaming, the 6800XT is undoubtedly faster. \n\nThe only reason I cannot wholeheartedly recommend the 4060Ti 16Gig at $500 because it isn't exactly future proof considering it's negligible gain in gaming performance with last gen cards. It just makes the 4070 look like better value.\n\nThe only reason to consider the 3060 12Gig is because of its acceptable rendering performance and decent vram capacity considering the recent drop in price. It is a significant upgrade from the 5600XT as far productivity is concerned. Gaming performance is slightly slower than the similarly priced RX7600 8GB but beats it handsomely in productivity.",
      "The 3060 12 gigabyte version below $300 is the best value option. I wouldn't recommend AMD for productivity.\n\nThe 4060Ti 16GB at $500 will probably be a disappointment due to its narrow memory bus.\n\nIf buying used is an option you might consider a 3090 or 3080Ti /3080 12GB.",
      "they and 3070s are unfortunately way out of my budget + they’re way too big Id have to buy a new case, and new power supply which would be like at least another 100-200€ on top of a graphics card that doesnt go much bellow 600€ when my budget is arround 400-500€+- .. dont wanna spare on a graphics card but dont wanna overspend either, so thats why iam considering the 4060s \n\nheard they are bad and they’re a bad buy , but i sense thats from a standpoint of somebody that might be upgrading from 3060ti or at least something from arround 20xx-30xx series which is not exactly my case, as upgrade from any of the gpus above will be huge change in comparision with my current gpu..",
      "Fair enough. But the 16GB 4060Ti is kind of a ripoff at $500. That's 6800XT price territory.\n\nRX6000 supports ray tracing which was not available in the 5000 series. They have gotten decent at blender these days due to vuklan updates. Not sure how it stacks up with RTX cards in UE performance.\n\n3060 12GB costs nearly half of your budget and will be a massive boost for unreal and blender than your current card. As for raw performance it's kinda like a RTX 2070 and will manage some ray tracing at 1080p with DLSS balanced/quality.",
      "6800XT consumes with its 300W even more power than the older RTXs mid ends meaning it adds up another 50-100€ to its price tag for me as i right now only have 650W PSU and although it seems to be reasonable adept, is the raw power of soon 3-4 years old 6800XT that much better in comparision it outweights RTX 4060 16GB considering all the productivity, nvidia tracing, dlss benefits?\n\nthe 12GB 3060 seems like the perfect middle ground, but then theres the question if there is that much of a gap in improvement between the two series that if in 2-3 years the 12GB VRAM wont become irelevant anyway due its slower speed in comparision to 3060 Ti let alone 4060ti",
      "thank you for descriptive answer, so far it looks like iam gonna be waiting till the 16gb 4060 ti comes out and see how she fares, or look out for a good deal on an used rtx 3080 12gb that will be under 500€ as i noticed there are plenty of those circling second hand reselers..\n\neven if i had to buy new 750W PSU for 60€ and modify the case so she fits in seems to be better option and more worth the price than paying +-550€ for the 4060 16GB.. just hope the 3070-3080s arent as power hungry as they appear to me and thats why people try to get rid of them so much"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "rtx 4060",
      "4060"
    ],
    "title": "GPU for design and architecture",
    "selftext": "Hi, I'd need some advice on buying a GPU. I usually work with Illustrator Photoshop, InDesign and Autocad. Well, I have replaced it with Zwcad (eventually with Revit but I'm a basic learner) and, in the beginning, I was thinking of buying Nvidia 4070 or 4070ti or 4070 ti super. I know the current issues with Nvidia so at this point I don't know if I should consider buying Nvidia. Nvidia is considered reliable for working with graphics, but someone recommended me Gigabyte RTX 4070 Windforce 2x OC 12GB GDR6RX DLSS3. It's a bit expensive (€699) ((expensive considering the sum of all the components)), compared to a\n\n\\- Gigabyte RTX 4060 Gaming OC 8GB GDDR6 DLSS3 (€358)\n\n\\- Gigabyte RTX 4060 WindForce 2 OC 8GB DLSS3 (€310)\n\nThe CPU I was thinking of is AMD Ryzen 7 9700X AM5.\n\nThe point is: I'm not a gamer, but I work with graphics, so WhIch criteria or numbering should I pay attention to? I mean, I can't distinguish between the RTX 4060 and 4070, (I don't edit video, I don't play on the pc) and within the 4060 series, I don't know which one is 'better . I don't know if I choose Gigabyte I have to see 'RTX'.\n\nSomeone told me: If you’re not planning on gaming, stick with a common GPU,-more like a 4060- but spend the extra on NVMEs\n\nCould anyone give me somme recommendations?",
    "comments": [
      "I recently had to make a similar choice for my gf, but she’s an amateur photoshop user and just does it for fun, not professionally. I found this matter very hard to find good info on. Based on a gut feeling and some research, I do believe you’d do fine with a 4060. What I’ve found mentions that you’d need around 4 gb’s of vram for photoshop @ 4k. As for RTX, this stands for raytracing. I don’t *think* rtx matters for photoshopping; but every card onward from the 2000 series produced by nvidia has RTX. \n\nThe 4000 cards are nog being manufactured anymore, and due to the scarcity of the new 5000 series, people are buying the old stock of the 4000 cards while they still can for a reasonable price. \n\nPlease note that I am by no means entirely knowledgable on gpu’s for graphics design, so take my input with a grain of salt where needed. Hope it helps.",
      "get like 64gb of ram or more, multiple nvmes and if its in your budget a 4070 ti super and if possible a 16core cpu but only if its in your budget. And dont throw this pc out wheb you upgrade next sone gamer would love it when you’re done.",
      "checl the prices on the core ultra 5 in your country. in australia its cheaper than the 9700x and whoops its ass",
      "Hi, thanks a lot! Any help is really appreciated!"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "rtx 4060",
      "4060",
      "4060 8gb"
    ],
    "title": "Zotac RTX 4060 Single Fan experience?",
    "selftext": "I'm upgrading from a 1660 Super to Zotac's 4060 8gb Solo fan version. I've never done any PC upgrades other than installing the more ram.\n\n I want to get this one because its $280 on Amazon, doesn't use much power, and it is small. I also want to play Borderlands 3 on 1080p Ultra settings, Cyberpunk, and maybe Starfield.\n\nMy current cpu is an i5-10400f.\nDoes anyone have experience with this specific card?",
    "comments": [
      "Loud",
      "Those are the cheapest models for a reason.\nCards with this tiny coolers are typically louder.\n\nUnfortunately, 4060 and 4060ti are some of the worst cards Nvidia hast ever released. Shitty performance for a shitty price.\n\n4060 should be good for about 30+ FPS in Starfield on 1080p/ultra without upscaling.",
      "Maybe they're better these days but I had a single fan single fan 1060 from Zotac a long time ago and they were very hot.",
      "Starfield optimization could be so much better you're not wrong but it WILL run. Don't be hyperbolic.",
      "Yeah, it's less wattage than a 3050 and a few of them had one fan too.\n\nI can only find one review, you've probably seen it.\n\n[https://smallformfactor.net/reviews/nvidia-rtx-4060-review-testing-zotac-gamings-rtx-4060-solo-163mm-long-gpu-for-the-small-form-factor-market/](https://smallformfactor.net/reviews/nvidia-rtx-4060-review-testing-zotac-gamings-rtx-4060-solo-163mm-long-gpu-for-the-small-form-factor-market/)",
      "Looks like it runs cool and quiet, offering roughly 3060 Ti performance (only at 1080p, much slower at higher resolution) while using just over half as much power.\n\nIt's a faster RX 6600 but with NVidia's driver stability and DLSS, while running about ten watts more than an RX 6600. Problem is it's a $300 card vs about a $200 card.",
      "Cost.",
      "It is possible to be happy but you'll need to learn undervolting with msi afterburner",
      "Slap a 120 case fan on it and easy",
      "Well the thing is he's also a video editing so I think Nvidia is going to be important in this case more than usual. \n\nedit - Pulled the trigger on this for him. Its the cheapest 4060 on amazon. FSR / DLSS reduces vRAM needs a bit anyway. And his video editing will be nice and smooth. Sucks Nvidia didn't have a better option for my little brother but its not too bad for 280.",
      "It's compact and the 4060 is lower power than your current card although a 115 watt card would likely be loud on one fan, I would suggest to go for a two fan model",
      "I have a dual fan 4060 and even under heavy load it's cool and quiet.  I imagine a single fan version wouldn't be too different as the cards really don't produce that much heat.",
      "don't buy 8gb card on 2023",
      "You buy a small card when you can't physically fit a larger card. There is no other good reason to do so.",
      "I upgraded my MSI trident 3 with a i5 10400 and a 1650 super to this zotac 4060 and I consider it a good buy for my needs. Reasons I chose it at the time. \n\n1. It fit in the case\n\n2. The Trident 3 is limited by its power supply and the 4060 solo uses way less power (55w less) than a 3060 cards of the same size.\n\nSo far the card has been great. It is loud, but not unbearable and you won't even notice it unless you have your face next to it while you're playing games. \nThere are better cards but if you have power restrictions and size restrictions it is tough to beat this card. \n\nIf you are upgrading from a 1660 to a 4060 you will not regret it. Your still getting a huge performance boost. If you don't have a size or power restriction you should look at a different card.",
      "I know this is an old thread but will this perform the same as a regular 2-fan 4060?",
      "how easy is it to change the fan",
      "Tell ur bro to buy a 6700XT, it might be a bit over 300(but not by a lot). Performs better and has 12GB instead of 8GB.\nCheck this out: https://www.youtube.com/watch?v=9O7Ij5rOqso",
      "Hey I have an 8tj or 9tjn gen MSI trident 3, i5 8400, GTX 1660, you think not worth it for me to get 2060 or 3060 and I should go right for 4060? I won't need 330w psu for it ?",
      "NO."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "rtx 4060",
      "4060",
      "rtx 4060 ti",
      "4060 ti"
    ],
    "title": "Upgrade from GTX1080 to?",
    "selftext": "Hello guys I recently upgraded my pc except for the GPU.\n\nCurrently have a B650 Gaming X, Ryzen 7800X3D, 32gb ram DDR5, and a power supply of 650W.\n\nI was looking to upgrade the GPU aswell, my budget is around 400€, and I've seen a deal on a MSI RTX 4060 Ti Gaming X SLIM 3X 8GB around that price.\n\nThe question is should I wait for 5xxx series, or maybe wait some time and try to get a 4070/4070 super?\n\nThe use would be 1080p gaming, at 240hz at least for competitive FPS and some MMOS/Open Worlds/Survival.",
    "comments": [
      "I avoid all 60 series, feel like they are for people who dont know any better. Either save up for like a 4070 super, an amd card or look at used cards. You can get a 3080 used for like 250 usd.",
      "Whatever video card you choose, I think the best option you can get is a video card that has at least 16 GB of DDR6 video ram memory.\n\nI doubt that you can get over 200 FPS for triple A games that require more than 10 GB of memory if the card does not have at least 16 GB for 1080p resolution or higher.",
      "650 watt psu m get overloaded stuff Like multiple hdd, cooling accessories, power fluctuations or even Overclocking of cpu or gpu. Definately it will take toll on PSU. 900 preferable. \n\nAnd if you gonna upgrade whole set of components its requires 900 watt. Specially Ryzen 7 or 9 cpu and 7800 xt above gpu.",
      "do you need to do it now, or can you wait a few months?\n\nif you can wait, then wait,   \n  \ntechnology often has cycles, where sometimes it stalls and all improvements if any also go paired with similar increases in price and powerdraw(the last 7 years or so have been largely such a case for gpu's).  \nand yet then at some moments there suddenly are big waves of sudden advancement, where there first is some peak, sometimes going even further, and then slowly going down again.  \n  \nI have been waiting since the beginning of this year, or actually longer but it is only since the beginning of this year that my system started to really show it has problems.  \nand I have been waiting because there has been a long stall in technology, nothing really exciting for years, but also when looking deeper already years ago it was obviously clear that around somewhere halway through this year to begin 2025 there would be another wave of sudden advancements coming in, as those waves are actually quite predictable since they are typically caused by a company which is the underdog at that moment who starts preparing far ahead to make some sudden huge improvement, and when looking closely in open source projects and such you can see that companies have a lot of confidence, stakes, and work in a certain product they are gonna launch\n\nin this case it was Intel, which many years ago already very clearly had set the upcomming lunarlake and battlemage as a very important thing and designed many things for, that said their metior lake and alchemist gpu's could also be seen as them setting the early framework, doing some testing and having something to prepare the other things more easily, but there where much more traces underground.  \namd now also seems to be reacting to it with many leaks and rumors suggesting they will actually launch their next gen gpu more early and actually pretty soon, as well as at better performance than current gen but also much lower prices(have seen people reffer to rtx 4080 to rtx 4080ti performance(and better raytracing) at around $499), which might make sense as amd needs to respond to intel's upcomming gen and can't just suddenly lower the prices to much and fast after it is already launched for a higher price since that will create lashback, and similarly if they are to expensive compared to battlemage then their products are obsolete. Nvidia almost certainly will also try something like that, but I am not sure how they will do it, but probably they will use a lot of marketing tricks, or lower prices of next gen greatly, or use both.\n\nin simple words we enter the 9th month soon, amd and intel are suggested to be launching stuf this year, some perhaps also in january, and nvidia is expected to also launch new stuf around then, this is  about around 3 to 4 months max, where intel is estimated to be around 1 to 2 months away, and amd is estimated by some to be even closer. also both of them are expected to have thigns that make much more sense for gamers than whatever is on the market right now also much better value, and if you want new nvidia then waiting until they launch their next gen will also push down all their other prices.\n\nso I would wait, because industry expects this soon to be another of those big waves in technological advancement, and since they are the ones making and designing the tech I trust them at it that if they beleive something is gonna be a huge wave of improvement(also in value) that it is something like that.\n\n**TLDR**:  \nhigh probability of sudden wave of improvement in technology like gpu's also much better performance for much lower prices, expected to be within around 1 to 4 months, where it should begin within 2 to 3 months at most, but potentially more early.  \nbuying new now will probably mean you regret it soon, as soon you might be able to get much better for cheaper, especially in that price range you mention.\n\n**so my main recomendation is:**  \nwait for next gen. also do not limit yourself to nvidia, as especially in that price range you reffer to battlemage will probably be a great option and amd will probably also beat nvidia quite much in that price range, that said, perhaps nvidia will get a good price/value, after all they intentionally wait with their launch until amd and intel have published their cards. but even then I expect nvidia to not actually give better value and instead use marketing to just make it seem good value, so make sure to also look at intel and amd cards.  \nbut no mather which one you think you want, or even if you are fixed to a certain brand, then still wait since all brands are expected to get much better value soon.\n\n**if you really want to get a new gpu now at that price point however.**\n\nthen get one secondhand. there are many gpu's I would say get something cheap secondhand. you can't go to high end since all the high end cards currently use insane amounts of power, and so would require a new psu,  \nnext to that at your price point conciderering power draw is also usefull since with modern day flagship gpu's their prices might be insane but if you live in a country where electricity isn't super cheap then soon the electricity cost can also become rather huge.",
      "Someone said 7600xt which has a really fair price, around 300, is the same as 60 series for nvidia or that could be actually a good buy? Also considering the nvidia/amd 70 series I should also upgrade my 650w PSU(?)",
      "I disagree on the 60 series.  The 3060 Ti is an astonishing card.  It smokes a 2080 Super.  The 3070 is barely any faster.  It can be found in the \\~$225 range and is a 1080p beast.\n\nNow, the 4060 and 4060 Ti are not impressive cards compared to the 30 series. Don't buy one unless it's a steal. Like $200.   The 4070 and particularly the 4070 Ti are a HUGE jump above the 4060 Ti.  4070 Ti just barely beats a 3090.\n\nThere are no bad video cards, just bad prices.\n\nAt $400, buy a used RTX 3080, A new RX 7700XT, or spend a bit more and get a new RTX 4070 or a used RTX 4070 Ti.  Or wait a bit.  nVidia usually releases high end cards first, 60 series 6 months later.",
      "650w is fine.  Try for the 7700xt it's a massive jump up from the 7600xt, or a used 3080.  Think of your GTX 1080 as an RTX 3050.",
      "A. The 4060 is decent, it's pretty good if you're playing something that can take advantage of all the DLSS bells and whistles (though last I checked the only games that would fit that criteria are cyberpunk 2077 and the new Alan Wake)\n\nB. There very certainly are bad video cards. Are you familiar with the RTX 4060 Ti 16GB?\n\nOne of the few non-top-end Nvidia cards to have more than 8GB of VRAM and since the card uses the same size memory bus as the 4060 Ti 8GB its absolutely worthless.",
      "I have almost reached paralysis by analysis and was wondering your thoughts on which is the better value for High FPS 1440p gaming. 7700xt vs 7800xt? Right now it’s about an 80$ difference in cost between the two for me. Just trying to be wise with my money. \n\nI have a Ryzen 5 7600 CPU if that matters.",
      "yes this,   \nthe rtx 4060 is mostly useless due to having almost no vram for it's price class.  \nand while the rtx 4060ti on paper comes close to the 4070 that is because it is litterally a nerfed 4070, but in most countries it also costs around as much as a rtx 4070, so the rtx 4060 ti should be called the rtx 4070lesser. \n\ncurrent rtx 4000 cards really are a mess, the later rtx 3000 cards also have problems, like how the rtx 3060ti is actually worse than the rtx 3060 in most games.\n\nso certainly agree when looking at any form of actual use or benchmarks instead of the nvidia selected marketing material it is clear the current rtx 4060 cards have serious issues, and many people think the rtx 4060 is similar to the rtx 4060ti 16gb, but they litterally are verry different cards and in modern games don't even come close to it, and then yes even that card underperforms as if intended to make the higher end cards look better, also it's pricing is actually similar to the higher end cards.  \nmany problems,like cards with the same name yet very different cards and performance, cards which just are completely unstable in modern games. etc.",
      "Again, it comes back to cost.  While I agree that jamming all that extra VRAM into a lower end card is a marketing stunt to upsell to people who think it makes the card WORTH the extra money, it does NOT make it a \"BAD\" card.  JUST a bad value.  If you could buy a 4060 Ti 8GB for $200, or a 4060 Ti 16GB for $200, you would still pick the 16GB card.  Having extra useless VRAM doesn't HURT the card.  It's just not worth the extra money.  This illustrates a mental fallacy that occurs where people label cards as being \"BAD\" as if there is something fundamentally wrong with them.\n\nI personally dislike the 4060 Ti, it's architecturally gimped on purpose to fit nVidia's marketing strategy.  It could have been a lot faster.  But it does play games, just not at the speed nVidia markets it at.\n\nLet's also not forget that the card exists because people thought the 8GB card was not enough, then when nVidia fixes it by doubling the VRAM, people call it useless.  Yes having a faster bus would have made that extra VRAM much more useful, but it largely fixes the 1% low FPS issues, and the VRAM errors people were running into, etc.  But at $500 it's a rip off.  But at $200 it's a GREAT card.  It's all about value.  Is an RX 580 8GB a bad card? No it was a great card, but the 4060 Ti beats it in every category including memory bandwidth.  The RX 580 has a 256 bit bus, but only 256GB/s of bandwidth, the 4060 Ti has a 128 bit bus, but the faster memory on the 4060 Ti wins with 288GB/s of bandwidth.  How can it be bad if it fully beats other cards we called \"good\".  Because it's about value only.\n\nA side note on VRAM, picking between two cards, one with extra VRAM and the other with less but no performance difference between them does have some niche markets.  Particularly, video editing.  Every MB of VRAM is precious.  I fall in this category, so when I was in the market for a new card, I ended up with a choice between a 24GB RTX 3090 or a 16GB RTX 4070 Ti.  Both cards perform about the same, with the 4070 Ti taking the lead by just a bit.  But I went with the 3090 because of the extra VRAM.  Editing 6K RAW video takes every MB you can get.  The point being that the MSRP on the 3090 was $1500.  But I got mine at $800, the same cost as a new $4070 Ti.  The bus on the 4070 Ti is 192 bit, while the 3090 is 384 bit.  Does this make the 4070 Ti a \"BAD\" card because it has a seemingly crappy bus?  No, because at the end of the day, the 4070 Ti is FASTER than the 3090 at gaming.\n\nThe 4060 Ti has a 128 bit bus, the 3060 Ti has a 256 bit bus.  But the bus on the 4060 Ti is not half the speed.  The memory it self is faster.  The number that matters is  288 GB/s for the 4060 Ti and 448 GB/s on the 3060 Ti. Yes it's slower than the 3060 Ti, but its not \"BAD\".\n\nImagine if we renamed the card 4050 Ti and it cost $200.  It would be a GREAT card.  It's just that it doesn't deserve to be called a 4060 Ti, and it's crappy that nVidia tried to make it seem like it was in the same class of card as the 3060 Ti. Pick on nVidia, not the poor little 4060 Ti who's doing the best he can.  It's not his fault.\n\nNo bad cards, just bad prices. (and bad companies)",
      "There is a significant improvement between the 7700xt and 7800xt.  Roughly an average of another 20-25 FPS at QHD (But it's more significant than merely an FPS bump, %1 lows at higher res is much better, smoother experience).  At $80 difference the 7800xt at 16GB is well worth it for QHD.  \n\nKeep in mind the 7700xt is already a really great card and is doing a lot of heavy lifting.  The 7800xt is going to bring you into higher resolutions, which is facilitated by the extra VRAM. \n\nRyzen 5 7600 is an excellent CPU in both single and multithreaded.  The 7800xt is a perfect pairing along with a high refresh rate QHD monitor.",
      "When I said the 4060Ti 16gb is bad I meant that it literally produces the same benchmark scores as the 8gb version, so you might as well just be lighting on fire however much the extra pointless vram adds to the cost.\n\nIt's more expensive, according to how it was marketed, due to better  performance, making it an upgrade to the normal 4060 Ti but, with it's insufficient data bus it has a ceiling to its performance. That ceiling is roughly equal to that 4060 Ti, and seeing as it's very reason for existence is to perform better than that card and it literally can not, yeah, that's a bad graphics card.\n\nMaybe not if your notion of good or bad is like, 'Does it function as a gpu? If yes then it's inherently not a bad card.' Because it's silly to use such a black and white sort of criteria to judge parts like gpus. I mean, they have such a wide range of qualities that should be accounted for like cost, standard performance, potential OC performance, additional capabilities like ray reconstruction, etc.\n\nSo yeah, the 4060 Ti 16GB is bad at doing the one thing we were told it was designed to do.",
      "Awesome thank you so much. I ordered the 7800XT today. Also ordered a 144hz 1440 monitor. May get a higher refresh rate monitor at Holiday season if there are some good sales."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "4060",
      "4060ti"
    ],
    "title": "Trying to decide between pny and inno3d 3060ti",
    "selftext": "I tired to find some reviews but failed, their price is pretty much the same\n\n* Inno3D GeForce RTX 3060Ti TWIN X2 LHR\n* PNY Geforce RTX3060Ti 8GB VERTO Dual Fan\n\nWhat is important to me is the card being quiet and cool, and maybe no coil whine or is it too much to ask?And just to make sure I shouldn't even consider the 4060 non ti right?\n\nThe 4060ti is about 90$ more where I live and I don't believe it's worth the difference.",
    "comments": [
      "Imo you can get any of those, 3060ti is still pretty solid even compared to the 4060ti.\n\nIf you're on a small case i totally see why you want a 2xfan but else you should get a triple fan model. You'll also find many used offers for the 3060ti (i'm also thinking to sell my gaming oc pro, looking great and running cool, for like 270€ for example)\n\nYou'll get decent temps if you undervolt, coil whine is a lottery and many times game related - limiting the fps can fix it sometimes."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "rtx 4060",
      "4060",
      "4060 8gb",
      "rtx 4060 8gb"
    ],
    "title": "RTX 4060 8GB for 200$",
    "selftext": "It’s the single fan edition and I wanna use it for my 5L build.\n\nI play cs2, valorant, wanna try Minecraft RTX and Cyberpunk (fhd with frame gen)\n\nIs 8GB enough? Or should I wait until there is a 12 or 16gb card with a similar size?",
    "comments": [
      "Personally I would go with something used. You can get a 2080 or a 3070 for the same type of money and twice the performance. If you're in the US you can try checking on facebook marketplace or Craigslist for used GPUs and check out online how to check if a GPU is ok to buy or not",
      "3070 has way better performance wdym? It's not even close.",
      "For 200, a 4060 is actually a pretty solid choice.",
      "if you play on 1080p go for it",
      "8gb is enough, you can play games with it. Is it future proof? no. Can you play ultra settings? No. Will it work? Yes.",
      "From the tests I’ve seen they both have worse performance even when I don’t use Frame Gen… and I’m also in the EU and those two cards both cost around 100$ more :/",
      "Id get the 5060 for 100$ more - it has 4x Frame Gen but except for that it’s not really worth it right?",
      "Okay just checked and yes I think I saw some weird staged video or sth - but there is no Single fan 3070 right?",
      "It's not staged I'd go with 4060 at least you get a new warranty and if it's a small build the 4060 uses way less power and won't need as much airflow",
      "I just watched one benchmark videos where the were pretty equally - maybe it was staged or something"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "rtx 4060",
      "4060",
      "4060 8gb",
      "rtx 4060 8gb"
    ],
    "title": "12GB of VRAM for 1440P vs 16GB of VRAM for 4K",
    "selftext": "If 16GB of VRAM for 4K is considered enough for 4K then why is 12GB of VRAM not looked at as being enough for 1440P? I feel like if you’re going to say 12GB isn’t good for 1440P then you have to keep the same energy and say 16GB isn’t enough for 4K as VRAM requirements scale up with resolution. \n\nGraphics cards and what they are marketed for. \n\nRTX 4060 8GB for 1080P\n\nRTX 4070 12GB for 1440P\n\nRTX 4080 16GB for 4K\n\nEDIT I’m NOT complaining about the VRAM idk why this sub has so many Dislikes when I myself own a 4070TI 12GB and it’s the best card Ive ever owned. \nI was only asking a question. ",
    "comments": [
      "I have a 4090 and I have yet to use even 10gb vram in 4k. I dont play garbage ports and unoptimized messes with memory leaks so other people's mileage may vary.",
      "I use over 14GB in Hogwarts at 1440p with my 7900XTX",
      "It’s a mindshare thing. People on YouTube, namely reviewers putting both 4070 and Ti in a bracket hey weren’t designed for, then blaming the lack of VRAM without going into detail as to why this is the case. Now you have people, namely AMD fans, going on and on about how 12GB isn’t enough, using broken ports, and extremely niche use case scenarios as justification. \n\nThis type of thinking has infested the minds of people who don’t bother researching data, and instead are quick to believe everything they heard because “someone who sounded like they knew what they were talking about said so.”\n\n12GB is sufficient for 1440p, and will be for at least the life of these GPU’s. In some cases 12GB is even fine for 4K. People just need to stop believing everything they read on Reddit and do some research.",
      "People who live off watching youtube benchmarks with every set on ultra at 90 fps can't accept this.",
      "Well, the PS5, which is the lead development console, does use one unified pool of memory, so the GPU and CPU are both accessing the exact same memory.  PS4 also did this.  \n\nThe Xbox series consoles do have dedicated pools of memory, so those are more like a traditional PC.  \n\nBy your rules I’m gonna assume you’re not disingenuous, so that must mean you’re just uninformed.",
      "Honestly, the only games I've seen issues with it on my 4070 Ti was in Hogwarts Legacy and Ratchet and Clank, but I'm still going to trade my card for the 16GB model and sell this one (will only be down 300 or so dollars in the end) because I can see it becoming a problem soon, yeah the consoles have around 12GB to use but usually you need to shoot a little higher on PC for the enhanced fidelity that is usually part of PC (turning down setting is an option yes but I feel like that should be a 2-3 year out thing this day and age, not a 1 year out thing), so 16GB is a good mark. \n\nI'm pretty sure the PS4 and Xbox One had around 5-6GB of usable VRAM but there could be some edge cases where 6 would run out despite that, and 8GB was generally safe for the generation. Some of these amounts of VRAM usage are wildly inflated though because they're running the game on a 24GB card that is allocating large amounts as a cache, TLOU for example uses around 9-10GB on mine, but that game does not have RT or Frame Gen, so if we add about 1GB for RT and 500MB for frame gen we're getting really close to the limit here. It's a bit overdramatic but imo the 4070 Ti should have had 16 from the beginning, regular 4070 was so far away from the Ti though performance and price-wise that 12 is more acceptable for that model.",
      "We had some awful Pc ports now everything is paranoid 12GB isn’t enough.\n\nJust lower textures if it’s an issue. You’re still getting better graphics than consoles.",
      "Idk where you’re seeing that 12 GB isn’t good enough for 1440p",
      "And why do you think that VRAM requirements would all of a sudden skyrocket? lol\n\nThe consoles aren't changing, and developers have to make games that the majority of people can run in order to actually make any money...",
      "But 24GB 4090 is \"future proof\", right?\n\n\nNo. Hogwarts and couple other games were poorly optimized and lagged even on 4080 before patch. \n\n\nIf devs screw up, can fill 4090 24GB, and hell even 900GB+.\n\n\nDevs make games for what gamers have. Until mid-range xx70 have 24GB+, most of that 3090/4090 memory will go unused.",
      "Because they moved it to AD103.\n\nThat's all there is to it.\n\nFor 1440p gamers, 12GB is totally fine for now.\n\nNow, there are non-gaming utilizations where 16GB is a big advantage over 12GB, for example for AI.",
      "Games are complicated, they don't follow some perfect linear curve for memory usage or anything else. Real world benchmarks tell the story, nothing else does. There's identical cards where one is 8gb and one is 16gb, we can benchmark each separately and see how a particukar game behaves. For 4060ti the extra ram ends up improving 1% lows and giving 3% uigher average fps, even if the game was only using 7gb on the 8gb card. Programs, games especially, are extremely dynamic, they can optimize duffereny when they detect extra resources.\n\n\nRTX 4060 8GB for 1080P\n\n\nRTX 4070 12GB for 1440P\n\n\nRTX 4080 16GB for 4K\n\n\nYou need to find people who test each of these cards in the literal same system same drivers etc with swapping out the card and running and identical benchmarks, that's the best way to tell the real world difference. You can still get a good picture by comparing different tests by different users but it takes a lot more data to be sure of the differences. And even then it's game specific, not always some general rule where at 2k ultra it uses the same vram as 4k low or something.",
      "12 is fine and so is 16.\n\nNvidia should have never done the 8 gigs cards last gen, now everyone is paranoid.\n\nRational:\nWe are tied to current gen consoles. They target a dynamic 4k. \nA 4070ti is obviously much more powerful but “12 gigs” isn’t 16 like PlayStation. \n\nTruth: PlayStation uses unified memory and the OS takes away from the 16 and so do other factors.\nI think it was confirmed to be around 10.5 is allocated. I can’t recall because I don’t have the source on hand.",
      "4070 is for 4k already.",
      "Personally I have the same card and playing the same game I didn't have any problem, in my opinion you are trying to convince yourself to buy something with more vram, I think it's great but 12 gb is enough for 1440 and the rn moments that haven't been enough is due to poor optimization and vram leak...",
      "very sad to set Textures from Ultra to High, lose basicly 0 fidelity and being fine with 12 GB.",
      "An opinion based on nothing is exactly that. Nothing. It's just made up. It can't be a \"probably\" if there is no merit to it. That's like me saying we'll probably all get nuked by aliens tomorrow. Just my opinion.\n\nThere is no trend that would show 12 GB will bottleneck games at 1440p.",
      "They have 16 GB of total system RAM, so you're right but it's about 12 GB for VRAM",
      "I have been monitoring VRAM on my 4090 for different games at 4k ultra, most stay under 16gb and many  well under 12gb (latest was robocop which i saw used around  20% of 4090 vram!)\n\nthat said i have games that have exceeded 16gb - the biggest one was Hogwarts (though recent fixes have improved it so i do't know what that looks like now - what i do know is if a game exceeds the vram you have it does cause stutter (it was the main cause of stutter on my Hogwarts playthrough until i swapped to 4090 from 4080 - but this is an exception, though also applied to my Jedi playthrough too, sigh)",
      "I ran 1440p and 1440p ultra wide on a 3080 10GB with 0 issues. I've recently upgraded to 4K and I'm really struggling to wait for the 50 series at the moment. Rendering at 75% with Nvidia Image Scaling currently 🥲"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "4060",
      "4060 ti"
    ],
    "title": "Is the 4060 Ti really worth over the 3060 12GB ?",
    "selftext": "Ok, so it needs a bit more context. \n\nCurrently, I'm still using my good ol' GTX 1060 6GB and I've been holding off getting an RTX GPU since I don't play games at max settings nor at high framerates. \n\nI'm fine with 40 to 50FPS for most games and with my card, even at 1440p or 4K, some games ran fine by my standards. I also don't play most latest titles ( really depends of the game basically ). But the situation has evolved and now, I'm looking for something to replace it.   \nThe obvious choice would be some RX GPUs but my needs also evolved. \n\nI'm now slowly getting in the 3D rendering and game dev scene ( UE5 mostly, so working with Lumen in mind ), and NVIDIA being the fastest, it is my only options. Since I'm using a 42\" TV, I'm a bit concerned with VRAM issues. I don't want to upgrade in the next 2 years because an 8GB is not enough to run at 1440p/4K. \n\nI unfortunately can't get some used GPU because of my location. I can get an RTX 3060 12GB for 309€ or a 4060 Ti 16GB for 519€. That's quite a difference in price but also in rendering. \n\nBlender rendering is really poor on my 1060 and the 3060 would be 6.5x faster on average according the benchmark but on the other side, with 4060 Ti would be more like 11x the performance of the 1060. And that's without considering the increase in VRAM buffer between the two. \n\nRegarding gaming performance, I'm fine playing with med-high settings with DLSS at both 4K and 1440p, so even the 3060 could probably achieve this I think. \n\nI need to gather more opinions, so what would you pick in my situation ? Is the 4060 Ti worth more than the 3060 in this context ? ",
    "comments": [
      "For the prices you mentioned, 4060 Ti is definitely not worth it. I've seen a 3070 / 3070 Ti for similar price - they would be much better for your tasks.",
      "Unfortunately, people here are... special \n\nI've seen used 3070 at around 600€ or even 3060s at 400€...",
      "BTW, US prices do not include tax. It's $430+ 0-9.5% depending on the state. I'm at 9.5%, so it would be $470 for me. \n\n\n1 USD : 0.95 Euro\n\n$430 = €408\n\n€408 x 1.20 (20% VAT) = €490\n \nYou guys have higher taxes, but the price margins are almost the same. You get universal healthcare and extremely cheap services/medications while I pay hundreds in premiums per month without even seeing a doctor. I was looking at medical costs, €18/day stay in a hospital bed regardless of surgery or treatment in France.  For me it would cost $235 in premiums/month, $250 ambulance trip, $330 ER visit, $75 xray or CT scan, $330/day in a bed, and whatever other surgery fees and shit they throw at me up to $8700/yr max out of pocket and that's on the \"good\" end of things.\n\nMicrocenter is cool unless you get into a car accident on the way and lose your entire PC budget to medical bills. I'm pretty sure that makes up for the slightly higher GPU costs.",
      "4060 ti is considerably less power hungry and will that will definitely show on your power bill at the end of the year. So that might even the price difference out eventually..\n\n Usually the 4060 ti will bottom out before it even needs anything close to that 16 gigs of VRAM, but it's WAY better to have 16 gigs instead of  the 8 gig variant. Obviously. You've got DLSS3 and Frame Gen with the 4000 series, which will make your card perform a little better than native. Given you don't really care about high FPS OR the latest and greatest games, or highest graphics settings, I think using DLSS Quality or DLSS balanced with FG and a game at 1440P/4K at medium settings will play very nice. Things the 3060 won't be able to do.\n\nHonestly if I was you, I'd be all over the 4060 Ti. Newer features and warranty. It's a no brainer. Not to mention you can sell it at a higher price later on the second hand market.",
      "Look at benchmarks on YouTube.\n\nShort answer is, if you have the extra $ it is absolutely worth it in my opinion",
      "It’s not a bad card. It’s only bad when you start to compare it to previous generations xx60 cards and it’s price. By itself it’s a very capable card imho.",
      "4060Ti 16GB has been going for $430 USD on amazon and newegg. So for that it's definitely worth it. Especially to not have vram concerns. It seems your euro pricing makes it less desirable.",
      "4060ti is a good productivity card, similar to 3060 when it came out, simply because of the amount of vram. \nSo if you dont need more than 12gb vram, get 4060ti, if not 3060 is enough\nWait till next year when the rumored refresh of rtx4000 come out with more vram.",
      "I went for 4060Ti 16GB and I'm happy with it. Would I want a more powerful one? Yes, of course. Would it be worth paying more for electricity? Hell no! If you have the cash, I think you should go with the 4060Ti. I play pretty much everything at High/Ultra with 1440p, the only game I don't enjoy the FPS at is Cyberpunk which runs ar around 50 FPS with RT Overdrive on max.",
      "How much is 3060 Ti?",
      "I got you. As for me, I'd better get 3060 here, it's a good card for its price. 4060 Ti 16 Gb is the worst price/performance card on the market, maybe only 3050 can compete.",
      "I know that the 4060 and 4060 Ti as a whole are basically waste of sand compared to the previous gen and have terrible value.\n\nBut in my situation, where VRAM is valuable and AMD/Intel aren't a good option, I thought that it would be not that much of a bad deal to get one. \n\nGoing for a 3060 is cheaper, I guess I'll get it Q1 2024 and upgrade it in 2025, hopefully with better options",
      "Post bump; Have you gotten a card yet?\n\n3060 12gb will perform just the same as 4060ti 16gb in rendering because the 4060ti only has a 128bit bus while the 3060 has a 256bit bus.. go with the 3060 12gb.",
      "For the power consumption, it's not really a problem. I mean, it matters of course but in rendering, the card don't use all its capacities, and the power bill compared to gaming is lower ( if rendering doesn't last longer than gaming activities of course ). \n\nAnd yes, that's why I'm thinking about the 4060 Ti. It's a bad card on it's own but in this context, it could be a greater option.",
      "Unfortunately, there aren't a lot of productivity benchmarks of the 4060 Ti. People considering it just trash at this point ( which isn't completely fair, but not completely false either ). \n\nFor gaming, both would be a large upgrade to my 1060 anyway.",
      "Well, the Euro pricing is terrible. Always about 50 dollars more than US and in France especially, good luck getting one for less than 499€. \n\nOn top of that, I can't get one from other retailers than the local store because, it's just more expensive. For example, if I get the cheapest 4060 Ti from LDLC ( major french hardware retailer ), without the country taxes, it drops from 499 to 416€. \n\nWhich is great, except, I need to deliver it and it's like 40€, takes 2 weeks to get here and then, I need to pay overseas taxes which are about 20%. So for a 416€, I'm paying about 540€. My local store is at 519€ and can deliver it in a day or two, for 10 more. \n\nIt's just a fucked up situation for me to upgrade.",
      "I think that even if refreshed 4000 series are coming up, I wouldn't be able to get one but at least it could drag the current price down a bit. \n\nFor the VRAM capacity, I don't mind it that much since 12GB would probably be sufficient. It's more based on the render performance. The 4060 Ti is basically at a 2080 Ti to 3080 level of performance in rendering in Blender for example. Almost 2 times the performance of the 3060. But is it worth at 200 more euros than the 3060 ? Considering the 4060 Ti being a crippled card.",
      "I didn't buy anything for the moment. I changed my mind since we're so close to the release of the next gen. Currently, I think I'll get a 5070 with the money saved for the time being. Hopefully, the 5070 will get at least a 16GB buffer to get decent performance in both rendering, game dev and 1440p/4K gaming",
      "I'm not talking about the 8GB variant of the 4060 Ti, which is... atrocious at best.  \nEven with the terrible memory bus, the 16GB one will definitely max out textures, even at 4K, for some time. \n\nBut currently, I'm more focused on the productivity side of things, where the 4060 Ti is way more relatively effective.",
      "Problem is : 670€\n\nThe price difference between both cards isn't 50 bucks like in other countries. Here, the 4070 is at the very least, 150 more than the 4060 Ti. At this price, the 4070 is just terrible anyway."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "4070ti super",
      "4070ti",
      "rtx 4070ti",
      "rtx 4070ti super"
    ],
    "title": "NVIDIA GeForce RTX 4070Ti SUPER is 8% faster on average than RTX 4070Ti in 3DMark tests - VideoCardz.com",
    "selftext": "",
    "comments": [
      "Welp, the most promising spec is the bump from 12 to 16GB GDDR6X. That helps a lot at 4K.",
      "Nvidia just making people comfortable with $1k cards with all these shenanigans",
      "The 4070ti super is what the 4070ti should have been all along if they just hadn’t gimped it’s Vram down to 12gb",
      "Just skip two generations.\n\nPointless and wasteful to upgrade every year.",
      "Not sure about gaming but when rendering large 3D scenes on 8GB and 12GB, there is a very noticeable difference. Renders are way ~~faster~~ stable on 12 GB cards.",
      "So the 4080 Super is gonna be even more attractive if this is the case.",
      "![gif](giphy|10JhviFuU2gWD6)",
      "There’s no such thing as a future proofed GPU. The 3090 TI released for 2000 dollars in 2022 and in 2023 it had a similar performance across 4k benchmarks by a 850 dollar GPU with the 4070TI. Whatever you buy now, including the 4090, is not going to compare in performance to the 5000 series. The 4080 Super for 1000 dollars in 2024 is going to feel like a bad deal in 2025. It happened with the 30 series and the 40 series now.\n\nThat argument really grinds my gears for some reason",
      "I do texture work and honestly the 3060 12gb is such a lifesaver budget option. Now I want to upgrade but throwing so much money at something to have the same vram is kinda unreasonable - vram bump is literally the only reason I'm holding to get a 4070ti super instead of any other 4070. The 4060ti 16gb is in many ways barely an upgrade from the 3060 to be worth so much money, and the 4080 is just out of my absolute budget limit. If I didn't read so many people having issues with AMD cards and substance painter and thr Adobe 3d suite in general I'd have gotten a 7900xtx.\nI guess I could get a 3090 too, but then it becomes an issue on the gaming part of my use case, throwing so much money at something to not get the latest tech is also hard to justify. Jfc how incredibly annoying nvidia's lineup is and has been this whole generation",
      "I was hoping for similar gains like the  4070 super has over 4070",
      "I mean…..you already have a 4070ti. You were not even close to the target market for the Supers.",
      ">The 4080 is what the 4070\n\nlol no. Nothing on the 4080 makes it a 70 non ti series card. People here are really delusional if these are the expectations",
      "yeah no shit sherlock.",
      "There is no point for current 4070 Ti owners to upgrade to this anyway, the minimum is pretty much an RTX 5070 or above.",
      "You’re right. I’m looking at this as NVIDIA trying out “make good” with buyers. From specs, to VRAM, to the 4080 basically just getting a more realistic price… these should have been the specs and pricing from day one.\n\nBetter late than never I suppose. Still pricey as hell to be a PC gamer these days.",
      "I still believe the 3070 being 8gb was the most scummy move nvidia has made in recent years. 1070 was 8gb and that card came out literally 4 years prior to 30 series.\n\nNvidia was crafty about it. Can't have a mid range card that performs well for too long, so they hamstrung the vram to \"encourage\" upgrading sooner. There is literally no other feasible reason to keep the vram so low on that card. Even amd was offering 12gb on similar cards at a cheaper price point.",
      "You can keep that card until the 7000 series.",
      "Thing is the 4080 was always horribly priced for what it had. We'll have to see how the 4080 Super compares in benchmarks.",
      "It helps around 8% according to the 2160p benchmark.",
      "Yeah I'm confused by people with high-end 3000 cards or even 4000 cards going \"ehhhh it's not worth the upgrade\" when it's not meant to be. I'm sitting here with a 6gb 2060 though getting excited about these Supers"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "rtx 4070",
      "4070",
      "4070ti super",
      "4070ti",
      "4070 ti",
      "rtx 4070 ti"
    ],
    "title": "The most overkilled and interesting 4070Ti : the Galax RTX 4070 Ti OC Lab (PCB pics included)",
    "selftext": "I got myself something very rare outside of China that will complete my collection. This 4070Ti has a pcb that is even better than the 4070Ti Super and 4080 Super HOF.\nIt’s also to this day the fastest 4070Ti ever when overclocked (even using its aircooler). \nMore pics and benchmarks results can be found on my twitter @bl4ckdot",
    "comments": [
      "the cooler is so goddamn ugly lol\n\n&#x200B;\n\nwhite pcb is sick tho",
      "Because I have a 4090 for that task ? The point of this card isn't the performance / price ratio. It's how much one can push a specific GPU.",
      "Why get this when its nowhere near the shittiest 4080 super?",
      "Lol OP really said their Ferrari is in the shop lmao",
      "I don't need justification, specially when I collect stuff. I post here to share what people may never have seen. I'll never say \"here what you should buy, trust\"",
      "My Bad, I didnt really interpret it that way.\n\nThanks for clarifying.",
      "GT1030 :D I mainly use that card to display when benching CPU.\n\nhttps://preview.redd.it/qxsidwcodzic1.jpeg?width=3024&format=pjpg&auto=webp&s=093a4ba04974dc38243bf040390cedaebe3257ee",
      "Here what it looks like on Timespy : [NVIDIA GeForce RTX 4070 Ti video card benchmark result - Intel Core i9 processor 14900K,ASUSTeK COMPUTER INC. ROG MAXIMUS Z790 APEX ENCORE (3dmark.com)](https://www.3dmark.com/spy/45512120)",
      "Lmao the little guy in the last pic. what card is that one?",
      "Yep can go up to 366W with stock bios",
      "Get that brick out of here. Simping for the 1030",
      "7300 CNY to my door. So around 950€ shipped from China",
      "You collect downvotes, OP collects GPUs - to each their own",
      "I get it, man. Why do we do anything that we do if not out of interest that brings us joy. I think it’s pretty cool 🤙",
      "That's a crazy good score for a 4070ti, almost matches my 7900XT in raster.",
      "Pretty sure this one will draw more than 285W.",
      "I love a good burn 🔥 if I was rich I would be doing the same thing as OP",
      "Exactly my mindset when looking at the pics lol",
      "You should know with your cookie cutter all white copy paste build 🤣",
      "Roughly 55°C while benching"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "4070ti super",
      "4070ti"
    ],
    "title": "Cyberpunk performance on 4070Ti Super OC + 14700k",
    "selftext": "I overclocked the dual fan ventus because on stock it was getting to only 65 degrees celsius max! Clock: +150 Memory:+950 stock power",
    "comments": [
      "I'm mean that cool and all but I'm pretty sure I can average 9.6 FPS with my 3060 with the same settings.",
      "Yall think a 30hz monitor overkill for that 9.6 fps?",
      "This is with path tracing activated, the most taxing raytracing available.",
      "Don’t suppose you’ve been able to test 4K?",
      "I always find it so wholesome and cute to see someone test their new GPU. Enjoy it mate.",
      "THIS is the reason why I say we’re not ready for 4k yet.",
      "This is with path tracing",
      "Turn on path tracing now and then compare :)",
      "I’m so jealous of you 4000 series owners. Holding off on playing Phantom Liberty until I get a 5090 so I can pump it to the max and really be blown away with the graphics path tracing offers. Tried the FG mod on my 3080 and at 1440p it’s ok, but feels like having major frame pacing issues.",
      "Nice. I went for dlaa and Raytracing psycho instead of dlss quality and Pathtracing. Dlaa makes details in the game look so much better imo. Give it a try.",
      "Because people want to maximize visuals and performance at the same time. Frame generation might be AI but it 100% works well.",
      "Getting ~65fps for the benchmark on 4k ultra with the same card paired with ryzen 7600",
      "Bro got cooked he didnt deserve this 😭",
      "This is 1440p",
      "sub 1080p actually",
      "Highly dependent on your settings. Guy there posted 83 frames with his 4070Ti, I get 50ish with a 4090.\n\nThis \"test\" is pretty much entirely meaningless unless you're comparing against the exact same settings across the board.",
      "I agree. 1440p high refresh rate is still demanding even for powerful Gpus like 4070Ti Super.\n\nWe need more power for 4k.",
      "I mean if you look at the first picture, it's literally there.",
      "Did you read that as 96? Because honestly I was getting disappointed that noone that responded had fell for my decimal point joke.",
      "I completely disagree. It’s not just a style change. The lighting and shadows on the world and character models completely makes the game feel more alive."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "rtx 4070",
      "4070",
      "4070 ti super",
      "4070 ti",
      "rtx 4070 ti",
      "rtx 4070 ti super"
    ],
    "title": "nVidia GeForce RTX 5090 Meta Review",
    "selftext": "- compilation of 17 launch reviews with ~6260 gaming benchmarks at 1080p, 1440p, 2160p\n- only benchmarks at real games compiled, not included any 3DMark & Unigine benchmarks\n- geometric mean in all cases\n- standard raster performance without ray-tracing and/or DLSS/FSR/XeSS\n- extra ray-tracing benchmarks (mostly without upscaler) after the standard raster benchmarks\n- stock performance on (usually) reference/FE boards, no overclocking\n- factory overclocked cards were normalized to reference clocks/performance, but just for the overall performance average (so the listings show the original performance result, just the performance index has been normalized)\n- missing results were interpolated (for a more accurate average) based on the available & former results\n- performance average is (some) weighted in favor of reviews with more benchmarks\n- all reviews should have used newer drivers for _all_ cards\n- power draw numbers based on a couple of reviews, always for the graphics card only\n- current retailer prices according to Geizhals (DE/Germany, on Jan 27) and Newegg (USA, on Jan 27) for immediately available offers\n- for the 5090 retail prices of $2200 and 2500€ were assumed\n- for discontinued graphics cards a typical retail price was used from the time they were sold (incl. 4080 & 4090)\n- performance/price ratio (higher is better) for 2160p raster performance and 2160p ray-tracing performance\n- for the full results and some more explanations check [3DCenter's launch analysis](https://www.3dcenter.org/artikel/launch-analyse-nvidia-geforce-rtx-5090)\n\n&nbsp;\n\nRaster 2160p|2080Ti|3090|3090Ti|7900XT|7900XTX|4070TiS|4080|4080S|4090|5090\n|:--|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|\n&nbsp;|Turing 11GB|Ampere 24GB|Ampere 24GB|RDNA3 20GB|RDNA3 24GB|Ada 16GB|Ada 16GB|Ada 16GB|Ada 24GB|Blackwell 32GB\nComputerBase|-|-|-|49.7%|58.3%|52.3%|-|59.9%|80.8%|_100%_\nCowcotland|-|-|-|51.5%|61.4%|53.8%|58.5%|59.6%|77.8%|_100%_\nEurogamer|29.9%|-|49.3%|50.9%|58.9%|-|56.4%|57.5%|76.4%|_100%_\nGamersNexus|27.5%|41.2%|48.4%|48.0%|60.2%|-|55.1%|-|75.0%|_100%_\nHardware&Co|-|45.7%|-|49.5%|57.9%|-|-|59.8%|78.3%|_100%_\nHardwareluxx|-|44.1%|50.0%|49.7%|57.4%|50.0%|58.2%|59.5%|76.9%|_100%_\nIgor's Lab|-|-|-|50.2%|61.0%|51.2%|-|60.%|79.6%|_100%_\nKitGuru|-|-|-|52.1%|61.0%|49.8%|-|58.6%|77.7%|_100%_\nLinus|28.0%|45.8%|49.2%|51.7%|60.2%|-|-|57.6%|78.0%|_100%_\nOverclocking|-|-|-|53.8%|63.6%|-|59.6%|60.4%|77.9%|_100%_\nPCGH|-|-|-|50.5%|60.2%|48.5%|-|57.6%|78.0%|_100%_\nPurePC|-|-|49.0%|49.4%|58.2%|-|58.6%|-|77.4%|_100%_\nQuasarzone|-|44.0%|48.5%|-|57.3%|-|57.1%|58.9%|78.5%|_100%_\nSweClockers|-|-|-|-|59.2%|-|58.1%|-|79.7%|_100%_\nTechPowerUp|28%|43%|49%|48%|57%|49%|57%|58%|74%|_100%_\nTechSpot|-|-|-|51.1%|61.3%|51.1%|57.7%|59.1%|78.8%|_100%_\nTweakers|-|43.6%|-|51.4%|59.3%|49.2%|58.8%|59.3%|76.5%|_100%_\n**avg 2160p Raster Perf.**|**~29%**|**44.1%**|**49.0%**|**50.1%**|**59.3%**|**50.0%**|**57.6%**|**58.8%**|**77.7%**|**_100%_**\n\n&nbsp;\n\nRaster 1440p|2080Ti|3090|3090Ti|7900XT|7900XTX|4070TiS|4080|4080S|4090|5090\n|:--|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|\n&nbsp;|Turing 11GB|Ampere 24GB|Ampere 24GB|RDNA3 20GB|RDNA3 24GB|Ada 16GB|Ada 16GB|Ada 16GB|Ada 24GB|Blackwell 32GB\nComputerBase|-|-|-|58.2%|65.8%|60.1%|-|68.2%|86.3%|_100%_\nCowcotland|-|-|-|65.0%|72.7%|62.9%|69.9%|71.3%|86.0%|_100%_\nEurogamer|33.8%|-|53.9%|55.9%|65.0%|-|63.1%|63.7%|80.9%|_100%_\nGamersNexus|31.3%|45.1%|52.4%|55.5%|66.1%|-|63.7%|-|81.9%|_100%_\nHardware&Co|-|51.1%|-|58.1%|66.0%|-|-|67.8%|84.4%|_100%_\nHardwareluxx|-|49.0%|54.8%|57.7%|65.9%|56.5%|66.1%|67.4%|82.2%|_100%_\nIgor's Lab|-|-|-|58.0%|68.3%|58.5%|-|68.2%|83.8%|_100%_\nKitGuru|-|-|-|57.2%|65.1%|54.9%|-|63.7%|81.7%|_100%_\nLinus|32.6%|50.8%|54.1%|60.2%|68.5%|-|-|65.7%|84.5%|_100%_\nPCGH|-|-|-|56.0%|65.6%|53.8%|-|63.6%|82.6%|_100%_\nPurePC|-|-|53.0%|55.1%|63.7%|-|64.5%|-|82.1%|_100%_\nQuasarzone|-|48.0%|51.9%|-|63.3%|-|64.1%|66.1%|83.3%|_100%_\nSweClockers|-|-|-|-|64.8%|-|64.6%|-|82.6%|_100%_\nTechPowerUp|33%|49%|55%|57%|65%|58%|66%|67%|83%|_100%_\nTechSpot|-|-|-|62.5%|72.4%|62.5%|70.8%|71.9%|89.1%|_100%_\nTweakers|-|48.7%|-|59.8%|66.4%|57.2%|67.7%|67.9%|82.6%|_100%_\n**avg 1440p Raster Perf.**|**~33%**|**48.9%**|**54.1%**|**57.8%**|**66.3%**|**57.3%**|**65.6%**|**66.8%**|**83.8%**|**_100%_**\n\n&nbsp;\n\nRaster 1080p|2080Ti|3090|3090Ti|7900XT|7900XTX|4070TiS|4080|4080S|4090|5090\n|:--|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|\n&nbsp;|Turing 11GB|Ampere 24GB|Ampere 24GB|RDNA3 20GB|RDNA3 24GB|Ada 16GB|Ada 16GB|Ada 16GB|Ada 24GB|Blackwell 32GB\nCowcotland|-|-|-|77.4%|83.1%|75.0%|80.6%|81.5%|93.5%|_100%_\nEurogamer|38.8%|-|63.1%|66.2%|73.0%|-|70.7%|71.3%|85.4%|_100%_\nGamersNexus|36.0%|51.0%|58.4%|64.3%|75.3%|-|74.3%|-|89.9%|_100%_\nHardwareluxx|-|54.4%|60.0%|63.8%|71.8%|64.3%|71.0%|72.5%|88.0%|_100%_\nIgor's Lab|-|-|-|64.6%|74.1%|67.2%|-|76.8%|90.1%|_100%_\nKitGuru|-|-|-|61.5%|68.9%|59.7%|-|68.4%|84.8%|_100%_\nPCGH|-|-|-|61.6%|70.4%|59.9%|-|69.3%|87.0%|_100%_\nPurePC|-|-|56.0%|59.7%|67.6%|-|69.4%|-|86.6%|_100%_\nQuasarzone|-|53.3%|56.9%|-|68.8%|-|71.5%|73.6%|88.1%|_100%_\nSweClockers|-|-|-|-|71.1%|-|71.4%|-|87.6%|_100%_\nTechPowerUp|40%|56%|62%|65%|73%|67%|75%|76%|90%|_100%_\nTechSpot|-|-|-|75.0%|83.3%|77.5%|84.3%|85.3%|99.0%|_100%_\nTweakers|-|54.7%|-|66.8%|72.9%|65.0%|76.6%|76.5%|86.8%|_100%_\n**avg 1080p Raster Perf.**|**~38%**|**54.6%**|**59.5%**|**64.7%**|**72.5%**|**64.7%**|**73.0%**|**74.0%**|**88.5%**|**_100%_**\n\n&nbsp;\n\nRayTracing 2160p|2080Ti|3090|3090Ti|7900XT|7900XTX|4070TiS|4080|4080S|4090|5090\n|:--|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|\n&nbsp;|Turing 11GB|Ampere 24GB|Ampere 24GB|RDNA3 20GB|RDNA3 24GB|Ada 16GB|Ada 16GB|Ada 16GB|Ada 24GB|Blackwell 32GB\nComputerBase|-|-|-|45.7%|52.8%|54.4%|-|62.6%|82.2%|_100%_\nCowcotland|-|-|-|39.1%|45.7%|48.9%|54.3%|56.0%|77.2%|_100%_\nEurogamer|24.3%|-|46.3%|38.3%|44.3%|-|53.8%|54.8%|76.3%|_100%_\nGamersNexus|22.6%|37.2%|44.0%|33.3%|41.4%|-|54.3%|-|74.3%|_100%_\nHardwareluxx|-|38.1%|43.6%|29.0%|32.5%|53.3%|60.3%|61.3%|81.4%|_100%_\nKitGuru|-|-|-|34.5%|39.9%|46.9%|-|55.9%|77.5%|_100%_\nLinus|22.2%|36.5%|39.7%|27.0%|30.2%|-|-|54.0%|76.2%|_100%_\nOverclocking|-|-|-|40.3%|48.5%|-|60.4%|61.6%|78.3%|_100%_\nPCGH|-|-|-|38.6%|45.6%|50.3%|-|59.3%|79.1%|_100%_\nPurePC|-|-|43.0%|29.1%|34.5%|-|55.4%|-|77.2%|_100%_\nQuasarzone|-|40.3%|43.5%|-|-|-|57.5%|59.3%|78.5%|_100%_\nSweClockers|-|-|-|-|33.8%|-|54.8%|-|79.3%|_100%_\nTechPowerUp|21%|41%|45%|34%|40%|49%|57%|58%|76%|_100%_\nTweakers|-|37.1%|-|35.7%|40.9%|46.0%|55.4%|55.9%|76.1%|_100%_\n**avg 2160p RayTr Perf.**|**~23%**|**39.5%**|**44.3%**|**34.9%**|**40.8%**|**49.0%**|**56.6%**|**57.8%**|**77.7%**|**_100%_**\n\n&nbsp;\n\nRayTracing 1440p|2080Ti|3090|3090Ti|7900XT|7900XTX|4070TiS|4080|4080S|4090|5090\n|:--|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|\n&nbsp;|Turing 11GB|Ampere 24GB|Ampere 24GB|RDNA3 20GB|RDNA3 24GB|Ada 16GB|Ada 16GB|Ada 16GB|Ada 24GB|Blackwell 32GB\nComputerBase|-|-|-|51.7%|58.6%|60.1%|-|68.2%|87.2%|_100%_\nCowcotland|-|-|-|46.0%|50.3%|51.5%|61.3%|62.6%|80.4%|_100%_\nEurogamer|28.4%|-|50.5%|43.3%|49.0%|-|59.6%|60.6%|80.6%|_100%_\nHardware&Co|-|40.8%|-|30.1%|34.4%|-|-|60.0%|79.2%|_100%_\nHardwareluxx|-|43.3%|48.4%|35.4%|39.0%|60.3%|67.7%|68.9%|85.7%|_100%_\nKitGuru|-|-|-|38.1%|43.4%|51.5%|-|60.5%|79.8%|_100%_\nLinus|22.5%|40.5%|43.2%|29.7%|34.2%|-|-|59.5%|79.3%|_100%_\nPCGH|-|-|-|45.3%|52.2%|56.7%|-|66.0%|84.3%|_100%_\nPurePC|-|-|46.2%|32.9%|38.3%|-|59.2%|-|79.8%|_100%_\nSweClockers|-|-|-|-|37.9%|-|61.3%|-|82.6%|_100%_\nTechPowerUp|29%|45%|50%|39%|45%|55%|63%|64%|80%|_100%_\nTechSpot|-|-|-|33.3%|38.2%|60.2%|69.1%|70.7%|85.4%|_100%_\nTweakers|-|41.0%|-|39.2%|44.3%|51.5%|61.6%|61.8%|80.2%|_100%_\n**avg 1440p RayTr Perf.**|**~27%**|**43.8%**|**48.2%**|**38.1%**|**43.4%**|**54.3%**|**62.5%**|**63.5%**|**81.9%**|**_100%_**\n\n&nbsp;\n\nRayTracing 1080p|2080Ti|3090|3090Ti|7900XT|7900XTX|4070TiS|4080|4080S|4090|5090\n|:--|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|\n&nbsp;|Turing 11GB|Ampere 24GB|Ampere 24GB|RDNA3 20GB|RDNA3 24GB|Ada 16GB|Ada 16GB|Ada 16GB|Ada 24GB|Blackwell 32GB\nCowcotland|-|-|-|55.2%|61.2%|68.7%|74.6%|76.1%|90.3%|_100%_\nEurogamer|31.9%|-|54.0%|48.1%|53.7%|-|65.5%|66.7%|85.1%|_100%_\nHardwareluxx|-|49.5%|54.3%|41.4%|45.4%|66.0%|71.6%|72.6%|89.0%|_100%_\nKitGuru|-|-|-|41.5%|46.5%|56.0%|-|64.4%|82.1%|_100%_\nPCGH|-|-|-|51.0%|57.7%|62.4%|-|71.5%|87.7%|_100%_\nPurePC-|-|49.4%|36.3%|41.4%|-|64.5%|-|72.1%|_100%_\nSweClockers|-|-|-|-|44.2%|-|69.9%|-|88.3%|_100%_\nTechPowerUp|32%|50%|54%|44%|50%|61%|69%|70%|84%|_100%_\nTechSpot|-|-|-|36.5%|41.9%|66.9%|75.0%|76.4%|87.8%|_100%_\nTweakers|-|44.7%|-|42.4%|47.1%|56.1%|66.5%|67.4%|82.4%|_100%_\n**avg 1080p RayTr Perf.**|**~32%**|**49.4%**|**53.7%**|**44.4%**|**49.9%**|**61.4%**|**69.1%**|**70.3%**|**85.1%**|**_100%_**\n\n&nbsp;\n\nFG/MFG @ 2160p|4090|4090 + FG|5090|5090 + FG|5090 + MFGx3|5090 + MFGx4\n|:--|:--:|:--:|:--:|:--:|:--:|:--:|\nComputerBase|82%|144%|_100%_|183%|263%|333%\nHardwareluxx|75%|133%|_100%_|177%|253%|318%\nTechPowerUp|77%|130%|_100%_|-|-|310%\naverage pure FG/MFG gain|&nbsp;|+74% (vs&nbsp;4090)|&nbsp;|+78% (vs&nbsp;5090)|+154% (vs&nbsp;5090)|+220% (vs&nbsp;5090)\n\n&nbsp;\n\nAt a glance|2080Ti|3090|3090Ti|7900XT|7900XTX|4070TiS|4080|4080S|4090|5090\n|:--|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|\n&nbsp;|Turing 11GB|Ampere 24GB|Ampere 24GB|RDNA3 20GB|RDNA3 24GB|Ada 16GB|Ada 16GB|Ada 16GB|Ada 24GB|Blackwell 32GB\navg 2160p Raster Perf.|~29%|44.1%|49.0%|50.1%|59.3%|50.0%|57.6%|58.8%|77.7%|_100%_\navg 1440p Raster Perf.|~33%|48.9%|54.1%|57.8%|66.3%|57.3%|65.6%|66.8%|83.8%|_100%_\navg 1080p Raster Perf.|~38%|54.6%|59.5%|64.7%|72.5%|64.7%|73.0%|74.0%|88.5%|_100%_\navg 2160p RayTr Perf.|~23%|39.5%|44.3%|34.9%|40.8%|49.0%|56.6%|57.8%|77.7%|_100%_\navg 1440p RayTr Perf.|~27%|43.8%|48.2%|38.1%|43.4%|54.3%|62.5%|63.5%|81.9%|_100%_\navg 1080p RayTr Perf.|~32%|49.4%|53.7%|44.4%|49.9%|61.4%|69.1%|70.3%|85.1%|_100%_\nTDP|260W|350W|450W|315W|355W|285W|320W|320W|450W|575W\nReal Power Draw|272W|359W|462W|309W|351W|277W|297W|302W|418W|509W\nEnergy Eff. (2160p&nbsp;Raster)|54%|63%|54%|83%|86%|92%|99%|99%|95%|_100%_\nMSRP|$1199|$1499|$1999|$899|$999|$799|$1199|$999|$1599|$1999\nRetail GER|~1100€|~1700€|~2100€|689€|899€|849€|~1150€|1074€|~1750€|~2500€\nPerf/Price GER 2160p&nbsp;Raster|65%|65%|58%|182%|165%|147%|125%|137%|111%|_100%_\nPerf/Price GER 2160p&nbsp;RayTr|52%|58%|53%|127%|113%|144%|123%|134%|111%|_100%_\nRetail US|~$1200|~$1500|~$2000|$650|$870|$900|~1200|~$1000|~$1600|~$2200\nPerf/Price US 2160p&nbsp;Raster|52%|65%|54%|170%|150%|122%|106%|129%|107%|_100%_\nPerf/Price US 2160p&nbsp;RayTr|42%|58%|49%|118%|103%|120%|104%|127%|107%|_100%_\n\n&nbsp;\n\nPerf. Gain of 5090|Raster 2160p|Raster 1440p|Raster 1080p|RayTr. 2160p|RayTr. 1440p|RayTr. 1080p\n|:--|:--:|:--:|:--:|:--:|:--:|:--:|\nGeForce RTX 2080 Ti|+249%|+205%|+162%|+335%|+272%|+213%\nGeForce RTX 3090|+127%|+104%|+83%|+153%|+128%|+103%\nGeForce RTX 3090 Ti|+90%|+85%|+68%|+126%|+108%|+86%\nRadeon RX 7900 XT|+100%|+73%|+55%|+187%|+163%|+125%\nRadeon RX 7900 XTX|+69%|+51%|+38%|+145%|+130%|+100%\nGeForce RTX 4070 Ti Super|+100%|+74%|+54%|+104%|+84%|+63%\nGeForce RTX 4080|+73%|+52%|+37%|+77%|+60%|+45%\nGeForce RTX 4080 Super|+70%|+50%|+35%|+73%|+57%|+42%\nGeForce RTX 4090|+28.6%|+19.4%|+12.9%|+28.6%|+22.2%|+17.5%\n\nNote: Performance improvement of the GeForce RTX 5090 compared to the other cards. The respective other card is then 100%.\n\n&nbsp;\n\n&nbsp;|nVidia FE|Asus Astral OC|MSI Suprim OC|MSI Suprim Liquid SOC|Palit GameRock\n|:--|:--:|:--:|:--:|:--:|:--:|\nCooling|Air, 2 Fans|Air, 4 Fans|Air, 3 Fans|Hybrid: Air & Water|Air, 3 Fans\nDimensions|DualSlot, 30.0 x 14.0cm|QuadSlot, 35.0 x 15.0cm|QuadSlot, 36.0 x 15.0cm|TripleSlot, 28.0 x 15.0cm|QuadSlot, 33.0 x 14.5cm\nWeight|1814g|3038g|2839g|2913g|2231g\nClocks|2017/2407 MHz|2017/2580 MHz|2017/2512 MHz|2017/2512 MHz|2017/2407 MHz\nReal Clock (avg/median)|2684 MHz / 2700 MHz|2809 MHz / 2857 MHz|2790 MHz / 2842 MHz|2821 MHz / 2865 MHz|2741 MHz / 2790 MHz\nTDP|575W (max: 600W)|600W (max: 600W)|575W (max: 600W)|600W (max: 600W)|575W (max: 575W)\nRaster (2160p, 1440p, 1080p)|_100%_|+5% / +3% / +2%|+3% / +3% / +2%|+4% / +4% / +3%|+2% / +2% / +2%\nRayTr. (2160p, 1440p, 1080p)|_100%_|+4% / +4% / +5%|+3% / +3% / +3%|+4% / +5% / +4%|+3% / +2% / +2%\nTemperatures (GPU/Memory)|77°C / 94°C|65°C / 76°C|75°C / 80°C|61°C / 74°C|74°C / 82°C\nLoundness|40.1 dBA|39.3 dBA|28.4 dBA|31.2 dBA|39.8 dBA\nReal Power Draw (Idle/Gaming)|30W / 587W|29W / 621W|24W / 595W|24W / 609W|40W / 620W\nPrice|$1999|allegedly $2800|allegedly $2400|allegedly $2500|allegedly $2200\nSource:|[TPU review](https://www.techpowerup.com/review/nvidia-geforce-rtx-5090-founders-edition/)|[TPU review](https://www.techpowerup.com/review/asus-geforce-rtx-5090-astral/)|[TPU review](https://www.techpowerup.com/review/msi-geforce-rtx-5090-suprim/)|[TPU review](https://www.techpowerup.com/review/msi-geforce-rtx-5090-suprim-liquid/)|[TPU review](https://www.techpowerup.com/review/palit-geforce-rtx-5090-gamerock/)\n\nNote: The values of the default BIOS were noted throughout. In addition, the graphics card manufacturers also offer Quiet BIOSes (Asus & Palit) and Performance BIOSes (MSI).         \n\n&nbsp;\n\nList of GeForce RTX 5090 reviews evaluated for this performance analysis:\n\n- [ComputerBase](https://www.computerbase.de/artikel/grafikkarten/nvidia-geforce-rtx-5090-test.91081/)\n- [Cowcotland](https://www.cowcotland.com/articles/4480/test-nvidia-geforce-rtx-5090-fe-un-nouveau-monstre-vert-debarque.html)\n- [Eurogamer](https://www.eurogamer.net/digitalfoundry-2025-nvidia-geforce-rtx-5090-review)\n- [Gamers Nexus](https://www.youtube.com/watch?v=VWSlOC_jiLQ)\n- [Hardware & Co](https://hardwareand.co/dossiers/gpu/test-de-la-geforce-rtx-5090-blackwell-et-son-neural-rendering-sont-ils-revolutionnaires)\n- [Hardwareluxx](https://www.hardwareluxx.de/index.php/artikel/hardware/grafikkarten/65361-die-geforce-rtx-5090-founders-edition-im-test.html)\n- [Igor's Lab](https://www.igorslab.de/nvidia-geforce-rtx-5090-founders-edition-im-test-das-600-watt-kraftpaket-im-gaming-und-labortest/)\n- [KitGuru](https://www.kitguru.net/components/graphic-cards/dominic-moass/nvidia-rtx-5090-review-ray-tracing-dlss-4-and-raw-power-explored/)\n- [Linus Tech Tips](https://www.youtube.com/watch?v=Q82tQJyJwgk)\n- [Overclocking](https://overclocking.com/test-nvidia-rtx-5090-founders-edition/)\n- [PC Games Hardware](https://www.pcgameshardware.de/Geforce-RTX-5090-Grafikkarte-281029/Tests/Reviews-Benchmarks-Vergleich-RTX-4090-1463971/)\n- [PurePC](https://www.purepc.pl/nvidia-geforce-rtx-5090-recenzja-test-wydajnosci-premiera-blackwell)\n- [Quasarzone](https://quasarzone.com/bbs/qc_bench/views/92822)\n- [SweClockers](https://www.sweclockers.com/test/40483-nvidia-geforce-rtx-5090-utmarkt-kort-for-dig-som-har-rad)\n- [TechPowerUp](https://www.techpowerup.com/review/nvidia-geforce-rtx-5090-founders-edition/)\n- [TechSpot](https://www.techspot.com/review/2944-nvidia-geforce-rtx-5090/)\n- [Tweakers](https://tweakers.net/reviews/12864/nvidia-geforce-rtx-5090-kunstmatig-en-krachtig.html)\n\n&nbsp;\n\nSource: [3DCenter.org](https://www.3dcenter.org/artikel/launch-analyse-nvidia-geforce-rtx-5090)",
    "comments": [
      "Thanks a lot for your effort!\n\nI was interested in the 1440p (+RT) performance and now I'm glad I bought the 4090 back then.",
      "I am really puzzled by RT uplift from 4090 being exactly in line with raster uplift. Considering change for RT cores is, as usual very noticeably bigger than change to CUDA - that seems bizarre.",
      "Sure. For every new GPU, since many years already.",
      "It’s where I’m sitting too. 6000 series it is.",
      "I just looked at the 3090 numbers and assumed it is around 10% worse. It usually splits the difference between the 2080 Ti and 3090, but a little closer to the 3090 in performance.",
      "You have to reemmber that this isnt a new node, there hasnt been any serious architectural improvements made toward rt either. So the uplift is linear to how much more cores there are. The 5090 is really a 4090ti",
      "3080?",
      "The value of the 4090 is amazing - though I wouldn't count myself out if presented with an opportunity to buy a 5090 at MSRP.  I got my FE through Nvidia's Priority Access program, where they randomly asked anyone who had an older nvidia card if they wanted to buy the 4090, hoping they do that again with the 5090 and lightning strikes twice.\n\nI hate reselling stuff but it's what-you-have-to-do with cards being so damn expensive - but I got to say the resell value of the 4090 I think is going to be tremendous even after the new series comes out.",
      "\\>there hasnt been any serious architectural improvements made toward rt either.\n\nThere was at least claimed doubling of intersection calcs, just the same way it was doubled in Ampere and Ada.",
      "Great work. Can you do the same for 5080 when it drops?",
      "It’s obvious that it makes little sense for someone with a 4090 to upgrade, but since I cannot buy a 4090 new, my only option is a 5090. As such, coming from a 3080Ti, I am happy with the performance of the 5090, and a bit less so with the price. Still a worthwhile upgrade for me.",
      "You're reading it backwards. It's a 23-27% gain, where the 4090 runs at 73-77% performance relative to the 5090",
      "Theres probably very few, if any. Benchmarks usually use parts that will not cause any bottleneck, and right now the 9800x3d is the fastest gaming cpu, this is done so that we can see as close to the pure performance of the cards as possible",
      "a +73-77% perf gain at 4k from 4080. This is very temping!",
      "I especially love seeing the meta comparison of the fan noise. Folks out there going crazy at how loud the FE is, and there’s actually a lot of other cards at the same level. \n\nWent back and looked up my 3080 stats and it’s right around 40db at max, too.",
      "Embargo is not lifted for 5080",
      "👑",
      "I think you're correct and the commend assumed you meant \"4090\" and were reading it wrong? That's what I am getting from that table too",
      "Ah!!! My apologies, I was looking at the 4090 in the table since that showed 77%. What's weird is in that same table it showed the 4080 at like 55-58% performance compared to the 5090. So conflicting data but still decent gains.",
      "Is there a post like this for the 5080?"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "rtx 4070",
      "4070",
      "4070 super",
      "rtx 4070 super",
      "4070ti",
      "4070 ti",
      "rtx 4070 ti"
    ],
    "title": "nVidia GeForce RTX 5070 Ti Meta Review",
    "selftext": "- compilation of 13 launch reviews with ~7220 gaming benchmarks at 1080p, 1440p, 2160p\n- only benchmarks at real games compiled, not included any 3DMark & Unigine benchmarks\n- geometric mean in all cases\n- standard raster performance without ray-tracing and/or DLSS/FSR/XeSS\n- extra ray-tracing benchmarks (mostly without upscaler) after the standard raster benchmarks\n- stock performance on (usually) reference/FE boards, no overclocking\n- factory overclocked cards were normalized to reference clocks/performance, but just for the overall performance average (so the listings show the original performance result, just the performance index has been normalized)\n- missing results were interpolated (for a more accurate average) based on the available & former results\n- performance average is (some) weighted in favor of reviews with more benchmarks\n- all reviews should have used newer drivers for _all_ cards\n- power draw numbers based on a couple of reviews, always for the graphics card only\n- performance/price ratio (higher is better) for 1440p raster performance and 1440p ray-tracing performance\n- for the full results and some more explanations check [3DCenter's launch analysis](https://www.3dcenter.org/artikel/launch-analyse-nvidia-geforce-rtx-5070-ti)\n\n&nbsp;\n\nRaster 2160p|7800XT|7900XT|79XTX|4070S|4070Ti|407TiS|4080|4080S|5070Ti|5080\n|:--|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|\n&nbsp;|RDNA3 16GB|RDNA3 20GB|RDNA3 24GB|Ada 12GB|Ada 12GB|Ada 16GB|Ada 16GB|Ada 16GB|Blackw. 16GB|Blackw. 16GB\nCBase|63.0%|84.3%|98.8%|74.4%|-|89.3%|-|102.4%|_100%_|114.8%\nHW&Co|67.1%|85.8%|100.1%|-|-|88.8%|-|103.5%|_100%_|115.4%\nIgor's|69.1%|87.8%|106.7%|74.5%|-|89.6%|-|105.2%|_100%_|115.3%\nKitGuru|69.4%|93.5%|109.4%|76.6%|82.0%|89.3%|-|105.1%|_100%_|118.0%\nPCGH|-|90.2%|107.7%|-|-|86.8%|-|103.0%|_100%_|117.3%\nPurePC|61.8%|83.6%|99.3%|-|79.6%|84.9%|100.7%|-|_100%_|115.8%\nQuasarZ|-|84.7%|-|-|81.6%|87.5%|100.8%|104.4%|_100%_|118.9%\nSweCl|67.1%|-|106.5%|-|-|-|103.9%|-|_100%_|118.1%\nTPU|64%|85%|100%|72%|78%|86%|_100%_|102%|_100%_|115%\nTechSpot|67.1%|87.3%|106.3%|75.9%|83.5%|89.9%|102.5%|105.1%|_100%_|115.2%\nTom's|-|-|103.3%|-|80.4%|87.7%|-|104.9%|_100%_|114.5%\nTweakers|68.5%|89.8%|103.6%|74.8%|81.9%|86.0%|102.7%|103.6%|_100%_|116.6%\n**avg**|**66.3%**|**87.6%**|**103.9%**|**74.5%**|**81.2%**|**88.0%**|**102.0%**|**104.2%**|**_100%_**|**116.7%**\nTDP|263W|315W|355W|220W|285W|285W|320W|320W|300W|360W\nMSRP|$499|$899|$999|$599|$799|$799|$1199|$999|$749|$999\n\n&nbsp;\n\nRaster 1440p|7800XT|7900XT|79XTX|4070S|4070Ti|407TiS|4080|4080S|5070Ti|5080\n|:--|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|\n&nbsp;|RDNA3 16GB|RDNA3 20GB|RDNA3 24GB|Ada 12GB|Ada 12GB|Ada 16GB|Ada 16GB|Ada 16GB|Blackw. 16GB|Blackw. 16GB\nCBase|65.8%|86.6%|97.8%|77.5%|-|91.0%|-|103.2%|_100%_|112.0%\nHW&Co|70.9%|90.0%|102.0%|-|-|92.0%|-|105.3%|_100%_|114.5%\nIgor's|71.6%|89.2%|104.9%|78.3%|-|90.4%|-|105.3%|_100%_|112.9%\nKitGuru|71.8%|95.3%|108.4%|80.1%|85.6%|91.5%|-|106.1%|_100%_|115.7%\nLinus|73.0%|93.9%|107.0%|77.4%|84.3%|90.4%|-|103.5%|_100%_|-\nPCGH|-|93.0%|108.8%|-|-|89.2%|-|105.6%|_100%_|115.6%\nPurePC|64.6%|86.4%|100.0%|-|83.7%|87.1%|103.4%|-|_100%_|114.3%\nQuasarZ|-|86.9%|-|-|84.9%|89.6%|101.6%|105.0%|_100%_|115.5%\nSweCl|68.7%|-|105.4%|-|-|-|104.1%|-|_100%_|113.6%\nTPU|67%|87%|100%|76%|83%|88%|101%|103%|_100%_|113%\nTechSpot|73.1%|92.3%|107.7%|83.1%|89.2%|93.8%|106.2%|108.5%|_100%_|113.1%\nTom's|-|-|101.6%|-|84.5%|90.4%|-|104.3%|_100%_|111.6%\nTweakers|70.5%|91.6%|101.8%|79.1%|85.6%|87.7%|103.7%|104.1%|_100%_|113.4%\n**avg**|**69.6%**|**90.4%**|**103.9%**|**78.9%**|**85.3%**|**90.3%**|**103.4%**|**105.3%**|**_100%_**|**114.3%**\nTDP|263W|315W|355W|220W|285W|285W|320W|320W|300W|360W\nMSRP|$499|$899|$999|$599|$799|$799|$1199|$999|$749|$999\n\n\n&nbsp;\n\nRaster 1080p|7800XT|7900XT|79XTX|4070S|4070Ti|407TiS|4080|4080S|5070Ti|5080\n|:--|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|\n&nbsp;|RDNA3 16GB|RDNA3 20GB|RDNA3 24GB|Ada 12GB|Ada 12GB|Ada 16GB|Ada 16GB|Ada 16GB|Blackw. 16GB|Blackw. 16GB\nIgor's|71.5%|87.5%|100.1%|79.6%|-|91.3%|-|104.3%|_100%_|109.6%\nKitGuru|73.5%|96.0%|107.6%|83.1%|88.3%|93.2%|-|106.9%|_100%_|114.3%\nLinus|72.7%|94.2%|105.8%|81.2%|87.0%|91.6%|-|-|_100%_|-\nPCGH|-|93.5%|106.8%|-|-|90.9%|-|105.2%|_100%_|113.9%\nPurePC|66.4%|87.0%|98.6%|-|86.3%|88.4%|104.1%|-|_100%_|112.3%\nQuasarZ|-|87.2%|-|-|87.9%|90.6%|101.8%|105.3%|_100%_|113.4%\nSweCl|70.2%|-|104.3%|-|-|-|104.3%|-|_100%_|111.3%\nTPU|69%|88%|99%|80%|87%|91%|102%|103%|_100%_|110%\nTechSpot|76.2%|93.3%|103.7%|89.0%|93.9%|97.0%|106.7%|107.9%|_100%_|106.7%\nTom's|-|-|100.3%|-|88.6%|93.0%|-|104.7%|_100%_|108.5%\nTweakers|72.7%|91.4%|99.8%|82.0%|88.5%|88.9%|104.8%|104.7%|_100%_|111.8%\n**avg**|**71.6%**|**91.0%**|**102.2%**|**82.4%**|**88.4%**|**91.8%**|**103.8%**|**105.3%**|**_100%_**|**111.3%**\nTDP|263W|315W|355W|220W|285W|285W|320W|320W|300W|360W\nMSRP|$499|$899|$999|$599|$799|$799|$1199|$999|$749|$999\n\n&nbsp;\n\nRayTr. 2160p|7800XT|7900XT|79XTX|4070S|4070Ti|407TiS|4080|4080S|5070Ti|5080\n|:--|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|\n&nbsp;|RDNA3 16GB|RDNA3 20GB|RDNA3 24GB|Ada 12GB|Ada 12GB|Ada 16GB|Ada 16GB|Ada 16GB|Blackw. 16GB|Blackw. 16GB\nCBase|53.8%|74.2%|85.2%|70.2%|-|89.8%|-|102.9%|_100%_|112.5%\nKitGuru|46.7%|65.6%|75.8%|68.8%|74.4%|89.3%|-|106.3%|_100%_|119.1%\nPCGH|-|68.8%|81.3%|-|-|89.7%|-|105.7%|_100%_|118.2%\nPurePC|41.8%|56.4%|67.9%|-|78.2%|83.6%|101.8%|-|_100%_|117.0%\nQuasarzone  (5 Tests)|-|-|-|-|82.4%|89.2%|102.9%|106.7%|_100%_|118.4%\nTPU|46%|61%|71%|62%|67%|88%|103%|104%|_100%_|115%\nTechSpot|35.3%|49.0%|58.8%|74.5%|82.4%|88.2%|105.9%|109.8%|_100%_|119.6%\nTom's|-|-|77.9%|-|80.2%|90.4%|-|106.1%|_100%_|113.1%\nTweakers|-|68.9%|78.8%|75.1%|82.6%|88.7%|106.7%|107.8%|_100%_|118.0%\n**avg**|**46.9%**|**64.0%**|**75.1%**|**70.8%**|**77.7%**|**88.8%**|**103.8%**|**105.9%**|**_100%_**|**117.0%**\nTDP|263W|315W|355W|220W|285W|285W|320W|320W|300W|360W\nMSRP|$499|$899|$999|$599|$799|$799|$1199|$999|$749|$999\n\n&nbsp;\n\nRayTr. 1440p|7800XT|7900XT|79XTX|4070S|4070Ti|407TiS|4080|4080S|5070Ti|5080\n|:--|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|\n&nbsp;|RDNA3 16GB|RDNA3 20GB|RDNA3 24GB|Ada 12GB|Ada 12GB|Ada 16GB|Ada 16GB|Ada 16GB|Blackw. 16GB|Blackw. 16GB\nCBase|59.2%|79.1%|88.0%|78.8%|-|93.0%|-|103.9%|_100%_|111.5%\nHW&Co|42.0%|54.3%|62.0%|-|-|90.8%|-|106.1%|_100%_|116.5%\nKitGuru|49.2%|66.9%|76.2%|77.8%|84.3%|90.5%|-|106.4%|_100%_|117.5%\nLinus|52.0%|68.0%|78.7%|74.7%|81.3%|89.3%|-|104.0%|_100%_|-\nPCGH|-|73.3%|84.5%|-|-|91.7%|-|106.8%|_100%_|116.0%\nPurePC|43.0%|58.9%|69.0%|-|82.3%|86.7%|103.2%|-|_100%_|116.5%\nTPU|49%|64%|74%|77%|85%|90%|104%|104%|_100%_|112%\nTechSpot|41.2%|55.3%|63.5%|83.5%|89.4%|94.1%|109.4%|110.6%|_100%_|116.5%\nTom's|-|-|82.6%|-|86.1%|93.0%|-|111.1%|_100%_|111.9%\nTweakers|52.0%|68.5%|77.4%|77.7%|86.0%|90.0%|107.7%|108.0%|_100%_|115.0%\n**avg**|**50.2%**|**66.8%**|**76.6%**|**78.2%**|**85.4%**|**91.2%**|**105.1%**|**106.7%**|**_100%_**|**115.3%**\nTDP|263W|315W|355W|220W|285W|285W|320W|320W|300W|360W\nMSRP|$499|$899|$999|$599|$799|$799|$1199|$999|$749|$999\n\n&nbsp;\n\nRayTr. 1080p|7800XT|7900XT|79XTX|4070S|4070Ti|407TiS|4080|4080S|5070Ti|5080\n|:--|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|\n&nbsp;|RDNA3 16GB|RDNA3 20GB|RDNA3 24GB|Ada 12GB|Ada 12GB|Ada 16GB|Ada 16GB|Ada 16GB|Blackw. 16GB|Blackw. 16GB\nKitGuru|50.9%|67.6%|75.7%|80.5%|85.6%|91.2%|-|104.9%|_100%_|115.7%\nLinus|37.6%|55.9%|63.4%|76.3%|82.8%|90.3%|-|-|_100%_|-\nPCGH|-|76.3%|86.4%|-|-|93.4%|-|107.0%|_100%_|114.7%\nPurePC|45.2%|60.0%|69.0%|-|84.5%|87.7%|103.2%|-|_100%_|114.2%\nTPU|53%|66%|75%|80%|87%|92%|104%|105%|_100%_|110%\nTechSpot|44.7%|56.1%|-|86.0%|92.1%|96.5%|109.6%|111.4%|_100%_|114.0%\nTom's|-|-|80.5%|-|87.0%|92.4%|-|103.2%|_100%_|104.3%\nTweakers|53.0%|67.9%|75.4%|79.6%|87.2%|89.7%|106.4%|107.9%|_100%_|113.8%\n**avg**|**51.0%**|**66.9%**|**75.8%**|**80.7%**|**87.1%**|**92.1%**|**104.6%**|**106.2%**|**_100%_**|**112.5%**\nTDP|263W|315W|355W|220W|285W|285W|320W|320W|300W|360W\nMSRP|$499|$899|$999|$599|$799|$799|$1199|$999|$749|$999\n\n&nbsp;\n\nAt a glance|7800XT|79XT|79XTX|407S|407Ti|407TiS|4080|4080S|507Ti|5080\n|:--|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|\n&nbsp;|RDNA3 16GB|RDNA3 20GB|RDNA3 24GB|Ada 12GB|Ada 12GB|Ada 16GB|Ada 16GB|Ada 16GB|Blackw. 16GB|Blackw. 16GB\n2160p&nbsp;Raster|66.3%|87.6%|103.9%|74.5%|81.2%|88.0%|102.0%|104.2%|_100%_|116.7%\n1440p Raster|69.6%|90.4%|103.9%|78.9%|85.3%|90.3%|103.4%|105.3%|_100%_|114.3%\n1080p Raster|71.6%|91.0%|102.2%|82.4%|88.4%|91.8%|103.8%|105.3%|_100%_|111.3%\n2160p RayTr.|46.9%|64.0%|75.1%|70.8%|77.7%|88.8%|103.8%|105.9%|_100%_|117.0%\n1440p RayTr.|50.2%|66.8%|76.6%|78.2%|85.4%|91.2%|105.1%|106.7%|_100%_|115.3%\n1080p RayTr.|51.0%|66.9%|75.8%|80.7%|87.1%|92.1%|104.6%|106.2%|_100%_|112.5%\nTDP|263W|315W|355W|220W|285W|285W|320W|320W|300W|360W\nReal Power Draw|250W|309W|351W|221W|267W|277W|297W|302W|287W|311W\nEE RA 1440p|80%|84%|85%|102%|92%|94%|100%|100%|_100%_|105%\nMSRP|$499|$899|$999|$599|$799|$799|$1199|$999|$749|$999\nRetail GER|495€|689€|899€|~600€|~830€|~830€|~1150€|~1000€|~1000€|~1300€\nP/P GER 1440p&nbsp;RA|141%|131%|116%|131%|103%|109%|90%|105%|_100%_|88%\nP/P GER 1440p&nbsp;RT|101%|97%|85%|130%|103%|110%|91%|107%|_100%_|89%\nRetail US|~$500|~$650|~$870|~$600|~$800|~$800|~$1200|~$1000|~$900|~$1150\n**P/P US 1440p&nbsp;RA**|**125%**|**125%**|**107%**|**118%**|**96%**|**102%**|**78%**|**95%**|**_100%_**|**89%**\nP/P US 1440p&nbsp;RT|90%|92%|79%|117%|96%|103%|79%|96%|_100%_|90%\n\nNote: RA = Raster, RT = Ray-Tracing, EE = Energy Efficiency, P/P = Performance/Price Ratio    \nNote: For the graphics cards that have already been discontinued, a retail price was assumed at the time of their sale. At US market, this applies to all other cards beside the RTX50 series. Retail prices were estimated for 5070Ti, 5080 & 5090 when availability is reached (based on the forecast that MSRP level will not be reached in the near future). These estimates are of course not perfect, as nobody knows how the price situation will develop.\n\n&nbsp;\n\nPerf. Gain of 5070Ti|Raster 2160p|Raster 1440p|Raster 1080p|RayTr. 2160p|RayTr. 1440p|RayTr. 1080p\n|:--|:--:|:--:|:--:|:--:|:--:|:--:|\nRadeon RX 7800 XT|+51%|+44%|+40%|+113%|+99%|+96%\nRadeon RX 7900 XT|+14%|+11%|+10%|+56%|+50%|+49%\nRadeon RX 7900 XTX|–4%|–4%|–2%|+33%|+31%|+32%\nGeForce RTX 4070 Super|+34%|+27%|+21%|+41%|+28%|+24%\nGeForce RTX 4070 Ti|+23%|+17%|+13%|+29%|+17%|+15%\nGeForce&nbsp;RTX&nbsp;4070&nbsp;Ti&nbsp;Super|+14%|+11%|+9%|+13%|+10%|+9%\nGeForce RTX 4080|–2%|–3%|–4%|–4%|–5%|–4%\nGeForce RTX 4080 Super|–4%|–5%|–5%|–6%|–6%|–6%\nGeForce RTX 4090|–27%|–24%|–21%|–29%|–27%|–23%\nGeForce RTX 5080|–14%|–12%|–10%|–15%|–13%|–11%\nGeForce RTX 5090|–43%|–36%|–29%|–45%|–39%|–33%\n\nNote: Performance improvement of the GeForce RTX 5070 Ti compared to the other cards. The respective other card is then _100%_.\n\n&nbsp;\n\n&nbsp;|Asus TUF OC|Galax 1-Click OC|MSI Gaming Trio OC+|MSI Vanguard SOC|MSI Ventus 3X OC|Palit GameRock OC\n|:--|:--:|:--:|:--:|:--:|:--:|:--:|\nCooling|Air, 3 Fans|Air, 3 Fans|Air, 3 Fans|Air, 3 Fans|Air, 3 Fans|Air, 3 Fans\nDimensions|TripleSlot, 33x14cm|TripleSlot, 30x12.5cm|TripleSlot, 34x14cm|QuadSlot, 36x15cm|TripleSlot, 30x12cm|QuadSlot, 33.15cm\nWeight|1616g|1300g|1301g|1937g|1060g|2186g\nClocks|2295/2588 MHz|2295/2467 MHz|2295/2572 MHz|2295/2588 MHz|2295/2482 MHz|2295/2512 MHz\nReal Clock (avg/median)|2785 MHz / 2827 MHz|2746 MHz / 2790 MHz|2747 MHz / 2782 MHz|2785 MHz / 2835 MHz|2759 MHz / 2805 MHz|2819 MHz / 2872 MHz\nTDP|300W (max. 330W)|300W (max. 320W)|300W (max. 330W)|300W (max. 350W)|300W (max. 300W)|300W (max. 330W)\nRaster Perf. (2160/1440/1080)|+2% / +1% / +1%|_100%_|+1% / +0% / +0%|+2% / +1% / +1%|+1% / +1% / +0%|+2% / +1% / +1%\nRayTr. Perf. (2160/1440/1080)|+2% / +1% / +1%|_100%_|+1% / +0% / +0%|+2% / +1% / +1%|+1% / +1% / –2%|+2% / +1% / +0%\nTemperatures (GPU/Memory)|61°C / 64°C|63°C / 68°C|63°C / 68°C|59°C / 60°C|68°C / 70°C|63°C / 68°C\nLoundness|30.8 dBA|29.5 dBA|24.3 dBA|23.9 dBA|40.9 dBA|29.4 dBA\nReal Power Draw (Idle/Gaming)|17W / 279W|21W / 279W|19W / 268W|18W / 274W|18W / 287W|28W / 292W\nPrice|$1000|$750|$980|$1000|$900|$1000\nSource:|[TPU](https://www.techpowerup.com/review/asus-geforce-rtx-5070-ti-tuf-oc/)|[TPU](https://www.techpowerup.com/review/galax-geforce-rtx-5070-ti-1-click-oc-white/)|[TPU](https://www.techpowerup.com/review/msi-geforce-rtx-5070-ti-gaming-trio-oc/)|[TPU](https://www.techpowerup.com/review/msi-geforce-rtx-5070-ti-vanguard-soc/)|[TPU](https://www.techpowerup.com/review/msi-geforce-rtx-5070-ti-ventus-3x/)|[TPU](https://www.techpowerup.com/review/palit-geforce-rtx-5070-ti-gamerock-oc/)\n\nNote: Just the values of the default BIOS were noted throughout, as _complete_ information including performance values are only available for that BIOS.\n\n&nbsp;\n\nList of GeForce RTX 5070 Ti reviews evaluated for this analysis:\n\n- [ComputerBase](https://www.computerbase.de/artikel/grafikkarten/nvidia-geforce-rtx-5070-ti-test.91379/)\n- [Hardware & Co](https://hardwareand.co/dossiers/gpu/test-de-la-geforce-rtx-5070-ti-plus-interessante-que-la-rtx-5080)\n- [Igor's Lab](https://www.igorslab.de/msi-geforce-rtx-5070-ti-ventus-als-msrp-karte-im-test-interessanter-chip-fuer-gamer-aber-ventus-kommt-von-ventilator/)\n- [KitGuru](https://www.kitguru.net/components/graphic-cards/dominic-moass/msi-rtx-5070-ti-ventus-3x-oc-review/)\n- [Linus Tech Tips](https://www.youtube.com/watch?v=NnhU2ZvHb10)\n- [PC Games Hardware](https://www.pcgameshardware.de/Geforce-RTX-5070-Ti-Grafikkarte-281031/Tests/Release-Preis-Test-Benchmarks-vs-5080-1466041/)\n- [PurePC](https://www.purepc.pl/msi-geforce-rtx-5070-ti-ventus-3x-recenzja-test-wydajnosci-cena-premiera-blackwell)\n- [Quasarzone](https://quasarzone.com/bbs/qc_bench/views/93577)\n- [SweClockers](https://www.sweclockers.com/test/40649-msi-rtx-5070-ti-ventus-3x-oc-gor-vad-den-ska)\n- [TechPowerUp](https://www.techpowerup.com/review/galax-geforce-rtx-5070-ti-1-click-oc-white/)\n- [TechSpot](https://www.techspot.com/review/2955-nvidia-geforce-rtx-5070-ti/)\n- [Tom's Hardware](https://www.tomshardware.com/pc-components/gpus/nvidia-geforce-rtx-5070-ti-review-asus)\n- [Tweakers](https://tweakers.net/reviews/12960/nvidia-geforce-rtx-5070-ti-waar-de-rtx-50-serie-leuk-begint-te-worden.html)\n\n&nbsp;\n\nSource: [3DCenter.org](https://www.3dcenter.org/artikel/launch-analyse-nvidia-geforce-rtx-5070-ti)",
    "comments": [
      "Yeah so the 5070ti is functionally identical to the 7900xtx in raster. Lots of people were saying the 7900xtx was much faster, but 3% is margin of error that can swing either direction depending on game selection.",
      "Yo, this took a lot of time to compile. Appreciate it man. \n\nIt's the least worst of all the cards released so far. It's 11-14% faster than a 4070TiS depending on the res. It's also 6% cheaper than the 4070TiS. Put the two together, and it's about 20% better for the same price. Which is the bare minimum for gen-on-gen in my completely arbitrary opinion.\n\nEdit: this is presuming you somehow nabbed a MSRP card. The real price seems to be $900.",
      "msrp mia",
      "People would cherrypick the data they want.",
      "Can’t tell you how many times I’ve heard “the XTX is way faster than the 4080 Super in raster”. These people don’t live in reality.",
      "And the moment you turn on DLSS/RT then that margin gets trampled.\n\nOnly thing holding back the 5070ti now is the low stock price",
      "I've had one yesterday tell me that 7900XTX is plain 20% faster because in one (out of whole 5) games tested by GN at 1440p XTX was like 17% faster. Disregarding than in the rest of those it was at best 10% faster and in any wider benchmark it never broke even 10% properly.",
      "boast versed weather coherent sheet violet trees friendly long payment\n\n *This post was mass deleted and anonymized with [Redact](https://redact.dev/home)*",
      "Man, I thought the 4070 struggling to consistently match the 3080 was sad, but now the freaking *70 Ti* card flat out loses to the previous gen 80 card? Can't even punch *half a tier* up?\n\nI guess once (if?) they come back down to MSRP that will make them good enough value... but you can also look at it as: 5 years after the 3080, you get slightly less than 4080 performance for slightly more than 3080 MSRP. If 40 series killed performance per dollar advancement then 50 series is dancing on its grave",
      "To be fair, even used 4070 ti super cards are going for much higher than its msrp on places like ebay.",
      "Some people live to cherry pick data because that confirms their beliefs. Maybe they are destined to be cherry farmers! \n\nThat's why i always appreciate what this OP is doing on his website because these sort of aggregation of many reviews is the only way we can get the big picture.",
      "Very comprehensive comparison",
      "I nabbed one at MSRP (PNY) to replace my 7900xt. Raster increase is meh but buying for the DLSS4 over FSR and RT upgrades.",
      "Have any reviewers found that their cards have the ROP issue?",
      "Not really, when it's not cheaper than the 4070ti super, but ok, maybe some models are in the US.\nEssentially it's a relaunch of the 4080/4080 super. Same price, same performance.",
      "I think someone should do a gen-to-gen performance comparison between Nvidia's various generations, on a per tier, apple-to-apples basis. Because I think an 11-14% uplift from a whole 2 year generational gap is probably not that great. Yeah it's technically a better deal than the previous gen, but not really.",
      "Yeah, definitely not a 1:1 comparison when the 50 series doesn't really sell at MSRP with most vendors. Still an interesting comparison though nonetheless.",
      "And it *should* hit MSRP eventually. Even the 3070 and 4070 did after a while.\n\n(And, of course, pretty much every gen before that, MSRP was just a higher price to make the always-lower street price seem like a better deal, like it is for every other kind of product. That was normal, and should be again, if competition ever starts being a thing again in the GPU space. All eyes on you intel).",
      "Can't wait for my RTX 5070 (non-ti) \n\nHope it will get the same treatment",
      "Always love these posts"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "rtx 4070",
      "4070",
      "4070 ti super",
      "4070ti",
      "4070 ti",
      "rtx 4070 ti",
      "rtx 4070 ti super"
    ],
    "title": "4070 Ti Super Partner Product Pages",
    "selftext": "[MSI](https://us.msi.com/Graphics-Cards/Products#?tag=GeForce-RTX%26trade%3B-4070-Ti-SUPER)\n\n\n[GIGABYTE](https://www.gigabyte.com/Graphics-Card/All-Series?fid=2992)\n\n\n[Zotac](https://www.zotac.com/product/graphics_card/GeForce-RTX-4070-Ti-SUPER/all)\n\n\n[ASUS](https://www.asus.com/us/motherboards-components/graphics-cards/all-series/filter?Category=NVIDIA&SubSpec=236210)\n\n\n[PNY](https://www.pny.com/promo/consumer/rtx-super-series)\n\n[Inno3D](https://www.inno3d.com/en/product_list/index/GRAPHICS%20CARD?q=4070+Ti+Super+&p1c2=on&p5c71=on)\n\n[Gainward](https://www.gainward.com/main/vgapc.php?vgapc_id=84&lang=en&chip=GeForce%20RTX%204070%20Ti%20SUPER)\n\n\n[Galax](https://www.galax.com/en/graphics-card/40-series/40series-super/4070ti-super.html)\n\nI am personally leaning towards: Gigabyte \n[GeForce RTX™ 4070 Ti SUPER EAGLE OC 16G](https://www.gigabyte.com/Graphics-Card/GV-N407TSEAGLE-OC-16GD#kf)\n\n[AORUS GeForce RTX™ 4070 Ti SUPER MASTER 16G](https://www.gigabyte.com/Graphics-Card/GV-N407TSAORUS-M-16GD#kf)\n\n\nOr Zotac\n[ZOTAC GAMING GeForce RTX 4070 Ti SUPER Trinity Black Edition 16GB\n GDDR6X](https://www.zotac.com/product/graphics_card/zotac-gaming-geforce-rtx-4070-ti-super-trinity-black-edition-16gb-gddr6x)\n\n\n[ZOTAC GAMING GeForce RTX 4070 Ti SUPER AMP HOLO 16GB GDDR6X](https://www.zotac.com/product/graphics_card/zotac-gaming-geforce-rtx-4070-ti-super-amp-holo-16gb-gddr6x)\n\n\nThe only hesitation with Zotac is that I think it uses 3x8 pin power connectors.\n\nUpdate: Added Inno3D, Gainward and Galax cards as well.",
    "comments": [
      "Whichever one is cheapest for me lol",
      "The larger difference tends to be in noise levels",
      "Whatever is cheapest",
      "Usually cheaper cooler designs which make it perform maybe 1-2% less then their top counterpart especially when it comes to boosting and OCing.",
      "Looks like it's basically the same comically large cards as before, just with a different chip under the heatsink.  That's a shame.  I truly hope that Asus is going to do a ProArt refresh as well, especially since the 4070ti and 4080 will no longer be available.",
      "Zotac is usually cheaper than other brands right?",
      "Why would the 3 8pin power connectors be cause for hesitation? Besides a cleaner cable run, to my knowledge the 8 pins are less prone to melting like the 12pin connector is. Granted this depends on the actual power draw of the 4070 ti super.",
      "Am I the only one who misses EVGA?",
      "I'll pick Asus, just because it comes with 2x HDMI 2.1 ports + it's the cheapest option for me at the moment. Would pay a little extra for that one extra HDMI output.",
      "No really sure why it's the cheapest but I think PNY is one of the cheapest too.",
      "It's smaller than the typically enormous 4070ti and 4080 cards so it actually fits in SFF cases.",
      "In zotacs case it absolutely means lower quality fans. Their fans are known to literally fall apart. I’ve had a few Zotac cards over the years. Never again.",
      "Virtually no money spent on advertising or marketing or sponsorships is why they are so cheap.",
      "More or less.  As has been said repeatedly in this sub, the coolers on the 4000-series cards are significantly overbuilt.",
      "[https://www.asus.com/motherboards-components/graphics-cards/proart/proart-rtx4070tis-o16g/](https://www.asus.com/motherboards-components/graphics-cards/proart/proart-rtx4070tis-o16g/)",
      "Size, actually, but thanks for playing.  \n\nThe typical 4070ti, 4080, and 4090 all have the same coolers from within the same AIB range.  In other words, all three Strix cards are the same size, all three TUF cards, all three of the Gigabyte Eagle and Aero cards, etc.  Not only that, they are huge.  The 4090 was originally going to have a much higher TGP (with a max at 660w) and the coolers were designed for that TGP, not what the 4090 eventually shipped with (450w).  Consequently (as we're heard again and again), the cooling solutions on the 4000 series are overbuilt.  An RTX 4080 has a 320w max, by comparison.  So those \"typical\" RTX 4080 cards are made with a cooler design that was originally for a GPU that has TWICE the max TGP as the 4080 has.\n\nSo with the ProArt line, Asus has released a much more sensibly sized card.  For example, the Asus TUF cards are (according to Asus) a 3.65-slot card.  The ProArt is 2.5 slot.  The TUF is 348.2mm long.  The ProArt is 300mm long.  Even the non-ti version of the TUF 4070 is 3.15 slots.  Thats a whole lot of space savings, and if you're building an SFF PC the chances of your case supporting anything larger than a 3-slot card are close to zero.  \n\nIf I want to replace my 3080 Strix with a 4000-series, the only 4080 cards that will fit are the ProArt.  If I want a 4070ti I believe that MSI's most entry-level 3X model will barely squeeze in there.  The TUF 4070 (non-TI) won't fit.  The ProArt will.  Literally, the only 4070 or higher cards that Asus makes that will fit in my 3-slot case is the [Dual 4070](https://www.asus.com/us/motherboards-components/graphics-cards/dual/dual-rtx4070-12g/) model, and then all of the ProArt cards.  And yes, I'm focusing on my preferred brand here, but most vendors have similarly large cards, even nVidia.\n\nIf I want a 4000-series card that fits it's either a 4070 or a ProArt.",
      "Sticking to my 115w Gigabyte 4060 Ti 16GB VRAM.",
      "pretty sure I saw a listing for a 4070ti super proart on their website or some retailer",
      "I'm wondering the same thing here actually; their one webpage mentions Ti Super models on the Gaming Trio cards, but all the actual listings say either ventus or gaming slim.  \n\n\n\n\nSo I'm hoping once the 4070 super launches they'll release more info about the higher end models; cause rn I'm torn between seeing if I should go for a Suprim or an Expert and would really wanna know more of the technical differences between them (can give or take rgb really)",
      "Only GPU that has ever died on my was a Zotac. They did replaced it tho."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "rtx 4070",
      "4070",
      "4070 ti super",
      "4070ti",
      "4070 ti",
      "rtx 4070 ti",
      "rtx 4070 ti super"
    ],
    "title": "RTX 4070 Ti Super Launch Thread",
    "selftext": "**What**: GeForce RTX 4070 Ti Super Launch Day\n\n**When**: Wednesday, January 24, 2024 at 9am Eastern Time\n\n**Protocol**:\n\n* **Subreddit may go on restricted mode for a number of times during the next 24 hours. This may last a few minutes to a few hours depending on the influx of content.**\n* This **Launch Day Megathread** will serve as the hub for discussion regarding various launchday madness. Thread will be sorted by \"new\"\n* [You can also join our Discord server for discussion!](https://discord.gg/nvidia)\n* Topics that should be in Megathread include:\n   * Sharing your successful order\n   * Sharing your non successful order\n   * Sharing your Brick & Mortar store experience\n   * Discussion regarding stock\n   * Any questions regarding orders and availability\n   * Any discussion regarding what you plan to use your new GPU for\n   * Any discussion about how you're happy because you get one\n   * Any discussion about how you're mad because you didn't get one\n* **Any standalone launch day related posts will be removed.**\n\n**Reference Info:**\n\n# [RTX 4070 Ti Super Announcement Megathread](https://new.reddit.com/r/nvidia/comments/191pdus/megathread_geforce_at_ces_super_gpus_rtx_games/)\n\n# [RTX 4070 Ti Super Review Megathread](https://www.reddit.com/r/nvidia/comments/19e24bk/geforce_rtx_4070_ti_super_review_megathread/)\n\n# [\\[PSA\\] Certain MSI GeForce RTX 4070 Ti Super Ventus 3X VBIOS Causes Lower Performance Than Expected](https://reddit.com/r/nvidia/comments/19dq7le/psa_certain_msi_geforce_rtx_4070_ti_super_ventus/)\n\n**Links to various RTX 4070 Ti Super Models:**\n\n# US:\n\n* [Newegg](https://www.newegg.com/p/pl?d=4070+Ti+Super&Order=1&N=601432392%20100007709)\n* [Best Buy](https://www.bestbuy.com/site/searchpage.jsp?_dyncharset=UTF-8&browsedCategory=abcat0507002&id=pcat17071&iht=n&ks=960&list=y&qp=gpusv_facet%3DGraphics%20Processing%20Unit%20(GPU)~NVIDIA%20GeForce%20RTX%204070%20Ti%20SUPER&sc=Global&sp=%2Bcurrentprice%20skuidsaas&st=categoryid%24abcat0507002&type=page&usc=All%20Categories)\n\n# Canada\n\n* [Newegg Canada](https://www.newegg.ca/p/pl?N=100007708%20601432392&Order=1)\n* [Best Buy Canada](https://www.bestbuy.ca/en-ca/collection/rtx-4070ti-super-series-graphic-cards/475706?sort=priceLowToHigh)\n\n# UK\n\n* [Scan UK](https://www.scan.co.uk/shop/gaming/gpu-nvidia-gaming/geforce-4070-ti-super-graphics-cards)\n* [OCUK](https://www.overclockers.co.uk/pc-components/graphics-cards/nvidia-graphics-cards/nvidia-geforce-rtx-4070-ti-super-graphics-cards?sort=price_asc)",
    "comments": [
      "Ironically, on the launch of this model, I was able to snag the 4090 FE at MSRP. Thanks 4070 Ti Super!",
      "I like how I was put on the list with Best Buy to be notified when they go on sale. They sell out and I still haven't even gotten an email that they are available. I'm going to make a post in r/conspiracy.",
      "[https://www.techpowerup.com/review/asus-geforce-rtx-4070-ti-super-tuf/32.html](https://www.techpowerup.com/review/asus-geforce-rtx-4070-ti-super-tuf/32.html)\n\nLooking at benchmark averages the performance gap between a 4070ti Super and 4080 Super is probably going to be around the same as the gap between 4070 Super and 4070ti Super. I just don't see how people are getting better value proposition out of the 4080 Super. Yea, compared to the $1200 4080 it's great, but for the Supers you're getting around the same boost in raster without the 4GB of VRAM for the same price bump. I think it's easier to justify the $200 for the 70ti Super from the 70 Super over $200 more for the 4080 Super, tbh.",
      "I'll be picking a 4080 Super up next week from Scan. Seeing as it's basically on my doorstep. Going from a 3070Ti. Only reason I'm doing it is because my son needs a GPU and doesn't have the money. So he gets my 3070Ti for free.",
      "Yeah, I also don't get this. It's a pretty linear progression in price/performance up the stack. You can always argue \"but the 4080 Super is faster at a little more money\", but the 4070 Super is also a little slower for a little less. And the 4070 non-Super is a little slower yet, for less.\n\nI could have gotten a 4080 or 4080 Super if I wanted, the extra money isn't really a big factor, the Ti Super just happened to come in around what I wanted to spend this time around. If the 4080 Super was like 20% faster for 5% more, sure but there doesn't seem to be any GPU in nVidia's stack that gives you a huge performance for a small increase. (At least not from the x70 and up)\n\n(And I'm wary of the kind of creep where you talk yourself into \"just $100 more\" up the tree, until suddenly you wanted to spend $500, but ended up spending $1000. :P)",
      "And nvidia thanks you. 😂",
      "I think it's more of a lukewarm reception where, when you're paying $800+ for a graphics card, you're in the territory in which it may be easier to feel that you may as well \"just\" spend another $200 and get a 4080 Super. That price gap also used to be $400 with the original 4080 MSRP.\n\n\nThe 4070 Ti Super isn't a bad product, but I do think it's flanked by what I consider better options. 4070 Super for more budget- and value-oriented builds. 4080 Super for those who want the best they can get without going all out on a 4090 which is a big price jump.\n\n\nMy guess is that quite a few people who are interested in this tier of GPU are waiting to snag a 4080 Super.",
      "For anyone shopping amazon, their search sucks, but here's a link to Asus tuf msrp with overnight prime shipping\n\nhttps://www.amazon.com/gp/aw/d/B0CQPXJFND?ref=ppx_pt2_mob_b_prod_image",
      "I’m going to try this next week with the 4080 super FE for my first ever GPU. Wish me luck",
      "Prices are still stupid AF nvidia. I've bought gtx and rtx since 2010 but never again.",
      "Might as well have waited for the 4080 super basically just a few bucks more",
      "Be nice, he edited.",
      "Within minutes after 6am pst, Best Buy wouldn't load for me and then when it actually did it said sold out. Newegg took around 8-10 mins to actually update their site. Once they did is where I got my 4070ti super TUF 👌. Upgrading from a 1070ti! Finally after so many years lol.",
      "There is no fe for 4070 ti super",
      "That’s mad expensive bruh.",
      "In Europe a good 4070 Ti Super like an MSI Gaming X Slim costs 999€, that’s insane for a 70 class GPU, that’s scalper/pandemic prices, I will not give in.",
      "Got the ASUS TUF OC from newegg, was going to try Best Buy but it sold out instantly.",
      "Picked this card up at micro center today, they had plenty of inventory before they closed for the night. Originally wanted the 4070S when these cards were announced, but I do a lot of video work so while my gaming performance may be pretty close I do believe the extra VRAM benefits my specific needs, and said work can pay for the jump. I am loving the performance so far but I do think the 4070S will be a really strong purchase for most.\n\nThis is 100% how the 4070ti should have been released, so while I have no regret on the purchase I do think everyone is justified in being kinda eh towards Nvidia for this generation of cards.\n\nI’m coming from a 2070S, I will be happy for a while.",
      "In looking around on BestBuy to see stock, I stumbled across a RTX 4090 FE that was in stock (said 1 left) so I bought it. Figure I can just return it if I can't get the 4080 Super next week. Lol",
      "The only reason anyone would need the 4080s is for 4k on Ultra settings. 4070 super and 4070ti super are plenty enough for 1080p and 1440p. Look at the benchmarks."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "rtx 4070",
      "4070",
      "4070 ti super",
      "4070 ti",
      "rtx 4070 ti",
      "rtx 4070 ti super"
    ],
    "title": "MSI launches GeForce RTX 4070 TI SUPER EXPERT and blower-style AERO GPUs - VideoCardz.com",
    "selftext": "",
    "comments": [
      "I’m holding out for the RTX 4070 Ti Super Duper Expert Aero Ultra though",
      "I really like the design, but i saw some thermal issues and the backplate is really ugly. The price is crazy too",
      "OC model will be better, though. You'll regret that decision.",
      "Ain’t blowers super fucking loud ?",
      "NGL MSI's expert design is so clean. It might be my favorite looking card out right now.",
      "eat shit spez you racist hypocrite",
      "besides the Founders Editions, this is IMHO the best looking RTX 40er card",
      "Yep, but you can slap 3 of these in a single Aliexpress X99 board and get tons and tons of compute for relatively cheap.  That's why all the super expensive workstation cards still use blowers.",
      "https://www.techpowerup.com/review/msi-geforce-rtx-4080-super-expert/40.html\n\nIt's the worst cooler by a considerable amount. Not gonna overheat your GPU, but still a pure form over function design.",
      "And Knuckles",
      "My ProArt 4080 (and it's triple fans) takes issue with this comment!",
      "Ah, thanks for the link. I'm more interested in the blower model, which doesn't appear to have an equivalent at the 4080 super level to check out. I make a lot of SFF builds where a blower can sometimes be advantageous, but I guess I'll wait until someone inevitably reviews the aero to see if it performs abysmally.",
      "Still waiting patiently for single slot air-cooled 4090.",
      "These names are killing me lmao",
      "Some people prefer to exhaust hot air from the gpu outside the case. Fun fact,  early gpus were all mostly blower style.",
      "MSI RTX 4070Ti Super Duper Expert OC THO Pro Edition - Hellz Yes V2",
      "Where did you read about thermal issues? I really like the minimalist design on the blower version, but the price and the fact that it's a blower feel not great.",
      "its worst cooled 4080 super according to TPU so not that efficient.",
      "LMFAO that naming... Might as well call it 4070 Ti Super Blow Me Away Edition",
      "This is genuinely exciting to see. I thought Nvidia did NOT want blower designs being used by AIBs, though?\n\nStill, it's always good to have options. Hope this is a trend that continues moving forward."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "rtx 4070",
      "4070",
      "4070 ti",
      "rtx 4070 ti"
    ],
    "title": "Gtx 1660 Super > Rtx 4070 Ti",
    "selftext": "Around RM10000 (2000+usd)",
    "comments": [
      "i disagree, i think the 4070ti is better",
      "Looks sick, a bit blinding for me... but it's damn clean and slick",
      "Iam sure you could have gone a super variant if you chose less bling aka RGB.\n\nWhy the 4 Ram sticks? It makes Ram overclocking basically zero",
      "That beast cpu, but the motherboard is on B chipset, if you don't consider overclock for the future, what was the reason of unlocked CPU?\nAnyway, enjoy the upgrade, I did the same from 1660s to 4070ti👀",
      "Oops, forgot the ->",
      "was only messing. enjoy the upgrade ❤️",
      "can you control your led lights from that mobo? I have the same (but b660m) and i just couldnt figure out how to actually control my lights. Nothing worked😭",
      "4 ram sticks looks cooler 😁 and I don’t plan to overclock it",
      "Super version cost way more in my country, and is over my budget so yeah 🥲",
      "Guess I’ll upgrade the motherboard in the future",
      "Download Armoury crate",
      "I did. My led strip was aury synd compatible but the armoury crate didnt recognised it.",
      "Hahaha thanks"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "rtx 4070",
      "4070",
      "4070 super",
      "rtx 4070 super",
      "4070 ti super",
      "4070ti",
      "4070 ti",
      "rtx 4070 ti",
      "rtx 4070 ti super"
    ],
    "title": "NVIDIA Reflex Surpasses 100 Games, a New GRD for RTX 4070 SUPER (available now), and New DLSS Games",
    "selftext": "From GeForce PR:\n\nNVIDIA Reflex is a game-changer, reducing system latency on GeForce graphics cards and laptops so actions occur quicker, giving users a competitive edge in multiplayer matches, and making single-player titles more responsive and enjoyable. This week marks a milestone for NVIDIA Reflex adaption, as *Layers of Fear*, *SCUM*, and *Squad* add support, pushing the supported games count to over 100 games.\n\nToday also marks the availability of the new GeForce RTX 4070 SUPER GPUs, and with that comes a new Game Ready Driver and more DLSS Games. \n\n**Reflex Hits 100 Games!**\n\nNVIDIA Reflex has been gaining momentum, with over 90% of GeForce gamers enabling the latency reducing technology which is supported in 9 of the top 10 competitive shooters. In 2023 alone, over 50 million GeForce gamers played over 10 billion hours of their favorite titles with increased responsiveness thanks to Reflex’s innovative system latency reducing technology.\n\nAnd momentum is not slowing down. [*Layers of Fear*](https://store.steampowered.com/app/1946700/Layers_of_Fear/), [*SCUM*](https://store.steampowered.com/app/513710/SCUM/), and [*Squad*](https://store.steampowered.com/app/393380/Squad/) all support Reflex now. In addition, [*Horizon Forbidden West Complete Edition*](https://store.steampowered.com/app/2420110/Horizon_Forbidden_West_Complete_Edition/) and [*NAKWON: LAST PARADISE*](https://store.steampowered.com/app/2582960/NAKWON_LAST_PARADISE/) will offer support at launch.\n\nSince its debut in September 2020, [over 100 games](https://www.nvidia.com/en-us/geforce/technologies/reflex/supported-products/) have launched with or added support for NVIDIA Reflex. It is a stellar list that includes *Apex Legends*, *Call of Duty: Modern Warfare III*, *Call of Duty: Warzone*, *Counter-Strike 2*, *Fortnite* and *Overwatch 2*, along with critically acclaimed smash hit games such as *Cyberpunk 2077*, *The Witcher 3: Wild Hunt*, *Diablo IV*, *Remnant 2*, *God of War*, *Microsoft Flight Simulator*, *Red Dead Redemption 2*, *Ratchet & Clank: Rift Apart*, *Marvel's Spider-Man Remastered* and more. \n\nAnd it is not just games. [G-SYNC Monitors with Reflex](https://www.nvidia.com/en-us/geforce/technologies/reflex/supported-products/) have the highest refresh rates with excellent image clarity, and [Gaming Mice with Reflex](https://www.nvidia.com/en-us/geforce/technologies/reflex/supported-products/) are primed to up your game. Together, monitors and mice compatible with Reflex provide the best way to measure system latency using the Reflex Analyzer. This month sees the launch of a new NVIDIA Reflex mouse, the [HyperX Pulsefire Haste 2 Mini - Wireless Gaming Mouse](https://hyperx.com/products/hyperx-pulsefire-haste-2-mini-wireless-gaming-mouse?variant=44417442054301), weighing in at a super low 59 grams, with a DPI of up to 26,000.\n\n**GeForce RTX 4070 SUPER is Available Now and has a New Game Ready Driver**\n\nAt CES last week NVIDIA kicked the GeForce RTX 40 Series up a notch with the introduction of the new [GeForce RTX 4080 SUPER](https://www.nvidia.com/en-us/geforce/graphics-cards/40-series/rtx-4080/), [GeForce RTX 4070 Ti SUPER](https://www.nvidia.com/en-us/geforce/graphics-cards/40-series/rtx-4070-4070ti/), and [GeForce RTX 4070 SUPER](https://www.nvidia.com/en-us/geforce/graphics-cards/40-series/rtx-4070-4070ti/) graphics cards. \n\nAll three launch this January, and the GeForce RTX 4070 SUPER is first out with availability today. The [GeForce RTX 4070 SUPER](https://www.nvidia.com/en-us/geforce/graphics-cards/40-series/rtx-4070-4070ti/) is available now, starting at $599. It boasts 20% more cores than the GeForce RTX 4070, and is great for gaming at max settings at 1440p in the latest and greatest titles. In the most graphically intensive games, the GeForce RTX 4070 SUPER is faster than the GeForce RTX 3090 while using a fraction of the power, and with DLSS 3 it’s 1.5X faster.\n\nTo support the launch, NVIDIA released a new Game Ready Driver. \n\nThe new Game Ready Driver also gets gamers ready for [*Palworld*,](https://store.steampowered.com/app/1623730/Palworld/) which enters Early Access on January 19th with DLSS 2.\n\n**More DLSS Games**\n\nDLSS continues its momentum, too. New DLSS titles this week include:\n\n* [*Dead Signal*](https://store.steampowered.com/app/2599300/Dead_Signal/) is available now with DLSS 2\n* [*Palworld*](https://store.steampowered.com/app/1623730/Palworld/) \\- entering early access on January 19th with DLSS 2\n* [*United 1944*](https://store.steampowered.com/app/2152790/UNITED_1944/) \\- in early access now with DLSS 2 and DLAA\n* [*Who is Abby*](https://store.steampowered.com/app/2614800/Who_is_Abby/) available now with DLSS 3 & Ray Tracing\n\n**Related links:**\n\nOver 100 Reflex Games article on GeForce.com:\n\n[https://www.nvidia.com/en-us/geforce/news/reflex-over-100-games-released-more-to-come-in-2024](https://www.nvidia.com/en-us/geforce/news/reflex-over-100-games-released-more-to-come-in-2024)\n\nGeForce RTX 4070 SUPER Game Ready Driver article on GeForce.com\n\n[https://www.nvidia.com/en-us/geforce/news/geforce-rtx-4070-super-game-ready-driver](https://www.nvidia.com/en-us/geforce/news/geforce-rtx-4070-super-game-ready-driver)\n\nNew DLSS Games article on GeForce.com:\n\n[https://www.nvidia.com/en-us/geforce/news/palworld-and-more-dlss-games-released](https://www.nvidia.com/en-us/geforce/news/palworld-and-more-dlss-games-released)\n\n(video) What is NVIDIA Reflex?\n\n[https://www.youtube.com/watch?v=-cXg7GQogAE](https://www.youtube.com/watch?v=-cXg7GQogAE)\n\n(video) *Horizon Forbidden West Complete Edition* NVIDIA DLSS 3, Reflex, DLAA - Announce Trailer\n\n[https://www.youtube.com/watch?v=DEqRbxOrFAw](https://www.youtube.com/watch?v=DEqRbxOrFAw)\n\n(video) NAKWON: LAST PARADISE 4K NVIDIA DLSS 3 Comparison video\n\n[https://www.youtube.com/watch?v=w36Gdwtnku8](https://www.youtube.com/watch?v=w36Gdwtnku8)\n\nList of all RTX Games and applications:\n\n[https://www.nvidia.com/en-us/geforce/news/nvidia-rtx-games-engines-apps/](https://www.nvidia.com/en-us/geforce/news/nvidia-rtx-games-engines-apps/)\n\nGeForce Game Ready Drivers:\n\n[https://www.nvidia.com/en-us/geforce/game-ready-drivers/](https://www.nvidia.com/en-us/geforce/game-ready-drivers/) \n\nG-SYNC Compatible displays on GeForce.com:\n\n[https://www.nvidia.com/en-us/geforce/news/g-sync-compatible-validation/](https://www.nvidia.com/en-us/geforce/news/g-sync-compatible-validation/)",
    "comments": [
      "G-sync + nvcp vsync + reflex is a god send.\n\nit just works on any game and it's buttery smooth with great latency.\n\nI'll be sticking with nvidia for the foreseable future just for that.",
      "That’s great—note that reflex oddly causes stutter in Ratchet and Clank: A Rift Apart. Players beware.",
      "I noticed that \"on+boost\" affects my framerate a lot in some games. I just always use \"on\" now and have had no problems so far.",
      "why g-sync + vsync?",
      "AMD's first jab at anti-lag was sub-par too. It barely did anything. It was a big smokescreen. Now their anti-lag+ is being detected like a cheat because they don't bother trying to work with developers. AMD just doesn't have an equivalent.",
      "Do I need a Reflex monitor?",
      "I believe its to fully eliminate tearing, both from the above target hz, which vsync handles, and below target hz, which gsync handles. And reflex on top of that acts also as a sub target hz cap, while also prioritizing cpu to gpu frame queue for lowest latency presentation? I believe this is the recommened way of setting up gsync monitors with reflex, and having vsync off in-game, but actually enabled in the NV control panel. This is the ideal recommended setup in general. So if you had a 144hz monitor, it effective will limit your fps to say 140 fps and you should never see tearing. \n\nIt doesn't mean you need to do all of this though to have a good experience with the game. Lots of people don't play with vsync on anymore as tearing is less of an issue these days with higher fps, faster gpus, better monitors, and other tools that limit fps anyways. Or they want higher fps for even lower latency.",
      "Yeah I usually do just ‘on’ as well. Didn’t make a difference in R & C.",
      "Yeah i don't understand g-sync and v-sync at all. I tried enabling both and one at a time, and i noticed zero difference in games. Is it supposed to be very noticeable?",
      "The boost part of reflex takes puts the GPU into max performance mode setting effectively upping power drawn and demanding more utilization out your GPU. But if your GPU is already being utilized to 98-99%, there's nothing more to give, so it allocates some perforamance to Boost I think, which can lower latency, but in this case also lowers FPS, which increases latency, and increases 1% lows because your GPU is trying to do more Reflex and output as many frames as possible (probably because you aren't limiting frames which would give some headroom to Reflex in the first place), and therefore you'll see more framerate stuttering and drops...theoretically in whatever game you are testing it on. Boost isn't really recommended unless you have resources to spare for Reflex, as turning on reflex gives you the majority of reduce latency, and boost only marginally reduces latency more, for when you absolutely need that extra reaction speed or maybe its just over what feels sluggish/smooth for you. That's how I understand it.",
      "Ohhh thanks for the info!",
      "I know I’m not OP,  but would you recommend going for 4070 super over 7800xt? 4070 super is a little better at 1080p (what I play), better at RT, and has reflex. I have a 220hz monitor \n\nIs the 4070 super worth $110 more dollars for 10 frames, RT, and reflex?",
      "Check Blur Busters webpage, they exolain it like you were 5yo"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "4070",
      "4070 ti super",
      "4070ti super",
      "4070ti",
      "4070 ti"
    ],
    "title": "RTX 3070ti Upgrade to 4070 ti super or 4080 Super (1440p gaming)",
    "selftext": "So I’m currently rocking a 3070ti with i7-12700k. I’m  thinking about upgrading to 4070ti super or 4080 super. I also plan to upgrade my cpu to ryzen 7 7800x3d. I know that the 50 series will be launch soon. But to be honest I don’t expect them to be available in any retail store soon. If 50 series became available, I’ll probably gonna trade in my 4070ti super or 4080 super (My local store offers a trade in). \n\nSo I just want to know which one is the best to buy right now, since black friday will be in a week.?",
    "comments": [
      "https://preview.redd.it/ozsk06466j2e1.png?width=1080&format=png&auto=webp&s=c4b68ffbbe3546e5878f08d574536a4e665afc88",
      "There are some pretty good deals on the 4070 Ti Super right now Im also looking to pick one up now I haven’t seen any 4080S on sale they’re still over 1k and I don’t know if I expect them to since they might be out of production soon",
      "Can someone give this man the chart",
      "The right answer? Wait till 5000 and the 4080 super should drop. The now answer? I just upgraded from a 2070 super to a 4070 ti super. I play cod, apex, fortnite, cyberpunk, runescape, and others and it is fantastic. I had an amazon gift card for 200 so I paid like 600 or something like that. So far it has been nothing but a fun experience at 1440p.",
      "Neither, dude. Why would you, you got a good GPU.\n\nWait for RTX 50 series, this close to it's release it is nonsensical to upgrade to two years+ old architecture.",
      "I need to print this and put it on my wall, however all reasoning will tell me no and I’ll just cave and give in with some self justification.",
      "What games do you play and what FPS do you want to play them at?",
      "I had the 3070 gaming oc and went to the 4070 ti super gaming oc all with the 7 7800x3d and I like the combo",
      "in my country both of these prices went up for around 150-200usd compared to what ive seen 2 days ago on amazon and some local shops. We will see if they'll go down again in upcoming days",
      "I would say between the two 4080 super then. Try to find one for like $950 or less",
      "I saw one for $950!",
      "Meanwhile I'm gaming 1440p on gtx1050ti",
      "5070 Ti.\nI'm alao using 3070 Ti too but i reckon i better wait. I mean it's only Q1 next year",
      ">The right answer? Wait till 5000 and the 4080 super should drop.\n\n[https://www.techpowerup.com/329125/nvidia-warns-geforce-rtx-40-series-gpus-could-be-in-shortage-in-q4](https://www.techpowerup.com/329125/nvidia-warns-geforce-rtx-40-series-gpus-could-be-in-shortage-in-q4)",
      "Best Buy had it at $1020 for the 4080S",
      "Some 7900 xtx are 820.",
      "I’m with ya OP I’d be upgrading from a 390rx… or whatever it’s called. With Black Friday deals I don’t think I should wait for an even more expensive card and potential impact of tariffs.",
      "I hear that. All week I've been scouring this sub and other sites for 4070 ti super deals, knowing I won't really need it until late Feb lol",
      "I've been building a new PC on various sites for three weeks now. Black Friday is hitting EU websites and I'm still on the fence if I even NEED a new PC lol.",
      "Don’t you go buying it I need my paycheck to hit got dammit"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "rtx 4070",
      "4070",
      "4070 super",
      "rtx 4070 super",
      "4070 ti super",
      "4070ti",
      "4070 ti"
    ],
    "title": "Buying either RTX 4070 Super or 4070 Ti Super",
    "selftext": "I bought a 4k tv late last year and now some newish games are struggling to run on my 3060ti. I also like to play around with local AI models. I'm really struggling to choose between buying a 4070S for 699€ or 4070ti s for 919€. I'd need to also buy a new psu for 4080s so that's not an option. I might upgrade my gpu and psu next gen if the 5000-series is really good. Because of that i'm not sure if i should buy the cheaper option now and upgrade sooner or try \"future proofing\" with the ti super model.",
    "comments": [
      "https://preview.redd.it/w708nzrw39rc1.jpeg?width=1080&format=pjpg&auto=webp&s=7070cf6d775580ab3b2af751f6cea52a769865eb\n\nTi Super is clearly better choice. There is also big difference in 4K",
      "https://preview.redd.it/jqh4ojd9barc1.jpeg?width=1080&format=pjpg&auto=webp&s=e26daf8be3f6fbb43cb54f34bde9eb0809628f62\n\nWhich is justified for games with RT played at 1440p , 4K resolution",
      "I bought the ti super becuase I couldn’t find a 4080 super. Plus the vram was the same and I didn’t think I’d notice the small performance difference.",
      "The Ti Super is just a detuned 4080S, same chip. It’s quite the performance gain over the 4070S, that’s why the price jump is so significant.",
      "You underestimate the impact memory has on 4K gaming, 4070tiS to 4080S will never offer a significant enough jump in performance to justify the price as long as they keep gimping their 80 tier cards on purpose.",
      "Not really because 4090 is obscenely expensive and 4080 does not have more VRAM than Ti Súper which is stupid for the 2nd most expensive card on the market.\n\n4070TiS is the 4xxx card that it will hold its value the best out of all 4xxx GPUs because it is strong mid range GPU that most people want",
      "It's 15% faster, costs 25% more and doesn't have more VRAM nor a bigger memory bus that would justify buying it for somewhat future-proof 4K.",
      "4070ti is a waste of money, 4070ti **SUPER** is worth the 200 bucks over a 4070 super because of reasons previously stated. 20% better performance, more VRAM and better memory bus which are all things crucial for 4K.\n\nSounds like you're clueless about GPUs and need to stop sharing your uninformed opinions.",
      "Judge for yourself, it's a 19-21% improvement in performance depending on model and you get more VRAM which will age better, I'd say that's worth 31,5% more money.\n\nhttps://preview.redd.it/jx6ox2bpmcrc1.png?width=796&format=png&auto=webp&s=cca1f238caa919390d09ac4852799d671cc04c00",
      "Definitely the Ti super. The additional 4 gigs of vram future proofs it for a while longer + overall a more powerful card due to the fact that the super is a downgrade of the ti and the ti super is an upgrade from the ti. So kind of 2 jumps in performance between the 2.",
      "If you have the money, get the TI super version of the card. The VRAM at 16GB is enough.",
      "What psu and cpu do you have?  The rated power Gao between a 4070 ti super and 4080S is just 35W (and with an undervolt they can easily be run below their rated wattage and near stock performance levels.",
      "It's clearly the stronger card, but also +40% more money, right",
      "Indeed, the difference is a measly 15% so with some overclocking it's just an undervolted 4080 non-super.",
      "It defo shoulda been a 4080 Lite 😅",
      "Theyre gimping their cards all along the range beside the 4090. (gimped on price still but ok, its halo product)\n\nImagine a 4070 super with 16 gb. It would fly off the shelves. \n\n\n4070ti super is a nice SKU. If it were abit cheaper it would be the AMD killer this generation on the midrange. Sadly in Europe its costs as much as an XTX and thats not a fair fight at all in terms of performance.\n\nThey can just completely corner the market but choose not too by putting not enough vram or abit more margin. In the end I think dominating the market would net them more money, but im not an accountant.\n\nAs it stands now at every price point u have to take amd in account still (in europe), and thats just due to bad pricing and extreme segmentation from nvidia (imo).\n\nIe: the GRE on 510 and the 4070 super on 660 in EU atm. Thats hardly a choice if you dont have a heavy brand bias (pick the GRE obv). Especially if u have a 4k60 tv like many do u sometimes wanna play some games on aswell the 12gb is gonna bite you soon.",
      "I pondered this exact question and ended up with 4070 TI SUPER. Reason being the main premise for this new system was that I wanted to play Cyberpunk at 4k with PT at a reasonable framerate. I got this exactly right, as I average 68fps (36fps 1% lows) and losing 15-20% of this would push it into barely playable/unplayable territory.",
      "Hi, a bit late, but which model would you recommond? Was it the actual one in the picture or another one?",
      "Depends on where you live, you can get an ASUS TUF for MSRP price in the US but in europe the one pictured is the cheaper card.",
      "Yeah. DLSS Quality + FG."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "rtx 4070",
      "4070",
      "4070 super",
      "rtx 4070 super",
      "4070 ti super",
      "4070ti",
      "4070 ti",
      "rtx 4070 ti",
      "rtx 4070 ti super"
    ],
    "title": "RTX 4070 Ti SUPER Available Now with New GRD, New DLSS Games and RTX Video HDR is Out Now",
    "selftext": "From GeForce PR:\n\nIt’s another busy week, as GeForce RTX 4070 Ti SUPER GPUs are available now, and they are accompanied by a new Game Ready Driver. The driver brings support for a new feature, RTX Video HDR. New games getting DLSS upgrades include *Enshrouded, Like A Dragon: Infinite Wealth, TEKKEN* 8, and *Suicide Squad: Kill the Justice League*, and more.\n\n**GeForce RTX 4070 Ti SUPER is Available Now and Brings a New Game Ready Driver**\n\nNVIDIA kicked off the new year with a trifecta of GeForce RTX 40 SUPER Series GPUs that were announced at CES. Last week [GeForce RTX 4070 SUPER](https://www.nvidia.com/en-us/geforce/graphics-cards/40-series/rtx-4070-4070ti/) graphics cards hit the shelves and today brings availability for [GeForce RTX 4070 Ti SUPER](https://www.nvidia.com/en-us/geforce/graphics-cards/40-series/rtx-4070-4070ti/) graphics cards.\n\nGamers can grab a GeForce RTX 4070 Ti SUPER right now from [ASUS](https://www.newegg.com/asus-geforce-rtx-4070-ti-super-tuf-rtx4070tis-16g-gaming/p/N82E16814126686), [Gigabyte](https://www.bestbuy.com/site/gigabyte-nvidia-geforce-rtx-4070-ti-super-windforce-oc-16gb-gddr6x-pci-express-4-0-graphics-card-black/6572570.p?skuId=6572570), [MSI](https://www.newegg.com/msi-geforce-rtx-4070-ti-super-rtx-4070-ti-super-16g-ventus-2x-oc/p/N82E16814137857),  [PNY](https://www.newegg.com/pny-geforce-rtx-4070-ti-super-vcg4070s12tfxxpb1-o/p/N82E16814133865) or [Zotac](https://www.newegg.com/zotac-geforce-rtx-4070-ti-super-zt-d40730d-10p/p/N82E16814500576) to name a few. \n\nThe GeForce RTX 4070 Ti SUPER is available now, starting at $799. It features more cores and more memory, increasing the frame buffer to 16GB, accompanied by a 256 bit memory bus. It’s the perfect GPU to max out your high refresh 1440p panels and it can even game at 4K. Creators will also love it for video editing and rendering large 3D scenes.\n\nThe GeForce RTX 4070 Ti SUPER is 1.6X faster than the GeForce RTX 3070 Ti, and 2.5X faster with DLSS 3 in the most graphically demanding games.\n\nTo support the launch, NVIDIA released a new Game Ready Driver. \n\n***Enshrouded, Like A Dragon: Infinite Wealth, TEKKEN*** **8, and** ***Suicide Squad: Kill the Justice League*** **Get a DLSS Upgrade**\n\nRTX continues its momentum, too. We now have [over 500 RTX-enhanced games and apps](https://www.nvidia.com/en-us/geforce/news/nvidia-rtx-games-engines-apps/). New DLSS titles this week include:\n\n* [*Enshrouded*](https://store.steampowered.com/app/1203620/Enshrouded/) *-* launches into Early Access today, GeForce RTX gamers can immediately activate DLSS 2 to accelerate frame rates by 93% on average at 4K, with max settings enabled. \n* [*Like a Dragon: Infinite Wealth*](https://store.steampowered.com/app/2072450/Like_a_Dragon_Infinite_Wealth/) *-* launching January 26th With DLSS 3\n* [*TEKKEN 8*](https://store.steampowered.com/app/1778820/TEKKEN_8/) *-* launches January 26th With DLSS 2\n* [*Suicide Squad: Kill the Justice League*](https://store.steampowered.com/app/315210/Suicide_Squad_Kill_the_Justice_League/) *-* launching February 2nd with ray tracing, DLSS Super Resolution, and DLAA\n* *Diablo IV*’s Season of the Construct, out now.  *Diablo IV* supports DLSS 3, and NVIDIA Reflex, and has a ray tracing update coming in March.\n\n**RTX Video HDR Available Now: AI Powered By GeForce RTX Tensor Cores Enhances SDR Content**\n\nAn important aspect of NVIDIA Game Ready drivers is that they are often used as a delivery mechanism to add new features for our GeForce users. This Game Ready driver supports the release of RTX Video HDR, which adds a new AI-enhanced feature to all GeForce RTX GPUs, instantly converting any Standard Dynamic Range (SDR) video playing in select internet browsers into vibrant High Dynamic Range (HDR).\n\nRTX Video HDR is yet another example of how GeForce RTX Tensor Cores and AI can further enhance your experience, for free. [NVIDIA DLSS](https://www.nvidia.com/en-us/geforce/technologies/dlss/) significantly accelerates performance in games and creative apps, [NVIDIA Broadcast](https://www.nvidia.com/en-us/geforce/broadcasting/broadcast-app/) supercharges mics and cams, transforming any room into a home studio, [NVIDIA Canvas](https://www.nvidia.com/en-us/studio/canvas/) turns simple brushstrokes into realistic landscape images, and the [NVIDIA RTX Remix Open Beta](https://www.nvidia.com/en-us/geforce/news/rtx-remix-open-beta-half-life-2-rtx-trailer/) began January 22nd, enabling modders to upgrade classic games with RTX technologies and textures enhanced by generative AI.\n\n**More Game Ready Goodies and Upgrades**\n\n* [GeForce Experience](https://www.nvidia.com/en-us/geforce/geforce-experience/)’s one-click optimal settings enable you to instantly configure game options for your system’s hardware, giving you smooth, optimized gameplay. [Over 1000 titles are supported](https://www.nvidia.com/en-us/geforce/geforce-experience/games/), and since our last driver release we’ve added support for 2 more:\n\n·  *Enshrouded*\n\n·  *Like A Dragon: Infinite Wealth*\n\n**About Game Ready Drivers**\n\nGeForce Game Ready Drivers deliver the best experience for your favorite games because they are finely tuned in collaboration with developers and extensively tested across thousands of desktop and laptop hardware configurations for maximum performance and reliability.\n\nNVIDIA’s Game Ready Driver program was created from the ground up as a method to provide the best gaming experience possible. This program creates a synergy with game developers, establishing a regular cadence of exchanging pre-release game builds and drivers. We work together on finding optimizations and resolving issues, and iterate builds accordingly to ensure both the game and the Game Ready Driver deliver the highest quality and performance at launch.\n\n**Related links:**\n\nNew DLSS Games article on GeForce.com:\n\n[https://www.nvidia.com/en-us/geforce/news/like-a-dragon-infinite-wealth-dlss-3-enshrouded-tekken-8-dlss-2](https://www.nvidia.com/en-us/geforce/news/like-a-dragon-infinite-wealth-dlss-3-enshrouded-tekken-8-dlss-2)\n\nGame Ready Driver for GeForce RTX 4070 Ti SUPER article on GeForce.com\n\n[https://www.nvidia.com/en-us/geforce/news/geforce-rtx-4070-ti-super-rtx-video-hdr-game-ready-driver](https://www.nvidia.com/en-us/geforce/news/geforce-rtx-4070-ti-super-rtx-video-hdr-game-ready-driver)\n\n(video) *Diablo IV* ray tracing video:\n\n[https://www.youtube.com/watch?v=Eh80iWrP95w](https://www.youtube.com/watch?v=Eh80iWrP95w)\n\n(video) *Like a Dragon: Infinite Wealth* Pre-Order Video:\n\n[https://www.youtube.com/watch?v=tQtwFIbk\\_gY](https://www.youtube.com/watch?v=tQtwFIbk_gY)\n\n(video) *Enshrouded* DLSS 2 video:\n\n[https://www.youtube.com/watch?v=ZJYcNwGTkjo](https://www.youtube.com/watch?v=ZJYcNwGTkjo)\n\n(video) *TEKKEN 8* Pre-Order Video :\n\n[https://www.youtube.com/watch?v=oJsrxgW3gfs](https://www.youtube.com/watch?v=oJsrxgW3gfs)\n\n(video) What is NVIDIA Reflex?\n\n[https://www.youtube.com/watch?v=-cXg7GQogAE](https://www.youtube.com/watch?v=-cXg7GQogAE)\n\nList of all RTX Games and applications:\n\n[https://www.nvidia.com/en-us/geforce/news/nvidia-rtx-games-engines-apps/](https://www.nvidia.com/en-us/geforce/news/nvidia-rtx-games-engines-apps/)\n\nGeForce Game Ready Drivers:\n\n[https://www.nvidia.com/en-us/geforce/game-ready-drivers/](https://www.nvidia.com/en-us/geforce/game-ready-drivers/) ",
    "comments": [
      "As a standalone product it’s a great GPU. As for a meaningful bump in performance from its prior predecessor, it’s abysmal. Or so they say.",
      "Is it true that the 4070 Ti Super is lame and not at all what was promised? It’s so hard to parse all the information and know what is true and what isn’t",
      "Did these driver improved anything on the performance front?\n\n&#x200B;\n\nCuz \\~3% over 4070 ti, with a higher die, 10% more cuda cores, and 40% more bandwith really looks like a defective product",
      "I appreciate the reply! Thank you. I would make the jump to 4k monitor and upgrade GPU then. I have a 1440p monitor now and I’m content with it.",
      "4080s will look better because it's dropping 200$ and getting maybe 5% bump in performance. So it will still be about same gap as 4070 ti vs 4080 was but this time 4080s is cheaper making it seem better imo.",
      "**RTX Video FAQ** \\- [https://nvidia.custhelp.com/app/answers/detail/a\\_id/5448/\\~/rtx-video-super-resolution-faq](https://nvidia.custhelp.com/app/answers/detail/a_id/5448/~/rtx-video-super-resolution-faq)",
      "I still have a 2070. Should I go for 4070 S or the ti S? I’m fine with 1440p for the next year or two and willing to upgrade then.",
      "Not sure what you mean.  Upgrade to 4K in a year or two, or upgrade your GPU again in 2 years?\n\nIf you plan to upgrade your GPU in 2 years, the 4070 S looks fine for 1440P.  If you plan to upgrade to 4K, then buy the best card you can afford.\n\nEither way, enjoy your upgrade!",
      "I guess my question should be then: is it worth the price?",
      "At $800, it's worse value than a 4070 Super, but probably better value compared to the 4080 Super. We're still waiting on the latter though, so I could be wrong. People might care about so-called \"future-proofing\" because of the 16GB of VRAM, but right now it's not really making a difference in terms of cases where additional VRAM aids performance. \n\nPersonally if I were choosing, then it would be the 4070 Super. But I can see use cases where spending more on the Ti Super is better. Like if you mod a lot or productivity/AI where the extra Memory and dual encoders would come in handy. \n\nFinally there's AMD's options that are similar in performance, which I'll bet will drop in price in the coming weeks. If one doesn't care about Nvidia's better features over AMD, then those would be the better option once they come down.",
      ">better value compared to the 4080 Super\n\nthe 4080s has the comparison to the 4080 price working in its favor so i have no clue how people will react.\n\nalso, i do think the 16GB matters but only if they play a lot of new games. The recent bad PC ports showed this. But they were (mostly) fixed within a few weeks. Most people dont play a new game every week so thats a small group. It does make me worried for the 4070 build in the near future but yes, its pretty selective",
      "In 4k native you hit about 10-12g in Cyberpunk 2077, Hogwarts Legacy, The Last of Us Part 1. Hard to say what other games will go, but it's imortant to know this is native 4k without DLSS or FSR which would likely be how most people playing as fps is terrible at native 4k. Also this is with over drive ray tracing and native 4k in cyberpunk where you even reach this."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "rtx 4070",
      "4070",
      "4070 ti super",
      "4070ti super",
      "4070ti",
      "4070 ti",
      "rtx 4070ti",
      "rtx 4070 ti",
      "rtx 4070 ti super",
      "rtx 4070ti super"
    ],
    "title": "Asus TUF RTX 4070ti super vs MSI expert RTX 4070ti super",
    "selftext": "\nI’m deciding between the Asus TUF RTX 4070 Ti Super and the MSI Expert RTX 4070 Ti Super. However, I’m in a bit of a dilemma as there aren’t many reviews of the MSI Expert version available. I’ve heard that MSI cards had an issue in the past, which was later fixed with a BIOS update. I wanted to know if the MSI Expert card still has that issue or not.\n\nAnother point to consider is that the MSI Expert card is about 40 dollars cheaper than the Asus TUF card in my country. I also wanted to know if the Asus TUF card is significantly better in terms of performance and thermals to justify the 40-dollar difference.",
    "comments": [
      "You put Asus in the same sentence... Zotac has a 5 year warranty and PNY makes some of the highest end workstation nvidia cards out there.",
      "I have the Asus Tuf version and it’s great. But I would honestly just go with whichever design you prefer and what will look best in your case. They’re going to perform about the same.",
      "The cheapest one(Zotac/pny/palit)",
      "PNY makes the professional cards for Nvidia. Lots of their Quadros and what not. Also the only American manufacturer as well. They make good cards, but they just have an unappealing cooler design for their \"gamer one\" on solely the box 💀.\n\nIt actually looks great from a side profile view and not bad in person at all. I wouldn't just toss them out. I love the look of their black ones and I would pick them if I wasn't obsessed with Sapphire lmao",
      "The expert line was not affected.  I run the affected ventus line and it's on par with any other card.\n\nThe Tuf might have better thermals but I don't fucking trust ASUS for shit, personally.  ASUS cheaps out everywhere they can even if it compromises the product and IMO are specifically designed to last only their warranty period.  Anything after that is luck of the draw.\n\nWhen MSI cheaps out they don't exactly cheap out things that will cause them to fail or have issues off of their warranty.",
      "I just wanted a reliable gpu out of the box, if these issues stand they could be a hassle to deal with",
      "I understand your point, yes it is hot af here but yeah its better to save the extra cash or invest into more fans for the case. Ill probably go for the pny instead. thanks for the help, really appreciate it!",
      "You get what you pay for. I just got the Asus Tuf Gaming 4070ti super. In my opinion, Asus makes the best quality cards.",
      "After what Asus's after sales did to me, I'd stay out of them as much as possible. Their service center is just so fukin horrible, at least in my country.",
      "Beside having bad thermal, my Asus doesn't give me any issue so far. Asus thermal paste is horrible. My new Asus Rtx 4070 TI super temp dropped 25C in temp with new thermal paste(Thermal Grizzly - Kryonaut Extreme). Imo, doesn't matter which one you go with, they both work the same; Mostly aesthetics for your build.",
      "Tbh, I like the aesthetics of both the cards so it’s coming down to performance and reliability for me.",
      "There was a report on Asus cheaping out on thermal paste. I have the Asus Dual 4070 Super, so hopefully it isnt that bad lol.",
      "Also do you know if MSI’s rma is any better than ASUS?",
      "Asus are known to be one of the worst to ever have to deal with regarding RMA, repairs, warranty, etc. Also known to cheapen out and cut corners which doesn't effect everyone so it still is considered a good product, but when you do get affected you have to deal with Asus' horrible customer service and tech departments. I've heard just stay away from asus graphics cards, not worth the hassle, while something like a motherboard is much less likely to go out or have issues.\n\nAlso word on the street is for at least the 40 series Nvidia cards, that Gigabyte and Zotac are the ones needing the most repairs, and the most RMA's coming in.",
      "Base on video reviews asus I’ve seen has the best thermals.",
      "Two identical pny 1080ti were more reliable my gaming x trio that cost more. All 3 had identical user experience.  The gaming x trio was higher spec but im telling u it was identical experience. The pny card was louder. Thats it. \n\nIm going to be buying 2 new gpus soon and after all the research im finding that i want as close to exactly 2x pice slots as possible with enough thermal mass - heatsink - to absorb spikes in load. \n\nI refuse to ever purchase a fuckin 3x+ pcie slot gpu ever again.",
      "Yeah I heard about that too on TUF and Dual.",
      "Wouldn't surprise me lol.  I have an a15 laptop with failing fan bearings that was fixed by me with..a drop of motor oil.  It's a very recurring issue across google for that year's chassis.  They just cheap out too much and are assholes about it.\n\nAt least MSI had the balls to actually be like \"oh hey so we fucked up the VRMs here's a second fixed variant.\"  Asus would just be like \"working as intended\" and tell people to get fucked.",
      "Depends what country you're in",
      "It's probably no worse."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "rtx 4070",
      "4070",
      "4070 ti super",
      "4070ti super",
      "4070ti",
      "4070 ti",
      "rtx 4070ti",
      "rtx 4070 ti",
      "rtx 4070 ti super",
      "rtx 4070ti super"
    ],
    "title": "RTX 4070ti Super MSI, Gigabyte vs Zotac which one should I buy?",
    "selftext": " I'm planning to purchase the RTX 4070 Ti Super, but I'm feeling uncertain about the different brands. Some people claim that popular brands like ASUS, Gigabyte, and MSI have superior cooling components and better build quality. On the flip side, brands such as Zotac, Palit, PNY, and Maxsun are said to have cheaper cooling components and poorer build quality. However, others argue that all GPU brands are essentially the same.  If they are all the same, then there's no need for me to spend extra money on ASUS, Gigabyte, and MSI. Unfortunately, in my country, only the Zotac 4070 Ti Super is currently available. If I opt for the more budget-friendly brand, I would choose the Zotac 4070 Ti Super Amp Holo card due to its bulky and beefy size, which I particularly like, but have doubt about it's cooling performance. Can anyone provide insights into the differences between these brands?",
    "comments": [
      "For me, I always preferred MSI just because I had no problems with their hardware for the last 10 years. And I can't say the same for Asus and gigabyte. But even there, all three make questionable software, which I use as less as possible.",
      "Problem with Gigabyte are that they don't honor the warranty - and I can confirm it with my personal experience",
      "Motherboards don't break that often in general.\n\nSo far, I've owned 2 MSI and 2 Gigabyte boards, and all of them are still fine to this date.\n\nThe fact that MSI is lacking MSRP GPU, I would recommend ASUS TUF model at MSRP.",
      "I for one like Zotac's design better, this is the one I got.\n\nhttps://preview.redd.it/xdcsm9um5zfc1.jpeg?width=1439&format=pjpg&auto=webp&s=b147140ad1411c84904c9d0fdb33605d69bf248c",
      "All brands have a top tier and bottom tier cards, e.g. MSI Suprim vs Ventus. You've got to research if said Zotac, Palit, PNY, and Maxsun cards are top tier within their respective brands or not. People tend to talk about the entire brand when it comes to having a bad experience which can happen with any manufacturer. You'll find at least 1 person on here who has had a poor expierience with each and every AIB, so that argument in my view is reduntant. If an AIB was trash, why would Nvidia supply them the chips? If they were so shockingly bad, why would Nvidia risk their reputation by continuing to work with them? Something to ponder upon.\n\nAs far as the flipside goes, I've owned a PC Partner Group card (ZOTAC, Manli, and Inno3D), it was a Manli GTX 1060 and it was abused by me for the entire time I gamed on it, overclocked to its limits to squeeve every bit of performance until I upgraded to an Asus Strix 1080Ti which had coil whine where as the 1060 was silent. In my personal experience, I would buy a Manli card over all these brands because of what my experience has been with that brand of card.",
      "Same here. Always chosing msi motherboards and msi video cards and never had a single problem with them.",
      "Thank you so much! I've discovered invaluable insights in your comment, providing a thorough explanation of the actual aspects of AIB. However, on a personal note, I'm seeking a graphics card with a more substantial and beefy/bulky look.",
      "Asus TUF is the only MSRP GPU I would recommend.",
      "How are the temperatures and noise with this card? Really dig the white look :O",
      "That is really good to hear, thx for the feedback.",
      "Refused warranty of my dead gigabyte Aorus Xtreme RTX 3090 - their flagship model with explanation that it was tempered with it - no warranty sticker but the card was shipped to me without one and I bought it directly from shop even the shop checked and they had brand new gigabyte cards without one and other models with one",
      "Couldn’t agree with you more. EVGA was the best of them and now we’re left with all the bad apples.",
      "No worries and happy Friday 🙂",
      "Mhh isn’t the Zotac one smaller in height and width? And doesn’t that mean „worse“ temperatures ?",
      "https://www.techpowerup.com/review/zotac-geforce-rtx-4070-ti-super-trinity/\n\nZotac has a good cooling Asus is very good too",
      "I was looking at the 4070 Super ASUS TUF but not sure about the brand itself, heard ASUS got some bad coil whine.",
      "Take a glance at the Zotac 4070ti Super Amp Holo card. It's enormous and has a robust and bulky build – quite impressive!",
      "If you take the time to read people’s experience trying to claim the warranty with Gigabyte then you’d want nothing to do with them at all.",
      "MSI's mobo software \"Dragon Center\" is straight up trash",
      "I'm RDR2 I was getting 57-63 C and the card is super quite compared to my 3080."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "rtx 4070",
      "4070",
      "4070 super",
      "4070 ti super",
      "4070ti super",
      "4070ti",
      "4070 ti",
      "rtx 4070 ti",
      "rtx 4070 ti super"
    ],
    "title": "Gigabyte 4070 Ti Super EAGLE OC and Gigabyte 4070 Ti Super WINDFORCE use coolers much smaller than the Gigabyte GAMING OC, or Asus TUF. Anyone have thermal benchmarks for these SUPER cards?",
    "selftext": "My options are..\n\n* Buy the **Gigabyte 4070 Ti Super WINDFORCE** locally soon. Convenient because I can get it fast, and if I have issues I can return it fast, instead dealing with shipping. $1099 CAD\n* Buy the  **Zotac RTX 4070 Ti Super Trinity** for $30 CAD less, but have it shipped here from a local Canadian retailer. Free shipping, but I have no idea if it'll take 2 days or 2 weeks. $1069 CAD\n* Wait for the **Asus 4070ti Super TUF** to be back in stock, which seems like it could take a hell of a long time. Can't find much on amazon or locally in stock. Been checking daily for a week, but losing hope. Temps on this massive beast are likely the best from all my options. It'll be a really tight fit into my case, but I believe from my measurements it should just barely fit. $1099 CAD\n\nI was kind of considering the 4070 Super as well, but I'm thinking of doing some Stable Diffusion work, and would like this GPU to work well in games, as well as Stable Diffusion for the next 5 years. The Super Ti is 33% more money for only 15% more performance, and 4GB more VRAM, so it starts to look like a lot worse value, though. But it's also not uncommon to pay a premium, and see worse FPS/$ at the high end. \n\nIf the **Gigabyte 4070 Ti Super WINDFORCE** temps are ok, maybe I should just pull the trigger on that. It's just so small compared to a lot of other cards. It's smaller than my brother **4070ti** Eagle cooler. And the **4070 Ti Super Eagle** cooler is also smaller and downgraded compared to his. It's the same as the Windforce. ***261mm***.\n\n...anyone have the Eagle, or Windforce Ti Super. I'd like **hotspot** temperatures in something like Cyberpunk with RT enabled. Or furmark. Or something replicatable on my brothers on my brother 4070ti with a ***301mm*** cooler.  I just don't know if going for the cheaper build card is a mistake if I could wait, and wait, and wait for the TUF to come back in stock locally or amazon. ",
    "comments": [
      "I would be ok with the windforce v1, but the windforce v2 seems like a bit of a clunker, with temps (anecdotally) reported as 10C higher than the earlier model. I guess gigabyte wanted to cut costs for the super lineup.",
      "I bought the 4070 Ti Super Windforce card had it a week and returned it. It feels cheap and I had Cyberpunk crash a couple times on me so I returned it and picked up the Asus TUF Gaming card. It is the opposite very big heavy card but Cyberpunk hasn't crashed since. Also surprisingly the fans on the Asus card are more quiet then the windforce.",
      "I own the Gigabyte 4070Ti Super Windforce. It feels cheaply made and it runs hot. I've had no issues with it performance wise and it lives in Fractal Arc Midi R2 case.",
      "Came to say when researching I read issues with the wjndforce because that off the eagle.put me.off to.\n\nEnded up with the asus dual oc",
      "Was even thinking of saving $280 CAD, and just getting a 4070 Super instead, and just sell early, and upgrade again in 3 years instead of trying to stretch it to 5 years. I mean I'm paying 33% extra for the ti Super for 15% perf and 4GB of VRAM. Which seems like a lot for that.\n\nOr even go as far a regular 4070 which I can get now for $699 CAD for a 2 more days if I act fast. That's a $510 US converted, which is a pretty sweet deal, although it's a really cheap PNY 4070 Verto. But still, the hotspot temps from that are at least under control since it's only a 200w card anyways. But it's also the bare minimum to get Path Tracing to work today at acceptable levels, and I'm hesitant on how well that will work like 3 years from now.",
      "They didnt realize the 40 series were very efficient cards so they went with a big heatsink for the 40 series. My 4070 Ti Aorus Master for example doesnt get higher than 65 degrees even at unlocked 128% power which draws anywhere from 260-310Watt.\n\nBut then again to answer your question, Gigabyte is propably your best bet this generation if you want good temperatures because they have the biggest heatsink of all other brands. Even if the Super variants have a smaller heatsink, the temperature difference wont be huge, merely a 3-5 degrees i assume. Anything between 70-80 degrees is absolutely normal for a GPU and the hotspot usually should be approx. 15 degrees hotten than the GPU die.\n\nAlthough between TUF and Windforce, TUF is a more premium model but it matters little.",
      "There is a review of [Gigabyte 4070 Ti Super WINDFORCE](https://www.eteknix.com/gigabyte-rtx-4070-ti-super-oc-graphics-card-review/16/) from ETeknix. They reported that after an hour of gaming:\n\n>*GPU temperature remained just under 69 degrees, with the hotspot peaking at around 82 degrees. Our memory junction temperature stayed fairly  cool at 72 degrees all while using around 274 Watts of power. The clock  speed did manage to boost up to 2775MHz in places, and the fans were  bordering on the more audible side at just shy of 2000 RPM.* \n\nSo decent cooler it seems, though pretty high fan speed (typical of Gigabyte, I have the 2060 Super and 5600XT Gaming OC, have similar experience temp/fan speed wise).\n\nMeanwhile TechPowerUp reviewed the [Zotac RTX 4070 Ti Super Trinity](https://www.techpowerup.com/review/zotac-geforce-rtx-4070-ti-super-trinity/39.html) and compared it to lots of other 4070Ti Super models, including Gigabyte Gaming and Asus TUF. Seems a bit worse than both at stock. With fan tuning you probably can get more out of it.",
      "Thanks.",
      "Wouldn't worry much about that level of junction temp. GPU die temp can run up to 95°C, and 110°C for junction temp, and that's still within safe operating margin. Sure the TUF is better and is preferable, but like you said stock may not come back soon. So all depends on if you can wait it out.",
      "Probably doesn’t matter at all unless overclocking bc they are so power limited/efficient",
      "Yeah, that's the only one I found too. But the thing is I have no idea how intense that game is. He tested the [4070ti TUF](https://youtu.be/kDHjrmjTx0E?si=b23h83p6eSJl1oif&t=486) as well in that game. Also, look at the screenshot in that link, or the timestamp [here](https://youtu.be/15vHr1QJYUM?si=kZLf7fVCdDw1VWQ7&t=1699). It's at only like 83% GPU usage. If it's already at 83c junction, I'd be curious where it would be at 100% usage."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "rtx 4070",
      "4070",
      "4070ti",
      "4070 ti",
      "rtx 4070ti",
      "rtx 4070 ti"
    ],
    "title": "RTX 4070 Ti vs. RTX 3090",
    "selftext": "Looking to buy a used PC, mostly for machine learning development, but potentially some gaming too. I’m not super familiar with the going rates for these cards in the US, but I’ve seen these two offers:\n\n1. RTX 4070Ti + i7 14700 + 32gb DDR5 — $1000\n2. RTX 3090 + Ryzen 7 9800x3D + 64gb DDR5 — $1500 \n\nI’m not too sure which of these offers is better, I’d appreciate any thoughts or advice. Thanks!  \n\n",
    "comments": [
      "for machine learning the 3090 24gb vs 12gb vram and just 2% diff perf in games and with that 9800x3d you always con drop a better card in the future",
      "Definitely the 3090 if you are going for machine learning.",
      "No wrong.\n\nHe does ML you want 2x GPU memory at least as RAM\n\n64GB is minimum with a 3090",
      "for LLM etc, 3090 may be the way to go.  However, 4070ti will use much less power moving f/w...  so..  if you care about running cost, go with 4070ti.",
      "64gb of RAM is generally overkill and I typically lean towards Intel processors but everyone has their preferences. I'd personally go with the $1000 and use the extra $500 for accessories/peripherals."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "rtx 4070",
      "4070",
      "4070 ti super",
      "4070ti super",
      "4070ti",
      "4070 ti",
      "rtx 4070ti",
      "rtx 4070 ti",
      "rtx 4070 ti super",
      "rtx 4070ti super"
    ],
    "title": "Is 1200 canadian a good price for rtx 4070ti super",
    "selftext": "Hello, is 1.2k a good price for a rtx 4070 ti Super? ",
    "comments": [
      "Jesus just buy a 5070 ti",
      "$1200 USD for that card is actually ridiculous. Your friend is an idiot, that's not how much it costs.",
      "No",
      "Damn that's a steal",
      "Conversion to getting scammed at the same ratio is not a good base conversion to start it. 1200 could land him an PNY OC 5080, not the msrp, one for the same price if availability is ever real.",
      "TBH I'm not sure what a good price is, but one of my buddies just paid $1,200 USD for the same thing so technically I think you're getting it for cheaper than he did. 1200 CAD is ~842 USD.  MSRP of 799 USD so you're pretty close to MSRP actually.imo",
      "I would say yes but only as of now, in reality that card is not worth anything beyond 900CAD or even less, it's a beast card though, almost a 4080, but at 1313CAD a 5070ti is available regular drops at bestbuy, if you're gonna spend that much money then might as well spend 100$ to get the most out of it. But even on its own 4070ti super is a decent 4k card but for 1200CAD it's kinda too much in my opinion.",
      "Fuck no",
      "Absolutely not.\n\nThey are selling for $1000 CAD not $1200 :(",
      "I didn't say he got a good deal by any means.  I'm simply referencing him because it's the same card. I'm not sure what the CAD MSRP of that card is, but by conversion it's pretty close.\n\nedit: Google says the MSRP of the 4070 ti Super is $1075 CAD. so it's roughly 10% higher than market",
      "It was Zotac open box so it had a warranty. Sold it last month for 789$ after taxes and ebay fees and used that to get an RX 9070 XT.",
      "I bought mine in november for $699 but that aint realistic anymore",
      "Could've gotten the 5070 ti for that price. Im assuming thats before tax.",
      "Go to eBay and look at how much they sold for recently. There is also a website that tracks prices on Amazon.",
      "Just get a 5700 Ti or a 9070 XT. If you're actively looking for a few days you can get a 9070 XT for around 700 and it'll be a bit faster than the 4070 Ti Super in most cases"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "rtx 4070",
      "4070",
      "4070 ti super",
      "4070ti",
      "4070 ti",
      "rtx 4070 ti",
      "rtx 4070 ti super"
    ],
    "title": "ASUS ProArt RTX 4070 Ti SUPER Waterblock?",
    "selftext": "Hello,\n\nI would like to know if you could help me, because I can't find a precise description and information anywhere about whether there is a compatible water cooling for my video card.\n\nI was able to see that the TUF series was made with the same PCB structure.\n\nAnd I also checked that the 4070Ti and 4070Tisuper from the TUF family look the same in terms of construction.\n\nBut the PCB of this proart GPU looks different:\n\n[https://www.formulamod.com/Bykski-GPU-Water-Block-For-Asus-ProArt-RTX-4070-Ti-OC-Full-Cover-With-Backplate-PC-Water-Cooling-Cooler-N-AS4070TIPR-X-p5566425.html](https://www.formulamod.com/Bykski-GPU-Water-Block-For-Asus-ProArt-RTX-4070-Ti-OC-Full-Cover-With-Backplate-PC-Water-Cooling-Cooler-N-AS4070TIPR-X-p5566425.html)\n\nThank you in advance for your help.",
    "comments": [
      "[https://www.amazon.com/GPU-Waterblock-GeForce-Cooling-Backplate/dp/B0CXXC6322?th=1](https://www.amazon.com/GPU-Waterblock-GeForce-Cooling-Backplate/dp/B0CXXC6322?th=1)\n\nFound this the other day while hunting. For alphacool, each of their 4070 ti blocks are compatible with the super variants, as they recently posted the article on their site. As for this block, I want to assume  the same. What I question is the reliability of the block. I have no issue with barrow, bykski/ other established Chinese brands, but this is straight no-name lol.",
      "[https://www.bykski.us/products/bykski-full-coverage-gpu-water-block-and-backplate-for-asus-proart-geforce-rtx-4070ti-oc-n-as4070tipr-x?srsltid=AfmBOoqUOWLqOA621PdkNdiYCQHIrduRXdGhSYdOw-ecTg9Pl3O8h7UZ](https://www.bykski.us/products/bykski-full-coverage-gpu-water-block-and-backplate-for-asus-proart-geforce-rtx-4070ti-oc-n-as4070tipr-x?srsltid=AfmBOoqUOWLqOA621PdkNdiYCQHIrduRXdGhSYdOw-ecTg9Pl3O8h7UZ)\n\nJust found this one as well, and Bykski is quite reputable. Sent them an email to check on compatibility and recommend you do the same, though I'll update should I hear anything back, Interested in a similar build myself within the coming months.",
      "Just ran across this post while investigating this exact issue. I got an Alphacool Eisblock Aurora block for the ASUS 4070 TI that should be compatible with TUF, and the PCB absolutely does not match the ProArt :(",
      "Have you heard anything?",
      "Have you found a block to fit the pro art ti super yet?",
      "The block is compatible! The only difference among the 2 pcb is just the additional 4gb of memory, but everything remains the same. \n\nI personally ended up going with the gigabyte gaming oc 4070 ti super and corresponding alpha cool block. Non-existent coil whine, great oc headroom, and cold temps even before block.",
      "i got that water block from the link in the next comment from bykski"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "rtx 4070",
      "4070",
      "4070 ti super",
      "4070ti",
      "4070 ti"
    ],
    "title": "GPU for design and architecture",
    "selftext": "Hi, I'd need some advice on buying a GPU. I usually work with Illustrator Photoshop, InDesign and Autocad. Well, I have replaced it with Zwcad (eventually with Revit but I'm a basic learner) and, in the beginning, I was thinking of buying Nvidia 4070 or 4070ti or 4070 ti super. I know the current issues with Nvidia so at this point I don't know if I should consider buying Nvidia. Nvidia is considered reliable for working with graphics, but someone recommended me Gigabyte RTX 4070 Windforce 2x OC 12GB GDR6RX DLSS3. It's a bit expensive (€699) ((expensive considering the sum of all the components)), compared to a\n\n\\- Gigabyte RTX 4060 Gaming OC 8GB GDDR6 DLSS3 (€358)\n\n\\- Gigabyte RTX 4060 WindForce 2 OC 8GB DLSS3 (€310)\n\nThe CPU I was thinking of is AMD Ryzen 7 9700X AM5.\n\nThe point is: I'm not a gamer, but I work with graphics, so WhIch criteria or numbering should I pay attention to? I mean, I can't distinguish between the RTX 4060 and 4070, (I don't edit video, I don't play on the pc) and within the 4060 series, I don't know which one is 'better . I don't know if I choose Gigabyte I have to see 'RTX'.\n\nSomeone told me: If you’re not planning on gaming, stick with a common GPU,-more like a 4060- but spend the extra on NVMEs\n\nCould anyone give me somme recommendations?",
    "comments": [
      "I recently had to make a similar choice for my gf, but she’s an amateur photoshop user and just does it for fun, not professionally. I found this matter very hard to find good info on. Based on a gut feeling and some research, I do believe you’d do fine with a 4060. What I’ve found mentions that you’d need around 4 gb’s of vram for photoshop @ 4k. As for RTX, this stands for raytracing. I don’t *think* rtx matters for photoshopping; but every card onward from the 2000 series produced by nvidia has RTX. \n\nThe 4000 cards are nog being manufactured anymore, and due to the scarcity of the new 5000 series, people are buying the old stock of the 4000 cards while they still can for a reasonable price. \n\nPlease note that I am by no means entirely knowledgable on gpu’s for graphics design, so take my input with a grain of salt where needed. Hope it helps.",
      "get like 64gb of ram or more, multiple nvmes and if its in your budget a 4070 ti super and if possible a 16core cpu but only if its in your budget. And dont throw this pc out wheb you upgrade next sone gamer would love it when you’re done.",
      "checl the prices on the core ultra 5 in your country. in australia its cheaper than the 9700x and whoops its ass",
      "Hi, thanks a lot! Any help is really appreciated!"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "rtx 4070",
      "4070",
      "4070 ti super",
      "4070ti super",
      "4070ti",
      "4070 ti",
      "rtx 4070 ti",
      "rtx 4070 ti super"
    ],
    "title": "Need help with pcie cables to rtx 4070 ti super",
    "selftext": "So I'm going from a 3070 to 4070ti super and my 3070 was able to get by with my 6+2 pcie cable. Now with the 4070, it requires 2 8 pin pcie. My psu is a evga 750 bronze from a few years ago. Does that support 8 pin pcie?",
    "comments": [
      "Hey man I finally got home and found another cable and gave it a try and it works. Thanks again, you saved me a trip to microcenter!",
      "Take a look at the ports on your PSU.\n\nIf it has two 8-pin power connector ports, you're all set. Just add a second VGA cable.",
      "It looks like your 750W PSU has two VGA ports and should be perfectly fine.\n\nYes, you'll need to buy a second 8-pin (or 6+2-pin) power cable.",
      "Yep, it's fine to leave the other 6-pin unconnected. I've had multiple cables left like that for years without issue. You just may want to make sure it doesn't dangle into any fans.",
      "Alright. Thank you for helping me out! Much appreciated!",
      "750W for a 4070 Ti Super? What is your CPU?",
      "https://www.bestbuy.com/site/sku/5594501.p?skuId=5594501 this one but the 750w version. It came with one pcie cord that has 2 6pin and 1 2pin. Do I just need to get another pcie cord then? I may have another 2 6pin+1 2pin pcie, but I will have two 6 pin ends dangling off since they are connected together",
      "im gonna buy the same wattage psu for the 4070ti super combined with a 7600, is 750 too low?",
      "I really don't know. PSU calculators confuse me since they often show that certain combinations are fine while the official spec often says you need more. I think this has to do with occasional power spikes where you need extra headroom. Please check out other threads where people have asked similar questions to be sure.",
      "Now like I said, the current cord I have has 2 6pin and 1 2pin all on one. Will it be ok to use the 6pin and 2 and just have the other 6pin dangling off not connected to anything?",
      "Yea ive got a 4070 Ti SUPER with the i7 13700K and I've gone for 850W to be safe but 750W is fine I think I was just a bit paranoid.",
      "Np! Enjoy the new card"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "rtx 4070",
      "4070",
      "4070 ti super",
      "4070ti super",
      "4070ti",
      "4070 ti",
      "rtx 4070 ti",
      "rtx 4070 ti super"
    ],
    "title": "4070ti super lower base clock than 4070ti?",
    "selftext": "I am looking online and I am wondering, is a 4070ti super with 1.92 gigahertz base clock better than a 4070 ti with a  2.31 gigahertz base clock?  Why would the super have a lower base clock?  \n\nI’m comparing the MSI NVIDIA GeForce RTX 4070 TI SUPER 16GB VENTUS 3X OC 16GB\nand the Gigabyte NVIDIA GeForce RTX 4070 Ti Gaming OC 12GB on Best Buy’s website.  Which is the better option?\n\nhttps://www.bestbuy.com/site/msi-nvidia-geforce-rtx-4070-ti-super-16gb-ventus-3x-oc-16gb-gddr6x-pci-express-4-0-graphics-card-black/6571811.p?skuId=6571811\n\nhttps://www.bestbuy.com/site/gigabyte-nvidia-geforce-rtx-4070-ti-gaming-oc-12gb-gddr6x-pci-express-4-0-graphics-card-black/6527972.p?skuId=6527972",
    "comments": [
      "The super card will be faster overall. It has more of the hardware components overall to do the work even if they don't run at as high a clock speed.",
      "No it doesnt. The Ti super is better.",
      "Omg the baseclock is lower omg Omg Omg",
      "Some 8 cylinder engines run at lower RPM then some 4 cylinder engines. But they often still have more horsepower overall.\n\nThe 4070ti Super has more shader cores, but it's given the same amount of fuel so it has to spread that fuel out thinner across each shader core. So each core can't rev as high.\n\nThe 4070ti is a horrible option for anything over $680 now. You just get a 4070 Super instead for $599 at that point",
      "Clocks are just instructions per cycle. But if the rest of the chip just does more to make each cycle more efficient and better than it can be a faster chip with lower clocks.",
      "Base clocks are weird. \n\nYou can take a founders edition and overclock it to more or the same specs as the third party overclock editions. All you pay (besides \"better\" cooling and looks) is the factory does it for you. \n\nSo if you never want to bother overclocking it yourself, buy the card that's overclocked right out the box.",
      "Just look at benchmarks.\nPure numbers mean very little.",
      "Idk if it that matters or not",
      "Is the 4070ti super still a good option?",
      "Yeah, that just came out a week ago. Just the non super cards that were replaced with the Super cards in January are almost all still overpriced."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "4070ti super",
      "4070ti"
    ],
    "title": "Help! My new 4070ti super graphics card is performing very poorly. I made sure the bios and drivers were up to date. What could be causing this?",
    "selftext": "&#x200B;\n\nhttps://preview.redd.it/1ig1809a4wgc1.png?width=2139&format=png&auto=webp&s=7c85cc2c796c75d49430690304db313e8f3be861",
    "comments": [
      "userbenchmark is literally horseshit. dont ever use that website please",
      "is... is that userbenchmark",
      "Why are people failing for UserBenchmark bullshit?\n\nIt’s nothing more than a troll site. \n\nUse a real benchmark test. Like Cinebench or 3D Mark. Or FurMark.",
      "spend $6 and buy 3d mark. then run timespy",
      "No it doesn’t. You are being lied too.",
      "that is called margin of error. aka normal just ignore it. 2% variance is meaningless. You are looking at a difference of 0.01 frames per second",
      "I’m guessing there won’t be a bunch of people in the comments saying this is why they won’t buy Nvidia cards like there would be if you were posting issues with an AMD card.\n\nThat said, have you tried doing a clean install? Fresh drive, then install only the OS and the GPU drivers.",
      "You don’t have to buy any benchmarks. Just play a game and look at your fps. Search up ‘4070ti super (game)’ and look at what fps they get. Just make sure all the settings and the resolution is the same.",
      "The average on timespy includes extreme overclockers, look at the bell curve. If you’re on the peak or near it you’re fine. Average is skewed past it due to extreme OCs.\n\nUserbenchmark is blscklisted basically everywhere it’s awful. I used their shitware before on a 6900xt to prove a point. They put my card stock in the bottom 10% and with a 100mhz core OC it was top 1% for them.\n\nAll this to say, their website and software is dog water and filled with extreme bias.",
      "normal, nothing to worry about",
      "I'm game. This kind of thing really *is* why I won't buy an Nvidia card...\n\n/s\n\nSeriously though, I've had no more or greater issues with AMD/Radeon cards (9600, X1300, 6800XT, 7900XTX) than I've had with Nvidia cards (5700, 8600, 970m,1070, 3070, 3070ti) though there was a break of some years between the first two of each list and the rest.\n\nOr, well... there was that one time where I had this one game (Total War: Warhammer 2) first go weird af for 3 days then totally bork out for 6 months apropos of nothing and no fixes working. That was a 1070, one of two which were otherwise ok, but can only have been some issue related to the card which was otherwise fine and lasted another few years (despite the initial symptoms looking like typical card dying behaviour)",
      "This. Would never pay for it",
      "Run pass mark video card benchmark and compare it to the 4070 to average if you need a free alternative. Will give a better idea than user benchmark",
      "show results. \n\nwhat is the score?",
      "Is it overheating? You can get and run hwinfo64 which parses all the data from your temperature sensors, and see if the GPU temperature is hitting the GPU thermal limit, which would result in thermal throttling. Just have that software open while you do 3dmark and then you can check the maximum value for the GPU temp",
      "I just took the front panel off and got a score of 19106.  Average is 19479.  Is this normal?  I am not overclocked.",
      "Make sure freesync, Vysync, and/or gysnc are all disabled your framerate is probably just being capped",
      "Download GPUZ and post a screenshot.",
      "How about trying an actual benchmark? And not whatever the fuck userbenchmark is these days.",
      "ok"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "rtx 4070",
      "4070",
      "4070 ti super",
      "4070ti super",
      "4070ti",
      "4070 ti",
      "rtx 4070ti",
      "rtx 4070 ti",
      "rtx 4070 ti super",
      "rtx 4070ti super"
    ],
    "title": "rtx 4070ti super vs rtx 4080 super",
    "selftext": "should i get the rtx 4070 ti super from zotac ( super solid line) at 839   \nor should i get the rtx 4080 super from msi ( ventus line ) at 1079  \ni played at 4k with my lg c3 oled , im so confused right now",
    "comments": [
      "RTX 4080 super is better for 4k",
      "I would wait, 50 series is around the corner and the prices will adjust.  \n4070ti super will struggle in 4k, so you will have to dial down details, not even talking about raytracing.  \nMy friend built a system with 7600x3d and 4070ti super over christmas and hes not happy playing in 4k - his expectations were, uhm, higher.\n\n4k is still a luxury and expensive.  \nAs reference - even my 4090 struggles at times to give me 100fps @ 4k in some games (thats with frame gen and dlss...).  \nso for 4k, the bigger the better -> wait for 50 series.",
      "what were your friend's expectations based on.\n\nSince the 2000 series people boast about having 4K cards. The gaming landscape got much higher requirements, which is exactly why Upscaling has become more commonplace.",
      "than a 4070ti super will more than be enough. [https://www.tomshardware.com/reviews/gpu-hierarchy,4388.html](https://www.tomshardware.com/reviews/gpu-hierarchy,4388.html)",
      "Yeah, Zotac is a decent option, they provide 5years (3+2) warranty too.",
      "Sapphire is the evga of amd. And yes",
      "He was expecting 60+fps with everything maxxed.  \nMainly based on, well, reddit lol  \n  \nWe went through benchmarks from various sources with him but he always had a objections about the results. He learned the hard way I suppose.",
      "Just wait lol",
      "I’d highly suggest you wait for the 5080 to be announced at CES on jan 6 as it already seems to be about 10-20% faster than the 4090 according to the leaks and rumors.\n\nEven if nvidia outrageously priced the 5080, it will still benefit you as prices for the 4080 or 4080 super will go down.\n\nIn the meantime, your LG C3 OLED is compatible with Geforce now (assuming you’re in a country where geforce now is available) so you could use geforce now for a month until the 5080 is launched.",
      "It's certainly a bit faster, but it's not enough to make a meaningful difference in terms of playable settings/games.",
      "im not looking for ultra tho , just good looking (medium / high) at a playable fps 60+ , just that , and i am ready to spend 1.2k -ish maybe , just not the 2k or the 1800ish price point",
      "ah i see , thanks for the insight sir , have a good day",
      "No need to worry. MSI usually launch 3 (or it might be 4) versions and they are quite consistent with this. It goes  (from entry to premium) Ventus, Gaming, Suprim. I think there may be a 4th but the name escapes me. They do do different variants of these (especially in the Gaming line) but the differences can be subtle, base clocks, cooling etc.\n\nThey are all good cards IMO. I've had many GPU's over the years, the last two have been the MSI 3080 Gaming X Trio and the MSI 4080 Super Gaming Slim. I've had zero issues with these, and the 3080 is still going strong in a friends PC.",
      "Im playing 4k with a rtx 4070 ti s and a 7600x n i am extremely  happy with wat i got",
      "CES is so near.....a few days away..just wait for the 5080 to be announced and see if have any discounts coming after the 5080 release.  At least see the sentiments after the announcement. LG C3 is seriously a nice TV, will be a shame to turn off the RT and other stuff just to get a decent 60fps.",
      "Asus TUF RTX 4070 Ti Super here and I have been using it as an eGPU via USB4. Got it over a month ago and ignored all the 50 series wait suggestions for several reasons. Very happy overall. Got both a 1440 Oled and a 4K LG CX OLED which I got a while ago for my consoles. I can play on both with a very good result. Example Stalker 2 on medium on 4K runs pretty well and looks great with Medium settings.\nEvery website suggests 4070 is a better value so go for it.",
      "I've got a 4080s ventus; it's fine.",
      "I like my Ventus and have had zero issues.",
      "No, sorry. The FF games aren't for me. But here's a [benchmark vid](https://youtu.be/OxNFSjf3YtQ?si=tjzZ-SHhZwhUm8c9) showing how the 4070 Ti Super performs at various resolutions, including 4K, in FF16. At 4K Ultra with DLSS Q, without frame generation, it seems to run at around 60 FPS.",
      "i guess this mean that zotac is good right?"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "rtx 4070",
      "4070",
      "4070 ti super",
      "4070ti super",
      "4070ti",
      "4070 ti",
      "rtx 4070ti",
      "rtx 4070 ti",
      "rtx 4070 ti super",
      "rtx 4070ti super"
    ],
    "title": "RTX 4070 ti super - ASUS vs GAINWARD",
    "selftext": "I am building PC with RTX 4070 ti super.\n\nI am considering two options:\n\n1. NVIDIA GeForce RTX 4070 Ti SUPER TUF GAMING 16G DLSS 3 - 1007 $\n2. Gainward GeForce RTX 4070Ti Super Phantom 16GB GDDR6X - 1077 $\n\nWhich one has better work culture? Any opinions?\n\nI mean asus has better benchmarks in 4070 ti; Gainward in 4070 and 4080",
    "comments": [
      "https://www.youtube.com/watch?v=udST-Hm7fg8"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "rtx 4070",
      "4070",
      "4070 ti super",
      "4070ti",
      "4070 ti",
      "rtx 4070 ti"
    ],
    "title": "4070 TI super or 4070TI",
    "selftext": "Should I get the 4070 TI super for 100€ more money then a KFA2 GeForce RTX 4070 Ti? Is it worth to spend 100€ more for a 3% Upgrade. Sounds ridiculous to me but maybe it is more future proof? I don't know.",
    "comments": [
      "You'll notice the biggest difference in 4k with the extra vram and wider bus.   If you don't do 4k they are almost the same.",
      "Thx for the quick answer. Playing on WQHD right now with 165hz.",
      "I would also stay away from the MSI cards due to their bios issue"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "4070",
      "4070 ti super",
      "4070ti",
      "4070 ti"
    ],
    "title": "4070Ti vs 4080 Super",
    "selftext": "Hi all! My current PC is really starting to show its age and I'm looking to build a new one, but I'm hung up on the graphics card. I was originally going to buy a lower cost 4080 Super but before I could, the model I was looking at was sold out and the next \"cheapest\" option is $1700, which is about $400 more expensive than my first choice. I'm instead looking at the 4070 Ti Super series since that was much closer to my original GPU cost ($1250-1350), but I wasn't sure if there was a major performance difference between the two that would justify biting the bullet and going for the more expensive model. I almost exclusively do single-player or co-op games at 4K and I am trying to future-proof this build as much as possible (so I don't have to upgrade for a considerable amount of time) if that helps. I'm no expert on PC building but I'll try to answer any other questions that I can if they will help. Thanks in advance!\n\nEdit: Should mention two things. I forgot to mention it's a 4070 Ti Super vs 4080 Super (apologies), and that my current card is an RTX 2080 (not sure if that's important, but wanted to add context)\n\nEdit #2: Ideally, I'd love if this graphics card could hold up for at least 4+ years with modern releases (not looking for ultra settings on every game, but the higher the better)\n\n  \nEdit #3: Thanks to some very helpful suggestions, I've decided to go with the more reasonably priced (but still high-performing) 5070Ti! Thanks everyone for all your feedback!",
    "comments": [
      "If those are the prices don't. \n\nThat's a joke",
      "Why not just go for a 50 series or amd 9070xt. 5070 ti is at a 4080 level for lower price. I have one and it just desreoys whatever I throw at it.",
      "Just go with 5080 in my country it cost less that’s 1700$ but if in your it cost more buy 4080s",
      "Appreciate the feedback! I was looking into it more and noticed the 5070ti might also be a viable option (and for cheaper too, compared to my other choices), how does that model measure up to the 40 series? Based on what I’ve read so far, it seems like it’s fairly similar to the 4080 in terms of performance",
      "I was going to mention that as the market is weird right now, I have a 5070 Ti and a 4080 Super and they are basically the same in performance but the 5070 Ti is quieter, cooler and uses slightly less power. I would choose the 50 series over the 4080 Super if I had to get rid of one.\n\n20 minute stress test on the 4080 Super :\n\nhttps://preview.redd.it/vfujbm96ujwe1.jpeg?width=2531&format=pjpg&auto=webp&s=2651d1c776cda73ae6fd8a890fb8d86120d2c552",
      "Wow, you went above and beyond, thank you so much! I was leaning towards the 5070 already (the crazy savings definitely helped haha) but this also helped convinced me, much appreciated!!!",
      "for gaming in 4k, the 4070tis will be too small for you in the foreseeable future, for 2k with DSR now it is an excellent card, which should be enough for 3-4 years for gaming on medium-high settings.",
      "The 4070 Ti Super is solid but if you want it to be more future proof then it’s the 4080 Super if you’re going to choose one of those specific ones.",
      "Wtf are those prices and why don't you just get a 5070ti or 9070xt? Get the one that's closer to MSRP that's all you need to know really.",
      "ows the 5070ti been?",
      "Sorry, I don't really know much about proper pricing for graphics cards (this is the the first time I've \"made\" a build on my own), do you have any good recommendations?\n\n  \nEdit: Looking at the 50 series and found a 5070ti for under 1k, would that be a better option?",
      "Still waiting for it to arrive haha, it’s gonna be at least a week before I can actually build this PC",
      "yeah of course it would",
      "It is within 3% of a 4080S. I would recommend you to get it over the 4070TiS.",
      "20 minute stress test on the 5070 Ti:\n\nhttps://preview.redd.it/fq9m6swbujwe1.jpeg?width=2447&format=pjpg&auto=webp&s=326d4e448793a49d02c065a3d0b7506983e08355",
      "Ohh ok no worries. Give us an update whenever it happens please",
      "No problem, the 5070 Ti will take a good OC too if you want a little extra performance. In a single steel nomad run the 5070 Ti went 75.12 with plus 440core +2000mem the other day.\n\nhttps://preview.redd.it/9nlzesfhvjwe1.jpeg?width=3024&format=pjpg&auto=webp&s=ed9572aa5b048a4042ead637209face56667a71b"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "rtx 4070",
      "4070",
      "4070 ti super",
      "4070ti",
      "4070 ti"
    ],
    "title": "gpu for graphic design and architecture",
    "selftext": "Hi, I'd need some advice on buying a GPU. I usually work with Illustrator Photoshop, InDesign and Autocad. (eventually with Revit but I'm a basic learner) and, in the beginning, I was thinking of buying Nvidia 4070 or 4070ti or 4070 ti super. I know the current issues with Nvidia so at this point I don't know if I should consider buying Nvidia. Someone recommended me Gigabyte RTX 4070 Windforce 2x OC 12GB GDR6RX DLSS3. It's a bit expensive (€699) ((expensive considering the sum of all the components)), compared to a\n\n\\- Gigabyte RTX 4060 Gaming OC 8GB GDDR6 DLSS3 (€358)\n\n\\- Gigabyte RTX 4060 WindForce 2 OC 8GB DLSS3 (€310)\n\nThe CPU I was thinking of is AMD Ryzen 7 9700X AM5.\n\nThe point is: I'm not a gamer, but I work with graphics, so WhIch criteria or numbering should I pay attention to? I mean, I can't distinguish between the RTX 4060 and 4070, (I don't edit video, I don't play on the pc) and within the 4060 series, I don't know which one is 'better . I don't know if I choose Gigabyte I have to see 'RTX'.\n\nSomeone told me: If you’re not planning on gaming, stick with a common GPU,-more like a 4060- but spend the extra on NVMEs\n\nCould anyone give me somme recommendations?",
    "comments": [
      "4070 ti s is good. Wait to see what the amd 9070/xt can do",
      "thanks!"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "4070",
      "4070ti",
      "4070 ti",
      "rtx 4070ti"
    ],
    "title": "Zotac 4070 ti Trinity (Non OC) or Zotac 4070 ti Trinity OC",
    "selftext": "Guy's I'm planning to buy a Zotac RTX 4070ti Trinity or RTX 4070ti Trinity OC \n\nMy current system system specs are \nRyzen 7 1700 stock \nGigabyte motherboard \n1TB silicon power NVME \nGskill Flare X 2400mhz \nGTX 1080 (now dead) \nA 1080p 144hz monitor \n\nI plan to upgrade the cpu to \nRyzen 7 5800X3D \nAIO Liquid Cooler for the Processor (Most Probably a 360mm)\n \nRyzen 7 7800X3D \nAIO Liquid Cooler for the Processor (Most Probably a 360mm)\nWhatever is the cheapest AM5 Motherboard with Wi-Fi capability \n32 or 16 gig's OF DDr 5 ram\n\nThe task intensive task on this pc will only be gaming and playing around and trying to learn Game Engine Cryengine, Unreal Engine and so on and maybe once or twice a year edit and render a few videos for fun and all\n\nThe processor upgrade will happen if the performance leap is significant between 5800X3D and the 7800X3D. I'm guessing a 30-40% + increase would be justification enough for the motherboard ram upgrade. Or else I'll be saving a decent amount by maintaining my current build. \n\nI tend to play co op and multiplayer and sim racing title's at 1080p at the max fps possible and story based titles at 4k Downscaled Super Resolution at around 45-60 fps \n\nI live in a moisture / humidity high place by the coastline. I need components with as much warranty as possible. Zotac is awesome at that with 5 year's warranty. My previous GTX 1080 served me well in the last 5 years. My plan is get a card that is Overkill now and 5 years later it's a pretty Decent Mid Range card. \n\nI kinda finalized on the Zotac 4070ti, I mean it's a very expensive card but it's 3090 performance levels. My plan was settle for the lowest end card and then years later consider OC if needed. I have realized with previous gens that getting an OC card doesn't mean you're getting performance enough to compete with the next card tier or extend the card competitiveness. It's more like 1-3% performance increase that is very much within the margin of error. So OC cards don't make sense. But here I see the Non OC card (2610 Boost) is getting 2 power connectors while the OC card (2625 Boost) is getting 3 power connectors so much more powerful is the card (15mhz) is it a card capable of going higher? Or what? What's the real world benefit / advantage of this card? Is it worth it? Non OC cost 82,999 Indian Rupees (1005.58 USD) vs OC cost 87,199 Indian Rupees (1056.47 USD) \nIs it worth the extra 4200rs ( approx 50USD) . The Additional Power connector aids in future potential OC? Or is it really useful? I kinda am left confused as to how is a 15mhz boost requiring an additional power connector, or rather is an additional power connector really just 15mhz of increase and is it worth anything in real world performance or capability? I mean they won't really add an additional power supply connector for just 1 - 3 % performance Increase right? What am I not seeing here? What's my mistake / mis-calculation here? \n\n\n\nEdit \n\nJust saw another review where the RTX 4070ti Trinity OC is outperforming the RTX 3090ti \nWhile all the other reviews I've seen of the RTX 4070ti Trinity (Non OC card) are below the RTX 3090ti, they are usually around RTX 3080ti - RTX 3090. Can anyone confirm that the OC card is really that high compared to the Non OC Card? Cause a 3090 performance level compared to the 3090ti performance level is a jump I'm willing to pay extra for! \n\nThe Zotac RTX The 4070ti Trinity OC card benchmarking ahead of the 3090ti review link\nhttps://youtube.com/watch?v=Sgt_DNdAtfA&si=EnSIkaIECMiOmarE",
    "comments": [
      "Having the same dilemma. Did you figure this out?"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "rtx 4070",
      "4070",
      "4070 ti super",
      "4070ti super",
      "4070ti",
      "4070 ti",
      "rtx 4070 ti",
      "rtx 4070 ti super"
    ],
    "title": "Will a 2 inch thick/height 4070ti Super fit my build?",
    "selftext": "I have a omen 875-0034 pre-built that I got as a gift years ago. At the time I upgraded the gpu and cpu aswell as adding a aio. Current setup is GPU Zotac 3070 twin edge with a i9 9900 cpu. I'm running into vram limitations and want to upgrade to the 4070ti Super. Was looking specifically at the GIGABYTE RTX 4070 Ti SUPER EAGLE OC https://www.techpowerup.com/gpu-specs/gigabyte-rtx-4070-ti-super-eagle-oc.b11491\n\nMy concern is the thickness of the gpu as the motherboard is a Edoras 84fd. https://support.hp.com/us-en/document/c06124984\n\nMy current GPU is 1.7 inches thick and is near to the motherboards power cord. The gpu I'm looking to get the 4070tisuper eagle is 2 inches thick. I'm concerned the thicker gpus fans will touch the motherboard power cord. \n\nI'm wondering if anyone has put a 2 inch thick gpu with this motherboard and had it work. Or has any advice on how I could make it fit. Thanks",
    "comments": [
      "Not sure if it would fit your build but I would just buy a case from Amazon or Best buy if you want it the same day and just put all your new stuff in there. Pre-builts are really just built for whatever they put in usually and not meant to really upgrade to bigger cards",
      "I thought about getting a new case, but im mainly concerned about the motherboards power connector hitting the gpu fans. And a new case wouldn't fixt that problem sadly."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "4070ti super",
      "4070ti",
      "rtx 4070ti",
      "rtx 4070ti super"
    ],
    "title": "RTX 4070TI Super Overclock & Nvidia App",
    "selftext": "Has anyone else tried the new AI overclock in the Nvidia app? I ended up trying it out then did a benchmark test and my GPU ended being on the leaderboard, i think i got lucky!  \nCLim: 3180 Mhz  \nMLim: 5350 MHz\n\nhttps://preview.redd.it/4qb3oly9obwd1.png?width=776&format=png&auto=webp&s=f0ae74562eb900514b93528568473bec1d560714",
    "comments": [
      "Don't use UserBenchmark. It's garbage. Try 3DMark or Superposition.",
      "Because they give bias conclusions, and inaccurate results that follow a \"scoring\" system that doesn't make any sense.",
      "Try something like superposition benchmark at 1080p extreme and compare to the leaderboard. 3180 is a very high boost clock.",
      "Use 3DMark. It'll compare your performance with others who have the same specs.",
      "I only got +135/+200 for core and mem frequency out of Nvidia auto tuning. What was your result?",
      "Maybe I’m old fashioned, but I still prefer an all natural organic overclock. \n\nAlso, 3180 sounds pretty high. What benchmark is that?",
      "Please run Superposition 4K Optimized or 3DMark's Steel Nomad. I have the same card, so we could compare our results and see if there is a big difference.",
      "Ain't no way in hell that 3180mhz OC is stable.",
      "https://preview.redd.it/ywohewcqybwd1.png?width=1024&format=png&auto=webp&s=090273c2e0e37cbdb2821db6f6d24b73c6b8ec1b\n\nthats at the 1080p Extreme, still pretty good?",
      "Yep, I'm curious too to see what value the NVidia App set. Mine was pretty low if I remember well, far below what I did manually...",
      "Not bad. Some high end models like aorus master or ROG strix can go pass 14000. But for your PNY it's an impressive score.",
      "New?",
      "why"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "4070",
      "4070ti super",
      "4070ti"
    ],
    "title": "Gigabyte 4070ti Super available now!",
    "selftext": "As title. All Gigabyte 4070ti Super variants are for sale and in stock right now on Amazon. Just ordered an Super eagle OC\n\n\nLink to available cards.\n\nhttps://www.trackalacker.com/products/showcase/nvidia-rtx-4070-ti-super\n\n\n\n",
    "comments": [
      "He prolly order a super or a ti as there is no ti super on amazon",
      "Here are the links to the products at least, from there there's a \"where to buy\" so maybe that will help you? \n\n* AORUS GeForce RTX™ 4070 Ti SUPER MASTER 16G: [link](https://www.gigabyte.com/Graphics-Card/GV-N407TSAORUS-M-16GD?lan=en)\n* AORUS GeForce RTX™ 4070 Ti SUPER GAMING OC 16G: [link](https://www.gigabyte.com/Graphics-Card/GV-N407TSGAMING-OC-16GD?lan=en)\n* GeForce RTX™ 4070 Ti SUPER AERO OC 16G: [link](https://www.gigabyte.com/Graphics-Card/GV-N407TSAERO-OC-16GD?lan=en)\n* AORUS GeForce RTX™ 4070 Ti SUPER EAGLE OC 16G: [link](https://www.gigabyte.com/Graphics-Card/GV-N407TSEAGLE-OC-16GD?lan=en)\n* AORUS GeForce RTX™ 4070 Ti SUPER WINDFORCE OC 16G: [link](https://www.gigabyte.com/Graphics-Card/GV-N407TSWF3OC-16GD?lan=en)",
      "Yep, they'll be whining here when that 12gb card hits the mailbox...",
      "I don’t see them in the US either. Wonder if this dude bought third party.",
      "Amazon is broken for me or their algorithm is stupid. When I type in Rtx 4070 ti super I only get 4070 super or 4070 ti but when I click on those links I see the products",
      "Good luck 🤞 holding out for 5080 :)",
      "Link",
      "In the US? Don’t see them in Canada.",
      "link?",
      "Nope, ordered a TI super. 16gb\n\nI had a tracker setup, surprised it was in stock.",
      "Edited with link",
      "Good for you but I haven’t found a single one since yesterday",
      "If it’s on Amazon most likely 3rd party",
      "Probably bought the wrong model.",
      "https://www.trackalacker.com/products/showcase/nvidia-rtx-4070-ti-super",
      "Yea it seems I might have ordered 3rd party but I see it as I have an order secured. Supposed to come in 2 weeks.  At any rate, if I can get my hands on an 4080 super FE edition I'll just cancel/return 4070 tiS"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "rtx 4070",
      "4070",
      "4070 ti super",
      "4070ti super",
      "4070ti",
      "4070 ti",
      "rtx 4070 ti",
      "rtx 4070 ti super"
    ],
    "title": "4070ti Super/PSU query",
    "selftext": "Hi all, \nFirst off I would like to express that I understand how many posts there are with similar questions to this but I’m struggling to find anyone with the exact same questions.\n\nSo I have an “Aerocool Integrator 700W 80 PLUS Bronze Non-Modular” PSU and I’m looking to upgrade my GPU to an “MSI GeForce RTX 4070 Ti SUPER 16G VENTUS 2X OC” GPU. \n\nI’ve found that the GPU is a special 12pin connector that’s different size connectors to the 8pin 3060ti I have right now.\n\nThe 40 series cards (from what I’ve seen) come with an adaptor to plug 2x6pin cables into which then plugs the special 12pin into the GPU at the other end.\n\nMy questions are\n1, is my 750W non-modular PSU good enough to handle the 4070ti Super?\n\n2, I can only find one 6+2 cable in my PC that has another 6+2pin routed from it (see photo as im awful at explaining things) so my question is, is it ok to use those two 6pin connectors from the same wire to connect to the adapter for the card?\n\nThe user manual for my PSU shows I should have two of these wires but I can only find one so I’m not sure I have the correct information. \n\nPlease note that I’m new to PC’s and their internals\nI’m especially new to PSU’s \nI’d appreciate any help you can provide as I would ideally like to avoid replacing my PSU purely down to the fact I have no idea how to actually replace it physically.\n\nImages attached for reference of the above questions. \nThank you.\n",
    "comments": [
      "The answer is yes. It can support it. Those cards come with adapters and you have 2 dedicated cables you can plug in the adapter which will power the card just fine. Obviously people will screech at you for not buying some overkill PSU that has a dedicated 12VHPWR connector on it but realistically you don't need it for the 4070 ts to work properly.",
      "Would've been ideal with 2 different cables but a single cable will do just fine.",
      "If you only have one GPU cable, you’re going to need to get a fully modular PSU. If you daisy chain the only GPU cable, you risk melting the cable and damaging your GPU. I have the 4070ti super and it will come with the adapter!\n\nhttps://preview.redd.it/tbdkqk8ovy9d1.jpeg?width=3024&format=pjpg&auto=webp&s=5fb4a90b11d07fae45adf858a7c3734a677916a6",
      "Instruction manual says to use two cables. Standard GPU cables are rated for 150w and the 4070ti super draws 285-300w. Trying to pull more watts than the cable is rated for causes melted GPU cables, damage to the GPU and can start a fire..",
      "Your GPU needs around 285w, but one 8 pin cable plus the pcie slot can only provide 225w which is not enough and could potentially be a fire hazard.",
      "So yes it's enough, first though most 3070 ti supers comes with 3 like the 4080super. If you use 2 on the models with 3 you cannot use the extra power in the OC apps. It will only let you go to 100% which is fine it's still 100% of the tdp. If you use the 3rd plug it allows you to get rhe extra % as explained by gamer nexus. It's due to the sensory pins it knows how many are plugged in. But if you get the tuf. The tuf only has 2 connectors so that one will give you the extra 10% without needing a 3rd. So yeah gl the psu is plenty and you are good to go. Luckily I already went through all of this lol.",
      "Stop, and buy a PSU with 12VHPWR/12V-2x6.\n\nIt's the future for all GPUs and most of those cheaply made adaptors are horrible.\n\nI have been using native 12VHPWR for my 4090 since Sep 2022 without a single issue. Way smarter. Looks better. Much less cable mess. Clicked right in and stayed there. People with no experience with it, will say stupid stuff but 12VHPWR is simply much better than hooking up 3x8 pin like my old GPU used.",
      "You mean the 12+4 pin? You’ve got the money for the GPU, spend a little more and get an 80+ gold PSU that will properly support that GPU. You can get good, modern PSUs in the 750w - 850w range for $100ish easily. PSU is something you want to make sure will work. Don’t chance it, just upgrade.",
      "Even though it’s only one wire with two plugs?",
      "The first image which does seem to correspond to this model PSU shows that it has two dedicated cables. The other one is probably just bundled up with the cables down by the PSU itself, if your current GPU only used one connector. You really should use one connector from each cable, not both on the same cable.",
      "It's a ti super some have 3 plugs. Only the tuf really has 2 and I believe and one other. Most 4070 ti supers have the adapter with 3 connectors like the 4080 super.\n\nYou can use only 2 if you want the 3rd is needed to pull the extra % if yoy decide to OC yoy can only utilize 100% of the tdp. You can't add extra to it which is fine it still gives you everyrhing just not the extra power most utilize when they OC. Its due to the sensory pins. It knows when 2 or 3 plugs are connected. If you get a 4070 ti super tuf you won't have to worry about that as it comes with only 2 on the adapter and you can get the extra 10% with that one. Kind of a plus. \n\nLuckily I already went through all of this so hopefully it helps him."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "rtx 4070",
      "4070",
      "4070 super",
      "4070 ti super",
      "4070ti super",
      "4070ti",
      "4070 ti",
      "rtx 4070 ti",
      "rtx 4070 ti super"
    ],
    "title": "Which 4070Ti Super to choose?",
    "selftext": "I'm decided to go for 4070Ti Super for my gaming build, but I need some help deciding \\*which\\* model of that card to choose. I'm going for a cheeper option, so they are kinda limited. I also assume 3-fan model would be better than 2-fan, cuz 4070Ti Super seems to be a bit warmer than 4070 Super I originally wanted to go for. Anyway, these are the models that's within my price range:\n\n- KFA2 GeForce RTX 4070 Ti Super EX Gamer V2\n\n- Zotac GeForce RTX 4070 Ti SUPER Trinity OC\n\n- Zotac GeForce RTX 4070 Ti SUPER AMP HOLO\n\n- Gigabyte GeForce RTX 4070 Ti SUPER WINDFORCE OC\n\n- Gigabyte GeForce RTX 4070 Ti SUPER WINDFORCE **MAX** OC\n\n- MSI GeForce RTX 4070 Ti SUPER VENTUS 3X OC\n\nBefore some suggests ASUS cards, ASUS 4070 Ti Super are so expensive over here that I can get a cheaper variant of 40**8**0 Super by paying slightly more. They are WAY outside the what I'm willing to pay.\n\nThat's said, currently I'm leaning towards Gigabyte's Windforce **MAX** model. I figure the giant heatsink would mean lower temps and quieter fans out-of-the-box, as well as give me a bit more headroom in manual UV/OC departament",
    "comments": [
      "TechTesters recently tested 7 RTX 4070 Ti Super models: https://youtu.be/UHWCDyOVp64   \n- MSI Ventus 3X (MSRP Model)   \n- Inno3D Twin X2 (MSRP Model, 2 Fans)   \n- Gigabyte Gaming OC   \n- Gigabyte Aero White    \n- Asus TUF Gaming OC   \n- Palit Gaming Pro White Edition   \n- Asus ROG Strix OC   \n    \nTLDR:   \ni) The Inno3D Twin X is the smallest and cheapest but loudest   \nii) The MSI Ventus is a good overall performer, The plastic backplate is a con, but the noise level is low   \niii) The most expensive models (e.g. ROG Strix) cannot be recommended because they are not faster and their price is closer to the RTX 4080 Super      \niv) From the GPUs priced in the middle, the Palit model is white, performs really well and has RGB. The Gigabyte  models perform really well, have DUAL BIOS and offer an extra year of warranty.   \nv) The Asus TUF Gaming has an extra HDMI port, has a solid metal design and it's quiet",
      "Well, Gaming one is a bit over my budget. About $100 after conversion. Maybe a bit less.\n\nI probably can get it, but I'd rather keep it within my budget. Maybe if price of other components goes down. Or there's a sale",
      "Hey I was looking into getting that card is there any issues with temperature? I've been seeing ppl say it over heats ??",
      "I haven't had an issue with it overheating. I just ran through some quick stress tests in games and it mostly stayed in the 50-55C range with a max of 59C. This was also in a 20C room. I tested three games all at max settings at 1440p; Horizon: Forbidden west, God of War: Ragnarök, and Witcher 3 with raytracing. I don't know how that compares to other cards but I defiantly don't consider that hot. It also has a massive heatsink, which helps.",
      "Alright thanks man I'll guess I'll just chalk it up to someone trying to overlock and it got to hot or maybe their room was too hot or they don't have great cooling in their pc I mean some ppl just don't know what they're doing sometimes honestly. Also all great games !",
      "I have the [Gigabyte Gaming OC](https://a.co/d/cvu9u2k) and I have been super happy with it. It's whisper quiet, no coil wine, and cool.",
      "I would choose a variant that has additional power limits and am unsure which ones do if you want additional overclocking potential.",
      "Zotac for the warranty. I've had mine since release day no issues. I also didn't undervolt cause I don't need to save on power. Highest temp I've ever seen on hot spot is like 80° on an extremely hot day. Cards fine to run to about 90° as well",
      "Final Answer: \" YOU GET WHAT YOU PAY FOR.\"   I went with ASUS TUF GAMING 4070TI SUPER.",
      "I have a msi ventus 2x fan version. Never hits 70C and is very quiet. Idles around 40C, light gaming like Valorant is around 50C. Jedi survivor 1440p epic settings with Ray tracing off was around 60C. \nCyberpunk 2077 DLSS quality with path tracing and framegen as well as Immortals of Aveum high settings pushed it to 65-70C.",
      "I saw that video, but the only card that I'm interested in that showed there was MSI Ventus 3X. So beyond that it doesn't really help me much...",
      "Ahh yes the company that turns down all the road request or over charges for the repairs. Nice gl with that",
      "is it at stock or did you fiddle with undervolting and/or overclocking?",
      "Undervolted it with msi afterburner. Just took 30mins including watching the YouTube guide.",
      "Cool, I plan on UVing my eventually too. Tho I probably should let it run at stock for a while to figure out what the temps and performance are at base. So realistically like 2-3 months after I get it",
      "I said that then went to UV and overclocking in less than one week.\n\nIn any case I would choose a 3 fan card if you want OC/UV as the thermal stability lends to better GPU boost clocks (it's about 15mhz less per 5c interval) and keep the fans a little quieter.  My 2x OC Ventus ti Super unit is a champ otherwise."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "rtx 4070",
      "4070",
      "4070 ti super",
      "4070ti super",
      "4070ti",
      "4070 ti",
      "rtx 4070ti",
      "rtx 4070 ti",
      "rtx 4070 ti super",
      "rtx 4070ti super"
    ],
    "title": "Help me decide which model i should get and why",
    "selftext": "Deciding between which model of the 4070 ti superi should go for\n\n \n\n# ASUS TUF Gaming GeForce RTX 4070Ti SUPER TUF-RTX4070TIS-16G-GAMING\n\nor the  \n\n# MSI NVidia RTX 4070 Ti SUPER Ventus 2X OC 16GB, 256bit GDDR6X both at the same price or if u have another opinion let me know im planning on mostly playing competitive fortnite",
    "comments": [
      "ASUS TUF for sure, more VRMs, has higher power limit 105% (vs 100% on Ventus) and much better cooler",
      "Asus",
      "Between those two, definitely the TUF.",
      "I've got the gigabyte 4070 TI Super OC. Runs great so you can throw that into the mix too. There's a review for it on Tom's Hardware I believe."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "4070ti super",
      "4070ti"
    ],
    "title": "Went from a 3070ti to a 4070ti super, couldn't be more amazed",
    "selftext": "The ada cards are nuts",
    "comments": [
      "Are you using a 60 cap with FG on?",
      "Even without DLSS, shouldn't a 4070Ti Super get more FPS thanks to FG being active? It's not with Path Tracing after all.",
      "I actually got curious and checked some benchmarks. Your results seem just a bit lower, but within margin of error for 1440p Ultra+RT+FG.",
      "I have the MSI gaming x slim variant and I don't believe any game I've played so far has reached over 60 degrees. The picture I included was when I still had the 3070ti still installed but to show you what the airflow looks like in my rig. The gaming x slim is actually about 1/3 smaller then that so I'd imagine I'll get even more airflow\n\nhttps://preview.redd.it/s2y1bs7ml6hc1.png?width=1440&format=pjpg&auto=webp&s=15ca64efb4c69e57b810f8cf41b6c351a7647ed8",
      "How are thermals for you? The only reason I sold my 3070 Ti was because it was cooking my ITX system. On the fence about a 4070 Ti Super vs a 4070 Super, heat might be the deciding factor for me",
      "The problem is in your CPU, it is generating the bottleneck, but still your benchmark results are not bad.",
      "fake frames: yes\n\nlol",
      "I also went from a 3070ti to a 4070ti super and I'm blown away. Nearly every game I play, without limited fps (and excluding cyber punk obviously) will hit 165 fps constantly at max settings. Sons of the forest is about 110 fps but I'm not gonna complain. It's much better than I thought it would be",
      "How does path tracer impact the performance?",
      "Idk I don't claim to know a whole lot but I'm getting over 60fps with everything pretty maxed. Not much more I could ask for.",
      "Pretty much cut the fps in half I believe",
      "Darn. That’s what I was afraid of. My prebuilt came with a 4060TI and it’s able to run everything maxed at 2K 60+ FPS, it seems like even the high end cards still struggle with pathtracing",
      "Where is a good place to find other cyberpunk benchmarks to compare?",
      "Just google the names of the card, game and resolution. You get plenty of videos.",
      "Oh, I was looking for a consolidated list of user benchmarks that I thought you were referencing.",
      "Yeah that's the first time I ever really benchmarked before so I'm not sure what to do I had other things open on my 2nd monitor while it was running but regardless I'm happy. As long as the gaming experience is good and the fps is at least above 60 idc about the rest. If I really cared I would have opted for the 4080 super but I'll never do 4k just because imo I don't think you see much of a difference on a smaller screen compared to like a TV. This so far has fulfilled my 1440p needs."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "rtx 4070",
      "4070",
      "4070ti",
      "4070 ti",
      "rtx 4070 ti"
    ],
    "title": "Upgrading from Gigabyte RTX 2060 Super to Gigabyte RTX 4070 TI Gaming OC",
    "selftext": "Hello, I have a question regarding upgrading my graphics card, my current card (Gigabyte RTX 2060 Super) uses 1x 8pin power cable, however I saw that the new card I want to upgrade to, the 4070ti gigabyte gaming oc card requires a 16 pin power connector and that it comes with an adaptor that converts 2x 8 pin to 1x 16 pin.\n\nMy question is can i daisy-chain 2x 8 pin connectors from 1 cable coming from my psu to the adaptor/convertor ? or does it have to be 2 separate 8 pin connectors coming directly from the psu?\n\nMy current pc specs are:\n\nMB: Asrock x570 Phantom Gaming 4\n\nProcessor: AMD rx 3600x\n\nRam: 1x Ballistix 2600 16GB Ram\n\nHD: P1 Crucial M.2 SSD 500GB\n\nCase: Cooler Master CMP 505 (600 watt psu included)\n\nGPU: Gigabyte RTX 2060 Super (to be upgraded to Gigabyte RTX 4070 TI Gaming OC)\n\n&#x200B;\n\nI also attached a photo for the cable i am refering to",
    "comments": [
      "I would rather go with two 8 pins from the psu. But to avoid using an adaptor I bought a new psu with the new cable. Or you can just get that new cable if your psu supports it. My psu did not support it.",
      "If you have the ability to use 2 8 pins then that is the best thing that you can do.\n\nHowever, the 4070ti is very power efficient and you should be ok to use the 1 daisy chain cable as they’re rated for 300w which is more than enough for the 4070ti.",
      "Do you recommend getting a new PSU ? or just connecting my exisiting PSU with 2 Cables instead of using the daisy chain into the adaptor?",
      "Definitely setup the second cable if nothing else as a precaution. Worst that would happen if you don't could be a graphics crash or reboot shouldn't do any harm real harm. Unless the cable is really crap but I don't think it is.",
      "A new psu is recommended but the card comsumes around 270/290 watts.\n\nBut take in consideration that you will have a bit bottleneck with the card.\n\nI have a little / moderatee with a 5600x with the GametrioX from msi.",
      "Get an adequate new PSU for your new 4070ti.\nYou should go with the recommendation of 2 x 8 pins, not as a daisy chain.\nBetter safe than sorry. Why risking anything with your new GPU, your PC etc…\nMy 2 cents…",
      "Either new PSU, don’t daisy, or downgrade to 4070 that uses std 8 pin and less power.",
      "No the spec is 150W from 8pin MINIMUM. Good PSU's and nice cables can do more but the PSU/cable is probably a pretty shitty one so I would expect closer to 150W safe output than 300W. \nThere is 75W from the PCIe slot so it should still be enough. But 300W is not the spec for an 8 pin. Many if not all might provide that but low quality hardware will not do it safely/consistently.",
      "The Daisy Chain cables that come with the PSU's are rated for 300W, that's literraly the reason they exist.\n\nNow, I agree that certain PSUs/Brands do not have great quality cables and so this can deviate a little but as long as it's Gold+ rated, OP will be fine.\n\nOP, you've not shared the details for your PSU so it's impossible to tell what you should do but IMO, just try the daisy chain cable, run some tests and see what happens.",
      "What they CAN handle and what they are certified to handle are 2 different things. It's 150W minimum certification for an 8 pin PCIe connector. This is what they promise. Just like a 500W PSU can probably deliver 700W without much problem. But how do they cope with time and degradation or efficiency? Better to keep it within spec if in doubt. \nHe clearly states the PSU was a tag along with the cabinet so he's lucky if it's bronze certified and I would definitely not allow 300W through whatever fruit salad cables it has. \n\nAlso why gold+ certificate? Bronze is fine for most needs as long as its rated power fits properly within the efficiency curve of the PSU. People don't need great PSU, a good bronze is plenty for 75% of people."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "rtx 4070",
      "4070",
      "4070 ti super",
      "4070ti super",
      "4070ti",
      "4070 ti",
      "rtx 4070 ti",
      "rtx 4070 ti super",
      "rtx4070ti"
    ],
    "title": "ASUS TUF Gaming RTX 4070 Ti SUPER vapor chamber??",
    "selftext": " [ASUS TUF Gaming GeForce RTX ™ 4070 Ti 12GB GDDR6X | Graphics Card | ASUS | Global](https://www.asus.com/motherboards-components/graphics-cards/tuf-gaming/tuf-rtx4070ti-12g-gaming/) \n\nhttps://preview.redd.it/s0knneaa0qnc1.png?width=2772&format=png&auto=webp&s=2bf2d8b995d7464378a50f201343b4073895f147\n\nSince I'm using the Tower100 case\n\nI'm looking for a graphics card with a shorter length that utilizes a vapor chamber. \n\n&#x200B;\n\nThere have been mentions that the ASUS TUF model of the 4070ti super utilizes a vapor chamber, \n\nand I've confirmed this on the ASUS official website.\n\n&#x200B;\n\nIs it correct that the 4070ti super TUF model has a vapor chamber?\n\n&#x200B;\n\n And if there are other models of the 4070ti super with a vapor chamber, please let me know. Thank you.",
    "comments": [
      "When installing the graphics card vertically (with the IO shield facing upwards), if there is no vapor chamber, the temperature may rise abnormally",
      "It wouldnt say that if it wasnt there✌️",
      "Why do you want a vapor chamber? It's absolutely not necessary considering how cold the 4000s run.",
      "https://preview.redd.it/rdm4c4fg1qnc1.png?width=2530&format=png&auto=webp&s=c6764da85714a5d009880f8c8056aec14071c5d5\n\n4070ti super tuf"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "4070",
      "4070ti",
      "4070 ti"
    ],
    "title": "Going to 4070 TI from 2070 super",
    "selftext": "So I just upgraded my setup, I had a 2070 super build with an i710700F pretty basic. Sold that set up for 800 only the desktop, just got a 4070TI, i712700KF, 32 GB ddr5 @6000 mhz, 2 TB Samsung NVME, z790 gigabyte MB. My most demanding game is probably Fortnite with epic settings on and RTX off. Should I be expecting 240 fps locked? I can’t seem to get that in game unless I turn off shadows fully and everything else epic. I also got the rig new for 1400 from a local reputable PC builder. So definitely gonna good deal ",
    "comments": [
      "What a real dolt. Only a pure dipshit would think the 12700k isn't capable of modern gaming.",
      "I know the 4070 ti FE was discontinued but are all 4070 tis from other manufactures also being discontinued or just the FE?",
      "Interesting, I thought it would definitely be able to keep up. It was either that, or a 7800x3d paird with a 3080. But I figured it was much cheaper to upgrade a processor in the future rather than a GPU. But I’ll have to go intel with this MB.",
      "Also after optimizing most I could, i did have some freezing it would freeze for around a second or so and then come back. Not sure if that’s a GPU issue or not",
      "A 12th gen i7 is more than enough.",
      "Fornite is horrible to run nowadays, as UE5 typically just has inefficiencies. With a 4070ti I don’t think it’s a GPU issue. Good luck finding the issue.",
      "Also after optimizing most I could, i did have some freezing it would freeze for around a second or so and then come back. Not sure if that’s a GPU issue or not",
      "It's not really a UE5 issue, per se. Fortnite is just a technical mess.",
      "Amazing deal but, I think it would be the 12700KF that is limiting you there. It’s not a bad processor by any means, just kind of old and struggles when any real modern gaming load is put up against it. \n\nDespite what people think, Fortnite is a pretty demanding game now unless set to performance mode."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "rtx 4070",
      "4070",
      "4070 ti super",
      "4070 ti",
      "rtx 4070 ti",
      "rtx 4070 ti super"
    ],
    "title": "Cant decided witch 4070TiS to choose ",
    "selftext": "As the title says i need a lil help choosing from 3 cards\n\n[ASUS Dual GeForce RTX 4070 Ti SUPER 16GB GDDR6X](https://tweakers.net/videokaarten/asus/dual-geforce-rtx-4070-ti-super-16gb-gddr6x_p1613322/vergelijken/)\n\n[Gigabyte GeForce RTX 4070 Ti SUPER WINDFORCE OC 16G](https://tweakers.net/pricewatch/2034688/gigabyte-geforce-rtx-4070-ti-super-windforce-oc-16g.html)\n\n[Inno3D GeForce RTX 4070 Ti SUPER TWIN X2](https://tweakers.net/videokaarten/inno3d/geforce-rtx-4070-ti-super-twin-x2_p1586544/vergelijken/) OC WHITE",
    "comments": [
      "The cheapest one",
      "They’re all dual fan so the cheapest one",
      "i did infact get the Gigabyte one :D",
      "The cheapest one friend, I would just avoid asus due to their horrible customer service. If it helps you I have the gigabyte one and it’s fantastic. You may want this one due to having more heat sink and more fans to keep that bad boy cool under full load. The twin OC may have a hard time keeping it cool under extended periods full load.\n\nHopefully this helps you out 👍",
      "This just got the Msi 4070 ti super for $740 on BF",
      "bought the Gigabyte one.",
      "I prefer the warlock edition.",
      "Bought the Gigabyte model too. Thx for your input",
      "I did get gigabyte",
      "(edit: just saw you aren't US. I looked up the prices of the card I listed in the following and it's the same price, so ignore most of this, but what I said about the overclocked editions remains true)\n\nI'm just going to say there's absolutely no reason to purchase the overclocked cards. Just get the Trinity black base edition from Zotac. It's like 750 plus tax. It is a powerhouse. I know because I have it, upgraded from the 3070 to the 4070 TI super Trinity Black zotac. \n\nYou definitely want one with 3 fans instead of 2. \n\nI would ignore the dual fan options. \n\n\nI'm always rendering things and blender and unreal engine, and playing games constantly. My temps wild game and hoves in the 50's(Celsius) and barely gets in the '60s. While rendering in blender it usually hovers around 45 to 50. There's not much of a performance difference between base clock and overclock. It's not worth stressing the card for such a tiny difference.",
      "Cheapest one..",
      "Me personally I used zotac in the past. I love zotac now and that's all I use",
      "I've got the strix variant. Runs at 55 max load. Super overbuilt. The dual should do nicely for that card",
      "i bought the Gigabyte one :D",
      "the Inno3D is good for small cases , Asus it the best for cooling, now depends on your budget. \nWhat do you want first ??",
      "The one with 3 fans.",
      "Just get the one whose after sales service is best in your area",
      "would buying one now be a good thing with 50xx just around the corner? Unless really really really good deal",
      "Gigabyte",
      "Gigabyte"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "rtx 4070",
      "4070",
      "4070 super",
      "rtx 4070 super",
      "4070 ti super",
      "4070ti super",
      "4070ti",
      "4070 ti",
      "rtx 4070ti",
      "rtx 4070 ti",
      "rtx 4070 ti super"
    ],
    "title": "Bought MSI GeForce RTX™ 4070 Ti VENTUS 2X 12G OC GPU",
    "selftext": "I can't find any more in-depth youtube reviews on this card. The MSI RTX Ventus OC 4070 , 4070 Super and 4070Ti Super versions seem to be more reviewed. I guess my only concern is that there are no in-depth reviews not on youtube or anywhere if I do a quick google search.\n\nMSI link: [https://www.msi.com/Graphics-Card/GeForce-RTX-4070-Ti-VENTUS-2X-12G-OC/Overview](https://www.msi.com/Graphics-Card/GeForce-RTX-4070-Ti-VENTUS-2X-12G-OC/Overview)\n\nThe reason I bought it because it was on sale in a local reputable store for 769.90€ which was a markdown from  €899.90 €.\n\nPS: I kinda wanted the card to be MSI, Current one I have is MSI RTX 2060 Super Gaming X but those versions of the 4070 series cost more where I live (Estonia).\n\nCards in order with price from the same store:\n\nMSI GeForce RTX 4070 VENTUS 2X E OC 12GB - 648.80€\n\nMSI GeForce RTX 4070 SUPER 12GB VENTUS 2X OC - 679.90€\n\nMSI GeForce RTX 4070TI VENTUS 2X OC 12GB - 769.90 (Original price €899.90 €)\n\nMSI GeForce RTX 4070 Ti SUPER VENTUS 3X OC 16GB - 959.90 €\n\nI checked some benchmarks from [https://gpu.userbenchmark.com](https://gpu.userbenchmark.com) and it seemed to be the best bang for the buck with those cards right now.\n\nEDIT: userbenchmark site is trash, noted.\n\nUPDATE: Card arrived and I accidently installed wrong power cables, one PCIe and one EPS, luckily PSU recognized the short and didn't fry the GPU. I changed cables to correct ones and everything works fine as of now.",
    "comments": [
      "Please stay as far away from anything userbenchmark. Absolute dogtu*d of a site. Otherwise, if the prices in your region aren't better. (4070ti super is kind of going for 4080 prices lol) then the pickup was good.",
      "“Why is UserBenchmarks hated on Reddit” \n\nCause they fucking suck.",
      "Difference between performance of 4070 ti and 4070 super is about 8-10% so for 90€ you will get 10% better performance. That’s decent and definitely better value than original price. Both have 12gb vram. Price difference between 4070 and 4070 super is only 30€ and you get 16% better performance. You can see that 4070\nSuper is best value pr performance GPU. Usually 4070 ti is 150 to 200. $ more than 4070 super. Here it’s only 100$/90€. I would go for 4070 ti if money isn’t an issue otherwise 4070 super is great too.",
      "because they are all the same.\n\nthe only thing that's changes is the  \namount of fans --> cooling --> and silicon lottery\n\nat the end of the day.  \nif a benchmarks shows the gpu will get you 200fps  \nyours will have 195-205 fps\n\nbut this will depend more on your other parts then on the gpu itself.",
      "What is the purpose of these obvious AI comments?",
      "The GeForce RTX 4070 Ti VENTUS 2X 12G OC offers a strong balance of high performance, efficient cooling, and compact design, making it an attractive option for gamers and content creators looking for top-tier graphics capabilities without requiring an overly large case."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "rtx 4070",
      "4070",
      "4070ti"
    ],
    "title": "Should I get 4070 or 4070Ti?",
    "selftext": "I wanted to upgrade my 1660 super and finally decided to get either RTX 4070 or 4070ti. I currently have an Acer VG271 1440p gaming monitor, and my processor is a Ryzen 7 5800X. I am also ready to upgrade my PSU. My current PSU is Fingers 500w(30A on 12V). I wanted to know if it is worth it to get the Ti version for an extra 25% performance. Please help me decide between these two  \nThe prices for the Zotac models are:\n\n4070 - Rs 62500(760$)\n\n4070Ti - Rs 82500(1000$)\n\nThe prices for PSUs are:\n\nCorsair CV750 - Rs 6000(73$)\n\nAdata XPG Core Reactor 750 - Rs 8000(97$)\n\nEVGA BQ 850 - Rs7000(85$)",
    "comments": [
      "Go with the 4070, especially since you only have a 500 watt power supply.",
      "Looks like you're paying 30% extra for 30% more performance putting them effectively at the same value. If you can afford the TI go for it.",
      "Which site are you using? I generally use MDcomputers but their 4070Ti Listings aren't this low, and Amazon listings are overpriced scam trash as always.",
      "Oof, overseas prices are rough. Still, if it were me I'd spend the extra now on the 4070ti; it'll probably give you an extra year of performance over the base 4070. That will be worth it in the long run since you seem to run a longer upgrade cycle given that you're coming from a 1660super, and the price:performance difference is basically 1:1.\n\nFor what it's worth, I bought a 4070ti last month, and if I had to make the same choice today with the 4070base on the market, I'd still have bought the 4070ti. It's a fantastic card.",
      "switched from an evga 2080 to a gigabyte 4070ti and it blows my old card away. Cyberpunk ultra settings in 1440p with pathtracing on gives you 60fps minimum up into the 100s. this is paired with a 5800x3d",
      "Do you want to pay 30 percent more for 20 to 25 more performance?  You have to decide",
      "Cheap power supplies can be dangerous. Definitely get a new one even if you only get a 4070.",
      "The 82.5k version is out of stock right now but is available at random times",
      "It's an ultracheap PSU with just 360watt on the 12V rail",
      "This is kinda the best value answer. You can keep your psu!",
      "I am thinking if I should spend extra on PSVR as I also have a PS5",
      "Seems like it is 10 to 25 percent more performance, depending on the game.  For 30 percent more money.",
      "More toys! Sounds like a plan 😅",
      "Its more like 30% from what I saw, and yeah its worth it",
      "If I'm not mistaken both cards have 12 GB of VRAM and a 192 bit bus. Be prepared to turn down textures sooner or later if you buy either card."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "4070",
      "4070ti super",
      "4070ti",
      "4070 ti"
    ],
    "title": "Should I keep my 4070Ti or return it and wait for the 4070Ti Super?",
    "selftext": "I just bought the [ASUS TUF Gaming NVIDIA GeForce RTX™ 4070 Ti](https://www.amazon.com/gp/product/B0BQTSV2GG/ref=ppx_od_dt_b_asin_title_s00?ie=UTF8&th=1) on Amazon for my new PC build to replace my 1070. However, after learning about the 4070Ti Super being the same price that I paid for the 4070Ti, would it be better to simply return it and wait for the 4070Ti Super? If it's the same price, I rather have the better card if there isn't a downside to it.",
    "comments": [
      "The TI Super is released in a few weeks, so if you can wait say, a month, to finish your new PC, then yeah, I'd totally return it and wait for the better card at the same price.",
      "How much did you pay for it?\n\nWhy not just go 4080 super since the current prices are $800-850 and 4080 super is just a small step away?",
      "We don’t actually know what the AIB prices will be. The ASUS TUF version will probably be like 1200",
      "Yep everyone is hung up on release price of the founders edition. Scalpers and oc editions are going to make the price go up to what they usually are",
      "My thoughts too. If you want to wait, you’ll get more for the same price. If you wanna start gaming at way higher quality than your 1070, just keep the non super. You’re not gonna be disappointed either way.",
      "$829.99, not including tax\n\nWhat ended up happening was I wanted a 4070 as it was $600, yet after enough consideration I ended up wanting to go $200 more for the 4070Ti. Following [this logic](https://www.reddit.com/r/nvidia/comments/191y73a/comment/kh028ce/?utm_source=share&utm_medium=web3x&utm_name=web3xcss&utm_term=1&utm_content=share_button), I dont know if I want to continue increasing the cost of this build and drop another $200 since its already getting expensive enough.\n\nI would really need to be convienced I should drop $400 more on a GPU, since $800 feels a lot already, let alone $600",
      "I'm in the US, would this be a problem or unlikely?",
      "Imma be disappointed in myself if I dont get the better card for the same price :(\n\nBut yeah I think that's the plan, imma just hold onto my card and wait until the 4070ti Super is released, and once I'm able to get it, i can just return my 4070 ti",
      "Prob. Since there is no founders. lol. Expect to pay some Asus like prices of 900$",
      "If you’re able and don’t mind waiting a week or 2 I’d just return it and get the 4070 Ti SUPER. Better bang for the buck.",
      "How long is your return window? I’d say use it for a few days then return it for the Super card closer to release",
      "I am in the same situation as you are. Recently got this white MSI 4070TI, mainly because it matches my white build, and do like the performance. Not sure if there are any drop-in replacements for a white 4070TI card.\n\nI wish Nvidia would offer some for of a rebate, maybe a game or something lol",
      "Typical Reddit advice xd",
      "Playing games, but wanna make sure the money i spend is worth it which... If the 4070Ti Super is a very similar price while also providing better frames, maybe just wait until I see how the price goes? I don't have to return it until February 7 so...",
      "February 7, so lots of time before I can no longer return it",
      "MSI\\* not Nvidia.",
      "I might not plan to overclock my GPU anyways so as long it's around or at MSRP, then I think I'm okay with it. I did choose the OC for the 4070ti though since weirdly enough, it was cheaper than the non oc edition",
      "If you are from EU expect inflaction on prices....you will not see any Ti Super below 1000€",
      "Do you have more fun playing games or counting frames?",
      "If it's an ASUS TUF non-OC, that should be MSRP.\n\nI got my 4090 TUF non-OC at release at MSRP."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "4080",
      "4080 super"
    ],
    "title": "Gigabyte Came Through BIG TIME – 3080 Ti RMA Turns into a 4080 Super!",
    "selftext": "I just wanted to give a huge shoutout to Gigabyte for their amazing warranty service and customer support. My 3080 Ti Vision died recently, and I was honestly dreading the RMA process. You always hear horror stories about long wait times, getting the runaround, or receiving a questionable refurb as a replacement.\n\nBut Gigabyte absolutely delivered. Not only was the RMA process smooth and relatively quick, but instead of just replacing my 3080 Ti, they upgraded me to a 4080 Super Aero! I was blown away—talk about standing behind your products and taking care of customers.\n\nIt’s rare to see companies go above and beyond like this, so I just wanted to give them the credit they deserve. If anyone is on the fence about Gigabyte, their warranty support is top-tier, and I can personally vouch for it.\n\nThanks again, Gigabyte! You’ve earned a loyal customer.",
    "comments": [
      "That's fucking sick! Grats on the upgrade. Probably the best money you've ever spent on a GPU.",
      "I did buy my 3080Ti for $1700 at Best Buy during covid, so this upgrade makes that price more worth it now!",
      "Now that’s how you do a turnaround in support, asus should take notes.",
      "Covid prices were nuts! I had to get a GPU for work, but I would have never paid $1700 for a 3080Ti for just video games.",
      "https://preview.redd.it/6k1v8sgbuwie1.jpeg?width=1290&format=pjpg&auto=webp&s=695315ec511eaeb78cff8316969ab6126ed51974\n\n🔥",
      "https://preview.redd.it/20vvuynqswie1.jpeg?width=828&format=pjpg&auto=webp&s=96f0835f87dec2f12510a215f8ac798824414f12",
      "I had a 3080 Ti Vision that I RMA'd 3x. Each time, it died due to the same reason. The final RMA, they upgraded me to a 3090 Eagle which absolutely killed my aesthetic in my build (since it's all white). I sold the 3090 Eagle for a good chunk of change and I bought an 4080 Aero at release.\n\nIronically enough, the 3090 Eagle died on the new owner about two months in. Fortunately, I was able to help them get that RMA'd.\n\nEDIT: I just thought that I should add that I echo your statement/sentiment regarding their warranty process and policy. They never gave me a hard time through all of the issues and held up their end of the bargain.",
      "Gigabyte is legit with their warranty. I had a Windforce v1 4090 fail and they sent me a brand new Windforce v2 4090.",
      "Solid warranty but damn that is a scary high failure rate.",
      "Meanwhile at gigabyte hq;\nWHO DID THIS GUYS RMA YOURE FIRED",
      "How many shares of Gigabyte stock did you buy before posting this?",
      "![gif](giphy|3o7TKMxBuO913uWyoU)",
      "Perhaps you are new here but, COVID pricing was combined with Crypto pricing... a 3080 Ti was insanely marked up. I think it capped around $2000",
      "I paid 800 CAD for a 6600.. still hurts",
      "so they replaced a broken windforce 4090 with a working windforce 4090, thats kinda the bare minimum for warranty.",
      "Least obv gigabyte propaganda",
      "What? OP was just giving more context why they paid that much",
      "We’re not all Reddit experts, I just clicked reply on the wrong comment and didn’t feel like rewriting or copy pasting. I assume most people would figure out the context when reading it all. It is pretty funny people think I might be a Gigabyte employee. \n\nWe should call out companies when they do things right and not just when they do things wrong, just like the same applies to people. So much negativity today! Stay positive people!",
      "Yeah, I was nervous after RMA #1 that they were going to pull some crap and screw me over but thankfully they didn't. They kept sending me these BS refurb units that would literally die after like 2-3 months. It was wild.\n\nHistorically, I had always gone with ASUS boards and GPU's but now they've got a customer in me for life.",
      "Almost 3 months since when i sent my card to Galax for warranty, havent got any real answer from them. Definitely my last Galax card."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "4080",
      "4080 super"
    ],
    "title": "Upgraded from 1050 Ti to a 4080 Super. The size difference is comical!",
    "selftext": "",
    "comments": [
      "Did you eat fried chicken before opening the 4080? Lol",
      "The fingerprints are insane lol",
      "Old build: i5 8400/1050Ti/16GB3000MHz/Z370/Seasonic M12-II 520W 80+ Bronze/250GB SATA SSD and 1TB HDD/Fractal Design Focus G\n\nNew build: R7 7800X3D/4080S FE/32GB6000CL30/B650E/2TB Gen4 NVME/240MM AiO/Corsair SF750/Dan A4 H2O\n\nWent from ATX mid tower to an SFF build.",
      "I swear I didn't! It didn't look that bad off camera, idk why",
      "Performance difference is comical too.",
      "BBC - Big Black Card :)",
      "Ikr! Should have worn gloves when building lol",
      "Had a really similar experience of i5-6500 + 10603gb ATX to 4090 SFF, I’m living a dream and hope you are too!",
      "Just making jokes. Lol congrats on the upgrade. Just got my 4070 Super FE and love it! Enjoy it!",
      "![gif](giphy|UoYA5jnXE5V7u4MJh7|downsized)",
      "Legit thought OP sanded it down, glad it's just fingerprints.",
      "Nope, it's pointless. The 1050 Ti has the old hardware nvenc encoder, which isn't as good as just one of the 4080's encoders when both are using H.264. The 4080 can do AV1 encoding as well, which is even better. Performance impact is negligible.",
      "you’ve got some oily fingers my guy",
      "muddle shame marvelous illegal zonked person disarm literate like imagine\n\n *This post was mass deleted and anonymized with [Redact](https://redact.dev)*",
      "Upgraded everything, essentially a new build.",
      "No need",
      "Phone cameras tend to exaggerate smudges or dust from my experience.",
      "eSports and indie games so far. Finally can try out some AAA gaming as well.",
      "Ya but it was a SUPERCLOCKED",
      "i had a 7800X3d and 4080 in an A4-H2O.\n\nairflow was bad. the whole case got hot as fuck to the touch.\n\nSwapped in a 4070 on that build, much better. 4080 lives in a proper airflow case with another 7800X3D.\n\nThere are SFF with good airflow. SSUPD mesh cases, etc."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "4080"
    ],
    "title": "My dad is offering me his RTX 4070 after being gifted a new pc. I have a RTX 3080 and my brother has a gtx 1080 I'm conflicted, help please.",
    "selftext": "So my dad got a new, top-notch pc from a friend who works at AMD. He has offered me his RTX 4070. I kinda feel stupid because a month before the 40 series released I bought a used RTX 3080, a new i9 10900k and a 850W PSU. My brother on the other hand has a GTX 1080 and a 750w PSU. Should I give my RTX 3080 to my brother as a hand me down or should I tell my dad to gift the RTX 4070 to my brother for his birthday since his psu is lower wattage than mine. Also, my brother has an intel i7 as a CPU.\n\nEdit: im keeping the 3080 unless i see reasons why the 4070 look is more sexy for me lol. Its just i didn’t want to stress my brothers psu so much. He would appreciate it either way he gets hand me downs when i upgrade anywah\n\nEdit 2: holy shit my phone is being pinged like crazy this subreddit has is super active lol\n\nEdit 3 (final): im taking the 4070 and will trade it in for a 4070 super or 4080 when i sell my dads other pc parts",
    "comments": [
      "Hand your brother the 3080 and keep the 4070",
      "the 3080? sure. btw that 3080 has 3 pcie or 2? make sure his psu has the recommended connectors.",
      "Give him the 4070. 3080 to a 4070 is negligible enough in uplift to make no serious real world gain for you. \n\nThough, if he's still rocking a 1080, chances are good the rest of the hardware is nearly as old. Possible CPU bottleneck.",
      "Ok i hope his 750w psu can handle it.",
      "I'd HIGHLY suggest an undervolt though. My 3080 peaks at 270w instead of 360-400 and has the same performance.",
      "Just give your brother your 3080, that’s what I would do. He’s not going to complain about not getting the 4070 when he’s getting a nice upgrade himself for free.",
      "-RTX 40/50 series runs the new DLSS 4 transformer model upscaling/ray reconstruction better than RTX 20/30 series cards\n\n-Extra +2GB VRAM (assuming they have the 10GB card)\n\n-DLSS framegen support (can be hit or miss)\n\n-Lower power consumption by ~120w\n\n......................\n\nIf they have the 3080 12GB, it will be a small downgrade moving to the 4070. If it is the 3080 10GB, those extra bonuses are probably worth the free swap in even if it is only a sidegrade.",
      "His psu is a cx750 it has 3 pcie outlets",
      "I've had a 350w 3080ti with a 650 PSU for years with no issues. \nHe will be fine",
      "You’ll see no performance boost from going to a 4070, would be better for your brother to have it instead unless you need 2x frame gen",
      "Hes not a big complainer lol. Its just i dont want to fry his pc",
      "If OP's getting the card for free, there's no reason not to take the offer.  Sure, it's a sidegrade based on pure raster performance, but better DLSS and frame gen is a straight upgrade.",
      "3080 to 4070 is a downgrade in raster.",
      "The 3080 is way more power hungry and powerspikes more than the 5070ti lol..",
      "3080 is slightly faster vs 4070 but 4070 has more VRAM, more features (Frame Generation) and more efficiency.\n\n3080 recommended PSU is 750w so your brother can use it.",
      "4070 uses significantly less power. That's enough reason for me.",
      "Yes, about 1-2%...\n\nHis statement that the performance difference is negligible in the real world is perfectly valid.",
      "Oh dont worry, 750w is perfect for 3080, I believe this is my current setup. And he can undervolt 3080 which is probably a good idea. I undervolt mine.",
      "I've been using a 3080 with a 650w psu for the past 3 years and haven't had a single issue. I have a Ryzen CPU though. His Intel probably uses a little more.",
      "My 650 can handle 5070ti so he will be more than fine"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "rtx 4080",
      "4080"
    ],
    "title": "Upgraded from GTX 1650 to RTX 4080",
    "selftext": "Hey all, I went from ASUS TUF GTX 1650 to MSI Gaming X Trio RTX 4080 since it was cheaper than the SUPER version.\n\nI turned off the RGB since I built this PC with All black + No RGB in mind.\n\nI now gave the GTX 1650 to my brother who mainly play Roblox/MC.\n\nSpecs:\n\nMSI B650 Tomahawk Max + Ryzen 5 7600X\nArctic Liquid Freezer III - 420mm (overkill I know but I got it for much cheaper than the 360mm)\nG.Skill Flare X5 32 GB (16x2) 6000mhz CL30\nSeasonic Focus GX-850 Gold",
    "comments": [
      "From 30 fps to 300 fps",
      "Definitely, it was a struggle powering through 1440p with the GTX 1650 before getting the GPU.\n\nI initially had an RTX 3060 which gave up on me that’s why I used the GTX 1650 for half a year!",
      "That's a generation upgrade from 1080p to 4 k max with ultra settings congratulations bro 🫡🔥",
      "I assume rest of the PC was build in preparation for this move? Perhaps recently?",
      "It’s the last piece of the upgrade.\n\nI gave my B450 system with a 5600 to my brother since I got this B650+7600X combo used (with warranty left) for a bargain from FB Marketplace",
      "One giant step for bonkerschonkers",
      "Congrats! Now you can play CP2077 in all its glory!",
      "As someone who has a gtx 1650 mobile I don't get 60 fps in any games. Tho in some games it could just stick to 50 for longer periods of time",
      "Don’t think my 3060ti heard of the fact that it can run path tracing in Cyberpunk.",
      "Depends on the game. I too have a 4080 but man some games really struggle when you crank the settings up and I have to rely on VRR to help out. That’s not the GPUs fault by any means. In those same games every card struggles.",
      "With a 4080 you can play 4k 60fps maxed out with RT path tracing as long as you’re down with dlss and frame gen. It’s truly incredible. Just got through phantom liberty this way and I’m wanting to play through the entire thing again.",
      "i never got 60 in AAA games on my 1650, even at 1080p with fsr quality (720p) i would struggle. now my 3060 ti can run cyberpunk path tracing",
      "congrats!\n\nwill do something like that.\n\nwill go from my i7 3770 + GTX 1070 to a 9800x3D + RTX 5090 when those parts get released.\n\nalso bought a 32inch 4k 240hz OLED monitor to pair it with. unfathomably excited to build/play on the best pc you can possibly build",
      "I got them all for around $350 from a dude who just wanted to get a little bit of his money back since he upgraded to the highest end stuff at that time",
      "Ik I was talking about high end games, tho I should add that I like to play with high graphics?",
      "That’s like a 6x performance increase. Huge!",
      "1650 user here, Man i can get 60 fps in many games \"-\"",
      "Very nice. I also like the Gaming X Trio lineup and have a 3070 Gaming X Trio myself.",
      "I’m using a Lian Li Lancool 3!\n\nThanks",
      "How much did you get the B650 + 7600X + 32GB DDR5 in total?"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "4080",
      "4080 super"
    ],
    "title": "Went from 4080 to 4080 Super… But for good reason.",
    "selftext": "My son was still rocking a 970 so he got my old 4080. Love the FE so far.",
    "comments": [
      "You're a good father.",
      "You have a good pc",
      "Thank you, a childhood of low grade PCs makes you want to compensate it somehow.",
      "Nice, I can't wait to get mine.  I had a good upbringing compared to others, but I sincerely can't imagine a dad supporting gaming since when I was growing up it wasn't allowed at all.  It was like bringing in satan into the home lol.",
      "https://preview.redd.it/fqmdm71x8ngc1.jpeg?width=4032&format=pjpg&auto=webp&s=106156e9ca3d78595560ae8aca053d9cd52d33f9\n\nMe and my twins build!",
      "The 4080 super looks awesome in your rig",
      "![gif](giphy|wijMRo7UZXSqA)",
      "I wish other people in the subreddit would be like this and not bash the shit out of the 4060 TI. They must be thinking I overspent on the CPU but it was just a bundle and I got the motherboard, ram and CPU for 400. Budget was 1200 and I didn’t have much time to make the list since we went for a trip to America and it was where I bought all the parts",
      "He loves Warzone and is only allowed to play on weekends (mom’s rule, he’s 10) but we love to squad up when we can.",
      "Also note. His KD is higher than mine.",
      ">My son was still rocking a 970 so he got my old 4080. Love the FE so far.\n\nnot a good reason, the best reason, gg :)\n\n&#x200B;\n\nYour PC looks really clean, it's those lian li fans that daisy chains without cables right ?",
      "Specs for those asking\n\n\n\n7800x3d \n\n4080 Super FE\n\nCorsair Vengeance 32GB 6000mhz\n\nMSI B650\n\nMSI A1000G\n\nLian Li Galahad Trinity LCD AIO\n\n7 Lian Li reverse blade SL V2 120mm\n\n5 Lian Li SL V2 120mm \n\nLian Li Dynamic Evo XL\n\nSons rig\n\n5600x\n\nGigabyte 4080 OC\n\nCorsair 32GB \n\nMSI B550\n\nMSI A850G \n\nLian Li Galahad Trinity II AIO\n\n5 Lian Li SL V2 140mm fans (intake) and 120mm \nexhaust\n\nLian Li Dynamic Evo",
      "I have no morality to bash anyone, I have one of the PCs that makes less sense in a gaming scenario. Be happy with your build, enjoy it and flip a finger to someone that tells you otherwise unless you specifically ask for an opinion. \n\nDoesn't matter if you could get 5% more performance by buying some another random GPU, if your ram is not ideal, if your case is not adequate or if the monitor is too big. It's your rig, you chose the parts and it was for sure a happy moment, and that's what matters the most.",
      "Can you adopt me?",
      "Kids have better reflexes than fathers.\nBut we have experience, which can be a hindrance.\n\nGood on your wife to regulate time.\n\nI have a policy too. I see what they get out of a game and judge time off that.\n\nI also ask questions to engage them. Like what did you learn? Did you find something hard? How did you figure it out? Or what do you think might be the solution?\n\n\nThe more feedback I get the more time I alot them for that game.\n\nDrifting on a track, sure 30mins. If they ask me more time I'll be relauntant.\n\nScience game learning about the planets, hey dad can I get 10 more mins? Sure kiddo.\n\nThanks for sharing. I hope they grow to have a positive experience with tech.",
      "Wow that black and white is one of the best looking builds I've ever seen. I'm sure your son is ecstatic. Great dad.",
      "smoggy water entertain repeat sheet erect jellyfish hard-to-find imagine disgusting\n\n *This post was mass deleted and anonymized with [Redact](https://redact.dev)*",
      "don’t let anyone tell you your gpu isn’t good enough",
      "I’m an engineer by trade and my only regret was not learning how to code earlier in life. He has an interest in tech/science now so hopefully this is a good foundation for him to be better than I was.",
      "Yea 1 cable to each group of fans. really clean."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "4080",
      "4080 super"
    ],
    "title": "Sold my 3080 while the price is right and pulled the trigger on 4080 Super.",
    "selftext": "",
    "comments": [
      "Damn, 3080 for 300 is a good deal.",
      "What was the total upgrade cost? And what price did you sell the 3080 for",
      "Got lucky on FB market place. Guy was selling this sealed box 4080s for 1000 pounds. And sold my 3080 for 300 to another person.  :) so 700 pounds.",
      "Indeed it’s an amazing deal. \nI think OP could have gotten more tbh.",
      "Can't wait another month or 2?",
      "Sold mine for £350 yesterday, and probably could have got more I reckon. They are selling for close to £400 on eBay.",
      "Crazy the size of these cards today.",
      "Wanted to, however I know I wouldn't get this deal again. Was 1000 pounds and sold the 3080 for 300. Besides given the scalper nature now days, there's no guarantee of getting 50 series card anytime soon when it launches. I wanted to enjoy my christmas break playing cyberpunk at ultra. 😄",
      "5080 is gonna be 30-40% faster for the same price ? Thats why. Expecting disappointment is as stupid as expecting the opposite. Its a matter of 2 weeks to announcement. Unless you need it RIGHT NOW theres really no reason to, especially with prices of the 4000 series being so high",
      "White Strix is the best looking model out of all in my opinion",
      ">Expecting disappointment is as stupid as expecting the opposite.\n\nLaunch is weeks away.  This your first time?",
      "Mining cards are not used at max power.  They are usually power limited for peak efficiency.",
      "Why wait for disappointment when you can get enjoyment instead, right now? \n\nMaybe a 5070 ti is a few percent better value, or a few percent faster, but unless it comes with some very crazy exclusive feature, i dont see the point in even waiting honestly. You never know nvidias greed, or how avaliability will be. But i guess we will see...",
      "His dad works at Nintendo",
      "He paid more than MSRP and 4080S have been popping up for sub £900 for the past year. \n\nGuy who sold it for £1000 must be laughing he'll be getting a 5080 on launch in 3 weeks 😂",
      ">a brand new 7800XT for ~£380. It's basically like getting another 3080 but with 3 years warranty, less power usage and 6GB more VRAM\n\nAnd with worse raytracing and no DLSS\n\nObjectively it is merely a sidegrade at best.",
      "Everything you just said is wrong lmao. Funny man",
      "Yeah coz no one should buy one with the 5080 just 2 weeks away",
      "People don't come here for facts and reasoning they come here for validation.",
      "Clean, could have waited for the 50 series though."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "rtx 4080",
      "4080",
      "4080 super",
      "rtx 4080 super"
    ],
    "title": "GeForce 256 25th Anniversary Celebration: Enter for a chance to win a retro RTX 4080 SUPER PC!",
    "selftext": "On October 11, 1999 the GeForce 256 launched 25 years ago today!\n\nThe GeForce 256 wasn’t just another graphics card — it was introduced as the world’s first GPU, setting the stage for future advancements in gaming, creating,  computing, and generative AI.\n\n[https://www.youtube.com/watch?v=eVNvSaNFRfA](https://www.youtube.com/watch?v=eVNvSaNFRfA)\n\nWe’re celebrating the GeForce 256 all day long and as part of the celebration we’re giving away three sleeper rigs that feature the NVIDIA GeForce RTX 4080 SUPER, inspired by the golden era of PC gaming. \n\nTo enter for a chance to win one of three PCs, you can follow the specific GeForce 256 prompts on our social channels \\[[X](https://x.com/NVIDIAGeForce?ref_src=twsrc%5Egoogle%7Ctwcamp%5Eserp%7Ctwgr%5Eauthor), [Instagram](https://www.instagram.com/nvidiageforce/?hl=en), [TikTok](https://www.tiktok.com/@nvidiageforce?lang=en)\\] , or comment below an answer to the following question:\n\n***What was your favorite PC game of that era?***\n\n[Terms and conditions](https://www.nvidia.com/en-us/geforce/contests/geforce-anniversary-sleeper-build-sweepstakes-official-rules/) apply. Edit: The entry period for this will end October 18, 5PM PT. \n\n[**@peachietech**](https://www.tiktok.com/@peachietech?lang=en)**'s classic HP Pavilion rig**\n\nPowered by a GeForce RTX 4080 SUPER, this mini sleeper build based on a childhood favorite is ready for all PC games - no floppy disks needed.\n\nhttps://preview.redd.it/aojobpnmw4ud1.png?width=2048&format=png&auto=webp&s=ff9bd3811290636d59cd87b16d4aa78021502cc7\n\n[**@PCJunkieMods**](https://www.instagram.com/pcjunkiemods/?hl=en)**' eMachines rig**\n\nComplete with a \"NEVER OBSOLETE\" sticker, this PC rocks a mighty GeForce RTX 4080 SUPER for your favorite games new & old - dial-up internet not required. \n\nhttps://preview.redd.it/w0w56t8qw4ud1.png?width=2048&format=png&auto=webp&s=d42a2e1e5ad50ad3cc61040d73bd774a56ce677c\n\n[**@PCJunkieMods**](https://www.instagram.com/pcjunkiemods/?hl=en)**' classic Gateway rig**\n\nWith a GeForce RTX 4080 SUPER at the center of this classic tower design, you'll dominate the competition - just don't forget your trackball mouse.\n\nhttps://preview.redd.it/81o2d9zsw4ud1.png?width=2048&format=png&auto=webp&s=ab0aa4e61c03a7a5ffd9f3e72edf79a5f50b0fcc\n\nTo read more about the impact of the GeForce 256 [check out our blog!](https://blogs.nvidia.com/blog/first-gpu-gaming-ai/)",
    "comments": [
      "Half life was by far the best game of the time.  It was mine and my friends first real game we played online with death match then lead to our obsessions with all the Half Life mods.  We played so many mods TFC, Counterstrike, Day of Defeat, and Sven Coop. \n\nNo single game I believe had a bigger impact on gaming or modding for gaming as Half Life.",
      "Has to be half life for sure",
      "GTA2 probably",
      "I'm seeing it echoed a lot but gotta say Unreal Tournament",
      "I was young in 1999 for Pc gaming, but i remember starting with Hercules game, then Half-life or AvP",
      "Yeah, original Unreal Tournament with all the crazy character and voice mods, now that was the day!",
      "Half-life! This game defined many of our modern gaming conventions.",
      "Dune 2000, Starcraft & Half-Life. I've still got them on optical disc. They made great games back then that are fun to play.  Cheers 🥃",
      "Of course Half life!",
      "Pepsi man. I need this to play Pepsi Man.",
      "The first game that I really wanted to play and required a 3D accelerator was Motorcross Madness.  I remember searching for a 3d accelerator emulator to no avail, though I do remember a few convincing websites as a young teen.",
      "Half-Life, the beginning of a legend.\n\nhttps://preview.redd.it/x0m0b7ze66ud1.jpeg?width=1024&format=pjpg&auto=webp&s=e08ae32f0e232eb15e9ce5d7aee92b614be23f3f",
      "Half-Life.\nI remember playing Half-Life in 99 on 320x280 software rendering with less than 30fps on a PC my dad built for me from spare parts. I bagged my for a year to buy me a 3D graphics card. Finally I got a TNT2 and later a GeForce 2 GTX from Hercules.\n\nI swear, hardware from that era was something different, almost magical…",
      "Diablo 1 even though PlayStation version was better with coop then Diablo II for sure!",
      "the worms era of games was a timeless time to be around, those nights were something else",
      "Half life is very good",
      "Definitely quake II",
      "Unreal Tournament, Quake III Arena,",
      "Age of Empires II",
      "rip Portugal, but it was Age of Empires II"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "4080",
      "4080 super"
    ],
    "title": "Finished my dream build ❄️",
    "selftext": "Upgraded from my original build which was a ryzen 3 and a R9 390x. Couldn't be more happy with how it turned out! \n\nFull specs:\n\nRyzen 7 7800X3D \n\nGigabyte RTX aero OC 4080 super \n\nGigabyte B650 Aorus elite ax ice \n\n32 GB gskill trident z ddr5 @6400 \n\n6 TB Acer predator gm7000 \n\nCorsair RM 850 Watt gold \n\nLian li Galahad II Trinity w/ Lian li UNI TL 120 fans \n\nLian li UNI TL LCD 120 fans Phanteks NV5\n\n2",
    "comments": [
      "https://preview.redd.it/il7hdaw60lvc1.jpeg?width=1125&format=pjpg&auto=webp&s=65537d0981c2ffcdfb511595694d95567b761c98\n\nClean build!!",
      "This is masterpiece",
      "Lmao never seen the opposite version before",
      "😂😂😂 thanks bruv",
      "That's a typo it's actually 64 gbs. But yes 2 dims are usually faster. To be completely honest I didn't even mean to buy four sticks 😅 I didn't remove the other one from my cart when I ordered lmao",
      "Oh you rich rich. That is the most contemporary build I have ever seen in my life.",
      "Much appreciated",
      "I love the fact we can have screens everywhere now, just expecting the mouse with a screen to launch.\n\nNice build!",
      "maybe I do want to stare at the pretty lights in the computer under my table...",
      "Pardon my ignorance but 32gb of ram with 4 sticks? Isn’t two 16gb sticks faster?",
      "Real hardware addicts know there is no such thing as a dream build because a few years or even a few months down the line there will be something new and shiny that you want again.",
      "Same😂",
      "need space for all my audio equipment!",
      "Few words but excellence at its finest. I like.",
      "Beautiful machine",
      "It looks like a cyberpunk render 😳!!! well done,  enjoy it 👍",
      "It's the phanteks NV5",
      "Thank you! And no an AIO is definitely not a must there are plenty of air coolers that work great",
      "Save it make it popular",
      "It is at this point"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "rtx 4080",
      "4080"
    ],
    "title": "[Megathread] GeForce at CES 2025 - GeForce RTX 50 Series GPUs & Laptops, DLSS 4, Reflex 2, Project G-Assist, NVIDIA ACE, and more",
    "selftext": "https://preview.redd.it/5sb22vtbyhbe1.jpg?width=1600&format=pjpg&auto=webp&s=3b411b7b446ac5e8163c0416f1372b03e218936c\n\nHello everyone! Below, you’ll find all of the NVIDIA GeForce announcements from CES 2025. We hope you enjoyed the keynote. You can [watch a recap of the keynote here](https://www.youtube.com/watch?v=k82RwXqZHY8), or get the tl;dr for GeForce below. For detailed information, be sure to read through the articles, and watch the explainer videos.\n\n# GeForce RTX 50 Series\n\nMultiply performance by up to 8X using DLSS 4 with Multi Frame Generation, reduce PC latency by up to 75% with Reflex 2, and experience next-generation RTX Neural Rendering.\n\n|Specs|GeForce RTX 5090|GeForce RTX 5080|GeForce RTX 5070 Ti|GeForce RTX 5070|\n|:-|:-|:-|:-|:-|\n|**GPU**|GB202|GB203|GB203|GB205|\n|**Transistor Count**|92.2 Billion|45.6 Billion|45.6 Billion|31.1 Billion|\n|**Die Size**|750 mm^(2)|378 mm^(2)|378 mm^(2)|263 mm^(2)|\n|**GPC**|11|7|7|5|\n|**TPC**|85|42|35|24|\n|**CUDA Cores**|21760 Cores (170 SM)|10752 Cores (84 SM)|8960 Cores (70 SM)|6144 Cores (48 SM)|\n|**Tensor Cores (AI)**|680 5th Generation 3352 AI TOPS|336 5th Generation 1801 AI TOPS|280 5th Generation 1406 AI TOPS|192 5th Generation 988 AI TOPS|\n|**Ray Tracing Cores**|170 4th Generation 318 TFLOPS|84 4th Generation 171 TFLOPS|70 4th Generation 133 TFLOPS|48 4th Generation 94 TFLOPS|\n|**ROPs**|176|112|96|80|\n|**Texture Units**|680|336|280|192|\n|**L2 Cache**|96 MB|64 MB|48 MB|48 MB|\n|**Boost Clock**|2.41 Ghz|2.62 Ghz|2.45 Ghz|2.51 Ghz|\n|**Base Clock**|2.01 Ghz|2.3 Ghz|2.3 Ghz|2.16 Ghz|\n|**Standard Memory Config**|32 GB GDDR7|16 GB GDDR7|16 GB GDDR7|12 GB GDDR7|\n|**Memory Interface Width**|512-bit|256-bit|256-bit|192-bit|\n|**VRAM Speed**|28 Gbps|30 Gbps|28 Gbps|28 Gbps|\n|**Memory Bandwidth**|1792 GB/s|960 GB/s|896 GB/s|672 GB/s|\n|**Displayport**|DisplayPort 2.1b with UHBR20: up to 4K 480Hz or 8K 165Hz with DSC|DisplayPort 2.1b with UHBR20: up to 4K 480Hz or 8K 165Hz with DSC|DisplayPort 2.1b with UHBR20: up to 4K 480Hz or 8K 165Hz with DSC|DisplayPort 2.1b with UHBR20: up to 4K 480Hz or 8K 165Hz with DSC|\n|**HDMI**|HDMI 2.1b: up to 4K 480Hz or 8K 120Hz with DSC, Gaming VRR, HDR|HDMI 2.1b: up to 4K 480Hz or 8K 120Hz with DSC, Gaming VRR, HDR|HDMI 2.1b: up to 4K 480Hz or 8K 120Hz with DSC, Gaming VRR, HDR|HDMI 2.1b: up to 4K 480Hz or 8K 120Hz with DSC, Gaming VRR, HDR|\n|**Video Engine**|3x NVENC (9th Gen) / 2x NVDEC (6th Gen)|2x NVENC (9th Gen) / 2x NVDEC (6th Gen)|2x NVENC (9th Gen) / 1x NVDEC (6th Gen)|1x NVENC (9th Gen) / 1x NVDEC (6th Gen)|\n|**Total Graphics Power**|575 W|360 W|300 W|250 W|\n|**Required System Power**|1000 W|850 W|750 W|650 W|\n|**Required Power Connectors**|4x PCIe 8-pin cables (adapter in box) OR 1x 600 W PCIe Gen 5 cable|3x PCIe 8-pin cables (adapter in box) OR 1x 450 W or greater PCIe Gen 5 cable|2x PCIe 8-pin cables (adapter in box) OR 300 W or greater PCIe Gen 5 cable|2x PCIe 8-pin cables (adapter in box) OR 300 W or greater PCIe Gen 5 cable|\n|**Founders Edition**|Yes|Yes|No|Yes|\n|**Price**|Starting at $1,999|Starting at $999|Starting at $749|Starting at $549|\n|**Availability**|January 30th|January 30th|February|February|\n\n***Stated Performance Claim***:\n\n**RTX 5090:**\n\n* Thanks to the Blackwell architecture’s innovations and DLSS 4, the GeForce RTX 5090 outperforms the GeForce RTX 4090 by 2X.\n* NVIDIA GeForce RTX 5090 Founders Edition is a 2-slot, 304mm long x 137mm high x 2-slot wide, SFF-Ready Enthusiast GeForce Card.\n\nhttps://preview.redd.it/7s6n96qvg6de1.jpg?width=2580&format=pjpg&auto=webp&s=b391f241fb1cc0d25985b76ab3fdf0955589f30a\n\n**RTX 5080:**\n\n* Up to twice the speed of the GeForce RTX 4080 in games, thanks to the Blackwell architecture and DLSS 4 with Multi Frame Generation.\n\nhttps://preview.redd.it/yz68h9mxg6de1.jpg?width=2580&format=pjpg&auto=webp&s=02b2f4637b5b27e632ad97559294ece5b0120c9d\n\n**RTX 5070 Ti:**\n\n* Using the full capabilities of the Blackwell architecture, and the power of DLSS 4 with Multi Frame Generation, game frame rates are 2X faster than the GeForce RTX 4070 Ti’s.\n\nhttps://preview.redd.it/1v05b7nyg6de1.jpg?width=2580&format=pjpg&auto=webp&s=8890de414ab322bfd4db28d11ad18ad24a07ce50\n\n**RTX 5070:**\n\n* At 2560x1440, with full ray tracing and other settings maxed, and DLSS Multi Frame Generation enabled, GeForce RTX 5070 owners can play Black Myth: Wukong, Alan Wake 2, and Cyberpunk 2077 at high frame rates, with performance that is twice as fast on average compared to the GeForce RTX 4070.\n\nhttps://preview.redd.it/m4wya0a0h6de1.jpg?width=2580&format=pjpg&auto=webp&s=00fe354dd86f43a1aed9b4d240dddc95fd7351c4\n\n# RTX 50 Series Laptops\n\n* Starting in March, GeForce RTX 50 Series comes to laptops. As thin as 14.9mm, GeForce RTX 50 Series laptops boast up to 40% better battery life thanks to new Blackwell Max-Q innovations, and double the performance of previous-generation models.\n* Game with double the FPS. Create content and complete workflows in half the time. And finish generative AI tasks 2.5X faster.\n* GeForce RTX 5090, GeForce RTX 5080, and GeForce RTX 5070 Ti laptops will be available starting in March, followed by GeForce RTX 5070 Laptops in April. There will be designs from the world’s top manufacturers, including Acer, ASUS, Dell, GIGABYTE, HP, Lenovo, MECHREVO, MSI, and Razer. Stay tuned to their websites for further details about the GeForce RTX 50 Series Laptops they’re creating\n\nhttps://preview.redd.it/nrl2bz5o1ibe1.jpg?width=1600&format=pjpg&auto=webp&s=fa9ce5c1daaf4e3309a8fbda3f7beccd796adf0a\n\n# RTX Neural Shaders\n\n* Alongside GeForce RTX 50 Series GPUs, NVIDIA is introducing [RTX Neural Shaders](https://developer.nvidia.com/blog/nvidia-rtx-neural-rendering-introduces-next-era-of-ai-powered-graphics-innovation/), which brings small AI networks into programmable shaders, unlocking film-quality materials, lighting and more in real-time games. \n* Rendering game characters is one of the most challenging tasks in real-time graphics, as people are prone to notice the smallest errors or artifacts in digital humans. [RTX Neural Faces](https://developer.nvidia.com/blog/nvidia-rtx-neural-rendering-introduces-next-era-of-ai-powered-graphics-innovation/) takes a simple rasterized face and 3D pose data as input, and uses generative AI to render a temporally stable, high-quality digital face in real time.  \n* RTX Neural Faces is complemented by new RTX technologies for [ray-traced hair and skin](https://developer.nvidia.com/blog/nvidia-rtx-neural-rendering-introduces-next-era-of-ai-powered-graphics-innovation/). Along with the new [RTX Mega Geometry](https://developer.nvidia.com/blog/nvidia-rtx-neural-rendering-introduces-next-era-of-ai-powered-graphics-innovation/), which enables up to 100x more ray-traced triangles in a scene, these advancements are poised to deliver a massive leap in realism for game characters and environments.  \n* The power of neural rendering, DLSS 4 and the new DLSS transformer model is showcased on GeForce RTX 50 Series GPUs with Zorah, a groundbreaking new technology demo from NVIDIA. \n\n# DLSS 4\n\n**Article Link**: [NVIDIA DLSS 4 Introduces Multi Frame Generation & Enhancements For All DLSS Technologies](https://www.nvidia.com/en-us/geforce/news/dlss4-multi-frame-generation-ai-innovations/)\n\n**Video Link**: [Watch NVIDIA’s Bryan Catanzaro and Edward Liu walk through DLSS 4](https://youtu.be/qQn3bsPNTyI)\n\nDLSS 4 FAQ: [Link Here](https://www.nvidia.com/en-us/geforce/forums/geforce-graphics-cards/5/555374/dlss-4-faq/)\n\n* [75 games and apps will have support](https://www.nvidia.com/en-us/geforce/news/dlss4-multi-frame-generation-ray-tracing-rtx-games) for Multi Frame Generation when they’re released.\n* DLSS 4 also introduces the biggest upgrade to its AI models since the release of DLSS 2.0 in 2020.\n\nhttps://preview.redd.it/0lhwv6q72ibe1.jpg?width=1600&format=pjpg&auto=webp&s=5db40477bd3025099ca17cb278c27064483fc634\n\n* **DLSS Multi Frame Generation** generates up to three additional frames per traditionally rendered frame, working in unison with the complete suite of DLSS technologies to multiply frame rates by up to 8X over traditional brute-force rendering. This massive performance improvement on GeForce RTX 5090 graphics cards unlocks stunning 4K 240 FPS fully ray-traced gaming.\n   * **Video Link**: [*On the GeForce RTX 5090, DLSS 4 with Multi Frame Generation multiplies performance by over 8X versus traditional brute force rendering in this Cyberpunk 2077 scene, PC latency is halved for more responsive gameplay, and image quality is further enhanced*](https://www.youtube.com/watch?v=yWYbqOFyB5Q)\n\nhttps://preview.redd.it/uzdkhzxc2ibe1.jpg?width=1600&format=pjpg&auto=webp&s=a7122bff7530378daf0f4ba84b22e813223178ab\n\n* **Frame Generation** gets an upgrade for GeForce RTX 50 Series and GeForce 40 Series GPUs, boosting performance while reducing VRAM usage.\n* **DLSS Ray Reconstruction, DLSS Super Resolution, and DLAA will now be powered by the graphics industry’s first real-time application of ‘transformers’**, the same advanced architecture powering frontier AI models like ChatGPT, Flux, and Gemini. DLSS transformer models improve image quality with improved temporal stability, less ghosting, and higher detail in motion\n* Alongside the availability of GeForce RTX 50 Series, NVIDIA app users will be able to upgrade games and apps to use these enhancements.\n* And on all GeForce RTX GPUs, DLSS games with Ray Reconstruction, Super Resolution, and DLAA can be upgraded to the new DLSS transformer model.\n* For many games that haven’t updated yet to the latest DLSS models and features, [NVIDIA app](https://www.nvidia.com/en-us/software/nvidia-app/) will enable support through a new DLSS Override feature. Alongside the launch of our GeForce RTX 50 Series GPUs, after installation of a new GeForce Game Ready Driver and the latest NVIDIA app update, the following DLSS override options will be available in the Graphics > Program Settings screen, under “Driver Settings” for each supported title.\n   * **DLSS Override for Frame Generation** \\- Enables Multi Frame Generation for GeForce RTX 50 Series users when Frame Generation is ON in-game.\n   * **DLSS Override for Model Presets** \\- Enables the latest Frame Generation model for GeForce RTX 50 Series and GeForce RTX 40 Series users, and the transformer model for Super Resolution and Ray Reconstruction for all GeForce RTX users, when DLSS is ON in-game.\n   * **DLSS Override for Super Resolution** \\- Sets the internal rendering resolution for DLSS Super Resolution, enabling DLAA or Ultra Performance mode when Super Resolution is ON in-game.\n   * Upgrading and enhancing games takes just a few clicks in NVIDIA app\n\nhttps://preview.redd.it/isew0jx86ibe1.png?width=1840&format=png&auto=webp&s=639462bdc55c8ee578d3051c4f71cbfce0e83ecd\n\n# [DLSS Multi Frame Generation & New RTX Technologies Coming To Black State, DOOM: The Dark Ages, Dune: Awakening, and More. 75 Games and Apps At Launch & More On The Way](https://www.nvidia.com/en-us/geforce/news/dlss4-multi-frame-generation-ray-tracing-rtx-games)\n\n* Multiply performance by up to 8X and experience new cutting-edge NVIDIA RTX ray tracing and AI technologies in Alan Wake 2, Black Myth: Wukong, Indiana Jones and the Great Circle, Marvel Rivals, NARAKA: BLADEPOINT, and many other titles.\n* Alan Wake 2 is also adding RTX Mega Geometry, and an Ultra quality full ray tracing mode.\n* Indiana Jones and the Great Circle is also adding DLSS Ray Reconstruction and RTX Hair.\n* The Witcher IV will feature the latest RTX technologies when released.\n* Even more games and apps are adding [RTX Neural Shader technologies](https://developer.nvidia.com/rtx-kit). Stay tuned for details.\n* **Video Link**: [RTX. It’s On. The Ultimate in Ray Tracing and AI with DLSS 4](https://www.youtube.com/watch?v=M3fglmDxD2U)\n\n# NVIDIA Reflex 2\n\n**Article Link**: [**NVIDIA Reflex 2 With New Frame Warp Technology Reduces Latency In Games By Up To 75%**](https://www.nvidia.com/en-us/geforce/news/reflex-2-even-lower-latency-gameplay-with-frame-warp)\n\n**Video Link:** [Click Here](https://www.youtube.com/watch?v=zpDxo2m6Sko)\n\n* Reflex 2 combines Reflex Low Latency mode with a new Frame Warp technology, further reducing latency by updating the rendered game frame based on the latest mouse input right before it is sent to the display.\n\n# Project G-Assist\n\nArticle Link: [**Project G-Assist: An AI Assistant For GeForce RTX AI PCs, Comes to NVIDIA App In February**](https://www.nvidia.com/en-us/geforce/news/g-assist-ai-companion-for-rtx-ai-pcs)\n\n* Optimize performance, configure PC settings, and more with a voice-powered AI Assistant, all run locally on GeForce RTX GPUs.\n\n# NVIDIA ACE\n\nArticle Link: [**NVIDIA Redefines Game AI With ACE Autonomous Game Characters**](https://www.nvidia.com/en-us/geforce/news/nvidia-ace-autonomous-ai-companions-pubg-naraka-bladepoint)\n\nVideo Link: [Click Here](https://www.youtube.com/watch?v=wEKUSMqrbzQ)\n\n* PUBG: BATTLEGROUNDS, inZOI, MIR5 & NARAKA: BLADEPOINT MOBILE PC VERSION are the first games to incorporate autonomous companions, enemies, and game systems powered by NVIDIA ACE.\n* In 2025, *PUBG* IP Franchise is introducing Co-Playable Character (CPC) with *PUBG* Ally. Built with NVIDIA ACE, Ally utilizes the Mistral-Nemo-Minitron-8B-128k-instruct small language model that enables AI teammates to communicate using game-specific lingo, provide real-time strategic recommendations, find and share loot, drive vehicles, and fight other human players using the game’s extensive arsenal of weapons.\n* In March 2025, NetEase will release a local inference AI Teammate feature built with NVIDIA ACE for[ *NARAKA: BLADEPOINT* *MOBILE PC VERSION*](https://www.narakamobile.com/en/#/), with[ *NARAKA: BLADEPOINT*](https://store.steampowered.com/app/1203220/NARAKA_BLADEPOINT/)on PC also adding the feature later in 2025. *NARAKA: BLADEPOINT* is one of the top 10 most played games on Steam each week, and *NARAKA: BLADEPOINT MOBILE* boasts millions of weekly players on phones, tablets, and PCs. AI Teammates powered by NVIDIA ACE can join your party, battling alongside you, finding you specific items that you need, swapping gear, offering suggestions on skills to unlock, and making plays that’ll help you achieve victory.\n* Several other games are also incorporating NVIDIA ACE technologies: full details in the article.\n\n# Creator\n\n* The GeForce RTX 50 Series revolutionizes creative workflows [thanks to new NVIDIA Studio tools and features for creators, and even faster hardware](https://blogs.nvidia.com/blog/generative-ai-studio-ces-geforce-rtx-50-series).\n* Added hardware support for encoding and decoding the 4:2:2 pro-grade color format yields a staggering 11X encoding speed increase compared to software encoders.\n* 9th Gen NVENC video encoders include a 5% improvement to HEVC and AV1 encoding quality, and a new AV1 Ultra Quality mode that offers an additional 5% improvement to encoding efficiency. And the 6th Gen NVIDIA decoder is capable of decoding and playing back up to eight 4K60 4:2:2 video streams simultaneously.\n\n# Giveaway\n\nRespond on the pinned comment below to enter giveaway for 3x $20 Steam giftcards.",
    "comments": [
      "$549 was certainly a surprise",
      "I'm going to be very interested to see 5000 series benchmarks without dlss/ai/upscaling features.  They seemed to be really talking AI enabled with the new cards, but I'm excited to see what benchmarks brings",
      "I'm ready to be so disappointed by linus tech tips or gamersnexus, watch it be an 18% uplift without the new magical fake frames feature",
      "It feels like this generation is the first true generation of AI prioritized GPUs.  Rasterization is essentially dead. \n\n\nGPUs from here on out will nearly completely rely on AI advancements instead of raw horsepower. This is what a GPU is now.",
      "Literally just murdered AMD’s 9070 before they even announce it lol.\n\nPeople over there were so fucking adamant that no way NVDA would sell the 5070 less than $650 and that the 9070 would undercut it by $50.",
      "Can’t wait for the 5090 and fighting all the bots again ugh",
      "Where are all the doomers saying that the 5080 was going to be at minimum 1500 dollars? Never believe rumored \"leak\" prices everyone. There's no such thing as a confirmed price until jensen walks on stage and says one",
      "Were any benchmarks shown without frame generation? Also it looks like DLSS4 features are coming to all RTX cards, just not multi-frame gen, which is the least exciting feature imo.",
      "Instead of fighting bots. You will be fighting 30+ year old men that smell like New York rats to get your 5090 at Microcenter.",
      "Very happy with the 5070 price point. Was expecting 650-700. Really excited to see reviews and upgrade out of my 2070 super. Pretty much only upgrading because of MH Wilds.",
      "From this imprecise bar graph, Nvidia seems to be saying that a 5090 gets framerates ~30 fps for native 4k path tracing in Cyberpunk, and ~150 fps with performance DLSS + DLSS3 frame generation.\n\nFor comparison, a 4090 gets ~20 fps with native 4k path tracing in Cyberpunk.\n\nhttps://www.nvidia.com/content/dam/en-zz/Solutions/geforce/news/dlss4-multi-frame-generation-ai-innovations/nvidia-dlss-4-multi-frame-generation-up-to-8x-faster-performance.jpg\n\nEDIT: Typo.",
      "I'm fine with it as long as it looks good. \n\nInsert bell curve meme\n\ndoes it look good? \n\nnooooo the raster performance is only 15% higher and blah blah blah\n\ndoes it look good?",
      "What the actual fuck are these AI benchmarks?  \n  \nFP8 on 40 series but FP4 on 50 series? That's not even remotely a fair comparison. It's not even a comparison at all.",
      "Can anyone explain to me if the new DLSS 4 multi frame generation thing still gives you input lag? Has it been improved?",
      "With a 27% increase in power draw... 20% isn't all that great.",
      "RTX 5090 *starting at* $4039 AUD… get fuuuuuucked.",
      "Lmao obviously not \nOnly with DLSS4 on",
      "Ok this is a game changer\n\nNvidia basically flipped the table and redid the whole rendering process. All of it\n\nThe Shader pipeline → Neural shader\n\nBVH structure → RTX Mega Geometry\n\nPath tracing RESTIR → Neural Radiance Cache\n\n  \nThey are WAY WAY ahead of competition, omg it hurts. AMD still hasn't even showcased their AI upscaler and Nvidia is leaping generation**s** ahead",
      "The 5090 still has 93 billion transistors over the 76 bil of the 4090 and also has GDDR7 so shouldn’t rely totally on ai for performance improvements",
      "My sincere apologies for the delay on the Megathread. There were tons of stuff announced. \n\nIf you want to enter the giveaway for a chance to win 3x $20 Steam Giftcard, please respond to this pinned comment for the following questions:\n\n   * Which platform technology or GPU feature are you most excited about from today’s announcement?\n   * Which RTX game are you most looking forward to playing and why?\n\nGiveaway will open until Sunday January 25th at Noon Eastern."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "4080",
      "4080 super"
    ],
    "title": "3080 FE x 4080 Super FE x 5080 FE",
    "selftext": "lol sorry for the horrid pictures. ",
    "comments": [
      "Damn the 4080S is a chonker never knew it was that fat",
      "He is the reason Nvidia can get away with 10% uplift generations. \n\nNvidia couldve done an Intel and put a GPU 10% slower and he still would've gone out and paid 2k$ for it. 💀",
      "Why would you go from 4080S to a 5080?",
      "Yup they just used the 4090 cooler",
      "You're the exact customer NVIDIA targets",
      "Same body/chassis, too. Kinda brilliant move -- only one spec to manufacture and stock. (Manufacturing junkie here, lol). Plus the OP 4090 FE cooler keeps my 4080 FE frosty.",
      "Because I’m a fool",
      "That's what rich means x)",
      "I have no words.",
      "Actually, he is. When Nvidia started engineering the 5090 and 5080 chips, employees referred to the project as \"project Ugly__God\".\n\n\nSource: Believe me, please.",
      "consume wisely...",
      "Bro what 💀😭",
      "Make sure u got all ur ROPs",
      "![gif](giphy|szWu9brqcBP45m36YE)",
      "Look at you being rich…",
      "and silent all the time!",
      "He’s saying it was FOMO",
      "I respect the honesty 🫡",
      "More money than sense lol",
      "There's no way you bought a 4080 Super to replace it a week later"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "rtx 4080",
      "4080",
      "4080 super",
      "rtx 4080 super"
    ],
    "title": "Ascended from 1080ti to 4080 Super",
    "selftext": "I was able to upgrade from 8700K - 1080ti to 9800X3D - 4080 Super last week. It felt so good together with the LG C4, 4K Oled is Amazing!  \n\n\nJust in case it’s necessary, here’s the specs.  \n\n\nCPU: 9800X3D.  \nMB: Gigabyte X870 Aorus Elite WiFi7.  \nRAM: 32GB DDR5 G.Skill Trident Neo.  \nGPU: Gigabyte RTX 4080 Super Gaming OC.  \nPSU: Lian Li Edge 1000w.  \nAIO: Lian Li Hydroshift R.  \nSSD: 1TB KC3000 (OS) 2TB P400 (Games) 2TB P220 (Media).  \nFANS: Interstellar V2.  \nCASE: Antec C8.  \nMonitors: LG C4 42 and Acer Predator X34P.  \nMnK: Mammoth 75 Wireless and X Lite Wireless.  \n\n\nYes, i cannot wait for the 5000 series, i’d rather enjoy my holidays gaming in 4K than waiting for 6-12 months for GPU Prices to normalize (Fuck Scalpers and Competition)\n",
    "comments": [
      "yeah this 1080ti and 8700k combo been smashing shit for almost 10 years. 1080ti was the best card for value ever created.",
      "I went from a 1080ti to the 4080 super this year as well! Loving it!",
      "Definitely! My old was still working, so i gave it to my sister as her work PC. \n\nI just wanted to play in 4K Oled and watch movies with the wife every weekend so i ended up with the LG C4. Money well spent.",
      "That’s a hyper jump upgrade! \nCongratulations!",
      "Thats not ascend. Just revert it and give me your 4080",
      "1080 ti is a beast",
      "I went from 2080 (basically the same as 1080ti) to 4080 and my fps more than doubled without upscaling!",
      "Welp I'm still using a 1080FE. I might be stuck forever 😭",
      "1080Ti still going hard too. stalker 2 60fps with some mild upscale",
      "![gif](giphy|26gsjCZpPolPr3sBy|downsized)",
      "I'm currently rocking the 1080, it's been a great card!  Just ordered a used 3080ti, not quite as big a jump as you made but should be pretty substantial",
      "You can now play cyberpunk in how it's meant to be played",
      "It's truly an incredible piece of technology. Never to be created again at such a value. I think I paid 650 for mine, it's under a water block and still kicking ass. Only thing I wish it had was DLSS.",
      "Clean build. Gorgeous!",
      "Still rocking my 1080ti. Nice build!",
      "![gif](giphy|g9582DNuQppxC|downsized)",
      "It truly is! Still was working, decided to give it to mu sister as her work PC.",
      "Those jumps are so satisfying.  I went from a i5-4670 and 980ti to a 5800x3D and 3800ti and remember games that struggled to maintain a sold 60 were now exceeding my monitors 165Hz limit.  RDR2 at 1440p ultra was the moment of justification for me.",
      "Cyberpunk on a 4080 Super is awesome! You’ll need upscaling to hit 60 FPS with full path tracing, though.",
      "Haven't played Cyberpunk but I also just made a very similar upgrade to a 4080S. I'm not even a fidelity junkie but I've been pretty damn wowed by the results and I don't regret what I spent at all."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "rtx 4080",
      "4080",
      "4080 super",
      "rtx 4080 super"
    ],
    "title": "Upgrade after 11 years: 780 Super to 4080 Super",
    "selftext": "After 11 years I have finally upgraded to a new build. Going from a Palit Geforce GTX 780 Super Jetstream 3 GB that I bought in November 2013 to an Asus RTX 4080 Super Proart 16 GB. My old CPU was an Intel Xeon, now I use an AMD Ryzen 9 7900.\n\nTiny new box, huge upgrade. Very happy with it. And yes, I will add a 120mm Noctua fan under the PSU, still waiting for the fan grill to arrive.\n ",
    "comments": [
      "...780 Super?",
      "Its part of palit naming \"Super JetStream\" , not Nvidia model name",
      "You are going to notice the difference, I daresay.",
      "They are already here, as expected. I couldnt care less what Nvidia will announce in January. Happy with what I have now. Will serve me well for years to come, and building in an itx case for the first time was an absolute blast. No regrets at all.",
      "waits 11 years but can't wait 10 days for concrete 5080 details :D\n\nEdit 11 (lol) days later... now we can see 40 users locked out of good framegen, and 16GB gpu for $750.. 5080 at $1000.... everyone believed the fake leaks, fell for the FOMO of tariffs... \n\n40 series users spamming reddit asking if they should sell/return their 40 series looool....",
      "Waiting for the YuO sHOuLD HaVe WaItED for tHe 5080 people",
      "Nah bro 15% performance increase max, wait for the 8090 ti super for a real boost /s",
      "This subreddit in a nutshell, at least is not another 4060 bought at full price lol",
      "Sums up the lack of optimism for the 5000 cards people have i guess.",
      "i cannot wait to spend $1700 on a 16GB gpu!!!",
      "You can finally play Crysis",
      "There was no 780 Super. Super Jetstream is Palit’s name for it.",
      "Why did you wait 11 years were you in a coma or something",
      "Can’t think of a single reason why? Maybe they couldn’t afford it? 🤡",
      "He waited 11 years, he could've waited one more month.",
      "2080 ti / 9900k is still great though",
      "Congrats, earlier this year I build similar system in a Lian li h2O a4 case. 7800x3d same Asus GPU. It's great",
      "You could make an argument for the GTX 780 classified being a \"780 super\", seeing as this was at a time when GPU overclocking gave sizable gains, but the Palit 780 Super Jetstream? Not so much.",
      "You're an optimist.",
      "This loser is going to misguide so many of you because the 10k series was just rumored and will destroy all other cards. Just wait for those to come out /s"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "4080",
      "4080 super"
    ],
    "title": "lucked out and got a 5080 FE on release day",
    "selftext": "this thing looks so clean and overclocks/undervolts very well. 95-97% the performance of a 4090 but with significantly lower wattage. sold my 4080 super for this with no regrets. ",
    "comments": [
      "![gif](giphy|G1vplGMypxBcp7kx32)\n\n(Sarcasm aside, congrats!)",
      "https://preview.redd.it/ys7jzp30t5ie1.jpeg?width=1440&format=pjpg&auto=webp&s=ec069cfe7d794c46aadca861bad3ef01772f6c84",
      "Nice cabinet by the way! Looks cool!",
      "i hope you’re using the factory cables that come with that gpu. homeboy in another sub fried his 5090fe using aftermarket cables. \n\nedit: congratulations! thats a nice looking rig you got there.",
      "So how much did you pay the scalper?",
      "You replaced a 4080 Super?!??!?!?! \n\n🤦‍♂️",
      "Every time, and every time it's worth clicking into these threads to see these.",
      "His dad's credit card paid.",
      "also saw that post today! i am in the process of replacing mine with the factory cables. thank you!",
      "I bought extensions for psu cables to get a cleaner look when I build my new pc this weekend, but that post has successfully taught me not to consider using them on a gpu. Gonna use it for mobo/cpu cables though.",
      "You bothered to disassemble your build to get a GPU less than 10% better, just why💀",
      "What cpu cooler is that? Looks really nice",
      "Montech METAL DT24 PREMIUM",
      "Some people enjoy building and working on computers, and look for excuses to do so.\n\nI guess if you aren't interested, or aren't very savvy/experienced, then opening up a PC can seem like a pain, but that's a big part of why I personally buy new hardware.\n\nBuilding computers professionally pays nothing, and my day job is staring at Excel. Tearing my rig apart for a GPU upgrade is like Christmas.",
      "Swapping a GPU takes maybe 5 mins, it’s one cable and 2-3 screws at most. Do you not take yours out to clean it?",
      "it honestly wasn’t but i tried my luck for the FE and got it. i put my 4080 super up for bid on ebay and ended up getting more than i paid for it. my benchmarks show i got about a 25% uplift after i overclocked the 5080 and the x4 DLSS frame gen isn’t too shabby either.",
      "least aggressive reddit user",
      "anyone with a 4080 would buy a 5080 at $999. Based on market value of the 4080 super, you'd at the very lease be getting a free upgrade",
      "The 4080 has 0 headroom to oc. The 5080 seemingly has loads.",
      "Damn, insane upgrade"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "rtx 4080",
      "4080",
      "4080 super",
      "rtx 4080 super"
    ],
    "title": "Alleged GeForce RTX 5080 3DMark leak: 15% faster than RTX 4080 SUPER - VideoCardz.com",
    "selftext": "",
    "comments": [
      "So it's worth upgrading from the 3080, but not from the 4080. Same as always.",
      "Coming from a 3080 10GB, this sounds good enough for me. I do not understand those who don’t hold on to their cards for longer than one generation…",
      "Yeah. I've always done every other generation. Unless money is no object and you enjoy always having the latest tech.",
      "Probably going to upgrade from an ancient 1080 Ti",
      "I do every generation since graphics cards hold their value so well I just sell my old one",
      "It's funny when people complain about low uplift from 40 to 50 series so suddenly the card isn't worth it \n\nAs if the only people upgrading are those on the 40 series",
      "10-15%",
      "The 1080 Ti and 4090, both cards people who bought them Day 1 got insane value with.",
      "How much slower than the 4090 does that make it?",
      "All you need to know is the 5090 is NOT 2x performance over the 5080. \n\nBut the 5090 is 2x the price. \n\nSo, 5080 is better value.",
      "Still not twice the performance and at least for me only 50% more Vram. I want twice the performance minimum and twice the Vram.",
      "Iono though I'm pretty sure people were initially laughing at Nvidia asking who the hell would spend 1600$ on a GPU back when 4090 came out. In retrospect 4090 seems like a great value because we have re-normalized our expectations of what GPUs should cost",
      "For Rtx 3080 users with the 10 GB model, its a bit more than 50% more vram! So this is a nice upgrade in a pinch!",
      "100%. the one generation uplift is almost never worth is anyway. I am sitting on a 2070 super and i cant wait to get a 5080",
      "Value is a relative term, it's not carved in stone, just FYI",
      "The elusive 4080 SUPER DUPER",
      "Yeah but you can also OC a 4090, so its pointless talking about overclocking. Just compare stock vs stock performance. There is no guarantee your card will even be able to OC, when the 2080 Ti's came out I went through 3 cards , the first two were fucked and had to be returned and the third was stable but could only OC 30 mhz, that was it. That was all she had in her. Same case with one of the first two.\n\nYou cant go into buying a card expecting a certain level of OC performance. In my opinion the 5080 will be a very solid gaming card but the 4090 will reign supreme as the 2nd best card for the foreseeable future. Being stronger and having 8GB more of VRAM is just too good. Some folks need that VRAM for AI model/productivity work or games with large texture sizes/mods. If the 5090 supply is as restricted as they say, we may very well see 4090 values rise to $2000 on eBay. they are already at $1850.",
      "Im interested to see what will be the best price for the performance upgrade from my trusty 3080",
      "If it's 10-15% slower than the 4090 and the 5090 is 30% faster than a 4090, doesn't that mean this is effectively something around 55% the speed of a 5090?\n\nI remember seeing the downvote brigade here disagree with the idea that 5080 is roughly half the power of a 5090. If the leak is true it doesn't seem far off... given half the cores, half the bandwidth, half of...everything more or less.\n\nNote: i'm extrapolating for gaming performance, not time spy performance. Time spy shows different numbers than typical gaming fps outcomes. Note that 3dmark puts the 7900xtx ahead of the 4080 super but in the real world it is usually behind even the 4080FE in gaming.",
      "Agreed. I wondered why this comment was faring so well before I realized we are in nvidia not pcmasterrace.\n\nHad you dropped this in there, you would have been littered with responses:\n\n”1070 still going strong! Plays everything I throw at it” \n\n”1060 gang represent!!”"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "4080"
    ],
    "title": "[Megathread] NVIDIA App Update Adds DLSS 4 Overrides, New Broadcast Update, Improvements To RTX Video Super Resolution & More",
    "selftext": "**Full Article Here**: [Link Here](https://www.nvidia.com/en-us/geforce/news/nvidia-app-update-dlss-overrides-and-more/)\n\n**Article Summary below**\n\n* By installing the update and our new driver, launching at 6am PT, you can employ NVIDIA DLSS 4 to enhance over 75 games and apps with [DLSS 4 with Multi Frame Generation](https://www.nvidia.com/en-us/geforce/news/dlss4-multi-frame-generation-ai-innovations/), and [new, even better AI models](https://www.nvidia.com/en-us/geforce/news/dlss4-multi-frame-generation-ai-innovations/) for DLSS Super Resolution, Frame Generation, and Ray Reconstruction.\n* GeForce RTX 50 Series gamers can now also enable **NVIDIA Smooth Motion**, a new driver-based AI model that delivers smoother gameplay by inferring an additional frame between two rendered frames. For games without DLSS Frame Generation, NVIDIA Smooth Motion is a new option for enhancing your experience on GeForce RTX 50 Series GPUs.\n* A new [NVIDIA Broadcast](https://www.nvidia.com/en-us/geforce/broadcasting/broadcast-app/) update is now also available for download, introducing new AI-powered Studio Voice and Virtual Key Light effects to enhance your streams, and a new user interface that enables users to combine even more effects.\n* RTX Video Super Resolution enhances the quality of video using AI. Our new NVIDIA app update reduces the GPU usage of this popular feature by 30%, adds an on-screen status indicator, and enables users to automatically adapt quality and GPU utilization when using other GPU-intensive programs.\n* Rounding out our new release is the addition of more NVIDIA Control Panel options, namely Advanced Optimus and Multiple Display management.\n\n# NVIDIA DLSS 4 Overrides Upgrade Your Games & Apps\n\n* DLSS 4 also introduces the biggest upgrade to its AI models since the release of DLSS 2.0 in 2020.\n* DLSS Super Resolution, DLSS Ray Reconstruction, and DLAA are now powered by the graphics industry’s first real-time application of ‘transformers’, the same advanced architecture powering frontier AI models like ChatGPT, Flux, and Gemini. DLSS transformer models improve image quality with improved temporal stability, less ghosting, and higher detail in motion.\n* Similarly, the DLSS Frame Generation AI model is upgraded, boosting performance and reducing VRAM use on GeForce RTX 40 Series GPUs and GeForce RTX 50 Series GPUs.\n\nhttps://preview.redd.it/8s8rasqmz4ge1.png?width=2560&format=png&auto=webp&s=d083f85edb60d937ca63e6c006bf56dcf3e5b04d\n\n* *Alan Wake 2*, *Cyberpunk 2077*, and *Hogwarts Legacy* [have added native support for DLSS 4 with Multi Frame Generation today](https://www.nvidia.com/en-us/geforce/news/dlss-4-multi-frame-generation-out-now/).\n\nIn games and apps that have yet to update to DLSS 4 or add native support for DLSS Multi Frame Generation, NVIDIA app users can activate DLSS 4 overrides to enhance image quality on all GeForce RTX GPUs, unlock DLSS Multi Frame Generation for GeForce RTX 50 Series GPUs, and more:\n\n* **DLSS Multi Frame Generation Override** \\- Enables DLSS Multi Frame Generation for GeForce RTX 50 Series users when Frame Generation is ON in-game\n* **DLSS Frame Generation Model Upgrade** \\- Enables the latest DLSS Frame Generation model for GeForce RTX 50 Series and GeForce RTX 40 Series users, when Frame Generation is ON in-game, which uses less video memory and can increase frame rates\n* **DLSS Transformer Model Upgrade -** Enables the latest transformer AI model for DLSS Super Resolution, Ray Reconstruction, and DLAA for all GeForce RTX users, when the aforementioned features are ON in-game\n* **DLAA & Ultra Performance Modes** \\- Sets the internal rendering resolution for DLSS Super Resolution, enabling DLAA or Ultra Performance mode in games lacking native support, when Super Resolution is ON in-game\n\n*For a full list of games and apps with DLSS overrides, and a breakdown of which overrides are available in each title,* [*head here*](https://www.nvidia.com/en-us/geforce/news/nvidia-rtx-games-engines-apps/)\n\nTo enable DLSS 4 overrides in NVIDIA app, press the “Refresh” button located within the 3 dot option:\n\nhttps://preview.redd.it/wo3v4ez105ge1.png?width=1142&format=png&auto=webp&s=c0b2d72fca09872e1367b963d7c6bbf3c17c2ba6\n\nThen select a compatible game or app in Graphics > Program settings, and scroll down the list of options on the right to reach “Driver Settings”.\n\n**To enable DLSS Multi Frame Generation, which will boost frame rates significantly:**\n\n* Ensure DLSS Frame Generation is activated in the program, and then exit to the desktop\n* Select “DLSS Override - Frame Generation” in NVIDIA app\n* Pick 3X if you’re targeting up to 180 FPS, and 4X for 240 FPS or more\n* Reopen the program and enjoy even faster performance!\n* *Revert to the game’s natively integrated DLSS Frame Generation feature set by selecting “Use the 3D application setting”*\n\nhttps://preview.redd.it/cmgw1sz305ge1.png?width=1817&format=png&auto=webp&s=32b720475b5679e8bf0c2dfefd2d45bc9f42b7b1\n\n**To upgrade DLSS Frame Generation to the new, more performant AI model:**\n\n* Ensure DLSS Frame Generation is activated in the program, and then exit to the desktop\n* Select “DLSS Override - Model Presets” in NVIDIA app\n* Select “Latest” under “Frame Generation”, then click “Apply”\n* Reopen the program\n* *Revert to the game’s natively integrated model by selecting “Use the 3D application setting”*\n\nhttps://preview.redd.it/y3budvh705ge1.png?width=1594&format=png&auto=webp&s=6be613ca0399292434c0ee9543ea0645b4fc876c\n\n**To upgrade DLSS Super Resolution, DLSS Ray Reconstruction, or DLAA to the new transformer AI model:**\n\n* Ensure the feature you wish to upgrade is activated in the program, and then exit to the desktop\n* Select “DLSS Override - Model Presets” in NVIDIA app\n* Select “Latest” under “Super Resolution” and “Ray Reconstruction”, then click “Apply”\n* As of January 30th, 2025, the “Latest” model for DLSS Super Resolution has been updated to Transformer \"Preset K\", a minor refinement to Transformer Preset J, which showcases improved temporal stability, reduced ghosting, and enhanced detail in motion. Let us know what you think!The “Latest” model for Ray Reconstruction continues to use Preset J\n* Revert to the game’s natively integrated models by selecting “Use the 3D application setting”\n* Reopen the program and experience enhanced image quality\n* *Apply an older or alternative DLSS Convolutional Neural Network (CNN) DLSS Super Resolution AI model by selecting one of the available presets in the dropdowns*\n\nhttps://preview.redd.it/116jj07a05ge1.png?width=1583&format=png&auto=webp&s=91b3aaf8488a8c063747005ea4ce9add1471e996\n\n**To enable DLAA or DLSS Ultra Performance mode in games without native support:**\n\n* Ensure DLSS Super Resolution is enabled in the program, and then exit to the desktop\n* Select “DLSS Override - Super Resolution” in NVIDIA app\n* Select the mode you wish to use, click “Apply”\n* Reopen the program\n* *Revert to the DLSS Super Resolution setting specified in the program by selecting “Use the 3D application setting”*\n\nhttps://preview.redd.it/4u8yf1wc05ge1.png?width=1596&format=png&auto=webp&s=c81e532af8045395ffbec06d315b401a06afa7ab\n\n# NVIDIA Broadcast Update Adds New AI Effects\n\nIn the Discover section of the NVIDIA app Home tab, or from [NVIDIA.com](https://www.nvidia.com/en-us/geforce/broadcasting/broadcast-app/), you can now download a new NVIDIA Broadcast update adding two new AI-powered beta effects.\n\nThe first, Studio Voice, enhances a user’s microphone sound quality. The other, Virtual Key Light, relights the subject to deliver even lighting, as if a physical key light was defining the form and dimension of the individual.\n\nBecause they harness demanding AI models, these new beta features are recommended for video conferencing or non-gaming livestreams using a GeForce RTX 5080 or 4080 GPU, or higher. NVIDIA is working to expand these features to more GeForce RTX GPUs in future updates.\n\nThe NVIDIA Broadcast upgrade also includes an updated user interface that allows users to apply more effects simultaneously, as well as improvements to the background noise removal, virtual background and eye contact effects.\n\n# RTX Video Super Resolution Now Supports HDR & Is More Efficient\n\nAccessed via System > Video in NVIDIA app, RTX Video uses AI to enhance streaming video on all GeForce RTX GPUs. It has 2 features: Video Super Resolution (VSR), which removes compression artifacts, and sharpens edges when upscaling. And Video HDR, which tone maps SDR videos to HDR.\n\nIn the new NVIDIA app update, VSR has been updated to a more efficient AI model, using up to 30% fewer GPU resources at its highest quality setting, allowing more GeForce RTX GPUs to enable it.\n\nVSR now also upscales HDR video, so if you are watching any HDR video below your monitor’s resolution in your browser, it will automatically get upscaled to your native panel resolution.\n\nWe’ve also added a GPU Utilization feature for RTX Video when Quality is set to “Auto”. Setting your GPU Utilization to “High” will use as much GPU as needed to provide the best quality Super Resolution available on your GPU.\n\nSetting the GPU Utilization to lower levels will reserve more GPU for games or creative apps by applying lower quality settings. Or alternatively, switch to Manual mode and set a fixed quality level to use at all times.\n\n# Advanced Optimus & Multiple Display Options\n\nThe NVIDIA app development team has converted, accelerated, and modernized two additional features from the NVIDIA Control Panel in this new release, with more on the way in the future.\n\nAdvanced Optimus enables a laptop to dynamically switch between using the GeForce GPU and integrated graphics. When performing basic tasks like word processing, the integrated processor is used. When GPU-accelerated apps or games are launched, Advanced Optimus switches to the GeForce GPU to maximize performance, to take advantage of high refresh rate displays, and to enable G-SYNC.\n\nNow, you can control Advanced Optimus in NVIDIA app from System > Displays. Open “Display Mode”, adjust as needed, then press Apply. With “NVIDIA GPU” selected, G-SYNC options and additional Display Settings appear, ready to be configured\n\nhttps://preview.redd.it/ky5qosi025ge1.png?width=2756&format=png&auto=webp&s=886ec3b0e7b9453a5720b23e7214c89963436ba6\n\nYou can determine if your laptop supports Advanced Optimus by going to System > My Rig, clicking “View Rig Details”, and scrolling down the list of items until you reach “Advanced Optimus”.\n\nhttps://preview.redd.it/mje5ct1b25ge1.png?width=2904&format=png&auto=webp&s=485da6455dd5612ca33b421541587690d135d25b\n\nNVIDIA Control Panel’s “Set up multiple displays” enables you to move the virtual position of connected monitors and TVs, select the primary display, and clone displays across multiple devices. \n\nThese features can now be accessed from System > Displays in NVIDIA app:\n\nhttps://preview.redd.it/ut70k3sc25ge1.png?width=2008&format=png&auto=webp&s=5d1447aa806f50e9f4584f3cce1327d82c105175\n\n# NVIDIA Smooth Motion Now Available\n\nNVIDIA Smooth Motion is a new driver-based AI model that delivers smoother gameplay by inferring an additional frame between two rendered frames. For games without DLSS Frame Generation, NVIDIA Smooth Motion is a new option for enhancing your experience on GeForce RTX 50 Series GPUs.\n\nTo enable NVIDIA Smooth Motion, select a compatible DirectX 11 or DirectX 12 game in Graphics > Program settings. Scroll down the list of options on the right to reach “Driver Settings”, and switch Smooth Motion on.\n\nhttps://preview.redd.it/gztnvcvg25ge1.png?width=1828&format=png&auto=webp&s=f40ccdd2f981c58712ca5d421b12e67f4d9a64a1\n\nNVIDIA Smooth Motion can be applied to games running at native resolution, with super resolution technologies, or with other scaling techniques, typically doubling the perceived frame rate.\n\n# Feedback\n\n*To send NVIDIA feedback about any feature of the new app, please click the exclamation point to the right of the NVIDIA Overlay button*\n\nhttps://preview.redd.it/0e687ovj25ge1.png?width=345&format=png&auto=webp&s=5e6f79cf96a34bf5a7917f7a4c95c80ba4ca4432",
    "comments": [
      "This feels bigger update than 50 series release itself.\n\nEdit: I tried the new driver in Cyberpunk quickly - seams performance improved\n\non 4070S 1440p DLSS Q / RT Ultra / FG - 105-120fps which I find myself surprised to see. Haven't tested more, but feels great",
      "There should be a way to set these options globally, i don't particularly want to investigate the DLSS version for every game i buy and then have to manually go into the Nvidia App and enable the override for each one.  \nJust give me an option to use DLSS4 for every game if possible, then i can set it and forget it.",
      "mine just says unsupported for everything?",
      "What 50 series? You mean all 200 cards they released in the United States 💀",
      "I like how they updated the transformer model just before launch. From J to K.\n\nTransformers scale and improve much faster. Expect more frequent updates and improvements.\n\nAlso, a checky update to enable ai frame gen on any games like afmf",
      "Real dick move to not include support for RTX 40 users to this new Motion smoothing tech. Don't tell me you are using Flip metering for this software solution.\n\nEDIT: According to a colleague of mine, he said they mentioned about this in the keynote very briefly and even said it's coming to 40 and 50 series so he's a bit surprised too.",
      "Ngl this is confusing as shit",
      "literally every online retailer was fucked today. \n\n* nvidia store - secure connection failed\n* best buy - you're in que! (x4) also what is your password? it doesn't match our records. verify your account! also we wont send you a verification link\n* b&h - *crickets*\n* msi - No connection could be made because the target machine actively refused it.\n* amazon - *crickets*\n\npaperless paper launch",
      "they need something to sell this new worthless generation",
      "Exactly this, I thought it would be a global override, I don't want to hunt down the setting for each game individually",
      "No driver Smooth Motion for 4090 but 5060 ok.\n\nBecause...reasons\n\nThanks Nvidia.",
      "i still can't believe that DLSS swapper does a better job than nvidia's own app",
      "The fact that we can't enable the Transformer model for all games like we did with the Nvidia Inspector trick is such a missed opportunity, I just don't get what Nvidia are thinking.",
      "Smooth Motion 50xx exclusive? Come on NVidia lol, AMD has it on even mobile iGPUs.",
      "not giving everybody at least motion smoothing is wild",
      "it's still easier to use DLSS swapper and nvidia profile inspector\n\nsad",
      "Checked my list of games where I can change DLSS override:\n\n1.  Sons of The Forest\n2. Witcher 3\n3. RDR 2\n4. No Man's sky\n5. Starfield",
      "Because it is 5000 series only.",
      "I checked myself. It fixes the weird shimmering/fuzziness in Screen space reflections and some ghosting in the edges of tree leaves. This is on 1440p DLSS Performance.",
      "Fixed it. Uninstall the nvidia app and re-install."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "4080",
      "4080 super"
    ],
    "title": "Upgraded from a 1070 to a 4080 SUPER",
    "selftext": "Wow! What a breath of fresh air. I knew my gpu was very lacking, and as a college student, gpu is an expensive upgrade. Very pleased with the Tuf OC that I got. No coil whine on this guy and the card runs so much cooler than my old asus dual 1070! Almost didn’t fit the case, luckily I measured before buying. Running a Ryzen 7 5800x, tuf x570, 32GB 3600, seasonic focus 1000W. All in a fractal north case!\n\nI was thinking about adding an exhaust fan here soon but honestly the thermals are fantastic right now as is. Card at full load hits 68 Celsius. ",
    "comments": [
      "&#x200B;\n\nhttps://preview.redd.it/x5hla395i5ud1.jpeg?width=735&format=pjpg&auto=webp&s=d50fa78093f7299859d190ea2adeab07baf3cf1e",
      "Nice upgrade!, avoid any comment that say \"why dont wait until 5000 series, why do u buy it when is near, blah blah...\" enjoy ur new gpu, It may be a hasty purchase, but if you want to enjoy current games and you still don't know if you'll be able to buy the next generation, it's foolish to speculate and wait for something that hasn't come out yet.",
      "Man I used to have that exact 1070, it was my first dedicated gpu, man that shit ran so hot LMAO, that 4080S is legit gonna run like a dream and super cool and quiet I’m happy for you",
      "Well I was looking at the leaks and it looks to be the 5080 vs 4080 will not be that much of a jump, and for the gaming I do. Which is 1440p, this is plenty for me now!",
      "Hot and LOUD. I don’t mind a loud card honestly but the fans on that old card are so whiny and high pitched I could hear it through the headphones I wear. That and the plastic body of that card had a slight rattle. One I heard it I could never unhear it. Even tried to repaste the card a few years ago to see if that would help, it in fact did not.",
      "If you're not aiming for 5090 then 5000-series looks like another disappointment",
      "Just jumped to a 4080 Super myself!! Enjoy those beautiful games 😍\n\nhttps://preview.redd.it/m32ojzk8r5ud1.jpeg?width=3000&format=pjpg&auto=webp&s=3bd209a9ad9ba92670f1675716db56b492fc5bad",
      "Had same thought, my 4080s should be here next week to replace my 970",
      "That’s what I’ve been seeing as well",
      "May your 1% be high and your future upgrade prices be low. Enjoy it!",
      "That and I got this tuf card for $100 off msrp, couldn’t pass it up.",
      "It is insanely big! It makes a 3090 look small...\nAbsolutely icy cool, even pushing to the max I'm at 67-68°. Thank you! Yours too!",
      "That card looks MASSIVE. How are temps? I imagine icy cold! Rig looks beautiful!",
      "Thank you kind stranger, may the same be for you!",
      "That’s going to be one heck of an improvement. I went from 970 to 3080 and I’m astounded.",
      "I agree man. The 1070 was honestly my first card I bought that was specifically for gaming and as I saw new cards come out I had the same conclusion.",
      "Yeah they really overbuilt the cooler on this one, which is a welcome upgrade from the 1070. I found out that the 4090 tuf has the same cooler and heatsink as this 4080 super, should stay nice and cold.",
      "Wow that’s crazy, that’s where mine sits at as well. Gonna add a noctua 120 on that exhaust here in a few days when I go to town I think. Don’t really need it tbh with my thermals. But it will help keep some of that hot air build up out. Are you running 4k games?",
      "10xx series were by far the best value per performance. 8GB of VRAM on a 70 class card which was released almost 9 years ago. The 4070 is 2.5X faster than the 1070, it should have at least twice the amount of VRAM.",
      "Congratulations!)\nI'm looking to buy 4070 Ti Super for myself because 4080S is much more expensive in my country (Ukraine) and considering that I'm planning to upgrade to 2k (not 4k for sure) - the card should be enough for next 4-5 years"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "4080"
    ],
    "title": "Went from 2080 super to 4080",
    "selftext": "I still play 1080p just so I can get 240fps on all the games I play. Don’t get me wrong I will play 4k on my tv at 120 but the buttery smooth nessssss is blissfully better!",
    "comments": [
      "Put the GPU in the correct slot.",
      "While you're correct, it's really sad that OP is getting downvoted for asking what the difference is, thus obfuscating the explanations for inexperienced builders.\n\nCPUs and chipset only have a certain amount of fast PCIe lanes for connecting cards like a GPU. Therefore, motherboard makers need to choose which slot to intend for the GPU, and this is by convention the top slot. In this example, the top slot uses PCIe 5.0 and has 16x electrical lanes (and 16x physical size).\n\nIn comparison, the lower slot OP was using is PCIe 4.0 and only has 4x electrical lanes (despite being also 16x physical size). \nThe lower slot seems to be a 4x PCIe 4.0 slot.\n\nA nice knowledge to keep in mind is that PCIe bandwidth scales linearly with the number of lanes and each lanes bandwidth doubles with every revision. So the 4x PCIe 4.0 lanes of the lower slot is equal 16x PCIe 2.0 lanes.\n\nThe new GPU is a PCIe 4.0 card and has 16 PCIe 4.0 lanes. It will run just fine with fewer lanes or in older PCIe slots, but the limited bandwidth that comes with it can affect performance.\n\nWhat is always surprising to me is how little this matters in practice:  \n\nhttps://www.techpowerup.com/review/nvidia-geforce-rtx-4090-pci-express-scaling/28.html  \n\nSo even on a 4090, the mistake OP made only costs 6-8% in performance.\n\nYou can calculate PCIe bandwidth here: https://3roam.com/pcie-bandwidth-calculator/",
      "Put the GPU in the top PCI-E slot, and reverse the bottom fan so it takes in fresh air from the bottom.",
      "Higher bandwidth and better performance on the slot meant for GPUs (top one)",
      "Top slot will have better performance. Easy and quick fix.",
      "How long have you been gaming using a bottom slot GPU?",
      "https://preview.redd.it/1huwsm7zmfgc1.png?width=3024&format=png&auto=webp&s=c653cd26a1e351bf8cc6a0c2203213baf5c9ee38\n\n?",
      "😅 really? What’s the difference",
      "Why the bottom fan pointed into the desk? And gpu is in incorrect slot.",
      "bro won the super bowl",
      "Yeah there’s some douche baggage pulling this boat down",
      "Hol ee fuck that ring",
      "It's the top most slot, where you already have a slot bracket missing. You didn't share a pic",
      "Poor op. You did great for your first build and learned a lot too!  Good job",
      "lol, holy fuck no. Heat rising does not overcome fans.  You're correct here it should be on top but that's because of the obstruction. How fast do you think heat rises, this is hilarious",
      "Did I mention this was my first build ever. I surprised it turned on the first try 😂 glad I posted here to fix my mistakes",
      "I’m fed up of people having to be so hostile to mistakes rather than just helping in a nice manor like what happened to kindness?",
      "ye",
      "Heat rises. That heat will just get recycled back into the case.",
      "And your fan is pulling air away from the card as exhaust at the bottom.. cmon bruh"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "rtx 4080",
      "4080",
      "4080 super",
      "rtx 4080 super"
    ],
    "title": "NVIDIA GeForce RTX 4090D with 48GB and RTX 4080 SUPER 32GB now offered in China for cloud computing ",
    "selftext": "https://videocardz.com/newz/nvidia-geforce-rtx-4090d-with-48gb-and-rtx-4080-super-32gb-now-offered-in-china-for-cloud-computing",
    "comments": [
      "I hope a YouTuber gets their hands on one to check out",
      "Linus is already frothing at the mouth to run Crysis",
      "GamersNexus will break it down and give us the cool nitty gritty. LTT will do something stupid with it. I’m looking forward to both videos",
      "I could really use one",
      "most likely AI",
      "I wonder how much they are. If they were close to the price of a normal 4090 many people would love them for local AI stuff. But I'm assuming they're quite expensive since they're mostly supposed to be a way to get around the sanctions that prevent selling the actual server GPUs.",
      "Wow that’s pretty cool, is it any good for gaming or more of a niche product?",
      "Nah, leave it to GamersNexus",
      "According to Tomshardware:\n\nThe GeForce RTX 4090D 48GB reportedly sells for around $2,500, $685 more expensive than the vanilla GeForce RTX 4090D, which has a 12,999 yuan ($1,815) MSRP.",
      "Or 4 4k games to max out brainrot.",
      "It does nothing for gaming and the 4090d is a watered down version of the 4090 in gaming specifically the 4090d does not perform as well. Thwy are not allowed to fully spec the 4090 in china so they turned down the power and other areas and named it the 4090d so they could sell it. They are just now I guess doing a version with 48gb.",
      "That's not bad, about the same as getting a 4090 and a 3090 or something I guess. Still expensive for a home user - but so is the 4090 in general.",
      "You make it sound as if the card sucks balls. \n\n>the 4090D offers only 14,592 CUDA cores and 425W TDP, compared to 16,384 CUDA cores and 450W TDP of the RTX 4090\n\nIt still has about 90% the performance, and now with twice the memory. Sounds like an AI beast to me. I wonder if it still supports nvlink",
      "Is this just another AI card to get around sanctions?",
      "Aw man. Me and the boys over on r/LocalLlama be having dreams about such a card! Come on Nvidia/AMD/Intel, launch a crazy inferencing GPU with enough VRAM for the apocalypse for us the unwashed masses.",
      "To play 16K games?",
      "Ironically most applications would take 48gb 4090d for ai over a 4090… so this just subverted the 4090 ban 1000000% and gave China better ai cards (at the consumer level) than the US.",
      "No game currently uses that much vram, so no",
      "By the time 48GB (heck, even 32...) is required by games or that it's worth it, these current GPU's themselves will be extremely slow in comparison making them pretty worthless for gaming. That's why VRAM isn't a huge deal after a certain point these days (for most games, anyway). If you're buying more VRAM because games in 3-5 years might use it, you're probably buying too much (if you need the extra GPU power, by all means go for it). Because when you REALLY need that extra VRAM, might as well buy the latest and greatest in the 3-5 years when you DO need it. That VRAM will come with a huge GPU boost as well.",
      "Cuberpunk doesnt even max out my 4090 with a bunch of 4k texture mods, crowd density, increased ai events and other visuql mods. All this with path tracing enabled. I can’t imagine 48gb being worth gaming for many years to come.\n\nEdit referring to Vram"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "4080",
      "4080 super"
    ],
    "title": "Went to get a 4080 Super, but walked out with a 5080 pre-built",
    "selftext": "Went into Microcenter Thursday afternoon to upgrade from a 3060 to a 4080 Super pre-built, but apparently Microcenter messed up and didn't advertise their 4 5080 pre-builts on their website. So, they were like \"We got a 5080 for just $200 more.\" Yes please, I'll take that! Can't believe I got that lucky! Their cards sold out in the first 30 minutes after opening.\n\nEdit: Here's the other specs for anyone wondering\nAMD Ryzen 7 7800X3D (4.2GHz) Processor\nMSI Pro X870-P WiFi Motherboard\n32GB DDR5-6000 RAM\nNVIDIA GeForce RTX 5080 Graphics Card\n2TB NVMe SSD\n\nEdit 2: For those wanting more context: The 4080 S pre-built I was planning to get was $2500 and the other parts were different. For $200 more, I got the 5080, a better CPU, better RAM, and a better SSD",
    "comments": [
      "$2700 isn't terrible. Sure, it's cheaper if you can build it yourself if:\n\nA) You can find a 5080 for MSRP.\n\nB) *Want* to build it yourself.\n\nI think a lot of people forget that gaming and building PCs are not the same hobby. Some people have no desire/time to build a PC. There's a reason why pre-builds have a market. Hell, that's a big reason why consoles are still around.",
      "wow...super nice....enjoy",
      "uhhh they paid $2700 for an entire computer containing a 5080. While it could be done a little cheaper and it should probably have a 9800x3d, it's not a *terrible* deal on a prebuilt.\n\nYou'll always lose to a DIY build of course, so idk why ppl always jump to make this comparison",
      "Exactly this! Putting my specs into PCPartPicker, I paid maybe $350 max more than what I should, but for not having to pick out my parts and learn how to build it myself, I'd say that's worth it",
      "That mobo and cpu are around $700 together, with everything else I don’t see it being $2k to build it. I’m all for building over buying built, but I feel like the estimation is a little off on your end.",
      "People and their elitist egos about building their own PC, tsk tsk tsk",
      "I’m waiting for Best Buy 5080 drops but if I can’t get one after a few days I think I might just walk in and ask. Who knows?",
      "You don't get it. You have to save some money by spending hours and hours determining the exact sku of every part you want, then hunt down the parts and snap them together yourself. Otherwise, you're not a real PC enthusiast.",
      "I like that people aren't considering the other parts in the 5080 pre built compared to the 4080 Super pre built. The graphics card isn't the only thing that's different for the $200 increase",
      "Somebody that is not into building pc’s will not finish it in two hours",
      "this comment right here is why so many people prefer a prebuilt. \n\njust like the guy enjoy his pc ffs",
      "[Please don’t tell me you paid $2,700 for a 5080.](https://www.microcenter.com/product/689586/powerspec-g722-gaming-pc)\n\nBecause that’s the exact same specs as you posted on Microcenter’s website",
      "So happy for you. Great. Awesome.",
      "Its odd why prebuilts are looked down upon. Its the only way I got a 3080 and its the only way I am getting a 5090.",
      "Not at micro center.  Their prebuilts are just off the shelf parts.  Same stuff you'd buy.  \n\nAnd usually, they are about $150 cheaper than building the exact spec/parts machine yourself.  \n\nMC offers a great value in their Powerspec computers.",
      "You lucked out man, enjoy. It’s a very capable PC.",
      "Imagine having this much energy for people not wanting to mow their own lawn or change the oil in their car.",
      "The 5080 is a good overclocker and can actually perform close to a 4090 minus the vram. Go be salty somewhere else.",
      "Probably could have got a little more savings by waiting and shopping around but that’s a pita too. Sometimes you just want to be done and game already so I feel like $350 isn’t horrible for that.",
      "I am into building my PC's and it's still probably take me more like 2-4 hours from scratch"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "4080"
    ],
    "title": "NVIDIA reportedly stops mass production of RTX 4070Ti/4080 GPUs, now focusing on SUPER variants",
    "selftext": "",
    "comments": [
      "So does the 4070ti get cheaper now because it has a successor ~~predecessor~~ or does it get more expensive because ther are fewer available? \n\nAsking as someone who still couldnt justify a 4070ti for himself",
      "Nah they'll keep them at same prices and sell them extremely slowly to people who don't know better.\n\nJust look at older gpus and cpus that many retailers still have around.\n\nOr older motherboards... :/",
      "Honestly these mid of life refreshes like 2000 supers are in my opinion such a scam. You have to know that in ~1 year or less they'll drop the 5000 series. People with 3000 series, please don't give your money to this super refreshes, save it for 5000 gen. It will be much worth it. Just my 0.2 cents.",
      "I'm not sure where this idea Nvidia needs to drop prices comes from. The PC enthusiast market has proven time and time again they'll spend absurd amounts on the latest and greatest. There's nothing to suggest a better business plan comes from slashing prices on highly demanded products.",
      "What about RTX 4070? Isn't the 4070 Super also supposed to be released soon?\n\nI hope this doesn't mean the 4070 Super will be so expensive that they'll keep producing the 599€/$ GPU because none of the new cards will be competing at that price....",
      "Exactly what happened when the 2070 super launched. Old 2070 cards remained at the same launch price on the shelf. There were a number of cases I recall where due to promos the super was actually cheaper. I had a number of friends reach out to ask why that was, assuming there was something better about the older card or that the refresh was in someway inferior based on the pricing alone.",
      "Enjoy your card man, there’s always something new around the corner",
      "I just bought a 4070ti",
      "I mean the new 3080 are still expensive as fuck even tho the 4070/4080came out like a year ago so dont get your hopes up",
      "I'm old enough to remember this being what PC enthusiasts mocked Apple enthusiasts about. I remember friends buying absurdly overpriced Apple monitors, laptops, desktops and I'd just keep building PC's with my friends for dirt cheap. Kinda wild seeing PC enthusiasts sound exactly like the Apple fans did back then. \"I expect (insert wildly unnecessary attribute) and I pay for that feature\" as if its a brag or something to tout.",
      "I’m holding out. The 3070ti only having 8gb of vram pisses me off and I didn’t have much choice during lockdowns. I also overpaid for it too. I’ll be going for 5080 or 5090 next year depending on reviews.",
      "Same.\n\n![gif](giphy|26ufcVAp3AiJJsrIs)",
      "I mean, a year is a long time. You know how much gaming you can squeeze out in that time?",
      "That won't happen, the older models stay expensive or out of stock.",
      "I don't agree because the enthusiasts and top level cards are not the point here. The most common card in the steam hardware survey is the 3060. Your average pc gamer isn't buying the mid tier 4070 because it's priced for enthusiasts. The 4XXX cards are too expensive across the board, not just the high end. The high end sure they can keep charging and the enthusiasts will pay but they are a small demographic. The vast majority never moved off the 3XXX series cards and in fact many gamers are still on the 1XXX series.\n\nNvidia don't want to destroy the PC gaming market and they will if PC gaming continues to be so drastically more expensive than consoles. Enthusiasts alone can't keep the PC graphics card market alive.",
      "I’m on 3080 10gb and playing Phantom Liberty pissed me off. Vram gets full, then stutters.",
      "And here I really thought the normal variants would get a bit cheaper. Silly me.",
      "It's a trap.\n\nNext gen they are probably going to hardware lock you out of a feature.",
      "Still holding out until the 50 series launches. By then, there will be enough games available to justify an upgrade for people still on Turing and below.",
      "Watch them just slide the price scale even further. 5090 starting at $2000."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "rtx 4080",
      "4080",
      "4080 super",
      "rtx 4080 super"
    ],
    "title": "NVIDIA GeForce RTX 4080 SUPER to feature 23 Gbps GDDR6X memory, full RTX 40 SUPER specs leaked",
    "selftext": "",
    "comments": [
      "seems like every day we get specs leaked on the same product, how many more leaks for the refresh before it launches early next year?",
      "> how many more leaks   \n\nthe ~~leaks~~ advertisements will continue until demand peaks",
      "Something tells me the cards will be introduced at the prices of their non-SUPER counterparts and the latter will simply disappear.\n\nNo free lunch for you.",
      "Don't forget the whopping 1.8% increase in boost clock! This is revolutionary!",
      "Ha! I doubt the 4080 super will retail for $999.",
      "Nvidia has to be intentionally \"leaking\" things to the press at this point.",
      "Personally I hoped for more Vram. Like 20 or 24.",
      "They did that with the 20 series, this seems to be the most logical way of going about it, because at the end of the day super variants are just revisions, just as RX xx50 cards are.",
      "Yeah, it's just marketing these days",
      "No we just need prices. my final guess on prices\n\n4080 super - $999\n\n4070ti super - $799 (would love $750)\n\n4070 super - $599\n\nEdit - if I’m wrong I’ll sell my 3070 and use a gt710 for the rest of the year\n\nEdit 2 - No gt710 😩 upgrading to a 4070ti super 🤑\n\nhttps://preview.redd.it/u726v8ewt8bc1.jpeg?width=2306&format=pjpg&auto=webp&s=b3b28deb93010b714138b78b324412aeaea158d8",
      "The real question is when is 5090 going to be released.",
      "1.8% faster and 20% more expensive! totally worth it!",
      "Seems hopeful.\n\nEdit: rip this guys gaming potential with that gt710.",
      "Would have to be 32 bc bus width determines memory size.",
      "Not HW, but semi related:\n\nCapcom (resident evil, monster hunter, etc) admitted to doing fake leaks a bit ago for a RE game. \n\nThey were basically just like, \"🤷‍♂️\" lol\n\nIt's just good business these days. If you drip feed small information a bit at a time it's an okay way of drumming up interest. If you \"leak\" it, it becomes \"sexy\" because of the forbidden fruit type thing, so people click even more even tho it's the exact same thing, you just outsource the PR to the community and content mills vs journalists.",
      "4080 Super looking like a complete joke unless it’s 1000. Such minimal uplift over the 4080",
      "cut down 4090 instead of building on the 4080.",
      "SHUT UP AND TAKE MY MONEY!!!!",
      "$700 for the 3080 and now we're *hoping* for $1000 just a generation later. Madness.",
      "For a split second I was thinking they were \"advertising\" 23GB of VRAM."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "rtx 4080",
      "4080",
      "4080 super",
      "rtx 4080 super"
    ],
    "title": "MSI RTX 40 SUPER leak confirms RTX 4080 SUPER and RTX 4070 Ti SUPER with 16GB memory",
    "selftext": "",
    "comments": [
      "If the prices are true then it is not worth like 4070ti super for 1,1k that's crazy expensive",
      "4070 TI SUPER is a dumb name i'm sorry",
      "that 4070 ti super looking spicy",
      "In the pic the 4070 ti super (lol name) costs 1300+ euros.\n\nExtremely DOA.",
      "Calling the 4080 Super **great value** is sort of ridiculous especially considering its regular counterpart is objectively *poor value* and these listed prices are mere leaks at this stage",
      "Am I the only one that thinks it’s weird there’s gonna be 4070 ti super tf is a ti super 😂",
      "Prices are popping up at more retailers, like [this one](https://www.meistersinger.at/shop_search.php?search_string=GEFORCE+RTX+4070&cat=0&verfug=0&man=&list=0&sort=price&order=desc) and [this one](https://www.meistersinger.at/shop_search.php?search_string=GEFORCE+RTX+4080&cat=&x=0&y=0&man=).\n\n* 4070 Super 20% more expensive than 4070\n* 4070 Ti Super 8-10% more expensive than 4070 Ti \n* 4080 Super replacing 4080 at the same price\n\nUS MSRP could be $699 for the 4070 Super and $849 for 4070 Ti Super.",
      "4070 Super Saiyan God Super Saiyan",
      "That naming scheme has big iphone Pro Max energy though",
      "The only problem is social media comments represent like 5% of the market.  Average Joe Gamer is buying whatever is on the shelf to replace his prebuild GPU.",
      "Leaked prices:\n\n* RTX 4080 SUPER: 1230.30 - 1355.80 CHF  \n* RTX 4070 Ti SUPER: 1,060.40 - 1063.4 CHF  \n* RTX 4070 SUPER: 777.50 - 848.70 CHF  \n\nCurrent GPU prices in Switzerland:\n\n* [MSI 4080: 1'308 - 1'815 CHF](https://www.galaxus.ch/en/s1/producttype/graphics-card-106?filter=t_bra%3D331%2Ct_347%3D1060010&so=5)\n* [MSI 4070 Ti: 769 - 901 CHF](https://www.digitec.ch/en/s1/producttype/graphics-card-106?filter=t_bra%3D331%2Ct_347%3D1228753&so=5)\n* [MSI 4070: 527 - 739 CHF](https://www.galaxus.ch/en/s1/producttype/graphics-card-106?filter=t_bra%3D331%2Ct_347%3D1246865&so=5)\n\n\nIf these prices are correct:\n\n* 4080 SUPER will be **great value** *(more cores for lower price)*\n* 4070 Ti SUPER will be **slightly better value** than 4080 *(fewer cores but lower price)*\n* 4070 SUPER will be **worse value** than existing 4070 Ti *(fewer cores for same price)*",
      "> 4070 would drop to $499\n\nUnlikely to happen with 4070 still selling very well, and 4060Ti 16GB already occupy $499 slot, so the whole lineup would have to be pushed down too.\n\n> 4070 Ti Super at $799\n\nThis may happen as 4070 Ti already ceased production.\n\n> 4080 Super at $999 or $1099\n\nThis can happen if they feel threatened by the 7900 XTX (which is gaining market share much faster than the 4080, due to aggressive discounts).",
      "Wtf are you on in wanting to upgrade already from a 40 series to another 40 series?  Same applies to rest of the 40 series owners complaining they can't upgrade because of prices.  If you can afford to upgrade (twice) every generation, you should've bought the highest or even the second highest tier card at launch.",
      "4080 SUPER SUPER lmao",
      "It is to us as gamers to vote with our wallet and not by comments (they don't care about them)\n\nI will move to amd for gaming they are fine",
      "I'm still holding off until next gen. This refresh could be nice but what's the point in buying now if in Q4 we get cards that outperform all of them at lower power draw\n\nEdit: to clarify if you have like 30 or 20 series then I'd say it's worth waiting (that's the position I'm in) if you are on older than that and have been waiting years then of course go for it. Me personally I'm running a SFF case so the more power in less space I can get the better hence why I noted lower power draw",
      "I imagine there’s seriously no reason to go from a 4080 to a 4080 Super.",
      "The average mid range GPU is $1000 or more now, what the hell happened man, I just want affordable cards again that arent my entire months paycheck.",
      "yea i find it weird but its just a name after all",
      "You know I love my 1080 but I just ordered a new gpu from team red because Nvidia pricing has gone out of control.\n\nYeah I know, it's stupid to buy a new gpu so close to the supers being released but I just stopped caring about that. Most likely the prices here will be even more ridiculous."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "rtx 4080",
      "4080",
      "4080 super",
      "rtx 4080 super"
    ],
    "title": "NVIDIA GeForce RTX 4080 SUPER rumored to feature 20GB memory - VideoCardz.com",
    "selftext": "",
    "comments": [
      "In case you can't read the article, TL;DR:\n\n**RTX 4080 SUPER**\n\n- Cut down AD102 die, even more cut down than RTX 4090\n- 20GB which means 320 bit memory bus width\n- Presumably GDDR6X\n\n**RTX 4070 SUPER**\n\n- Cut down AD103 die\n- 16GB which means 256 bit memory bus width\n- Also presumably GDDR6X\n\nNo current release timeline for either. But probably Q1 2024 if I had to guess.\n\nSourced from Benchlife via @harukaze5719, report by Videocardz.com.",
      "I mean the cards have always been appealing,  it's just that all of the prices are atrocious. \n\nNew super cards are nice too, but it won't matter much because they're still too expensive in the end.",
      "And just to add context, when Nvidia did this the last time:\n\n* 2080 Super released 10 months after 2080\n* 2070 Super released 9 months after 2070\n* 2060 Super released 6 months after 2060\n\nSo strictly from a timeline perspective, Q1 of 2024 would be appropriate. That would mean 14 to 16 months for the 4080, 9 to 12 months for the 4070, and 5 to 7 months for the 4060.",
      "+$300 for +10 FPS",
      "4070S sounds interesting, might get that TBH. Id like to use DLSS and do at least *some* ray tracing which my current card cant do without dipping into the 20s for FPS",
      "Also CES is in January and that would be a suitable event for an announcement.",
      "Actually not early, one year almost.",
      "Yep the prices suck still",
      "We don't know the name. \n\nTi or SUPER are just marketing names. All they really represent is that Ti and SUPER are more powerful than the regular baseline card. i.e 2080 Ti is more powerful than the 2080, same goes for 2080 SUPER.\n\n> They still released the ti with the 2000 series and the super also existed.\n\nLook anything is possible because NVIDIA release too many SKUs, I mean you need look no further than last generation with the 3060 8GB, 3060 12GB, 3060 Ti 8GB, 3060 Ti 8GB GDDR6X etc.\n\nThey could release this AD102 chip in the article as the 4080 SUPER or as the 4080 Ti or they could be brazen enough to call it the 4080 20GB. Who knows? People are just calling it the 4080 SUPER because it makes sense or that's what their sources refer to it as. I assume they probably are not going to release an FE card model though.",
      "Yes, and then if the leaks are accurate but are not what you want, get the 4070 again at reduced price because of the supers.",
      "This is huge, feel bad for the early customers though, missing out on the 4gb VRAM hurts the longevity of the card so much.",
      "Nvidia has slides indicating a slowdown in consumer gpu's, also a slide indicating 2025 for next consumer GPU release. And they are speeding up their datacenter AI gpus \n\nhttps://www.pcworld.com/article/1974281/nvidia-sets-2025-date-for-rtx-50-series-cards.html",
      "Releasing new architectures on a longer schedule, so neither of the options you gave",
      "> Meanwhile new series is only 3 quarters out so people will feel FOMO again and Nvidia again can stack margins.\n\nNot exactly, rumors are that 50 series is being pushed to 2025, around either Q2 2025 or Q3 2025. Reason being is that NVIDIA probably doesn't feel threatened by AMD's RDNA4 since it's going to be like RDNA1 where they target the mid-range, not high end performance, after AMD's top RDNA4 MCM project supposedly has been abandoned.\n\nNVIDIA is likely going to use whatever TSMC capacity they have for datacenter and AI chips first anyways seeing as thats making them big money right now.",
      "If the 4070 super is the same price as the 4070, I wouldn't say it's a bad price.",
      "Personally I have literally zero concerns about 16 GB not being enough on my 4080 before I upgrade it to a 5080 or whatever",
      "They’re probably talking more about the 4070/4070ti having only 12gb of vram.\n\nThe reg 4080 will be fine for a while with 16gb of vram.",
      "Man the 4070 super having more vram than the 4070 ti and probablyonlylosesto it by like 5 fps will  be a f you to the 4079 ti users.",
      "Does this mean there is no 4080ti this generation? Or maybe the 4080S is just the ti with another name? They still released the ti with the 2000 series and the super also existed.",
      "My guess was holidays Q4 2023, cuz people after holidays would already spent their money.\n\nBut then I realized releasing after Holidays is genius business strategy, cuz then Nvidia gett to sell their old stock first. Then they can sell new stuff at again margins and people who had FOMO and waited out the upgrade will now upgrade.\n\nMeanwhile new series is only 3 quarters out so people will feel FOMO again and Nvidia again can stack margins.\n\nI will probably go 4090 > 4080 / 4070 Super Q1 > 5080."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "rtx 4080",
      "4080",
      "4080 super",
      "rtx 4080 super"
    ],
    "title": "GeForce RTX 5070 Ti leak: 7.6% faster than 4070 Ti SUPER in Blender, on par with RTX 4080 SUPER in OpenCL test",
    "selftext": "",
    "comments": [
      "Compared to a 4070 Ti Super.....\n\nAbout 6% more cores.  Uses about 6% more power.  Delivers about 7.6% more performance.\n\nYawn fest.  Nvidia still gonna charge $750-800 bucks for this nonsense.",
      "This is definitely the 4070 SUPER TiTi",
      "7,6% Performance boost for only a 35% price increase. What a steal ! \n/s",
      "But but nvidia said: 5070~~ti~~ = 4090 🤓",
      "not everyone has a 40 series gpu lmao",
      "Soo... It is a 4070 Ti Super Ultra!",
      "Basically they’re re-releasing the 4000 series, except the flagship is better.",
      "Turns out I had no idea how lucky I was when I got my 4070TI Super for 750$.",
      "i mean at this point everyone can agree this is the worst generation. i was not gonna upgrade this gen anyway but this reduces my expectation for the next generation as well cuz even if they do 20% boost on 6th gen RTX it will still be relative to this subpar generation.",
      "nVidia really have the consumer GPU market by the balls. Two extremely lackluster generations and I'm still having to consider a new card because 10gb VRAM is not enough for my needs anymore. \n\nOn top of that, more money gets me a tier below what it did last time. \n\nAnd on top of *that*, the tiers have essentially been shifted down by applying higher tier names to lower tier specs.",
      "I remember when a generational uplift was 20-30% faster not <10%",
      "If this is indeed 1.2x vs 4070 Ti Non Super, then here's how 5070 Ti performance will shake out (based on TechPowerUp 4K Average FPS):\n\nAgainst 40 Series\n\n* 5070 Ti = 1.1x vs RTX 4070 Ti Super (probably not worth upgrading)\n* 5070 Ti = 1.2x vs RTX 4070 Ti (upgrade might be ok if you want MFG)\n* 5070 Ti = 1.3x vs RTX 4070 Super\n* 5070 Ti = 1.5x vs RTX 4070\n\nAgainst 30 Series\n\n* 5070 Ti = 1.42x vs RTX 3080\n* 5070 Ti = 1.8x vs RTX 3070 Ti\n* 5070 Ti = 1.9x vs RTX 3070\n\nAgainst 20 Series\n\n* 5070 Ti = 1.86x vs RTX 2080 Ti\n* 5070 Ti \\~= 2.21x vs RTX 2080",
      "Is this the weakest generational uplift ever?",
      "~7% slower than a 4080s for $750… I guess that’s something, but then again the 4080s even with the price cut was too expensive anyways soooo",
      "There are not really any meaningful upgrades that have a decent value proposition for the > 3080 gang.",
      "Oh you will pay over $1000 for a 5070Ti. There's no FE which means no guaranteed MSRP and the AIB's will be well over that.",
      "wow great overclock series nvidia",
      "Don’t kid yourself into thinking that was a good price for that range of GPU. Market is fucked and we should not let this normalize",
      "Not impressive, as expected. Entire 5000 series lineup is just a refresh.",
      "I can’t wait for Nvidia to reveal the 6000 series and be like it’s 400% faster than the 5090"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "rtx 4080",
      "4080",
      "4080 super",
      "rtx 4080 super"
    ],
    "title": "NVIDIA RTX 4080 SUPER tested: up to 2.4% faster in 3DMark, similar gaming performance to RTX 4080 [VideoCardz.com]",
    "selftext": "",
    "comments": [
      "Because announcing a new card with a lower price is better PR than cutting the price of an existing card.",
      "Yep. They way they would be able to not admit that the OG 4080 was always priced way too high.",
      "With what drivers exactly? On some of the benchmarks is worse than the normal 4080 which is highly unlikely.",
      "The only super thing is the MSRP. Albeit, Expect AIBs to reach original 4080 price.",
      "Because price cuts are an embarrassing admission that the 4080 was priced too high and didn't sell well. But an all new 4080 super is an amazing new value!!!!!!",
      "The price is only good if you compare it in isolation to only the 4080. It is still profoundly insane, even after the cut.",
      "Ain’t nothing SUPER about it",
      "It still is....",
      "Margin of error, inconsistent benchmark etc. It's not actually strong enough to pull a noticeable lead over 4080 in any case.",
      "For someone like me who's building a brand new build I can't wait for the 4080S. I can see how people upgrading their systems are not impressed though",
      "It’s overpriced and I spent 1200$ on mine lmao.\n\nThis is an inflated priced and everybody knows it but you. Just cause we can afford it and buy it doesn’t mean it’s not overpriced",
      "Slightly overclocked 4080s for $200 off MSRP.",
      "Marketing. Nvidia doesn't want to admit they were wrong with the 4080. I don't even care for this $999 price considering the 3080 was $699. I would have liked to see this closer to $799-$849 myself.\n\nBut that wasn't going to happen given current market/RDNA3 pricing.",
      "It should have been $800 at max",
      "I agree. After all the cost/FPS champ is the 4070 Super. Nothing else scales quite as well. The 4070Ti Super should honestly be cheaper as well. Cost tiers should be $600/$700/$800 but this is NVIDIA.",
      "What 320b bus? This is just a 4080 with 5% more CUDA cores enabled, 10240 instead of 9728. \n\nThe 4080 SUPER is a “price drop” that doesn’t hurt Jensen’s ego as badly.",
      "Basically, a price cut for the 4080 would be saying \"yeah... we really messed up guys, sorry\" but a 4080 Super is like \"yo guys check this out, because we're so generous we're gonna give you this AMAZING deal compared to our last one\".",
      "You can believe whatever you like. I think it's pretty common knowledge throughout the tech press and hardware retail industry that the 4080 sold very poorly.  \n\nAnd Nvidia DID cut the price (or well, it will as of this time tomorrow). that's what the 4080 Super is.",
      "I think they purposefully priced the 4080 to make people buy a 4090 instead.",
      "Yeah, idk why everyone is upset. I'm doing a new build and a 4080s seems like a fair price for the premium performance."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "rtx 4080",
      "4080"
    ],
    "title": "[Megathread] Celebrate Cyberpunk 2077 Launch with DLSS 3.5 & RTX 4080 Giveaway!",
    "selftext": "&#x200B;\n\nhttps://preview.redd.it/rw79uqv9v7pb1.jpg?width=1820&format=pjpg&auto=webp&s=362c5ad27764853a3843c01845d8073b37e8fc63\n\n# DLSS 3.5 with Ray Reconstruction will be coming to Cyberpunk 2077 with the game’s 2.0 update on September 21st.  \n\n# DLSS 3.5 with Ray Reconstruction will be available September 26th in Cyberpunk 2077: Phantom Liberty, along with full ray tracing.  \n\nIn the Ray Tracing: Overdrive Mode, DLSS 3.5’s new Ray Reconstruction technology enhances the quality and clarity of reflections, global illumination is even more accurate, and lighting is more dynamically responsive, for an even better, more immersive, more realistic experience. \n\n&#x200B;\n\n|**Topic**|**Articles / Videos**|\n|:-|:-|\n|Exclusive Cyberpunk 2077: Phantom Liberty RTX Technology Video|[Video Link](https://www.youtube.com/watch?v=DbuKZgZpDP8)|\n|Cyberpunk 2077: Phantom Liberty With NVIDIA DLSS 3.5 & Full Ray Tracing article  |[Article Link](https://www.nvidia.com/en-us/geforce/news/dlss-3-5-cyberpunk-2077-september-21-launch/)|\n|\\[Digital Foundry\\] - Inside DLSS 3.5 Ray Reconstruction + Cyberpunk 2077 Phantom Liberty - AI Visuals Roundtable|[Video Link](https://www.youtube.com/watch?v=Qv9SLtojkTU)|\n|NVIDIA DLSS 3.5 New Ray Reconstruction Enhances Ray Tracing with AI|[Video Link](https://www.youtube.com/watch?v=sGKCrcNsVzo)|\n|Cyberpunk 2077: Phantom Liberty – Official Cinematic Trailer|[Video Link](https://youtu.be/H-2J0x6oWUg)|\n\n# DLSS 3.5 FAQ\n\n**What is DLSS 3.5?**\n\nNVIDIA DLSS 3.5 features Ray Reconstruction, a new AI model that creates higher quality ray-traced images for intensive ray-traced games and apps. \n\nDLSS 3.5 is a suite of AI rendering technologies powered by Tensor Cores on GeForce RTX GPUs for faster frame rates, better image quality, and great responsiveness. DLSS now includes Super Resolution & DLAA (available for all RTX GPUs), Frame Generation (RTX 40 Series GPUs), and Ray Reconstruction (available for all RTX GPUs)\n\n**How does DLSS 3.5 work?**\n\nDLSS Ray Reconstruction adds additional AI to the ray-tracing lighting pipeline by replacing  multiple hand-tuned denoisers and adding a combined AI model for Super Resolution and Ray Reconstruction, addressing image quality challenges associated with a denoiser and high frequency information loss during upscaling.  \n\n**Is DLSS Ray Reconstruction for path traced games, RT games or both?**\n\nDLSS Ray Reconstruction is most advantageous to games that use ray tracing heavily. Path tracing definitely falls into that category. It can also provide advantages to games that use ray tracing on multiple effects.\n\n**Can we expect Ray Reconstruction to be a separate setting in game menus like Frame Generation?**\n\nYes. There is a new Ray Reconstruction toggle available when Super Resolution is ON.\n\n**Why does Ray Reconstruction require Super Resolution to be on?**\n\nBecause Ray Reconstruction is a combined AI model with Super Resolution to address the image quality issues that occur when there is high-frequency detail loss during the denoising/upscaling stage of the ray-tracing pipeline.\n\n**Does DLSS 3.5 improve performance or take away performance?**\n\nPerformance varies based on the number of ray-traced effects. Games with multiple ray-traced effects may have several denoisers that are replaced by the single Ray Reconstruction neural network. In these cases, Ray Reconstruction can also offer a performance boost. In titles with less intensive ray tracing and fewer denoisers, Ray Reconstruction improves image quality though may have a slight performance cost.\n\n**Compatibility**\n\n* GeForce RTX 40 Series users can combine Super Resolution and Frame Generation with Ray Reconstruction.\n* GeForce RTX 20 and 30 Series users can add Ray Reconstruction to their AI-powered technologies, alongside Super Resolution and DLAA.\n\nhttps://preview.redd.it/hs0janfim7pb1.jpg?width=3840&format=pjpg&auto=webp&s=e2ef1d6bae16be8bdd7f02f8efcc84ccb4bd62d3\n\n# Giveaway\n\nSee stickied comment for the giveaway details. You will need to respond to the stickied comment for the giveaway. Use the top level comments for regular news discussion.",
    "comments": [
      "# Giveaway is here.\n\n**Respond to this comment only. Any entries not in this comment will not be counted**.\n\nYou can enter for a chance to win a RTX 4080 GPU by answering the following:\n\n*“Tell us what excites you the most about DLSS 3.5 in Cyberpunk 2077: Phantom Liberty or Cyberpunk 2077 2.0 update!”*",
      "excited for idris",
      "I just got a 4090 and it's coming in on Thursday. I'm excited to see what DLSS is all about and can't think of a better game to try it in! Coming from a 1080 ti.",
      "Super excited for this. I enjoy cyberpunk nightly and it's the best game I have ever played. I am running vorpx VR to walk around the world and I believe this new AI Ray Trace will enhance the experience tremendously.",
      "I am excited to be fully immersed with the Cyberpunk world the game built with the 2.0 update and Phantom Liberty, and what Nvidia help support with DLSS 3.5.",
      "I’m excited to walk around and stare at puddles and other reflective things oohing and aahing because that sort of thing tickles my brain.",
      "Disappointed with the initial launch and would love to revisit the game in it’s full glory with full on RT",
      "Best looking game around.  Stunning.",
      "does anybody feel added latency with path / ray reconstruction on? my nvidia geforce show that latency is added round 50ms with it",
      "Gimme them RAYS",
      "Excited to see the game meet the developers vision, and to see what they’ve done to make Night City feel more vibrant and alive",
      "I dont think theres anything to celebrate with what happened with the controversy surrounding this game.",
      "Is crazy how DLSS 3.5 can look so good with awesome stable fps which is a reason why I’m so impressed of how nivida could do something like this, from what I’ve seen from comparisons I’m surprised of the huge difference between different DLSS’s especially with frame generations which makes it smoother and enjoyable to play.",
      "I'm excited to play game with DLSS 3.5, to see how much frame I can get",
      "I remember reading papers on AI for ray tracing denoising, and it's interesting the work finally come to fruition in a consumer product like this.",
      "Excited how the game is nowadays, pre-ordered it and played it like 10 hours only because of the poor optimization and bugs it had, with the 2.0 Update it deserves a new fully playthrough so im gassed for it.",
      "Making my RTX4070 shine like a GPU superstar!",
      "I like that the title of this post implies that Cyberpunk is finally releasing, as if it hasn't already been out for several years and a \"meh\" rpg the whole time. *Still better than starfield though",
      "never tried dlss so excited for that",
      "Ray reconstruction really makes the game even more of a night and day difference between RTX and without. So excited to see the tech visually move forward even more."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "rtx 4080",
      "4080",
      "4080 super",
      "rtx 4080 super"
    ],
    "title": "NVIDIA RTX 4080 SUPER reportedly costs $999, RTX 4070 Ti/4070 SUPER at $799/$599 - VideoCardz.com",
    "selftext": "",
    "comments": [
      "Well I was about to pull the trigger on a 7900xt, but think I’ll try and snag a 4070ti super simply for the reduced power consumption and dlss/frame gen at 1440p should be fine at 16 gbs vram for a while.\n\nIt all comes down to price, if these rumors are true it’s an instant buy, if it’s $999 then I’ll go back to the 7900xt idea",
      "For sure.\n\nAlmost 4080 level of power for 799 with DLSS + Frame Gen with 16GB VRAM? Solid 4k card, makes the 7900XTX obsolete.",
      "TiSuper vs 7900xtx is really favourable for nvidia. It is basically a $400 drop on 4080 which was similar to 7900xtx and way better in RT.\n\nAssuming 4070 is going to be like $500 now, I would get that over Super.\n\nThe only compelling product is TiSuper here.",
      "A year and a price cut later, the 4080 is still overpriced by $200.\n\nAt least the Ti Super is closer to the sweet spot with 16 GB.",
      "$599 will be like 750€ I guess",
      "4070 Ti Super is the star of the show, and all of these super variants should have been like this since the 40 series release.",
      "Pretty much. AMD is going to have to drop prices significantly if these prices are accurate.",
      "So are they all getting a price drop? A 4080 here in Canada is like 1600-1800 dollars it’s fucking stupid.",
      "The 4070Ti Super at $799 is basically what the 4080 should've been at launch.\n\nReally seems to be the most attractive option out of all cards from this mid-gen refresh. If it has any decent overclocking headroom, it should be able to match stock 4080 Super performance.\n\nIt will also, more than likely, be a huge problem for both 7900XTX and 7900XT sales, unless AMD does a price cut by at least $100-150 on each.",
      "It is so close to 4080 and 7900XTX that it doesn’t matter while it will outperform XTX in RT games.\n\nThe main thing is if nvidia can keep this in stock, it will be a scalping mess.",
      "You are forgetting the exchange rate.\n\n$599 is about 560 EUR. Even with 20% tax the price should be about 672 EUR. And not 750-800 EUR where it will be.\n\nEurope always had more expensive hardware for no fucking reason than sheer greed.",
      "I'm sorry but an 80 series card should still be 600-700. Do not cheer for nvidia",
      "what is this AI work that suddenly everyone and their dad is doing?",
      "yeah, most likely. and the 70ti super will be around 1k. prices here are stupid.",
      "I was just about to grab 4080S or 4070TIS but with 5xxx coming out in less than a year I’ll play the waiting game and use GFNow",
      "I keep wondering if they also have a refresh in the works.\n\nRdna3 just didn't meet expectations, and there were a lot of rumors that something went wrong that would have required new silicon to fix. So with that in mind, I wonder if an rdna 3.5 refresh could be on the way.\n\nIf the 4070ti super comes anywhere close to the 4080 for 800 bucks, even the 7900xtx at 800, which is Hella performant, won't look like an amazing deal.\n\nBut if course we need to see performance first. I'm rooting for Nvidia here. The horror of gpu prices that started in 2020 needs to be done. Inflation is what it is, but if Nvidia stops trying to gouge everybody for even a generation or two, then card prices will effectively equalize with inflation, and it won't \"feel\" so shitty anymore.",
      "what why",
      "Everything is overpriced",
      "We've gone from bad to ok pricing on the 40 series. Makes it a no brainer to get over RDNA3 unless AMD drastically cuts prices.\n\nStill debating exactly what I want to do. If I upgrade to 4080S then I'm going to finally make the jump to 4K. Otherwise I'll just have to settle for 4070S.",
      "I don't think the 4070ti Super is to compete with the 7900xtx, it is to sit between the 7900xt and 7900xtx. More to offer a better option over the 7900xt than anything else."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "rtx 4080",
      "4080"
    ],
    "title": "NVIDIA GeForce RTX 4070 Ti SUPER GPU Benchmarks Leak: Up To 10% Faster Vs 4070 Ti, Almost Matches RTX 4080",
    "selftext": "",
    "comments": [
      "4080 performance and 16 gigs of VRAM for 799 seems kinda tempting ngl",
      "That’s the 4080 we should’ve got at launch, for the 80 series cost. \n\nNvidia is a bag of clowns.",
      "The 16gb vram are what push me to it over the 4070s, tbh",
      "Think of it this way:\n\nThe 4070 super is a cut down 4070 ti die for the price of the original 4070. The original 4070 still exists as a base 1440p tier card for $549 msrp. \n\nThe 4070 ti super is a cut down 4080 die for the price of the original 4070 ti and replace it altogether.\n\nThe 4080 super is the fully realized potential of the die it is based on, everything that could be thrown at it thrown its way, for $200 less than the original 4080 and replaces that card entirely.",
      "Will the 4080S really be worth the additional $200+?",
      "There know exactly what they are doing.",
      "Because people are clearly sick of gamery looking trash lol. AIBs need to catch up. The AMD partners are gamery but have much better looking GPUs, especially XFX and Sapphire.",
      "I'm waiting to see the difference in 4070 ti super and 4080 super. I've got an Alienware 1440p UW, so I wonder is 200 extra worth it if it's only 10-15%.",
      "Everything is relative, but a 10% increase puts it in the gap between the 4070 ti and 4080. So you might as well say that the 4070 ti super almost matches the 4070 ti.\n\n10% uplift is roughly the compute increase, meaning that the 4070 ti memory system is not bottlenecking and well designed contrary to popular belief.",
      "I'm not going to disagree with that but still think 799 for what is essentially a 4080 is actually decent for once\n\nThe only thing wrong with this gpu is it's a year late and \"4070 Ti Super\" is one of the dumbest GPU names I've heard in a long time.",
      "I mean the 4070 super launched at MSRP.... These are not wildly in demand cards",
      "FE’s fit in way more cases. They don’t look like a space ship, and perform extremely well.",
      "The importance of VRAM for gaming importance has been greatly exaggerated. As evidenced by the amount of people that call the 4070Ti unsuitable for 4k.",
      "In my opinion, yes! RTX 4070 Ti S offers great performance, but it does have a way less capable cut down version chip.\n\n>RTX 4080 SUPER graphics card will be using the full AD103-400 GPU with 10240 CUDA cores in total, 320 TMUs, 112 TOPs, and 64MB of L2 cache.\n\nRTX 4070 Ti Super comes with 8,448 CUDA cores + cut down RT & Tensor cores. [More info here.](https://www.makeuseof.com/nvidia-rtx-4070-super-vs-rtx-4070-super-ti-vs-rtx-4080-super/)\n\nEdit. 1/5 price increase, get you about 1/5 core/chip increase. If the price difference is $200, I would pay the extra. But that's just me. For most of the users, 4070 TiS is more than enough for the price.",
      "$799 for only 12gb vram was a crime. 12gb is seriously on the edge of not being enough for a 4k monitor if you want it to last 4-5 years without issue. Even at 1440p at higher settings in some games it could prove to not be enough, certainly at 3440x1440 which is very common with the Alienware ultrawides.",
      "I never said you said they didn't know. I just said they know what they are doing.",
      "3% faster memory and 21% more shaders.  It used to be pretty normal to pay 25% extra for something that is only 10% to 15% faster at the high end. I don't think people at the top really care much about performance per dollar.\n\nFit example the RTX 3080 vs 3080ti, or even 3090.  People will argue it's cause of double the VRAM, but if going from 8gb to 16gb is a rip off for $100 on a 4060ti, then certainly going from 12gb to 24gb on a 3080 12gb to a 3090 is as well. But people would bought them anyway for 10% performance and 24gb even if COVID didn't happen.",
      "Incoming 7900 XTX price drop :D",
      "This is the one to get, IMO.  Of all the Super models, this is the best.",
      "Still waiting on a 16GB midrange option from Nvidia for no more than the $500 with 4070 performance at minimum. The super should have had 16gb.  The past 3 generations from Nvidia have been kinda disappointing for one reason or another"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "rtx 4080",
      "4080",
      "4080 super",
      "rtx 4080 super"
    ],
    "title": "RTX 4080 Super",
    "selftext": "I’m good until RTX 70 series.",
    "comments": [
      "she’s gorgeous",
      "Waiting for mine to come in!\n\nAlso plan to have it for a good while.\n\nCan’t wait!",
      "Enjoy the unboxing!  It’s probably the best bar none; it’s better than Apple unboxing!",
      "Crying in poor 😭",
      "It really made me feel like I had purchased a premium product. \n\nBetween the inner and outer boxes, this is by far the best packaging I've ever had for an electronic device delivered by mail.",
      "From one fellow 4080 FE Super owner to another, welcome! I was impressed with the box itself, very unique packaging. Such a high quality piece of hardware it felt great in the hands. Good stuff :)",
      "I’m sure people won’t want to divulge their secrets, but I’ll ask anyway:  what’s the best way to score a Founder’s edition of the 4080 Super?  Best Buy?",
      "https://preview.redd.it/dfuwz7bs7tsc1.jpeg?width=1179&format=pjpg&auto=webp&s=dbea75832dda933551db6666888431b6b42fde86\n\nAbsolute monster of a card when I got mine. Made my 3070 look like peanuts. Barely fit my meshify C case too! Congrats!",
      "Why is everyone in here been downvoted lmao",
      "Don't be you r not alone",
      "Yeah I was not expecting even the outer cardboard box to unfurl and open like a treasure chest, that was sick. Reminded me of a Borderlands collectors edition",
      "Hold me! 😭",
      "HotStock app and/or nvidia website and check their inventory every 1hr and have your credit card info ready.",
      "It does look very pretty doesn’t it",
      "Jealousy in the air tonight I could tell",
      "14700K 🙌🏽",
      "It does not come with anti-static bag ;however the box it came with is another level.  It is well-protected and probably the best GPU box to date.",
      "MSRP.  Nothing more.  I bought it a month ago.",
      "Man I really envy people who got Nvidia Official GPU",
      "I usually throw boxes away immediately but I kept both the 4090 FE box and even the weird Foxconn outer shipping box for it."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "rtx 4080",
      "4080",
      "4080 super",
      "rtx 4080 super"
    ],
    "title": "RTX 4080 Super Founders Edition $999.99 In stock.",
    "selftext": "",
    "comments": [
      "You need to join a queue to buy a MSRP 4080s in 2025 lol",
      "#  \n\n**Please note: if you are in line for a high demand product, being in the queue does not guarantee a purchase.**\n\nNumber of users in line ahead of you is: **556**\n\n  \nlol",
      "Waited in a queue, forced to log on, checkout with my cart, and it wont even accept my payment what a fucking joke",
      "Can’t even buy a 3 year old card at MSRP in 2025. Market is so cooked",
      "wait in a que for the website to tell you there was an error and unable to complete transaction\\*",
      "I’m sitting this one out. \n\nAlready played this entire dumbass game during the RTX 3000 launch. Saw Nvidia were pulling the same dumb bullshit with the 5000-series and just got an AMD card instead. \n\nI’ll be back for the RTX 6000-series lmao.",
      "So, Nvidia figured out how to make a queue after all this time? And the queue still breaks on checkout? What are they even using AI for over there?",
      "there was none available to begin with the website is just bugged out lol",
      "Probably some kind of last batch but regardless the 4080S is effectively a 5080 without MFG",
      "to be fair this is like my trial queue to make sure my nvidia account is ready to buy 5090 should that come in stock",
      "Seems like they bottled FOMO and are turning a luxury good into a bare necessity, people need to study just how the hell they turned people into zombies, it could have been the 4080 at $1200 and people would have gobbled it up when they rejected it 3 years ago...",
      "Why are they restocking this dogshit instead of the 5080?",
      "Brother, the 5080 is only like 10% faster than the 4080S how is it dogshit lol",
      "These are all going to the resale market.",
      "https://preview.redd.it/av6jm2nezcie1.png?width=1200&format=png&auto=webp&s=6eddf9b61e457d5dc93a2a9f68932b476b70dabd",
      "> What are they even using AI for over there?\n\nInflating the share price temporarily.",
      "You think 5080 reviews impressed people so much they are buying all the stock available?",
      "IS it true nvidia will not sell the 5000 FE cards through their market place?",
      "No one can buy it, I tried and so did hundreds of others , it wont accept credit card details. I only saw one person get a confirmed order in a certain very large GPU drops discord.",
      "I'm afraid the same thing will happen when AMD cards launch lol"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "4080",
      "4080 super"
    ],
    "title": "4080 Super in stock now",
    "selftext": "",
    "comments": [
      "Nvidia stock at $1000+ \n\nI'm sure the 5090/5080 will be reasonably priced and not prone to scalpers markups. A couple of lucky ones will secure a card, but it is mostly going to be for China.\n\nAlso, everyone and their mother is selling off their barely used GPU in anticipation. Prepare for the greatest FOMO launch in Nvidia's history, and they are most definitely reading out post.",
      "SKIP ill wait for the 5000 series. \n\n  \ndamn.. then I wont find one to buy and ill have to wait for the 6000 series. ffs..",
      "$300 too much",
      "In the week since rumors for the 5000 series hit the price of used 4090's dropped $200~",
      "300 TOO MUCH",
      "300 TOO MUCH",
      "While I generally endorse the idea of waiting as long as possible, some people need hardware now or relatively soon. The 5070 could be another 12-16 months before release.",
      "https://i.redd.it/9b9fv39k573d1.gif",
      "Man I can't wait for the second great GPU crisis lol, I remember 30 series and 40 series being months and months. Even reading people pulling shenanigans with swapping gpu in prebuilt pcs.",
      "So you recommend wasting more money while waiting on a used hardware?",
      "im waiting for 5080 at this point.",
      "Wish the old cards actually came down in price when the new ones come out but we know Nvidia is way too good at inventory management to let that happen.\n\nI also will be looking for a 5080 and imagine it will be just as much of a nightmare as trying to get a 3090 was at launch. Stock tracker discords including a paid one to get early alerts, auto-refresher chrome extensions, just crazy shit a consumer shouldn't have to go through. But it was either that or wait another 6 months (might do that this time since the 3090 is still fine) or pay a scalper markup (will never do that).",
      "![gif](giphy|3o7TKGMslz2YfhkuwU|downsized)",
      "still in stock",
      "Wait for 5070",
      "How did you kill a gpu in 5 and a half years!? I had a rx480 for like 6, sold it still working, and I've had a 5700xt for like 5 years now",
      "Have fun with the mark up plus the 25 percent tariff to deal with. Card is gonna be like 1500 bucks.",
      "4000 series wasn't too bad, i was able to get a 4090 at launch from bestbuy (msrp). Stock got a bit worse (tariff/ban etc..)and i was still able to casually buy a second at msrp around mid cycle.  I don't expect 5090 to be any different, the margin on these items are so high(still nothing compare to enterprise tho) its whatever the market will bear at this point, it has no relation to the underlying cost anymore.",
      "Still only 16gb in a thousand dollar card",
      "If AMD got their shit together with rendering and CUDA compatibility, it'd buy it in a heartbeat. I don't need to flex on neckbeards who spend 50% of their time overclocking."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "4080",
      "4080 super"
    ],
    "title": "4080 super for my first ever build.",
    "selftext": "13yo.",
    "comments": [
      "The motherboard without FE cover really irks me, still a nice build for your age, congrats",
      "Sorry if I sound dumb but what’s an fe cover?",
      "The plates that cover the rear ports of the motherboard\n\nSeems like you only have one in the back of the case, meanwhile the front of the mb does not have one",
      "I find it funny that you cheap out on a mobo while running a 4080. I can’t really see which cpu you are running, and yes, most likely you won’t «need» a headsink, until you do. But hey to each their own.",
      "Nice build! Enjoy it.",
      "I've bought expensive motherboards that performed like shit, and shitty motherboards that were super reliable. When I was looking at reviews for my AM5 build last year it was a mixed bag, spending an extra $100 - $200 was no guarantee of RAM compatibility or stability.",
      "Better they spend the extra $100 on the GPU than on the motherboard.",
      "The thickness of that thing is ridiculous.",
      "There’s no need to get defensive. You literally made a post which then obviously will make people respond to that post.\n\nMatter of fact, I would have gotten a different cpu as well. The 5800X3D is better, and probably costs less. The 7800X3D costs more but is even better.",
      "No problem mate, I was just mentioning it, because if I say you did a good job on intel, purchase and finishing your PC, I should also give some credits to your family who supported you financially to get it so far. No ill meaning or intention. I am also greatfull for my family supporting me in your age for the same reason. I did started a bit earlier and was almost always fascinated by electronics and especially computers and that’s what lead to my career as an IT professional.",
      "I actually got my cpu for quite cheap locally. Something around 210 so it was good value",
      "I love this case  alot\nH6 flow not so ridiculously big like h9 and not so basic like other cases good choice",
      "Is not having it an issue or just a minor inconvenience? The build has been running fine.",
      "It looks better with it, but also it usually has a heatsink for the vrms as well",
      "Who cares? All computers should be black boxes. RGB & windows are like racing stripes, fake spoilers & fake air intakes on a car.",
      "It’s 4 times the size of my hand it’s insane",
      "My motherboard only has 2 Ram slots sooooo",
      "I assuming that you got sponsored, because you said you are 13yo. Or did I interpret something wrong?",
      "LTT did a good video testing performance of Boards and how heat affects them. The cheaper boards work fine but the VRMs not having a heatsink can affect performance once they get really hot.\n\nhttps://youtu.be/GvyQXkFUe3E?si=z6wttDc23xS5Nj9h\n\nTbh, I would have done the same thing if it meant I could get a 4080 with the extra budget.",
      "Don't listen to those idiots, if the motherboard works with your build it's absolutely fine. Especially with a 7700X there is zero difference between a cheap motherboard and the most expensive one when it comes to performance.\n\nThe pricier motherboards usually have more features, but if you don't need them it's wasted money."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "rtx 4080",
      "4080"
    ],
    "title": "GeForce Beyond Megathread - NVIDIA GeForce RTX 40 Series GPUs, DLSS 3, Portal with RTX and more",
    "selftext": "# Addendum 2: Important note on Power Specifications\n\nPlease visit this page for important information on power specifications: [https://www.nvidia.com/en-us/geforce/forums/geforce-graphics-cards/5/501736/geforce-rtx-40-series-power-specifications/](https://www.nvidia.com/en-us/geforce/forums/geforce-graphics-cards/5/501736/geforce-rtx-40-series-power-specifications/)\n\nSome important points listed below\n\n**Do I need to upgrade my PSU for the RTX 40 Series?**\n\nThe RTX 40 Series doesn’t require a new power supply if you already meet the PSU wattage recommendations. The RTX 4090 TGP is 450 W and the minimum recommended PSU is 850 W. The 4080 16GB TGP is 320 W with a minimum recommended power supply of 750W, and the minimum recommended power supply for the 4080 12GB is 700W.\n\n**Do the RTX 40 Series cards require a new type of power connector or a new power cable?**\n\nNo. The RTX 40 Series cards come with power adapters that allow you to use existing power supplies with existing 8-pin PCIe connectors. The RTX 40 Series cards can also use the PCIe Gen5 power connector which allows you to power the graphics card with a single cable.\n\n# Addendum 1: Important note on DLSS 3\n\nDLSS 3 consists of 3 technologies – DLSS Frame Generation, DLSS Super Resolution (a.k.a. DLSS 2), and NVIDIA Reflex.\n\nDLSS Frame Generation uses RTX 40 Series high-speed Optical Flow Accelerator to calculate the motion flow that is used for the AI network, then executes the network on 4th Generation Tensor Cores. Support for previous GPU architectures would require further innovation and optimization for the optical flow algorithm and AI model. \n\nDLSS Super Resolution and NVIDIA Reflex will of course remain supported on prior generation hardware, so current GeForce gamers & creators will benefit from games integrating DLSS 3.  We continue to research and train the AI for DLSS Super Resolution and will provide model updates for all RTX customers as we have been doing since DLSS’s initial release.\n\n|**DLSS 3 Sub-Feature**|**GPU Hardware Support**|\n|:-|:-|\n|DLSS Frame Generation|GeForce RTX 40 Series GPU|\n|DLSS Super Resolution (aka DLSS 2)|GeForce RTX 20/30/40 Series GPU|\n|NVIDIA Reflex|GeForce 900 Series and Newer GPU|\n\n&#x200B;\n\n# This thread is best viewed on new Reddit.\n\n[Image Link - GeForce RTX 4090 Founders Edition](https://preview.redd.it/6orjy4mwi0p91.png?width=3840&format=png&auto=webp&s=f868594edce3c4857dee6028498428dfd55bfd61)\n\n\\#BeyondFast. Powered by the Ada Lovelace architecture, GeForce RTX 40-Series is finally upon us. The goal of this megathread is to provide everyone with the best information possible and consolidate any questions, feedback, and discussion to make it easier for NVIDIA’s community team to review them and bring them to appropriate people at NVIDIA.\n\n# r/NVIDIA GeForce RTX 40-Series Community Q&A\n\nWe are hosting a community Q&A today where you can post your questions to a panel of 7 NVIDIA product managers. [Click here to go to the Q&A thread for more details.](https://new.reddit.com/r/nvidia/comments/xjcr32/geforce_rtx_40series_community_qa_submit_your/)\n\n# r/NVIDIA GeForce Beyond Giveaway\n\nPrize includes GeForce RTX 4080 16GB card, Steam giftcards, and Nvidia swag bags including RTX Keycaps and Mugs. **See pinned comment for details!**\n\n# GeForce RTX 40-Series GPU information:\n\n# [Official Spec Sheet Here](https://www.nvidia.com/en-us/geforce/graphics-cards/compare/?section=compare-specs)\n\n&#x200B;\n\n||**RTX 4090**|**RTX 4080 16GB**|**RTX 4080 12GB**|\n|:-|:-|:-|:-|\n|**GPU**|TSMC 4N AD102|TSMC 4N AD103|TSMC 4N AD104|\n|**Transistor**|76.3 billion|45.9 billion|35.8 billion|\n|**Die Size**|608.5 mm^(2)|378.6 mm^(2)|294.5 mm^(2)|\n|**Transistor Density**|125.5 MT/mm^(2)|121.1 MT/mm^(2)|121.6 MT/mm^(2)|\n|**GPC**|11|7|5|\n|**TPC**|64|38|30|\n|**SMs**|128 SM|76 SM|60 SM|\n|**TMUs**|512|304|240|\n|**ROPs**|176|112|80|\n|**Base Clock**|2.23 Ghz|2.21 Ghz|2.31 Ghz|\n|**Boost Clock**|2.52 Ghz|2.51 Ghz|2.61 Ghz|\n|**CUDA Cores**|16384 CUDA Cores|9728 CUDA Cores|7680 CUDA Cores|\n|**Shader FLOPS**|82.6 Shader TFLOPS|48.7 Shader TFLOPS|40.1 Shader TFLOPS|\n|**RT Cores**|128 3rd Gen RT Cores|76 3rd Gen RT Cores|60 3rd Gen RT Cores|\n|**RT FLOPS**|191 RT TFLOPS|112.7 RT TFLOPS|92.7 RT TFLOPS|\n|**Tensor Cores**|512 4th Gen Tensor Cores|304 4th Gen Tensor Cores|240 4th Gen Tensor Cores|\n|**Tensor FLOPS (FP8)**|660.6/1,321 Tensor TFLOPS|389.9/779.8 Tensor TFLOPS|320.7/641.4 Tensor TFLOPS|\n|**Memory Interface**|384-bit|256-bit|192-bit|\n|**Memory Speed**|21 Gbps|22.4 Gbps|21 Gbps|\n|**Memory Bandwidth**|1,008 GB/s|716.8 GB/s|504 GB/s|\n|**VRAM Size**|24GB GDDR6X|16GB GDDR6X|12GB GDDR6|\n|**L2 Cache**|72MB|64MB|48MB|\n|**Max TGP**|450W|320W|285W|\n|**PSU Requirement**|850W|750W|700W|\n|**Price**|$1599 MSRP|$1199 MSRP|$899 MSRP|\n|**Release Date**|October 12th|November|November|\n\n# Performance Shown (take with grains of salt until actual review):\n\n* RTX 4090\n   * 2x Performance of RTX 3090 Ti\n* RTX 4080 16GB\n   * 2x Performance of RTX 3080 Ti\n* RTX 4080 12GB\n   * \\~3090 Ti performance\n\n# Power Requirements:\n\n&#x200B;\n\n|**SKU**|**Power Supply Requirements**|\n|:-|:-|\n|GeForce RTX 4090 Founders Edition|**850W Required**. 3x PCIe 8-pin cables (adapter in the box) OR 450 W or greater PCIe Gen 5 cable|\n|GeForce RTX 4080 16GB Founders Edition|**750W Required**. 3x PCIe 8-pin cables (adapter in the box) OR 450 W or greater PCIe Gen 5 cable|\n|GeForce RTX 4080 12GB Founders Edition|**700W Required**. 2x PCIe 8-pin cables (adapter in box) OR 300 W or greater PCIe Gen 5 cable|\n\n**See Diagram below**\n\n[Image Link - RTX 4090 and 4080 16GB Founders Edition Power and Case Requirements](https://preview.redd.it/1dph84mvn0p91.png?width=3172&format=png&auto=webp&s=9aacb9dcdfbe1c12db5c8d1d376e5e6892ca071c)\n\n# DLSS 3\n\n* Over 35 Games and Apps adding DLSS 3\n* DLSS 3 is a revolutionary breakthrough in AI-powered graphics that massively boosts performance while maintaining great image quality and responsiveness. Building upon DLSS Super Resolution, DLSS 3 adds Optical Multi Frame Generation to generate entirely new frames and integrates NVIDIA Reflex low latency technology for optimal responsiveness. DLSS 3 is powered by the new fourth-generation Tensor Cores and Optical Flow Accelerator of the GeForce RTX 40 Series graphics cards.\n* Optical Frame Generation boosts performance by reducing the GPU workload, thus increasing performance. Powered by new fourth-generation Tensor Cores and the new Optical Flow Accelerator on GeForce RTX 40 Series GPUs, DLSS 3 analyzes sequential frames and motion data and uses AI to create additional high-quality frames. \n* Ada includes a powerful new 3rd-generation RT Core (Ray Tracing Core) that provides up to 2x the ray-triangle intersection performance of the prior 2nd-generation RT Core used in NVIDIA Ampere architecture GPUs.\n* 4th Generation Tensor Cores accelerate AI features that allow you to apply advanced effects faster, and without requiring advanced editing knowledge. 4th Gen Tensor cores are up to 2x faster vs prior gen, and now they add support for INT8.\n\n# Portal RTX\n\n* **Wishlist on STEAM Now!  - Coming November 2022** [**https://store.steampowered.com/app/2012840/Portal\\_with\\_RTX/**](https://store.steampowered.com/app/2012840/Portal_with_RTX/)\n* **Note: Free DLC for owners of Portal.**\n* NVIDIA Lightspeed Studios has reimagined Valve’s iconic video game *Portal*, regarded as one of the best video games of all time. Advanced graphics features such as full ray tracing and DLSS 3 give the game a striking new look and feel. *Portal with RTX* will be released as free, official downloadable content for the classic platformer with RTX graphics in November, just in time for *Portal*’s 15th anniversary.\n\n# RTX Remix\n\n* **Sign up Now! -** [**https://www.nvidia.com/en-us/geforce/rtx-remix/**](https://www.nvidia.com/en-us/geforce/rtx-remix/)\n* [NVIDIA RTX Remix](https://www.nvidia.com/en-us/geforce/rtx-remix/), a free modding platform built on [NVIDIA Omniverse](https://www.nvidia.com/en-us/omniverse/) that enables modders to quickly create and share #RTXON mods for classic games, each with enhanced materials, full ray tracing, [NVIDIA DLSS 3](https://www.nvidia.com/en-us/geforce/news/dlss3-ai-powered-neural-graphics-innovations), and [NVIDIA Reflex](https://www.nvidia.com/en-us/geforce/technologies/reflex/).\n\n# NVIDIA STUDIO & AV1 Encoder\n\n* The new [GeForce RTX 4090](https://www.nvidia.com/en-us/geforce/graphics-cards/40-series/rtx-4090/) brings a massive boost in performance, third-generation Ray Tracing Cores, fourth-generation Tensor Cores, **dual eighth-generation NVIDIA AV1 Encoders**, and 24GB of Micron G6X memory capable of reaching 1TB/s bandwidth. The GeForce RTX 4090 is up to **2X faster than a GeForce RTX 3090 Ti in 3D rendering, AI, and video exports.**\n* RTX 40-series Ada generation GPUs feature hardware accelerated encoding for the AV1 video codec using the NVIDIA hardware encoder, NVENC. AV1 offers improved visual quality at the same bitrates as H.265/H.264 which is a boon for game streaming. Optionally, users can opt to maintain the same level of visual quality, with reduced bit rates when using AV1, resulting in smaller file sizes and faster video uploads. Ada’s AV1 encoder is 30% more efficient than the H.264 encoder used today for 4K HDR video. \n\n# Reference Links\n\n|**Articles**|**Links**|\n|:-|:-|\n|GeForce RTX 40 Series Graphics Cards: Up To 4X Faster, Powered By 3rd Gen RTX Architecture & NVIDIA DLSS 3|[Link Here](https://www.nvidia.com/en-us/geforce/news/rtx-40-series-graphics-cards-announcements)|\n|NVIDIA DLSS 3: AI-Powered Performance Multiplier Boosts Frame Rates By Up To 4X |[Link Here](https://www.nvidia.com/en-us/geforce/news/dlss3-ai-powered-neural-graphics-innovations/)|\n|Portal with RTX Reimagines Valve’s Classic with Full Ray Tracing, NVIDIA DLSS & NVIDIA Reflex|[Link Here](https://www.nvidia.com/en-us/geforce/news/portal-with-rtx-ray-tracing)|\n|NVIDIA RTX Remix: Create & Share #RTXON Mods For Classic Games|[Link Here](https://www.nvidia.com/en-us/geforce/news/rtx-remix-announcement/)|\n|Over 35 Games And Apps Adding NVIDIA DLSS 3. Plus Portal with RTX, Cyberpunk 2077 New Ray Tracing: Overdrive Mode & More|[Link Here](https://www.nvidia.com/en-us/geforce/news/dlss3-supports-over-35-games-apps)|\n|Step Up To 1440p 360 FPS Competitive Gaming With New GeForce RTX 40 Series Graphics Cards and NVIDIA Reflex|[Link Here](https://www.nvidia.com/en-us/geforce/news/play-competitive-games-with-rtx-40-series-and-reflex)|\n|GeForce RTX 40 Series #BeyondFast Sweepstakes|[Link Here](https://www.nvidia.com/en-us/geforce/news/rtx-40-series-beyondfast-sweepstakes)|\n|Creativity At The Speed of Light: GeForce RTX 40 Series Graphics Cards Unleash Up To 2X Performance In 3D Rendering, AI, and Video Exports For Gamers and Creators|[Link Here](https://www.nvidia.com/en-us/geforce/news/rtx-40-series-and-studio-updates-for-content-creation/)|\n\n&#x200B;\n\n|**Videos**|**Links**|\n|:-|:-|\n|GeForce Beyond: A Special Broadcast at GTC (keynote cutdown)|[Link Here](https://youtu.be/Uo8rs5YfIYY)|\n|GeForce RTX 4090 Beyond Fast|[Link Here](https://youtu.be/fj245xMr-BM)|\n|Portal with RTX World Premiere|[Link Here](https://youtu.be/AZHBl5yWqJk)|\n|NVIDIA Racer RTX The future of graphics powered by GeForce RTX 40 Series|[Link Here](https://youtu.be/AsykNkUMoNU)|\n|Cyberpunk 2077 NVIDIA DLSS 3 & Ray Tracing: Overdrive - Exclusive First-Look|[Link Here](https://youtu.be/spq0jSWRCqI)|\n|Microsoft Flight Simulator NVIDIA DLSS 3 - Exclusive First-Look |[Link Here](https://www.youtube.com/watch?v=cJlo2I7CiD0)|\n|A Plague Tale: Requiem RTX ON - Exclusive First-Look|[Link Here](https://youtu.be/341KyDYjI0U)|\n|JUSTICE Fuyun Court - Path Tracing Showcase Premiere|[Link Here](https://www.youtube.com/watch?v=X9zMxCPqgGI)|\n|RTX. IT’S ON. Ray Tracing & DLSS In Your Favorite Games|[Link Here](https://youtu.be/mqiVYUAonoE)|\n|GeForce Garage - RTX 4090 Build by LiquidHaus|[Link Here](https://youtu.be/H5soCA5SQD0)|\n|Cyberpunk 2077 NVIDIA DLSS 3 Performance Comparison|[Link Here](https://youtu.be/r-hu006p23I)|\n\n&#x200B;",
    "comments": [
      "RTX 4080 *12GB* being called RTX 4080 is misleading and bad naming. It's not same GPU as RTX 4080 *16GB* at all. Names makes it suggest the only difference is the VRAM but it's totally different class of GPU.\n\nYou seriously don't have any other letters or numbers to use?",
      "Selling the rebranded 4070 for $900 is ridiculously anti-consumer.",
      "Pricing is god awful.",
      "Two 4080 versions... Really? This is BS, just call them differently. I hate when companies do this. Just call the better one 4080 TI or 4085. They are NOT the same.",
      "Guess I’ll keep my Rtx 3080 and skip this gen.",
      "DLSS 3....Wait so dlss 3 is just for 40 series of cards?\n\nWTF?",
      "Hahahahhahahahahha, the pricing is ridiculous. What should be a 70 series card for $899.",
      "It's because the 12Gb is really the 4070 as it's AD104, but they don't want to call it that cause it makes it look like the 4070 is more expensive than the 3080 at launch etc.",
      "Amazing technologies were shown, but the prices where I live are inexcusable. No thanks.",
      "Not the first time they've done this. \n\nThey know exactly what they're doing.",
      "Jensen pulling the Apple power move by gatekeeping software features to push sales of new products",
      "1500€ for 4080 in Europe, lmfao.",
      "Like EVGA, we should skip this gen",
      "Yep, there should not be a crippled 12GB version imo. \n\nWhat a great way to artificially move the stack even further out to make everything more expensive.",
      "From what I've read they should have just called the 12GB version the 4070. Maybe they didn't want to say \"The 4070 costs more than the 3080 did at launch?\" I don't know.",
      "Can’t extort the miners anymore so they’re extorting the general consumers instead, lovely",
      "*cries in 1060 3gb*",
      "Ouch that price. My 1080ti going to have to keep ticking over a little longer",
      ">Amazing technologies were shown, but the prices ~~where I live~~ are inexcusable. No thanks.",
      "Terrible pricing, but it makes sense to see a price bump considering how many people were overpaying for 30 series cards for nearly 2 years so leather jacket boy probably figured they could get away with it, and they will."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "rtx 4080",
      "4080",
      "4080 super",
      "rtx 4080 super"
    ],
    "title": "GeForce RTX 4080 SUPER reviews rescheduled to January 31st - VideoCardz.com",
    "selftext": "",
    "comments": [
      "4080s is just a discounted 4080. That’s how I’m viewing it. Still a a good thing imo even if the improvements are in the single digits.",
      "I mean the 4080 Super is nothing more than a small bump in cores, faster memory by a tad, and a healthy price reduction. I expect 5% at most but the price reduction makes the 4080 Super a competitive offering.",
      "17% price reduction + 5% base OC = what the 4080 should've been on release.",
      "Should’ve been $799, but I guess leather jacket prices went up so what’re you gonna do?",
      "I just imagine it as an OC'd card.",
      "I mean I don’t really need reviews, I wanted a 4080 but wasn’t willing to pay for it, at this new price I’m willing to pay for it. Had the original model just been discounted instead of a new sku introduced I would have bought that. But this is frustrating regardless.",
      "Issues with reviewers not getting cards on time? \n\nSo punish consumers? Mislead them and not allow them to get the most informed purchase possible? \n\nBut guys just remember it’s really just going to be like a 5% bump at best. Don’t overthink this card.",
      "yep, just like 2080 super was in 2019",
      "still waaay to expensive",
      ">So punish consumers? Mislead them and not allow them to get the most informed purchase possible?\n\nsome people here are really complaining just about anything as long as they can complain about nvidia. Your argument would be valid, if the card was a brand new one. This is literally a refresh of an existing with no major spec change, you know what the perfomance will be within low single digit %.\n\n**Also nobody forces you to buy at launch.**",
      "Having a review embargo the day before release is super scummy. Not shipping the cards enough in advance is harmful for the creators who have to crunch to get a review out. Screwing up shipping to the reviewers is just a huge middle finger to the reviewers and us!",
      "Yeah. If it's 80% of a 4090 for $1000, while the 4090 is being valued at $2000 and gulps 450W, then it's a no-brainer. I can just forget that the 4090 exists.",
      "The benefit of 4070 Super was it's large increase in core count at same price of 4070.\n\nThe benefit of 4070 Ti Super was additional 4GB of VRAM and small performance increase at same price of 4070 Ti.\n\nThe benefit of 4080 Super is just a small performance increase at a $200 price reduction from a 4080.\n\nThere's nothing more or less to what the \"super\" line up is.",
      "To replace the confusing Titan",
      "3080 price and 3080 availability....",
      "melodic theory shelter selective full ten homeless aromatic worthless squeamish\n\n *This post was mass deleted and anonymized with [Redact](https://redact.dev/home)*",
      "or more cyncically, to make the notoriously bad value titans seems like less of a vanity card and more like just another item atop the stack.",
      "That still doesn't account for the increase. It's not even half of the price difference.",
      "Yeah this screams “let consumers buy before you put out a review”. Super lame practice",
      "3080 debuted at $699, but saying it’d be the same availability is a bit pessimistic. 3080 had to contend with a banger price as well as a global pandemic. Had it been a normal year I don’t think it’s insane to think it would’ve been available in wide release a few months after launch."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "rtx 4080",
      "4080",
      "4080 super",
      "rtx 4080 super"
    ],
    "title": "RTX 4080 Super",
    "selftext": "My first \"high-end\" gpu in a long time, I was running Intel Arc 770 16Gb before this. The Arc was nice and I didn't have much issues with it, one thing that bothered though me was that Intel never fully fixed topaz Ai with the Arc. \n\n13700k\n64Gb RAM\n2x nvme 1Tb\nCorsair SF 750\nHyte revolt 3 \nAsus z690 STRIX gaming \nRTX 4080 Super Proart \nEK-AIO 240 basic \n",
    "comments": [
      "https://preview.redd.it/bmk5en03z0pd1.jpeg?width=3060&format=pjpg&auto=webp&s=5607ae1023bd3244db4d7d2b34e08374b60d77f2",
      "Hyte revolt 3",
      "Re: case - bookmarked for my next build! Looks super clean!\n\nThanks for sharing!",
      "I can completely relate! The switch from my budget gtx 1660 ti to the 4070 ti super was also crazy for me. That was my first high end card.",
      "What case is this?",
      "https://preview.redd.it/nwj2s30772pd1.jpeg?width=3024&format=pjpg&auto=webp&s=74e05837a584805c60b3d2f4e9e683f72b6539ba\n\nThis was me Friday. I sent my Radeon 7900xtx  back to power color for warranty because my pc kept crashing constantly (30-40x) in a 12 hour session for 2 months straight. We thought it was a driver issue specifically 24.6.1-24.7.1, and when 24.8.1 dropped for BO6 my game was still crashing, so sent that off and put a rtx 2060 super in and was getting 35-60fps and didn’t crash one time, just didn’t like the frames and I couldn’t wait potentially another 3 weeks for the 7900xtx, so I decided I liked nvidia and went and bought two cards one for me and one for my fiance.",
      "The Pro Art resembles the XFX MERC cards so much. It's basically \"What if XFX didn't do an oopsie and still made NVIDIA cards?\"",
      "Dayum, casually dropping 2k plus just for GPUs is big D energy",
      "Thanks! Looks sick! I am sure you will enjoy your new 4080 Super too! It is a beast of a card.",
      "Nostalgia....This is how I brought back my first gpu upgrade 1070ti.\n\nPut in the passenger seat with seat belt, Every time I stopped at a traffic light or junction on the way home I grinned and felt super happy about it.",
      "Why is that? Boring? Pointless?",
      "you do you but imo its high range. Its the first nvidia card that can do 4k60 without upscaling in most games.",
      "I took them off for the photo.",
      "Thats straight bullshit. Im implying the performance difference between the 4070 and 4070 ti super which is big. The ti super is not a mid range card. Its literally the third best card on the market together with the 7900 xt only 10-15% worse than the 4080 super/7900 xtx.",
      "I'm using the corsair 12VHPWR, it's pretty stiff but I managed a gentle bend that won't damage the cable and still looks good.",
      "I used to own this case, how did your maneuver the gpu connector? Did you get a right angle adapter?",
      "Really nice. I love Small form factor PCs.",
      "Thank you!",
      "Thanks, yeah it's a huge pgrade from my Arc.",
      "So you compare a 4070 with a 4070 ti super and say they are both midrange? While the ti super is like 30% faster than the 4070? that doesn’t make any sense."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "4080",
      "4080 super"
    ],
    "title": "Picked up the FE cheese grater",
    "selftext": "Msi 4080 Super Expert",
    "comments": [
      "It looks nice but it's kind of crazy they're charging $1150 for cooling and noise levels that are worse than the FE.",
      "I'm so glad I bought the 4090 FE on release day. Best videocard I've had in terms of build quality and performance when it comes to thermals. And I've been buying cards since the early 2000s.",
      "It looks nice but doesn't perform great. Not a good buy imo.",
      "Been trying to find a FE for years.",
      "😆 I appreciate that you can tease yourself a little.",
      "Not for over 1k, rip off",
      "now grate some garlic on that bitch",
      "Lmao no",
      "I meant, grate ;)",
      "Bought a humble 4070 super last week. Was shocked at the packaging. Used to get it in the same type box as a motherboard. Now it’s the size of a case, with a forcefield around it. Profit margins must be high.",
      "i don't know if they're still doing it, but around the 4090 launch they would give a \"reward\" in geforce experience's notification section, which was just a guaranteed purchase of an FE card.\n\ni barely used geforce experience and only had it installed for the overlay and it still gave me a purchase link.",
      "I can definitely see why people say cheese grater for that bottom side of the card 😅 over all pleased with the card and the aesthetics though!",
      "It is very similar, it's also pretty heavy compared to other cards I've owned/held",
      "😅",
      "Doesn't really matter for ada anyway, they all have excellent cooling even the slim cards",
      "Thanks!",
      "I remember those clown lips, they ended up removing them or changing the color to black. I hated them , bought a strix card instead cause of that",
      "Hey, great !",
      "I don’t get why they are allowed to have it so similar to the FE",
      "I personally went with zotac for my 4080 super, got it for msrp. Now I just gotta wait. And see who I can sell my 3080 too among my coworkers."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "4080",
      "4080 super"
    ],
    "title": "The most overkilled and interesting 4070Ti : the Galax RTX 4070 Ti OC Lab (PCB pics included)",
    "selftext": "I got myself something very rare outside of China that will complete my collection. This 4070Ti has a pcb that is even better than the 4070Ti Super and 4080 Super HOF.\nIt’s also to this day the fastest 4070Ti ever when overclocked (even using its aircooler). \nMore pics and benchmarks results can be found on my twitter @bl4ckdot",
    "comments": [
      "the cooler is so goddamn ugly lol\n\n&#x200B;\n\nwhite pcb is sick tho",
      "Because I have a 4090 for that task ? The point of this card isn't the performance / price ratio. It's how much one can push a specific GPU.",
      "Why get this when its nowhere near the shittiest 4080 super?",
      "Lol OP really said their Ferrari is in the shop lmao",
      "I don't need justification, specially when I collect stuff. I post here to share what people may never have seen. I'll never say \"here what you should buy, trust\"",
      "My Bad, I didnt really interpret it that way.\n\nThanks for clarifying.",
      "GT1030 :D I mainly use that card to display when benching CPU.\n\nhttps://preview.redd.it/qxsidwcodzic1.jpeg?width=3024&format=pjpg&auto=webp&s=093a4ba04974dc38243bf040390cedaebe3257ee",
      "Here what it looks like on Timespy : [NVIDIA GeForce RTX 4070 Ti video card benchmark result - Intel Core i9 processor 14900K,ASUSTeK COMPUTER INC. ROG MAXIMUS Z790 APEX ENCORE (3dmark.com)](https://www.3dmark.com/spy/45512120)",
      "Lmao the little guy in the last pic. what card is that one?",
      "Yep can go up to 366W with stock bios",
      "Get that brick out of here. Simping for the 1030",
      "You collect downvotes, OP collects GPUs - to each their own",
      "7300 CNY to my door. So around 950€ shipped from China",
      "That's a crazy good score for a 4070ti, almost matches my 7900XT in raster.",
      "Pretty sure this one will draw more than 285W.",
      "I get it, man. Why do we do anything that we do if not out of interest that brings us joy. I think it’s pretty cool 🤙",
      "I love a good burn 🔥 if I was rich I would be doing the same thing as OP",
      "Exactly my mindset when looking at the pics lol",
      "Roughly 55°C while benching",
      "Galax Hall of Fame series actually started in 2010 on low to mid end GPU to make them as strong / overkill as possible. Their first HOF GPU was the GTS 450, followed by the GTX 460 and then GTX 550Ti and 560Ti. They then made high end stuff but continued to make some smaller fun cards like the GTX 750Ti HOF or even the GTX 1060 HOF."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "rtx 4080",
      "4080"
    ],
    "title": "NVIDIA rumored to be preparing GeForce RTX 4080/4070 SUPER graphics cards - VideoCardz.com",
    "selftext": "",
    "comments": [
      "Will there be a 4070 Ti Super TI?",
      "4070 Super Titi",
      "Meh. I doubt they'll be at a better price point than existing cards.",
      "4070 super sweet spot if 16GB",
      "Hey! I’m sure they’ll put the price of the other cards up so they at least look lower priced",
      "Nah bro I prefer 4070 super TiTis.",
      "OOOOF. Would much rather have a 16GB 4070 Ti Super than my current 4070 Ti",
      "Super 4070 Super Ti²",
      "3090ti was released half a year before the 4000 series. There’s no rhyme or reason to Nvidia’s release schedule.",
      "They didn’t? There is no 2170 super",
      "Just as I bought a 4070.\n\nListen people, FOMO is right and you should always wait for the next big thing! Learn from my mistakes.\n\n/s",
      "The current cards are not selling well according to distributors and havent been with the exception of the 4090.\n\nThis is the same strategy as the 20 series where they way over valued their products. \n\nWhat they will do is release the super at the current price points and lower the old models to clear stock or hope to.",
      "That Twitter account was the one that leaked the 4060ti 16gb before anyone ever mentioned. And then leaked the date and price correctly in a later tweet.\n\nhttps://twitter.com/hongxing2020/status/1655768882320375808?t=NjoQaXGgd9qbFsx-nnxspg&s=19\n\nAlso Kop said there was no news yet last time he tweeted, didn't definitively say that there won't be a refresh.",
      "I just prefer super tits",
      "Well I mean, they haven’t been stopped from giving higher VRAM to worse cards before.",
      "And when you bought rtx 4070super then 1 year later they release rtx 5070 with 50% more powerful and you keep telling that buying rtx 4070s was mistake too .",
      "This has to be a joke",
      "The 3060 coming with more VRAM than the 3080 was a head scratcher",
      "Kopeit said there is no refresh , so this article is just click bait .",
      "Historically the super versions have been worse than the Ti versions. I'd be happily surprised if it was more than 12gb."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "4080",
      "4080 super"
    ],
    "title": "5700 xt to 4080 super",
    "selftext": "Can you identify which one is which?",
    "comments": [
      "The card your girlfriend told you not to worry about.",
      "Is that your tempered glass side panel on a stone countertop? Oo",
      "What can I say, I like to live on the edge of breaking my tempered glass panels at any moment.",
      "Yes. I too am interested in the girth.",
      "I don't like this trend at all, what happened with slim and slick new tech?",
      "5700XT is a different class of card than a 4080. The 4070 is much more similar in size.",
      "wow, would you mind showing us differences in thickness too?",
      "It’s a joke about how big the 4080 super is",
      "It literally says GeForce rtx",
      "terrifying",
      "how to break a tempered glass side panel",
      "Heat displacement",
      "Right one is the 5700XT I believe. I recognize the backplate.",
      "No risk, no fun :)",
      "The only joke is being a fanboy to a company who doesn't know you exist and doesn't care about you.",
      "80% heatsink",
      "Thermodynamics",
      "Performance cracks to streamline more airflow",
      "lol my 3090 died recently and i bought a 7800xt just to throw something in there for the next year until i build my next full rig.   the dif in the amount of heat and power my pc is generating is staggering xD the radiators on the top of my computer no longer feel like a space heater.   (granted I didn't put the 7800xt on the water loop but they are also still the exit fans so...). literally using like half the power of my last card though",
      "There are still some options like the Inno3D X3 or ASUS ProArt but the slimmer you get the hotter and louder the card runs."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "rtx 4080",
      "4080",
      "4080 super",
      "rtx 4080 super"
    ],
    "title": "GeForce RTX 5090 Review Megathread",
    "selftext": "# GeForce RTX 5090 Founders Edition reviews are up.\n\nhttps://preview.redd.it/3568lwrnwqee1.jpg?width=3840&format=pjpg&auto=webp&s=30ca4f255f94899838a70ab1168949437d3e03fd\n\n# Below is the compilation of all the reviews that have been posted so far. I will be updating this continuously throughout the day with the conclusion of each publications and any new review links. This will be sorted alphabetically.\n\n# Written Articles\n\n# [Babeltechreviews](https://babeltechreviews.com/nvidia-geforce-rtx-5090-founders-edition-review/)\n\n>For the Blackwell RTX 50 series launch, NVIDIA strategically chose to introduce their flagship model first, launching the GeForce RTX 5090 ahead of other models to set a high benchmark in performance. Following this release, other models like the RTX 5080 and RTX 5070 are set to be launched, all of which we assume will also be impressive with DLSS 4 and their new design. The RTX 5090 remains the pinnacle in terms of raw power and capabilities and is in a class of its own, alongside its high price tag.\n\n>The NVIDIA GeForce RTX 5090 Founders Edition’s powerful performance make it an essential upgrade for enthusiasts and professionals aiming to push the limits of what’s possible in their digital environments. Purists will not enjoy DLSS 4 and will want a much larger raw performance jump, but for those that do the performance uplift will make you drop your jaw just like it did to ours. We remember titles like Hogwarts Legacy having performance issues at launch and with DLSS 4 enabled we saw incredibly high gains of 301.6 AI generated FPS performance difference over its raw power. Nothing can replace proper optimization but expanding the capabilities of a game to perform in such large amounts is amazing.\n\n# [Digital Foundry Article](https://www.eurogamer.net/digitalfoundry-2025-nvidia-geforce-rtx-5090-review)\n\n# [Digital Foundry Video](https://www.youtube.com/watch?v=Dk3fECI-fmw)\n\n>Going into this review, it was clear that there was some trepidation that the RTX 5090 wouldn't offer enough of a performance advantage over its predecessor when it comes to raw frame-rates, ie without the multi frame generation tech that Nvidia leaned heavily on in its pre-release marketing. These are justifiable concerns - after all, there's no die shrink to accompany this generation of processors, and pushing more power can only get you so far.\n\n>Thankfully - for those that want to justify upgrading to a $2000+ graphics card - the beefier design and faster GDDR7 memory do deliver sizeable gains over the outgoing 4090 flagship, measured at around 31 percent on average at 4K. The differentials are understandably smaller when you look at lower resolutions - just 17 percent at 1080p, though anyone considering the 5090 is probably unlikely to be rocking a 1080p display. Nvidia, Intel, AMD and Sony have all spoken about the slowing progress in terms of silicon price to performance, and we can see why all four companies are now [looking to machine learning](https://www.eurogamer.net/digitalfoundry-2024-sony-ps5-pro-tech-interview-with-mark-cerny-and-mike-fitzgerald) technologies to shore up generational advancements.\n\n>Speaking of which, DLSS 4's multi frame generation is an effective tool for pushing frame-rates - though arguably not *performance* to higher levels. On the RTX 5090, it's best used along similarly high-end 4K 144Hz+ monitors, so it's no surprise that Nvidia and its partners ensured that reviewers had access to 4K 240Hz screens for their testing. If you're lucky enough to be in that situation, you can use MFG to essentially max out your monitor's refresh rate, with a choice of 1x, 2x or 3x frame generation.\n\n>There's of course a trade-off in terms of latency, but it's smaller than you might think - and once you've already enabled frame generation, knocking it up an extra level has only a small impact on thos latency figures. For example, in [Cyberpunk 2077](https://www.eurogamer.net/games/cyberpunk-2077) with RT Overdrive (path tracing), we saw frame-rates go with 94.5fps with DLSS upscaling to 286fps when adding 4x multi frame generation, a \\~3x multiplier at the cost of \\~9ms of added latency (26ms vs 35ms). If you have a 4K 240Hz monitor, that might be a trade worth taking - and of course, you're more than free to ignore frame generation and knock back other settings instead to get performance to a level you're happy with.\n\n# [Guru3D](https://www.guru3d.com/review/review-nvidia-geforce-rtx-5090-reference-edition/)\n\n>The RTX 5090 features an advanced rendering engine that pushes past previous limits with the help of its  21,760 CUDA cores. This means smoother and faster gameplay with more realistic environments, creating an immersive experience. The RTX 50 series introduced a new generation of Ray tracing and Tensor cores. These aren’t just numbers on a spec sheet – they represent a leap in efficiency and power. Located close to the shader engine, these cores work tirelessly to deliver distinctive outputs. Even though Tensor cores can be tricky to measure, their impact is unmistakable, especially when paired with DLSS3.5 and new DLSS4 with MFG  technology that delivers impressive results. The GeForce RTX 5090 is not just an enthusiast-class card; it's a versatile powerhouse. Whether playing games at 2K (2560x1440) or better yet, game at 4K (3840x2160), it offers superlative performance at every resolution. This makes it an outstanding choice for gamers who seek both quality and speed, transporting them into new realms of interactive entertainment\n\n>Depending on the game title this value can greatly differ! However, on average you're looking at 25% maybe 30% more traditional rendering performance. The thing is though, NVIDIA has invested a lot of the transistor budget into AI, Deeplearning and Neural shading. We've presented the numbers with DLSS4 and when you enable frame generation mode at 4x, the performance is astounding. The reality is that we are reaching physical limits where traditional methods of increasing performance are becoming harder than ever. Chips would have to grow even larger, power consumption would skyrocket, and costs would soar. Imagine a future where every attempt to push technology further leads to larger, more power-hungry chips that become increasingly expensive. As we encounter these boundaries, think creatively and seek new solutions. Instead of following a path that leads to dead ends, this challenge invites us to innovate and discover groundbreaking ideas such as DLSS4 and MFG.\n\n>If you factor out pricing and energy consumption, it's gonna be hard to not be impressed with the GeForce RTX 5090. The card drips and oozes performance and it all packs into a two-slot form factor. On the traditional shader rasterizer part, it's still a good notch faster than RTX 4090, however, if you are savvy with technologies like DLSS4 offers, the sky is the limit. We do hope to see more backwards compatibility with DLSS 4 so that older games will get this new tech included as well. DLSS4 is not perfect though, yes butter smooth, but in Alan Wake 2 for example the scene rendered was fantastic but we; see birds flying over in the sky leaving a weird hale trail. The scene was otherwise very nice though.  The Blackwell GPU architecture of the 5090 demonstrates proficient performance. It boasts about 1.25 to sometimes 1.50 times the raw shader performance compared to its predecessor, along with enhanced Raytracing and Tensor core capabilities.\n\n# [Hot Hardware](https://hothardware.com/reviews/nvidia-geforce-rtx-5090-review)\n\n>NVIDIA's GeForce RTX 5090 is the fastest, most powerful, and feature-rich consumer GPU in the world as of today, period. There’s no other way to put it. The NVIDIA GeForce RTX 5090 Founders Edition card itself is also a refined piece of hardware. To design a card that offers significantly more performance than an RTX 4090, at much higher power levels, in a roughly 33% smaller form factor is no small feat of engineering. The card also looks great in our opinion. On its own, the GeForce RTX 5090 is currently unmatched in the consumer GPU market – nothing can touch it in terms of performance, with virtually any workload – AI, content creation, gaming, you name it.\n\n>It's not all sunshine and rainbows, though. In many cases, the GeForce RTX 5090 offered nearly double the performance of its predecessor (RTX 3090) when it debuted, at lower power, while using the exact same settings and workloads. If you compare the GeForce RTX 5090 to the RTX 4090 at like settings, however, the RTX 5090 is “only” about 25% - 40% faster and consumes more power. The RTX 5090’s $1,999 MSRP is also significantly higher than the 4090’s $1,599 price tag. Considering the Ada and [Blackwell GPUs](https://hothardware.com/reviews/nvidia-rtx-blackwell-architecture-overview) at play here are manufactured on the same TSMC process node, NVIDIA was still able to move the needle considerably, but the GeForce RTX 5090 doesn’t represent the same kind of monumental leap the RTX 4090 did when it launched, if you disregard its new rendering technologies at least.\n\n>You can’t disregard those new capabilities, though. Neural Rendering, DLSS 4 with multi-frame generation, the updated media engine, and all that additional memory and memory bandwidth all have to be taken into consideration. When playing a game that can leverage Blackwell’s new features, the GeForce RTX 5090 can indeed be more than twice as fast as [the RTX 4090](https://hothardware.com/reviews/nvidia-geforce-rtx-4090-gpu-review).\n\n>The use of frame generation has spurred much discussion since its introduction, and we understand the concerns regarding input latency and potential visual artifacts that come from using frame-gen. But the fact remains, using AI and machine learning to boost game and graphics performance in the most effective and efficient way forward at this time. Moving to more advanced manufacturing process nodes doesn’t offer the kind of power, performance and area benefits it once did, so boosting performance must ultimately come mostly from architectural and feature updates. And everyone in the PC graphics game is turning to AI. We specifically asked about the importance of traditional rasterization moving forward and were told development is still happening, and it will remain necessary for “ground truth” rendering to train the models, but ultimately AI will be generating more and more frames in the future.\n\n# [Igor's Lab](https://www.igorslab.de/en/nvidia-geforce-rtx-5090-founders-edition-review-the-600-watt-powerhouse-in-gaming-and-lab-tests/)\n\n>The GeForce RTX 5090 delivered impressive results in practical tests. The card achieved significantly higher frame rates in Full HD, WQHD and Ultra HD compared to the RTX 4090, especially with DLSS and ray tracing support enabled. The multi-frame generation enables consistent frame pacing and reduces noticeable latency, which is particularly beneficial in fast and dynamic gaming scenarios. The improvements in patch tracing and ray tracing ensure a more realistic representation of complex scenes. Games such as Cyberpunk 2077 and Alan Wake 2 visibly benefit from the technological advances and show that the Blackwell architecture has the potential to smoothly display the most demanding graphic effects.\n\n>The image quality achieved by the Transformer models in DLSS 4 is another important aspect. Where previously a clear trade-off had to be made between performance and quality, DLSS 4 combines both in an impressive way. Most notably, the new Performance setting offers almost the same visual quality as previous Quality modes. This is achieved through advanced AI-powered models that capture both local details and global relationships to produce a near-native image representation. The smooth and detailed rendering at significantly higher frame rates shows that DLSS 4 is an essential part of the RTX 5090, further underlining its performance. There will be a detailed practical test on this from our monitor professional Fritz Hunter.\n\n>In my opinion, the GeForce RTX 5090 is an impressive graphics card that shows just how far GPU technology has come. The new features in particular, such as DLSS 4 and Transformer-supported image optimization, set new standards. The performance of this card is simply breathtaking, be it in games in Ultra HD with active patch tracing or in demanding AI-supported applications. It is remarkable how NVIDIA has managed to find the balance between graphical excellence and innovative technologies. Another outstanding aspect is the ability of DLSS 4 to achieve an image quality that is almost indistinguishable from native resolutions, while at the same time increasing performance. The change from “Quality” to “Performance” as a standard option is like a revolution in the way we perceive image enhancement. The smooth display, combined with an incredible level of detail, takes the gaming experience to a new level.\n\n# [KitGuru Article](https://www.kitguru.net/components/graphic-cards/dominic-moass/nvidia-rtx-5090-review-ray-tracing-dlss-4-and-raw-power-explored/)\n\n# [KitGuru Video](https://www.youtube.com/watch?v=8wEXrZSnsRM)\n\n>Much was made of the performance ahead of launch, people were breaking out rulers and [pixel counting Nvidia's bar charts](https://www.reddit.com/r/nvidia/comments/1hvvrqj/50_vs_40_series_nvidia_benchmark_exact_numbers/), but after thorough testing today we can confirm native rendering performance has increased in the ballpark of 30% over the RTX 4090 when testing at 4K. That makes the RTX 5090 64% faster on average compared to AMD's current consumer flagship, the RX 7900 XTX, while it's also a 71% uplift over the RTX 4080 Super. Ray tracing also scales similarly, given we saw the exact same 29% margin over the RTX 4090 in the eight RT titles we tested.\n\n>Those are the sort of performance increases you can expect at 4K, but the uplift does get progressively smaller as resolution decreases. Versus the RTX 4090, for instance, we saw smaller gains of 22% at 1440p and 18% at 1080p. Now, I don't expect many people will be gaming at native 1080p on an RTX 5090, but it's worth bearing that in mind if you'd typically game with DLSS Super Resolution. After all, using its performance mode at 4K utilises a 1080p internal render resolution. Clearly this is a card designed for 4K – and perhaps even above – but that performance scaling at lower resolutions could be something to bear in mind.\n\n>Of course, whether or not you are impressed by those generational gains depends entirely on your perspective – an extra 30% over the 4090 could sound great, or it could be a disappointment. The main thing from my perspective as a reviewer is to give you, the reader, as much information as possible to allow you to make an informed decision, and I think I have done that today.\n\n>Gamers do get the extra value add of DLSS 4, specifically Multi Frame Generation (MFG), which is a new feature exclusive to the RTX 50-series. I spent a fair bit of time testing MFG as part of this review and I think if you already got on with Frame Generation on the RX 40-series, you'll probably find a lot to like with MFG. It's been particularly useful in enabling 4K/240Hz gaming experiences that wouldn't otherwise be possible – such as high frame rate path tracing in Cyberpunk 2077 – and with the growing [4K OLED monitor segment](https://www.kitguru.net/components/matthew-wilson/ces-2025-leo-gets-a-closer-look-at-new-msi-oled-monitors-dual-system-case-and-more/), that's certainly good news.\n\n>However, it's definitely not a perfect technology as the discerning gamer will still notice some fizzling or shimmering that isn't otherwise there, while latency scaling is still backwards compared to what we've come to expect – in the sense that latency actually *increases* as frame rate increases with MFG, rather than latency decreasing. That means some will find it problematic as the *feel* doesn't always match up to the visual fluidity of the increased frame rate.\n\n>It is great to see Nvidia is improving other aspects of DLSS, though, with its new Transformer-based models of Super Resolution and Ray Reconstruction. Not only do these improve things like ghosting and overall level of detail compared to the previous Convolutional Neural Network (CNN) model, but this upgrade actually applies to *all* RTX GPUs, right the way back to the 20-series. There's even a possibility that Multi Frame Gen [might come to older cards](https://www.kitguru.net/gaming/joao-silva/nvidia-multi-frame-generation-could-come-to-rtx-30-series-gpus/) given that Nvidia hasn't explicitly ruled it out, but personally I'd be surprised to see that happen given it currently acts as an incentive to upgrade to the latest and greatest.\n\n>We can't end this review without a discussion of Nvidia's Founders Edition design, either. This is a *highly* impressive feat of engineering, considering it's a mere dual-slot thickness yet it is able to comfortably tame 575W of power. We saw the GPU settling at 72C during a thirty-minute 4K stress test, while the VRAM hit 88C, which is slightly warmer but still well within safe limits. I love to see the innovation in this department, as when pretty much every AIB partner is slapping quad-slot coolers onto their 5090s, this is a refreshing step back to a time when GPUs didn't cover the entire bottom-half of your motherboard.\n\n# [LanOC](https://lanoc.org/review/video-cards/9132-nvidia-rtx-5090-founders-edition)\n\n>Performance for the new generation of cards in my testing had the RTX 5090 outperforming the RTX 4090 by around 32% which is right in line with the increase in CUDA cores for the card. There were some tests which saw an even bigger increase and the RTX 5090 was at the top of the chart across the board in every applicable test. What was even more impressive to me was the improvements with DLSS 4, the performance difference that it can make is sometimes shocking, but on top of that Nvidia has improved the smoothness and picture quality. At the end of the day, there wasn’t anything that I threw at the RTX 5090 that slowed it down, but if you do run into something that it can’t handle DLSS 4 is going to fix you right up. I did see some bugs in my DLSS testing, mostly when trying down resolutions, but I suspect some of those will be smoothed out once the updates are released. The biggest issue I ran into performance-wise was that a few of our benchmarks just wouldn’t run at all and they were all OpenCL. Nvidia is aware and is working to get support for those tests.\n\n>The big increase in performance without any change in manufacturing size does have the RTX 5090 having a significantly higher power consumption. I saw it pulling up to 648 watts at peak, combine that with today's highest-end CPUs and we are swinging back to needing high-wattage power supplies. Speaking of power, the power connection has been improved in a whole list of ways including moving from the original 12VHPWR connection to the changed design that is called 12V-2-6. It looks the same and all of the power supplies will still connect. But they have changed the pin heights to get a better connection and the sense pins are shorter and are more likely to catch when the plug isn’t connected all the way. On top of that Nvidia’s card design has recessed the connection down into the card and angled it to reduce any strain on the connection. They have also included a much nicer power adapter as well. All of that power does mean there is more heat but the double blow-through design handled it surprisingly well running similarly in temperatures to the RTX 4090 Founders Edition even with a thinner card design and a lot more wattage going through.\n\n# [OC3D Article](https://overclock3d.net/reviews/gpu_displays/nvidia-rtx-5090-founders-edition-review/)\n\n# [OC3D Video](https://www.youtube.com/watch?v=4oDxME5APa8)\n\n>Speaking of DLSS 4, that comes with the big ticket item in the Blackwell release, Multi Frame Generation. By refining the algorithm, and giving the card newer generations of hardware, the RTX 5090 can now generate three extra frames from a single frame rendered. As you could see from our results in Alan Wake II, Cyberpunk 2077 and Star Wars Outlaws, the effect is considerable. Cyberpunk 2077, with an open world, neon soaked, usually wet and thus reflective environment is about as good as games can look. Turn on path-tracing and it’s nearly real life. That path-tracing has a massive performance cost though. On the RTX 4090 you get 133 FPS @ 4K without it, 40 FPS with it.\n\n>Even turning DLSS and Frame Gen on doesn’t recoup all that, maxing out at 104. Click through the Multi Frame Gen settings on the RTX 5090 though and that number hits 241 FPS. With, and we cannot state this enough, NO loss in visual fidelity. That’s Cyberpunk at 4K with pathed ray-tracing turned on and a frame rate you’d require a very expensive monitor (4K@240Hz!) to appreciate fully. When CD Projekt Red’s Magnum Opus first appeared you could get smoother frame rates from a flipbook.\n\n>All of which returns us to the way we’ve tested how we have. Because in regular mode, with DLSS turned on and, at most, a single frame generated as is currently the way, the RTX 5090 is another big step forwards on the best of the current cards. Anything which can stomp on a RTX 4090 is crazy good. That the RTX 5090 Founders Edition can do that, and then has much further to go with the benefits of MFG, makes any claims about it being a purely software-based improvement look as ill-informed as they do.\n\n>Already that’s more than enough to make the Nvidia RTX 5090 Founders Edition a Day One recommendation to anyone serious about their gaming. We haven’t even mentioned the crazy low latencies – and thus higher KD ratio – of the upgraded Reflex 2 technology. Or RTX Neural Faces that can convert a 2D picture into a 3D character. We’ve not discussed, because it’s embryonic, the potential of the AI powered NPCs with the Nvidia Ace technology. Or the extra broadcast features, faster encoding and decoding, and all the AI calculation benefits having this much power at your disposal can bring.\n\n>Simply put, the Nvidia RTX 5090 has coalesced all the current thinking on AI, performance, sharpness, and generative content into a single card that blows the doors off anything on the market. It’s the future, today.\n\n# [PC Perspective](https://pcper.com/2025/01/nvidia-geforce-rtx-5090-founders-edition-review/)\n\n>Well, NVIDIA has topped NVIDIA. Once again, and with zero competition at the high end, GeForce reigns supreme. And while raster performance has risen, DLSS 4 is the star of the show with the RTX 50 Series, now supporting up to ***four*** generated frames per rendered frame (!) if you dare. Yes, the price for NVIDIA’s flagship has risen again, from $1599 to $1999 this generation, but those who want the fastest graphics card in the world will surely buy it anyway.\n\n# [PC World Article](https://www.pcworld.com/article/2585806/nvidia-geforce-rtx-5090-review.html)\n\n# [PC World Video](https://www.youtube.com/watch?v=_J5wDq2ba2E)\n\n>The GeForce RTX 4090 stood unopposed as the ultimate gaming GPU since the moment it launched. No longer. The new Blackwell generation uses the same underlying TSMC 4N process technology as the RTX 40-series, so Nvidia couldn’t squeeze easy improvements there. Instead, the company overhauled the RTX 5090’s instruction pipeline, endowed it with 33 percent more CUDA cores, and pushed it to a staggering 575W TGP, up from the 4090’s 450W. Blackwell also introduced a new generation of RT and AI cores.\n\n>Add it all up and the RTX 5090 is an unparalleled gaming beast — though the effects hit different depending on whether or not you’re using RTX features like ray tracing and DLSS.\n\n>In games that *don’t* use ray tracing or DLSS, simply brute force graphics rendering, the RTX 5090 isn’t much more than a mild generational performance upgrade. It runs an average of 27 percent faster in those games — but the splits swing wildly depending on the game: *Cyberpunk 2077* is 50 percent faster, *Shadow of the Tomb Raider* is 32 percent faster, and *Rainbox Six Siege* is 28 percent faster, but *Assassin’s Creed Valhalla* and *Call of Duty: Black Ops 6* only pick up 15 and 12 percent more performance, respectively.\n\n>Much like DLSS, DLSS 2, and DLSS 3 before it, the [new DLSS 4 generation](https://go.skimresources.com/?id=111346X1569483&xs=1&url=https://www.nvidia.com/en-us/geforce/news/dlss4-multi-frame-generation-ai-innovations/&xcust=2-1-2585806-1-0-0-0-0&sref=https://www.pcworld.com/article/2585806/nvidia-geforce-rtx-5090-review.html) is an absolute game-changer. Nvidia’s boundary-pushing AI tech continues to look better, run faster, and now *feel* smoother. It’s insane.\n\n>Nvidia made two monumental changes to DLSS to coincide with the RTX 50-series release. First, all DLSS games will be switching to a new “Transformer” model from the older “Convolutional Neural Network” behind the scenes, on all RTX GPUs going back to the 20-series.\n\n>More crucially for the RTX 5090 (and future 50-series offerings), DLSS 4 adds a new Multi Frame Generation technology, building upon the success of [DLSS 3 Frame Gen](https://www.pcworld.com/article/1662185/what-is-dlss-3-nvidia-geforce-rtx-ai-feature-explained.html). While DLSS 3 uses tensor cores to insert a single AI-generated frame between GPU-rendered frames, supercharging performance, MFG inserts *three* AI frames between each GPU-rendered frame (which itself may only be rendering an image at quarter resolution, then using DLSS Super Resolution to upscale that to fit your screen).\n\n>Bottom line: DLSS 4 is a stunning upgrade you *must* play around with to fully appreciate its benefits. It’s literally a game-changer, once again — though we’ll have to see if it feels *this* sublime on lower-end Nvidia cards like the more affordable RTX 5070.\n\n>In a vacuum, the RTX 5090 delivers around a 30 percent average boost in gaming performance over the RTX 4090. That’s a solid generational improvement, but one we’ve seen throughout history delivered at the same price point as the older, slower outgoing hardware. Nvidia asking for an extra $500 on top seems garish and overblown from that perspective.\n\n>While I wouldn’t recommend upgrading to this over the RTX 4090 for gaming (unless you’re giddy to try DLSS 4), it’s a definite upgrade option for the RTX 3090 and anything older. The 4090 was 55 to 83 percent faster than the 3090 in games, and the 5090 is about 30 percent faster than *that*, with gobs more memory.\n\n>At the end of the day, nobody needs a $2,000 graphics card to play games. But if you *want* one and don’t mind the sticker price, this is easily the most powerful, capable graphics card ever released. The GeForce RTX 5090 is a performance monster supercharged by DLSS 4’s see-it-to-believe it magic.\n\n# [Puget Systems (Content Creation Review)](https://www.pugetsystems.com/labs/articles/nvidia-geforce-rtx-5090-content-creation-review/)\n\n>Overall, the RTX 5090 is a beast of a card. Drawing 575 W, with 32 GB VRAM and a $2000 price tag (at least), it is overkill for many use cases. However, it excels at GPU-heavy workloads like rendering and provides solid performance improvements over the last-gen 4090 in many applications. There are some issues with software compatibility that need to be worked out, but historically, NVIDIA has been great about ensuring its products are properly supported throughout the software ecosystem.\n\n>For **video editing and motion graphics**, the RTX 5090 performs well, with 10-20% improvements across the board. In particular sub-tests, where the workload is primarily GPU bound, we see up to 35% performance advantages over the previous-generation 4090. However, the area we are most excited about is actually the enhanced codec support for the NVENC/NVDEC engines. In DaVinci Resolve, the H.265 4:2:2 10-bit processing was more than twice as fast as software decoding and exceeded even what we see from Intel Quick Sync. Even if the 5090 is more than a workload requires, we are excited to see what this means for upcoming 50-series cards.\n\n>In **rendering applications**, real-time and offline, the 5090 pushes its lead over previous-generation cards even further. It is 17% faster than the 4090 in our Unreal Engine benchmark while also offering more VRAM for heavy scenes. Offline renderers, such as V-Ray and Blender, score 38% and 35% higher than 4090, respectively. This more than justifies the $2,000 MSRP, especially factoring in the added VRAM. The lack of support for some of our normally-tested rendering engines is non-ideal, but we are hopeful NVIDIA will address that issue shortly.\n\n>NVIDIA’s new GeForce RTX 5090 is a monster of a GPU, delivering best-in-class performance alongside a rich feature set. However, it comes along with a huge price tag of $2,000 MSRP; ad likely higher for most buyers, as AIB cards will be a good bit more expensive than that. It also requires that your computer can support that much power draw and heat. If you need the most powerful consumer GPU ever made, this is it. Otherwise, we are excited by what this promises for the rest of the 50-series of GPUs and look forward to testing those in the near future.\n\n# [Techpowerup](https://www.techpowerup.com/review/nvidia-geforce-rtx-5090-founders-edition/)\n\n>At 4K resolution, with pure rasterization, without ray tracing or DLSS, we measured a 35% performance uplift over the RTX 4090. While this is certainly impressive, it is considerably less than what we got from RTX 3090 Ti to RTX 4090 (+51%). NVIDIA still achieves their \"twice the performance every second generation\" rule: the RTX 5090 is twice as fast as the RTX 3090 Ti. There really isn't much on the market that RTX 5090 can be compared to, it's 75% faster than AMD's flagship the RX 7900 XTX. AMD has confirmed that they are not going for high-end with RDNA 4, and it's expected that the RX 9070 Series will end up somewhere between RX 7900 XT and RX 7900 GRE. This means that RTX 5090 is at least twice as fast as AMD's fastest next-generation card. Compared to the second-fastest Ada card, the RTX 4080 Super, the performance increase is 72%--wow!\n\n>There really is no question, RTX 5090 is the card you want for 4K gaming at maximum settings with all RT eye candy enabled. I guess you could run the card at 1440p at insanely high FPS, but considering that DLSS 4 will give you those FPS even at 4K, the only reason why you would want to do that is if you really want the lowest latency with the highest FPS.\n\n>Want lower latency? Then turn on DLSS 4 Upscaling, which lowers the render resolution and scales up the native frame. In the past there were a lot of debates where DLSS upscaling image quality is good enough, some people even claimed \"better than native\"--I strongly disagree with that--I'm one of the people who are allergic to DLSS 3 upscaling, even at \"quality.\" With Blackwell, NVIDIA is introducing a \"Transformers\" upscaling model for DLSS, which is a major improvement over the previous \"CNN\" model. I tested Transformers and I'm in love. The image quality is so good, \"Quality\" looks like native, sometimes better. There is no more flickering or low-res smeared out textures on the horizon. Thin wires are crystal clear, even at sub-4K resolution! You really have to see it for yourself to appreciate it, it's almost like magic. The best thing? DLSS Transformers is available not only on GeForce 50, but on all GeForce RTX cards with Tensor Cores! While it comes with a roughly 10% performance hit compared to CNN, I would never go back to CNN. While our press driver was limited to a handful of games with DLSS 4 support, NVIDIA will have around 75 games supporting it on launch, most through NVIDIA App overrides, and many more are individually tested, to ensure best results. NVIDIA is putting extra focus on ensuring that there will be no anti-cheat drama when using the overrides.\n\n# [The FPS Review](https://www.thefpsreview.com/2025/01/23/nvidia-geforce-rtx-5090-founders-edition-video-card-review/)\n\n>There is a lot to unpack in regards to the NVIDIA GeForce RTX 5090, and GeForce RTX 50 series from NVIDIA. A lot of technologies have been debuted, and there are a lot of features to test that we simply cannot do in one single review. In today’s review, we focused on the gameplay performance aspect of the GeForce RTX 5090.\n\n>We focused on the GeForce RTX 5090 performance, so subsequent reviews will focus on the rest of the family, and we’ll have to see how they fit into the overall opinion of the RTX 50 series family this generation. For now, we can look at the GeForce RTX 5090 as the flagship of the RTX 50 series, and what it offers for the gameplay experience at a steep price of $1,999, a 25% price bump over the previous generation GeForce RTX 4090.\n\n>If we look back at the average performance gains we saw in just regular raster performance, we experienced performance that ranged from 19%-48%, but there were a lot of common performance gains in the 30-33% range. We did have some outliers that were lower, and some higher, depending on the game and settings. We generally saw gains in the 30% region with Ray Tracing enabled, where scenarios were more GPU-bound.\n\n>We think one problem that is being encountered is that the NVIDIA GeForce RTX 5090 is becoming CPU-bound in a lot of games. The data tells us that perhaps even our AMD Ryzen 7 9800X3D is holding back the potential of the GeForce RTX 5090. Therefore, as newer, faster CPU generations are released, the GeForce RTX 5090’s performance advantage may increase over time. The GeForce RTX 5090 has powerful specifications, but the performance advantage we are currently seeing seems shy of what should be expected with those specifications. It may very well be the case that it is being held back, and it has more potential with better-optimized games or faster CPUs. Time will tell on that one.\n\n>As it stands right now, you should always buy based on the current level of performance, not what might happen. Therefore, at this time you are seeing about a 33% gameplay performance advantage average, but with a 25% price increase, making the price-to-performance value very narrow. The facts are, that the GeForce RTX 5090 has no competition, it does offer the best gameplay performance you can get on the desktop.\n\n# [Tomshardware](https://www.tomshardware.com/pc-components/gpus/nvidia-geforce-rtx-5090-review)\n\n>The RTX 5090 is a lot like this initial review: It's a bit of a messy situation — a work in progress. We're not done testing, and Nvidia isn't done either. Certain games and apps need updates and/or driver work. Nvidia usually does pretty good with drivers, but new architectures can change requirements in somewhat unexpected ways, and Nvidia needs to continue to work on tuning and optimizing its drivers. We're also sure Nvidia doesn't need us to tell it that.\n\n>Gaming performance is very much about running 4K and maxed out settings. If you only have a 1440p or 1080p display, you're better off saving your pennies and upgrading you monitor — and probably the rest of your PC as well! — before spending a couple grand on a gaming GPU.\n\n>Unless you're also interested in non-gaming applications and tasks, particularly AI workloads. If that's what you're after, the RTX 5090 could be a perfect fit.\n\n>The RTX 5090 is the sort of GPU that every gamer would love to have, but few can actually afford. If we're right and the AI industry starts picking up 5090 cards, prices could end up being even higher. Even if you have the spare change and can find one in stock (next week), it still feels like drivers and software could use a bit more time baking before they're fully ready.\n\n>Due to time constraints, we haven't been able to fully test everything we want to look at with the RTX 5090. We'll be investigating the other areas in the coming days, and we'll update the text, charts, and the score as appropriate. For now, the score stands as it is until our tests are complete.\n\n# [Computerbase - German](https://www.computerbase.de/artikel/grafikkarten/nvidia-geforce-rtx-5090-test.91081/)\n\n# [HardwareLuxx - German](https://www.hardwareluxx.de/index.php/artikel/hardware/grafikkarten/65361-die-geforce-rtx-5090-founders-edition-im-test.html)\n\n# [PCGH - German](https://www.pcgameshardware.de/Geforce-RTX-5090-Grafikkarte-281029/Tests/Reviews-Benchmarks-Vergleich-RTX-4090-1463971/)\n\n# [Elchapuzasinformatico - Spanish](https://elchapuzasinformatico.com/2025/01/nvidia-geforce-rtx-5090-founders-edition-review/)\n\n\\--------------------------------------------\n\n# Video Review\n\n# [Der8auer](https://www.youtube.com/watch?v=La4EdRPT_Mg)\n\n# [Digital Foundry Video](https://www.youtube.com/watch?v=Dk3fECI-fmw)\n\n# [Gamers Nexus Video](https://www.youtube.com/watch?v=VWSlOC_jiLQ)\n\n# [Hardware Canucks](https://www.youtube.com/watch?v=5TJk_P2A0Iw)\n\n# [Hardware Unboxed](https://www.youtube.com/watch?v=eA5lFiP3mrs)\n\n# [JayzTwoCents](https://www.youtube.com/watch?v=ulUZ7bf_MXI)\n\n# [KitGuru Video](https://www.youtube.com/watch?v=8wEXrZSnsRM)\n\n# [Level1Techs](https://www.youtube.com/watch?v=nryZwnVYpns)\n\n# [Linus Tech Tips](https://www.youtube.com/watch?v=Q82tQJyJwgk)\n\n# [OC3D Video](https://www.youtube.com/watch?v=4oDxME5APa8)\n\n# [Optimum Tech](https://www.youtube.com/watch?v=5YJNFREQHiw)\n\n# [PC World Video](https://www.youtube.com/watch?v=_J5wDq2ba2E)\n\n# [Techtesters](https://www.youtube.com/watch?v=srQHBeWnQzw)\n\n# [Tech Notice (Creators Benchmark)](https://www.youtube.com/watch?v=Ah0JxguHdp4)\n\n# [Tech Yes City](https://www.youtube.com/watch?v=Lv-lMrKiwyk=)",
    "comments": [
      "I am whelmed.",
      "As someone with a 30 series gpu that never expected to upgrade after only 1 gen and left potential 40 series buyers alone in 2022 and didn't judge their potential upgrades, id like to express that 4090 owners that ponder upgrading after 1 gen and then when they realize it's not worth it for them BUT their ego can't handle that there's a better gpu available, start make posts saying they're glad they won't be upgrading are annoying as fuck. We get it, you want the best at all times but now that you don't want to dish out the money for a smaller relative upgrade you want to shit on a product that would be a much bigger upgrade for everyone else that doesn't look to upgrade every generation.",
      "https://preview.redd.it/uk4qaluuiree1.png?width=845&format=png&auto=webp&s=7139c38c5162a46e822fac34e9298fa6b4a4d8ec\n\nFeels accurate",
      "RTX 4090 Ti indeed",
      "+25% cost for +25% the performance and +50% the pooooowwwweeerrrrrr",
      "In summary, 30% average uplift in 4K. Old games or UE5 games don't get any significant uplift so there is only a couple of examples in the gray zone like TLoU or Cyberpunk that experience a worthwhile \\~50% uplift.\n\nFor anyone on the 4090 there isn't any point to upgrading right now, besides a few exceptions there aren't enough games demanding enough to utilize the card's full potential so you'll only waste money trying to get it for scalped/paper launch prices.",
      "I like how everyone here is wondering if they should upgrade their 3090 or 4090. I am just trying to decide if I should upgrade my 1080.",
      "https://preview.redd.it/0s0q58ntzsee1.png?width=1018&format=png&auto=webp&s=4cd9ce969154258d47b6f511c7b3e28d9ee695d8\n\nYou're going to have to go water or you need a gargantuan case with half a dozen fans if you want to pair the 5090 with big air.",
      "Terrible coil whine. My number one takeaway",
      "It's a 4090TI good if moving from 3090, lower spec 40 series or older cards, pointless for 4090 owners.",
      "We need real world testing!  wtf uses 1600 PSUs and open cases?\n\nPut the damn thing in a case (fractal north, lancool 7, etc) and then tell me noise, temps, wattage.",
      "So 100%+ increase over a 3090 at 4K. I’m in.",
      "Damn, the FE is loud and hot according Techpowerup, might need to look at AIBs for this ! Always felt like two slots was pushing it with 600W GPU.",
      "Well it was near, the 1080Ti was 27% faster than the 1080\n\nThough the 5090 is faster than that vs the 4090",
      "Yes, very sorry you will have to “keep your 4080”",
      "Everywhere else is saying around 75c and quiet fans, be curious to see why Techpowerup is getting different results. For a dual-slot cooler dissipating up to 600w that's insanely good. Obviously the coil whine is bad though...",
      "Are there any reviews for VR for the 5090 out there yet?  I haven't been able to find any.",
      "One of the things that always bothered me about some sites is when they say “we are using the medium preset with medium ray tracing”. wtf…with a $2000 card you are testing medium? Turn everything on and let’s see.\n\nAlso I only perused the various articles but I want to see this compared to the 4090 with and without framegen. A lot of sites don’t seem to offer thorough results. They may do a CP2077 test but it’s one single chart. That game alone should be at least 3 charts at every resolution. Raster,  DLSS, frame gen.",
      "the amount of 4000 series owners stroking each other to validate their purchases is wild lol",
      "Own a 4080/4090 (not worth it) - as expected tbh, who upgrades every generation of iPhone? (but I'm old)\n\nOwn a 3090 or older - you will see a performance bump for the price. And hopefully after 4+ years since your last purchase, your finances have recoverd enough to be in a possition to asses if you want to spend to upgrade. \\[Hopefully for another 4 years to allow one's finances to recover\\]"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "4080",
      "4080 super"
    ],
    "title": "Upgraded from an Arc A770 LE to a 4080 Super",
    "selftext": "The Arc card was neat to have but the 4080s supercharged my gaming and allowed me to crank all the visuals up! Card sits at 45* C at load.",
    "comments": [
      "The PNY actually looks good. I assume there is RGB but it looks so clean without!",
      "No RGB on this PNY card, it just lights up the logo in white which I don't mind at all.",
      ">Card sits at 45* C at load\n\nThat means it's underutilized, as in resolution is too low. Without an undervolt, it should be closer to 65°C. And if you are already playing in 4k, you need to crank up those effects or get a better CPU.",
      "Nice man. I just got a 4080s this week, upgraded from a 3080 and have been blown away by how good it is. Quite the improvement.",
      "Nice! The 4080 is incredibly power efficient as well!",
      "I am using a 7600X3D so I think the whole system stays under 500W under load. Sips power.",
      "Definitely, I am still using a 1440p 75hz monitor. I'm going to be looking to upgrade to 4k down the line. I have a 7600X3D which I don't think should bottle neck it.",
      "How was the experience with the Arc? I'm really interested in any kind of competition to the NVIDIA/AMD monopoly",
      "Or fps lock on, which is always nice and smooth as hell with vsync and gsync.",
      "WH40K Darktide. I indeed turned on the raytracing and everything, haha.",
      "Damn that's neat! I had to replace my 650W PSU because it couldn't provide enough power to my system when gaming. I run an i7 6700K, 24 GB of DDR4, 3200 MHz CL16 RAM and an RTX 2080. The only thing that's overclocked is my RAM because my PC BSODs whenever I attempt to even slightly overclock my CPU 😂 so now I got a 1200W PSU instead",
      "That should be using everything to the max. Are you using the power adapter that came with the card?",
      "No shortage of RGB in the build, I totally agree 👍🏼",
      "I remember when I thought 75hz was enough. You are in for a nice shock.",
      "The fans on the card are definitely the loudest out of all of the fans in my system, my other fans are fairly quiet. From what I can see in the nvidia overlay, the GPU fans ramp up to 700 rpm under load and are at 0 rpm at idle (I can confirm and see the fans not moving). The card is 31c at idle as I'm typing this.",
      "What game are you playing? Just set everything to max",
      "Big improvement but also big investment. I wanted the nvidia features though.",
      "And i'm stuck with a 3060 🥲",
      "I’ve been thinking about buying a PNY 4070 myself as it’s a bit cheaper than everything else, but I’m a bit hesitant to trust the brand.",
      "Side grade...\n\n>!Just kidding, very nice!!<"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "rtx 4080",
      "4080",
      "4080 super",
      "rtx 4080 super"
    ],
    "title": "NVIDIA GeForce RTX 4080 SUPER stock running low in the US, no MSRP cards available - VideoCardz.com",
    "selftext": "",
    "comments": [
      "According to comments, when Nvidia cards are still sitting on shelves it means they're overpriced and gamers don't want them, and when they're sold out it's intentionally low stock or bots.",
      "This is precisely why I decided against returning my 4080 during the return period and trying to get a Super lol, just couldn't be bothered with fighting against stock issues.",
      "It's always been like this for at least the first week of any major GPU release. People need to relax",
      "4080 super FE is constantly restocking at Best Buy. Last night I had one to where I could have completed my order without much effort.",
      "Both of these can be true? \n\n4080 sold like shit when it was new. Most went for 4090, 4070ti and 4070.\n\nAnd there have also been multiple credible reports of Nvidia artificially limiting stock. \n\nNot everything is an anti Nvidia conspiracy",
      "Man, thought the GPU shortage was over. 2020 was tough. Here we go again.....",
      "* nVidia wants consumers to pay $1200 for the 4080.\n* Consumers do not want to pay $1200 for the 4080, so it sells under expectations.\n* nVidia re-releases the 4080 at $999 so they can say they listened and get big PR points and more time in the news cycle, then makes very few of the $999 models so most people still have to pay $1200 if they actually want one.\n\nThat doesn't sound like some far-fetched conspiracy to me, it sounds like an extremely common retail tactic. See also the advertised prices of cars (which don't include expensive \"options\" that you will never find a car on a lot without.)",
      "I'm so glad I got mine as soon as they went on sale. I managed to get the Gigabyte white aero model for msrp.",
      ">nVidia re-releases the 4080 at $999 so they can say they listened and get big PR points and more time in the news cycle, then makes very few of the $999 models so most people still have to pay $1200 if they actually want one.\n\nDo you guys realize that third party sellers or AIB partners selling custom 4080s for $1500 doesn't mean that Nvidia is getting 50% more money? \n\nNvidia makes the same profit from a 4080 Ventus selling at MSRP and a 4080 Strix OC that's $300 more expensive because they get paid in advance for the dies and memory.",
      "yeah it's completely delusional",
      "\"constantly\"?....... hmm",
      "I bought my card before the Super was announced, back in October. Best Buy has an extended return period through the holidays. By that point, I wasn't too upset about $200.",
      "Nvidia already got paid for that 4080 in stock. The only way for them to get extra money is if that person were to buy a 4080 FE which is not being sold anymore.\n\nAre you guys for real? It's not rocket science to understand that for every Nvidia or AMD GPU you see on the shelves they have already made money because AIB contracts pay in advance.\n\nOr do you think Nvidia/AMD give to AIB partners free GPUs and then when Jimmy goes to Microcenter and buys a graphic card then ASUS Venmo Nvidia its sale percentage.",
      "This title really isn’t correct, the MSRP cards are constantly being restocked.\n\nI’m in a discord that alerts you when the 4080s come back in stock, it’s very easy to grab most of the MSRP cards that aren’t the FE if you purchase within 10 minutes or so.",
      "Schrodiner's Nvidia supply.",
      "It's just the 4080S because there was an untapped market for a $999 Nvidia GPU. Plenty of 4070S and 4070TiS available.\n\nBut the 4080S shortage is certainly intentional. Canada Computers had 10 units of my card (4080S Aorus Master) for all of Canada, and newegg.ca had 0 units, instead allowing people to buy the USA stock until it too ran out.",
      "In nvidia’s point of view. Sale is a sale. If bots are buying them, it means that there are demands on highend gpus",
      "Yep. Also NVIDIA’s site had a drop on Tuesday again and it went for over an hour before it was OOS. My local MC last week had about 50 various AIB models and they took 3 days to sell out. It’s no where near as bad as the pandemic. Just launch-week excitement.",
      "They honestly don't care about us. They are making a killing selling cards for AI development. Nvidia is drowning in cash.",
      "> Man, thought the GPU shortage was over. \n\nIt was a learning opportunity for companies, and they clearly learnt a lot."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "rtx 4080",
      "4080",
      "4080 super",
      "rtx 4080 super"
    ],
    "title": "NVIDIA RTX 4080 SUPER and RTX 4070Ti SUPER to feature AD103 GPU, RTX 4070 SUPER gets AD104 - VideoCardz.com",
    "selftext": "",
    "comments": [
      "$1100 it is then!",
      "How about some reasonable prices",
      "Still bummed we aren't getting a 4080Ti on a AD102 die with like 20GB VRAM and a larger bump in cores. That would be a no brainer upgrade for me at that point.\n\nAs it stands I'll probably wait and see what the pricing is on the 4080S and maybe get one next year.",
      "Looks like its not going to be a cut down 4090 after all. 4090 is AD102. May not be as powerful as previous rumors suggested.",
      "Ti Super lol",
      "The rumored 16GB VRAM capacity was a telltale sign anyone could see from a mile away, they'd be cutting from 384bit all the way down to 256bit, that's a HUGE waste of die space.",
      "You’re asking a little too much from Nvidia with that reasonable price nonsense/s",
      ">4080 Ti for $699 is the level of performance I need to upgrade.\n\nthat is also just unrealistic.",
      "Meh,   \n50 series it is.",
      "4080 Ti for $699 is the level of performance I need to upgrade. \n\nSeems like I'll be waiting another 2-4 years. LOL",
      "Back in the days they replaced the RTX 2080 with the 2080 Super at same price point.",
      "So 4070Ti bascially becomes a 4080 at a reduced price? Pretty solid card until RTX 50 series in 1-2 years.",
      "So gutted. Bought a 4070ti 2 months ago. I'd of waited if I knew for the 16gb",
      "4070 at 499. Doubt.",
      "4070 Ti Super looking good. Will definitely be picking one up even if it does have a stupid name.",
      "AMD just doesn't cut it for people who need CUDA and/or Raytracing for workstation tasks.",
      "Currently? Sure but he said 2 to 4 years which isn't unreasonable.",
      "And the same measly 5% increase.",
      "TLDR: cards looks good, with good prices, it can save everything (\"go 4090 or nothing\"), if prices are bad, nothing changes",
      ">If this doesn't bring down the price of the regular 4080 to 950 or lower it's wasted space.\n\nIt replaces the 4080.\n\nAlso, Nvidia wouldn't use AD102 for the 4080 Super because a lot of AD102 dies are used for enterprise GPUs, which are selling like hotcakes."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "4080",
      "4080 super"
    ],
    "title": "It is time…",
    "selftext": "Finally got my hands on one. Higher than MSRP at $2600 after tax. But still satisfying to get one before the orange tariffs hit. \n\nReplacing at 4080 Super. \n\n9950x, 96GB 6400Mhz RAM, 16TB SSDs (4x4). Productivity w/ medium 4K gaming build. ",
    "comments": [
      "May your cables be cool and ROPS complete!",
      "All lf your fans are exhaust",
      "New headline!  Need to use this more here.",
      "You’re the first person that’s ever mentioned this in all the photos I’ve posted online… Thank you. Getting two sets of reverse blades now.",
      "i got my 5090 3 days ago and updated my motherboard bios which failed during the update and now my shit is bricked. 😔",
      "Congrats.",
      "Blows my mind when people build $5000 gaming rigs and they can’t figure out fans.",
      "Figured it out now though. \n\n![gif](giphy|9xt5eMX6WhOhvfWajw)",
      "zotac really has one of the better designs this time around.  i’m liking the lowkey almost steam punk look.",
      "I keep seeing posts like this downvoted for people showing their gear they scored. But I'll upvote them because it's great to see people not gaming at anything less than like the artist and game developers envisioned. So nice to see people not compromising on settings and getting a game experience better than 99% of the other gamers.  \n\nI feel like there are a lot of salty-ass people that just want to downvote stuff they don't understand.",
      "You're welcome! Get those blades and may your temps be low!",
      "You would need to:\n- Have a USB formatted to FAT32 (MBR) <- specifically this formatting\n- Have the BIOS file at the root of the USB directory\n- (maybe) have to rename the file depending on what your manual says\n\nThe first point is what usually gets people. You can't just use a 8gb/16gb usb. It has to be fat32(mbr). Not gpt table, not exFAT.",
      "Good shit hoping to get one soon",
      "Its time to turn some fans",
      "This case is heavy as hell bro, never again lol. can’t wait to build in it tho :)",
      "a solid score 😉",
      "Before the tariffs!!! You perfectly timed it!",
      "What are you doing with the 4080 Super?",
      "Was it’s a gigabyte one?",
      "Nah for real it’s a heavy ass case. 🤣"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "rtx 4080",
      "4080",
      "4080 super",
      "rtx 4080 super"
    ],
    "title": "[Megathread] GeForce At CES: SUPER GPUs, RTX Games, GenAI, Remix Open Beta, Enhanced Broadcasting, G-SYNC Pulsar, Half-Life 2 RTX, and More",
    "selftext": "&#x200B;\n\n[GeForce at CES 2024](https://preview.redd.it/gbyu1q2oa8bc1.jpg?width=1920&format=pjpg&auto=webp&s=cf3e981d161137ea260aca909d40a62f71983952)\n\n# GeForce RTX 40 SUPER Series\n\n**Article Link**: [Click Here](https://www.nvidia.com/en-us/geforce/news/geforce-rtx-4080-4070-ti-4070-super-gpu/)\n\n&#x200B;\n\n||**RTX 4070 Super**|**RTX 4070 Ti Super**|**RTX 4080 Super**|\n|:-|:-|:-|:-|\n|**GPU**|TSMC 4N AD104-350|TSMC 4N AD103-275|TSMC 4N AD103-400|\n|**SMs**|56 SM|66 SM|80 SM|\n|**Base Clock**|1980 Mhz|2340 Mhz|2295 Mhz|\n|**Boost Clock**|2475 Mhz|2610 Mhz|2550 Mhz|\n|**CUDA Cores**|7168 CUDA Cores|8448 CUDA Cores|10240 CUDA Cores|\n|**Shader FLOPS**|36 TFLOPS|44 TFLOPS|52 TFLOPS|\n|**RT FLOPS**|82 RT TFLOPS|102 RT TFLOPS|121 RT TFLOPS|\n|**Tensor TOPS**|568 AI TOPS|706 AI TOPS|836 AI TOPS|\n|**Memory Interface**|192-Bit|256-Bit|256-Bit|\n|**Memory Speed**|21 Gbps|21 Gbps|23 Gbps|\n|**Memory Bandwidth**|504 GB/s|672 GB/s|736 GB/s|\n|**VRAM Size**|12GB G6X|16GB G6X|16GB G6X|\n|**L2 Cache**|48 MB|48 MB|64 MB|\n|**Max TGP**|220W|285W|320W|\n|**PSU Requirement**|650W|700W|750W|\n|**Price**|$599 MSRP|$799 MSRP|$999 MSRP|\n|**Founders Edition**|Yes|No|Yes|\n|**Release Date**|January 17|January 24|January 31|\n\n# Performance Claim\n\n**Be sure to wait for independent benchmarks**\n\n**RTX 4070 Super**\n\n* Faster than RTX 3090 without Frame Generation.\n\n**RTX 4070 Ti Super**\n\n* 1.6x faster vs RTX 3070 Ti without Frame Generation and 2.5x faster with Frame Generation\n\n**RTX 4080 Super**\n\n* 1.4x Faster vs RTX 3080 Ti without Frame Generation and 2x faster with Frame Generation\n\n[40 Super Performance](https://preview.redd.it/w9j0kll4v8bc1.png?width=2880&format=png&auto=webp&s=aba85f3227ce144b60152df89f2278f35521b904)\n\n&#x200B;\n\n[40 Super Performance w\\/ Frame Generation](https://preview.redd.it/uzipyv96v8bc1.png?width=2880&format=png&auto=webp&s=505fcc4e9fe97003e4bd0f49b2674ff7964ed36d)\n\n# Power Comparison\n\n||RTX 4070 Super|RTX 3070|RTX 2070|\n|:-|:-|:-|:-|\n|Idle (W)|11W|11W|10W|\n|Video Playback (W)|16W|20W|18W|\n|Average Gaming (W)|200W|215W|177W|\n|TGP (W)|220W|220W|185W|\n\n&#x200B;\n\n||RTX 4070 Ti Super|RTX 3070 Ti|RTX 2070 Super|\n|:-|:-|:-|:-|\n|Idle (W)|12W|12W|11W|\n|Video Playback (W)|17W|20W|15W|\n|Average Gaming (W)|226W|240W|205W|\n|TGP (W)|285W|290W|215W|\n\n&#x200B;\n\n||RTX 4080 Super|RTX 3080 Ti|RTX 2080 Super|\n|:-|:-|:-|:-|\n|Idle (W)|15W|13W|10W|\n|Video Playback (W)|22W|27W|17W|\n|Average Gaming (W)|246W|352W|227W|\n|TGP (W)|320W|350W|250W|\n\n# Power Supply Requirement (RTX 4070 Super & 4080 Super Founders Edition)\n\n&#x200B;\n\n[GeForce RTX 4070 Super Founders Edition PSU Requirements](https://preview.redd.it/5maz8ws5e8bc1.jpg?width=1350&format=pjpg&auto=webp&s=4b0ffd3c00baa5ad784f6792273d340b93c71638)\n\n&#x200B;\n\n[GeForce RTX 4080 Super Founders Edition PSU Requirements](https://preview.redd.it/r83l5wj7e8bc1.jpg?width=1350&format=pjpg&auto=webp&s=eb92388d1b52417d14fb773ff5e0a74f91d79479)\n\n&#x200B;\n\n[GeForce RTX 40 Series Stack](https://preview.redd.it/auew3nais8bc1.jpg?width=1270&format=pjpg&auto=webp&s=9479c7e515386aa27ec97d8e904a9243bd245c29)\n\n# RTX Games\n\n**Article Link**: [Click Here](https://www.nvidia.com/en-us/geforce/news/ces-2024-dlss-ray-tracing-rtx-games-announcements)\n\n* Launching with or Adding DLSS\n   * Dragon’s Dogma 2\n   * Enshrouded\n   * Gray Zone Warfare\n   * Half-Life 2 RTX\n   * Horizon Forbidden West Complete Edition\n   * Layers of Fear\n   * Like a Dragon Gaiden: The Man Who Erased His Name\n   * Like a Dragon: Infinite Wealth\n   * NAKWON: LAST PARADISE\n   * Pax Dei\n   * Starminer\n   * TEKKEN 8\n   * THRONE AND LIBERTY\n* And Diablo IV is getting Ray Tracing in March.\n\n# Half Life 2 RTX Trailer\n\nHalf-Life 2 RTX, An RTX Remix Project - Ravenholm Trailer: [Click Here](https://www.youtube.com/watch?v=nIE9gQt6WXQ)\n\n# NVIDIA RTX Remix Open Beta Begins January 22nd\n\n**Article Link**: \\[Click Here\\]([https://www.nvidia.com/en-us/geforce/news/rtx-remix-open-beta-half-life-2-rtx-trailer](https://www.nvidia.com/en-us/geforce/news/rtx-remix-open-beta-half-life-2-rtx-trailer))\n\n* With NVIDIA RTX Remix, modders can remaster their favorite classic games with full ray tracing, NVIDIA DLSS, NVIDIA Reflex, modern physically-based rendering (PBR), and generative AI texture tools\n* Starting January 22nd, modders can remix a compatible, classic game thanks to the open beta release of the RTX Remix Application\n* [Head here](https://www.nvidia.com/en-us/geforce/rtx-remix/) to sign up to be notified of its immediate release.\n\n# G-SYNC Pulsar Tech Unveiled, G-SYNC Comes to GeForce NOW, Plus 24 New Models\n\n**Article Link**: [Click Here](https://www.nvidia.com/en-us/geforce/news/g-sync-pulsar-gaming-monitor)\n\n* G-SYNC Pulsar is the next evolution of Variable Refresh Rate (VRR) technology, not only delivering a stutter-free experience and buttery smooth motion, but also a new gold standard for visual clarity and fidelity through the invention of variable frequency strobing, boosting effective motion clarity to over 1000Hz on the debut ASUS ROG Swift PG27 Series G-SYNC gaming monitor launching later this year.\n* G-SYNC technology comes to the cloud with GeForce NOW, vastly improving the visual fidelity of streaming to displays that support G-SYNC.\n* Our partners announced 24 new models, including some of the world’s first 240Hz 4K OLED gaming monitors (Alienware AW3225QF), DQHD 240Hz OLEDs (Philips Evnia 49M2C8900), 144Hz G-SYNC Compatible TVs (LG SIGNATURE OLED M4), and many more.\n\n# NVIDIA and Developers Pioneer Lifelike Digital Characters for Games and Applications with NVIDIA ACE\n\n**Article Link**: [Click Here](https://www.nvidia.com/en-us/geforce/news/nvidia-ace-architecture-ai-npc-personalities)\n\n* [NVIDIA ACE](https://developer.nvidia.com/omniverse/ace) (Avatar Cloud Engine) is a suite of technologies that helps developers bring digital avatars to life using generative AI. With ACE, generic non-playable characters (NPCs) can be turned into dynamic, interactive characters capable of striking up a conversation, or providing game knowledge to aid players in their quests.\n* At CES 2024, NVIDIA is announcing the availability of ACE production microservices for NVIDIA Audio2Face (A2F) and NVIDIA Riva Automatic Speech Recognition (ASR), and that NVIDIA is working with top digital avatar developers to bring NVIDIA ACE technologies to gamers.\n* [Watch the latest NVIDIA ACE demo](https://www.youtube.com/watch?v=psrXGPh80UM) in collaboration with Convai, showcasing next-generation AI NPCs and NVIDIA ACE microservices: Audio2Face and Riva ASR for AI powered animation and speech.\n\n# GeForce NOW at CES 2024: Activision & Blizzard Games, Day Passes, and G-SYNC Technology\n\n**Article Link**: [Click Here](https://www.nvidia.com/en-us/geforce/news/geforce-now-ces-2024-games-technology-day-pass)\n\n* More games, including Diablo IV and Overwatch 2 are coming to GeForce NOW\n* Play for just a day\n* Get an even better experience thanks to new G-SYNC technology.\n\n# GeForce RTX Livestreaming: Twitch, OBS & NVIDIA To Enable Multi-Encode Broadcasting This Month\n\n**Article Link**: [Click Here](https://www.nvidia.com/en-us/geforce/news/rtx-twitch-obs-multi-encode-av1-livestreaming)\n\n* Twitch Enhanced Broadcasting enables up to five concurrent streams to Twitch from a single GeForce PC, for viewers on different platforms and devices, enhancing the viewing experience.\n\n# Community FAQ\n\n**Article Link**: [Click Here](https://www.nvidia.com/en-us/geforce/forums/geforce-graphics-cards/5/534976/geforce-at-ces-super-gpus-rtx-games-genai-remix-op/)\n\n**NVIDIA GeForce RTX SUPER GPUs**\n\n***What are the MSRPs of the RTX 4080 SUPER, RTX 4070 Ti SUPER, and RTX 4070 SUPER?***\n\nThe GeForce RTX 4070 SUPER will be available from January 17th starting at $599\n\nThe GeForce RTX 4070 Ti SUPER will be available from January 24th starting at $799\n\nThe GeForce RTX 4080 SUPER will be available from January 31st starting at $999\n\n***What is different about the RTX 4080 SUPER vs. RTX 4080?***\n\nThe RTX 4080 SUPER features more cores and faster memory, giving it a performance edge at a great new price of $999\n\n***What is the performance of the RTX 4080 SUPER?***\n\nIt is 1.4x faster than the RTX 3080 Ti without frame gen in the most graphically intensive games. DLSS Frame Generation delivers an extra performance boost, making the RTX 4080 SUPER twice as fast as an RTX 3080 Ti.\n\n***What is different about the RTX 4070 Ti SUPER vs. RTX 4070 Ti?***\n\nWe’ve added more cores and increased the frame buffer to 16GB and the memory bus to 256-bits.\n\n***What is the performance of the RTX 4070 Ti SUPER?***\n\nIt’s 1.6X faster than a 3070 Ti in the most graphically intensive games, and 2.5X faster with DLSS Frame Generation.\n\n***What is different about the RTX 4070 SUPER vs. RTX 4070?***\n\nWe’ve added 20% more cores.\n\n***What is the performance of the RTX 4070 SUPER?***\n\nIt is faster than the RTX 3090 while using a fraction of the power in the most graphically intensive games. And with DLSS Frame Generation it’s 1.5x faster.\n\n**NVIDIA G-SYNC Pulsar**\n\n***What is G-SYNC Pulsar?***\n\nIt is a new progression on the G-SYNC technologies, delivering the best combination of motion clarity and tear-free, stutter-free gaming. It marks a significant breakthrough utilizing two advanced technologies, Adaptive Overdrive and Pulse Modulation, to reduce ghosting and provide 4x effective motion clarity.\n\n***When will new monitors be available that support G-SYNC Pulsar?***\n\n2024.\n\n***Can G-SYNC Pulsar be implemented on every display panel in the future?***\n\nNo. G-SYNC Pulsar requires matching panel character with tuning, but because it leverages LCD panel technology, we are planning broader G-SYNC Pulsar support in the future.\n\n***Does G-SYNC Pulsar mode replace any of the existing G-SYNC monitor features?***\n\nG-SYNC Pulsar is a new extra mode. All the previous modes, such as G-SYNC, V-SYNC on/off, and ULMB 2, etc. all still exist.\n\n**NVIDIA RTX Remix**\n\n***Where can I sign up to join the NVIDIA RTX Remix Open Beta?***\n\n* RTX Remix will be available for modders January 22nd.  [Head here](https://www.nvidia.com/en-us/geforce/rtx-remix/) to sign up to be notified of its release.\n\n# Reference Links\n\n|Topic|Article|Video|\n|:-|:-|:-|\n|CES 2024 Special Address|N/A|[Link Here](https://www.youtube.com/watch?v=KtGY-tZGXfk)|\n|GeForce RTX 40 SUPER Series Graphics Cards Launching This January, For Supercharged Gaming & Creating, With Super-Fast AI|[Link Here](https://www.nvidia.com/en-us/geforce/news/geforce-rtx-4080-4070-ti-4070-super-gpu)|[Link Here](https://www.youtube.com/watch?v=1vXFxEzozcE)|\n|Horizon Forbidden West Complete Edition, Pax Dei and Diablo IV Lead The Charge For RTX and DLSS 3!|[Link Here](https://www.nvidia.com/en-us/geforce/news/ces-2024-dlss-ray-tracing-rtx-games-announcements)|[Link Here](https://www.youtube.com/watch?v=DEqRbxOrFAw)|\n|Half-Life 2 RTX, An RTX Remix Project - Ravenholm Trailer|N/A|[Link Here](https://www.youtube.com/watch?v=nIE9gQt6WXQ)|\n|NVIDIA RTX Remix Open Beta Begins January 22nd|[Link Here](https://www.nvidia.com/en-us/geforce/news/rtx-remix-open-beta-half-life-2-rtx-trailer)|N/A|\n|G-SYNC Pulsar Tech Unveiled, G-SYNC Comes to GeForce NOW, Plus 24 New Models|[Link Here](https://www.nvidia.com/en-us/geforce/news/g-sync-pulsar-gaming-monitor)|N/A|\n|NVIDIA and Developers Pioneer Lifelike Digital Characters for Games and Applications with NVIDIA ACE|[Link Here](https://www.nvidia.com/en-us/geforce/news/nvidia-ace-architecture-ai-npc-personalities)|[Link Here](https://www.youtube.com/watch?v=psrXGPh80UM)|\n|Pax Dei|N/A|[Link Here](https://www.youtube.com/watch?v=eMZhZxKvroc)|\n|Diablo IV|N/A|[Link Here](https://www.youtube.com/watch?v=Eh80iWrP95w)|\n|NAKWON: LAST PARADISE|N/A|[Link Here](https://www.youtube.com/watch?v=w36Gdwtnku8)|\n|Enshrouded|N/A|[Link Here](https://www.youtube.com/watch?v=ZJYcNwGTkjo)|\n|THRONE AND LIBERTY|N/A|[Link Here](https://www.youtube.com/watch?v=OAkSe0yC_9k)|\n|Starminer|N/A|[Link Here](https://www.youtube.com/watch?v=OwAoUuxqeJE)|\n|Dragon’s Dogma 2|N/A|[Link Here](https://www.youtube.com/watch?v=mAb4a5CsfU0)|\n|Like a Dragon Gaiden: Infinite Wealth|N/A|[Link Here](https://www.youtube.com/watch?v=tQtwFIbk_gY)|\n|Tekken 8|N/A|[Link Here](https://www.youtube.com/watch?v=oJsrxgW3gfs)|\n\n&#x200B;",
    "comments": [
      "I'm honestly sick of Nvidia comparing cards like this, they're not even comparing these cards to their non-SUPER variants, just their 30-series 'equivalents', and with DLSS and RT turned on. Blatantly shady marketing.",
      "20% core increase on the 4070S is a great bump up, but 4070TiS going from 12GB to 16GB just made it really appealing. The value proposition for the Ti is certainly there now with Super.",
      "The 4080 was clearly an attempt at Nvidia to squeeze the middle of the market up in pricing. It wasn't close enough to the 4090 performance, and it was priced far too high for the performance it offered. Consumers spoke by not buying it, which is why it constantly is on sale and still always seems to be in stock.  \n\n\n\nDropping the retail $200 to $1000 will definitely help it sell better. But is that enough? will enough people be persuaded to buy this over the $800 4070ti? I think it's still going to be a flop given it's marginal gain over the 4080.",
      "The cards aren’t really aimed at existing 40 series owners and the non super variants are being phased out. So it makes sense to compare to prior gen",
      "Yes, 4070 Ti SUPER will be available through add-in card partners. There will be an FE version of 4070 SUPER and 4080 SUPER.",
      "4070 Ti Super won't be coming in Founder's Edition and only available through 3rd parties?",
      "Ti tie tee eye",
      "UK prices  \n  \n4080 s - £959  \n4070ti s - £769  \n4070 s - £579  \n  \nSource: nvidia website",
      "👀",
      "FINALLY AV1 coming to Twitch, along with 4k streaming and higher bitrates, even at lower resolutions it sounds like. This will be a huge improvement to streaming quality.",
      "Nobody who owns 40 series currently will be buying these Super cards.",
      "1,1k €+ for a 4080 Super in Germany - There goes my interest in buying.",
      "They show both.",
      "Small part of me kinda regrets going for the 7800xt back in November when I should’ve waited for the 4070ti super :(",
      "(inhale) 3080ti is fine, 3080ti is fine, 3080ti is fine (exhale)",
      "Tbf it was 4-5 years ago lol",
      "They are comparing both with Frame generation and without frame generation! Check the graph and read the questions and answers at the bottom",
      "Yes. Before they started leaking the supers, i was pretty close to buying a 7900xt. Shame 4070 super is still 12gb thou. I guess 4070 ti super is the one i will buy in the end, if all goes well.",
      "Can we call 4070 Titan Super 4070TitS for short?",
      "> Small part of me kinda regrets going for the 7800xt back in November when I should’ve waited for the 4070ti super :(  \n\nPeople are saying the 4070ti Super *probably* won't have an FE. Meaning it's MSRP $800, but retailers will list the branded versions with their own markups for higher than that. At $500-$550, your card is probably a way better deal."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "4080",
      "4080 super"
    ],
    "title": "Built my first PC!",
    "selftext": "Finally built my first PC instead of going with a pre build. Took me 4 hours to build but love it!\n\nSpecs:\nGigabyte B650 Gaming X AX\nRyzen 7 7800X3D\nAsus Tuf 4070 TI Super OC\nLian-Li Galahad Trinity II AIO\nCorsair RM1000e\nCorsair Vengeance RGB 2x32GB 6000Mhz CL 30 \nC:// Western Digital 500GB m.2 NVMe SSD\nD:// Crucial 4TB m.2 NVMe SSD\nWhite Vetroo AL600 Case\n\nI learned a lot and over spent on a lot of things. I probably could have cut back on a few things and upgraded to 4080 Super for the same price but live and learn I guess.\n\nStill proud I could put this together and now know so much more for the future.",
    "comments": [
      "I went for the gtx 1080 to the rtx 4090 and i nearly fainted",
      "https://preview.redd.it/oaeh4w8bggkc1.png?width=823&format=png&auto=webp&s=b4a00571219ceccac457ffb3cbb3dc0bfa5c53f8",
      "Congratulations on the new PC but I would recommend getting that gorgeous thing off the carpet if you have the space on your desk.",
      "thank you for that. took it off. I got all the others off thought I got them all off.",
      "Sorry for the horrible formatting. I can't find how to edit. I don't make many original posts but was excited about this.",
      "Solid build, I moved to 4070 a couple months ago from 1650 and the differences were staggering",
      "I don't right now but good advice I'll have to move some things around.",
      "What ? It’s the best raw power in the consumer market lmao",
      "No it doesn’t ? Else AMD which doesn’t focus on that would have been able to make a card that’s at least as good in raster. They didn’t\n\nAnd that non sense is very useful, and probably adds more performance than anything we’ve done to improve rasterization recently. Just stay stuck in the past I guess ?",
      "Sweet build! I have the same CPU/GPU combo. It's a beast, enjoy!",
      "Me too my friend me too , I cannot believe how powerful it really is.  Stuff that used to crash my old PC now just slays and stays true on screen.",
      "yeah I upgraded from 2080. from 80 fps to 240 in warzone",
      "thanks man. no idea how you noticed it.",
      "As any new technology, it’s not perfect at first… but what else do you want ? We can’t produce infinitely smaller chips. At some point we have to optimize the software and have specific cores tailored for specific purposes if we can’t progress in hardware. That’s what Nvidia is doing right now. That’s the way forward",
      "you really dont understand what you are talking about..... your argument is paramount to saying you think electric car engines are inferior to gas powered ones.... because you personally have a car that only burns gas?",
      "dunno how nobody has said it yet, but get that thing off the carpet! you're suffocating that power supply and it will certainly cause problems. even something small but hard to allow that psu intake to breathe will be enough, but you don't want a psu with no airflow\n\nedit; I now see that one person has in fact also said it. still, you'll want to do that sooner rather than later.",
      "https://preview.redd.it/5xzkr9957hkc1.jpeg?width=750&format=pjpg&auto=webp&s=8454a4e1c93c5d30d48a62f2ba6f7be32bd16b21",
      "Glad i could help. Congrats on the build!",
      "aah, no its quiet.",
      "I'm currently build an all white build. \n\nRyzen 7800 x3d processor\n64gb 6000hz ram\nSapphire pure rx7800XT 16gb\nGIGABYTE B650 AORUS ELITE AX ICE mobo\nNZXT H9 hi flow dual chamber all white tower. \n\n\nI'm pretty excited to get it all together. \n\nYours looks great buddu"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "rtx 4080",
      "4080",
      "4080 super",
      "rtx 4080 super"
    ],
    "title": "Deshrouded my Palit GeForce RTX 4080 Super GamingPro OC with Noctua fans",
    "selftext": "",
    "comments": [
      "Original fans had unpleasant whine noise even on min RPM. Noctua fans fix this and are 1.5-2 times more silent. This was the goal.",
      "Useless unless there's a before and after temps",
      "https://preview.redd.it/9e3d38optkqc1.jpeg?width=432&format=pjpg&auto=webp&s=db649c96fea81ae4b06ac0e0d5127876b6712ed1\n\nThere’s literally a noctua 4080",
      "It's a great reason actually. My old 3070 Ventus 2x made a ridiculously loud fan noise. Now with a 6800 XT I no longer have this problem.",
      "Just got my ASUS GeForce RTX 4080 SUPER 16GB GDDR6X Noctua OC Edition installed today. My dream card. Stupid price ($1300), but not nearly as stupid as the \"regular\" 4080 Noctuas price ($1650).\n\nhttps://preview.redd.it/mzpih2tdzkqc1.jpeg?width=5712&format=pjpg&auto=webp&s=933259f18e3fe3eb1554f5a8de7f87e5edd8364a",
      "40 series is not the 30 series. the coolers are massively overbuilt especially for low tdp cards like the 4070/S and 4080/S. the fans are not going to have the same pleasant sound profile as a noctua but they can run so low, especially if undervolted that it doesn't really matter.",
      "This is exactly why I did this to my 6800 XT. The fans were audible and would come on every now and then at idle due to driving 4 monitors, which is unacceptable in an all Noctua PC that idles completely silent. \n\nOP, I'd recommend using a tap+die set to put screw holes into the metal rail on the heatsink, if you care about aesthetics.",
      "Dramatically reduces the fan noise and the tone of the fan to a much more pleasant hum rather than the WHRRRRRRRRRRR you hear with stock fans.",
      "This is was a UV at 0.91v?",
      "6 months ago I did a test on this similar topic:\n\nhttps://preview.redd.it/lcgj42797nqc1.jpeg?width=1920&format=pjpg&auto=webp&s=06e737307b3e16e2b7a34fc32ecf24f19b3d762d\n\n’GeForce RTX 4090 can be this silent’ [https://youtu.be/ueLpP-Kaw4A](https://youtu.be/ueLpP-Kaw4A)",
      "My PC case has closed panel. Anyways I don't care how it looks. My goal is silence.",
      "There's easier way to get similar or even better temps with adding PCI slot dual fans (+ still have full warranty). One slot adapter for 2 fans goes for like 5-10€ here. Can use any fans. Place either on bottom or top of the card. When extra fans are placed on the top, it's even possible to add extra heatsinks for the backplate. I did this to my last 3080 Ti and temps dropped massively + GPU fans stayed at low speeds. Max VRAM temps went down -20C and fans never run over 50% speed.\n\nhttps://preview.redd.it/met3mqxu6jqc1.png?width=2449&format=png&auto=webp&s=addc6b631f93b7ed78135a631a271f60fd4f233d",
      "oh yeah, that is protection from the GPU I believe, it will do what it can do target a TDP, and that means running it at lower voltage when it detects furmark like test. \n\nIf you were at 1.06v the power draw would be in the 400W potentially.",
      "Before after temps? I think it looks fine btw",
      "its supposed to be silent and cool, not look pretty",
      "At $1650 you can get a 4090 for $100 more, so not worth it.",
      "Probably not necessary, but if you are happy with it, great.",
      "also, the noctua one looks like a shit, lazy, amateur mod.",
      "This is the most underrated comment on Reddit.",
      "coil whine louder than my fans under some particular loads XD"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "4080",
      "4080 super"
    ],
    "title": "ZOTAC now offers RTX 4070Ti/4080 SUPER graphics cards for purchase on Amazon",
    "selftext": "",
    "comments": [
      "1400 for a super 😂😂😂",
      "No one is buying these at those prices. Hold that L, Zotac. Even Asus are offering their TUF models at MSRP this time.",
      "900 dollars what a joke, just buy a 4080 at that point",
      "ZOTAC clearly thought scalpers would inflate prices. Bad move",
      "That's the plan , 4080 had one of the worst sales so with this they finally get some good sales",
      "I would never buy another zotac card ever again. Fan wiring is atrocious.",
      "If I can picture it, people who probably are desperate for a super high end Nvidia GPU but can’t buy $2000+ 4090s or wait for them to go back at MSRP.",
      "They are banking that there won’t be much stock available.  This is criminal.",
      "It was.",
      "This must be an error",
      "1400 for a 4080S is ludicrous, though I can’t say buy a 4090 when those are still going for above 2000 dollars….",
      "That tuf model looking nice.",
      "Maybe they were better back then. But the wiring on my 3080 is awful. The zotac forums are full of fan issues",
      "I recently got a 4080 for $800. Totally worth it at that price",
      "Zotax?",
      "There's usually enough i3 7350k or FX 9590 folks to justify such products.",
      "I think Zotac needs to fix the pricing at Amazon. Their pricing at Newegg seems about right though and is different from that on Amazon.",
      "Probably they noticed the release date mistake and paused all the listing",
      "No one buying\n\nYou’d b surprised how dumb some people can be 😂",
      "I saw these few days ago and was making sure it’s Amazon selling them and not third party vendors since those prices were so marked up"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "rtx 4080",
      "4080"
    ],
    "title": "NVIDIA GeForce RTX 4070 Ti SUPER modded to 26 Gbps memory outperforms RTX 4080 in synthetic test - VideoCardz.com",
    "selftext": "",
    "comments": [
      "breaking news: if you mod a card to make it faster, it will become faster.",
      "Yeah, unless the 4080 gets overclocked too 💁‍♂️",
      "Bro get the heck out where do you get this stuff.",
      "4070Ti Super is an underrated GPU imo. I have my VRAM OCed to 23Gbps and core clock OCed to +210MHz running at 320W and it basically matches a 4080 in performance for $300 cheaper.",
      "my buddy joel gives me this insane information",
      "As I always said, gpus are bandwidth constrained these days. Rough performance went up way faster than memory speed and it acts as a bottleneck, always thought this. With all this nanite, path tracing etc I think we should start going back to hbm memory.",
      "Now mod the 4080",
      "Power prices globally have increased drastically. \n\nI guess you ain't the one paying your electricity bills? You can see huge increases in cost in both USA and Europe. \n\nOvertime this does add up per year. A decade ago this would have been $15. Prices in the last 4 years have risen 10x depending on location. The price now is way more expensive than what people think it is.\n\nPower consumption is now a thing people care about because of the prices of electricity a year. It's the same reason why people are buying solar panels.",
      "\"waaa other people don't enjoy the things i enjoy waaaaaaa how dare they i'm gonna cry about it like a little bitch\"",
      "Did you actually read the article? The memory swap only made it 3% faster, and even then only after they had got 23% more performance from extreme overclocking the core. It was already faster than a stock 4080 from that OC before they upgraded the memory.\n\nSpeaking from first-hand experience, at stock core clock speeds there is negligible benefit from faster memory. It's not memory bandwidth bound.",
      "because my room gets up to 80+ degrees if i play a game for an hour or two with just a 5800X3D and RTX 4070",
      "That's not the point at all, the point is that the old memory ICs can be replaced by manufacturers on newer models (because they are pin compatible) and get performance of a tier higher card. Same as the 16GB mod on a 3070. The cards were literally build to accept these memories, the manufacturers are not doing so for whatever reason.\n\nTo re-iterate, for 20$ more expensive new memory ic's you can get performance of 200$ more expensive card. Nvidia is just not doing this because nobody would buy 4080s then. Same reason why AMD is intentionally gimping memory on 7900 GRE.",
      "Gonna need a source on that, chief.",
      "320W and the temps are good, will max out around 70-71C. It's a Gigabyte Gaming OC which is a good model with a large heatsink and has the power limit unlocked to 320W.",
      "That's the same with all GPUs, but it's nice when you can jump up a full tier. You can't overclock a 4080 to 4090 performance.",
      "Clearly they do after looking at your profile😂😂",
      "When did yall start giving a fuck about power consumption lmfao. As long as it’s not drawing 500+, wtf cares",
      "hahaha i wish. Prices are sky high and sold out for years because of datacenter gpus. Thanks AI",
      "Right lol. Like we’re all gaming 4-5 hours a day, stressing about fps, resolution, which 1440p/4k panel to buy, but the last straw is +50 watts of power draw lol. You have bigger problems if the extra kW/hr is causing a concern",
      "yeah because it's plenty enough to play games at 100+ fps at 1440p and it can already make it too uncomfortable to play games, because sweating in >80 degree heat really takes the fun out of it.\n\nA stronger card wouldn't be as much as a benefit as this would be over something like a 3060 since I've already past all the biggest difference makers and am at diminishing returns, but it would reduce the amount of time I could enjoy the games because it would output even more heat into the area in the same timeframe."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "4080",
      "4080 super"
    ],
    "title": "First PC build. I canceled my 7900xtx order when I heard the Nvidia 4080 super was dropping.",
    "selftext": "4080 Super $999, \n7800x3d $399, \n240 Arctic Liquid cooler argb $104.99 , \n6 Arctic argb fans $87.98 ,\nEvga 1000G FTW $184.99,\nMsi x670e gaming plus Wi-Fi $279.99,\nCorsair 4000D airflow $89.99,\nCorsair Vengeance RGB Cl30 ddr5 64g total $119.99,\nWD sn850x 2tb $134.99\nEdit. Prices added USD",
    "comments": [
      "Bro got 4x16gb cl30 cheaper than any 2x16 cl36 kits in europe...",
      "I got 2 of them for free because Amazon took too long on the order and temporarily lost it. They sent me a replacement when I reached out and I got to keep original order for free when it arrived.\nEdit. I removed 2 of the ram and the speed went for 3600 mhz to 4800 mhz. Thanks for the input",
      "How so? It was $80 cheaper and games look great on it. I had an order for the Sapphire Nitro +",
      "What a low iq comment",
      "Smart move. Amd gpu’s are inferior",
      "Temps ?",
      "PC building is our family hobby, and we have numerous NVIDIA and AMD graphics cards.  Both brands have their pros and cons.  We love our NVIDIA cards, but our AMD cards are also great.",
      "For raster, they're absolutely in the same class and either is a good choice. Ray Tracing and features, not so much. I would like the Adrenaline software on my Nvidia GPU though.",
      "Amd fans who havent had any driver issues have been saying the driver issues have been solved for a long time now.\n\nI had a 6600xt which caused world of warships to glitch out like crazy which turned out to be a driver issue (a lil over a year ago) and then it began blue screening my pc, i sold it cheap and bought a 6700 non xt which would only wake up my monitors 50% of the time when turning my pc on or waking it from sleep mode, said fawk this.\n\nI bought a 4060ti and all issues vanished, my main pc has always rocked team green but at the time of buying the 6600xt i saw nothing but praise for amd so i thought \"eh why not, lets give it a try\" and i got burned :/",
      "Why do yall hate on AMD their graphics cards are great, great build tho 👍",
      "Gonna need more substance than just *fucks everything up.* Maybe an informative source to educate us? Genuinely.",
      "It's also not as good on the image quality front. But they are making decent progress, so that's a positive.",
      "Better choice👍🏽\nHave fun",
      "I played a lot of cyberpunk on Xbox and the game looks great on the 4080. I also play Apex Legends and it holds at a steady 240fps with my 240hz monitor. I plan on getting more games that support ray tracing too. I’m definitely more than happy with the build",
      "Fucking excellent build, especially for a first PC. I just got my 4080 super; it’s fantastic.",
      "dlss, ray tracing also i often hear about how much amd cards have issues be it drivers or hardware",
      "Real talk the Arctic Cooler does its job insanely well, I got one and wasn’t expecting much from it. Beyond happy with it!",
      "Its all a out that sweet sweet dlss and fg",
      "Not his fault nvidia is better",
      "yeah, i do realize my case is surely a unicorn considering i had issues with not one but TWO amd cards but it definitely left a crappy taste in me for amd :/"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "4080",
      "4080 super"
    ],
    "title": "4080 Super FE",
    "selftext": "Going from a 2080 Ti to a 4080 Super. This thing is massive! Feels super premium and love the black on black metal. Got super lucky and picked it up from the Nvidia site at MSRP. Waiting for the rest of my parts to arrive. Super hyped!",
    "comments": [
      "Such a good looking card. Hope you enjoy it!",
      "Upgraded from a 2080ti system rebuild.\n\nhttps://preview.redd.it/pjbntvy1lslc1.jpeg?width=2992&format=pjpg&auto=webp&s=6e86fc9c059f88bfbc29bc58cc4c7089a47c91f8\n\nBest looking card imo.",
      "I hated the promotional pictures, but once I had it in hand, my god does it look great.",
      "The 4070s is probably the best performing Nvidia card for the price at the moment.",
      "I hope they keep this general aesthetic for the 5000 series.",
      "hehe that's what she said",
      "Sweet FE looks awesome",
      "Killer setup!",
      "Depends on what you want. A 4070s is a BEAST for 1440p gaming, and hands down has the best price to performance ratio. But if you want to play in 4k, then the 4070s is not the greatest of choice with 12gb of vram. Also, note that the 4080s is well capable of 4k but doesn't really perform that amazing on 4k ultra/max settings with ray tracing in a lot of modern games.",
      "They kept it from the 3000 series.  Should be ongoing to the 5000",
      "Folks like you are insufferable",
      "If he doesn’t enjoy it we can confirm a successful lobotomy.",
      "This late in the cycle the 4070 super is a better choice I think, at least for 1440p. Flip it when the 5 series comes out and get a 5080 early.",
      "4070S is by far the best value proposition Nvidia has to offer this gen. You have a solid card.",
      "Thanks man!",
      "It’s crazy how the Super FE’s look so much better than most(all?) of the AIB cards yet offer the cheapest price.",
      "Chonky and beautiful.",
      "I wanted an FE card but got impatient when I found an ASUS TUF version on sale for MSRP.",
      "No way dude",
      "It's a really good card, you'll be able to comfortably game in 4K with most things turned up to max"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "rtx 4080",
      "4080",
      "4080 super",
      "rtx 4080 super"
    ],
    "title": "Based on the leaked 3D Mark benchmarks, 5070Ti could be ~1-2% faster than 4080S",
    "selftext": "4080S Numbers are from this article - [https://en.overclocking.com/test-nvidia-rtx-4080-super-founders-edition/5/](https://en.overclocking.com/test-nvidia-rtx-4080-super-founders-edition/5/)\n\n|Test|RTX 5070 Ti|RTX 4080 Super|5070 Ti vs RTX 4080 Super (%)|\n|:-|:-|:-|:-|\n|Speed Way (1440p)|7,646|7,554|\\+1.20%|\n|Port Royal (1440p)|19,045|18,539|\\+2.66%|\n|Time Spy (1440p)|27,384|27,024|\\+1.31%|\n|Time Spy Extreme (4K)|13,485|13,324|\\+1.19%|\n|Fire Strike (1080p)|68,741|47,904|\\+30.31%|\n|Fire Strike Ultra (4K)|18,065|17,702|\\+2.01%|\n\n* 5070Ti lead over 4080S\n* **With Fire Strike (1080p)**: 6.45% \n* **Without Fire Strike (1080p)**: 1.68%",
    "comments": [
      "Revolutionary 👏👏👏👏",
      "So... a $1000 MSRP card is being replaced by a $750 MSRP card. \n\nActually not terrible, from a price-to-performance perspective. We'll see how available this card is in the $750-$800 range, though. \n\nI honestly think that this card will be the best release this generation, however. \n\nThe 5070 has a $550 MSRP and will be replacing the $600 MSRP 4070 Super, so... basically no improvement in that price category.",
      "Microcenter listed the 5070Ti at over 900$. Only two models at $750.",
      "Unfortunately this happens if you have zero competition",
      "Did they find the shittiest 4080 Super to benchmark, what are those numbers lol",
      "But it will cost more or equal to a 4080s. I’ve seen them for 999 - 1100€ a year ago. You won’t find a 5070 ti here in europe for under 1000€ for the next few weeks/months.",
      "Yup, this is the GPU version of Intel's 14nm++++ CPUs.",
      "You'll never be able to buy the 5070 Ti for $750. The MSRP is a big fat lie.",
      "So its a 4080s with new 5000 bells and whistles for hopefully lower price? Once prices stabilize that might be THE GPU for folks that want 1440p at high refresh rates or entry 4k gaming. Since I got 7900xtx for 970 eur, Id actually choose 5070ti over it if it was under 900 eur. Sacrificing 8 gigs of VRAM for better frame gen/upscaling/ray tracing is a decent tradeoff imho. I'm still hoping for a 5000 series refresh sometimes during 2026.",
      "RTX 5070 ti has 70 SMs, what do you mean?",
      "Yeah... so it's an Nvidia launch. Also, no FE for the 4070 Ti, I think.\n\nI wonder how many cards are available at launch, though? This card probably won't be quite as scalp-able as the 5080s and 5090s, which might help a little bit.",
      "If we're being real only a fraction of 5070ti's will be sold at msrp, at least for the foreseeable future.",
      "Huh? It's got just shy of 9000 CUDA cores. The 4080 Super had a little over 10,000.\n\nSo, about a 13% CUDA core difference. And the 5070 Ti has \\~20% more memory bandwidth and a very similar boost clock. \n\nIt's not at all unrealistic that this thing ties a 4080S.",
      "700€ for 5070 ti? I’m afraid that’s not going to happen any time soon. I wouldn’t be surprised if 800-850 will be the absolute lowest they go for the next 2 years.",
      "If you believe this at this point, you’re just a fanboy.",
      "With DLSS it’s much more than entry level 4K",
      "That fact that he has 12 likes shows that people don’t fact check their shit, If it pleases their narrative, like.",
      "Those are right numbers, just checked",
      "If by very few you mean 0, since there's no FE for 5070ti",
      "I think I read the same. PNY will be doing the two MSRP models from what I remember. I have a funny feeling they will produce like no meaningful amount of those cards at launch."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "rtx 4080",
      "4080",
      "4080 super",
      "rtx 4080 super"
    ],
    "title": "nVidia GeForce RTX 5080 Meta Review",
    "selftext": "- compilation of 18 launch reviews with ~8520 gaming benchmarks at 1080p, 1440p, 2160p\n- only benchmarks at real games compiled, not included any 3DMark & Unigine benchmarks\n- geometric mean in all cases\n- standard raster performance without ray-tracing and/or DLSS/FSR/XeSS\n- extra ray-tracing benchmarks (mostly without upscaler) after the standard raster benchmarks\n- stock performance on (usually) reference/FE boards, no overclocking\n- factory overclocked cards were normalized to reference clocks/performance, but just for the overall performance average (so the listings show the original performance result, just the performance index has been normalized)\n- missing results were interpolated (for a more accurate average) based on the available & former results\n- performance average is (some) weighted in favor of reviews with more benchmarks\n- all reviews should have used newer drivers for _all_ cards\n- power draw numbers based on a couple of reviews, always for the graphics card only\n- performance/price ratio (higher is better) for 2160p raster performance and 2160p ray-tracing performance\n- for the full results and some more explanations check [3DCenter's launch analysis](https://www.3dcenter.org/artikel/launch-analyse-nvidia-geforce-rtx-5080)\n\n&nbsp;\n\nRaster 2160p|3080|3090|309Ti|79XT|79XTX|407TiS|4080|4080S|4090|5080|5090\n|:--|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|\n&nbsp;|Ampere 10GB|Ampere 24GB|Ampere 24GB|RDNA3 20GB|RDNA3 24GB|Ada 16GB|Ada 16GB|Ada 16GB|Ada 24GB|Blackw. 16GB|Blackw. 32GB\nCBase|-|-|-|74.2%|87.0%|78.0%|-|89.3%|120.5%|_100%_|149.2%\nCowcotl|-|-|-|74.6%|89.0%|78.0%|84.7%|86.4%|112.7%|_100%_|144.9%\nEurog|64.1%|66.6%|73.7%|76.0%|88.0%|-|84.3%|85.8%|114.1%|_100%_|149.4%\nGamersN|59.9%|64.7%|75.9%|74.4%|93.5%|-|86.8%|87.8%|118.8%|_100%_|155.3%\nHW & Co|51.5%|68.4%|-|74.2%|86.7%|-|-|89.5%|117.3%|_100%_|149.8%\nHWLuxx|58.1%|65.0%|73.7%|73.4%|84.6%|73.8%|85.8%|87.8%|113.4%|_100%_|147.5%\nIgor's|-|-|-|76.1%|92.5%|77.7%|-|91.2%|121.2%|_100%_|152.5%\nKitGuru|-|-|-|79.1%|92.6%|75.6%|-|88.9%|117.9%|_100%_|151.8%\nLinus|57.5%|67.5%|72.5%|76.3%|88.8%|75.0%|-|85.0%|115.0%|_100%_|147.5%\nOvercl|-|-|-|79.9%|94.3%|-|88.4%|89.7%|115.6%|_100%_|148.4%\nPCGH|52.8%|-|-|76.9%|91.6%|73.8%|-|87.7%|118.7%|_100%_|152.2%\nPurePC|56.8%|-|73.9%|72.7%|85.2%|-|87.5%|-|117.0%|_100%_|151.7%\nQuasarZ|-|65.1%|71.9%|-|84.8%|-|84.5%|87.2%|116.1%|_100%_|148.1%\nSweCl|59.9%|-|-|-|90.1%|-|88.4%|-|121.3%|_100%_|152.1%\nTPU|57%|66%|74%|73%|87%|74%|87%|88%|113%|_100%_|152%\nTechSpot|60.4%|70.3%|-|76.9%|92.3%|76.9%|87.9%|90.1%|120.9%|_100%_|150.5%\nTom's|-|-|-|-|90.2%|-|-|91.6%|120.4%|_100%_|150.9%\nTweakers|58.9%|65.2%|-|77.0%|88.9%|73.7%|88.1%|88.9%|114.6%|_100%_|151.1%\n**avg**|57.2%|66.9%|74.3%|75.2%|89.0%|75.2%|86.8%|88.5%|117.2%|_100%_|150.3%\n\n&nbsp;\n\nRaster 1440p|3080|3090|309Ti|79XT|79XTX|407TiS|4080|4080S|4090|5080|5090\n|:--|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|\n&nbsp;|Ampere 10GB|Ampere 24GB|Ampere 24GB|RDNA3 20GB|RDNA3 24GB|Ada 16GB|Ada 16GB|Ada 16GB|Ada 24GB|Blackw. 16GB|Blackw. 32GB\nCBase|60.6%|-|-|78.6%|88.8%|81.2%|-|92.0%|116.5%|_100%_|135.0%\nCowcotl|-|-|-|83.0%|92.9%|80.4%|89.3%|91.1%|109.8%|_100%_|127.7%\nEurog|64.0%|67.0%|73.8%|76.5%|89.0%|-|86.4%|87.2%|110.7%|_100%_|136.8%\nGamersN|60.5%|64.9%|75.2%|79.2%|94.2%|-|91.9%|92.1%|118.3%|_100%_|142.4%\nHW & Co|60.1%|69.6%|-|79.1%|89.8%|-|-|92.3%|114.9%|_100%_|136.1%\nHWLuxx|60.1%|70.7%|79.0%|83.2%|95.0%|81.5%|95.4%|97.2%|118.5%|_100%_|144.2%\nIgor's|-|-|-|78.5%|92.2%|79.1%|-|92.3%|114.0%|_100%_|135.2%\nKitGuru|-|-|-|82.2%|93.6%|78.9%|-|91.6%|117.4%|_100%_|143.8%\nLinus|60.9%|69.2%|73.7%|82.0%|93.2%|80.5%|-|89.5%|115.0%|_100%_|136.1%\nPCGH|58.5%|-|-|80.3%|94.1%|77.2%|-|91.2%|118.5%|_100%_|143.5%\nPurePC|59.2%|-|74.0%|75.1%|87.0%|-|90.5%|-|115.4%|_100%_|141.4%\nQuasarZ|-|65.6%|70.9%|-|86.5%|-|87.6%|90.4%|113.8%|_100%_|136.7%\nSweCl|61.8%|-|-|-|92.4%|-|92.0%|-|117.7%|_100%_|142.5%\nTPU|60%|67%|74%|77%|89%|79%|90%|91%|112%|_100%_|137%\nTechSpot|63.7%|73.3%|-|82.2%|95.2%|83.6%|93.8%|95.9%|119.2%|_100%_|131.5%\nTom's|-|-|-|-|91.1%|-|-|93.5%|113.3%|_100%_|128.2%\nTweakers|59.9%|65.7%|-|80.8%|89.8%|77.3%|91.4%|91.8%|111.6%|_100%_|135.1%\n**avg**|60.4%|68.3%|75.0%|79.3%|91.2%|79.3%|90.5%|92.0%|115.3%|_100%_|137.3%\n\n&nbsp;\n\nRaster 1080p|3080|3090|309Ti|79XT|79XTX|407TiS|4080|4080S|4090|5080|5090\n|:--|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|\n&nbsp;|Ampere 10GB|Ampere 24GB|Ampere 24GB|RDNA3 20GB|RDNA3 24GB|Ada 16GB|Ada 16GB|Ada 16GB|Ada 24GB|Blackw. 16GB|Blackw. 32GB\nCowcotl|-|-|-|88.1%|94.5%|85.3%|91.7%|92.7%|106.4%|_100%_|113.8%\nEurog|65.6%|70.2%|79.9%|83.8%|92.4%|-|89.4%|90.2%|108.1%|_100%_|126.5%\nGamersN|62.5%|66.8%|75.9%|81.7%|95.8%|-|95.6%|95.7%|115.9%|_100%_|131.7%\nHWLuxx|67.1%|70.9%|78.3%|83.2%|93.6%|83.8%|92.6%|94.5%|114.8%|_100%_|130.4%\nIgor's|-|-|-|79.5%|91.2%|82.7%|-|94.8%|111.6%|_100%_|124.0%\nKitGuru|-|-|-|83.6%|93.7%|81.2%|-|93.1%|115.4%|_100%_|136.0%\nPCGH|60.1%|-|-|82.0%|93.7%|79.8%|-|92.3%|115.8%|_100%_|133.2%\nPurePC|61.0%|-|74.4%|87.8%|87.8%|-|92.1%|-|115.9%|_100%_|137.2%\nQuasarZ|-|67.1%|71.7%|-|86.6%|-|89.9%|92.6%|110.9%|_100%_|125.9%\nSweCl|63.3%|-|-|-|93.2%|-|93.5%|-|114.8%|_100%_|131.1%\nTPU|63%|69%|76%|80%|90%|82%|93%|94%|111%|_100%_|124%\nTechSpot|71.0%|79.5%|-|86.9%|96.6%|90.3%|99.4%|100.6%|117.0%|_100%_|115.9%\nTom's|-|-|-|-|92.5%|-|-|96.5%|111.4%|_100%_|115.1%\nTweakers|61.4%|67.0%|-|81.8%|89.3%|79.5%|93.8%|93.6%|106.2%|_100%_|122.4%\n**avg**|63.5%|70.1%|76.6%|82.7%|92.0%|82.5%|93.0%|94.2%|112.8%|_100%_|128.1%\n\n&nbsp;\n\nRayTr. 2160p|3080|3090|309Ti|79XT|79XTX|407TiS|4080|4080S|4090|5080|5090\n|:--|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|\n&nbsp;|Ampere 10GB|Ampere 24GB|Ampere 24GB|RDNA3 20GB|RDNA3 24GB|Ada 16GB|Ada 16GB|Ada 16GB|Ada 24GB|Blackw. 16GB|Blackw. 32GB\nCBase|-|-|-|67.3%|77.8%|80.1%|-|92.1%|121.0%|_100%_|147.2%\nCowcotl|-|-|-|59.0%|68.9%|73.8%|82.0%|84.4%|116.4%|_100%_|150.8%\nEurog|63.6%|65.9%|75.6%|62.5%|72.4%|-|87.9%|89.5%|124.6%|_100%_|162.0%\nGamersN|54.8%|59.0%|69.4%|54.4%|68.8%|-|86.2%|87.1%|116.3%|_100%_|156.3%\nHWLuxx|45.8%|58.7%|67.2%|44.7%|50.1%|82.1%|92.9%|94.4%|125.3%|_100%_|154.0%\nKitGuru|-|-|-|55.1%|63.7%|75.0%|-|89.3%|123.8%|_100%_|159.8%\nLinus|28.2%|59.0%|64.1%|43.6%|48.7%|74.4%|-|87.2%|123.1%|_100%_|161.5%\nOvercl|-|-|-|59.9%|72.1%|-|89.8%|91.6%|116.3%|_100%_|148.6%\nPCGH|46.3%|-|-|58.2%|68.8%|75.9%|-|89.4%|119.3%|_100%_|150.8%\nPurePC|50.0%|-|67.5%|47.0%|56.0%|-|86.5%|-|122.0%|_100%_|160.0%\nQuasarZ|-|60.5%|65.3%|-|-|-|85.7%|88.4%|116.9%|_100%_|148.6%\nSweCl|-|-|-|-|56.0%|-|90.7%|-|131.2%|_100%_|165.6%\nTPU|44%|64%|71%|53%|62%|77%|89%|90%|119%|_100%_|156%\nTechSpot|-|-|-|41.0%|49.2%|73.8%|88.5%|91.8%|118.0%|_100%_|149.2%\nTom's|-|-|-|-|68.9%|-|-|93.9%|128.8%|_100%_|163.1%\nTweakers|51.6%|60.7%|-|58.4%|66.8%|75.2%|90.5%|91.4%|124.3%|_100%_|164.1%\n**avg**|47.1%|61.3%|68.7%|53.8%|63.0%|76.2%|88.2%|90.0%|121.1%|_100%_|155.4%\n\n&nbsp;\n\nRayTr. 1440p|3080|3090|309Ti|79XT|79XTX|407TiS|4080|4080S|4090|5080|5090\n|:--|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|\n&nbsp;|Ampere 10GB|Ampere 24GB|Ampere 24GB|RDNA3 20GB|RDNA3 24GB|Ada 16GB|Ada 16GB|Ada 16GB|Ada 24GB|Blackw. 16GB|Blackw. 32GB\nCBase|46.4%|-|-|72.4%|80.5%|82.9%|-|93.4%|115.2%|_100%_|125.9%\nCowcotl|-|-|-|64.1%|70.1%|71.8%|85.5%|87.2%|112.0%|_100%_|139.3%\nEurog|63.2%|66.8%|75.3%|65.1%|73.7%|-|89.6%|91.1%|121.2%|_100%_|150.4%\nHW & Co|52.8%|62.5%|-|46.2%|52.8%|-|-|92.0%|121.4%|_100%_|153.3%\nHWLuxx|57.3%|60.5%|67.6%|49.4%|54.5%|84.2%|94.4%|96.1%|119.6%|_100%_|139.5%\nKitGuru|-|-|-|56.8%|64.7%|76.8%|-|90.3%|119.1%|_100%_|149.2%\nLinus|52.0%|60.0%|64.0%|44.0%|50.7%|78.7%|-|88.0%|117.3%|_100%_|148.0%\nPCGH|56.2%|-|-|63.2%|72.8%|79.1%|-|92.1%|117.6%|_100%_|139.5%\nPurePC|52.9%|-|68.3%|48.7%|57.1%|-|87.3%|-|118.5%|_100%_|150.3%\nSweCl|-|-|-|-|57.3%|-|92.8%|-|125.0%|_100%_|151.3%\nTPU|59%|66%|72%|57%|66%|80%|92%|93%|117%|_100%_|146%\nTechSpot|-|-|-|47.5%|54.5%|80.8%|93.9%|94.9%|117.2%|_100%_|139.4%\nTweakers|56.0%|62.3%|-|59.5%|67.2%|78.2%|93.6%|93.9%|121.9%|_100%_|151.9%\n**avg**|55.6%|63.4%|70.0%|55.5%|63.3%|78.9%|90.5%|92.0%|118.6%|_100%_|144.7%\n\n&nbsp;\n\nRayTr. 1080p|3080|3090|309Ti|79XT|79XTX|407TiS|4080|4080S|4090|5080|5090\n|:--|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|\n&nbsp;|Ampere 10GB|Ampere 24GB|Ampere 24GB|RDNA3 20GB|RDNA3 24GB|Ada 16GB|Ada 16GB|Ada 16GB|Ada 24GB|Blackw. 16GB|Blackw. 32GB\nCowcotl|-|-|-|63.2%|70.1%|78.6%|85.5%|87.2%|103.4%|_100%_|114.5%\nEurog|62.8%|68.2%|74.8%|66.6%|74.3%|-|90.7%|92.4%|117.9%|_100%_|138.5%\nHWLuxx|60.2%|62.5%|68.6%|52.3%|57.3%|83.4%|90.5%|91.7%|112.4%|_100%_|126.3%\nKitGuru|-|-|-|58.3%|65.2%|78.6%|-|90.4%|115.3%|_100%_|140.4%\nPCGH|59.3%|-|-|66.6%|75.3%|81.5%|-|93.3%|114.5%|_100%_|130.5%\nPurePC|55.2%|-|68.5%|51.4%|58.6%|-|90.1%|-|117.1%|_100%_|142.0%\nSweCl|56.8%|-|-|-|59.3%|-|93.9%|-|118.6%|_100%_|134.3%\nTPU|61%|68%|74%|60%|68%|83%|94%|95%|115%|_100%_|136%\nTechSpot|-|-|-|49.2%|56.2%|84.6%|96.2%|97.7%|113.8%|_100%_|130.8%\nTweakers|57.1%|62.9%|-|59.7%|66.3%|78.9%|93.6%|94.8%|116.0%|_100%_|140.7%\n**avg**|59.2%|65.3%|71.6%|59.2%|66.5%|81.3%|91.7%|93.1%|114.4%|_100%_|133.0%\n\n&nbsp;\n\nFG/MFG 2160p|4090|4090 FG|5080|5080 FG|5080 MFGx3|5080 MFGx4|5090|5090 FG|5090 MFGx3|5090 MFGx4\n|:--|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|\nComputerB|123.2%|216.2%|_100%_|175.0%|251.2%|322.0%|150.0%|274.3%|394.9%|499.8%\nHWLuxx|129.5%|228.4%|_100%_|183.6%|254.8%|323.4%|172.0%|303.9%|435.0%|547.0%\nTechPowerUp|114.3%|139.2%|_100%_|-|-|274.5%|148.8%|-|-|460.9%\navg pure FG/MFG gain|&nbsp;|+74% vs4090|&nbsp;|+73% vs5080|+141% vs5080|+206% vs5080|&nbsp;|+78% vs5090|+154% vs5090|+220% vs5090\n\n&nbsp;\n\nAt a glance|3080|3090|309Ti|79XT|79XTX|407TiS|4080|4080S|4090|5080|5090\n|:--|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|\n&nbsp;|Ampere 10GB|Ampere 24GB|Ampere 24GB|RDNA3 20GB|RDNA3 24GB|Ada 16GB|Ada 16GB|Ada 16GB|Ada 24GB|Blackw. 16GB|Blackw. 32GB\n2160p Raster|57.2%|66.9%|74.3%|75.2%|89.0%|75.2%|86.8%|88.5%|117.2%|_100%_|150.3%\n1440p Raster|60.4%|68.3%|75.0%|79.3%|91.2%|79.3%|90.5%|92.0%|115.3%|_100%_|137.3%\n1080p Raster|63.5%|70.1%|76.6%|82.7%|92.0%|82.5%|93.0%|94.2%|112.8%|_100%_|128.1%\n2160p RayTr|47.1%|61.3%|68.7%|53.8%|63.0%|76.2%|88.2%|90.0%|121.1%|_100%_|155.4%\n1440p RayTr|55.6%|63.4%|70.0%|55.5%|63.3%|78.9%|90.5%|92.0%|118.6%|_100%_|144.7%\n1080p RayTr|59.2%|65.3%|71.6%|59.2%|66.5%|81.3%|91.7%|93.1%|114.4%|_100%_|133.0%\nTDP|320W|350W|450W|315W|355W|285W|320W|320W|450W|360W|575W\nReal Power Draw|325W|359W|462W|309W|351W|277W|297W|302W|418W|311W|509W\nEE RA 2160p|55%|58%|50%|76%|79%|84%|91%|91%|87%|_100%_|92%\nMSRP|$799|$1499|$1999|$899|$999|$799|$1199|$999|$1599|$999|$1999\nRetail GER|800€|1700€|2100€|679€|889€|831€|1150€|1000€|1750€|1300€|2600€\nP/P&nbsp;GER 2160p&nbsp;RA|93%|51%|46%|144%|130%|118%|98%|115%|87%|_100%_|75%\nP/P&nbsp;GER 2160p&nbsp;RT|77%|47%|43%|103%|92%|119%|100%|117%|90%|_100%_|78%\nRetail US|$700|$1500|$2000|$650|$870|$900|$1200|$1000|$1600|$1150|$2300\nP/P US 2160p RA|94%|51%|43%|133%|118%|96%|83%|102%|84%|_100%_|75%\nP/P US 2160p RT|77%|47%|39%|95%|83%|97%|85%|103%|87%|_100%_|78%\n\nNote: RA = Raster, RT = Ray-Tracing, EE = Energy Efficiency, P/P = Performance/Price Ratio    \nNote: For the graphics cards that have already been discontinued, a retail price was assumed at the time of their sale. The same applies to the 7900XT, 7900XTX and 4080S, which are currently on the retreat from the market. Retail prices were estimated for 5080 & 5090 when availability is reached. These estimates are of course not perfect, as nobody knows how the price situation will develop.\n\n&nbsp;\n\nPerf. Gain of 5080|Raster 2160p|Raster 1440p|Raster 1080p|RayTr. 2160p|RayTr. 1440p|RayTr. 1080p\n|:--|:--:|:--:|:--:|:--:|:--:|:--:|\nGeForce RTX 2080 Ti FE|+131%|+119%|+102%|+176%|+156%|+135%\nGeForce RTX 3080 10GB|+75%|+66%|+58%|+112%|+80%|+69%\nGeForce RTX 3090|+50%|+46%|+43%|+63%|+58%|+53%\nGeForce RTX 3090 Ti|+35%|+33%|+31%|+46%|+43%|+40%\nRadeon RX 7900 XT|+33%|+26%|+21%|+86%|+80%|+69%\nRadeon RX 7900 XTX|+12%|+10%|+9%|+59%|+58%|+50%\nGeForce&nbsp;RTX&nbsp;4070&nbsp;Ti&nbsp;Super|+33%|+26%|+21%|+31%|+27%|+23%\nGeForce RTX 4080|+15%|+11%|+8%|+13%|+10%|+9%\nGeForce RTX 4080 Super|+13%|+9%|+6%|+11%|+9%|+7%\nGeForce RTX 4090|–15%|–13%|–11%|–17%|–16%|–13%\nGeForce RTX 5090|–33%|–27%|–22%|–36%|–31%|–25%\n\nNote: Performance improvement of the GeForce RTX 5080 compared to the other cards. The respective other card is then _100%_.\n\n&nbsp;\n\n&nbsp;|nVidia FE|Asus Astral OC|Colorful Vulcan OC|Gainward Phoenix GS|Galax/KFA2 1-Click OC|Gigabyte Gaming OC\n|:--|:--:|:--:|:--:|:--:|:--:|:--:|\nCooling|Air, 2 Fans|Air, 4 Fans|Air, 3 Fans|Air, 3 Fans|Air, 3 Fans|Air, 3 Fans\nDimensions|DualSl, 30x13.5cm|TripleSl, 35x15cm|TripleSl, 36x15cm|TripleSl, 33x13cm|TripleSl, 30x13.5cm|TripleSl, 34x14cm\nWeight|1635g|2900g|2796g|1595g|1308g|1823g\nClocks|2295/2617 MHz|2295/2760 MHz|2295/2685 MHz|2295/2700 MHz|2295/2625 MHz|2295/2730 MHz\nReal Clock (avg/median)|2640 MHz / 2662 MHz|2882 MHz / 2925 MHz|2822 MHz / 2865 MHz|2821 MHz / 2865 MHz|2745 MHz / 2790 MHz|2815 MHz / 2857 MHz\nTDP|360W (max: 390W)|400W (max: 400W)|375W (max: 400W)|360W (max: 380W)|360W (max: 450W)|360W (max: 450W)\nRaster Perf. (2160/1440/1080)|_100%_|+6% / +6% / +5%|+5% / +4% / +4%|+5% / +5% / +4%|+3% / +3% / +2%|+4% / +4% / +3%\nRayTr. Perf. (2160/1440/1080)|_100%_|+6% / +6% / +6%|+4% / +5% / +5%|+4% / +5% / +4%|+2% / +3% / +4%|+4% / +4% / +5%\nTemperatures (GPU/Memory)|67°C / 74°C|62°C / 66°C|61°C / 66°C|68°C / 76°C|69°C / 76°C|64°C / 66°C\nLoundness|36.8 dBA|36.3 dBA|34.4 dBA|37.4 dBA|35.6 dBA|38.4 dBA\nReal Power Draw (Idle/Gaming)|20W / 325W|17W / 388W|30W / 367W|22W / 361W|17W / 350W|18W / 358W\nPrice|$999|$1500|$1300|$1150|$1000|$1200\nSource:|[TPU](https://www.techpowerup.com/review/nvidia-geforce-rtx-5080-founders-edition/)|[TPU](https://www.techpowerup.com/review/asus-geforce-rtx-5080-astral-oc/)|[TPU](https://www.techpowerup.com/review/colorful-geforce-rtx-5080-vulcan-oc/)|[TPU](https://www.techpowerup.com/review/gainward-geforce-rtx-5080-phoenix-gs/)|[TPU](https://www.techpowerup.com/review/galax-geforce-rtx-5080-1-click-oc/)|[TPU](https://www.techpowerup.com/review/gigabyte-geforce-rtx-5080-gaming-oc/)\n\n&nbsp;|nVidia FE|MSI Vanguard OC|MSI Suprim SOC|Palit GameRock OC|Zotac AMP Extreme Infinity\n|:--|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|\nCooling|Air, 2 Fans|Air, 3 Fans|Air, 3 Fans|Air, 3 Fans|Air, 3 Fans\nDimensions|DualSl, 30x13.5cm|TripleSl, 36x15cm|TripleSl, 36x15cm|TripleSl, 33x14.5cm|TripleSl, 33x14cm\nWeight|1635g|1954g|2639g|2200g|2161g\nClocks|2295/2617 MHz|2295/2730 MHz|2295/2745 MHz|2295/2730 MHz|2295/2670 MHz\nReal Clock (avg/median)|2640 MHz / 2662 MHz|2791 MHz / 2835 MHz|2726 MHz / 2752 MHz|2803 MHz / 2857 MHz|2830 MHz / 2872 MHz\nTDP|360W (max: 390W)|360W (max: 400W)|360W (max: 400W)|360W (max: 400W)|360W (max: 400W)\nRaster Perf. (2160/1440/1080)|_100%_|+4% / +3% / +3%|+2% / +2% / +2%|+5% / +5% / +4%|+5% / +5% / +4%\nRayTr. Perf. (2160/1440/1080)|_100%_|+4% / +4% / +4%|+2% / +1% / +3%|+4% / +5% / +5%|+5% / +5% / +5%\nTemperatures (GPU/Memory)|67°C / 74°C|60°C / 62°C|60°C / 62°C|64°C / 68°C|66°C / 66°C\nLoundness|36.8 dBA|35.0 dBA|25.5 dBA|37.3 dBA|38.6 dBA\nReal Power Draw (Idle/Gaming)|20W / 325W|15W / 352W|18W / 318W|30W / 346W|24W / 371W\nPrice|$999|$1230|$1250|$1200|$1250\nSource:|[TPU](https://www.techpowerup.com/review/nvidia-geforce-rtx-5080-founders-edition/)|[TPU](https://www.techpowerup.com/review/msi-geforce-rtx-5080-vanguard-soc/)|[TPU](https://www.techpowerup.com/review/msi-geforce-rtx-5080-suprim-soc/)|[TPU](https://www.techpowerup.com/review/palit-geforce-rtx-5080-gamerock-oc/)|[TPU](https://www.techpowerup.com/review/zotac-geforce-rtx-5080-amp-extreme/)\n\nNote: Just the values of the default BIOS were noted throughout, as _complete_ information including performance values are only available for that BIOS.\n\n&nbsp;\n\nList of GeForce RTX 5080 reviews evaluated for this performance analysis:\n\n- [ComputerBase](https://www.computerbase.de/artikel/grafikkarten/nvidia-geforce-rtx-5080-test.91176/)\n- [Cowcotland](https://www.cowcotland.com/articles/4489/test-nvidia-geforce-rtx-5080-fe-blackwell-s-attaque-au-gaming-haut-de-gamme.html)\n- [Eurogamer](https://www.eurogamer.net/digitalfoundry-2025-nvidia-geforce-rtx-5080-review)\n- [Gamers Nexus](https://www.youtube.com/watch?v=nShh_j4s2YE)\n- [Hardware & Co](https://hardwareand.co/dossiers/gpu/test-de-la-geforce-rtx-5080-une-demi-5090)\n- [Hardwareluxx](https://www.hardwareluxx.de/index.php/artikel/hardware/grafikkarten/65395-leistungsplus-nur-ueber-mfg-die-geforce-rtx-5080-founders-edition-im-test.html)\n- [Igor's Lab](https://www.igorslab.de/nvidia-geforce-rtx-5080-founders-edition-im-test-geforce-rtx-4080-ti-mit-blackwell-genen/)\n- [KitGuru](https://www.kitguru.net/components/graphic-cards/dominic-moass/nvidia-rtx-5080-review-efficiency-gains-but-a-performance-letdown/)\n- [Linus Tech Tips](https://www.youtube.com/watch?v=Fbg7ChsjmEA)\n- [Overclocking](https://overclocking.com/test-la-nvidia-rtx-5080-founders-edition/)\n- [PC Games Hardware](https://www.pcgameshardware.de/Geforce-RTX-5080-Grafikkarte-281030/Tests/Release-Preis-kaufen-Benchmark-Review-vs-4080-Super-1464610/)\n- [PurePC](https://www.purepc.pl/nvidia-geforce-rtx-5080-recenzja-test-wydajnosci-premiera-blackwell)\n- [Quasarzone](https://quasarzone.com/bbs/qc_bench/views/93127)\n- [SweClockers](https://www.sweclockers.com/test/40513-nvidia-geforce-rtx-5080-mer-refresh-an-revolution)\n- [TechPowerUp](https://www.techpowerup.com/review/nvidia-geforce-rtx-5080-founders-edition/)\n- [TechSpot](https://www.techspot.com/review/2947-nvidia-geforce-rtx-5080/)\n- [Tom's Hardware](https://www.tomshardware.com/pc-components/gpus/nvidia-geforce-rtx-5080-review)\n- [Tweakers](https://tweakers.net/reviews/12896/nvidia-geforce-rtx-5080-vooral-interessant-dankzij-de-extra-ai-frames.html)\n\nSource: [3DCenter.org](https://www.3dcenter.org/artikel/launch-analyse-nvidia-geforce-rtx-5080)",
    "comments": [
      "* 5080 is faster vs 4080 by 1.152x \n* 5080 is faster vs 4080 Super by 1.129x \n* 5080 is 0.85x performance of 4090\n* 5080 is faster vs 3080 by 1.748x\n\nPretty expected based on [NVIDIA's claimed performance](https://videocardz.com/newz/nvidia-official-geforce-rtx-50-vs-rtx-40-benchmarks-15-to-33-performance-uplift-without-dlss-multi-frame-generation) from January 15th",
      "I love that performance per dollar is the same between 5080 and 4070 Ti Super:\n- 4070 Ti Super is 75% of 5080 and costs $750\n- 5080 is 100% and costs $1000.",
      "Men, you've made my day. Good job, holy shit. Something do add, OC values of some reviews, which shows the real gab between 4090 and 5080",
      "Yeah but where can you get a 4070 ti super from a trusted source? They aren't being manufactured anymore.",
      "Considering the 5080 is the same price and better at everything, why is the 4080S the one?",
      "Will be a very nice upgrade from my 3080 at 4k, especially if it OC's as good as people are claiming.",
      "So you made a pointless comment lol. As of now the 5080 is superior to the 4080S in every way including price",
      "So just to sum it up\n\n* 5080 is faster vs 4080 by 15%\n* 5080 is faster vs 4080 Super by 13%\n* 5080 is 85% performance of the 4090\n* 5080 is faster vs 3080 by 75%",
      "Indeed.",
      "The problem is that overclocking means relying on the silicon lottery to some extent. There has to be some reason why Nvidia made the 5080 so much worse than the 4090 stock. I guess it could be because they’re leaving space for a 5080 super, but still I feel like we’re going to discover something about overclocking the 5080 to explain why Nvidia didn’t do it for the stock version",
      "Yeah you can but the 5080 is 16% better at it and it's technically the same price if you can find them both at MSRP, with the top to the 5080 of being easier at MSRP because it's actively being restocked. \n\nThis is just normal growing pains, everyone freaked out when the 40 series launched and now they love it.  Next year we won't remember the 4080.",
      "It is.\nMine is at 3250 with no issues at all !\n(Upgraded from a 3080)",
      "Doesn't seem like a worthwhile investment to me, but it ain't my money!",
      "Problem is that 5080 dont cost 1000usd. Its fake msrp. Most AIB cards cost 20-50% more.",
      "When your GPU doesn’t show up on the charts anymore…",
      "Silicon lottery by avarage 10% uplift with OC?",
      "Most definitely happy to stick with my 4080 until the next gen. Will just wait a couple years and do a full build with new CPU etc.",
      "I got one on Amazon last week when I couldn’t get a 5080 or 5090. Manufactured by ASUS. Paid more than $750 though…",
      "Can you provide a link to a $1050 4080S? Everything I see in stock is over $1500",
      "NVIDIA has to set clocks at a spot that every card they deem acceptable can reach, so it's a balancing act of how many cards they want to defect down from 5080 status.\n\nCould also just be product placement shenanigans.\n\nIt does seem like a lot of cards have solid oc headroom which is very sus, I have yet to see or hear of anyone complaining of being unable to OC their 5080 however Im not in any of the OC communities"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "rtx 4080",
      "4080"
    ],
    "title": "40 Series Performance & Cost Analysis Based on Published Data -- Please take with grains of salt",
    "selftext": "# Lots of caveats here so let me open with them\n\n1. This analysis is based on the performance number on [Nvidia's charts](https://images.nvidia.com/aem-dam/Solutions/geforce/ada/news/rtx-40-series-graphics-cards-announcements/geforce-rtx-40-series-gaming-performance.png) utilizing the 3 games without DLSS. **The games are: Resident Evil Village, Assassin's Creed Valhalla, and The Division 2**\n2. I will take the minimum and maximum uplift vs 3090 Ti across these 3 games\n3. **No DLSS**. This should be some sort of worst case scenario without DLSS.\n4. I did similar napkin math a couple years ago for 3080 vs prior generation and the number comes in within 5-10% of final benchmarks.\n5. Since this is first party benchmark numbers, please take this with grains of salt. **This is just for fun while we wait for actual benchmarks**\n6. Please Wait for Benchmarks\n7. Wait for Benchmarks\n\nFirst, we need to determine what these uplifts are. Based on my \"totally scientific\" (just kidding) line-drawing methodology, this is what I get.\n\n|**vs 3090 Ti Performance**|**Min**|**Max**|\n|:-|:-|:-|\n|RTX 4080 12GB|0.9x (Resident Evil Village)|0.99x (The Division 2)|\n|RTX 4080 16GB|1.15x (The Division 2)|1.2x (Resident Evil Village)|\n|RTX 4090|1.5x (AC Valhalla)|1.7x (Resident Evil Village)|\n\nThese numbers came in relatively close to what [this other person sees](https://twitter.com/SkyJuice60/status/1572288601781866498?s=20&t=okQhIy1RAK0gdOTEpfeIgA)\n\nNext, I grabbed the 4K average FPS figure from Techpowerup review of RTX 3090 Ti FE [here](https://www.techpowerup.com/review/nvidia-geforce-rtx-3090-ti-founders-edition/31.html). Direct link to the 4K table [here](https://tpucdn.com/review/nvidia-geforce-rtx-3090-ti-founders-edition/images/average-fps_3840-2160.png)\n\nBelow is the summarized table starting from RTX 2070 and up along with its Launch MSRP.\n\n|**Techpowerup 4K Benchmark**|**Average FPS**|**Launch MSRP**|\n|:-|:-|:-|\n|RTX 2070|41.1|$499 MSRP / $599 FE|\n|RTX 2070 Super ^(\\[1\\])|46.7|$499|\n|RTX 2080|50.7|$699 MSRP / $799 FE|\n|RTX 3060 Ti|55.6|$399|\n|RTX 3070|63.6|$499|\n|RTX 2080 Ti|64.6|$999 MSRP / $1,199 FE|\n|RTX 3070 Ti|68.5|$599|\n|RTX 3080 10GB|82.2|$699|\n|RTX 4080 12GB (0.9x 3090 Ti)|91.5|$899|\n|RTX 3080 Ti|91.9|$1,199|\n|RTX 3090|93.4|$1,499|\n|RTX 4080 12GB (0.99x 3090 Ti)|100.7|$899|\n|RTX 3090 Ti|101.7|$1,999|\n|RTX 4080 16GB (1.15x 3090 Ti)|116.9|$1,199|\n|RTX 4080 16GB (1.2x 3090 Ti)|122.0|$1,199|\n|RTX 4090 (1.5x 3090 Ti)|152.6|$1,599|\n|RTX 4090 (1.7x 3090 Ti)|172.9|$1,599|\n\n\\[1\\] - RTX 2070 Super Average FPS is +13.64% from RTX 2070 per [this benchmark](https://www.techpowerup.com/review/nvida-geforce-rtx-2070-super/27.html) from TPU\n\n**Generational Improvements vs Cost**\n\nAmpere to Ada comparison are bolded!\n\n|**RTX 90 Class**|**2080 Ti -> 3090**|**2080 Ti -> 3090 Ti**|**3090 -> 4090**|**3090 Ti -> 4090**|\n|:-|:-|:-|:-|:-|\n|FPS Uplift|1.45x|1.57x|**1.63x - 1.85x**|**1.5x - 1.7x**|\n|Cost|1.5x|2.0x|**1.07x**|**0.8x**\\*\\*\\*\\***^(\\[2\\])**|\n\n\\[2\\] - RTX 3090 Ti MSRP is $1,999. If we were to use [current 3090 Ti FE price on Bestbuy](https://www.bestbuy.com/site/nvidia-geforce-rtx-3090-ti-titanium-and-black/6502626.p?skuId=6502626) of $1,099, the cost uplift between $1,099 3090 Ti to 4090 is **1.45x.**\n\n&#x200B;\n\n|**RTX 80 Class**|**2080 -> 3080**|**3080 -> 4080 16GB**|**3080 Ti -> 4080 16GB**|**3080 -> 4080 12GB**|\n|:-|:-|:-|:-|:-|\n|FPS Uplift|1.6x|**1.4x - 1.5x**|**1.27x - 1.33x**|**1.1x - 1.22x**|\n|Cost|1.0x|**1.72x**|**1.0x**|**1.29x**|\n\n&#x200B;\n\n|**RTX 70 Class**|**2070 -> 3070**|**2070 Super -> 3070**|**3070 -> 4080 12GB**|\n|:-|:-|:-|:-|\n|FPS Uplift|1.5x|1.36x|**1.44x - 1.58x**|\n|Cost|1.0x|1.0x|**1.8x**|\n\n# Some observations\n\n* **RTX 4090**\n   * Nothing that hasn't been said before on the subreddit but RTX 4090 looks to be the \"superstar\" SKU of Ada Lovelace generation. It seems to provide substantial performance improvement (1.63x-1.85x) for pretty similar pricing (1.07x) to RTX 3090 before it. Similar parallel can be drawn with RTX 3080 performance and price in relations to RTX 2080 before it.\n* **RTX 4080 16GB**\n   * RTX 4080 16GB looks to be the \"true\" gen over gen successor of RTX 3080 (1.4-1.5x) but its cost increase (1.72x) negated the appeal of its performance increase\n   * If we view 4080 16GB from the lens of \"80 Ti class\" GPU, then it looks to provide approx 1.3x performance for the same price ($1,199) vs 3080 Ti.\n* **RTX 4080 12GB**\n   * RTX 4080 12GB can be viewed 2 ways\n      * As an 80 class GPU, it is providing around 1.1x-1.22x more performance vs 3080 at 1.29x the cost.\n      * As an 70 class GPU, it is providing 1.44x-1.58x more performance vs 3070 at 1.8x the cost.\n   * I suspect that Nvidia is calling it \"RTX 4080\" to avoid price comparison with RTX 3070 because that's a steep increase in price (1.8x) despite its healthy performance improvement (approx 1.5x).\n   * Unfortunately comparing it with 3080 also shows a relatively weak generational improvement (1.1x-1.22x) for its cost increase (approx 1.3x). Practically flat Perf/$ for this market segment. It's a lose-lose situation because 3080 was a really strong SKU in terms of performance and price last generation.\n* Please remember that no DLSS included. So this should be a very early conservative guesses of what your experience with the products will be. DLSS will improve performance (thus increasing value proposition listed in this post if your games have DLSS), RT will improve image quality, etc etc.\n\nAny other observations feel free to comment!\n\nRemember this is just for fun while we wait for benchmark. Please take this with grains of salt and remember the number comes from a published first party benchmark.\n\nBait for Wenchmark.\n\nWait for Benchmark.",
    "comments": [
      "Nowadays, performance is linear and price is exponential. Thanks Nvidia.",
      "The whole 4070 debacle is really grinding my gears. I was pretty hype for this card before Nvidia butchered the price and tried to trick us with marketing.",
      "That was a fun read, thanks for your effort.",
      "the way its meant to be paid",
      "For 4090 in relations to 3090 and 3090 Ti? Yes (Performance increase is more than Cost increase)\n\nFor the other 2 SKUs? No. (Performance increase is less than Cost increase)",
      "Don't worry. They're going to repurpose the 4060 and sell it as a 4070 for 600 dollars later.",
      "The 3 games I used do not have DLSS support as they are AMD partnered games. In fact, if you look at benchmarks with AC Valhalla, it is almost always 30 series' worst performance when compared to its AMD equivalent products.\n\nMSFS does have DLSS and I believe Darktide as well in the \"Today's Games\" section but they are not part of this analysis.",
      "I'd argue that the issue here is the price has increased pretty much in lockstep (or more) with the performance increase for the 2 4080 SKUs.\n\nIn the old Moore's Law age, you either get 2x performance for 1x price or 1x performance for 0.5x price.\n\nI guess this is in like with Jensen's statement last week about Moore's Law being dead.",
      "Or customers can tell Jensen to shove it.  This isn't a ransom, Nvidia isn't the only one that gets to have a say on the pricing of products.  Customers can force a change by not buying and Nvidia has the margins to do so.\n\nIn reality this is Nvidia pushing for margins after it just came off record profits during the pandemic.  Meanwhile everyone else is facing reduced discretionary income.  All these companies refusing to cut margins going into a recession are in for a rude awakening.  These products are non-essential for many.",
      "The more you buy, the more you pay.",
      "Thanks! This is really interesting - and matches up with the other speculation I’ve seen on r/hardware etc.\n\nNvidia is really relying on DLSS3 and the RT improvements to draw customers to Lovelace. I could see a 3090/3090TI being below the $899 MSRP of the 4080 12 GB very shortly (in the USA at least) - if you don’t care about RT (or the adoption of DLSS3 isn’t widespread or is underwhelming), why wouldn’t you go for the older Ampere? Even the 4080 16 GB might not provide the uplift you’re looking for with the potential price difference. Furthermore, once people purchase cards, it’s unlikely you’ll get them to upgrade again in the short term - this also makes it more unlikely for software companies to support DLSS3 in a widespread fashion.\n\nThat being said, the 4090 is quite impressive - higher than expected rasterization difference (and obviously great DLSS and RT performance). Itll be very interesting to see how it stacks up with RDNA3",
      "4080 16GB has a pretty healthy gap from 3080 perf wise. I think a $999 pricepoint will make more sense for that SKU (not ideal for consumer but at least it follows the Price/$ trendline). \n\nUnfortunately that will necessitates 4080 12GB to come down in pricing to $699-799 pricepoint.\n\nIf Nvidia could do this they would've done it instead of announcing at the current prices. So... probably not going to happen?",
      "4080 12GB should cost us $499\n\n4080 16GB should cost us $699\n\nand that is when taking into account higher costs of production\n\notherwise Nvidia is gradually making PC gaming only for the wealthy",
      "Yeah. 4080 pricing is definitely out of whack.",
      "Don't think AMD sponsored game will add DLSS honestly. Even they do then the number makes no sense. 1.5x perf with DLSS means there is no performance increase for 4090 vs 3090 Ti lol. Just not going to happen.",
      "Still laughing at $899 before tax for the 4070.\n\nThis gun' be good.",
      ">I can’t actually remember whether the 3090 was horrifying at launch\n\nThey increased the top end price from an already vomit inducing $1200 up to $1500, meanwhile they touted the 3080 as an absolute performance monster at a $700 MSRP. The 3090 pricing was absolutely horrific at launch. Granted, everything ended up obscenely expensive, but MSRP the 3090 was a total scam compared to the 3080 at MSRP. It was a Titan card without the name.\n\nFast forward to now, and they've flipped the script. The 4090 is a literal bargain compared to the jokes they're calling 4080s.",
      "yeah its gonna be 10GB and 160 bus.",
      "Regardless what you'd like to believe, 1.5x performance uplift with DLSS means there's no performance increase without it. Especially seeing 2x and more for games that do actually have DLSS 3 like Darktide and MSFS.\n\nThe math just doesn't add up... unless that's what you want to believe. In which case then this discussion is pointless.",
      "I thought DLSS was enabled in the comparisons for \"Today's Games' in the official Nvidia charts?"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "rtx 4080",
      "4080",
      "4080 super",
      "rtx 4080 super"
    ],
    "title": "Game Ready & Studio Driver 551.23 FAQ/Discussion",
    "selftext": "# GeForce Hotfix Driver Version 551.46\n\nGeForce Hotfix display driver version 551.46 is based on our latest [Game Ready Driver 551.23](https://www.nvidia.com/en-us/geforce/news/geforce-rtx-4070-ti-super-rtx-video-hdr-game-ready-driver/). This hotfix addresses the following issues:\n\n* Some users may experience intermittent micro-stuttering in games when vertical sync is enabled \\[4445940\\]\n* Potential stutter may be observed when scrolling in web browsers on certain system configurations \\[4362307\\]\n* \\[Red Dead Redemption 2\\]\\[Vulkan\\] Stutter observed on some Advanced Optimus notebooks \\[4425987\\]\n* \\[Immortals of Aveum\\] Addresses stability issues over extended gameplay \\[4415277\\]\n\n**551.46 Hotfix Download Link**: [https://international.download.nvidia.com/Windows/551.46hf/551.46-desktop-notebook-win10-win11-64bit-international-dch.hf.exe](https://international.download.nvidia.com/Windows/551.46hf/551.46-desktop-notebook-win10-win11-64bit-international-dch.hf.exe)\n\n# --------------------------------\n\n# RTX 4080 Super owners,\n\n# Please download Driver version 551.31. This version is the same as 551.23 except with adding support for RTX 4080 Super.\n\n# For everyone else, use 551.23 as they are the same driver otherwise.\n\n**551.31 Release Notes**: [https://us.download.nvidia.com/Windows/551.31/551.31-win11-win10-release-notes.pdf](https://us.download.nvidia.com/Windows/551.31/551.31-win11-win10-release-notes.pdf)\n\n**551.31 Download Link**: [https://us.download.nvidia.com/Windows/551.31/551.31-desktop-win10-win11-64bit-international-dch-whql.exe](https://us.download.nvidia.com/Windows/551.31/551.31-desktop-win10-win11-64bit-international-dch-whql.exe)\n\n\\--------------------------------\n\n# Game Ready & Studio Driver 551.23 has been released.\n\n**Article Here**: [https://www.nvidia.com/en-us/geforce/news/geforce-rtx-4070-ti-super-rtx-video-hdr-game-ready-driver/](https://www.nvidia.com/en-us/geforce/news/geforce-rtx-4070-ti-super-rtx-video-hdr-game-ready-driver/)\n\n**Game Ready Driver Download Link**: [Link Here](https://us.download.nvidia.com/Windows/551.23/551.23-desktop-win10-win11-64bit-international-dch-whql.exe)\n\n**Studio Driver Download Link**: [Link Here](https://us.download.nvidia.com/Windows/551.23/551.23-notebook-win10-win11-64bit-international-nsd-dch-whql.exe)\n\n**New feature and fixes in driver 551.23:**\n\n**Game Ready** \\- This new Game Ready Driver provides the best gaming experience for the latest new games supporting DLSS 3 technology including Like a Dragon: Infinite Wealth. Further support for new titles leveraging NVIDIA DLSS technology includes the launch of Enshrouded, TEKKEN 8, and Suicide Squad: Kill The Justice League which support DLSS Super Resolution.\n\n**What's New in Release 550**:\n\n* Support for CUDA 12.4.\n* Adds support for RTX Video HDR.\n* Adds support for the “Auto” setting for RTX Video Super Resolution.\n* Adds support for NVIDIA Ultra Low Latency Mode with DirectX 12 titles.\n* Adds the latest performance improvements, bug fixes, and driver enhancements.\n\n**Applications** \\- The January NVIDIA Studio Driver provides optimal support for the latest new creative applications and updates including the NVIDIA RTX Remix open Beta. In addition, this Studio Driver introduces support for RTX Video HDR, as well as for the new GeForce RTX 4070 SUPER, GeForce RTX 4070 Ti SUPER, and GeForce RTX 4090 D GPUs.\n\n**Gaming Technology** \\- Adds support for the GeForce RTX 4070 Ti SUPER GPU\n\n**Fixed Gaming Bugs**\n\n* Forza Horizon 4: Ansel/ Freestyle filters cause application to freeze or crash \\[4253513\\]\n\n**Fixed General Bugs**\n\n* RTX 4060 Ti: Display may randomly flicker with a black bar on the top of the screen when using desktop apps \\[4239893\\]\n* Horizontal band may appear when cloning a G-SYNC display to HDMI monitor \\[4103923 / 4343427\\]\n\n**Open Issues**\n\n* \\[Netflix\\] Display issues for videos when using Edge browser. Recommend using Windows Netflix application as workaround. \\[4388454\\]\n* GeForce GTX 10/RTX 20 series: PC may randomly freeze when Windows Hardware- Accelerated GPU Scheduling and NVIDIA SLI are both enabled \\[4009884\\]\n* Potential stutter may be observed when scrolling in web browsers on certain system configurations \\[4362307\\]\n\n**Additional Open Issues from** [GeForce Forums](https://www.nvidia.com/en-us/geforce/forums/game-ready-drivers/13/535546/geforce-grd-55123-feedback-thread-released-12424/)\n\n*Notes: This is not new. Manuel from Nvidia has been tracking any additional driver issues in their forum post separate from release notes. Started doing this recently and will continue moving forward*\n\n* N/A\n\n**Driver Downloads and Tools**\n\nDriver Download Page: [Nvidia Download Page](https://www.nvidia.com/Download/Find.aspx?lang=en-us)\n\nLatest Game Ready Driver: **551.23** WHQL\n\nLatest Studio Driver: **551.23** WHQL\n\nDDU Download: [Source 1](https://www.wagnardsoft.com/) or [Source 2](http://www.guru3d.com/files-details/display-driver-uninstaller-download.html)\n\nDDU Guide: [Guide Here](https://docs.google.com/document/d/1xRRx_3r8GgCpBAMuhT9n5kK6Zse_DYKWvjsW0rLcYQ0/edit)\n\n**DDU/WagnardSoft Patreon:** [**Link Here**](https://www.patreon.com/wagnardsoft)\n\nDocumentation: [Game Ready Driver 551.23 Release Notes](https://us.download.nvidia.com/Windows/551.23/551.23-win11-win10-release-notes.pdf) | [Studio Driver 551.23 Release Notes](https://us.download.nvidia.com/Windows/551.23/551.23-win10-win11-nsd-release-notes.pdf)\n\nNVIDIA Driver Forum for Feedback: [Link Here](https://www.nvidia.com/en-us/geforce/forums/game-ready-drivers/13/535546/geforce-grd-55123-feedback-thread-released-12424/)\n\n**Submit driver feedback directly to NVIDIA**: [Link Here](https://forms.gle/kJ9Bqcaicvjb82SdA)\n\n**RodroG's Driver Benchmark:** TBD\n\n[r/NVIDIA](https://new.reddit.com/r/NVIDIA/) Discord Driver Feedback: [Invite Link Here](https://discord.gg/y3TERmG)\n\nHaving Issues with your driver? Read here!\n\n**Before you start - Make sure you Submit Feedback for your Nvidia Driver Issue**\n\nThere is only one real way for any of these problems to get solved, and that’s if the Driver Team at Nvidia knows what those problems are. So in order for them to know what’s going on it would be good for any users who are having problems with the drivers to [Submit Feedback](https://forms.gle/kJ9Bqcaicvjb82SdA) to Nvidia. A guide to the information that is needed to submit feedback can be found [here](http://nvidia.custhelp.com/app/answers/detail/a_id/3141).\n\n**Additionally, if you see someone having the same issue you are having in this thread, reply and mention you are having the same issue. The more people that are affected by a particular bug, the higher the priority that bug will receive from NVIDIA!!**\n\n**Common Troubleshooting Steps**\n\n* Be sure you are on the latest build of Windows 10 or 11\n* Please visit the following link for [DDU guide](https://goo.gl/JChbVf) which contains full detailed information on how to do Fresh Driver Install.\n* If your driver still crashes after DDU reinstall, try going to Go to Nvidia Control Panel -> Managed 3D Settings -> Power Management Mode: Prefer Maximum Performance\n\nIf it still crashes, we have a few other troubleshooting steps but this is fairly involved and you should not do it if you do not feel comfortable. Proceed below at your own risk:\n\n* A lot of driver crashing is caused by Windows TDR issue. There is a huge post on GeForce forum about this [here](https://forums.geforce.com/default/topic/413110/the-nvlddmkm-error-what-is-it-an-fyi-for-those-seeing-this-issue/). This post dated back to 2009 (Thanks Microsoft) and it can affect both Nvidia and AMD cards.\n* Unfortunately this issue can be caused by many different things so it’s difficult to pin down. However, editing the [windows registry](https://www.reddit.com/r/battlefield_4/comments/1xzzn4/tdrdelay_10_fixed_my_crashes_since_last_patch/) might solve the problem.\n* Additionally, there is also a tool made by Wagnard (maker of DDU) that can be used to change this TDR value. [Download here](http://www.wagnardmobile.com/Tdr%20Manipulator/Tdr%20Manipulator%20v1.1.zip). Note that I have not personally tested this tool.\n\nIf you are still having issue at this point, visit [GeForce Forum for support](https://forums.geforce.com/default/board/33/geforce-drivers/) or contact your manufacturer for RMA.\n\n**Common Questions**\n\n* **Is it safe to upgrade to <insert driver version here>?** *Fact of the matter is that the result will differ person by person due to different configurations. The only way to know is to try it yourself. My rule of thumb is to wait a few days. If there’s no confirmed widespread issue, I would try the new driver.*\n\n**Bear in mind that people who have no issues tend to not post on Reddit or forums. Unless there is significant coverage about specific driver issue, chances are they are fine. Try it yourself and you can always DDU and reinstall old driver if needed.**\n\n* **My color is washed out after upgrading/installing driver. Help!** *Try going to the Nvidia Control Panel -> Change Resolution -> Scroll all the way down -> Output Dynamic Range = FULL.*\n* **My game is stuttering when processing physics calculation** *Try going to the Nvidia Control Panel and to the Surround and PhysX settings and ensure the PhysX processor is set to your GPU*\n* **What does the new Power Management option “Optimal Power” means? How does this differ from Adaptive?** *The new power management mode is related to what was said in the Geforce GTX 1080 keynote video. To further reduce power consumption while the computer is idle and nothing is changing on the screen, the driver will not make the GPU render a new frame; the driver will get the one (already rendered) frame from the framebuffer and output directly to monitor.*\n\nRemember, driver codes are extremely complex and there are billions of different possible configurations. The software will not be perfect and there will be issues for some people. For a more comprehensive list of open issues, please take a look at the Release Notes. Again, I encourage folks who installed the driver to post their experience here... good or bad.\n\n*Did you know NVIDIA has a Developer Program with 150+ free SDKs, state-of-the-art Deep Learning courses, certification, and access to expert help. Sound interesting?* [Learn more here](https://nvda.ws/3wCfH6X)*.*",
    "comments": [
      "Please tell me I can get off of 537.58 now",
      "Wait… Ultra Low Latency hasn’t been on DX12 titles since its implementation?? Wow. I gotta try this now. I’ve been using it with some games that use DX12 thinking it would work haha.",
      "NULL (Nvidia Ultra Low Latency) is for games that do not support Reflex as that is something the games need to implement.\n\nIf the game supports Reflex, that feature will override NULL",
      "Dx12 low latency? Man can't wait to get home and try that",
      "There will be another one next week to support 4080 Super.",
      "fingers crossed for all of us, we just want to game in peace.",
      "Stutter update: interesting findings with these drivers. It looks like quite a lot has been fixed. Adding u/m_w_h \n\nIn my testing, I featured the following settings:\n\n* HAGs = on\n* V-Sync = on globally\n* G-Sync = on\n* FPS cap = 235 (240HZ display)\n* Prefer Max Perf (PMP) = tested both on and off\n\nGames tested and results:\n\n* DOOM DSDA port - OpenGL API - no stuttering with or without PMP set to on. This is a huge improvement over previous drivers, which would require PMP to be on for smooth gameplay.\n* DOOM GZDOOM - Vulkan API - stuttering is massively reduced, even with PMP set to off. This is also a huge improvement over previous drivers. I will still keep PMP on for smoother gameplay, but we're moving in the right direction.\n* VKQUAKE (Vulkan API obvs!) - stuttering is somewhat reduced, but still visible without PMP on. I will be keeping PMP on for smooth gameplay.\n* DUSK (not sure of the API but it runs on Unity engine I think) - stuttering is the same as previous drivers with PMP set to off; PMP set to on completely clears up all stuttering.\n\nOverall, this is an improvement over previous drivers. I will be keeping PMP on through NVCP on a per game basis for a smoother experience.",
      "This comment is unofficial and not maintained by Nvidia. I'm not a Nvidia employee, just a fellow Redditor helping the Reddit community by tracking issues and collating information / troubleshooting.\n\nWill keep the comment updated [like I did with previous driver](https://www.reddit.com/r/nvidia/comments/198xlyb/game_ready_driver_54665_faqdiscussion/kiajwbg/). \n\nEDITs section in footer can be used to track additions/updates.\n\n---\n\n**Notes**\n\n* **551.46 Hotfix** driver addresses issues with Vsync / browser stutters https://nvidia.custhelp.com/app/answers/detail/a_id/5519 and supports all current Nvidia GPUs i.e. including 4070 SUPER, 4070Ti SUPER, 4080 SUPER\n\n* Windows 10 KB5033372 *or newer* addresses a Windows (not driver)  issue that affects non-admin processes, specifically game performance goes down and video stutters \n\n* 'RTX Video HDR' is supported for all RTX GPUs in 551.23 and later drivers. 'RTX Video Super Resolution' is supported for all RTX GPUs in 545.84 and later drivers\n\n* Samsung Odyssey Neo G9 57\" G95NC 240Hz issue appears to be a GPU firmware/hardware limitation related to DSC, not specifically a driver issue\n\n* Security Bulletin issues updated by Nvidia on 31st October 2023 are addressed by 546.01 and later - https://nvidia.custhelp.com/app/answers/detail/a_id/5491\n\n* Shader cache locations have been updated for [545 Release/Mainline](https://www.reddit.com/r/nvidia/comments/18go5ej/game_ready_studio_driver_54633_faqdiscussion/kd1r7zk/) or newer drivers  - *%USERPROFILE%\\AppData\\LocalLow\\NVIDIA\\PerDriverVersion\\DXCache* and *%USERPROFILE%\\AppData\\LocalLow\\NVIDIA\\PerDriverVersion\\GLCache* \n\n---\n\n**Benchmarks and Analysis**\n\nTBC\n\n---\n\n**Branch Information**\n\nRecent branch information only, an extensive and detailed list can be found in the subcomment at https://www.reddit.com/r/nvidia/comments/19ehx1r/game_ready_studio_driver_55123_faqdiscussion/kjcwi8c/\n\n* 551.52: r551_06-24 (Quadro)\n\n* 551.46: r551_06-21 (Hotfix) \n\n* 551.32: r551_06-17 (3050 6GB Only)\n\n* 551.31: r551_06-16 (4080 Super Only)\n\n* **551.23**: r551_06-14 (Game Ready/Quadro/Studio)\n\n* 546.65: r546_33-9 (Game Ready)\n\n* 546.33: r545_00-157 (Game Ready/Studio)\n\n* 545.84: r545_74-7 (Game Ready)\n\n* 538.37: VK535_87-26 (Developer) ^(States Series 40 Super Support - https://i.imgur.com/cVnaUDL.png)\n\n* 537.58: r537_56-2 (Game Ready/Studio)\n\n---\n\n**Confirmed Additional Issues** \n\nThis section covers issues officially acknowledged by Nvidia that are not in the original driver [release notes](https://uk.download.nvidia.com/Windows/551.23/551.23-win11-win10-release-notes.pdf) **OR** in the Reddit moderator's /r/Nvidia driver post\n\n* [GeForce RTX Series 40] graphics cards running older firmware could experience blank screens on boot with certain motherboards in UEFI mode until the OS loads - https://nvidia.custhelp.com/app/answers/detail/a_id/5411/\n\n* [Halo Wars 2] in-game foliage is larger than normal and displays constant flickering [3888343]\n\n* [Monster Hunter: World] Game may display artifacting in DX11. No issue in DX12 [4471655]\n\n* [The Talos Principle Principle 2/Ark: Survival Ascended] Game may randomly crash if DLSS Frame Generation is enabled [4362644]\n\n* [NVIDIA Freestyle filter] settings are not saved after quitting game [4472656]\n\n* [Chromium Browsers][SDR] when playing back SDR videos in Chrome/Edge, deep blacks may not appear correctly when HDR is enabled from the Windows Settings [4492243]\n\n* [Notebook/Laptop] maximum brightness on some notebook panels may appear dimmer after updating to driver 551.23 [4486559]\n\n* [Rainbow Six: Siege] [Vulkan] may randomly crash during gameplay after updating to driver 551.23 [4494886]\n\n---\n\n**Unconfirmed Additional Issues** \n\nThis section contains issues not officially acknowledged by Nvidia but are reported across multiple forums:\n\n* [GeForce RTX Series 40 GPUs] stability/TDR/black screen issues. Check for a *motherboard BIOS* update that states '*compatibility updates for Lovelace*'. The motherboard update is in *addition* to any VBIOS update\n\n* [Lenovo Legion GEN6 Laptops] enabling GSYNC (dedicated mode) may result in overshoot artifacts, distortion, stuttering, flickering. Full details and steps to reproduce in comment by /u/Rfx_0 at https://www.reddit.com/r/nvidia/comments/15luoca/game_ready_studio_driver_53699_faqdiscussion/jvlqbpf/\n\n* [Lenovo Legion 3070m Laptops] ~~display brightness issue in dedicated mode~~. Fixed with BIOS update *GKCN64WW* (thanks /u/Rfx_0)\n\n* [Nvidia Management Library] [NVML] frametime spikes, framerate stutters and elevated load when monitoring utilities that access NVML API features (e.g. *nvmlDeviceGetPowerUsage*, *NvAPI_GPU_ClientPowerTopologyGetStatus*) are running \n\nFor any issues not officially acknowledged by Nvidia please submit a report using the [official form](https://forms.gle/kJ9Bqcaicvjb82SdA). General guidance in [provide valuable feedback](http://nvidia.custhelp.com/app/answers/detail/a_id/3141) document. Display issue guidance in [collecting logs for display issues](https://nvidia.custhelp.com/app/answers/detail/a_id/5149)\n\n---\n\n**Resizable Bar (ReBAR) Support** \n\nNo ReBAR additions / changes since the previous driver other than missing ReBAR flags *Options* and *Size* in **some** ReBAR game profiles and new ReBAR compatibility flags *0x00e942fc* (not be be confused with *0x00e942fe (DirectX)*) and *0x20feaf0d (Vulkan)* \n\nDiscussion on the above and a complete list of ReBAR enabled games/applications for this driver can be found in the subcomment at https://www.reddit.com/r/nvidia/comments/19ehx1r/game_ready_studio_driver_55123_faqdiscussion/kjcxmbr/\n\n34 unique profiles out of 6835 profiles in the driver have official ReBAR support enabled, however restrictions may apply based on CPU platform:\n\n* Intel CPU based platforms have ReBAR disallowed for F1 2021, F1 2022, Hitman 3 and Horizon Zero Dawn\n\n* AMD CPU based platforms have no restrictions, all 34 unique profiles are supported\n\n---\n\n**Troubleshooting and Workarounds**\n\n* Performance dropping significantly in all games after installing a driver, see https://nvidia.custhelp.com/app/answers/detail/a_id/5408/\n\n* Laptop users with major stutter/framerate issues when running games with official ReBAR support, try [setting flag 0x00e942fe to 1 in the game's profile](https://www.reddit.com/r/nvidia/comments/17v3i31/game_ready_driver_54617_faqdiscussion/kb8le6q/) *OR* disable ReBAR in Nvidia's game profile *OR* use Hybrid GPU mode rather than Discrete GPU mode\n\n* Browser responsiveness issues under Windows 11 even after 551.46. Try disabling Windows 11 feature *EcoQoS* (Efficiency Mode) for the browser e.g. Chromium/Edge append *--disable-features=UseEcoQoSForBackgroundProcess* to a shortcut and Firefox set *dom.ipc.processPriorityManager.backgroundUsesEcoQoS* to false OR force off using a utility such as Process Lasso \n\n* DPC Latency spikes, if drivers 536.67 and later haven't resolved the issue try [potential workaround(s) in subcomment](https://www.reddit.com/r/nvidia/comments/19ehx1r/game_ready_studio_driver_55123_faqdiscussion/kjcwo87/)\n\n* Display blinking/temporary blackout, try setting *'Content Type Detection'* in *'Nvidia Control Panel > Display > Adjust Desktop Color Settings'* to *'Desktop Programs'* if setting is available *AND/OR* adjust monitor/TV's display settings for auto-content detection *AND/OR* check for a display firmware update *AND/OR* avoid triggering Display Stream Compression (DSC) *AND/OR*  disable display 'HDMI Consumer Electronics Control' (CEC) *AND/OR* disable 'AMD Instant Game Response' on LG displays\n\n* NIS (Nvidia Image Scaling) this driver still has an 8% to 10% NIS performance penalty on Maxwell/Pascal based GPUs. Workaround is available for Maxwell/Pascal based cards: https://www.reddit.com/r/nvidia/comments/tkca3g/game_ready_studio_driver_51215_faqdiscussion/i1sod9e/ \n\n* Custom Resolution Utility (CRU) adding, removing or editing custom resolutions / EDID information may cause issues (Nvidia Driver Bug?). If impacted, reset the EDID to default and don't use CRU  - https://www.monitortests.com/forum/Thread-Removing-TV-Resolution-causes-black-screens-Crashesa?pid=14462#pid14462\n\n* NVLDDMKM / TDR / Stability issues, if troubleshooting (re-evaluating RAM/CPU/GPU overclocks voltage timings, disabling PCI Express Link State Power Management/PCI Express ASPM (PCH)/PCI Express Clock Power Gating in BIOS, testing with Nvidia Debug Mode, testing Powersupply [PSU] e.g set to Single Rail, disabling Hardware Accelerated GPU Scheduling setting, EDID ?driver? bug (see CRU entry), disabling hibernation/fast startup, disabling Low Level Driver options in Afterburner/PrecisionX etc) hasn't helped try a driver considered by the community as stable/consistent\n\n* Drivers 512.95, 516.94, 517.48, 522.25, 526.86, 528.49, 532.34 are considered stable/consistent by the community. While driver branches based on r530/r535/r545 mainline currently have the most reported issues, versions 536.99, 537.13, 537.42, 537.58 and 538.37 are worth trying despite issues\n\n---\n\n**EDITs**\n\n01: tested 'NIS (Nvidia Image Scaling)' on Pascal/Maxwell GPUs\n\n02: updated branch information\n\n03: updated Resizable Bar (ReBAR) Support with profile counts / flags change\n\n04: added to unconfirmed NMVL specific API call issue\n\n05: re-added to unconfirmed, Lenovo Legion issues\n\n06: added to confirmed Monster Hunter: World issue\n\n07: added to confirmed The Talos Principle Principle 2 and Ark: Survival Ascended issue (thanks pidge2k)\n\n08: added to confirmed Freestyle Filter issue (thanks pidge2k)\n\n09: updated notes section vsync/stutter driver entry\n\n10: added to notes Windows 11 KB5034204\n\n11: added 538.37 branch information\n\n12: added 551.46 Hotfix to notes and branch information\n\n13: added to confirmed 'Chromium Browsers' SDR' / 'Laptop Brightness' / Rainbow Six: Siege issues (thanks pidge2k)\n\n14: added 551.52\n\n---",
      "I'm so confused with all these things Nvidia is doing. Is Reflex not the low latency technique already?",
      "I upgraded from 537.58 again yesterday, I tried all of the 546.x drivers and they caused me problems. \n\nThe main one was a system wide stutter caused when the driver nvlddmkm doesn't seem to start properly with windows. Event viewer gives error 100, not found. \n\nThe system either loads fine, and works flawlessly all day, or starts stuttering as soon as I hit windows desktop and open Chrome or any application. If I don't close the application, the system wille eventually blue screen, citing a hardware error. \n\nI ran SFC and DISM, both found nothing wrong. Samsung magician reports my SSDs are in good condition, and my EXPO is stable, validated by an overnight memtest when I built the system. \n\nI have had no major issues until updating to these god forsaken drivers. \n\nAll was going well, yesterday I played cyberpunk for hours with no issues. Today, my system immediately stutters it's shit all over the floor as soon as I hit desktop. Nvlddmkm pops off in event viewer again. \n\nBack to 537.58. I await the Nvidia hotfix.\n\nEdit 7800X3D / 32gb DDR5 6000 / 4090FE / win 11.",
      "So they lied regarding the hotfix coming out with the next game-ready driver. Yay",
      "Need someone kind enough to test the v-sync and stutter issue.",
      "RTX Video HDR is just as good as I hoped it would be, essentially autohdr for internet videos, I love it.",
      "I never update until a while after this thread has been out, ill wait and read what others have said.",
      "Yes, just in time for Tekken 8 too.",
      "May be of interest.\n\nFrom the unofficial 551.23 tracking comment at https://www.reddit.com/r/nvidia/comments/19ehx1r/game_ready_studio_driver_55123_faqdiscussion/kjcwdip/\n\n* ?Vsync related? stutters [isn't a Nvidia driver bug](https://www.reddit.com/r/nvidia/comments/198xlyb/game_ready_driver_54665_faqdiscussion/kiurbcv/) but should be addressed with a driver side workaround in a driver to be [released after 551.31](https://www.reddit.com/r/nvidia/comments/198xlyb/game_ready_driver_54665_faqdiscussion/koc6ccd/) **UPDATED** with new information from Nvidia\n\n---\n\n**EDIT:** added latest information from Nvidia, workaround driver delayed \n\n---",
      "they so lied about the hotfix driver didn't they",
      "Yep, he had a 1070 Ti and won an RTX 4080 at the end of 2022. His tag is u/lokkenjp, and he no longer does benchmarks of any description for months now. It was essentially just a hobby of his to do in his spare time.",
      "It's just fun they keep releasing new buggy drivers on top of old buggy drivers.\n\nIt all should be declared beta and having known major issue months ago.\n\nPity for the 4080 SUPER owners, they won't have a chance to get older driver variant without microstutter. Should have been based on 537.58 either.",
      "I think the person that was doing pascal test upgraded to an RTX card and stopped doing them :\\"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "rtx 4080",
      "4080",
      "4080 super",
      "rtx 4080 super"
    ],
    "title": "MSI EXPERT GeForce RTX 4080 SUPER card gets confirmed specs - VideoCardz.com",
    "selftext": "",
    "comments": [
      "it looks like you can grate cheese on it.",
      "Staying put with 3080Ti FE, but that is the nicest looking AIB card I've seen in many a generation.  My build isn't visible, but I'd still be leaning toward this vs the anime space invaders designs of other cards.",
      "Honestly I think the FE looks better with the all black look. I like the Suprim cards aesthetics more IMO",
      "FE looks for premium price lol",
      "Yeah and, dual purpose is the name of the game.",
      "I wish more third party gpu manufacturers would just stick with a simple and clean design rather than throwing RGB on every possible surface.",
      "This design seems the most appealing to me out of all the different variations. But i have a lianli q58 and according to this article its over the limit of 320mm clearance unfortunately",
      "That’s the super part.",
      "Looks real nice.",
      "Reminds me of the FE shroud for the GTX 480",
      "RGB is brutal. I can’t stand the “gamer” look of everything in this industry.",
      "How much are you willing to sell it for?",
      "FE is 304mm. Not sure about other AIBs",
      "Haven’t you see those videos where they slice the cheese with a hot knife so it melts as you cut it? It’s kind of like that",
      "A 256 bit bus?",
      "cast alu",
      "That’s literally what he means with his comment lol",
      "Does a 4080 even exist that isn’t over 320?",
      "No. It’s a flow through design similar to NVIDIAs current FE cards.",
      ">Bus speed can make huge diff when you do the maths on bandwith\n\nBoth bus width and memory speed determine the overall memory bandwidth. You could have a 512-bit bus, but with just 7Gbps GDDR5 it means a raw bandwidth of 448GB/s. Which means you could get the same result by simply using 14Gbps GDDR6 on a 256-bit bus instead.\n\nRegarding the 4080, a 256-bit bus using 22.4Gbps G6X memory gives a total raw bandwidth of 716.8GB/s, which is certainly not a small amount. As well, do remember the benefit of the fairly large 64MB L2 cache, which further boosts the effective bandwidth of the card.\n\nAll of this to say, getting hung up on the bus width alone is pretty nonsensical, when the overall memory bandwidth is what matters"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "4080",
      "4080 super",
      "rtx4080"
    ],
    "title": "[Giveaway] Black Myth: Wukong launches August 20th featuring Full Ray Tracing and DLSS 3. Tell us what you are most excited about Black Myth: Wukong for a chance to win a copy or a custom GPU backplate!",
    "selftext": "&#x200B;\n\nhttps://preview.redd.it/xt0kccrgnuid1.jpg?width=2048&format=pjpg&auto=webp&s=fcc2854c6cb80064fd11cb4d6978952cca61d3dc\n\nBlack Myth: Wukong is coming on August 20th. Dive into the enchanting world of Chinese mythology in Black Myth: Wukong, an action RPG that offers a deep narrative and stunning visuals.  \n\nPowered by [GeForce RTX GPUs and featuring full ray tracing and DLSS 3 technologies](https://www.nvidia.com/en-us/geforce/news/black-myth-wukong-full-ray-tracing-dlss-3/), the game showcases some of the most realistic lighting, reflections, and shadows.\n\n[Launch Trailer](https://www.youtube.com/watch?v=97egUiMlLZM)\n\n**Win a copy of Black Myth: Wukong or a custom GPU backplate**\n\nComment below between 8/15 and 8/20 for a chance to win a copy of the game or a custom Black Myth: Wukong GPU backplate. *(Compatible with RTX4080 / 4080 SUPER / 4090 FE)* \n\n* *What excites you the most about Black Myth: Wukong?*\n* *Which NVIDIA RTX feature (DLSS 3, full ray tracing) are you most looking forward to in Black Myth: Wukong?*\n\nTo learn more: [*\\[Link to article\\]*](https://www.nvidia.com/en-us/geforce/news/black-myth-wukong-full-ray-tracing-dlss-3/)\n\n[Terms and Conditions](https://www.nvidia.com/en-us/geforce/contests/wukong-backplate-giveaway-official-rules/)",
    "comments": [
      "When the monkey gets a wrench, he fixes things his way.",
      "It has path tracing, I need me more games with path tracing, enough reason imo lol",
      "I just want to beat monsters up as a Monkey Man",
      "What excites me most about Black Myth Wukong is the amazing Soundtrack. Seriously, the soundtrack is some of the best I've heard in gaming and I would love to experience it for myself on launch day 😊",
      "Can't wait for release date!",
      "playing it on my last gen 3060ti",
      "I can't wait! I'm excited about the combat, the new mechanics and transformations while utilizing DLSS 3 and Ray Tracing with my new recently bought 4080!",
      "Unleashing my inner monke and go big bonk with big stick",
      "I'm excited for rewarding exploration on a extraordinary time through Asia. I'll turn on Nvidia RTX full ray tracing your the very best outstanding visuals. Black Myth: Wukong has great reviews! Read \"Journey to the West\" while you play. Nice giveaway!",
      "The lore as well as RTX technology",
      "Definitely the art style and lore.",
      "I’m most excited about Black Myth: Wukong's rich storytelling and innovative combat inspired by the Journey to the West myth. For NVIDIA RTX features, DLSS 3 stands out for its potential to boost performance while maintaining stunning graphics and fluid gameplay.",
      "I have seen every single Journey to the west movie, I like the character so yeah it's exciting to see him have a game of his own.",
      "Most interested in their way of telling this story.",
      "I really want to see how graphically good this game is.",
      "monkey, cranked to the max on rtx",
      "Definitely the graphics",
      "*What excites you the most about Black Myth: Wukong?*\n\nThe story of the monkey King, I don't know nothing about it",
      "Can't wait to escape into the stunning world of ancient China, brought to life with NVIDIA RTX cinematic Ray Tracing! This is the action-adventure game we've all been waiting for— and I'm more than ready to dive in!",
      "•Bosses and level-design for me (big fan of soulsborne)\n• Full ray tracing and also DLSS 3"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "rtx 4080",
      "4080",
      "4080 super",
      "rtx 4080 super"
    ],
    "title": "Nvidia announces January event after rumors of an RTX 4080 Super launch",
    "selftext": "",
    "comments": [
      "This is not news, nvidia always have an event at CES\n\nMoving on",
      "This is just wishful thinking on my part but I'd love for them to announce a new Nvidia Shield TV device.",
      "Still a huge rumour because Nvidia is always present at CES.",
      "They have an event every year at CES, how can you definitively connect this to the super series rumours?",
      "So everything I've read points to there being no refresh on the 4090, similar to nothing on the 2080ti?\n\nCrazy thing about the 4090, is as fast at it is, it has a good amount of disabled units. Turning those on in tandem with an increase to stock memory clocks would net a significant performance bump, likely a larger increase than any of the super cards bring over the 80/70 cards.",
      "> When is the expected time frame for its release?\n\nA few months after you cave and buy an existing product",
      "Stop using cablemods, one of your favorites subreddit according to your history.",
      "The Nvidia Shield is still the best Android box out there but I agree, it is getting pretty long in the tooth and could use a refresh.",
      "I'd like to see:\n\n* A faster processor (would be nice even for just improved/smoother UI navigation)\n* Improved upscaling\n* At least 1 USB-C port\n* AV1 support\n* Support for HDR in YouTube\n* HDMI 2.1 support\n \nI doubt that all of this would come to a 2024 Shield, but this is just what I'd like to see.",
      "You hear that everyone?\n\nIf it isn’t a wholly unique or unprecedented event, then it isn’t news!",
      "The struggle is too real. Do I buy a 4080 during Black Friday or do I wait until January for Super refresh? If they just came out and gave us the price and specs then we could at least make an informed decision. Not like those will be changing any time in the next 61 days...",
      "They already fixed that with new connector revision and its receded pins.",
      "Kind if wonder if they’d rebrand it separately (like the old Titan X) if they decided to go that route.",
      "Why would they ever do that when they can just sell the full chip for 10x the price... It makes zero financial sense.",
      "What about an option C: Wait til Jan and catch the standard 4080 for a discount due to Supers coming in, it looks like the suoer version is only going to be something like 5% more powerful anyways?",
      "That would make no business sense for them. Pay more for more performance. I imagine the cost will sit between a 4080 and 4090.",
      "Higher quality upscaling? The tech has improved quite a bit over the last five years.",
      "I'm with you on that wish.\n\nThe Shield Pro ruined all TV OS for me. Roku is too slow and LG is restricting.\n\nI want to get a few more for the other rooms in the house since Plex performs really well on it but keep holding off with the whispers now leaks and rumors of new tech and Switch 2.",
      "Will they be? These things will no doubt be hilariously expensive. They will probably collect even more dust than the vanilla 4080’s.",
      "Won't they just end up being within ~$50 of black Friday sale prices were about to see? My only fear is leakers being wrong and the 4080 super being 15-20% stronger than the current 4080 at around the same price."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "rtx 4080",
      "4080",
      "4080 super",
      "rtx 4080 super"
    ],
    "title": "nVidia GeForce RTX 5090 Meta Review",
    "selftext": "- compilation of 17 launch reviews with ~6260 gaming benchmarks at 1080p, 1440p, 2160p\n- only benchmarks at real games compiled, not included any 3DMark & Unigine benchmarks\n- geometric mean in all cases\n- standard raster performance without ray-tracing and/or DLSS/FSR/XeSS\n- extra ray-tracing benchmarks (mostly without upscaler) after the standard raster benchmarks\n- stock performance on (usually) reference/FE boards, no overclocking\n- factory overclocked cards were normalized to reference clocks/performance, but just for the overall performance average (so the listings show the original performance result, just the performance index has been normalized)\n- missing results were interpolated (for a more accurate average) based on the available & former results\n- performance average is (some) weighted in favor of reviews with more benchmarks\n- all reviews should have used newer drivers for _all_ cards\n- power draw numbers based on a couple of reviews, always for the graphics card only\n- current retailer prices according to Geizhals (DE/Germany, on Jan 27) and Newegg (USA, on Jan 27) for immediately available offers\n- for the 5090 retail prices of $2200 and 2500€ were assumed\n- for discontinued graphics cards a typical retail price was used from the time they were sold (incl. 4080 & 4090)\n- performance/price ratio (higher is better) for 2160p raster performance and 2160p ray-tracing performance\n- for the full results and some more explanations check [3DCenter's launch analysis](https://www.3dcenter.org/artikel/launch-analyse-nvidia-geforce-rtx-5090)\n\n&nbsp;\n\nRaster 2160p|2080Ti|3090|3090Ti|7900XT|7900XTX|4070TiS|4080|4080S|4090|5090\n|:--|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|\n&nbsp;|Turing 11GB|Ampere 24GB|Ampere 24GB|RDNA3 20GB|RDNA3 24GB|Ada 16GB|Ada 16GB|Ada 16GB|Ada 24GB|Blackwell 32GB\nComputerBase|-|-|-|49.7%|58.3%|52.3%|-|59.9%|80.8%|_100%_\nCowcotland|-|-|-|51.5%|61.4%|53.8%|58.5%|59.6%|77.8%|_100%_\nEurogamer|29.9%|-|49.3%|50.9%|58.9%|-|56.4%|57.5%|76.4%|_100%_\nGamersNexus|27.5%|41.2%|48.4%|48.0%|60.2%|-|55.1%|-|75.0%|_100%_\nHardware&Co|-|45.7%|-|49.5%|57.9%|-|-|59.8%|78.3%|_100%_\nHardwareluxx|-|44.1%|50.0%|49.7%|57.4%|50.0%|58.2%|59.5%|76.9%|_100%_\nIgor's Lab|-|-|-|50.2%|61.0%|51.2%|-|60.%|79.6%|_100%_\nKitGuru|-|-|-|52.1%|61.0%|49.8%|-|58.6%|77.7%|_100%_\nLinus|28.0%|45.8%|49.2%|51.7%|60.2%|-|-|57.6%|78.0%|_100%_\nOverclocking|-|-|-|53.8%|63.6%|-|59.6%|60.4%|77.9%|_100%_\nPCGH|-|-|-|50.5%|60.2%|48.5%|-|57.6%|78.0%|_100%_\nPurePC|-|-|49.0%|49.4%|58.2%|-|58.6%|-|77.4%|_100%_\nQuasarzone|-|44.0%|48.5%|-|57.3%|-|57.1%|58.9%|78.5%|_100%_\nSweClockers|-|-|-|-|59.2%|-|58.1%|-|79.7%|_100%_\nTechPowerUp|28%|43%|49%|48%|57%|49%|57%|58%|74%|_100%_\nTechSpot|-|-|-|51.1%|61.3%|51.1%|57.7%|59.1%|78.8%|_100%_\nTweakers|-|43.6%|-|51.4%|59.3%|49.2%|58.8%|59.3%|76.5%|_100%_\n**avg 2160p Raster Perf.**|**~29%**|**44.1%**|**49.0%**|**50.1%**|**59.3%**|**50.0%**|**57.6%**|**58.8%**|**77.7%**|**_100%_**\n\n&nbsp;\n\nRaster 1440p|2080Ti|3090|3090Ti|7900XT|7900XTX|4070TiS|4080|4080S|4090|5090\n|:--|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|\n&nbsp;|Turing 11GB|Ampere 24GB|Ampere 24GB|RDNA3 20GB|RDNA3 24GB|Ada 16GB|Ada 16GB|Ada 16GB|Ada 24GB|Blackwell 32GB\nComputerBase|-|-|-|58.2%|65.8%|60.1%|-|68.2%|86.3%|_100%_\nCowcotland|-|-|-|65.0%|72.7%|62.9%|69.9%|71.3%|86.0%|_100%_\nEurogamer|33.8%|-|53.9%|55.9%|65.0%|-|63.1%|63.7%|80.9%|_100%_\nGamersNexus|31.3%|45.1%|52.4%|55.5%|66.1%|-|63.7%|-|81.9%|_100%_\nHardware&Co|-|51.1%|-|58.1%|66.0%|-|-|67.8%|84.4%|_100%_\nHardwareluxx|-|49.0%|54.8%|57.7%|65.9%|56.5%|66.1%|67.4%|82.2%|_100%_\nIgor's Lab|-|-|-|58.0%|68.3%|58.5%|-|68.2%|83.8%|_100%_\nKitGuru|-|-|-|57.2%|65.1%|54.9%|-|63.7%|81.7%|_100%_\nLinus|32.6%|50.8%|54.1%|60.2%|68.5%|-|-|65.7%|84.5%|_100%_\nPCGH|-|-|-|56.0%|65.6%|53.8%|-|63.6%|82.6%|_100%_\nPurePC|-|-|53.0%|55.1%|63.7%|-|64.5%|-|82.1%|_100%_\nQuasarzone|-|48.0%|51.9%|-|63.3%|-|64.1%|66.1%|83.3%|_100%_\nSweClockers|-|-|-|-|64.8%|-|64.6%|-|82.6%|_100%_\nTechPowerUp|33%|49%|55%|57%|65%|58%|66%|67%|83%|_100%_\nTechSpot|-|-|-|62.5%|72.4%|62.5%|70.8%|71.9%|89.1%|_100%_\nTweakers|-|48.7%|-|59.8%|66.4%|57.2%|67.7%|67.9%|82.6%|_100%_\n**avg 1440p Raster Perf.**|**~33%**|**48.9%**|**54.1%**|**57.8%**|**66.3%**|**57.3%**|**65.6%**|**66.8%**|**83.8%**|**_100%_**\n\n&nbsp;\n\nRaster 1080p|2080Ti|3090|3090Ti|7900XT|7900XTX|4070TiS|4080|4080S|4090|5090\n|:--|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|\n&nbsp;|Turing 11GB|Ampere 24GB|Ampere 24GB|RDNA3 20GB|RDNA3 24GB|Ada 16GB|Ada 16GB|Ada 16GB|Ada 24GB|Blackwell 32GB\nCowcotland|-|-|-|77.4%|83.1%|75.0%|80.6%|81.5%|93.5%|_100%_\nEurogamer|38.8%|-|63.1%|66.2%|73.0%|-|70.7%|71.3%|85.4%|_100%_\nGamersNexus|36.0%|51.0%|58.4%|64.3%|75.3%|-|74.3%|-|89.9%|_100%_\nHardwareluxx|-|54.4%|60.0%|63.8%|71.8%|64.3%|71.0%|72.5%|88.0%|_100%_\nIgor's Lab|-|-|-|64.6%|74.1%|67.2%|-|76.8%|90.1%|_100%_\nKitGuru|-|-|-|61.5%|68.9%|59.7%|-|68.4%|84.8%|_100%_\nPCGH|-|-|-|61.6%|70.4%|59.9%|-|69.3%|87.0%|_100%_\nPurePC|-|-|56.0%|59.7%|67.6%|-|69.4%|-|86.6%|_100%_\nQuasarzone|-|53.3%|56.9%|-|68.8%|-|71.5%|73.6%|88.1%|_100%_\nSweClockers|-|-|-|-|71.1%|-|71.4%|-|87.6%|_100%_\nTechPowerUp|40%|56%|62%|65%|73%|67%|75%|76%|90%|_100%_\nTechSpot|-|-|-|75.0%|83.3%|77.5%|84.3%|85.3%|99.0%|_100%_\nTweakers|-|54.7%|-|66.8%|72.9%|65.0%|76.6%|76.5%|86.8%|_100%_\n**avg 1080p Raster Perf.**|**~38%**|**54.6%**|**59.5%**|**64.7%**|**72.5%**|**64.7%**|**73.0%**|**74.0%**|**88.5%**|**_100%_**\n\n&nbsp;\n\nRayTracing 2160p|2080Ti|3090|3090Ti|7900XT|7900XTX|4070TiS|4080|4080S|4090|5090\n|:--|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|\n&nbsp;|Turing 11GB|Ampere 24GB|Ampere 24GB|RDNA3 20GB|RDNA3 24GB|Ada 16GB|Ada 16GB|Ada 16GB|Ada 24GB|Blackwell 32GB\nComputerBase|-|-|-|45.7%|52.8%|54.4%|-|62.6%|82.2%|_100%_\nCowcotland|-|-|-|39.1%|45.7%|48.9%|54.3%|56.0%|77.2%|_100%_\nEurogamer|24.3%|-|46.3%|38.3%|44.3%|-|53.8%|54.8%|76.3%|_100%_\nGamersNexus|22.6%|37.2%|44.0%|33.3%|41.4%|-|54.3%|-|74.3%|_100%_\nHardwareluxx|-|38.1%|43.6%|29.0%|32.5%|53.3%|60.3%|61.3%|81.4%|_100%_\nKitGuru|-|-|-|34.5%|39.9%|46.9%|-|55.9%|77.5%|_100%_\nLinus|22.2%|36.5%|39.7%|27.0%|30.2%|-|-|54.0%|76.2%|_100%_\nOverclocking|-|-|-|40.3%|48.5%|-|60.4%|61.6%|78.3%|_100%_\nPCGH|-|-|-|38.6%|45.6%|50.3%|-|59.3%|79.1%|_100%_\nPurePC|-|-|43.0%|29.1%|34.5%|-|55.4%|-|77.2%|_100%_\nQuasarzone|-|40.3%|43.5%|-|-|-|57.5%|59.3%|78.5%|_100%_\nSweClockers|-|-|-|-|33.8%|-|54.8%|-|79.3%|_100%_\nTechPowerUp|21%|41%|45%|34%|40%|49%|57%|58%|76%|_100%_\nTweakers|-|37.1%|-|35.7%|40.9%|46.0%|55.4%|55.9%|76.1%|_100%_\n**avg 2160p RayTr Perf.**|**~23%**|**39.5%**|**44.3%**|**34.9%**|**40.8%**|**49.0%**|**56.6%**|**57.8%**|**77.7%**|**_100%_**\n\n&nbsp;\n\nRayTracing 1440p|2080Ti|3090|3090Ti|7900XT|7900XTX|4070TiS|4080|4080S|4090|5090\n|:--|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|\n&nbsp;|Turing 11GB|Ampere 24GB|Ampere 24GB|RDNA3 20GB|RDNA3 24GB|Ada 16GB|Ada 16GB|Ada 16GB|Ada 24GB|Blackwell 32GB\nComputerBase|-|-|-|51.7%|58.6%|60.1%|-|68.2%|87.2%|_100%_\nCowcotland|-|-|-|46.0%|50.3%|51.5%|61.3%|62.6%|80.4%|_100%_\nEurogamer|28.4%|-|50.5%|43.3%|49.0%|-|59.6%|60.6%|80.6%|_100%_\nHardware&Co|-|40.8%|-|30.1%|34.4%|-|-|60.0%|79.2%|_100%_\nHardwareluxx|-|43.3%|48.4%|35.4%|39.0%|60.3%|67.7%|68.9%|85.7%|_100%_\nKitGuru|-|-|-|38.1%|43.4%|51.5%|-|60.5%|79.8%|_100%_\nLinus|22.5%|40.5%|43.2%|29.7%|34.2%|-|-|59.5%|79.3%|_100%_\nPCGH|-|-|-|45.3%|52.2%|56.7%|-|66.0%|84.3%|_100%_\nPurePC|-|-|46.2%|32.9%|38.3%|-|59.2%|-|79.8%|_100%_\nSweClockers|-|-|-|-|37.9%|-|61.3%|-|82.6%|_100%_\nTechPowerUp|29%|45%|50%|39%|45%|55%|63%|64%|80%|_100%_\nTechSpot|-|-|-|33.3%|38.2%|60.2%|69.1%|70.7%|85.4%|_100%_\nTweakers|-|41.0%|-|39.2%|44.3%|51.5%|61.6%|61.8%|80.2%|_100%_\n**avg 1440p RayTr Perf.**|**~27%**|**43.8%**|**48.2%**|**38.1%**|**43.4%**|**54.3%**|**62.5%**|**63.5%**|**81.9%**|**_100%_**\n\n&nbsp;\n\nRayTracing 1080p|2080Ti|3090|3090Ti|7900XT|7900XTX|4070TiS|4080|4080S|4090|5090\n|:--|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|\n&nbsp;|Turing 11GB|Ampere 24GB|Ampere 24GB|RDNA3 20GB|RDNA3 24GB|Ada 16GB|Ada 16GB|Ada 16GB|Ada 24GB|Blackwell 32GB\nCowcotland|-|-|-|55.2%|61.2%|68.7%|74.6%|76.1%|90.3%|_100%_\nEurogamer|31.9%|-|54.0%|48.1%|53.7%|-|65.5%|66.7%|85.1%|_100%_\nHardwareluxx|-|49.5%|54.3%|41.4%|45.4%|66.0%|71.6%|72.6%|89.0%|_100%_\nKitGuru|-|-|-|41.5%|46.5%|56.0%|-|64.4%|82.1%|_100%_\nPCGH|-|-|-|51.0%|57.7%|62.4%|-|71.5%|87.7%|_100%_\nPurePC-|-|49.4%|36.3%|41.4%|-|64.5%|-|72.1%|_100%_\nSweClockers|-|-|-|-|44.2%|-|69.9%|-|88.3%|_100%_\nTechPowerUp|32%|50%|54%|44%|50%|61%|69%|70%|84%|_100%_\nTechSpot|-|-|-|36.5%|41.9%|66.9%|75.0%|76.4%|87.8%|_100%_\nTweakers|-|44.7%|-|42.4%|47.1%|56.1%|66.5%|67.4%|82.4%|_100%_\n**avg 1080p RayTr Perf.**|**~32%**|**49.4%**|**53.7%**|**44.4%**|**49.9%**|**61.4%**|**69.1%**|**70.3%**|**85.1%**|**_100%_**\n\n&nbsp;\n\nFG/MFG @ 2160p|4090|4090 + FG|5090|5090 + FG|5090 + MFGx3|5090 + MFGx4\n|:--|:--:|:--:|:--:|:--:|:--:|:--:|\nComputerBase|82%|144%|_100%_|183%|263%|333%\nHardwareluxx|75%|133%|_100%_|177%|253%|318%\nTechPowerUp|77%|130%|_100%_|-|-|310%\naverage pure FG/MFG gain|&nbsp;|+74% (vs&nbsp;4090)|&nbsp;|+78% (vs&nbsp;5090)|+154% (vs&nbsp;5090)|+220% (vs&nbsp;5090)\n\n&nbsp;\n\nAt a glance|2080Ti|3090|3090Ti|7900XT|7900XTX|4070TiS|4080|4080S|4090|5090\n|:--|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|\n&nbsp;|Turing 11GB|Ampere 24GB|Ampere 24GB|RDNA3 20GB|RDNA3 24GB|Ada 16GB|Ada 16GB|Ada 16GB|Ada 24GB|Blackwell 32GB\navg 2160p Raster Perf.|~29%|44.1%|49.0%|50.1%|59.3%|50.0%|57.6%|58.8%|77.7%|_100%_\navg 1440p Raster Perf.|~33%|48.9%|54.1%|57.8%|66.3%|57.3%|65.6%|66.8%|83.8%|_100%_\navg 1080p Raster Perf.|~38%|54.6%|59.5%|64.7%|72.5%|64.7%|73.0%|74.0%|88.5%|_100%_\navg 2160p RayTr Perf.|~23%|39.5%|44.3%|34.9%|40.8%|49.0%|56.6%|57.8%|77.7%|_100%_\navg 1440p RayTr Perf.|~27%|43.8%|48.2%|38.1%|43.4%|54.3%|62.5%|63.5%|81.9%|_100%_\navg 1080p RayTr Perf.|~32%|49.4%|53.7%|44.4%|49.9%|61.4%|69.1%|70.3%|85.1%|_100%_\nTDP|260W|350W|450W|315W|355W|285W|320W|320W|450W|575W\nReal Power Draw|272W|359W|462W|309W|351W|277W|297W|302W|418W|509W\nEnergy Eff. (2160p&nbsp;Raster)|54%|63%|54%|83%|86%|92%|99%|99%|95%|_100%_\nMSRP|$1199|$1499|$1999|$899|$999|$799|$1199|$999|$1599|$1999\nRetail GER|~1100€|~1700€|~2100€|689€|899€|849€|~1150€|1074€|~1750€|~2500€\nPerf/Price GER 2160p&nbsp;Raster|65%|65%|58%|182%|165%|147%|125%|137%|111%|_100%_\nPerf/Price GER 2160p&nbsp;RayTr|52%|58%|53%|127%|113%|144%|123%|134%|111%|_100%_\nRetail US|~$1200|~$1500|~$2000|$650|$870|$900|~1200|~$1000|~$1600|~$2200\nPerf/Price US 2160p&nbsp;Raster|52%|65%|54%|170%|150%|122%|106%|129%|107%|_100%_\nPerf/Price US 2160p&nbsp;RayTr|42%|58%|49%|118%|103%|120%|104%|127%|107%|_100%_\n\n&nbsp;\n\nPerf. Gain of 5090|Raster 2160p|Raster 1440p|Raster 1080p|RayTr. 2160p|RayTr. 1440p|RayTr. 1080p\n|:--|:--:|:--:|:--:|:--:|:--:|:--:|\nGeForce RTX 2080 Ti|+249%|+205%|+162%|+335%|+272%|+213%\nGeForce RTX 3090|+127%|+104%|+83%|+153%|+128%|+103%\nGeForce RTX 3090 Ti|+90%|+85%|+68%|+126%|+108%|+86%\nRadeon RX 7900 XT|+100%|+73%|+55%|+187%|+163%|+125%\nRadeon RX 7900 XTX|+69%|+51%|+38%|+145%|+130%|+100%\nGeForce RTX 4070 Ti Super|+100%|+74%|+54%|+104%|+84%|+63%\nGeForce RTX 4080|+73%|+52%|+37%|+77%|+60%|+45%\nGeForce RTX 4080 Super|+70%|+50%|+35%|+73%|+57%|+42%\nGeForce RTX 4090|+28.6%|+19.4%|+12.9%|+28.6%|+22.2%|+17.5%\n\nNote: Performance improvement of the GeForce RTX 5090 compared to the other cards. The respective other card is then 100%.\n\n&nbsp;\n\n&nbsp;|nVidia FE|Asus Astral OC|MSI Suprim OC|MSI Suprim Liquid SOC|Palit GameRock\n|:--|:--:|:--:|:--:|:--:|:--:|\nCooling|Air, 2 Fans|Air, 4 Fans|Air, 3 Fans|Hybrid: Air & Water|Air, 3 Fans\nDimensions|DualSlot, 30.0 x 14.0cm|QuadSlot, 35.0 x 15.0cm|QuadSlot, 36.0 x 15.0cm|TripleSlot, 28.0 x 15.0cm|QuadSlot, 33.0 x 14.5cm\nWeight|1814g|3038g|2839g|2913g|2231g\nClocks|2017/2407 MHz|2017/2580 MHz|2017/2512 MHz|2017/2512 MHz|2017/2407 MHz\nReal Clock (avg/median)|2684 MHz / 2700 MHz|2809 MHz / 2857 MHz|2790 MHz / 2842 MHz|2821 MHz / 2865 MHz|2741 MHz / 2790 MHz\nTDP|575W (max: 600W)|600W (max: 600W)|575W (max: 600W)|600W (max: 600W)|575W (max: 575W)\nRaster (2160p, 1440p, 1080p)|_100%_|+5% / +3% / +2%|+3% / +3% / +2%|+4% / +4% / +3%|+2% / +2% / +2%\nRayTr. (2160p, 1440p, 1080p)|_100%_|+4% / +4% / +5%|+3% / +3% / +3%|+4% / +5% / +4%|+3% / +2% / +2%\nTemperatures (GPU/Memory)|77°C / 94°C|65°C / 76°C|75°C / 80°C|61°C / 74°C|74°C / 82°C\nLoundness|40.1 dBA|39.3 dBA|28.4 dBA|31.2 dBA|39.8 dBA\nReal Power Draw (Idle/Gaming)|30W / 587W|29W / 621W|24W / 595W|24W / 609W|40W / 620W\nPrice|$1999|allegedly $2800|allegedly $2400|allegedly $2500|allegedly $2200\nSource:|[TPU review](https://www.techpowerup.com/review/nvidia-geforce-rtx-5090-founders-edition/)|[TPU review](https://www.techpowerup.com/review/asus-geforce-rtx-5090-astral/)|[TPU review](https://www.techpowerup.com/review/msi-geforce-rtx-5090-suprim/)|[TPU review](https://www.techpowerup.com/review/msi-geforce-rtx-5090-suprim-liquid/)|[TPU review](https://www.techpowerup.com/review/palit-geforce-rtx-5090-gamerock/)\n\nNote: The values of the default BIOS were noted throughout. In addition, the graphics card manufacturers also offer Quiet BIOSes (Asus & Palit) and Performance BIOSes (MSI).         \n\n&nbsp;\n\nList of GeForce RTX 5090 reviews evaluated for this performance analysis:\n\n- [ComputerBase](https://www.computerbase.de/artikel/grafikkarten/nvidia-geforce-rtx-5090-test.91081/)\n- [Cowcotland](https://www.cowcotland.com/articles/4480/test-nvidia-geforce-rtx-5090-fe-un-nouveau-monstre-vert-debarque.html)\n- [Eurogamer](https://www.eurogamer.net/digitalfoundry-2025-nvidia-geforce-rtx-5090-review)\n- [Gamers Nexus](https://www.youtube.com/watch?v=VWSlOC_jiLQ)\n- [Hardware & Co](https://hardwareand.co/dossiers/gpu/test-de-la-geforce-rtx-5090-blackwell-et-son-neural-rendering-sont-ils-revolutionnaires)\n- [Hardwareluxx](https://www.hardwareluxx.de/index.php/artikel/hardware/grafikkarten/65361-die-geforce-rtx-5090-founders-edition-im-test.html)\n- [Igor's Lab](https://www.igorslab.de/nvidia-geforce-rtx-5090-founders-edition-im-test-das-600-watt-kraftpaket-im-gaming-und-labortest/)\n- [KitGuru](https://www.kitguru.net/components/graphic-cards/dominic-moass/nvidia-rtx-5090-review-ray-tracing-dlss-4-and-raw-power-explored/)\n- [Linus Tech Tips](https://www.youtube.com/watch?v=Q82tQJyJwgk)\n- [Overclocking](https://overclocking.com/test-nvidia-rtx-5090-founders-edition/)\n- [PC Games Hardware](https://www.pcgameshardware.de/Geforce-RTX-5090-Grafikkarte-281029/Tests/Reviews-Benchmarks-Vergleich-RTX-4090-1463971/)\n- [PurePC](https://www.purepc.pl/nvidia-geforce-rtx-5090-recenzja-test-wydajnosci-premiera-blackwell)\n- [Quasarzone](https://quasarzone.com/bbs/qc_bench/views/92822)\n- [SweClockers](https://www.sweclockers.com/test/40483-nvidia-geforce-rtx-5090-utmarkt-kort-for-dig-som-har-rad)\n- [TechPowerUp](https://www.techpowerup.com/review/nvidia-geforce-rtx-5090-founders-edition/)\n- [TechSpot](https://www.techspot.com/review/2944-nvidia-geforce-rtx-5090/)\n- [Tweakers](https://tweakers.net/reviews/12864/nvidia-geforce-rtx-5090-kunstmatig-en-krachtig.html)\n\n&nbsp;\n\nSource: [3DCenter.org](https://www.3dcenter.org/artikel/launch-analyse-nvidia-geforce-rtx-5090)",
    "comments": [
      "Thanks a lot for your effort!\n\nI was interested in the 1440p (+RT) performance and now I'm glad I bought the 4090 back then.",
      "I am really puzzled by RT uplift from 4090 being exactly in line with raster uplift. Considering change for RT cores is, as usual very noticeably bigger than change to CUDA - that seems bizarre.",
      "Sure. For every new GPU, since many years already.",
      "It’s where I’m sitting too. 6000 series it is.",
      "I just looked at the 3090 numbers and assumed it is around 10% worse. It usually splits the difference between the 2080 Ti and 3090, but a little closer to the 3090 in performance.",
      "You have to reemmber that this isnt a new node, there hasnt been any serious architectural improvements made toward rt either. So the uplift is linear to how much more cores there are. The 5090 is really a 4090ti",
      "3080?",
      "The value of the 4090 is amazing - though I wouldn't count myself out if presented with an opportunity to buy a 5090 at MSRP.  I got my FE through Nvidia's Priority Access program, where they randomly asked anyone who had an older nvidia card if they wanted to buy the 4090, hoping they do that again with the 5090 and lightning strikes twice.\n\nI hate reselling stuff but it's what-you-have-to-do with cards being so damn expensive - but I got to say the resell value of the 4090 I think is going to be tremendous even after the new series comes out.",
      "It’s obvious that it makes little sense for someone with a 4090 to upgrade, but since I cannot buy a 4090 new, my only option is a 5090. As such, coming from a 3080Ti, I am happy with the performance of the 5090, and a bit less so with the price. Still a worthwhile upgrade for me.",
      "You're reading it backwards. It's a 23-27% gain, where the 4090 runs at 73-77% performance relative to the 5090",
      "Great work. Can you do the same for 5080 when it drops?",
      "\\>there hasnt been any serious architectural improvements made toward rt either.\n\nThere was at least claimed doubling of intersection calcs, just the same way it was doubled in Ampere and Ada.",
      "a +73-77% perf gain at 4k from 4080. This is very temping!",
      "I especially love seeing the meta comparison of the fan noise. Folks out there going crazy at how loud the FE is, and there’s actually a lot of other cards at the same level. \n\nWent back and looked up my 3080 stats and it’s right around 40db at max, too.",
      "Embargo is not lifted for 5080",
      "Theres probably very few, if any. Benchmarks usually use parts that will not cause any bottleneck, and right now the 9800x3d is the fastest gaming cpu, this is done so that we can see as close to the pure performance of the cards as possible",
      "👑",
      "I think you're correct and the commend assumed you meant \"4090\" and were reading it wrong? That's what I am getting from that table too",
      "Ah!!! My apologies, I was looking at the 4090 in the table since that showed 77%. What's weird is in that same table it showed the 4080 at like 55-58% performance compared to the 5090. So conflicting data but still decent gains.",
      "Well, I am real. They did a direct comparison with previous hardware revisions. Which we know for a fact were correct: Ampere was a big jump in RT performance over Turing, Ada was a big jump over Ampere. So I see zero reason why NOW this claim ought to be false.\n\nBut it isn't supported by benchmarks at the moment. Strange."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "4080",
      "4080 super"
    ],
    "title": "Upgraded from a 1080 Ti to 4080 Super!",
    "selftext": "",
    "comments": [
      "I hate when people say, oh its an i3, oh its an i5 its terrible, without specifying the gen, current gen i5,i3 are really good and powerful CPUs",
      "Why it’s a 14th gen",
      "Full Specs:\n\n\nIntel i5-14600K\n\nMSI 4080 Super Gaming X Trio\n\nCorsair H150i pro\n\nMSI PRO Z790-P WIFI\n\n32GB DDR5-5200\n\nCorsair RM1000i PSU\n\nPhanteks P600s",
      "Atm 1440p. I may look to upgrade in the future. I do some machine learning so the 4080 Super is really nice outside of gaming.",
      "it doesnt consume 400w to match a 7800x3d in gaming 😂😂",
      "Whats wrong with an i5?",
      "Nothing wrong with i5 in a gaming only build",
      "Nice pc.....what resolution r u playing at",
      "I've never seen any other gpu that has aged as well has the 1080/ti. Was such a good bang for your buck imo (compared to now at least) and has held up in most if not all games that have come out in the last few years. Had an 1080 FE in 2018 that I used for years!!",
      "Dude I'm also going for the same upgrade! From evga 1080 ti to 4080 super on a 1440p monitor",
      "Absolutely use DLDSR",
      "congrats still rocking my 1080ti",
      "I am using 3 separate pcie cables",
      "Yeah. It's the reason I couldn't consider AMD as AI and machine learning just aren't as good as nvidia yet",
      ">Is it as simple as enabling it in nv control panel and choosing the higher resolution in game?\n\nYes.\n\nBut if the game won't let you pick the resolution because it doesn't have fullscreen mode setting, just set your DESKTOP resolution to DLDSR option of your choice prior to opening the game and it should default the game to said resolution. Desktop will look blurry but don't worry, that's normal. Game will reap the benefit.\n\nAfterwards once you're done gaming you go back to desktop and change the resolution back to native.",
      "I went from the 1080ti to the 4090, it was faster then 4x 1080ti lol",
      "1080 to 4080super here. Games like cyberpunk is a totally new experience. 4k is playable now and looks great compared to the old card.",
      "How much for your 1080 Ti? I heard a new amazing game came out called Crysis that requires a beast of a gpu",
      "I gave my 1080 Ti to my younger brother so it isn't for sale. An upgrade for him from his laptop 😅",
      "Congratulations brother."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "rtx 4080",
      "4080"
    ],
    "title": "Putting RTX 4000 series into perspective - VRAM bandwidth",
    "selftext": "https://preview.redd.it/bzotplyr1bqd1.png?width=979&format=png&auto=webp&s=6554e7dbde2fe1cb2d49b15e710f0dd205f15392\n\nThere was a [post](https://www.reddit.com/r/nvidia/comments/1flapxu/why_do_series_40_cards_have_lower_memory_bus/) yesterday that got deleted by mods, asking about reduced memory bus on RTX 4000 series. So here is why RTX 4000 is absolutely awful value for compute/simulation workloads, summarized in one chart. Such workloads are memory-bound and non-cacheable, so the larger L2$ doesn't matter. The only RTX 4000 series cards that are not worse bandwidth than their predecessors are 4090 (matches the 3090 Ti at same 450W), and 4070 (marginal increase over 3070). All others are much slower, some slower than 4 generations back. This is also the case for Ada series Quadro lineup, which is the same cheap GeForce chips under the hood, but marketed for exactly such simulation workloads.\n\nRTX 4060 < GTX 1660 Super\n\nRTX 4060 Ti = GTX 1660 Ti\n\nRTX 4070 Ti < RTX 3070 Ti\n\nRTX 4080 << RTX 3080\n\nEdit: inverted order of legend keys, stop complaining already...\n\n  \nEdit 2: Quadro Ada: Since many people asked/complained about GeForce cards being \"not made for\" compute workloads, implying the \"professional\"/Quadro cards would be much better. This is not the case. Quadro are the same cheap hardware as GeForce under the hood (three exceptions: GP100/GV100/A800 are data-center hardware); same compute functionalities, same lack of FP64 capabilities, same crippled VRAM interface on Ada generation.\n\nMost of the \"professional\" Nvidia RTX Ada GPU models are worse bandwidth than their Ampere predecessors. Worse VRAM bandwidth means slower performance in memory-bound compute/simulation workloads. The larger L2 cache is useless here. RTX 4500 Ada (24GB) and below are entirely DOA, because the RTX 3090 24GB is both a lot faster and cheaper. Tough sell.\n\n[How to read the chart: Pick a color, for example dark green. This dark green curve is how VRAM bandwidth changed across 4000 class GPUs over generations: Quadro 4000 \\(Fermi\\), Quadro K4000 \\(Kepler\\), Quadro M4000 \\(Maxwell\\), Quadro P4000 \\(Pascal\\), RTX 4000 \\(Turing\\), RTX A4000 \\(Ampere\\), RTX 4000 Ada \\(Ada\\).](https://preview.redd.it/ict97fmlhrrd1.jpg?width=1050&format=pjpg&auto=webp&s=9125734bd0b087f8aba749f2c85747bf6bb0b7e9)",
    "comments": [
      "I don't mean to be a dick, but that graph is damn near unreadable.",
      "The post is good but the graph is so badly made and unoptimized that it's a headache to look at overall.\n\n  \nOP should've made a 16:9 version, this alone would've made it easier to comprehend.",
      "Jesus you weren't kidding. Graph gore.",
      "Tbh I wonder how 5000 series will look bandwidth wise cause GDDR7 is gonna be a significant step up.",
      "Not all cards are going to have GDDR7, probably just the 5080 and 5090, maybe the 5070 but I wouldn’t count on it.",
      "It’s common practice by Nvidia with new memory adoption, RTX3070 also only got GDDR6 while the 3080 and 3090 got GDDR6X. Same thing with the GTX1070, it only got GDDR5, with the 1080 getting GDDR5X…",
      "Quick and dirty is no excuse for not having a Y-Axis label, young man/woman!",
      "Honestly impossible to read",
      "Listen OP, never make any graphs or charts again. Got it?",
      "Actually a scatter plot is probably the better way to go, and has been done before. [A quick and dirty version](https://i.imgur.com/CaOtJ7q.png)",
      "That doesn't make them any faster or better. And most professional Ada cards are slower than their Ampere predecessors, just like their GeForce counterparts. Tough sell.\n\n\nHigher VRAM capacity is only available on the top-end models at steep price premium. Anything under 24GB is DOA because the 3090 or other gaming cards are both cheaper and faster.",
      "The Quadro/professional counterparts of Nvidia Ada series aren't any better. It's identical GPU hardware under the hood, just a different marketing name and higher price tag.",
      "LOL, nope. It's just a marketing bullshit.",
      "90 and Titan should be grouped together, even the graph shows it.\n\nThe 3090ti was a one-off, and it came out so close to the 4090 that it's hardly in the 3000 generation, more like a weird prototype for the 4090.",
      "Combine them, and put them into a moving average.",
      "That’s because he used the lower bandwidth 4060 than the superior 1660 to simulate it",
      "GDDR6X is different than GDDR6 though. It's not an entirely new ram standard but an improved one. GDDR6X has more data throughput per pin than GDDR6 and it uses different signalling.\n\n  \nWhen GDDR6 was officially out, RTX 20 series all used GDDR6 right out of the gate instead of it being used only on the top cards and lower ones using GDDR5X. And when developing RTX 30 cards, Nvidia needed more bandwidth that was simply not possible with normal GDDR6 so they co-developed GDDR6X with Micron for the cards that could benefit from it (aka 3080 and up). GDDR6X is still GDDR6 with some differences and a few extra pins that allow that gap in performance. The extra difference between the two is the fact that GDDR6X has more latency and sucks up more power to achieve this performance. So it requires different tunning.\n\n  \nSimilar thing happened with the GTX 10 series. With how much power efficiency became important, I heavily doubt Nvidia will release the RTX 50 series with anything but GDDR7 due to power efficiency concerns as well. Imagine giving the RTX 5060 GDDR6X that sucks up twice the power of GDDR7 and heats up like a furnace. It makes no sense. Instead of giving it 192bit GDDR6X it would be more logical cost wise to give it 128bit GDDR7 instead.",
      "You are right, the people who look behind the marketing nonsense don't buy professional GPUs because those are a scam. Quadro ain't faster, Quadro lacks FP64 capabilities, it's just 5x the price for no benefit at all. Only the top end 48GB models make sense, when you need the VRAM.\n\nI'm surprised that the myth of their superiority still sticks. There was a time when Nvidia paid software vendors like Solidworks or Siemens to enshittify their own software - artificially slow it down if the name of the GPU contains \"GeForce\", peaking in some [absolutely hilarious marketing videos](https://www.youtube.com/watch?v=uwCu-b7htV8).\n\nNowadays Nvidia is so desperate to prevent people buying cheap but otherwise identical gaming cards and putting them in workstations/servers that they force board partners to ship hilariously oversized 4-slot coolers even on toaster GeForce cards, for the sole reason that they won't physically fit.\n\nBack in the day when we needed GPUs with a lot of VRAM and FP64, guess what we packed our servers full with? Radeon VII, the 10x cheaper but otherwise identical variant of Instinct MI50 data-center card. Good times!",
      "Well, I suppose it's a good thing that the 4000 series are consumer grade cards that aren't designed for compute and simulation workloads.\n\nThat's exactly what their professional grade cards are designed for.",
      "This seems pretty okay to me TBH.  It took one extra second to process.  Not the MOST easy but like \"Ah, got it\"\n\nEdit: ya'll here bitching about this graph have skill issues."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "rtx 4080",
      "4080",
      "4080 super",
      "rtx 4080 super"
    ],
    "title": "GeForce RTX 5080 Review Megathread",
    "selftext": "# GeForce RTX 5080 Founders Edition reviews are up.\n\nhttps://preview.redd.it/0b57tcm6vxfe1.jpg?width=3840&format=pjpg&auto=webp&s=ad230615d607bf9dd8a84e9abf0861c159b5cc42\n\n# Below is the compilation of all the reviews that have been posted so far. I will be updating this continuously throughout the day with the conclusion of each publications and any new review links. This will be sorted alphabetically.\n\n# Written Articles\n\n# [Babeltechreviews](https://babeltechreviews.com/rtx-5080-founders-edition-review/)\n\n>Upgrading to the new RTX 5080 from a 30 series GPU—or for those who simply demand peak performance—presents a clear decision. The price-to-performance ratio of the RTX 5080 is impressive, especially when viewed against the backdrop of NVIDIA’s previous generations or its current competitors. There is a uplift gen-over-gen of around 7-15% on average in raw power, when you consider DLSS 4 and its incredible uplift for max settings its really exciting. DLSS 4 is not perfect, however, and it cannot replace raw power for enthusiasts. The RTX 5080 also carries a higher price tag, albeit lower than the RTX 4080’s MSRP at $200 less. This is much better and the value it offers in enhanced performance, especially with advancements in ray tracing and AI-driven capabilities like DLSS 4, justifies the investment in our opinion.\n\n>We understand the inclination to wait for the more budget-friendly 70 and 80 class GPUs from the Blackwell generation, as these models often strike a balance between cost and performance, catering to the needs of the average gamer. However, for those seeking the pinnacle of current gaming technology, the RTX 5080 is unparalleled in its price range and class. It’s designed to deliver top-tier performance for years to come, making it an investment in future-proofing your gaming or creative setup. Ultimately, the decision to invest in such a high-end GPU depends on your specific needs and budget, but for those who prioritize leading-edge technology, the RTX 5080 is a wonderful new addition to the market.\n\n# [Digital Foundry Article](https://www.eurogamer.net/digitalfoundry-2025-nvidia-geforce-rtx-5080-review)\n\n# [Digital Foundry Video](https://www.youtube.com/watch?v=k7hDtGh0wIo)\n\n>See Stickied Comment\n\n# [eTeknix Article](https://www.eteknix.com/nvidia-geforce-rtx-5080-founders-edition-review/)\n\n# [eTeknix Video](https://www.youtube.com/watch?v=CKhoBBX2h00)\n\n>See Stickied Comment\n\n# [Guru3D](https://www.guru3d.com/review/review-nvidia-geforce-rtx-5080-founders-edition-reference/)\n\n>Depending on the game, performance improvements can vary widely. On average, you can expect a 10 to 25 percent boost in traditional rendering performance coming from a 4080S. The more effective part is NVIDIA's heavy investment in AI, deep learning, and neural shading. When we tested DLSS4 with frame generation enabled at 4x, the performance is simply incredible. However, the pressing question arises: will consumers be ready to invest in AI-assisted rendering? The answer isn’t clear yet, but time will tell. One thing is certain—DLSS4 works wonders. The performance metrics shown are a testament to its power. This GPU is quintessential for gamers using Ultra-Wide HD, Quad HD, or Ultra HD monitors, delivering a great visual experience with framerates to match. But yes, overall from the shading rasterization performance, the card is somewhat lacklustre\n\n>The GeForce RTX 5080 will speak to a lot more people compared to the $1999 costing RTX 5090. However, you'll get far less performance. Compared to the RTX 4080/4080 Super the overall rasterizer performance is a notch faster, but not heaps, and that is today's most disappointing news. NVIDIA invested heavily in the transistor budget for AI, the new generation of products places a strong focus on Raytracing, Neural Shading and of course DLSS4 with MFG (Multi Frame Generation). The combination of these together can easily bring in a fact x3 or x4 (and sometimes faster) result. Whether or not the end user is ready for artificially created frames in this degree we doubt, but as far as NVIDIA is concerned, it's the future. We do hope to see more backwards compatibility with DLSS 4 so that older games will get this new tech included as well. We stated this in the RTX 5090 review already, we wonder if the balance hasn't shifted towards AI assistance a bit too much. For the end-user change and thus a move away from the traditional render engine it will be a tough pill to swallow. The potential is huge though. For example, games like Microsoft Flight Simulator 2024, when combined with 4.0, could achieve over 150+ FPS at Ultra HD. Similarly, Cyberpunk in UHD did \\~180 FPS, that's with raytracing enabled. The recent move towards Ray reconstruction also moved NVIDIA into a new sweet spot. All features and performance combined with new technology like DLSS4 really make the Series 5000 from NVIDIA compelling. Other downsides for today's tested product have to be the high energy consumption and price level. In the end whatever we write, or how we feel about the AI-driven content doesn't matter. It's you guys that make the decisive purchase or not which makes this product series a success. The product is a notch faster than the previous generation if you look at that traditional render engine, however looking just that alone is not enough. With a whole lot of extra AI driver functionality that comes along with it, boosting your game FPS towards very high levels in the highest resolutions is possible with the likes of DLSS4 and MFG. Realistically though an RTX 4000 card with DLSS3.5 and Frame Generation will get you plenty of AI-driven performance as well. The founder card itself is lovely in design, it looks nice and it is reasonably silent. The power usage is somewhat icky. If you're coming from the RTX 3000 series or lower products, then this might be an attractive enough buy, but I think many of you expected to see RTX 4090 performance, or even slightly better. For that, you'll need a premium AIC OC version with a premium price. \n\n# [Hot Hardware](https://hothardware.com/reviews/nvidia-geforce-rtx-5080-blackwell-review)\n\n>Last week’s launch of the [GeForce RTX 5090](https://hothardware.com/reviews/nvidia-geforce-rtx-5090-review), crowned a new king in the gaming GPU market. It’s pricier and consumes more power than its predecessor, but the RTX 5090 was performance leader across the board. The GeForce RTX 5080 is also technically an upgrade over the RTX 4080 in virtually every way, but its power consumption is in the same ball park and its introductory $999 MSRP is actually somewhat lower. That should be a great story, but the GeForce RTX 5080 is only a mild upgrade over its previous-gen namesake for gaming, unless you can turn on all DLSS features with multi-frame generation. It does, however, offer more of a boost with AI and content creation workloads.\n\n>When the GeForce RTX 4080 launched, it [crushed the GeForce RTX 3090](https://hothardware.com/reviews/nvidia-geforce-rtx-4080-gpu-review) with many workloads. That’s not the case with the GeForce RTX 5080, but that was obviously not NVIDIA’s intention. The GB203 GPU powering the card is actually smaller than the AD103 on the RTX 4080, and it is manufactured on the same process node.\n\n>NVIDIA’s focus here was obviously on architectural advancements and AI-powered rendering. When you factor in the capabilities of RTX Neural Rendering and DLSS 4 with multi-frame generation, the RTX 5080 separates itself from previous-gen offerings and offers clearly superior performance and technology. And therein lies the rub. Traditional raster will likely be less of a focus for the industry moving forward. NVIDIA is looking to the [future with Blackwell](https://hothardware.com/reviews/nvidia-rtx-blackwell-architecture-overview), and they're not alone, as both AMD and Intel are on this path as well . As game developers incorporate more of the technologies available in the RTX 50 series, its performance profile relative to previous-gen GPUs will change. Though 75 titles will offer support for DLSS as of tomorrow (if you factor in the DLSS override controls in the NVIDIA app), we suspect revisiting the performance of these cards in a few months may tell a different story. AMD and Intel may also have some fresh competitors in the mix too by then.\n\n>That said, most consumers buy products for what they offer today, and not what they may potentially offer in the future. If you’re considering a card in the GeForce RTX 5080 FE’s price range, it is the current best option on the market. It’s faster and has more advanced features than a GeForce RTX 4080 and also AMD’s current flagship offering. It is not a significant upgrade over the GeForce RTX 40 series for gamers though. For owners of GeForce RTX 30 series cards (or older), however, the GeForce RTX 5080 will offer a massive boost.\n\n# [Igor's Lab](https://www.igorslab.de/en/nvidia-geforce-rtx-5080-founders-edition-im-test-geforce-rtx-4080-ti-mit-blackwell-genen/)\n\n>The RTX 5080 is particularly impressive in Ultra-HD resolutions (3840 x 2160 pixels) with activated ray tracing and patch tracing effects. Thanks to the 10,752 CUDA cores, 336 fifth-generation Tensor cores and support for DLSS 4, the card achieves exceptional frame rates in graphically demanding scenarios. While the RTX 4080 Super lags behind the RTX 5080 in most benchmarks, the new card manages to deliver a smoother frame rate and better stability through the integration of multi-frame generation (MFG). This is certainly advantageous for those who believe they need something like this.\n\n>The improved ray tracing performance, made possible by 84 fourth-generation RT cores, is particularly evident in games such as *Cyberpunk 2077* and *Alan Wake 2*. With ray tracing enabled, the RTX 5080 also benefits from advanced ray reconstruction functionality, ensuring outstanding image quality in even the most demanding scenarios. Despite this impressive performance, some limitations can be recognized: In native 4K with maximum settings, the card may still remain at its performance limit, especially at high frame rates and intensive lighting simulations. Apart from these new features, however, the GeForce RTX 5080 remains a classic sidegrade and can hardly score with significant additional performance. Everyone has to decide for themselves whether they are disappointed by this. For my part, I had actually hoped for 20 percent.\n\n>The thermal design of the RTX 5080 is based on a double-sided flow-through cooling system that directs cool air through the card and efficiently dissipates heated air. During operation, the GPU temperature remains stable even in intensive gaming scenarios, with the card reaching a maximum temperature of just under 76 °C. The memory temperatures benefit from the optimized power supply via separate power rails, which ensure an even power supply. This minimizes thermal fluctuations and ensures that the memory area remains stable even under high loads. Thermal analysis using the Optris PI 640 shows homogeneous heat distribution, with hotspots such as the GPU and voltage converters being effectively cooled.\n\n>The noise development of the RTX 5080 is heavily dependent on the fan speed. When idling and at moderate speeds, the card remains pleasantly quiet, which is due to the low-vibration fan mounting and the aerodynamic optimization of the fan blades. Under load, however, the noise increases noticeably and reaches values of up to 38 dB(A). A characteristic humming at around 200 Hz was detected in the tests, which is caused by resonances of the fans or the voltage converters. This noise is particularly noticeable at certain fan speeds, but is not consistently audible.\n\n# [KitGuru Article](https://www.kitguru.net/components/graphic-cards/dominic-moass/nvidia-rtx-5080-review-efficiency-gains-but-a-performance-letdown/)\n\n# [KitGuru Video](https://www.youtube.com/watch?v=uKIwmW5j6oc)\n\n>Only consider the RTX 5080 if you buy into Nvidia’s AI-fueled vision of the future\n\n>DLSS 4’s Multi Frame Generation feature must be seen (and felt) to be believed. On PCWorld’s Full Nerd podcast, we compared the leap from Single Frame to Multi Frame Generation to the leap from DLSS 1 to DLSS 2. When both technologies first came out, they showed promise but had plenty of rough edges. With DLSS 2, gamers agreed that Nvidia *nailed it*. And while it’s not quite perfect, Multi Frame Generation *nails it*. Once more gamers get their Dorito-stained paws on RTX 50-series cards, and are able to tool around with MFG in 75+ games and apps, I wouldn’t be surprised if all the furor over “fake frames” online dies down quite a bit. It’s a literal game changer.\n\n>But Nvidia is in trouble this generation if the masses *don’t* embrace Multi Frame Generation. Because when it comes to traditional gaming performance, the RTX 5080 is no game changer.\n\n>It’s a pretty damned terrible generational upgrade, actually. Eking out a mere 11 to 15 more render performance than the RTX 4080 Super, at the same price, at a higher power draw, isn’t compelling whatsoever. It can’t come anywhere close to last gen’s 4090. If you don’t like AI-generated frames — maybe you’re sensitive to latency, or you focus on competitive games, or you loathe the idea of AI frames potentially introducing visual glitches — I’d even go so far as to suggest picking up a 4080 Super to get roughly comparable performance for less cash.\n\n>Remember: The [RTX 3080 beat the RTX 2080 by *60 to 80 percent*](https://www.pcworld.com/article/393472/nvidia-geforce-rtx-3080-founders-edition-review.html) when it launched earlier this decade, and it did so for just $700. Then [Nvidia jacked the price of the vanilla RTX 4080](https://www.pcworld.com/article/1379747/nvidia-geforce-rtx-4080-tested-5-things.html) by *$500 dollars* for a 30 percent performance increase, leading to poor sales rectified only by the launch of the 4080 Super at $999. With the RTX 5080 barely outpacing that, the RTX 5080 would have been immensely more compelling at a couple hundred dollars cheaper. Two generations after the RTX 3080, Nvidia has truly devastated the xx80 tier’s value in recent memory. Upgrading from the 3080 to a 5080 will only get you about 40 to 45 percent more performance, for a price tag that’s 42 percent higher. That’s not progress.\n\n>If Nvidia didn’t have MFG in tow, this would’ve been a *scathing* review for the RTX 5080 itself. But boyyyyy does DLSS 4’s new tricks feel great. Multi Frame Generation makes *Star Wars Outlaws*, a notoriously janky game, feel just as good as *Doom 2016*. *Cyberpunk*’s neon Night City feels so much more *alive* when you’re racing around at a buttery-smooth 240Hz+, or over 150fps even with the game’s nuclear RT Overdrive Mode active.\n\n>And that’s the promise Nvidia needs gamers to buy into for the GeForce RTX 5080 — heck, perhaps this entire RTX 50-series generation. Are you willing to embrace “fake frames” and dip your toes into experiences that aren’t currently possible with traditional rendering alone? If so, this GPU provides enough grunt to fuel those adventures in 4K and 1440p alike.\n\n>If not, the RTX 5080 is one of the most disappointing GPU releases in a long time. It’s probably best to save your cash.\n\n>Me? I’m into the vision. But I wish Nvidia imbued the RTX 5080 with more raw rendering firepower, so it could be a decent upgrade even for “fake frame” haters. Nvidia didn’t, alas — so now the RTX 5080’s future hangs in the balance of those 75 DLSS 4 games working correctly at launch.\n\n>If DLSS 4 and Multi Frame Generation perform like a champ when that wider availability hits, it could usher in a new era of smooth, AI-supercharged performance. But if DLSS 4 winds up plagued by visual artifacts or other issues once the floodgates open, it could instead set off an explosion of “fake frames” memes and sign a death warrant for the otherwise ho-hum RTX 5080 — perhaps even the rest of Nvidia’s 50-series lineup.\n\n>The GeForce RTX 5090 can stand alone on its own merits, but the RTX 5080 is all-in on DLSS 4. All that’s left us to see is where the chips fall.\n\n# [LanOC](https://lanoc.org/review/video-cards/9135-nvidia-rtx-5080-founders-edition)\n\n>For performance, it will depend a lot on what your goal is for the card on whether you would say it did well in testing or not. Nvidia markets the card as a 2k or 1440p card and at that resolution and at 1080p it did extremely well, outperforming last generation's flagship RTX 4090. At 4k I would still say it did very well, but on average the RTX 4090 does edge back in ahead of it in our tests. The RTX 5080 has 16GB of memory and a smaller memory interface than the RTX 4090. It does have faster memory which makes up the difference a lot, but that does make a difference at 4k in some tests. That said, if you haven’t experienced DLSS 4 with the improved transformer models making significant improvements in the visual quality and frame generation x4 giving mind blowing performance, I would take that over the 8 extra FPS at 4k. Not only do you see a lot of those improvements even in CPU-limited situations, but you can see 300-500% performance improvements over not using DLSS at all. I didn’t run into as many of the bugs as I saw when testing the RTX 5090, but OpenCL-based workloads were still a problem but Nvidia is aware and working on it.\n\n>At the end of the day though, it always comes down to pricing. The RTX 5080 Founders Edition has an MSRP of $999. That is $200 less than the RTX 4080 launched at but is $300 more than what the RTX 3080 launched at. It’s also half of the price of the new RTX 5090. More importantly, how does it compare to other cards with current pricing? For that, I put the graph above together that takes every card I’ve tested’s Time Spy Extreme GPU Score and divides it by its current price as well as its launch MSRP. For current pricing, it is the lowest available price on PCPartPicker and it is interesting to see how much pricing and card availability has changed from last week when the performance of the RTX 5090 was shown. The RTX 5080 Founders Edition is sitting in the middle of the pack for value right now but there aren’t any cards faster or even near it in performance on the chart. With all of the talk on how it compares with the RTX 4090 for example, the only 4090’s you can currently get are $2598 or more. I wouldn’t call it a value, but if you are looking for high-end 1400p or 4k performance and the RTX 5090 isn’t in your budget this is the clear choice, that is assuming you can find these anywhere near the launch price once they hit stores.\n\n# [OC3D Article](https://overclock3d.net/reviews/gpu_displays/nvidia-rtx-5080-founders-edition-review/)\n\n# [OC3D Video](https://www.youtube.com/watch?v=k-6Dw4qsGhA)\n\n>As we said in our introduction, the Nvidia RTX 5080 Founders Edition is almost famous before it’s appeared. Such is the incredible reputation of its similarly numbered forebears, the expectation is massive. The GTX 280 was launched 17 years ago, and apart from a couple of notable missteps – the red hot GTX 480 for example – they’ve all been stellar. It’s not a coincidence that when Nvidia introduced the RTX series of cards the top model was a RTX 2080 Ti. The name has cachet.\n\n>Clearly the RTX 5090 follows the recent trend where the 90 card is the flagship, money-no-object option. The x080 cards are for those with deep pockets, but not unlimited ones. Or perhaps those for whom gaming is your primary thing and so spending a little more is worthwhile. That’s where the Nvidia RTX 5080 Founders Edition comes in. We’ve yet to see performance figures for the guaranteed massive selling RTX 5070 and RTX 5070Ti models. That leaves us with either seeing how close the Nvidia RTX 5080 can get to the big RTX 5090, or how much better than the Ada Lovelace cards it is.\n\n>If the RTX 5090 was jaw-dropping, the RTX 5080 continues that good work. The next generation of cores which festoon the tiny PCB really put the work in to give you smooth performance. We know that the big ticket item is multi-frame generation, but even in pure rasterised benchmarks the Nvidia RTX 5080 Founders Edition proves a big upgrade on the previous model. If you’re just after the latest and greatest at an enthusiast price point, you can almost stop reading here.\n\n# [PC World Article](https://www.pcworld.com/article/2591060/nvidia-geforce-rtx-5080-review.html)\n\n# [PC World Video](https://www.youtube.com/watch?v=YaZT5OuW6v0)\n\n>DLSS 4’s Multi Frame Generation feature must be seen (and felt) to be believed. On PCWorld’s Full Nerd podcast, we compared the leap from Single Frame to Multi Frame Generation to the leap from DLSS 1 to DLSS 2. When both technologies first came out, they showed promise but had plenty of rough edges. With DLSS 2, gamers agreed that Nvidia *nailed it*. And while it’s not quite perfect, Multi Frame Generation *nails it*. Once more gamers get their Dorito-stained paws on RTX 50-series cards, and are able to tool around with MFG in 75+ games and apps, I wouldn’t be surprised if all the furor over “fake frames” online dies down quite a bit. It’s a literal game changer.\n\n>But Nvidia is in trouble this generation if the masses *don’t* embrace Multi Frame Generation. Because when it comes to traditional gaming performance, the RTX 5080 is no game changer. \n\n>It’s a pretty damned terrible generational upgrade, actually. Eking out a mere 11 to 15 more render performance than the RTX 4080 Super, at the same price, at a higher power draw, isn’t compelling whatsoever. It can’t come anywhere close to last gen’s 4090. If you don’t like AI-generated frames — maybe you’re sensitive to latency, or you focus on competitive games, or you loathe the idea of AI frames potentially introducing visual glitches — I’d even go so far as to suggest picking up a 4080 Super to get roughly comparable performance for less cash.\n\n>If Nvidia didn’t have MFG in tow, this would’ve been a *scathing* review for the RTX 5080 itself. But boyyyyy does DLSS 4’s new tricks feel great. Multi Frame Generation makes *Star Wars Outlaws*, a notoriously janky game, feel just as good as *Doom 2016*. *Cyberpunk*’s neon Night City feels so much more *alive* when you’re racing around at a buttery-smooth 240Hz+, or over 150fps even with the game’s nuclear RT Overdrive Mode active.\n\n>If not, the RTX 5080 is one of the most disappointing GPU releases in a long time despite its prowess. It’s probably best to save your cash unless you’re on a card several generations old and don’t mind spending big for a big performance upgrade.\n\n>If DLSS 4 and Multi Frame Generation perform like a champ when that wider availability hits, it could usher in a new era of smooth, AI-supercharged performance. But if DLSS 4 winds up plagued by visual artifacts or other issues once the floodgates open, it could instead set off an explosion of “fake frames” memes and sign a death warrant for the otherwise ho-hum RTX 5080 — perhaps even the rest of Nvidia’s 50-series lineup.\n\n>The GeForce RTX 5090 can stand alone on its own merits, but the RTX 5080 is all-in on DLSS 4. All that’s left us to see is where the chips fall.\n\n# [Puget Systems (Content Creation Review)](https://www.pugetsystems.com/labs/articles/nvidia-geforce-rtx-5080-content-creation-review/)\n\n>Overall, the RTX 5080 is a solid GPU that provides good performance nearly across the board. However, following [our 5090 review](https://www.pugetsystems.com/labs/articles/nvidia-geforce-rtx-5090-content-creation-review/), we are somewhat disappointed by the relatively small performance uplifts over the RTX 4080 SUPER. In some places, the 5090 seemed to justify the price increase over the 4090 with staggering performance increases. For the 5080, the same price seems to get you basically just the same performance in many workloads.\n\n>In **video editing and motion graphics**, the RTX 5080 is about 5-10% faster than the RTX 4080 SUPER and 20-30% faster than the 3080 Ti. There were some standout areas, such as 3D performance in After Effects, with gains double those. We’re still waiting on finalized DaVinci Resolve results, but we are doubtful the 5080 will be a huge upgrade over a 4080 or 4080 SUPER, except perhaps with LongGOP media. Still, for new-to-PC users or those on even older cards, it offers a solid upgrade.\n\n>In **rendering applications**, the 5080 manages better, with a 10-20% lead over the 4080 SUPER and a 55% to 188% lead over the 3080 Ti. This is definitely a performance jump that may be worth upgrading for even from the 40-series card, and it offers a great value for those using older generation cards. However, there is still the lingering issue of compatibility and performance quirks, so we would recommend buying with caution or holding off for a bit before committing to a 5080 for a rendering system. We are currently [maintaining a list of known issues](https://www.pugetsystems.com/blog/2025/01/27/nvidia-geforce-rtx-50-series-known-software-issues/) in content creation applications that you can check in on to see when these are resolved.\n\n>NVIDIA’s new GeForce RTX 5080 is a great workhorse GPU that provides solid performance across the board and can handle most of the tasks you throw at it. In many workflows, it is only slightly slower than the RTX 5090, so it may end up being one of the better price-to-performance cards of this generation. If you are on a 30-series card or older, it offers a great upgrade, but less so for users on a 40-series card. Especially given the dwindling supply of those previous-generation cards, we expect the RTX 5080 to be an incredibly popular GPU.\n\n# [Techpowerup](https://www.techpowerup.com/review/nvidia-geforce-rtx-5080-founders-edition/)\n\n>At 4K resolution, with pure rasterization, without ray tracing or DLSS, we measured a 14% performance uplift over the RTX 4080 Super, 15% over the RTX 4080 non-Super. This is definitely MUCH less than expected and not nearly as much as what we saw last week from RTX 5090, which beat the RTX 4090 by 35%. Compared to the GeForce RTX 3080, the performance increase is 75%, which means NVIDIA missed the \"twice the performance every second generation\" rule. Last-generation's flagship, the RTX 4090 is 13% faster than the RTX 5080 and the new RTX 5090 flagship is 52% faster, but twice as expensive.\n\n>GeForce RTX 5080 is still faster than AMD Radeon RX 7900 XTX, Team Red's best GPU, by 15% in a pure raster scenario, much more in RT. AMD has confirmed that they are not going for high-end with RDNA 4, and it's expected that the RX 9070 Series will end up somewhere between RX 7900 XT and RX 7900 GRE. This means that AMD's new cards don't pose a threat to the RTX 5080, which might explain why we're not getting bigger performance improvements.\n\n>RTX 5080 is a good card for 4K gaming. With RT or Path Tracing enabled, some titles require that you use DLSS Upscaling / Frame Generation. The card is also great for 1440p gaming, to feed those high-refresh-rate gaming monitors.\n\n>NVIDIA is betting on ray tracing and Blackwell comes with several hardware improvements here. Interestingly, the RTX 5080 runs only 11% faster at RT than RTX 4080 Super—remember, we got +14% in without RT. It looks like this is partly due to the game selection. The games that show the biggest gains in our non-RT test suite do not support RT. Still, compared to AMD's Radeon RX 7900 XTX, the difference is massive—the RTX 5080 is 61% (!) faster than the RX 7900 XTX. On top of that, NVIDIA is introducing several new optimization techniques that game developers can adopt. The most interesting one is Neural Rendering, which is exposed through a Microsoft DirectX API (Cooperative Vectors). This ensures that the feature is universally available for all GPU vendors to implement, so game developers should be highly motivated to pick it up. AMD has confirmed that for RDNA 4 they have put in some extra love for the RT cores, so hopefully they can catch up a bit.\n\n>NVIDIA made a big marketing push to tell everyone how awesome DLSS 4 is, and they are not wrong. First of all, DLSS 4 Multi-Frame-Generation. While DLSS 3 doubled the framerates by generating a single new frame, DLSS 4 can now triple or quadruple the frame count. In our testing this worked very well and delivered the expected FPS rates. Using FG, gaming latency does NOT scale linearly with FPS, but given a base FPS of like 40 or 50, DLSS x4 works great to achieve the smoothness of over 150 FPS, with similar latency than you started out with. Image quality is good, if you know what to look for you can see some halos around the player, but that's nothing you'd notice in actual gameplay.\n\n>Want lower latency? Then turn on DLSS 4 Upscaling, which lowers the render resolution and scales up the native frame. In the past there were a lot of debates whether DLSS upscaling image quality is good enough, some people even claimed \"better than native\"—I strongly disagree with that—I'm one of the people who are allergic to DLSS 3 upscaling, even at \"quality.\" With Blackwell, NVIDIA is introducing a \"Transformer\" upscaling model for DLSS, which is a major improvement over the previous \"CNN\" model. I tested Transformer and I'm in love. The image quality is so good, \"Quality\" looks like native, sometimes better. There is no more flickering or low-res smeared out textures on the horizon. Thin wires are crystal clear, even at sub-4K resolution! You really have to see it for yourself to appreciate it, it's almost like magic. The best thing? DLSS Transformer is available not only on GeForce 50 series, but on all GeForce RTX cards with Tensor Cores! While it comes with a roughly 10% performance hit compared to CNN, I would never go back to CNN. While our press driver was limited to a handful of games with DLSS 4 support, NVIDIA will have around 75 games supporting it on launch, most through NVIDIA App overrides, and many more are individually tested, to ensure best results. NVIDIA is putting extra focus on ensuring that there will be no anti-cheat drama when using the overrides.\n\n>For $1000, there is no reason you should buy RTX 4080 or RTX 4080 Super now. AMD's Radeon RX 7900 XTX is $820, or 18% cheaper, but it's also 15% slower in raster, and 38% slower in RT. NVIDIA is also very strong in software features, the new DLSS Transformer model is a game-changer and DLSS 4 multi-frame-generation is a notable selling point, too. No way I would buy RX 7900 XTX at that price instead of RTX 5080—maybe if AMD drops the price considerably. Also, the way AMD is handling Radeon lately makes me wonder if their discrete GPU brand will still be around in two or three years. The upcoming RDNA 4 lineup will not target the top end of the market, so unless a miracle happens, RX 9070 XT won't be able to compete with RTX 5080, maybe RTX 5070 Ti, which is coming out soon.\n\n>If you already have a high-end GeForce RTX 40 Series card, then there is no reason to upgrade. You're just missing out on multi-frame-generation, the DLSS Transformer model is supported on all older RTX cards, too. On the other hand, if you're coming from GeForce 30, then suddenly you'll get to experience frame generation, which will make a huge difference for your gaming experience.\n\n# [The FPS Review](https://www.thefpsreview.com/2025/01/29/nvidia-geforce-rtx-5080-founders-edition-video-card-review/)\n\n>GeForce RTX 5080 performance makes us go hmmm. That’s an interesting way for us to start this paragraph, but the performance of the GeForce RTX 5080 is indeed all over the place. There are some games where the generational uplift looks exciting, and then there are others that make us scratch our head. It generally gives us a feeling of “hmmm.”\n\n>There are some good cases where the GeForce RTX 5080 is a nice uplift from the previous generation. We did see some 23%+ performance improvements, but those seemed to be outliers, more than the norm. Overall, it has somewhere between a 10%-20% performance uplift depending on the game and settings, Ray Tracing wasn’t that big. This isn’t enough to reach or match the GeForce RTX 4090 in performance. The GeForce RTX 4090 remains the performance leader in this regard. If you thought the GeForce RTX 5080 would be as fast as the GeForce RTX 4090, it isn’t.\n\n>Some of the results we have experienced make sense, after all, the raw specifications of the GeForce RTX 5080 are not that much upgraded from the GeForce RTX 4080 Super. The GeForce RTX 5080 is a GPU that is essentially a GeForce RTX 5090 cut in half, and the price reflects that as well. The GeForce RTX 5080 seems to consume about 17% more power than the GeForce RTX 4080 Super, and we get a performance increase that is close to that, some cases better, some cases worse.\n\n>Overall this means that the GeForce RTX 5080 at times follows a little too closely to the previous generation it is supposed to be supplanting. Often times we are left with a sense of a less-than-desirable gameplay experience improvement that one would expect from a new generation.\n\n>One could even call the GeForce RTX 5080 more akin to a theoretical ‘GeForce RTX 4080 Super Ti” or “GeForce RTX 4080 Super Super”, at least that is what it feels like. Keep in mind that the MSRP is $999, and that IS the same MSRP that the GeForce RTX 4080 Super was as well. Therefore, technically, it is a price for performance improvement, if pricing is at $999. It’s just that… it isn’t that exciting really.\n\n>As the GeForce RTX 4080 Super’s dry up in the market and the GeForce RTX 5080’s replace it, you will be getting a better gameplay experience with the GeForce RTX 5080. At the $999 MSRP, the NVIDIA GeForce RTX 5080 Founders Edition would be a solid upgrade from *prior generations*, such as GeForce RTX 3080 or GeForce RTX 2080 or even earlier.\n\n>If you are moving from an older generation prior to the RTX 40 series, the GeForce RTX 5080 will offer a good substantial upgrade path to modern features and gameplay performance at the $999 MSRP, but if you currently own a GeForce RTX 40 Series, unless you are moving from low-end to high-end, it is not going to be worth the upgrade.\n\n# [Tomshardware](https://www.tomshardware.com/pc-components/gpus/nvidia-geforce-rtx-5080-review)\n\n>Nvidia's RTX 5080 Founders Edition delivers what we were expecting, mostly. We can't help but feel that, like the RTX 5090, these first drivers made available to reviewers aren't fully tuned for the Blackwell architecture yet. In some games, performance looks quite good with reasonable generational improvements. In others, the gains don't materialize — particularly at lower resolutions.\n\n>What is obvious is that the RTX 5080 isn't a massive leap in performance compared to its predecessor — whether that's the 4080 Super we tested or the slightly slower RTX 4080. Nvidia's performance claims depend almost entirely on Multi Frame Generation (MFG), and that's disingenuous at best. Nvidia knows as well as anyone that a game running at 200 FPS with 4X MFG doesn't feel the same as a game rendering at 200 FPS without any form of framegen. Pretending that the resulting \"framerates\" are comparable requires serious mental gymnastics.\n\n>However, it's equally disingenuous to suggest that framegen/MFG are useless or \"fake frames.\" If you play a game running at 30–35 FPS without framegen and then try the same game running at 55–60 FPS with framegen, the latter feels better in my book. It's not anywhere close to twice as fast, but perhaps 20% faster. And if you use 4X MFG running at 105–115 FPS, that might feel another 10–20 percent faster than the 2X framegen result.\n\n>It's really just frame smoothing, but that smoothness interacts with your brain to make the game generally feel better, even if the base input sampling rate decreases slightly.\n\n>As a potential GPU purchase, if they're both priced the same, the RTX 5080 will be better than an RTX 4080 Super. That much is a given. Right now, it doesn't always win, but driver tuning should address any shortcomings. But if you already have a decent GPU, the benefits of the 5080 over the 4080 Super are pretty thin at present. If you didn't see enough in the RTX 4080 Super to entice you to upgrade in early 2024, the extra 10% performance plus new features that the 5080 offers isn't likely to change things.\n\n>If you're in the market for a $1,000 graphics card, and assuming there's enough supply to keep prices down, the RTX 5080 now sits on the podium as the second fastest GPU overall. It's half the price of the 5090, less likely to be continually sold out, and has all the other Blackwell architecture features. It's just nowhere near the potential 30% higher baseline performance we like to see with generational upgrades.\n\n>And if you're able to justify spending a grand on the RTX 5080, it's probably not that much of a stretch to double that for the clearly superior RTX 5090 that's over 50% faster on average — at 4K. The RTX 3090 was only 15% faster than an RTX 3080 four years ago, for double the price. For the well-funded gamer / streamer / AI researcher / etc., the 5090 is the clearly superior option. Which is one more reason we expect it will be hard to come by for quite some time.\n\n# [Computerbase - German](https://www.computerbase.de/artikel/grafikkarten/nvidia-geforce-rtx-5080-test.91176/)\n\n# [HardwareLuxx - German](https://www.hardwareluxx.de/index.php/artikel/hardware/grafikkarten/65395-leistungsplus-nur-ueber-mfg-die-geforce-rtx-5080-founders-edition-im-test.html)\n\n# [PCGH - German](https://www.pcgameshardware.de/Geforce-RTX-5080-Grafikkarte-281030/Tests/Release-Preis-kaufen-Benchmark-Review-vs-4080-Super-1464610/)\n\n# [Elchapuzasinformatico - Spanish](https://elchapuzasinformatico.com/2025/01/nvidia-geforce-rtx-5080-founders-edition-review/)\n\n\\--------------------------------------------\n\n# Video Review\n\n# [Der8auer](https://www.youtube.com/watch?v=IvQwlN1sE0U)\n\n# [Digital Foundry Video](https://www.youtube.com/watch?v=k7hDtGh0wIo)\n\n# [eTeknix Video](https://www.youtube.com/watch?v=CKhoBBX2h00)\n\n# [Gamers Nexus Video](https://www.youtube.com/watch?v=nShh_j4s2YE)\n\n# [Hardware Canucks](https://www.youtube.com/watch?v=JFF7lMvpV-s)\n\n# [Hardware Unboxed](https://www.youtube.com/watch?v=sEu6k-MdZgc)\n\n# [JayzTwoCents](https://www.youtube.com/watch?v=meekBr-ZB1E)\n\n# [KitGuru Video](https://www.youtube.com/watch?v=uKIwmW5j6oc)\n\n# [Level1Techs](https://www.youtube.com/watch?v=ZoE8GQnDwQQ)\n\n# [Linus Tech Tips](https://www.youtube.com/watch?v=Fbg7ChsjmEA)\n\n# [OC3D Video](https://www.youtube.com/watch?v=k-6Dw4qsGhA)\n\n# [Optimum Tech](https://www.youtube.com/watch?v=d7k4XWg-TcA)\n\n# [PC World Video](https://www.youtube.com/watch?v=YaZT5OuW6v0)\n\n# [Techtesters](https://www.youtube.com/watch?v=azD56D4_bFM)\n\n# [Tech Yes City](https://www.youtube.com/watch?v=6NwO1qrkEds)",
    "comments": [
      "> And if you’re able to justify spending a grand on the RTX 5080, it’s probably not that much of a stretch to double that for the clearly superior RTX 5090 that’s over 50% faster on average — at 4K\n\nWhat a stupid take (as expected) from Tomshardware.",
      "Literally the worst generation of GPUs Nvidia has ever released.",
      "RTX 50 8.0%",
      "TLDR; Skip the 5080 if you have a 40 series.",
      "I hope this doomer posting from this sub continues so I can get a 5080 tomorrow. \n\nNot everyone is upgrading from a 4000 series, and this seems like a great upgrade from my 3070ti.",
      "I may as well double it again and run dual 5090s at that point because clearly if im just throwing thousands around like that it's not an issue",
      "RIP my dreams of cheaper used 4090s.",
      "Fairly disappointing coming from a 3080 Ti looking to upgrade.",
      "My takeaway.\n\n\nIf you are on 4000 series, skip. Unless you really want multi frame gen.\n\n\nFor 3000 series, it is up to you. It's up to 50% more frames, some improvements in frame time, and access to frame Gen.\n\nUnder the 3000 series? Much better performance, much better frame times, more features. If you were previously considering the 4000 series, this is a no brainer. Better performance at the same price.\n\nThe 5000 series is being compared to Turing. A lot of the new architecture is focused on neural rendering, but no games use it yet. Like Turing, these cards might age well in 2 years time.\n\nThe small Gen on Gen uplift is why everyone is upset. Neural rendering doesn't exist in games right now. Silver lining is that the 5000 series is the same price as last Gen.\n\n\n\nThere is so much room for a 5080 Ti or Super. The 5090 is getting something like up to 50% more frames over the 5080. Also room for more ram on a 5080 Super/Ti.",
      "NVIDIA has been trying to make people think this way for years, but this gen doesn’t sell it at all. $1200 -> $1600 made a lot more sense last gen, even if that was also BS",
      "This \" launch \" could've been an email",
      "See the bright side: There will be less posts about 5080 not beeing in stock.",
      "CPU manufs should retaliate by blowing hot air towards the GPU.",
      "Gonna keep my 3080 for a while longer, lets see what the next generation has in store.",
      "The 16gb vram aside (which already made it a no-buy for me), the pitiful perf increase and price tag make this a slap in the face from nvidia.\n\nI'll definitely be holding on to my 3080 for another gen it seems.",
      "basically a 4080 Ti Super with multi frame gen \n\nnot a bad card if you're going from 30 series GPUs and below or a 4060, but still a bad card generation to generation wise",
      "Barely 10 per cent improvement ...  there: done.\n\nYou're welcome.",
      "Going from a 1070 to a 5080 is a massive upgrade, why would it not be worth it?",
      "I thought my 4090 purchase was insane at launch. It might actually turn out one of the best in a few more years.\n\n5xxx series is the least impressive launch since GTX 700 series!",
      "I wasn't expecting much and was still disappointment"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "rtx 4080",
      "4080"
    ],
    "title": "RTX 4080 for only $660!",
    "selftext": "was looking on offerup for a 3080ti when this PNY 4080 popped up for only $660 \n\nthe guy who was selling it upgraded to a 4090 because of the whole intel cpu power issue, he thought it was his gpu before it became more common issue for people.",
    "comments": [
      "https://preview.redd.it/egxcum0r1k1d1.png?width=632&format=png&auto=webp&s=ea55340071c9975050d45d471108e2038bc4701c\n\nJokes aside nice find bro!",
      "Steal of the century good looks man",
      "https://preview.redd.it/q8dp91m2tm1d1.jpeg?width=1389&format=pjpg&auto=webp&s=4e27de9fc68817f1098ee48c26e68d1d417cfd9e",
      "I like how this meme is becoming gradually more grainy from people screenshotting it",
      "Had a similar experience and ended up with a 4070ti for 400 shipped.  It wasn't the card I was shopping for but couldn't pass it up.",
      "https://preview.redd.it/79s5h1hyml1d1.jpeg?width=561&format=pjpg&auto=webp&s=aa4a3afb38e8f4796f7a4ab080f1d7a3832427cd\n\nscreenshot this one instead people!",
      "I would never have the balls to buy a used component like that, even less so for that price but thats amazing",
      "https://preview.redd.it/q67vcxqw3o1d1.jpeg?width=1024&format=pjpg&auto=webp&s=e64249cf2055d6ffd381e6cf51dbbd8cc298d71f",
      "Incredibly jealous. I have a 3080 so I am good for a while (hopefully) but I would have scooped that up in a heart beat",
      "[Here's my attempt](https://i.imgur.com/FQDmXHe.png)",
      "Zimbabwe dollars, though it would amount to like 10K usd at most due to inflation ._.",
      "That is just false. PNY is underrated and only shunned for their non-US-friendly warranty policy. They are cheaper than the other high quality models but on par or even better. I'm on my 3rd PNY XLR8 card (4070 -> 4070 Ti -> 4080) and all 3 cards were performing way above average with an undervolt + OC. My current card is only slightly undervolted and scores higher than the average 4080 Super.",
      "Jesus Christ that thing is HUGE",
      "If you got proper tests why not?",
      "$660 usd",
      "offerup",
      "card was barely used, guy who had it built his PC in January with an Intel 14th GEN and he had the motherboard power issue and assumed it was the GPU so he bought a 4090, only to find out it was and intel problem. cool guy talked about computers for like 20 minutes while the card did 3dmark",
      "Yeah, different model.",
      "What dollar do you mean? Because the last time i checked, a 4080 isn't worth 11845574776103298668108996611464848941298114758752849955839899515943785936771277621868784031678851459697654158282068706909975320139600711043510969878851972867066637303859577102038629568864882113293677344271316754018351837011502130166812019953728371406583077111886117124196679437327967894798492878091517527904897031301318471314068480796311216464897234263828412545873076852790938835071294503481398081099412367241392499753809336438649992401239586812557779801969810567427415991816845995811640903411979393564066599544489657501447345506097125501037541255747083353753120317093245357599088384362811902460071043770732742013992536480470054053470103110958527864437221135549299946446319494649496733919890283565355360299168901781924547763289047904411317614163944638144348223145490780868328810569444173295524788962414031056752375442360538877278515963062240944551434852522753811947333108125989633115672734628274290447316059377212464564148289803390769483690103865432900808757585095826298459650438233516829963370763155702864049973342431581183674213958886327100648926325991510275259029660497949026093510724545537389973667088676775821278080867834001636329617480050127168053134310689166368637382697256840586579853078069289654376516816671460186607862120454205799904478594303723445114003124732645560181279807690863096786890131788377994499915662688651944291697561432048501119068048064439273880590420058509604539548657873962517356819251200000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000 USD/CAD/AUD (ik there are other dollars but they aren't that common on reddit)",
      "What marketplace is that"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "rtx 4080",
      "4080",
      "4080 super",
      "rtx 4080 super"
    ],
    "title": "GeForce RTX 4070 Ti Super Review Megathread",
    "selftext": "# GeForce RTX 4070 Ti Super reviews are up.\n\n&#x200B;\n\n[GeForce RTX 4070 Ti Super](https://preview.redd.it/yoex906xo9ec1.jpg?width=1200&format=pjpg&auto=webp&s=5ddccd2aa72c6eb61e5bee2e341626d7c9b818dd)\n\n# Below is the compilation of all the reviews that have been posted so far. I will be updating this continuously throughout the day with the conclusion of each publications and any new review links. This will be sorted alphabetically.\n\n# [\\[PSA\\] Certain MSI GeForce RTX 4070 Ti Super Ventus 3X VBIOS Causes Lower Performance Than Expected](https://www.reddit.com/r/nvidia/comments/19dq7le/psa_certain_msi_geforce_rtx_4070_ti_super_ventus/)\n\n# Written Articles\n\n# [Babeltechreviews](https://babeltechreviews.com/rtx-4070-ti-super-review-800-for-near-4080-performance/)\n\n>Nvidia claimed a 10% increase of the previous model and we did achieve mostly that in our testing, with some slightly lower than quoted. Its obvious this card easily surpasses the original model at the same price and its really close to the original RTX 4080 performance point at significantly less than MSRP for the RTX 4080. This will change soon with the upcoming launch of the RTX 4080 SUPER at its lowered price point of $999.00.  \n>  \n>The real decision for gamers, in our opinion, looking for a card at this level is looking for a used RTX 4080 or something at this similar price. If you are looking for a new card that can compete with the RTX 4080 for lower entry cost then this is a good choice.\n\n# Digital Foundry Article - TBD\n\n# Digital Foundry Video - TBD\n\n# [eTeknix](https://www.eteknix.com/gigabyte-rtx-4070-ti-super-oc-graphics-card-review/)\n\n>So I’m going to admit. That was painful. When looking at performance and analysing the point of our content, it’s easy to get excited when we see an evolutionary jump, but that’s not the case here. It’s slightly faster, and I’m talking marginally.  \n>  \n>When you look at the specifications, this new graphics card is better in every way. There are higher core counts, there are more RT and Tensor cores, there’s more VRAM, the clock speeds are up, and really, that should be an indication of a pretty potent performance boost. However, from our pretty extensive testing, that’s not really what we see in the real world. It’s a little bit better, but does it feel like an upgrade? Not really, if I’m being honest. More VRAM is nice and does improve the 1% lows, but not as much as the fanatics in the internet comment sections would have you believe it would have.  \n>  \n>DLSS and other technologies should have seen a boost too, but in games like Cyberpunk and Hogwarts Legacy, some were up, some were down, and some were about the same, so it is splitting hairs on whether this is better or not. Not that there’s anything wrong with the performance though, it’s still largely a very great card, the performance is fantastic, but it just feels like something may be missing. I hope and honestly largely expect that this will improve with a few driver updates, as things always do. I suspect in a few weeks or a couple of months, the Super variants will have a bigger lead on the non-Super cards they are replacing.  \n>  \n>What I do like about both the Gigabyte and INNO3D cards is the cooler upgrades. Gigabyte has honed its Windforce designs over the years, and INNO3D has a great-looking product too with a 2-slot form factor. Having a premium quality cooler on this chipset showed that it can run nice and cool and quiet, while still delivering great performance overall.  \n>  \n>So overall, the 4070 Ti SUPER can be taken one of two ways. If you’re already rocking a 4070 Ti, then there is no reason to change to a Ti SUPER, and if you want more performance then you need to be looking at 4080 levels or above, but even then I’d personally wait for the 4080 SUPER to see what that brings, though I fear it could be the same levels as what we saw today. If however, you’re on something older and your heart was set on a 4070 Ti, then obviously it makes sense to pay the same, and get a 4070 Ti SUPER, though I’d seriously be questioning how much extra performance you’re going to be gaining over what you already have.\n\n# [Guru3D](https://www.guru3d.com/review/asus-tuf-geforce-rtx-4070-ti-super-review/)\n\n>The data speaks for itself, key factors here are gaming performance and rendering quality. Indeed, the RTX 4070 Ti SUPER offers better value for money compared to the 4080. This card is approaching the raw performance required for gaming at 4K resolution. It caters specifically to enthusiast gamers who typically use monitors with UWHD, QHD, or UHD resolutions, making it an ideal choice for that demographic. The rasterizer engine in the RTX 40 series significantly surpasses the performance capabilities of its predecessors. This series introduces a new generation of more potent Ray tracing and Tensor cores. Raw counts of RT and Tensor cores are not the sole indicators of performance; rather, the effectiveness of each unit is key. These cores are positioned near the shader engine, enhancing their efficiency, a fact that is evident in their performance. While Tensor cores' impact is more challenging to quantify, the impressive results observed, especially with DLSS3, indicate their robust performance. The GeForce RTX 4070 Ti demonstrates its strength across various resolutions, performing effectively from 2K (2560x1440) to 4K (3840x2160).  \n>  \n>Overall the GeForce RTX 4070 Ti SUPER delivers a robust gaming experience, and when comparing it directly to similar GPUs, it surpasses the performance range of the 3090 Ti and is close to the RTX 4080, with some variability. In a broader context, when comparing it to other GPUs like the Radeon RX 6950 XT and 7900 XT/XTX, a complex decision-making process ensues. The choice between the 4070 Ti SUPER and 7900 XTX hinges on several factors. The RTX 4070 Ti SUPER excels in ray tracing performance and boasts the added benefit of DLSS3/3.5 and at many levels is on par with more than 3090 cards. Looking at Team Red the 7900 XT exhibits a slight advantage in rasterizer engine performance, supported by its additional L3 cache. The 16GB of VRAM offered by the 4070 Ti SUPER is sufficient for most current titles, especially when playing at Ultra HD resolutions. Powered by the ADA GPU architecture, this card delivers precision and competence in gaming. The substantial increase in shader cores translates to nearly 1.5 times the raw shader performance, resulting in faster ray tracing and improved Tensor core performance. Underlying technologies such as Shader Execution Reordering (SER) and DLSS 3 contribute to the excellence of the new product and the Series 4000 overall. In conclusion, the GeForce RTX 4070 Ti SUPER leaves a notable impression and is sure to please gamers, but it comes at a considerable cost. Despite its commendable performance-per-watt ratio, its energy consumption levels remain relatively high. This graphics card is capable of handling Ultra HD gaming smoothly, particularly when enhanced with DLSS3 / Frame generation, and offers the possibility of a moderate overclock. The TUF Gaming version of the GeForce RTX 4070 Ti SUPER offers an appealing choice for users who value a quiet performance and visual appeal in their PC gaming setup. The model we tested today, which is the non-overclocked (nonOC) version, is priced at the manufacturer's suggested retail price (MSRP) of $799 for retail purchase.\n\n# [Hot Hardware](https://hothardware.com/reviews/asus-geforce-rtx-4070-ti-super-review)\n\n>At this point, NVIDIA’s blueprint with the [GeForce RTX 40 SUPER](https://hothardware.com/reviews/nvidia-geforce-rtx-4070-super-review) series is clear – boost performance at similar (or lower) introductory prices, to enhance the overall value of the line-up. The ASUS TUF GeForce RTX 4070 Ti SUPER arrives at the same $799 price point of its predecessor, but offers more cores, more video memory, and ultimately more performance across every workload. The ASUS TUF GeForce RTX 4070 Ti SUPER can’t quite catch the GeForce RTX 4080, bit it comes close in many tests, for a couple of hundred bucks less.  \n>  \n>With [recent price cuts](https://hothardware.com/news/amd-slashes-radeonrx-7900-xt-price), the [Radeon RX 7900 X](https://amzn.to/42cJYaA)T is being offered for about $710. Looking back through the numbers, that price adjustment is just about in-line with its performance relative to the ASUS TUF GeForce RTX 4070 Ti SUPER if you factor in ray tracing. In games that don’t make extensive use of ray tracing and mostly rely on traditional rasterization techniques, the Radeon RX 7900 XT may pull ahead of the RTX 4070 Ti SUPER. Today’s GPUs are about much more than gaming, however. Looking at the content creation, rendering, and other compute tests and the ASUS TUF GeForce RTX 4070 Ti SUPER outpaces the Radeons.  \n>  \n>Ultimately the GeForce RTX 4070 Ti SUPER represents additional value for gamers and creators. It arrives at the same price point as its predecessor, but effectively offers more of everything. If you’ve got the budget and are looking for a GPU its price category, the GeForce RTX 4070 Ti SUPER is the card to beat right now, and ASUS’ TUF model ticks many of the right boxes.\n\n# [Igor's Lab](https://www.igorslab.de/en/msi-geforce-rtx-4070-ti-super-ventus-3x-16-gb-in-test-desired-upgrade-with-contemporary-memory-expansion-and-under-pressure-from-amd/)\n\n>The GeForce RTX 4070 Ti Super is an excellent card in WQHD when it comes to the highest frame rates and is also quite suitable for Ultra HD. At the latest then, however, you will have to think about smart upscaling in places and this is where DLSS and frame generation come into play. Meanwhile, games such as “The Last of Us Part 1” (TLOU) look subjectively even better in Ultra HD with DLSS than native Ultra HD. This is where NVIDIA can really play to its advantages, which DLSS 2.x and, above all, DLSS 3.5 also offer in purely visual terms.  \n>  \n>However, if a game also supports frame generation and you would still be bobbing around in the less playable FPS range even with super sampling, then this can even be a lifeline to good playability. You can’t improve the latency with it, but not every genre is as latency-bound as various shooters. I would have really liked DLSS 3.5 for TLOU, but you can’t have everything. From this point of view, the GeForce RTX 4070 Ti Super completely fulfills all expectations based on the data already published. All the AI including the appropriate programs, DLSS 3.5, frame generation and the often better latencies are also good arguments. If it weren’t for the current dumping by AMD, which should be just right for the customer.  \n>  \n>The GeForce RTX 4070 Ti Super with the AD103-275-A1 is a thoroughly interesting upper mid-range card, but nothing more at the moment. Especially in view of the AMD Radeon RX 7900XT and the current price difference, it won’t sell for the really good features, but rather only for the street price. Apart from the outdated display port connection, I don’t see any disadvantages at all with the GeForce RTX 4070 Ti Super that would speak against this card, only the price has just been badly undermined by the competitor. We will have to wait and see whether the so-called OC cards justify the additional price. After all, MSI has shown with the Ventus 3X that even the MSRP card can almost perfectly convert the additional performance of the significantly increased number of shaders into adequate gaming performance.\n\n# [KitGuru Article](https://www.kitguru.net/components/graphic-cards/dominic-moass/nvidia-rtx-4070-ti-super-review-ft-msi/all/1/)\n\n# [Kitguru Video](https://www.youtube.com/watch?v=WdmZLIWGYo8&pp=ygUHa2l0Z3VydQ%3D%3D)\n\n>Ultimately, the RTX 4070 Ti Super is about as good as I was expecting considering the 10% bump in core count and the switch to 16 gigs of memory over a 256-bit interface. I will certainly be interested to see how other models compare, as if the Ventus 3X really is 5% slower than what the 4070 Ti Super should be, then that's only a further positive for the new GPU as a whole.  \n>  \n>Of course, I can only base my conclusions on what we have tested, but even then this is a strong refresh and a GPU that's well worth buying. I do believe the RX 7900 XT remains a credible option if rasterised gaming is your top priority, as it is still slightly faster overall, while [some strategically timed cut-price deals](https://www.scan.co.uk/products/powercolor-radeon-rx-7900-xt-hellhound-20gb-gddr6-ray-tracing-graphics-card-rdna3-5376-streams?utm_source=pc%20part%20picker&utm_medium=referral) only increase the value proposition. That said, I think if you are spending £750+ on a new graphics card, chances are you will be tempted by the superior ray tracing performance, DLSS support and increased efficiency of the **RTX 4070 Ti Super**.\n\n# [LanOC](https://lanoc.org/review/video-cards/8952-asus-tuf-gaming-rtx-4070-ti-super)\n\n>As for its performance, the RTX 4070 Ti SUPER has 10% more CUDA cores and Nvidia has also increased the video memory up from 12 GB to 16 GB which should help at high resolutions and help keep the card relevant in the future for longer. In my testing, this translated to a 6-10% increase in performance depending on the testing. In game at 1440p it was 5.5% faster than the overclocked TUF Gaming RTX 4070 Ti that I tested previously but at 4K this ramped up to 10% and I saw similar numbers in synthetic benchmarks like Time Spy and Time Spy Extreme which it improved 6.8% on Time Spy and 9.1% on Time Spy Extreme. This helped it catch up with AMDs RX 7900 XT, especially at 4k but the 7900 XT was on average still 3 FPS faster at 1440p. Where the 7900 XT didn’t keep up was with ray tracing performance and once you figure in DLSS which the games you are playing support it is a huge improvement. The performance improvement also helped with overall efficiency. While it has the same TGP our TUF Gaming RTX 4070 Ti SUPER did pull a hair more than our overclocked TUF Gaming RTX 4070 Ti did for power, but with the performance improvement its already great power to performance was even better. The cooler for the TUF Gaming RTX 4070 Ti SUPER ran surprisingly quiet in my testing as well and while I wouldn’t say the cooling performance was the best it did perform well keeping the card more than cool enough which when combined with how quiet it was would make me happy.  \n>  \n>As for pricing the TUF Gaming RTX 4070 Ti SUPER is launching at the RTX 4070 Ti SUPER launch MSRP of $799. This fits right in at the same MSRP as last year's RTX 4070 Ti which is it replacing. There aren’t any game partnerships right now however which is a bummer given that AMDs RX 7900 XT does come with Avatars Frontiers or Pandora. AMD did also just recently dropped the pricing on a few of their cards including the 7900 XT which now has an MSRP of $749 in response to Nvidia’s SUPER cards announcement. This does put the 7900 XT as the better value if you are looking only at raster performance, but I do think that the ray tracing and DLSS performance have a lot of value as well and that $50 difference still makes this a good pickup if you are looking for high-end performance without spending RTX 4080 or RX 7900 XTX numbers. The TUF Gaming RTX 4070 Ti SUPER specifically is looking especially appealing this time around given that there isn’t a Founders Edition for this GPU and its all-metal construction. Asus does have an overclocked model as well which will hit stores at $849.99 and a white overclocked TUF model for $879.99. They will also have a Pro Art card for that same $879.99 price point and then a Strix model as well which has a hefty $949.99 price point which is WAY too close to the announced MSRP of the RTX 4080 SUPER in my opinion.\n\n# OC3D Article - TBD\n\n# OC3D Video - TBD\n\n# [PC Perspective](https://pcper.com/2024/01/nvidia-geforce-rtx-4070-ti-super-review-featuring-asus/)\n\n>This was a refreshing review. Not just because the RTX 4070 Ti has been refreshed, and is now SUPER for the same price, but because it really lives up to the SUPER branding with double-digit gains over its predecessor. This card is being neatly dropped in to the same price slot as its predecessor, bringing quite a bit of RTX 4080 DNA along with it.  \n>  \n>You know, it’s like NVIDIA was holding out on us. They could have released the RTX 4070 Ti in this AD103 configuration, with this level of performance, all along – if they really wanted to. It would have made the original $799 price tag a lot more palatable. Or maybe they were playing chess, and now that we’ve accepted this price level they’re bringing performance in line with expectations… I think I’m babbling at this point.  \n>  \n>Bottom line, the new GeForce RTX 4070 Ti SUPER isn’t just the first card in NVIDIA’s history to be both a **Ti** *and* a **SUPER** at the same time; it’s a solid performer with a significantly better price/performance ratio than its predecessor. We can’t argue with that. And once you factor in ray tracing performance, DLSS, and Frame Generation (if you’re into that sort of thing), at $799 this is a lot of GPU in the current market .\n\n# PC World\n\n>TBD\n\n# TechGage\n\n>TBD\n\n# [Techpowerup](https://www.techpowerup.com/review/asus-geforce-rtx-4070-ti-super-tuf/)\n\n>With these performance numbers RTX 4070 Ti Super is a perfect match for 1440p with maximum settings, it's actually slightly overkill, which means that the card is a decent option for 4K monitors, too, or for 1440p at 120/144 Hz. While you won't be able to game at 4K60 at highest settings, just dropping them down a bit should help get those 60 frames and there's always the various upscaling technologies, especially if you plan on enabling ray tracing. Just like the other GeForce 40 cards, RTX 4070 Ti Super has support for all of NVIDIA's DLSS technologies: NVIDIA DLSS 2 upscaling, DLSS 3 frame generation and DLSS 3.5 ray reconstruction. On top of that you can enable AMD FSR 2 and FSR 3 in games, because those technologies work on all GPUs from all vendors. Basically this means that you'll be covered in terms of upscaling and frame generation. While DLSS 3 is definitely the leading solution right now, with best game support, AMD is pushing hard and their frame generation solution will come to several major titles in 2024. From a technology perspective, DLSS 3 is superior, because it uses the optical flow hardware unit in Ada GPUs, and NVIDIA Reflex will help bring down the input latency.  \n>  \n>The biggest selling point of the RTX 4070 Ti Super vs the RTX 4070 Ti non-Super is the increased VRAM size of 16 GB. RTX 4070 Ti's 12 GB VRAM size has been a constant topic for debate on tech forums, so it makes a lot of sense that NVIDIA is giving us a 16 GB option now, and at pretty reasonable pricing, unlike RTX 4060 Ti 16 GB. Unlike more cores or higher clocks, more VRAM will not make all games run faster automatically. Across all the 100+ game tests, (25 raster + 10 RT) x 3 resolutions, we only identified two cases where 16 GB results in a meaningful improvement over 12 GB: The Last of Us 4K and Alan Wake 2 RT at 4K. No doubt, you will be able to find more such results with other titles, too, but the vast majority of games out there will not see any meaningful improvement from the 16 GB upgrade. I'm sure that this will change in the coming years, with more and more games increasing their VRAM requirements, but I don't think that a 12 GB card will suddenly turn out to be useless in 2024 and 2025. You also have to consider that as soon as you enable upscaling, the actual render resolution is reduced, which lowers the VRAM usage significantly. Still, given all the drama about 12 GB VRAM—people can finally put their money where their mouth is and grab the RTX 4070 Ti Super 16 GB.  \n>  \n>A secondary effect of the 16 GB VRAM capacity is that the bus width is increased from 192-bit to 256-bit (or +25%). This is required, because to achieve 16 GB, you need to install eight 2 GB memory chips, each having a 32-bit interface to the GPU. With just 12 GB and six chips a 192-bit interface is sufficient (6 x 32 =192). This 25% increase in bus width leads to an equivalent increase in memory bandwidth, which should help provide an additional performance boost. Looking at my data I'm not so convinced. While the card does have slightly better scaling than RTX 4070 Ti 12 GB, the RTX 4080 is still able to pull away at higher res. It seems that what matters more for performance scaling is the L2 cache size and not the VRAM bus width. Unfortunately NVIDIA did limit the 4070 Ti Super to 48 MB L2 cache, while the RTX 4080 gets the full 64 MB.  \n>  \n>As expected, ray tracing works very well on the GeForce RTX 4070 Ti Super, clearly offering a superior experience than what Radeon RX 7900 XT, and often even RX 7900 XTX, can achieve. On average, the RTX 4070 Ti Super offers 22% higher FPS with RT than RX 7900 XT, which is quite a bit. NVIDIA's new card also shows better RT performance numbers than RX 7900 XTX in most games—if you're betting on ray tracing, then definitely opt for the RTX 4070 Ti Super. That doesn't mean that RT is unusable on AMD, it's just running considerably slower, because their cards are lacking dedicated hardware units to accelerate RT operations.\n\n# [The FPS Review](https://www.thefpsreview.com/2024/01/23/asus-tuf-gaming-geforce-rtx-4070-ti-super-video-card-review/)\n\n>Overall, when it comes to rasterized gaming without Ray Tracing, the new GeForce RTX 4070 Ti SUPER is around 12% faster than the GeForce RTX 4070 Ti. This was the common number we experienced mostly, without Ray Tracing. When Ray Tracing was used, this percentage number crept up slightly. With Ray Tracing the GeForce RTX 4070 Ti SUPER was more like 15% faster, with some outliers like Alan Wake 2. There are of course games, where the percentages were lower, around 10% or 11%, maybe even some under, as you lower the resolution. The highest differences were at 4K or with Ray Tracing.  \n>  \n>Looking at performance compared to the Radeon RX 7900 XT is more mixed. The Radeon RX 7900 XT put up a competitive fight, and in many games was as fast as the GeForce RTX 4070 Ti SUPER or faster. When looking at raster performance, without Ray Tracing, the Radeon RX 7900 XT is compelling in its performance by comparison, and this was at 4K and 1440p. More often than not, there were standout games like Starfield, or Cyberpunk 2077, or Returnal or Dying Light 2 where the Radeon RX 7900 XT seemed to get the edge on the GeForce RTX 4070 Ti SUPER. Even in Alan Wake 2, performance was equal between the cards, delivering the same experience.  \n>  \n>The one sore spot for the Radeon RX 7900 XT is once again Ray Tracing. This is going to be game dependent, and also depend on the types of Ray Tracing effects used and how heavily implemented they are. The GeForce RTX 4070 Ti SUPER has a huge lead in Path Tracing performance, as is shown in Alan Wake 2 and Cyberpunk 2077. Overall, the GeForce RTX 4070 Ti SUPER is going to deliver much higher Ray Tracing performance in games. In some circumstances, you can use upscaling FSR on the Radeon RX 7900 XT to make it playable, but this brings up the image quality of FSR at 1440p.  \n>  \n>That is an advantage the GeForce RTX 4070 Ti SUPER has, DLSS, and RTX features. When the going gets tough on the GeForce RTX 4070 Ti SUPER with Ray Tracing you can also use upscaling on it with DLSS. Overall, DLSS has superior image quality to FSR at lower resolutions, like 1440p. You will more likely want to use DLSS on the GeForce RTX 4070 Ti SUPER than you would want to use FSR on the Radeon RX 7900 XT at 1440p if you also want to get good Ray Tracing image quality. The GeForce RTX 4070 Ti SUPER also has DLSS 3.5 Ray Reconstruction support, to improve Ray Tracing image quality. In games that support it, like Alan Wake 2 and Cyberpunk 2077, its Ray Tracing image quality is unmatched.\n\n# [Tomshardware](https://www.tomshardware.com/pc-components/gpus/nvidia-geforce-rtx-4070-ti-super-review)\n\n>This isn't a generously priced graphics card, in other words, and by raising the MSRP, Nvidia probably took a more sizeable cut from its AIB partners. Still, it's certainly better than paying the same $800 for the RTX 4070 Ti — which is probably why the base price on those cards has fallen to around $740, and we've seen sales push the price as low as $720, which is still arguably too high.  \n>  \n>Is the RTX 4070 Ti Super worth the asking price? That depends on what you want to do with it. Relative to AMD's RX 7900 XT, even at its current promotional pricing starting at $709, you can certainly make arguments in favor of Nvidia's GPU. It's more power efficient, is potentially better equipped for future games (if ray tracing adoption picks up), offers access to Nvidia's proprietary DLSS features, including frame generation, and you get superior AI performance.  \n>  \n>If all you care about is rasterization performance, AMD's 7900 XT comes out ahead and offers a better value. And there are hundreds of new rasterization-only games released every year. But if you value any of those other 'extras' — even if you only think you might want to try them — Nvidia has cards at every price point that are worth a look.  \n>  \n>Ultimately, the RTX 4070 Ti Super provides some worthwhile improvements over its non-Super predecessor. If you're in the market for a high-end Nvidia GPU and you haven't upgraded in a few years, it's a great card. Just don't be surprised when next-generation GPUs come out in a year or so that have even more new features, improved performance, and just maybe not a massive generational price increase. (We can dream about that last one, right?)\n\n# [Computerbase - German](https://www.computerbase.de/2024-01/nvidia-geforce-rtx-4070-ti-super-review-test/)\n\n# [HardwareLuxx - German](https://www.hardwareluxx.de/index.php/artikel/hardware/grafikkarten/62759-mehr-speicher-zum-gleichen-preis-die-geforce-rtx-4070-ti-super-im-test.html)\n\n# [PCGH - German](https://www.pcgameshardware.de/Geforce-RTX-4070-Ti-Super-Grafikkarte-280115/Tests/RTX-4070-Ti-Super-Leistungsprobleme-BIOS-Firmware-Updates-1438677/)\n\n# ----------------------------------------------\n\n# Video Review\n\n# [Daniel Owen](https://www.youtube.com/watch?v=lDpr84DK7xQ&pp=ygULZGFuaWVsIG93ZW4%3D)\n\n# Der8auer\n\n# Digital Foundry Video\n\n# [Gamers Nexus Video](https://www.youtube.com/watch?v=QruyaA0ZrLk)\n\n# Hardware Canucks\n\n# [Hardware Unboxed (Updated Review with TUF)](https://www.youtube.com/watch?v=98ogL7ijrik)\n\n# [JayzTwoCents](https://www.youtube.com/watch?v=8U_S8vrRs-Y)\n\n# [Kitguru Video](https://www.youtube.com/watch?v=WdmZLIWGYo8)\n\n# Linus Tech Tips\n\n# OC3D Video\n\n# Optimum Tech\n\n# [Paul's Hardware](https://www.youtube.com/watch?v=PRxxc-0VfnM)\n\n# Techtesters\n\n# Tech Yes City\n\n# The Tech Chap\n\n# [zWORMz Gaming](https://www.youtube.com/watch?v=mcBr6UDV5pE)\n\n\\-----------------\n\n# [\\[PSA\\] Certain MSI GeForce RTX 4070 Ti Super Ventus 3X VBIOS Causes Lower Performance Than Expected](https://www.reddit.com/r/nvidia/comments/19dq7le/psa_certain_msi_geforce_rtx_4070_ti_super_ventus/)",
    "comments": [
      "Mann i was pretty hyped for it, these reviews do kill the hype a bit",
      "So basically not the same performance as the 4080 that many people were saying it would be.",
      "It seems like if you're considering paying 800 for a 4070 ti super, you should just take the 200 increase for a 4080 super.",
      "Agreed, between the less than stellar reviews, the lack of an FE, and my mobo/ram lost in the mail I’m just going to wait another week and try and snag a 4080S",
      "They missed the cache is cut down from 64MB to 48MB, same as 4070S. They fooled people by using the 103 die and rumors assumed that means similar or close performance.  With the same cache perhaps closer, but not here in cheap-ville chipmaker USA.",
      "I'm on the lower end, was gna stretch my budget a bit for the 16gb RAM but this just makes me want to go back to the 4070",
      "The 4080 is now the top tier graphics card for gaming. 4090 will always be AI/machine learning and rich kid gaming. In short marketing to upsell to 4080S or down to 4070S.  Remember NVidia doesn’t want you to buy this card which is why no FE.  They have stockpiled enough rejected 4080 dies to do this, but can’t have it with 64MB and too close to original 4080.",
      "People were going crazy when the specs were right in front of us the whole time.\n\n4080 has +15% cores, +33% L2 cache, slightly higher memory bandwidth, higher TBP\n\nWhy would anyone expect the Ti Super to have the same performance as the 4080??",
      "Overhyped, wasn’t nearly as close to the 4080 as we thought.",
      "It's about 10% better than 4070S.  Honestly, if money is tight you're perfectly fine with the 4070S.",
      "Was this nvidia's plan all along lol",
      "Tbh, people are on a negative train cause they wanted the world.\n\n4070 Ti normal could do 4k@60 with RT no problem - let alone 1440p. Your fine. People want to be negative.\n\nThe reality is both the 4080S/4070 ti are not good values. 4080s might be a bit better but your throwing more money into a stop gap generation. I sold my 3090 3 weeks ago and got $720 when all is said and done. I know this gen is garbage but for $100+ i can get DLSS 3, get a 10% boost, and wait for whats next.\n\n&#x200B;\n\nPeople need to stop pretending like any of these cards are great. The 4080/4080 Super isnt great either. Its why last generation cards are still selling for a boat load.",
      "I have a 3080 ti and I *hate* how it sounds like a jet engine taking off and runs so hot I have to open my window in winter to keep my room from getting uncomfortably warm. Undervolting helped some but causes games like Alan Wake 2 to crash so I ended up just going back to stock settings.\n\nI'm seriously considering a 4070 ti super or 4080 super just to have lower power needs (and therefor hopefully lower temps / quieter fans).\n\nAm I crazy?",
      "Text wall incoming! I just want to thoroughly share my experience with my 3080 Ti and 40 series. \n\nI’m using a Gigabyte 3080 Ti Vision OC and it seems that the heat sink is just not big enough for the stock TPD across most 3080 Ti models, causing a the stock fan curve to be aggressive and loud. Running stock, I pull about 350W average and the fan speed likes to hover around 80% which is very audible especially with my mesh panel case and open back headphones. \n\nLast month I financed and later returned a 4080 from Best Buy and it was significantly cooler and quieter than the 3080 Ti. Full load it was barely tapping 240W and the fans sat around 50%, completely inaudible from my sitting position, all while smashing the fps in ways the 3080 Ti couldn’t. Alan Wake 2 1440p everything ultra with path tracing, over 60fps in most areas without upscaling while running cool and quiet. \n\nSo after THAT experience, I worked pretty hard to get my 3080 Ti to settle down on the heat and noise and wound up with what I consider I decent under volt. My silicon isn’t great so it wasn’t stable using a lot of the common 3080 Ti undervolt values I found in Reddit. But I’ve currently got it OC’d at +120 MHz on the curve, with voltage limited to 850 mV at 1785 MHz and a power limit of 84% + a custom fan curve, which has helped reduce heat and noise immensely. Fans sit around 60-65% with power between 240-280W and only a 2-3% fps loss. Use DLSS and that fps loss is negligible. \n\nOn top of all of that, I just tried out the DLSS + FG mod and it’s worked wonders in some demanding games. With the mod and undervolt, Jedi Survivor doesn’t dip below 120fps on Ultra no RT, DLSS quality + FG on. Exact same performance increase on Hogwarts Legacy. In cyberpunk Path tracing is too demanding without a 40 series card, even with the mod, but standard RT and ultra settings was a breeze. \n\nThat said, I’ve got a 4070 Super FE readying up at Best Buy since I can sell the 3080 Ti for close to the 4070S msrp and hopefully avoid having to mess with undervolting and modding while getting 5-10% better performance.",
      "Not at all with the cut down cache. It’s exactly where it should be. 48MB cache(same as 4070S) vs 64MB on 4080.  Using 103 die means nothing beyond 16GB layout.  It’s gimped more than usual cut down cards are.  Even Tom’s hardware is listing 64MB in their review because of this assumption incorrectly.",
      "meh",
      "Yeah. It seems like NV intentionally wanted to upsell people to the 4080S since the 4090 is so damn expensive.",
      "[https://cdn.mos.cms.futurecdn.net/vWJtUTXRbC4od53gZm7VtH-1200-80.png.webp](https://cdn.mos.cms.futurecdn.net/vWJtUTXRbC4od53gZm7VtH-1200-80.png.webp)\n\nNot even close tbh. VR is higher resolution. The median puts it at 20%.\n\n&#x200B;\n\nIts hard to say 2K gaming and VR are two entirely different things.",
      "Yeah, every Nvidia card is designed so that you want to buy the one above it.",
      "I know. But the number of comments I saw saying “this is gonna be a 4080 beater” was insane."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "rtx 4080",
      "4080"
    ],
    "title": "New NVIDIA Game Ready & Studio Drivers, New GeForce ‘Alan Wake 2’ RTX bundle, New NVIDIA DLSS Games, including the ‘Call of Duty Modern Warfare III’ beta",
    "selftext": " From GeForce PR:\n\nNVIDIA released a flurry of news this morning, including a new GeForce Game Ready Driver for the *Call of Duty: Modern Warfare III* PC Multiplayer Open Beta, *Forza Motorsport* & *Lords of the Fallen,* delivering the definitive day one experience in three new, highly-anticipated blockbusters. NVIDIA also released the October Studio Driver driver.\n\nNVIDIA is also kicking off a bundle for GeForce RTX 40 Series GPUs and laptops that includes a copy of the highly anticipated blockbuster *Alan Wake 2*. New DLSS games include *Lords of the Fallen, RoboCop: Rogue City* demo, *Highrise City* and the aforementioned *Call of Duty: Modern Warfare III* Multiplayer open beta.\n\n**Call of Duty: Modern Warfare III PC Multiplayer Open Beta Kicks-off October 12th With DLSS Super Resolution & Reflex**\n\n[Call of Duty: Modern Warfare III](https://www.nvidia.com/en-us/geforce/news/call-of-duty-modern-warfare-iii-beta-dlss-reflex) launches on November 10th, but PC gamers can participate in the multiplayer beta, enhanced with DLSS 2 Super Resolution and NVIDIA Reflex from October 12th. GeForce Gamers are Game Ready today, with the new Game Ready Driver.\n\nGamers who have pre-purchased Call of Duty: Modern Warfare III, you can begin playing October 12th, and from October 14th everyone can download and play until October 16th.\n\nIn first person shooter games, PC latency can be the difference between wins and losses, and GeForce gamers get the latency improving benefits of NVIDIA Reflex, starting in the beta. GeForce gamers will also get a DLSS 2 Super Resolution performance upgrade in the beta.\n\nWhen the PC campaign launches on November 2nd for pre-order customers, and in the full game launching November 10th, GeForce RTX 40 Series gamers can also activate DLSS 3 Frame Generation for even faster frame rates. Learn more in our [Call of Duty: Modern Warfare III tech article](https://www.nvidia.com/en-us/geforce/news/call-of-duty-modern-warfare-iii-beta-dlss-reflex).\n\nFor the definitive experience at each stage of the game’s release, download and install the aforementioned new Game Ready Driver.\n\n**Game Ready For Forza Motorsport and Lords of the Fallen**\n\nThis is also the driver to use for gamers playing Turn 10 Studios’ [*Forza Motorsport*](https://forza.net/motorsport), which launches October 10th.\n\nThis driver also supports HEXWORKS and CI Games’ [Lords of the Fallen](https://store.steampowered.com/app/1501750/Lords_of_the_Fallen/), which launches October 13th with day-one support for DLSS 3 Frame Generation and NVIDIA Reflex.\n\n**Buy GeForce RTX, Get Alan Wake 2**\n\nRemedy Entertainment’s highly-anticipated sequel, [*Alan Wake 2*](https://www.nvidia.com/en-us/geforce/campaigns/alan-wake-2-pc-game-bundle), is loaded with industry-leading technology, including Full Ray Tracing and NVIDIA DLSS 3.5 with Ray Reconstruction and NVIDIA Reflex.\n\nTo celebrate our technical partnership, NVIDIA is today introducing a new [*Alan Wake 2* GeForce RTX 40 Series Bundle](https://www.nvidia.com/en-us/geforce/campaigns/alan-wake-2-pc-game-bundle), available until November 13th. Buyers of eligible GeForce RTX 4070, 4070 Ti, 4080 and 4090 graphics cards and desktop PCs, or a laptop with a GeForce RTX 4090 Laptop GPU, RTX 4080 Laptop GPU, or RTX 4070 Laptop GPU from select retailers and etailers will receive a digital copy of the game,to play when released on October 27th.\n\nSolve the deadly mysteries of *Alan Wake 2* with RTX On - the definitive way to play.\n\n**New DLSS games this week include:**\n\n* [***Call of Duty: Modern Warfare III***](https://www.nvidia.com/en-us/geforce/news/call-of-duty-modern-warfare-iii-beta-dlss-reflex) PC Multiplayer open beta kicks off October 12th with DLSS 2 and NVIDIA Reflex. The game will support DLSS 3 at launch, November 10th. DLSS and Reflex will deliver the definitive experience in *Call of Duty: Modern Warfare III.*\n* [*Lords of the Fallen*](https://store.steampowered.com/app/1501750/Lords_of_the_Fallen/) launches October 13th with DLSS 3, [multiplying performance by an average of 2.9X at 4K max settings](https://www.nvidia.com/en-us/geforce/news/lords-of-the-fallen-dlss-3-october-13).\n* [*RoboCop: Rogue City*](https://store.steampowered.com/app/1681430/RoboCop_Rogue_City/) demo is available now with DLSS 3 and DLAA.\n* [*Highrise City*](https://store.steampowered.com/app/1489970/Highrise_City/) recently exited Early Access and is available now with DLSS 2.\n\n**October Studio Driver Available Oct. 10 @ 9AM (Pacific)**\n\nNVIDIA Studio technologies will be on display at [Adobe MAX](https://blogs.nvidia.com/blog/2023/10/10/adobe-max-firefly-creative-cloud-substance-3d) this year, kicking off with the keynote on Oct. 10, and running through Thursday, Oct. 12. This year, look for updates and new features for Adobe Firefly — running in the cloud on NVIDIA GPUs. Plus, creators can celebrate improved performance with the October Studio Driver.\n\n**About Game Ready Drivers**\n\nGeForce Game Ready Drivers deliver the best experience for your favorite games because they are finely tuned in collaboration with developers and extensively tested across thousands of desktop and laptop hardware configurations for maximum performance and reliability.\n\nNVIDIA’s Game Ready Driver program was created from the ground up as a method to provide the best gaming experience possible. This program creates a synergy with game developers, establishing a regular cadence of exchanging pre-release game builds and drivers. We work together on finding optimizations and resolving issues, and iterate builds accordingly to ensure both the game and the Game Ready Driver deliver the highest quality and performance at launch.\n\n**Related Links:**\n\nGame Ready Driver article on GeForce.com:\n\n[https://www.nvidia.com/en-us/geforce/news/call-of-duty-modern-wafare-3-pc-beta-game-ready-driver](https://www.nvidia.com/en-us/geforce/news/call-of-duty-modern-wafare-3-pc-beta-game-ready-driver)\n\n*Alan Wake 2* GeForce RTX 40 Series Bundle info on GeForce.com:\n\n[https://www.nvidia.com/en-us/geforce/campaigns/alan-wake-2-pc-game-bundle/](https://www.nvidia.com/en-us/geforce/campaigns/alan-wake-2-pc-game-bundle/)\n\n(video) *Alan Wake 2* 4K DLSS 3.5 trailer\n\n[https://www.youtube.com/watch?v=HwGbQwoMCxM](https://www.youtube.com/watch?v=HwGbQwoMCxM)\n\n*Call of Duty: Modern Warfare III* PC Multiplayer open beta:\n\n[https://www.nvidia.com/en-us/geforce/news/call-of-duty-modern-warfare-iii-beta-dlss-reflex](https://www.nvidia.com/en-us/geforce/news/call-of-duty-modern-warfare-iii-beta-dlss-reflex)\n\nNew DLSS games article on GeForce.com\n\n[https://www.nvidia.com/en-us/geforce/news/lords-of-the-fallen-dlss-3-october-13](https://www.nvidia.com/en-us/geforce/news/lords-of-the-fallen-dlss-3-october-13)\n\nGame Ready Drivers:\n\n[https://www.nvidia.com/en-us/geforce/game-ready-drivers/](https://www.nvidia.com/en-us/geforce/game-ready-drivers/) \n\nIn the NVIDIA Studio @ Adobe MAX, including October Studio Driver\n\n[https://blogs.nvidia.com/blog/2023/10/10/adobe-max-firefly-creative-cloud-substance-3d](https://blogs.nvidia.com/blog/2023/10/10/adobe-max-firefly-creative-cloud-substance-3d)",
    "comments": [
      "Massive performance increase in Forza Motorsport.\n\n8AM 537.42 3080 Ti 4k max settings no ray-tracing / no dlss in-game benchmark:\n\n**55 FPS**\n\n10AM 537.58 3080 Ti 4k max settings no ray-tracing / no dlss in-game benchmark:\n\n**75 FPS**",
      "This driver finally by default enables  *Message-Signaled Interrupts* which should allow for increased performance in general and less stutters in games.",
      "I really hope they get the \"muddy/oil-painty faces\" problem with ray reconstruction sorted till Alan Wake 2 releases.\n\nI love the tech, I truly do, but there's no way I'm playing a game with such beautiful character models with their faces blurred out.",
      "Forza had soooo many issues even with a 4090. DLSS option wouldn't even appear for me (kept showing FSR). No DLAA options. Hoping this driver fixes that (but not holding my breath).",
      "It's disappointing that there isn't game-ready support for Assassin's Creed Mirage. I hope NVIDIA knows that enabling ReBAR can boost performance for NVIDIA users in this game.\n\nBy the way. You can manually add the profile in the control panel and force-REBAR ON inside the NVIDIA Profile Inspector.\n\n&#x200B;\n\nEDIT: It seems the recent drivers have a game profile but NVIDIA did not care to mention.",
      "> anti upscaling \n\nBeing anti upscaling with a Nvidia gpu in UE4/5 games is just being dumb. ( if 1440p/4k screen, sometimes even at 1080p)\n\nNew versions of DLSS look better than UE's TAA.",
      "Ask Todd Howard not Nvidia lol.",
      "They haven't enabled rebar for Aveum and Hoghwarths.. so don't hold your breath, manual enabling is the way to go!",
      "Follow-up - DLSS is showing up now. Will check out if there are any performance improvements.",
      "[https://www.nvidia.com/en-us/geforce/campaigns/alan-wake-2-pc-game-bundle/terms-conditions/](https://www.nvidia.com/en-us/geforce/campaigns/alan-wake-2-pc-game-bundle/terms-conditions/)\n\n**Eligible Products**: Valid on select GeForce RTX 4090, GeForce RTX 4080, GeForce RTX 4070 Ti, GeForce RTX 4070 desktop or graphics card, or laptop with a GeForce RTX 4090 Laptop GPU, GeForce RTX 4080 Laptop GPU, GeForce RTX 4070 Laptop GPU.\n\n>**Start Date**: 10/10/23  \n>  \n>**End Date**: 11/13/23  \n>  \n>**Redemption Period End Date**: 12/13/23\n\nBlack Friday is 11/24, so no.",
      "Wow really? Finally??",
      "What CPU are you using?",
      "zero improvement on my 4090 between .42 and .58",
      "Hahaha you steam loyalists are so dumb. Why can’t you just enjoy the game? Guess you missed out on Alan Wake Remastered too ;)",
      "That’s on Bethesda, not NVIDIA. It’s on Beth’s to-do list though so only a matter of time.",
      "Maybe we get a newer version of ray reconstruction in alan wake 2 that we can simply drop into cyberpunk like the normal dlss files. Would be cool.",
      "It's published by Epic so that may never happen.",
      "Except that it does. FFS...\n\nhttps://preview.redd.it/f3ofrxjn7etb1.png?width=1612&format=png&auto=webp&s=a135f247ece4114c1528e2e8428995b1833dc1ef",
      "I wonder how they determine the start date. I just bought and installed a 4070 a week ago.",
      "Its all about trade offs right now. Yes the faces get weird at times (not always) in Cyberpunk 2077 but without ray reconstruction you get some weird ass shimmer at times using ray tracing and DLSS especially on palm trees and chrome. There is a lot of chrome in the game that gets noisy without ray reconstruction so I prefer ray reconstruction to the other modes currently."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "rtx 4080",
      "4080",
      "4080 super",
      "rtx 4080 super"
    ],
    "title": "[Gamers Nexus] Lame, But Cheaper: NVIDIA RTX 4080 Super Review, Benchmark Comparison, & Value Discussion",
    "selftext": "",
    "comments": [
      "1-3% faster than a 4080 for $200 less.",
      "Nvidia anchored that $1200 price for a little too long. These card will sell out  because of the perceived value, but they're still overpriced. I say that having bought a 4080 recently (used under $1k).",
      "Housing sells out all the time and most people would agree it is overpriced.",
      "As someone with an All-AMD build, it's hilarious to see the XTX selling at basically the same price when it loses to the 4080S in literally every category. The XTX needs to be $800, yesterday.",
      "4080S also didn't exist yesterday",
      "The price drop is welcome (I bought one) but they could have just dropped the price on the original 4080 and saved themselves and the board partners a lot of bother.\n\nMaybe it's good marketing and will sell more. I dunno.",
      "Looking at Techpowerup's bench of around 25 games, the 7900 XTX is faster at 1080, 1440p and 4k. The 4080S beats it in RT. They are currently trading blows, I'd say AMD will drop the price of the 7900 XTX.",
      "”Any product which sells out is, by definition, not overpriced.”\n\nFalse. Selling out is more to do with production size and available quantity. Nvidia could make a 4090Ti and sell it for 6K. It would still sell out if they made it in small quantities. \n\nRTX 4000 series hasnt in general been selling as well as Nvidia would like it to. They’re trying to anchor the prices higher, but especially in this market it’s simply untenable.",
      "It IS good marketing because everyone is talking about it but retailers sure aren't happy stuck with the overpriced 4080 cards nobody will buy now.",
      "I bought a 4080 for $1500 AUD ($990 USD) today, the cheapest 4080 Super is at its inflated Aussie MSRP of $1850 AUD ($1220 USD). \n\nHell 4070 Supers cost more than 4070 Tis here.",
      "People are economically illiterate.",
      "For what? The 7600 XT review is also marked with the thumbnail as \"Not worth it\". You're reading bias where there is none.",
      "They should've just dropped the price of the existing cards, but thats not how marketing works I guess :)",
      "This, for $1000 I don't want to see raster benchmarks. At a similar cost, AMD just cannot compete with the 4080S.\n\nHardware Unboxed 12 game average has the 4080S losing by 5FPS in pure raster. You won't notice a 5fps difference, but you will notice a massive difference in RT.",
      "It's not exactly \"trading blows\" when in RT performance it completely fumbles. Should drop 100 bucks minimum but even then I don't see many buying it, maybe 125 bucks so that it can compete with the 4070tiS, offering much better rasterization for the same price at the cost of RT.",
      "Pure rasterization, sure. But between the 4080 ray tracing and DLSS, and although the 7900 XTX is smaller it's way more power hungry, plus the CUDA cores for AI capability, the 7900 XTX is not competitive.",
      "5% more core count, 1% boost clock bump and 5% base clock bump. Even if performance increase was 1:1 (it never is), it was never meant to be that much faster. \n\nI'm not exactly sure what all these \"disappointed\" people were expecting? Maybe next time don't set expectations to some non realistic ones.\n\nIt's a $200 price cut, that's all it is.",
      "I dont disagree with the overpriced part but the RTX 5 series might be even more expensive",
      "The way I see it, when these cards launched in 2022, both AMD and Nvidia’s offerings were overpriced, but the 7900xtx was perceived to be good value only because of that $200 price gap between it and the 4080. In a vacuum, or compared to previous gen pricing of its own cards, even AMD is taking the piss out of consumers with that price tag.\n\nNow that the 4080 Super is out at the same price, people are seeing that $1000 is too much to ask for the 7900xtx, but it always has been. The 4080S price drop is also still too much. Steve says it himself in this video, the price went from “complete insanity to moderate insanity.”\n\nIdc which “team” you’re on, we’re all getting taken for a ride.",
      "They were clearly very careful about this card not stepping on the 4090's toes so it's basically the same thing again but cheaper."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "rtx 4080",
      "4080"
    ],
    "title": "NVIDIA GeForce RTX 4080/4070Ti/4070 SUPER GPUs rumored to require 320/285/220W power - VideoCardz.com",
    "selftext": "",
    "comments": [
      "That’s the same as the current 4080 / 4070 Ti / 4070 is it not?\n\nTo be honest, it’s hard to imagine there will be a 4070 Ti Super…\n\n4080 Super and 4070 Super make more sense to me",
      "No",
      "I will be interested to see if they still use the 4090 cooler on the 4080 ? I could see them cutting costs here.\n\nI have the 4080 and it runs very cool, and I reckon they might try and get away with a smaller cooler for it.",
      "Rumour wheel spins, but seriously, watch these literally be the same as the non-super with the addition of VRAM they needed from launch (12gb+). OFC with the value added markup to finish 2023 strong profitwise.\n\nMy 3070 has a TDP of 220w so this would be a nice swap + FG addition. This 8gb is seriously lean for me.",
      "Silly ? Bro you just a hater. You’re jealous cuz I got that sweet 4070.5 Ti Super Ti",
      "Have they ever done a “Ti Super”?",
      "Yeah the 4080 coolers are absolute overkill. the rumor was that these cards were designed with the Samsung process node in mind which would have seen a 4090 with 600W and a 4080 with 450W but did come to a late deal with TSMC and therefore a much more efficient process node but the cooler designs were already produced or something like that, so they used them regardless, so we end up with absolute overkill GPU coolers for 320W cards.",
      "My 3080 Ti already pulls 400W anyway, it's a double edged sword because I get cold easily so it's fantastic in the winter when my office ends up 10F warmer than the rest of the house. Not so much in the Summer when I have to game in nothing but my boxers",
      "> No\n\nI thought so. Sounds kinda silly tbh especially when you consider where it would be positioned in terms of vram and perf.",
      "I wouldn’t go so far as to say overkill…I get it but for SFF enjoyers these coolers are legit a dream come true.  Nothing feels better than seeing my gpu stay below 65 degrees in demanding games in my A4-h20.",
      "![gif](giphy|bjB3gtFvREqqr5NAHW|downsized)",
      "So the 4080 Super rumors that it's still based on AD103, the power limit is the same as the base model, and at most they can add 5% more cores since the 4080 uses nearly the full AD103. This is not adding up. First off, what's the point, and second, how is the power limit not going up at all if the core count is presumably going up?\n\nEither the recent leaks are wrong, or the 4080 Super isn't very Super at all.",
      "Can't wait till the ZTX 6090 Ti SUPER requires a backup generator to run",
      "I think these aren’t launching until 2024, post holiday return window, based on the speculation I’ve seen.",
      "If you need some additional heating you can always get FX 8350",
      "The 4070 Ti Super Turbo Max is what I’m waiting for them to drop",
      "No. If they ever release a 4090ti then *that* would be stronger but I doubt that’s coming considering how the 4090 is already in a league of its own.",
      "Efficient is almost doubled from 30 to 40 series, my 4090 give the same performance as my old 3080ti with half the watts and a full power is still\nway cooler",
      ">used to\n\nThey've literally only had 1 generation of \"Super\" cards (16x0 & 20x0 are both Turing)",
      "You get 1000 fps at 8k ultra path tracing in any game but the cable needs to be replaced every 10 minutes"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "rtx 4080",
      "4080",
      "4080 super",
      "rtx 4080 super"
    ],
    "title": "‘Diablo IV’ Gets a Ray Tracing Update, ‘Outpost: Infinity Siege’ Launches With DLSS 3 & New DLSS 2 Games Out Now",
    "selftext": "From GeForce PR:\n\nThis week,  *Diablo IV* gets an update [which adds ray-traced effects to Sanctuary](https://www.nvidia.com/en-us/geforce/news/diablo-iv-ray-tracing-update-out-now). Also, *Outpost: Infinity Siege* launches with DLSS 3 support\\*.\\* In addition, *Alone In The Dark* is available with DLSS 2 and *Lightyear Frontier* is available with DLSS 2 and DLAA. The news follows the release of *Horizon Forbidden West*™ *Complete Edition*, which boasted day-one support for NVIDIA DLSS 3, NVIDIA DLAA, and NVIDIA Reflex.\n\n**RTX Gaming News This Week:**\n\n* [*Outpost: Infinity Siege*](https://store.steampowered.com/app/1566690/Outpost_Infinity_Siege/) \\- launches today with DLSS 3 Frame Generation , DLSS Super Resolution and Reflex. At 4K, with every setting maxed out, DLSS 3 will multiply performance by an average of 3.3X in *Outpost: Infinity Siege*. With this massive frame rate boost, GeForce RTX 4090 users can hit 160 FPS, the GeForce RTX 4080 SUPER exceeds 120 FPS, the GeForce RTX 4070 Ti SUPER tops 110 FPS, and the GeForce RTX 4070 SUPER surpasses 100 FPS, giving GeForce RTX 40 Series gamers the definitive experience at the highest resolution, with everything cranked.\n* [*Diablo IV*](https://diablo4.blizzard.com/en-us/) \\- new update is available now [which adds ray-traced effects to Sanctuary](https://www.nvidia.com/en-us/geforce/news/diablo-iv-ray-tracing-update-out-now). The game is already accelerated with DLSS 3 Frame Generation and Reflex. The update adds ray traced reflection and shadows. With a GeForce RTX 40 Series GPU, you can multiply performance by up to 3X thanks to DLSS 3.\n* [*Horizon Forbidden West*™ *Complete Edition*](https://store.steampowered.com/app/2420110/Horizon_Forbidden_West_Complete_Edition/) \\- available now with DLSS 3 Frame Generation, DLSS 2 Super Resolution, DLAA and Reflex. At 4K, with every setting maxed out, GeForce RTX 40 Series gamers are able to double their *Horizon Forbidden West*™ *Complete Edition* frame rates by enabling DLSS 3 with just a few clicks. On the GeForce RTX 4090, performance tops 180 FPS; the GeForce RTX 4080 SUPER surpasses 144 FPS, the GeForce RTX 4070 Ti speeds past 120 FPS, the GeForce RTX 4070 SUPER exceeds 110 FPS, and the GeForce RTX 4070 runs at over 90 FPS.\n* [*Alone in the Dark*](https://store.steampowered.com/app/1310410/Alone_in_the_Dark/) \\- available now with DLSS 2 Super Resolution.\n* [*Lightyear Frontier*](https://store.steampowered.com/app/1677110/Lightyear_Frontier/) \\- available now with DLSS 2 Super Resolution and DLAA\n\nOver 500 games and applications feature RTX technologies, and barely a week goes by without new blockbuster games and incredible indie releases integrating [NVIDIA DLSS](https://www.nvidia.com/en-us/geforce/technologies/dlss/), [NVIDIA Reflex](https://www.nvidia.com/en-us/geforce/technologies/reflex/), and advanced [ray-traced effects](https://www.nvidia.com/en-us/geforce/rtx/) to deliver the definitive PC experience for GeForce RTX gamers.\n\n**Quotable:**\n\n\"The launch of *Diablo IV* was just the beginning for us. We are regularly iterating based on player feedback and exploring how we can enhance the visuals and dark atmosphere of the game. The addition of ray-traced effects is our next step in making the brutal world of Sanctuary feel more immersive than ever. Effects like lightning strikes are now reflected in pools of blood and water, dank cellars and dungeons are more foreboding with realistic soft shadows, and the open world and towns are more grounded with additional realistic shadows and reflections. We are very excited for our community to experience this new technology.\" - Michael Bukowski, *Diablo IV* Technical Director\n\n“It was great working closely with NVIDIA to bring raytracing to *Diablo IV*. The experience they have with ray tracing technologies was instrumental in helping us take our ray tracing implementation to production quality, and libraries they offer like [RTXMU](https://developer.nvidia.com/rtx/ray-tracing/rtxmu) gave us a valuable boost as we were developing.” - Kevin Todisco, *Diablo IV* Principal Software Engineer \n\n**Related Links:**\n\nDLSS weekly article on GeForce.com:\n\n[https://www.nvidia.com/en-us/geforce/news/dlss-3-outpost-infinity-siege-diablo-iv-ray-tracing](https://www.nvidia.com/en-us/geforce/news/dlss-3-outpost-infinity-siege-diablo-iv-ray-tracing)/\n\n*Dibalo IV* ray tracing update article on GeForce.com\n\n[https://www.nvidia.com/en-us/geforce/news/diablo-iv-ray-tracing-update-out-now](https://www.nvidia.com/en-us/geforce/news/diablo-iv-ray-tracing-update-out-now)/\n\n(video) *Diablo IV* | Official GeForce RTX Ray Tracing Reveal Video\n\n[https://www.youtube.com/watch?v=Eh80iWrP95w](https://www.youtube.com/watch?v=Eh80iWrP95w)\n\n(New video) *Horizon Forbidden West™ Complete Edition* DLSS trailer\n\n[https://youtu.be/iOdAa0ou4b8?feature=shared](https://youtu.be/iOdAa0ou4b8?feature=shared)",
    "comments": [
      "**Edit: They did update to 3.5.10 DLSS (in the latest PTR) so someone must have passed by this thread ;)**\n\n\n\nThey're still using an old DLSS [3.1.1.0](http://3.1.1.0) which makes the game blurry when moving. Any attempt to put an newer DLSS version will eventually get replaced by their launcher, a shame.\n\nIf a Nvidia rep comes by this thread or even blizz, please update the goddamn DLSS.",
      "Really glad I bought this game on Steam for that exact reason. I've been using version 3.5 of both the DLSS and DLSSG .dll files for months, without the game trying to replace them with the older version. I just upgraded to the recent 3.6 release of each today.\n\nRockstar's launcher does the same thing with RDR2 whereas the Steam version of the game does not. It's one of the reasons I pretty much buy games on Steam or not at all now.",
      "Trying it out now. It's definitely a bit noisy looking, at least when using DLSS Performance at 2160p. \n\nThe reflections are noticeable in the very few locations where they're present, otherwise aren't noticeable at all. Hopefully the DLC area has some great metallic surfaces for reflections, akin to many of the environments from Diablo III. \n\nThe shadows are definitely an improvement, foliage looks much more grounded in the scene now. By far, though, the new ambient occlusion is the biggest upgrade, despite not being RTAO. \n\nThe performance cost is substantial, though. Without Frame Generation this would be unplayable, IMO. And I'm using a 4090.",
      "- Download latest DLSS and DLSS Frame Generation files from [Techpowerup](https://www.techpowerup.com/download/drivers/)\n\n- Right click game in Steam, click Properties\n\n- Click Browse Local files\n\n- Drop in both the nvngx_dlss_3.6.0 and nvngx_dlssg_3.6.0 files right in Diablo IV's root directory\n\n- Overwrite\n\nThat's it!\n\nKeep in mind that people claim that you can get banned for modifying game files. I've swapped in newer DLSS files in Overwatch 2, Diablo IV, Call of Duty MW2, MW3, RDR2, and plenty of other multiplayer games and have never been banned, for what it's worth.",
      "Getting 70-80fps with dlss quality and frame gen on with all maxed out in 4k in a 4090  \nThis with a lot of mobs on screen  \nCities - 100+fps  \nBefore ray tracing it was 200+ with DLAA  \nLOL  \nRay tracing tanked like 130 fps",
      "Or just download DLSS Swapper",
      "Shockingly, they might be enjoying it.",
      "180fps at 4k with a 4090?   Huh?  I’m playing on a 3440x1440p monitor and I’m not even getting that with everything maxed.  This must be with DLSS on ultra performance mode or something… which… I would never do I guess. I want a high quality image. Especially for a single player game.",
      "Agree with all of this.    4080S/14900K here and the visual improvements to ground clutter/foliage are nice, the water looks great, and the effects around flames look good.  I don't know if it's \"worth\" the performance hit, with the Ray Trace Ultra settings, framerates and stuttering are annoying.   I'm going to have to back the quality down a notch to get the RT performance in line.",
      "I recommend waiting until half of May when Season 4 goes live\n\na whole bunch of changes are coming that will make the game a looot better, including changes to itemization",
      "What if I want more than 70 FPS?  \nWhat if I want to play at a higher resolution?  \nWhat if I want to reduce GPU load?  \nWhat if the TAA sucks and I want to use DLSS as an antialiasing (or better, DLAA) ?  \nEvery game needs DLSS as an option.",
      "lol\n\nyou dont need a loot filter with the new changes",
      "[https://www.youtube.com/watch?v=6mhFD7JClhM](https://www.youtube.com/watch?v=6mhFD7JClhM)\n\nD4 RT ON vs OFF. On most scenes it is beyond impossible to tell the difference besides your fps cut by **50%**. This is by far one of the most useless things to implement in a game like this, and they should have instead added or worked on RTGI.",
      "I think it allocates near the max available VRAM but it's not using  all that. 12G should be more than fine for Very High textures.",
      "why not?",
      "Much better than at launch and it's going to be basically a new game entirely next season.",
      "It doesn't modify your game install, though. Unlike when you actually purchase and install RDR2 through the Rockstar launcher.",
      "You guys could really stop making things up and watch the Season 4 Public Test Realm livestream instead. These changes are 100% amazing for the game, you lost your mind if you think INCREASING THE QUALITY OF LOOT IN THE GAME is a bad thing.\n\n>that's just to keep people grinding longer\n\nThat is literally the goal of a hack'n'slash / systems ARPG like Diablo, Torchlight, Path of Exile, Last Epoch, Grim Dawn, etc. - keeping you engaged. You mad about the game finally beginning to fulfill its genre's potential?",
      "Why? In D4 I'll never see it because the whole screen explodes every 2 seconds.",
      "> Get a better GPU than a 2060?  \n\nWhat if I don't have the money? If only there were an option to get more FPS without spending hundred of dollars...  \n(I have a 3080 by the way but I'm thinking about those who don't.)"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "rtx 4080",
      "4080",
      "4080 super",
      "rtx 4080 super"
    ],
    "title": "Vertical mount",
    "selftext": "Just finished mounting my RTX 4080 Super using a Coolermaster vertical mount kit, how did I do ? ",
    "comments": [
      "Needs more fans.",
      "Wow your case has only fans",
      "Subscribe to it for exclusive content",
      "Love the little plant touch.",
      "You can never have enough fans",
      "The more you have, the slower they can spin.\n\n![gif](giphy|d3mlE7uhX8KFgEmY)",
      "The bottom and rear fans are reversed blades , they are intake",
      "You mean hot content?",
      "You are correct",
      "What’s the board attachment to do that",
      "the montech fans are growing on me, didnt like them at first",
      "It's been a few months. Do you notice any \"sag\" or tilt from the cooler master mount? I have a similar brick of a card (Rx 7900xt TUF) and was thinking of going for a similar aesthetic as well.\n\nVery nice build btw.",
      "What case is that?",
      "Did a similar build with the Asus TUF gt502 case, hid the aio tubes behind the vertical mount.",
      "Thanks 🙏🏼",
      "It would make sense, but I’m mainly doing this for the looks and it only made a 3 degree difference under stress .",
      "Very easy , this case is great",
      "Thank you",
      "You realise you can tune the fans to be slower rpm right.\n\n  \nWouldn't be suprised if his pc with that many fans is more quiet than whatever pc you have.",
      "Yes some brands have reverse blades, so you can always have the nice side showing where you need it"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "rtx 4080",
      "4080",
      "4080 super",
      "rtx 4080 super"
    ],
    "title": "[Digital Foundry] Nvidia GeForce RTX 5080 Review vs RTX 5090/RTX 4090/RTX 4080 Super - Performance Worthy Of The Name?",
    "selftext": "",
    "comments": [
      "Everyone who was saying that the 5080 will outperform the 4090, where are you now? The weird part is that 5080 doesn't even pull ahead in RT.\n\nWhat a joke, lol.",
      "This is the same 5080 die in a \"5090\" laptop with 24GB VRAM and 175watts limit\n\nBut those laptops costs upwards of 4k \n\nNvidia has the capability to give 24GB VRAM to desktop 5080 but nope\n\nSeriously the disrespect to desktop gamers.......lmao!",
      "Too bad they won’t undo all their downvotes on me lol.",
      "As soon as I found out that the review embargo was going to be the day before release for this one, I knew I’d be a dud. \n\n4090 owner here and we’re still second in the stack over 2 years later (and for the next 2 years it seems). Lol",
      "This is what I find the most disappointing by far. I really wasn't expecting much from the 50 series. I would've bought a card that had a 10% improvement and 24GB of VRAM but 16GB again is an absolute joke. Sod off Nvidia",
      "This is a \"passer-by\" generation, it would seem. I know I intend to pass it by.",
      "It's not a new generation is really the simple way of looking at it. \n\nThis is just a refresh of the 40 series, same TSMC 4nm process.",
      "They need the 5090 to look much better...",
      "Or even 20GiB would suffice.\n\nI guess they want to sell us a 5080ti 24GiB for 1499$ in 10-12 months.",
      "What a shit card lol",
      "The 4090 embargo was also one day before release.  That doesn’t mean anything.  We knew the 5080 would be unimpressive when kopite7kimi released its specs, and arguably even earlier when we learned it would be on TSMC 4N, the same as the RTX 4000.  The 5080 has no node advantage, only a 4% core count advantage, and while GDDR7 afforded a significant increase in memory bandwidth, it’s still below that of the 4090.\n\nThe 5090 achieved a 30% raster improvement via a 33% increase in SM count and nearly 80% memory bandwidth increase.  It got a 512-bit memory bus and a massive 750 mm2 die (actually measured a bit larger).  It’s basically double the 5080 in all relevant metrics, including die size, SMs, memory bandwidth, and memory size. It shouldn’t be shocking the 5090 is 50-55% faster than a 5080, or that the 5080 is only 10-15% faster than a 4080S.",
      "Same 28nm process node didn't stop the 980 Ti being 30% faster than the 780 Ti at the same TDP.\n\nJust sayin'",
      "Nah. The 3080 to a 3090 was still an increase.\n\n10gb to 24gb of vram, and around 10-15%. Honestly that was fine, you should pay a premium for a halo tier card.\n\nThe best card available is worth a price hike beyond cost/performance so for that I can't get mad.\n\nWhen I get mad is that the 5080 can't even beat a 4090 and is basically just a 4080 super again so like wtf are we doing here?",
      "You're smoking crack if you think they are there for anything other than the 5090.",
      "offbeat numerous cows dime ad hoc tie follow fade straight decide\n\n *This post was mass deleted and anonymized with [Redact](https://redact.dev/home)*",
      "Everyday I get more and more relieved I got my 4080super on sale, what a disappointing generation this is",
      "Some people need to buy a GPU, and 40 series aren't produced anymore so...",
      "I’m still rocking a 2080 super FE, I’m going to try and get this card considering it’s been a disappointment to most but I think it will be a nice upgrade for me and easier to grab compared to the 5090 or 5070 cards. I think this card is targeting 20/30 series users that didn’t upgrade to 40 series. I would go for a 5090 but I have a 2020 Corsair 850 gold plus PSU so that won’t work :/",
      "While the 5080 isn’t as impressive over the previous gen, i think it’s enough to finally upgrade my 3080…",
      "It’ll still sell out and there’s people actually camping in front of Microcenters for one. That’s the timeline we live in 🫨"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "rtx 4080",
      "4080",
      "4080 super",
      "rtx 4080 super"
    ],
    "title": "4080 super build",
    "selftext": "I finally built a desktop after running a gaming laptop for the last few years. Tried to go with a sleek all black look with great airflow. \n\nSpecs:\n\nAmd 7800x3d\nTeamgroup T-create expert 32gb ddr5 cl30\nGigabyte RTX 4080 super windforce v2\nMSI B650 gaming plus WiFi\nArctic liquid freezer 3 240mm cooler \nCorsair rm850e power supply\nCorsair 4000d airflow case\nArctic p12 pst case fans\nMsi spatium ecopack 2tb m.2 nvme ssd\n\n",
    "comments": [
      "We calling people who don't use RGB sleeper builds now? Cause a sleeper build is normally when you have a 4090 class card is in an old Compaq case or something",
      "Nice now hand it over to me 🔫",
      "Very nice",
      "Good choice 5080 price gonna be astronomical",
      "Why is this downvoted? It’s a nice comment lol",
      "because reddit users are a toxic dumbass community so a nice comment is never appreciated, they only try hard to find bad things and never appreciate the good ones… ty man",
      "Clearly u didn’t understand, i called it a starter pc cause the op said it’s his first dekstop after using a laptop, and that’s why I said it’s very good, because it may be even considered overkill",
      "Nice Build! Enjoy!\n\nI upgraded to the RTX 4080 Super 16GB ..\n\nMSI RTX 4080 Super 16G SUPRIM X\n\nhttps://preview.redd.it/zt8nuxl013be1.jpeg?width=4590&format=pjpg&auto=webp&s=dd30dea0bed60efb8946c07f0f76f7de9edc232b\n\nCheers 🥂 🍻 🍸 🍹",
      "very cool, that’s surely a very good starter for desktops pc 🤣",
      "I was back and forth on waiting for the 5080 or just getting a 4080super and I have had zero regrets. I was the same way with waiting for a 9800x3d or just getting the 7800x3d and I also feel like I made the right decision.",
      "\"Starter PC?! This is a *finisher* PC!!\"   \n\n\n\n*- Dennis Reynolds, shouting all red in the face*",
      "OP said it was their first Desktop PC. They meant starter PC as in their first fucking desktop pc. He wasn't saying the PC was entry level or low spec.",
      "Looks super clean, enjoy the build",
      "I don't like RGB at all.  I just bought all my parts before xmas and putting it together this week.  9800x3d, 4080 super Artic 360 black freezer and the Antec Flux Pro case, and 1000 watt power supply.  Motherboard is the MSI Tomahawk 670e.  I got it at Microcenter for the bundle with the memory too.  It should be a good setup when I get it built.",
      "W case I just built with This case and i love it",
      "Looks great! Wish I could vertically mount my Suprim 4080",
      "Surprisingly I love the yellow",
      "I love the case. I would get it again for another build without a doubt.",
      "Just read reviews, it was popular on pc part picker for am5 builds at the time, and the price was right in comparison to the other options out there.",
      "Yes, originally it said sleeper build. :)"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "4080",
      "4080 super"
    ],
    "title": "Amazon just dropped 4080 super",
    "selftext": "https://www.trackalacker.com/products/showcase/nvidia-rtx-4080-super\n\nJust got an alert, made my order. ",
    "comments": [
      "For those with questions about the shipping dates, sometimes Amazon gives an incorrect date on popular to put off scalpers. It *might (probably)* arrive quicker.",
      "Ships from and sold by Amazon, so prob legit. If I’m disputing CC charges next week I’ll let you know 🤣",
      "If that worked, you are the man! Also I hate you for enabling my impulse purchase lol",
      "Think I just grabbed the Aorous one!  Says it is ordered but now the product page is missing 🤔",
      "Same thing happened last week with the gigabyte 4070 ti super.  It's shipped and sold by Amazon,  but delivery is several weeks out.",
      "So it is not a scam?",
      "Its sold by amazon and shipped by amazon\n\nwhat do you think\n\n&#x200B;\n\nif you want the product asap buy elsewhere\n\n&#x200B;\n\namazon doesn't touch your funds till they ship so nothing came out of your bank account.",
      "How high are you rn?",
      "Not a dud. You just had your expectations too high. With the specs, this was always the expectation. The main draw of the 4080s was always the price.",
      "No product page, seems fishy",
      "Haha! You're welcome!",
      "1-5% above 4080, but still 20% below 4090.",
      "Honestly, as time goes on I feel less and less good about keeping Asus in the a-tier list.",
      "i mean they havent even took any money out they dont touch your money until they ship",
      "no one cares about performance improvement but the price cut",
      "Scalper prison would be so annoying, can you imagine the commissary",
      "You gone order tomorrow and amazon will have the same shipping they always do this on products they may not have in there warehouse yet.",
      "It worked for me too! Got a regular gigabyte at Msrp! Thanks!!!",
      "It’s always like that.",
      "It is nowhere close to 4090. It's 5% faster than the 4080 vanilla, at best."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "rtx 4080",
      "4080",
      "4080 super",
      "rtx 4080 super"
    ],
    "title": "GeForce RTX 4070 Super Review Megathread",
    "selftext": "# GeForce RTX 4070 Super reviews are up.\n\n&#x200B;\n\n[GeForce RTX 4070 Super Founders Edition](https://preview.redd.it/mf1cn1ub2vcc1.png?width=3840&format=png&auto=webp&s=6091252019eaae1d26099fd8605de3945522f1d4)\n\n# Below is the compilation of all the reviews that have been posted so far. I will be updating this continuously throughout the day with the conclusion of each publications and any new review links. This will be sorted alphabetically.\n\n# Written Articles\n\n# [Babeltechreviews](https://babeltechreviews.com/4070superreview/)\n\n>The Nvidia RTX 4070 Super is a strong contender in the 1440p gaming market, offering substantial improvements over its predecessor and rival AMD cards at the same price point. While it excels in 1440p performance, it is also a viable option for 4K gaming with some settings adjustments.  \n>  \n>Owners of the 4070 should keep their cards and we only recommend 30 class series upgrades if you really want the latest and greatest and play games that can take advantage of DLSS 3. There is not such a large raw performance upgrade that we can 100% say every user should upgrade but the AI capabilities and 40-class series of upgrades from Nvidia could sway you to upgrade.\n\n# [CGDirector](https://www.cgdirector.com/nvidia-rtx-4070-super-review/)\n\n>The RTX 4070 SUPER graphics card is nearly an RTX 4070 Ti, without getting all the way there.  \n>  \n>For video editing and motion graphics/animation workloads, I’m reasonably confident that this card, at its MSRP, will be the best bang-for-buck option on shelves for this generation of GPUs.  \n>  \n>On the other hand, if you need a new GPU for your GPU rendering setup, I’d wait for **all** the new SUPER graphics cards to launch before pulling the trigger on this one. Keep your eyes peeled for more 2-slot solutions further up the 40-series line!  \n>  \n>A 2-slot RTX 4070 Ti SUPER that’s nearly an RTX 4080 would be a truly ‘SUPER’ GPU for rendering.  \n>  \n>If you’ve been holding out for a genuinely significant upgrade over something like an RTX 2070 or a 3070, the RTX 4070 SUPER is an excellent option. Not only does it finally beat the top-end card from NVIDIA’s last-gen RTX 30-series, but it does so at a somewhat reasonable price.  \n>  \n>That said, you should know that NVIDIA’s RTX 5000 series (or whatever they’ll call it) is slated to launch in a year. So, if you’re happy with the performance you’re getting right now, you could stick with it for another year. However, if your work demands faster hardware, especially for the workloads we covered above, now is as good a time as any for an upgrade.\n\n# [Dexterto](https://www.dexerto.com/tech/nvidia-rtx-4070-super-review-2476303/)\n\n>The RTX 4070 impressed us upon its release, by essentially being [a parallel to an RTX 3080](https://www.dexerto.com/tech/nvidia-rtx-4070-vs-3080-2109040/), with more VRAM and handy frame generation features. However, the GPU’s only foil was that the card didn’t match up to performance expectations when it came to generational uplift. If you cast your mind back to the RTX 30-series, the original 3070 matched up to the performance of a 2080 Ti. Now, the RTX 4070 Super looks to absolve Nvidia of this issue entirely, by offering up RTX 3090-level performance at an accessible price.  \n>  \n>While our only criticism of the VRAM capacity remains, the RTX 4070 Super is everything the original card should have been at launch. It’s easy to rake Nvidia over the coals when a GPU releases, and it’s not quite as good as everyone expects. But, you have to equally give Team Green some credit here. The 4070 Super simply trounces the current competition from the RX 7800 XT by offering faster performance all-round and DLSS 3’s frame-generation features, as well as better Ray Traced performance for a slight premium.  \n>  \n>I get a lot of questions about which GPU people should buy, and it’s always been quite difficult to answer. But, Nvidia has handed the answer to me on a silver platter. This is the go-to GPU for people looking for the ideal price-to-performance ratio on the market as it stands. You also get heaps of extra Nvidia [AI](https://www.dexerto.com/tech/nvidia-rtx-4070-vs-3080-2109040/) software features in Broadcast, Reflex, and more.  \n>  \n>No matter if you’re looking for a card that can manage adequate 4K, great 1440p, or blazing 1080p framerates, the RTX 4070 Super has it all. At this mid-to-high-end price point, this GPU is simply unbeatable. I just wished that it had come out earlier.\n\n# [Digital Foundry Article](https://www.eurogamer.net/digitalfoundry-2024-nvidia-geforce-rtx-4070-super-review)\n\n# Digital Foundry Video - TBD\n\n>There are many different ways of looking at the RTX 4070 Super's delivery of price vs performance. Especially with RT factored into the equation, you're looking at a decent performance boosts over the standard RTX 4070, which now looks excessively priced at its new $549 price-point. Meanwhile, in a world where the RTX 4070 Ti cost $799 at launch, you're usually getting 90 to 95 percent of its performance level with a substantial $200 price cut. That's not bad.  \n>  \n>However, three-and-a-half years from its launch, the $649 RTX 3080 continues to remind us that value just isn't the same as it was. Yes, the RTX 4070 Super is cheaper, more efficient and has more memory - but ultimately, the performance increase is variable. At worst, it's like a slightly faster RTX 3080. At best, it's up there with RTX 3090... and that's before we factor in DLSS 3 frame generation, which is a very useful feature.  \n>  \n>On a broader level, performance that's in line with RTX 3080 Ti or RTX 3090 isn't bad at all for the price-point - but AMD's Radeon RX 7800 XT continues to be an interesting competitor, if you can get it at its $499 MSRP. It lacks the hardware features that make Nvidia so compelling, while its RT performance is way behind. Even so, it continues to deliver the goods in terms of rasterisation and the 16GB complement of framebuffer memory remains a spec point where you can't help but feel Nvidia should be doing better.  \n>  \n>So, the first Super arrival increases value - and, like the 2019 20-Series refresh, comes across as the kind of pricing we should have had at launch. In terms of competition, AMD's Radeon RX 7800 XT continues to possess more memory, holds up well in rasterisation and obviously costs a lot less - to the point where cutting prices on the non-Super 4070 to match it would have been a good idea. However, in terms of features and overall performance, the 4070 Super is the one to have.\n\n# [eTeknix](https://www.eteknix.com/nvidia-rtx-4070-super-founders-edition-graphics-card-review/)\n\n>Would I replace my 4xxx series card with a SUPER? Not likely, it’s a small upgrade offering something like 10-20 FPS in a lot of games, but there are other improvements to the cooling and efficiency that are welcome too. However, if you want a more compelling reason to upgrade from the 3xxx or 2xxx series of cards, or exponentially more so even older cards, then this certainly tips the scale in the favour of consumers. The card is on average around 50% faster than the RTX 3070, and on par with the 3080 Ti, but with a significantly lower cost per frame.  \n>  \n>Between the AMD 7800 XT and the Nvidia RTX 4070 SUPER, it’s an extremely close race on average, with AMD coming in around $100 cheaper, that’s maybe a no-brainer for some, but I still think Nvidia lead the pack with their scaling, frame generation and ray tracing technologies, and for some, that’s worth paying the extra premium.\n\n# [Guru3D](https://www.guru3d.com/review/geforce-rtx-4070-super-founder-edition-review/)\n\n>The GeForce RTX 4070 SUPER (12GB) has been released at a retail price of $599, making it a more budget-friendly option for high-end gaming compared to the earlier RTX 4070 Ti, which was priced at $899. This graphics card is designed with features like ray tracing, DLSS3, and AI-powered assists, targeting gamers looking for optimal performance. It comes equipped with an increased count of 7168 shader cores (up from 5888), 12GB of 21Gbps GDDR6X memory on a 192-bit memory interface, and a maximum bandwidth of 504GB/s. Additionally, the RTX 4070 SUPER includes 56 RT cores, 224 Tensor cores, 224 TMUs, and 80 ROPs. It utilizes the same 35.8 billion transistor counting AD104 silicon as the RTX 4070 Ti, with 56 out of 60 streaming multiprocessors activated. This makes the RTX 4070 SUPER a compelling, more accessible option for those seeking high-end gaming performance. Boasting a powerful architecture, advanced ray tracing capabilities, and enhanced DLSS3 technology, the GeForce RTX 4070 SUPER showcases significant improvements in performance compared to it 4070 predecessor. Compared to the Radeon Series the RTX 4070's ray tracing performance has a bit more stamina, making notable advancements in this field. Additionally, with the DLSS3 + Frame generation technology, the GPU can create remarkable visual experiences in games that support it.  \n>  \n>The RTX 4070 SUPER is a graphics card that can create waves in the gaming world due to its rendering quality and gaming performance when combined with DLSS3 frame generation. The RTX 4070 provides a bit more value for the money. It is a well-balanced card that can handle gaming at WQHD and even 4K resolution, although it is targeted towards WQHD. Compared to AMD's offerings, the Nvidia GPU struggles to keep up with the Radeon RX 7900 XT, but has positive aspects like DLSS (3) and ray tracing features, which  work exceptionally well, AMD cannot match Nvidia in this regard. The RTX 4070 SUPER is an excellent option for gamers who play at UWHD, QHD, and even UHD monitor resolutions.  \n>  \n>The GeForce RTX 4070 Founder Edition graphics card stands out with its very nice performance and visual quality thanks to DLS3 and RT assistance. It is also characterized by enhanced power efficiency and lower thermal output, positioning it as an excellent energy-efficient choice. This card is suited for high-resolution gaming and demanding creative tasks, with its 12GB of VRAM being quite satisfactory for most applications. In the competitive landscape, particularly when comparing it to the Radeon RX 7900 XT specific capabilities such as ray tracing and DLSS3, areas is where the RTX 4070 SUPER shows notable strength. Conversely, the Radeon RX 7900 XT boasts a faster rasterizer engine and additional L3 cache, presenting it as a formidable alternative. However, with the RTX 4070 priced $150-200 lower, it may offer better value for some users. The RTX 4070 SUPER seems to align more closely in competition with the Radeon 6800/6900 XT/ 7800 XT rather than the 7900XT. Its performance can be likened to that of the RTX 3080series, varying according to the benchmarks used. Aesthetically, the Founder Edition models of the RTX 4070 SUPER are visually striking and add to its appeal with the new more dark design. The card is capable of handling Ultra HD gaming, particularly when utilizing features like DLSS3 and Frame Generation, and even supports mild overclocking. The GeForce RTX 4070 Founder Edition is a respectable option for those seeking performing and a visually appealing graphics card. Pricing remains a point of friction in the market\n\n# [Hot Hardware](https://hothardware.com/reviews/nvidia-geforce-rtx-4060-review-with-asus)\n\n>After months of rumors and leaks, and NVIDIA’s official announcement at CES a couple of weeks back, the GeForce RTX 4070 Super was somewhat of a known quantity heading into today’s launch. We are, however, impressed overall and think NVIDIA is going to shake things up with the introduction of its GeForce RTX 40-series “Super” GPUs.  \n>  \n>The GeForce RTX 4070 Super will be hitting store shelves shortly after you read this, with Founders Edition -- and similarly configured partner boards – commanding an MSRP of $599. That’s slightly higher than the GeForce RTX 4070’s introductory price, but nearly $200 below the [GeForce RTX 4070 Ti](https://amzn.to/48PQMx4). Radeon RX 7800 XT cards are currently for sale in the $520 - $580, and Radeon RX 7900 XT starts [around $780](https://amzn.to/48LUfge), with some models breaking the $900 mark. Looking back through the numbers, the GeForce RTX 4070 Super puts a hurting on the Radeon RX 7800 XT and often hangs with the [Radeon RX 7900 XT](https://hothardware.com/reviews/powercolor-hellhound-rx-7900-xtx-spectral-white-review), particularly when ray tracing is in the mix. At $599, the GeForce RTX 4070 Super is a very solid value in its price segment, and puts significant pressure on AMD. We suspect AMD and its partners will have to react somehow, especially in terms of Radeon RX 7900 XT pricing.  \n>  \n>While we tried to show an array of compute, rendering, encoding, graphics, and gaming workloads in our testing, NVIDIA offers a ton of additional functionality with the GeForce RTX 40 series that must be considered as well. From RTX Video Super Resolution, to AV1 encoding, to AI-accelerated tools for various content creation applications, NVIDIA Broadcast, and others, [GeForce RTX 40 series](https://hothardware.com/reviews/nvidia-geforce-rtx-40-architecture-overview) cards aren’t *just* for gaming. The combination of NVIDIA’s extensive software support, with the GeForce RTX 4070 Super’s relatively strong performance, and competitive pricing make it a compelling option in its product segment. If you’re looking for a GPU in this price range, the GeForce RTX 4070 Super should be at the top of your short list.\n\n# [Igor's Lab](https://www.igorslab.de/en/nvidia-geforce-rtx-4070-super-founders-edition-12-gb-in-test-half-a-performance-class-gain-makes-a-big-difference/)\n\n>The GeForce RTX 4070 Super with the AD104-350 is a highly interesting mid-range card that no longer has to fear a direct competitor from AMD in this super generation until Team Red brings a slimmed-down and attractively priced RX 7900 Non-XT to the German market or pumps the RX 7900 GRE into the normal channel and not just supplies system integrators. In terms of efficiency, NVIDIA is once again setting standards by which AMD must (but currently cannot) be measured. Whether and when the RX 7900 without XT or a GRE for everyone will come is still written in the stars. But gamers live in the here and now and there are simply no alternatives at the moment if you want the complete feature set including high-quality super sampling, frame generation and AI.  \n>  \n>Apart from the outdated Display Port connection and the still somewhat meagre 12 GB memory expansion for Ultra HD, I don’t see any disadvantages with the GeForce RTX 4070 Super that would speak against this card. The price is okay so far, if you put it in relation to the performance of the other cards. Because AMD isn’t really any cheaper. The manufacturers will hardly make any big profits with the MSRP cards, at least that much I can tell you. But they won’t starve either. Much of it is little more than a zero-sum game, where it only becomes somewhat profitable through the masses.\n\n# [KitGuru Article](https://www.kitguru.net/components/graphic-cards/dominic-moass/nvidia-rtx-4070-super-review/)\n\n# [Kitguru Video](https://www.youtube.com/watch?v=PgZpghANDso&pp=ygUHa2l0Z3VydQ%3D%3D)\n\n>In terms of its gaming performance, the 4070 Super slots between the RTX 4070 and the RTX 4070 Ti, though it comes in much closer to the latter than it does the former. At 1440p for instance, it's 15% faster on average than the vanilla 4070, but just 6% slower than the Ti variant. That performance bump is enough to make it faster than the RX 7800 XT, this time by an 8% margin, while it offers 13% more performance than the last-gen RTX 3080 10GB. 4K gaming isn't out of the question, especially if you enable DLSS, though the 4070 Super does fare better at 1440p due to its relatively narrow 192-bit memory interface, which isn't suited for higher resolutions.  \n>  \n>Ray tracing performance also scales similarly, at least when comparing the 4070 Super to the OG 4070 and the 4070 Ti. It is significantly faster than the RX 7800 XT over the eight games we tested with ray tracing enabled, to the tune of 47% on average, while it's in the same class as the [RX 7900 XTX](https://www.kitguru.net/components/graphic-cards/dominic-moass/amd-rx-7900-xtx-review/). We already knew Nvidia has the edge when it comes to ray tracing performance, and that is further confirmed by our testing today.  \n>  \n>Interestingly, despite performance increasing by about 15% over the original RTX 4070, power draw is only 9% higher on average with this new Super card, and that means it is a touch more efficient than the other xx70 SKUs. It can't quite match the RTX 4080 in terms of performance per Watt, that remains the most efficient Ada GPU we've tested so far, but it only widens the gap between the RX 7800 XT and its competition.  \n>  \n>What's clear is that if you are in the market for a new £600 GPU, things just got that bit better. Sure, the RTX 4070 Super may not be a revolution in graphics performance, but it's hard to quibble with an extra 15% performance and increased efficiency, all at the same price as the previous product.  \n>  \n>It's also fair to point out that the RX 7800 XT remains a viable option for those only interested in bang per buck, with the RDNA 3 GPU still offering the best cost per frame for rasterised 1440p gaming, and of course it does offer that extra 4GB VRAM. Many may now be swayed by the 4070 Super however, considering it is faster outright, significantly so when it comes to ray tracing performance, while also offering support for its superior DLSS upscaling technology alongside increased efficiency.  \n>  \n>Whatever your priorities, there's no doubt the **Nvidia RTX 4070 Super** is a step in the right direction. Let's hope this is a sign of things to come.\n\n# [LanOC](https://lanoc.org/review/video-cards/8948-nvidia-rtx-4070-super-founders-edition)\n\n>As far as performance goes, the new RTX 4070 SUPER takes a nice step forward ahead of the original RTX 4070 by increasing the core count. This translated to a 10% improvement at 1440p in our testing and 15% at 4k with 1080p and 1440p running into some CPU limited situations. With just a 20-watt increase in power usage, this also moved the Nvidia RTX 4070 SUPER Founders Edition up higher in our performance to wattage charts as well. Gaming performance was especially effective once I got into RTX and DLSS testing which with DLSS and DLSS combined with Frame Generation you can see huge performance improvements even in situations where your game is CPU limited. The Nvidia RTX 4070 SUPER Founders Edition even did well in raster performance compared with AMD’s current generation RX 7800 XT but I will talk about that here in a second when we get into pricing. The Founders Edition cooler still kept things running relatively cool even with a little higher TGP and the under load noise performance had the card running surprisingly quiet.  \n>  \n>So Nvidia has the Nvidia RTX 4070 SUPER Founders Edition starting at an MSRP of $599, this is the same price as the original RTX 4070 when it launched back in April of 2023. For an idea of where that puts it in the market, the RX 7800 XT from AMD can be found in the $500 to $580 range. The RTX 4070 is now $549, and the RTX 4070 Ti is in the $769 range. There are also a few RX 6800 XT options still available as well at $499. The RTX 4070 SUPER does outperform the RX 7800 XT and the RX 6800 XT, but you are going to pay more to get that performance. Adding ray tracing and DLSS performance into the mix helps add value as well which as long as the games that you plan on playing support it there is a lot of value to be had.\n\n# [OC3D Article](https://overclock3d.net/reviews/gpu_displays/nvidia-rtx-4070-super-fe-review/)\n\n# OC3D Video - TBD\n\n>However, the fact remains that the RTX 4070 is still a brilliant card. It’s still a fabulous gaming card in all but the most demanding 4K games. If you’re on anything from the 3000 range or earlier, or all but the flagship Radeon card, this will spank any game you offer up to it. Additionally the CUDA and Tensor cores leverage massive rendering potential in either 3D, video encoding or even AI generation tasks. It might leave a nasty taste in our mouth, but it’s still incredibly nourishing.  \n>  \n>Yes, if budgets are tight you should use the introduction of the Super and subsequent price drop of the vanilla card to get one of them. If you want performance the soon-to-be ended Ti card is still the best bet before you reach the RTX 4080. But the RTX 4070 Super FE is on the shelves, and reasonably priced with great performance, thus winning our OC3D Gamers Choice Award.\n\n# [PC Perspective](https://pcper.com/2024/01/nvidia-geforce-rtx-4070-super-founders-edition-review/)\n\n>While an improvement over the original – and generally more so than in this comparison with an overclocked RTX 4070 – the new GeForce RTX 4070 SUPER does not always reach the heights that a 20% CUDA core increase (7168 vs. 5888) might suggest. The card is powered by the same AD104 GPU, albeit a more enabled one, but is limited to the 192-bit memory system of the original RTX 4070. With 21 Gbps memory this means we have the same bandwidth, but the new card does have 48MB of L2 cache, up from 36MB with the original.  \n>  \n>I still have to wonder how much better this card could have performed with some faster memory (and a Boost clock bump), and if there is some actual overclocking headroom I’ll be happy to follow up with more testing. As it is, the GeForce RTX 4070 SUPER does represent a better value than the original at the same $599 USD price point, but the upcoming RTX 4070 Ti SUPER promises to be a far more interesting entry into the lineup.\n\n# PC World\n\n>TBD\n\n# TechGage\n\n>TBD\n\n# [Techpowerup](https://www.techpowerup.com/review/nvidia-geforce-rtx-4070-super-founders-edition/)\n\n>Averaged over the 25 games in our test suite, at 1440p, we find the RTX 4070 Super Founders Edition 15% faster than the RTX 4070 non-Super, which is a pretty substantial improvement for a refresh—unlike what Intel did with their 14th Gen Raptor Lake. This means that the card is able to match last generation's RTX 3090 flagship, and the gap to RTX 4070 Ti shrinks to just 8%. RTX 4070 Ti benefits from its higher power limit of 285 W, though. While AMD's Radeon RX 7800 XT was a bit faster than RTX 4070 in pure raster scenarios, this has changed with the RTX 4070 Super, which is now 7% faster—an important goal that NVIDIA achieved successfully. The gap to RTX 4080 is still pretty big with +30%, likely the reason why NVIDIA is launching the RTX 4070 Ti Super, and RTX 4080 Super, to cover strategically important points in that segment.  \n>  \n>With these performance numbers RTX 4070 Super is a perfect match for 1440p with maximum settings. You should be able to enable ray tracing in most titles, too. Thanks to modern upscalers, even 4K at solid framerates is in reach with the card. Just like the other GeForce 40 cards, RTX 4070 Super has support for all of NVIDIA's DLSS technologies: NVIDIA DLSS 2 upscaling, DLSS 3 frame generation and DLSS 3.5 ray reconstruction. On top of that you can enable AMD FSR 2 and FSR 3 in games, because those technologies work on all GPUs from all vendors. Basically this means that you'll be covered in terms of upscaling and frame generation. While DLSS 3 is definitely the leading solution right now, with best game support, AMD is pushing hard and their frame generation solution will come to several major titles in 2024. From a technology perspective, DLSS 3 is superior, because it uses the optical flow hardware unit in Ada GPUs, and NVIDIA Reflex will help bring down the input latency.  \n>  \n>Priced at $600 for the RTX 4070 Super Founders Edition, NVIDIA's new card sells at the same price point as the MSRP of RTX 4070 non-Super. The 4070 non-Super is getting an official $50 price-cut now, but it has been at around $550 months already, which means the price cut is just making things official. The cheapest RTX 4070 non-Super is currently $540, I suspect that in the coming weeks and months it will drop much closer to $500. It has to, because AMD's RX 7800 XT is $510, offering a strong alternative to both the RTX 4070 and RTX 4070S, especially when you don't care about ray tracing. Even when considering non-Super ($500) vs Super ($600) I feel that a lot of people will be tempted to go to for the 4070S, +$100 or +20% for a +15% performance increase isn't such a bad deal, especially in this segment. For AMD vs NVIDIA the situation is similar, DLSS 3 is the green team's biggest selling point, Super adds more performance on top of that, at \"close enough\" pricing, which aligns with NVIDIA's pricing strategy, betting that this is something many people desire. Still, the current GPU market as a whole is far from \"affordable\" or \"tempting,\" it seems that AMD is happy with the current situation in which they follow NVIDIA's pricing, undercutting them only slightly—no price war in sight. Given RTX 4070 Super's positioning and performance, and the lower price of RTX 4070 non-Super, I suspect that AMD will adjust their pricing for RX 7800 XT a bit. What could really make a difference if they gave RX 7900 XT a substantial price-cut, but that seems unlikely considering that they never tried to make the card sexy from a pricing perspective and rather opted for \"close enough to 7900 XTX,\" so that people will consider the upsell option. For RTX 4070 Super that means it owns that price point. There's no way people will buy a RX 6900 XT, RX 6950 XT or RTX 3090 instead of 4070 Super, unless they seriously go down in pricing. I guess some DLSS 3 naysayers could be tempted by a used sub-$500 RTX 3080 10 GB, but besides that, the only real competition is the RX 7800 XT and NVIDIA's own GeForce 40 cards.\n\n# [The FPS Review](https://www.thefpsreview.com/2024/01/16/nvidia-geforce-rtx-4070-super-founders-edition-video-card-review/)\n\n>With the launch of the GeForce RTX 40 series SUPER GPUs, you are going to hear a lot of: “This is what it should have been from the beginning.” While that can be said, it is more nuanced and layered than this. NVIDIA has addressed its segmentation and pricing and is now offering a better price-performance offering and overall creating a more desirable lineup for its GPUs. It is certainly a value increase at these price points.   \n>  \n>In our testing, the [GeForce RTX 4070 SUPER](https://www.nvidia.com/en-us/geforce/graphics-cards/40-series/rtx-4070-family/) is a bigger performance uplift from the GeForce RTX 4070 than rumors were suggesting. We are seeing it make a pretty significant difference in performance compared to the GeForce RTX 4070. The fact that NVIDIA is giving you 20% more performance, at the same price point is positive, and a good move, it creates a performance and pricing value increase in this price segment from the RTX 40 series lineup.  \n>  \n>Overall, the [GeForce RTX 4070 SUPER](https://www.nvidia.com/en-us/geforce/graphics-cards/40-series/rtx-4070-family/) is a better value than the GeForce RTX 4070 was at $599. There is a decent performance difference between the GeForce RTX 4070 and GeForce RTX 4070 SUPER to warrant the differences in pricing now and make it more appealing at $599. There are a lot of NVIDIA RTX features packed in here, which can make the price premium worth it, the features are compelling. There is stiff competition from the competition in this generation, so be sure to check pricing to get the best deals.\n\n# [Tomshardware](https://www.tomshardware.com/pc-components/gpus/nvidia-geforce-rtx-4070-super-review-boosted-clocks-and-core-counts-for-the-same-dollar599-as-the-vanilla-4070)\n\n>If you're in the market for a new graphics card that costs around $500–$600, give or take, the RTX 4070 Super now looks like the best option. It's not perfect, but it's a nice step up from the existing 4070, it's efficient, and it provides all of the usual Nvidia features. But we also said most of these things about the RTX 4070 when it first launched — and if you weren't enticed to upgrade then, the 4070 Super doesn't massively change the underlying prospects.  \n>  \n>Given the choice, we'd take the 4070 Super at $599 over the RX 7800 XT at $499, even though it doesn't have as much memory. And all indications are that AMD has no intention of launching anything new that will compete with the 4070 Super — the RX 7800 XT and 7900 XT have already launched, while the upcoming RX 7600 XT targets the RTX 4060.   \n>  \n>For the high-end gaming market, the 4070 Super is arguably the best option right now. Let's just hope the next generation sequel ends up with more VRAM.\n\n# [Computerbase - German](https://www.computerbase.de/2024-01/nvidia-geforce-rtx-4070-super-review-test/)\n\n# [HardwareLuxx - German](https://www.hardwareluxx.de/index.php/artikel/hardware/grafikkarten/62715-asus-gigabyte-inno3d-und-nvidia-die-geforce-rtx-4070-super-im-test.html)\n\n# [PCGH - German](https://www.pcgameshardware.de/Geforce-RTX-4070-Super-Grafikkarte-280116/Tests/Release-Preis-kaufen-Specs-vs-RTX-4070-vs-7800-XT-1437772/)\n\n# ----------------------------------------------\n\n# Video Review\n\n# [Daniel Owen](https://www.youtube.com/watch?v=OKRMqGXXjOg&pp=ygUKNDA3MCBTdXBlcg%3D%3D)\n\n# [Der8auer](https://www.youtube.com/watch?v=mbVbgD4PNOU)\n\n# Digital Foundry Video\n\n# [Gamers Nexus Video](https://www.youtube.com/watch?v=mL1l4jmxLa8)\n\n# [Hardware Canucks](https://www.youtube.com/watch?v=9GdmDvG_rQY)\n\n# [Hardware Unboxed](https://www.youtube.com/watch?v=HT8UmPrQYvk)\n\n# [JayzTwoCents](https://www.youtube.com/watch?v=F7mvkR8gsbM&pp=ygUMamF5enR3b2NlbnRz)\n\n# [Kitguru Video](https://www.youtube.com/watch?v=PgZpghANDso&pp=ygUHa2l0Z3VydQ%3D%3D)\n\n# Linus Tech Tips\n\n# OC3D Video\n\n# Optimum Tech\n\n# Paul's Hardware\n\n# Techtesters\n\n# [Tech Yes City](https://www.youtube.com/watch?v=O0uU3MpFArA&pp=ygUNdGVjaCB5ZXMgY2l0eQ%3D%3D)\n\n# The Tech Chap\n\n# [zWORMz Gaming](https://www.youtube.com/watch?v=y1gmOH0pdrk&pp=ygUKNDA3MCBTdXBlcg%3D%3D)",
    "comments": [
      "Going to be my first gpu upgrade in 5 years. Will replace my 1070ti so expecting >250% performance increase which is *very* exciting. Assuming I can get one at msrp anyways…\n\nEdit: Got the ASUS Dual at MSRP!",
      "maybe you could include Daniel Owen and zWORMz Gaming's reviews?",
      "he's probably gonna play League of Legends",
      "Tell you what, all those who upgrade from good gpus like 3070 or 3080 to these 4000 super gpus will cry with crocodile tears once 5000 gets released at the end of year.\n\nHow do I know? The same happened when 2070/2080 super launched and after a couple of months, the rtx 3000 rumors started to appear.\n\nIn conclusion, no, don't do this, 3070 is holding pretty strong at 1440p and the best upgrade would be a 5070 with 16gb vram and more than 100% performance increase over 3070. \n\nOh and let's not forget the new tech the 5000 series will bring, maybe dlss 4.0 or PTX or whatever they'll call it.\nAnd btw, I would rather play GTA 6 in 2026 on a rtx 5070 than on a 4070 super duper ti.",
      "Hey OP, I’m Brad from PCWorld. I came back from CES with the plague and have some emergency travel to do later this week. I have a 4070 Super but it’ll be a couple weeks before I manage to get a review up. Feel free to delete our stub section for now if you’d like.",
      "Ti Super definitely looks like it will be great, I just can’t stomach that much for a GPU. Even $600 is pushing it for me but I saved a bunch on my cpu upgrade so it’ll even out.",
      "4070 Super is basically what the regular 4070 was meant to be from the beginning.",
      "same",
      "3060 here and ready to swoop up a 4070 TI Super!",
      "In Nvidia page I can reserve the new founder (4070 super)? Or I have to be fast to buy it at 00:00?",
      "So I was gonna upgrade to 4070ti super but actually now quite interested in this, only really concerned about the VRAM ...",
      "Steve said it would be a good upgrade for 2070 owners. It often is 100% better performance than a regular 2070. That generally is where I start considering an upgrade as long as I will actually use the additional performance.",
      "Same! Looking at the 4070ti super tho just for longevity but the 4070 super looks great!",
      "Think you just convinced me to hold onto my 3070 dual",
      "Same boat but its deciding between a 4070TiS or 4080S.  Either way, my evga 1080ti sc2 is a fucking super soldier.  I will build it an alter and worship it when the day comes.",
      "Will add. Thanks",
      "Go for ti super. From what card do you plan to upgrade?",
      "His face is gonna melt. Not the gpu.",
      "Jesus no. 6900xt is a beast of a card still. For 500 would want a big increase in performance, the 4070S is comparable in pure performance outside of upscaling so you're not really going to notice anything. The 4090 or 7900xtx are the only two that you'd see a noticeable gain but no way is it worth the money unless you absolutely MUST game in 4k 60fps in every single game. If you're gaming at 1440p or a light 4K gamer you would likely not need to upgrade for a few years.",
      "No you shouldn't. Wait until 5000/RDNA4."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "rtx 4080",
      "4080",
      "4080 super",
      "rtx 4080 super"
    ],
    "title": "First ever build! Upgraded from an older laptop",
    "selftext": "First ever build! Upgraded from an older laptop\n\nPretty happy with how it turned out! Spent $2k flat on the build, which I think is pretty good. Upgraded from a laptop 1650 Max-Q so it’s quite the jump.\n\nCPU: AMD Ryzen 7 9800X3D\n\nCPU Cooler: Arctic Liquid Freezer III 360 A-RGB\n\nMotherboard: MSI MAG X670E TOMAHAWK WIFI\n\nMemory: G.Skill Flare X5 64GB DDR5-6000 CL30\n\nStorage: Samsung 990 Pro 4TB\n\nGPU: NVIDIA RTX 4080 SUPER Founder’s Edition\n\nCase: Antec C5 ARGB\n\nPSU: Corsair RM850x (2024) 850W",
    "comments": [
      "Congrats huge upgrade, but important question are those fans in Reverse blade motion? cause your airflow direction is not optimal in your case it should be like this : \n\nBottom : Intake   \nTop Radiator : Exhaust  \nSides : Intake  \nRear : Exhaust",
      "Thank you! And yep, that’s the exact configuration. The case came with reverse blade fans for the bottom and side, which is pretty cool",
      "Nice. Very nice.🎖️",
      "Looks cool. Im also a fellow 1650 maxq(Msi)user, building my first PC.",
      "The case came with 7 fans - bottom 3 and front 3 are reverse blade, pretty neat",
      "And 21 hours later, you can get a videocard x2 faster for the same price.",
      "How much was the gpu?",
      "How did you get all that dor 2k flat?",
      "I have the same case and aio. Does yours sound like a jet engine about to take off?",
      "I went from a 2070 Super laptop to a 4080 Super. That was big, couldn't image 1650 Mobile, would be huge",
      "Such a cool build! Where does the power supply go?",
      "very interested in your rgb setup. details?",
      "I live near a few Microcenters so I was able to snag one of their 9800X3D bundles before they increased the price and eventually swapped in the CL36 RAM. I also had a decent amount of credit from the past which saved me some money on the GPU. Also caught a pretty hot sale for the SSD on the Samsung site and was able to get it for around $195.",
      "I’m using a custom fan curve in fan control so it’s pretty quiet overall. Before I installed it though I think the case fans were preset to near max so that was definitely pretty loud.",
      "Thank you!! It’s a dual chamber case so the PSU sits behind the motherboard which is quite convenient\n\nhttps://preview.redd.it/sw04qsff2gbe1.jpeg?width=4032&format=pjpg&auto=webp&s=bc0e99284e79c066c72f96311484ff7f0651f642",
      "Nah I’m good. It more than meets all my needs and for $2k it’s solid value without dealing with all the new gen waiting and hassle.",
      "Eh, I’d rather not play the waiting game. It won’t be the first or even the second to launch, and the 4080S satisfies all my needs for the foreseeable future.",
      "Nice enjoy your new system!",
      "What are your temps looking like? For me both CPU and GPU max out at around 65C under full load.",
      "Nice! Did you buy it a long time ago and just get around to using it? The founders edition cards have been sold out for a while now"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "4080"
    ],
    "title": "4080 Founders on Stock",
    "selftext": "4080 Founders is currently on stock at nvidia germanys shop",
    "comments": [
      "Buying an 4080 at MSRP two (?) weeks before the release of the new generation seems kind of stupid..",
      "I dunno... as a european im not very optimistic about this launch at this point... but we will see.",
      "One last scam before 5080 releases in 3 weeks.",
      "Its absolutely dumb as bricks behaviour to buy a 4080 right now",
      "Absolutely idiotic purchase",
      "If you're a \"fan\" of these companies, you're pretty stupid.",
      "Yea ... no.\n\nNot putting more than 700€, since it would be match a 5070 ti minus DLSS 4 and efficiency improvement.",
      "in 3 weeks for the same price the 5080 with better performance and new technology",
      "If you manage to get one to begin with.",
      "Eh there's no guarantee the 4080 will be cheaper unfortunately. Especially if the new GPUs get scalped to all hell, plus the fact that they stopped manufacturing 40 series GPUs... Yeah I'm not sure.",
      "Terrible buy at this price, with the new GPUs just around the corner.",
      "How expensive could the new one be? 50? 100€? It's stupid to buy 40xx right now at msrp.",
      "Nvidia fanbase in a nutshell.",
      "I don't get why people keep replying with this illogical statement. \n\n\nNo ONE knows what the price would be but we have a rough idea based on past pricing. In any case, the best bet would be to wait and see. You'd be gambling $400 effectively by buying now.",
      "Have fun with your new gpu then. That's your money and your preference. I'm also in Europe and I don't find msrp for 40xx series any interesting at this point.",
      "- rtx40 supply will continue to reduce\n- buying new rtx40 at msrp during rtx50 launch is going to be a gamble\n- if you want to buy a \"new\" rtx40 during rtx50 launch, a 20% mark up over msrp is a good target if you are willing to buy on ebay.\n- we know this because the rtx30s were selling on marketplaces at 50% over msrp and the rtx40s at ~20% over.\n- during launch period the older gen rtx (rtx20 and rtx30 respectively) were also marked up on marketplaces, and new stock at hardware resellers were difficult to find.\n- given this estimation i think rtx40 at msrp today is still a decent buy.\n- even buying an rtx50 at launch day for msrp is going to be a significant challenge.\n- if you do not want to pay over msrp, you can wait 6 months for supply to stabilize. by then, rtx50s will be more available and rtx40s much less and you can consider the value of the new generation then.",
      "It isn't dumb.\n\nThese are the same idiots who will tell people 6 months later when most people will be able to get their hands on a 5000 series GPU that they should wait for the \"Super\" that's \"just around the corner\".\n\nFor some reason on Reddit everyone forgets that not everyone has a Microcenter right where they live or they may not even live in the US.\n\nIn Eastern Europe we get very limited supply of hardwares, for example the 9800X3D has been out since 2nd week of November and I've only seen it in stock ONCE over more than a month and even then, it was at 1.5x price of MSRP. Retailers are saying the next stock will be here by early February and even then, it will be instantly out of stock anyway. Second hand marketplaces have 9800X3D at 2x MSRP prices due to scalpers. Same shit will happen to 5080 and 5090, I'd bet my left nut on this. An average person will get their hands on a 9800X3D by probably April at the earliest date and I'd guess for 5080-5090 it will be like May or whatever.",
      "This sub is as insufferable as the company sometimes lol",
      "But really why though? How much more price to performance could the 5070 ti have over the 4080 super to make it dumb for not waiting for it? 10%, no way, im fine with having \"wasted\" 150 bucks. Whats more interesting is if they come with some exclusive feature.",
      "Is the 5080 confirmed to be the same price?"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "rtx 4080",
      "4080"
    ],
    "title": "‘Alan Wake 2’, Launches October 27th With Full Ray Tracing & DLSS 3.5 - More",
    "selftext": " From GeForce PR:\n\nThe highly-anticipated *Alan Wake 2* launches this week, and looks stunning with breathtaking, fully ray-traced graphics which are accelerated and enhanced by NVIDIA DLSS 3.5’s complete suite of AI-powered technologies.\n\nGeForce RTX 40 Series gamers will receive the definitive day-one experience: frame rates are multiplied by an average of 4.5X at 4K, ray tracing is even more immersive thanks to NVIDIA DLSS Ray Reconstruction, and NVIDIA Reflex makes gameplay even more responsive.\n\nAdditionally, *Ikonei Island: An Earthlock Adventure*, and *Shadows of Doubt*, two highly rated indie games, also receive DLSS performance upgrades today.\n\n**The Return of** ***Alan Wake*****!**\n\nRemedy Entertainment’s eagerly awaited [*Alan Wake 2*](https://store.epicgames.com/en-US/p/alan-wake-2), published by Epic Games, arrives October 27th with jaw-dropping fully ray-traced graphics, enhanced and accelerated by DLSS 3.5 with Ray Reconstruction. Players will explore two beautiful yet terrifying worlds, boasting the most advanced visuals seen to date in gaming, searching for the source of a supernatural darkness that has trapped Alan in an endless nightmare.\n\n*Alan Wake 2*’s fully ray-traced, path-traced visuals take the game’s ray-traced lighting, reflections and shadows to the next level, unifying them in a single solution that produces incredible results, as seen in this new, [exclusive *Alan Wake 2* RTX launch video](https://www.youtube.com/watch?v=tiUiCzzVu8g).\n\n***Alan Wake 2*** **Gets Up to 4.5X Faster with a DLSS Performance Upgrade** \n\nActivating ray tracing and DLSS in *Alan Wake 2* on a GeForce RTX GPU automatically enables Ray Reconstruction, replacing two denoisers with a unified AI model that enhances the quality of ray tracing, making gameplay more immersive, and graphics more realistic. In addition, Ray Reconstruction runs up to 14% faster in our benchmarks, further accelerating performance for GeForce RTX gamers.\n\nThe combination of NVIDIA technology gives NVIDIA GeForce RTX Gamers the ultimate *Alan Wake 2 experience*, with beautiful graphics and a remarkable performance uplift. Here are a few examples:\n\n* At 4K, with every setting maxed and full ray tracing enabled, activating Frame Generation, Ray Reconstruction and Super Resolution sees frame rates multiply astronomically. On the GeForce RTX 4090, performance multiplies by 4.1X, enabling owners to play Alan Wake 2 at its very best at over 120 FPS at 4K! The GeForce RTX 4080 sees its performance multiplied by 4.7X, and the GeForce RTX 4070 Ti multiplies performance by 4.7X, for max setting 4K gameplay at nearly 80 FPS\n* At 1440p, GeForce RTX 40 Series frame rates multiply by an average of 3X with full ray tracing and every other setting maxed out, enabling 80 FPS+ gameplay on the GeForce RTX 4070 and above\n* At 1080p, the most popular gaming resolution, performance multiplies by 2.7X on average, enabling owners of faster cards to play at up to 190 FPS\n\n**The Fully Ray Traced World of** ***Alan Wake 2***\n\nFull ray tracing, also known as path tracing, accurately simulates light throughout an entire scene. It is used by visual effects artists to create film and TV graphics that are indistinguishable from reality, but until the arrival of GeForce RTX GPUs with RT Cores, and the AI-powered acceleration of NVIDIA DLSS 3.5, real-time video game full ray tracing was impossible.\n\nIn *Alan Wake 2*, RT High and RT Medium settings use path tracing. For full details, the following table shows which settings utilize path tracing, and what ray-traced features are available when enabling each preset.\n\n&#x200B;\n\nhttps://preview.redd.it/gpw36df2l5wb1.png?width=917&format=png&auto=webp&s=fd7cf0233c778fbea67979704c4f4f0a3083ec34\n\n***Alan Wake 2*** **Game Ready Drivers, Bundle and Cloud Gameplay**\n\nLook for the NVIDIA Game Ready Driver for *Alan Wake 2* on October 26th.\n\nBuyers of eligible GeForce RTX 4070, 4070 Ti, 4080 and 4090 graphics cards and desktop PCs, or a laptop with a GeForce RTX 4090 Laptop GPU, RTX 4080 Laptop GPU, or RTX 4070 Laptop GPU from select retailers and etailers will receive a digital copy of the game, to play when released on October 27th. To see the complete list of participating partners in your country, head to the [*Alan Wake 2* bundle homepage](https://www.nvidia.com/en-us/geforce/campaigns/alan-wake-2-pc-game-bundle).\n\nPlay *Alan Wake 2* in the Cloud on [GeForce NOW](https://www.nvidia.com/en-us/geforce-now/).\n\n**More DLSS games!**\n\nOther new DLSS games this week include:\n\n* [*Ikonei Island: An Earthlock Adventure*](https://store.steampowered.com/app/1550730/Ikonei_Island_An_Earthlock_Adventure/) *-* Updates today with a DLSS 2 Performance Upgrade\n* [*Shadows of Doubt*](https://store.steampowered.com/app/986130/Shadows_of_Doubt/) \\- Updates today with a DLSS 2 Performance Upgrade\n\n**Quotable:**\n\n*“The new Ray Reconstruction feature in DLSS 3.5 renders our fully ray-traced world more beautifully than ever before, bringing you deeper into the story of Alan Wake 2”*\n\n \\- Tatu Aalto, Lead Graphics Programmer Remedy Entertainment\n\n**Related Links:**\n\nDLSS Weekly article on GeForce.com:\n\n[https://www.nvidia.com/en-us/geforce/news/alan-wake-2-dlss-3-5-full-ray-tracing-out-this-week](https://www.nvidia.com/en-us/geforce/news/alan-wake-2-dlss-3-5-full-ray-tracing-out-this-week)\n\n(video) Exclusive *Alan Wake 2* RTX launch video:\n\n[https://www.youtube.com/watch?v=tiUiCzzVu8g](https://www.youtube.com/watch?v=tiUiCzzVu8g)\n\n(video) Ray Reconstruction Explained, with Bryan Catanzaro, NVIDIA Vice President of Applied Deep Learning Research:\n\n[https://www.youtube.com/watch?v=sGKCrcNsVzo](https://www.youtube.com/watch?v=sGKCrcNsVzo) ",
    "comments": [
      "Their slide shows 4070 doing path tracing at more than 90+ FPS at 1440p DLSS Quality+FG+RR. Honestly, this is better than path traced Cyberpunk.",
      "Yep, looks like it performs a bit better. And this is at \"max settings\", which is 3 bounces (compared to 2 in Cyberpunk). I like how the \"Medium\" setting gives the option for 1 bounce, which is what the Cyberpunk performance mod did.",
      "this game is published and funded by Epic so I doubt it will go anywhere beyond EGS.",
      "Yeah and low is just normal ray tracing. I feel Remedy has overblown the system requirements.",
      "Based on the numbers the full path tracing is about 50% faster than Cyberpunk's Overdrive mode.\n\nA 4090 at 4k Dlss quality should be able to get 60 fps as its ats 63 fps at 1440p\n\nRR increases by 14% as well.\n\nYou could be looking about 4k 70 ish fps with Dlss Q + RR\n\nAnd then FG over 100 fps.\n\nA 4080 at Dlss balanced+RR should be able to get 60 as well.",
      "Cyberpunk is open world",
      "Man just... shut up. You native res purists are insufferable.",
      "133fps average on a 4080 at 1440p with DLSS Quality, guess I’m good.",
      "you are actually, there are still 3,686,400 unique pixels, some of them are just AI generated, and modern AI is quite good at that.",
      "Ok fine. 960p then. I hope it helps you sleep at night.",
      "It’s 50 dollars on epic cause they funded it and it’s owned by them. The game on regular consoles is 60",
      "People have been doing it for years.",
      "I don't think they are forcing anything, RR can clearly be disabled",
      "It's a weird hill to die on, for sure.  But it's Reddit-cool to hate Epic that much.",
      "I can't see myself missing a nicer store page, discussion forum, or how my library is sorted after this single player game is running.  Steam is full of stuff I appreciate like this, but choosing to not play a game at all because of these things seems counter productive.",
      "I am aware but AW2's system requirements are higher than Cyberpunk. That is why I was concerned at first.",
      "You can buy games, you can launch them. What else is really needed?",
      "Honestly a lame take",
      "Do you understand the underlying mathematical differences between traditional \"real\" pixels and AI-generated \"fake\" pixels? Could you actually map it out, mathematically, if you were asked to? \n\nI'm assuming the answer is no, as you likely need a doctorate in math to actually understand it. That's not a personal attack, I don't understand it either. \n\nBut the point is that for 99.9999% of people on this forum, everything that a GPU does to ultimately put pixels on a screen is effectively magic. \n\nSo what's the effective difference? \n\nThe traditional \"real\" pixels which result from math/physics you don't understand? \n\nVs\n\nThe AI-generated \"fake\" pixels which result from different math/physics that you also don't understand? \n\nIf you were just watching a game on a screen, would you have any way of knowing which pixels were \"real\" and which were \"fake\" without Nvidia actually telling you or making that information somehow transparent to the public? \n\nSo back to the original point, what's \"real\" 1440p vs \"fake\" 1440p when it's all just magic anyway?",
      "It’s supposed to be Remedy’s longest game yet. At or over 20hrs"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "4080",
      "4080 super"
    ],
    "title": "Farewell to my 1060. It's time to move on. (4080 Super)",
    "selftext": "(I was ready to buy a new case but I got lucky)",
    "comments": [
      "This guy upgrades",
      "Nice one! I installed mine today as well. From 1070 to 4080 super. I also went with an Msi. Do you think the sag support will help or should I buy a new one",
      "It’s still usable for stuff like movies, or just as storage for large files you don’t need that often",
      "I even forgot what good graphics + good FPS were, it's so good now.",
      "What cable did you use for power and what type of psu do you have if you don’t mind me asking. I’m new to pc and my 4080 is coming this Monday but I have no effin clue about cables for power, all I know is that the cable that comes included isn’t very good when there isn’t much space and there’s pressure on it which is most likely going to be my case. I was trying to buy a cable but I got all confused because some say only use with certain brands of psu",
      "Wow, that is a tight fit, but congrats and enjoy the huge upgrade!\n\nMaybe in the future you could consider putting your CPU radiator up top as exhaust and add two new fans at the front for intake. Right now, a lot of your airflow for the graphics card is immediately blocked by the side of it.",
      "tremendous upgrade",
      "Yeah, unfortunately i can't put my radiator up top because there's not enough space, it hits the motherboard",
      "Imagine a Fox getting kicked.",
      "i stuff movies with hdd & games with ssd",
      "I actually don't know it should be all red or white, red, white, red but sometimes it does this",
      "Most of the time my 4080 gaming x slim sits at 60C at 30% fan speed. Max I've seen it go is 65C. My unit, however has audible coil whine above 100W at any fps",
      "So happy for you. I've still got a 970 and just haven't been able to get a 4080 super due to no stock. Sorely due for an upgrade lol. Good job!",
      "This could be the deffinition to \"perfect fit\".",
      "Awesome build , I'm moving on from my 2080 super to a 4080 super , in the process of installing mother board , still waiting for the GPU to come in the mail",
      "Meshify/Define Cs are right at the border of what’s possible with the high-end cards. There’s like a dozen models in the 320-330mm range, yet the case is 315mm for GPU clearance. What specific model is that so I can keep an eye out?",
      "Afaik that's the same SAG support I had for my 3080, it sufficed for that card so it probably will for this one :D",
      "I screwed it tightly and it still moves a bit, but I think it's good enough",
      "I had to buy the seasonic 12vhpwr since my PSU only came with 2 GPU cables and it's a Seasonic Focus GX",
      "Just done that and I must say it makes a good amount of difference on a high refresh rate oled monitor. From medium settings to max settings hits beautifully."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "4080",
      "4080 super"
    ],
    "title": "RIP 2080, should I get 4080 or 4090?",
    "selftext": "Hi everyone, a few days ago my dear RTX 2080 abandoned me and I am forced to change graphics card. I wanted to wait for the new 5000 series but at this point I can't stay without a graphics card for about a year (considering that they won't be available right away). I currently play with a resolution of 3440x1440 with a ryzen 3900x (I plan to switch to 5700x3d before or during black friday).\n\nHaving said that, is it better for me to get a 4080 super at a price of around 1100-1200 euros or a new 4090 at a price of 1500-1700 euros?\n\nI fear that with the release of the 5000 series, the 4090 is the one that will not lose much compared to the others in terms of performance, but that it could depreciate more than the others given its high current value (even if it will obviously remain a good graphics card).",
    "comments": [
      "I gotta leave this sub lol, everyone always talking about buying 4080s and 4090s, when my gpu dies I’ll have to quit pc gaming",
      "I'd get the 4090 again, because the 5090 prices will make people waiting now, to buy the 4090.  I don't see 4090s getting cheaper when 5090s release.  4090 may be discontinued.",
      "4090 production is being shut down for 5000 series production yes.",
      "This is always a gamble. Just chill, don't give Nvidia $1000, coming from a 2080, 4070 Ti Super is more than fine, if you don't have money to burn.  \n$799 msrp, +109% faster than 2080, 285w vs 215w TDP is enough of a TDP increase.  \nDouble the VRAM.",
      "Or look for a $300ish 3080 10GB to get bye for awhile, you can always sell it when you figure out which 50 series to grab.",
      "AMD is absolutely the alternative. Nvidia’s lineup is terrible for value even though the cards themselves are still solid. But if money is an issue, go AMD. Their cards aren’t stellar in value but they’re certainly MUCH better than Nvidia.\n\nI can see why people forget AMD video cards exist but they’re absolutely the better budget option bar none (though I hope to see Intel getting there eventually too).",
      "4090 prices are extremely high rn. The 4080 makes more sense. It's €1000 for a palit jetstream",
      "This. I think people are putting too much stock in the price and availability of the 5080 and 5090.",
      "4080 super is what I’d get no card is worth 2 grand",
      "Am I crazy to suggest buying a used 2080 for way cheaper than a 4080 or 4090?  Then once the new cards come out see how the 5000 series do and by then a 4000 series would be cheaper if you want.",
      "If you afford can 4090\n\nAbsolutely 4090 \n\nit is one beast of a card.",
      "My whole dilemma with that is if you can afford a 4090 right now then just wait for the 5090.",
      "I’m enjoying my 70tiSuper. It’s my first PC build and I’m quite enjoying the experience. It can run most games at max settings 1440p(sometimes 4K) at 60fps. \n\nComing from console, I’m honestly enjoying path traced cyberpunk w/max settings at DLSS 1440 at like 40fps. That’s a world away from what I had on PS5.",
      "it was 6 years old, and unfortunately it had already been replaced after 3 years with a refurbished one from EVGA",
      "I mean when your GPU dies, you just buy another used one of the same tier for cheap.",
      "300ish? Where? 😂",
      "The 24GB on XTX is pretty useless right now.  Don't need it for games and professional apps that could use more memory don't run well on it to begin with.",
      "Yes. In my country the 4070 cost alot more than the rx 7800xt. A clear choice.",
      "Nah pretty much everyone here knows Nvidia has BEEN out of hand for a while. The 2000 series started “okay” and then things just got worse in terms of value as time went on. Now they have absolutely no reason to better their pricing model. AMD is absolutely where people should go if they’re on a budget. It sucks that it’s become this way but no reason paying $600 for a 70-class card when that money can get you a 7900XT for $100 more.",
      "Can afford is relative.   \nI know people who are really wealthy and still run very old iPhones and don't throw money on new tech."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "rtx 4080",
      "4080",
      "4080 super",
      "rtx 4080 super"
    ],
    "title": "How'd I do? ",
    "selftext": "RTX 4080 Super I7-3700k Corsair Vengeance 64gb Samgsung 990 pro MSI Mortar Wifi II Corsair H150i ELITE LCD XT Thermaltake Tower 300",
    "comments": [
      "a very nice popcorn machine",
      "interesting case, not my style but it looks fresh fr. Looks nice and simple I love that and that cpu cooler must of been expensive. I would say if u could make the bottom fan more subtle and not so bright it would look even more clean.👍🏾",
      "Really nice!  I love that case!  Next build I'll probably grab one.  Congratulations!",
      "13700K right? Right?..\n\n![gif](giphy|3ohuApAxgxXUVeDFm0)",
      "could just be the camera doe bc ik the camera is never as good as seeing it in real life😭",
      "The final tally came out to about 3100",
      "Man I was gona say. Wth u doing with a 14 year old cpu and a 4080...... that's one hell of a bottle neck. 22nm cpu from 2012 lmfao",
      "The cable management for the most part is really nice! There are cable guides and places for tie downs on the back side!",
      "Yah 😂",
      "😂",
      "You're right... Mine isn't on my desk... It's underneath... On a riser... It sitting on the floor is bad for the long term health of the PC, airflow, etc... unless you're cleaning it regularly.",
      "I'm not being salty... I was just making an observation. I'm very happy. Thank you for your concern though. Idk about your case, but mine has a filter underneath it that I clean regularly. Gets pretty dusty.",
      "I'm a cultured man. I have a laptop. Those do belong on a desk",
      "Now we agree on something 😉",
      "What track is the music from? Sounds like the main menu but couldnt find it on the track",
      "Total cost?",
      "Yes",
      "Very cool!\n\nWas the build harder\\easier than a standard ATX case?",
      "I'm being a hater but it amazes me how many people enjoy the garish ugly cyberpunk disco builds. What happened to style? What happened to class and decorum? Yoh people should be ashamed.",
      "https://preview.redd.it/i61ufql66vhc1.jpeg?width=1290&format=pjpg&auto=webp&s=091f246d30a06116c2f1f222955193bf765d1bcb"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "rtx 4080",
      "4080",
      "4080 super",
      "rtx 4080 super"
    ],
    "title": "This heatsink is sexy af. [ASUS×Noctua GeForce RTX 4080 SUPER]",
    "selftext": "",
    "comments": [
      "It's so pricy you had to stole it or why is the photo taken from jail? /s",
      ">should have got a 4090 for that price\n\nmaybe it's an American thing, but some prices in my country for comparison:\n\n**32k** ASUS TUF RTX 4080 Super\n\n**35k** (what I paid) Noctua 4080 Super\n\n**50k** ASUS TUF RTX 4090\n\nnow let the mental gymnastics (\"you could have bought used!\" etc) begin",
      "Been wanting one of these myself - finally got it. $1300 for SUPER is much better than the $1650 for non-SUPER.\n\nhttps://preview.redd.it/m7d3ya97gorc1.jpeg?width=5542&format=pjpg&auto=webp&s=b0f05c541ec04d8dcb1e387a539b1d1152a45a69",
      "That is legit the size of a brick",
      ";) I still use the same case since ~2010, it's the CoolerMaster HAF-922, I know newer ones are more often glass side but I prefer this old school steel mesh",
      "> be ready for all the haters to tell you \"you wasted money should have got a 4090 for that price\"\n\n  This was true **at launch** for all the ASUSxNoctua cards.  \nThey're good coolers but no way do they deserve such a premium price.\n\nAlso: absolutely terrible picture.",
      "I really like the noctua models, just not the price.",
      "Nobody needs it, all 4080 supers are super close to equal noise normalized, it’s more of a “want.”",
      "https://preview.redd.it/avg2sagbgorc1.jpeg?width=5712&format=pjpg&auto=webp&s=a15ee0a177214f4f1bfed16eb8fa0b5870a30571\n\nVersus the FE SUPER",
      "I see a fellow Czech I upvote. Yeah, very different from American prices, unfortunately.",
      "Is no one going to talk about the 10/10 anti-sag mechanism?",
      "May want to get a better PSU I’ve never had coil whine issues and I’ve had over 10 GPUs this gen alone. Seasonic and Corsair top tier PSUs…",
      "What temperatures you get that you need this heatsink? My 4070Ti Super barely goes higher than 63-64C",
      "For some reason, I thought these two pics were related, while I was quickly scrolling. I thought the nvidia pic was the back of that audi, showing the beautiful cooling system for the engine….\n\nhttps://preview.redd.it/ow6lxzhfoorc1.jpeg?width=2732&format=pjpg&auto=webp&s=bf4fa56469efdad54afb46e561a53e82a5ee2351",
      "MFW I become aware Noctua also made a 4080 Super version.",
      "![gif](giphy|UaYDUGyY2Ao6UtpyjA)",
      "I think it looks great",
      "Yeah, the price premium is a problem. A few Noctua fans aren't so expensive they account for the several hundred euro price differences, and the only thing special about the heatsink is that it fits those fans and looks nice.",
      "Tested with; Seasonic prime, Seasonic vertex, Be quiet dp 13 pro, Fsp hydro ti pro. All 1000w. I work with hardware, trust me it’s not psu (it can be sometimes though), there is just higher probability that some cards will whine more then other because of the pwm signal and power delivery configuration on the board.",
      "It’s so nice I have to delete history after viewing it."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "4080",
      "4080 super"
    ],
    "title": "4070 ti super or 4080 super?",
    "selftext": "Does the $200 price difference really warrant better performance or should I just save my money?",
    "comments": [
      "The performance difference is about 15%\n\nThe cost-performance scaling is not perfectly linear",
      "Neither. Don't buy Open box from Newegg.",
      "I've heard so many horror stories with Newegg open-box conditions",
      "no it's Stay away from Open box on ASUS.",
      "I noticed the 4080 super it's the OC version. Check if there is a non OC one, so you can save some money, as the 4070 it's not the OC version. this way you can compare both better in price",
      "Performance uplift were never scale the same with money spent in the same generation, usually double the money for about 30% in mid range and worse at high end.",
      "If 1440P, get the 4070 Ti super.",
      "I've bought an open box GPU which didn't have the GPU I bought in it. Someone pulled the old switcheroo.",
      "5080.",
      "Maximizing frames vs budget is literally performance per dollar",
      "It's 11% at 1080p, 13% at 1440p and 15% at 4K/UHD.\n\n[https://www.techpowerup.com/review/nvidia-geforce-rtx-4080-super-founders-edition/32.html](https://www.techpowerup.com/review/nvidia-geforce-rtx-4080-super-founders-edition/32.html)",
      "Haven’t had issues with Newegg open box yet",
      "![gif](giphy|PtfccZBHY2VBm)",
      "lol no. there's a reason people wanted this class of gpu, they wanted to take a peek at the state of the art game rendering tech a.k.a Path Tracing, or they wanted something more than gaming, a little bit of media productivity. Radeon at this price point is kinda hard to  justify \"hey save a little bit to get a little bit raw performance\"",
      "Oc 4070 ti s is $750, just checked",
      "Yeah looks like the better deal, also why the shade on gaming lol.",
      "Because people are jerks and think other people having fun is a waste of time.",
      "Man I’ve been out of the pc gaming loop for far too long, gonna cancel my Newegg open box order than, Jesus Christ what happened they used to be top notch????",
      "Definitely buy the card that doesn't exist yet, and is likely to exist in about 10-12 months time.",
      "Some people worry about overspending for diminishing returns…"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "rtx 4080",
      "4080",
      "4080 super",
      "rtx 4080 super"
    ],
    "title": "nVidia GeForce RTX 5070 Ti Meta Review",
    "selftext": "- compilation of 13 launch reviews with ~7220 gaming benchmarks at 1080p, 1440p, 2160p\n- only benchmarks at real games compiled, not included any 3DMark & Unigine benchmarks\n- geometric mean in all cases\n- standard raster performance without ray-tracing and/or DLSS/FSR/XeSS\n- extra ray-tracing benchmarks (mostly without upscaler) after the standard raster benchmarks\n- stock performance on (usually) reference/FE boards, no overclocking\n- factory overclocked cards were normalized to reference clocks/performance, but just for the overall performance average (so the listings show the original performance result, just the performance index has been normalized)\n- missing results were interpolated (for a more accurate average) based on the available & former results\n- performance average is (some) weighted in favor of reviews with more benchmarks\n- all reviews should have used newer drivers for _all_ cards\n- power draw numbers based on a couple of reviews, always for the graphics card only\n- performance/price ratio (higher is better) for 1440p raster performance and 1440p ray-tracing performance\n- for the full results and some more explanations check [3DCenter's launch analysis](https://www.3dcenter.org/artikel/launch-analyse-nvidia-geforce-rtx-5070-ti)\n\n&nbsp;\n\nRaster 2160p|7800XT|7900XT|79XTX|4070S|4070Ti|407TiS|4080|4080S|5070Ti|5080\n|:--|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|\n&nbsp;|RDNA3 16GB|RDNA3 20GB|RDNA3 24GB|Ada 12GB|Ada 12GB|Ada 16GB|Ada 16GB|Ada 16GB|Blackw. 16GB|Blackw. 16GB\nCBase|63.0%|84.3%|98.8%|74.4%|-|89.3%|-|102.4%|_100%_|114.8%\nHW&Co|67.1%|85.8%|100.1%|-|-|88.8%|-|103.5%|_100%_|115.4%\nIgor's|69.1%|87.8%|106.7%|74.5%|-|89.6%|-|105.2%|_100%_|115.3%\nKitGuru|69.4%|93.5%|109.4%|76.6%|82.0%|89.3%|-|105.1%|_100%_|118.0%\nPCGH|-|90.2%|107.7%|-|-|86.8%|-|103.0%|_100%_|117.3%\nPurePC|61.8%|83.6%|99.3%|-|79.6%|84.9%|100.7%|-|_100%_|115.8%\nQuasarZ|-|84.7%|-|-|81.6%|87.5%|100.8%|104.4%|_100%_|118.9%\nSweCl|67.1%|-|106.5%|-|-|-|103.9%|-|_100%_|118.1%\nTPU|64%|85%|100%|72%|78%|86%|_100%_|102%|_100%_|115%\nTechSpot|67.1%|87.3%|106.3%|75.9%|83.5%|89.9%|102.5%|105.1%|_100%_|115.2%\nTom's|-|-|103.3%|-|80.4%|87.7%|-|104.9%|_100%_|114.5%\nTweakers|68.5%|89.8%|103.6%|74.8%|81.9%|86.0%|102.7%|103.6%|_100%_|116.6%\n**avg**|**66.3%**|**87.6%**|**103.9%**|**74.5%**|**81.2%**|**88.0%**|**102.0%**|**104.2%**|**_100%_**|**116.7%**\nTDP|263W|315W|355W|220W|285W|285W|320W|320W|300W|360W\nMSRP|$499|$899|$999|$599|$799|$799|$1199|$999|$749|$999\n\n&nbsp;\n\nRaster 1440p|7800XT|7900XT|79XTX|4070S|4070Ti|407TiS|4080|4080S|5070Ti|5080\n|:--|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|\n&nbsp;|RDNA3 16GB|RDNA3 20GB|RDNA3 24GB|Ada 12GB|Ada 12GB|Ada 16GB|Ada 16GB|Ada 16GB|Blackw. 16GB|Blackw. 16GB\nCBase|65.8%|86.6%|97.8%|77.5%|-|91.0%|-|103.2%|_100%_|112.0%\nHW&Co|70.9%|90.0%|102.0%|-|-|92.0%|-|105.3%|_100%_|114.5%\nIgor's|71.6%|89.2%|104.9%|78.3%|-|90.4%|-|105.3%|_100%_|112.9%\nKitGuru|71.8%|95.3%|108.4%|80.1%|85.6%|91.5%|-|106.1%|_100%_|115.7%\nLinus|73.0%|93.9%|107.0%|77.4%|84.3%|90.4%|-|103.5%|_100%_|-\nPCGH|-|93.0%|108.8%|-|-|89.2%|-|105.6%|_100%_|115.6%\nPurePC|64.6%|86.4%|100.0%|-|83.7%|87.1%|103.4%|-|_100%_|114.3%\nQuasarZ|-|86.9%|-|-|84.9%|89.6%|101.6%|105.0%|_100%_|115.5%\nSweCl|68.7%|-|105.4%|-|-|-|104.1%|-|_100%_|113.6%\nTPU|67%|87%|100%|76%|83%|88%|101%|103%|_100%_|113%\nTechSpot|73.1%|92.3%|107.7%|83.1%|89.2%|93.8%|106.2%|108.5%|_100%_|113.1%\nTom's|-|-|101.6%|-|84.5%|90.4%|-|104.3%|_100%_|111.6%\nTweakers|70.5%|91.6%|101.8%|79.1%|85.6%|87.7%|103.7%|104.1%|_100%_|113.4%\n**avg**|**69.6%**|**90.4%**|**103.9%**|**78.9%**|**85.3%**|**90.3%**|**103.4%**|**105.3%**|**_100%_**|**114.3%**\nTDP|263W|315W|355W|220W|285W|285W|320W|320W|300W|360W\nMSRP|$499|$899|$999|$599|$799|$799|$1199|$999|$749|$999\n\n\n&nbsp;\n\nRaster 1080p|7800XT|7900XT|79XTX|4070S|4070Ti|407TiS|4080|4080S|5070Ti|5080\n|:--|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|\n&nbsp;|RDNA3 16GB|RDNA3 20GB|RDNA3 24GB|Ada 12GB|Ada 12GB|Ada 16GB|Ada 16GB|Ada 16GB|Blackw. 16GB|Blackw. 16GB\nIgor's|71.5%|87.5%|100.1%|79.6%|-|91.3%|-|104.3%|_100%_|109.6%\nKitGuru|73.5%|96.0%|107.6%|83.1%|88.3%|93.2%|-|106.9%|_100%_|114.3%\nLinus|72.7%|94.2%|105.8%|81.2%|87.0%|91.6%|-|-|_100%_|-\nPCGH|-|93.5%|106.8%|-|-|90.9%|-|105.2%|_100%_|113.9%\nPurePC|66.4%|87.0%|98.6%|-|86.3%|88.4%|104.1%|-|_100%_|112.3%\nQuasarZ|-|87.2%|-|-|87.9%|90.6%|101.8%|105.3%|_100%_|113.4%\nSweCl|70.2%|-|104.3%|-|-|-|104.3%|-|_100%_|111.3%\nTPU|69%|88%|99%|80%|87%|91%|102%|103%|_100%_|110%\nTechSpot|76.2%|93.3%|103.7%|89.0%|93.9%|97.0%|106.7%|107.9%|_100%_|106.7%\nTom's|-|-|100.3%|-|88.6%|93.0%|-|104.7%|_100%_|108.5%\nTweakers|72.7%|91.4%|99.8%|82.0%|88.5%|88.9%|104.8%|104.7%|_100%_|111.8%\n**avg**|**71.6%**|**91.0%**|**102.2%**|**82.4%**|**88.4%**|**91.8%**|**103.8%**|**105.3%**|**_100%_**|**111.3%**\nTDP|263W|315W|355W|220W|285W|285W|320W|320W|300W|360W\nMSRP|$499|$899|$999|$599|$799|$799|$1199|$999|$749|$999\n\n&nbsp;\n\nRayTr. 2160p|7800XT|7900XT|79XTX|4070S|4070Ti|407TiS|4080|4080S|5070Ti|5080\n|:--|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|\n&nbsp;|RDNA3 16GB|RDNA3 20GB|RDNA3 24GB|Ada 12GB|Ada 12GB|Ada 16GB|Ada 16GB|Ada 16GB|Blackw. 16GB|Blackw. 16GB\nCBase|53.8%|74.2%|85.2%|70.2%|-|89.8%|-|102.9%|_100%_|112.5%\nKitGuru|46.7%|65.6%|75.8%|68.8%|74.4%|89.3%|-|106.3%|_100%_|119.1%\nPCGH|-|68.8%|81.3%|-|-|89.7%|-|105.7%|_100%_|118.2%\nPurePC|41.8%|56.4%|67.9%|-|78.2%|83.6%|101.8%|-|_100%_|117.0%\nQuasarzone  (5 Tests)|-|-|-|-|82.4%|89.2%|102.9%|106.7%|_100%_|118.4%\nTPU|46%|61%|71%|62%|67%|88%|103%|104%|_100%_|115%\nTechSpot|35.3%|49.0%|58.8%|74.5%|82.4%|88.2%|105.9%|109.8%|_100%_|119.6%\nTom's|-|-|77.9%|-|80.2%|90.4%|-|106.1%|_100%_|113.1%\nTweakers|-|68.9%|78.8%|75.1%|82.6%|88.7%|106.7%|107.8%|_100%_|118.0%\n**avg**|**46.9%**|**64.0%**|**75.1%**|**70.8%**|**77.7%**|**88.8%**|**103.8%**|**105.9%**|**_100%_**|**117.0%**\nTDP|263W|315W|355W|220W|285W|285W|320W|320W|300W|360W\nMSRP|$499|$899|$999|$599|$799|$799|$1199|$999|$749|$999\n\n&nbsp;\n\nRayTr. 1440p|7800XT|7900XT|79XTX|4070S|4070Ti|407TiS|4080|4080S|5070Ti|5080\n|:--|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|\n&nbsp;|RDNA3 16GB|RDNA3 20GB|RDNA3 24GB|Ada 12GB|Ada 12GB|Ada 16GB|Ada 16GB|Ada 16GB|Blackw. 16GB|Blackw. 16GB\nCBase|59.2%|79.1%|88.0%|78.8%|-|93.0%|-|103.9%|_100%_|111.5%\nHW&Co|42.0%|54.3%|62.0%|-|-|90.8%|-|106.1%|_100%_|116.5%\nKitGuru|49.2%|66.9%|76.2%|77.8%|84.3%|90.5%|-|106.4%|_100%_|117.5%\nLinus|52.0%|68.0%|78.7%|74.7%|81.3%|89.3%|-|104.0%|_100%_|-\nPCGH|-|73.3%|84.5%|-|-|91.7%|-|106.8%|_100%_|116.0%\nPurePC|43.0%|58.9%|69.0%|-|82.3%|86.7%|103.2%|-|_100%_|116.5%\nTPU|49%|64%|74%|77%|85%|90%|104%|104%|_100%_|112%\nTechSpot|41.2%|55.3%|63.5%|83.5%|89.4%|94.1%|109.4%|110.6%|_100%_|116.5%\nTom's|-|-|82.6%|-|86.1%|93.0%|-|111.1%|_100%_|111.9%\nTweakers|52.0%|68.5%|77.4%|77.7%|86.0%|90.0%|107.7%|108.0%|_100%_|115.0%\n**avg**|**50.2%**|**66.8%**|**76.6%**|**78.2%**|**85.4%**|**91.2%**|**105.1%**|**106.7%**|**_100%_**|**115.3%**\nTDP|263W|315W|355W|220W|285W|285W|320W|320W|300W|360W\nMSRP|$499|$899|$999|$599|$799|$799|$1199|$999|$749|$999\n\n&nbsp;\n\nRayTr. 1080p|7800XT|7900XT|79XTX|4070S|4070Ti|407TiS|4080|4080S|5070Ti|5080\n|:--|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|\n&nbsp;|RDNA3 16GB|RDNA3 20GB|RDNA3 24GB|Ada 12GB|Ada 12GB|Ada 16GB|Ada 16GB|Ada 16GB|Blackw. 16GB|Blackw. 16GB\nKitGuru|50.9%|67.6%|75.7%|80.5%|85.6%|91.2%|-|104.9%|_100%_|115.7%\nLinus|37.6%|55.9%|63.4%|76.3%|82.8%|90.3%|-|-|_100%_|-\nPCGH|-|76.3%|86.4%|-|-|93.4%|-|107.0%|_100%_|114.7%\nPurePC|45.2%|60.0%|69.0%|-|84.5%|87.7%|103.2%|-|_100%_|114.2%\nTPU|53%|66%|75%|80%|87%|92%|104%|105%|_100%_|110%\nTechSpot|44.7%|56.1%|-|86.0%|92.1%|96.5%|109.6%|111.4%|_100%_|114.0%\nTom's|-|-|80.5%|-|87.0%|92.4%|-|103.2%|_100%_|104.3%\nTweakers|53.0%|67.9%|75.4%|79.6%|87.2%|89.7%|106.4%|107.9%|_100%_|113.8%\n**avg**|**51.0%**|**66.9%**|**75.8%**|**80.7%**|**87.1%**|**92.1%**|**104.6%**|**106.2%**|**_100%_**|**112.5%**\nTDP|263W|315W|355W|220W|285W|285W|320W|320W|300W|360W\nMSRP|$499|$899|$999|$599|$799|$799|$1199|$999|$749|$999\n\n&nbsp;\n\nAt a glance|7800XT|79XT|79XTX|407S|407Ti|407TiS|4080|4080S|507Ti|5080\n|:--|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|\n&nbsp;|RDNA3 16GB|RDNA3 20GB|RDNA3 24GB|Ada 12GB|Ada 12GB|Ada 16GB|Ada 16GB|Ada 16GB|Blackw. 16GB|Blackw. 16GB\n2160p&nbsp;Raster|66.3%|87.6%|103.9%|74.5%|81.2%|88.0%|102.0%|104.2%|_100%_|116.7%\n1440p Raster|69.6%|90.4%|103.9%|78.9%|85.3%|90.3%|103.4%|105.3%|_100%_|114.3%\n1080p Raster|71.6%|91.0%|102.2%|82.4%|88.4%|91.8%|103.8%|105.3%|_100%_|111.3%\n2160p RayTr.|46.9%|64.0%|75.1%|70.8%|77.7%|88.8%|103.8%|105.9%|_100%_|117.0%\n1440p RayTr.|50.2%|66.8%|76.6%|78.2%|85.4%|91.2%|105.1%|106.7%|_100%_|115.3%\n1080p RayTr.|51.0%|66.9%|75.8%|80.7%|87.1%|92.1%|104.6%|106.2%|_100%_|112.5%\nTDP|263W|315W|355W|220W|285W|285W|320W|320W|300W|360W\nReal Power Draw|250W|309W|351W|221W|267W|277W|297W|302W|287W|311W\nEE RA 1440p|80%|84%|85%|102%|92%|94%|100%|100%|_100%_|105%\nMSRP|$499|$899|$999|$599|$799|$799|$1199|$999|$749|$999\nRetail GER|495€|689€|899€|~600€|~830€|~830€|~1150€|~1000€|~1000€|~1300€\nP/P GER 1440p&nbsp;RA|141%|131%|116%|131%|103%|109%|90%|105%|_100%_|88%\nP/P GER 1440p&nbsp;RT|101%|97%|85%|130%|103%|110%|91%|107%|_100%_|89%\nRetail US|~$500|~$650|~$870|~$600|~$800|~$800|~$1200|~$1000|~$900|~$1150\n**P/P US 1440p&nbsp;RA**|**125%**|**125%**|**107%**|**118%**|**96%**|**102%**|**78%**|**95%**|**_100%_**|**89%**\nP/P US 1440p&nbsp;RT|90%|92%|79%|117%|96%|103%|79%|96%|_100%_|90%\n\nNote: RA = Raster, RT = Ray-Tracing, EE = Energy Efficiency, P/P = Performance/Price Ratio    \nNote: For the graphics cards that have already been discontinued, a retail price was assumed at the time of their sale. At US market, this applies to all other cards beside the RTX50 series. Retail prices were estimated for 5070Ti, 5080 & 5090 when availability is reached (based on the forecast that MSRP level will not be reached in the near future). These estimates are of course not perfect, as nobody knows how the price situation will develop.\n\n&nbsp;\n\nPerf. Gain of 5070Ti|Raster 2160p|Raster 1440p|Raster 1080p|RayTr. 2160p|RayTr. 1440p|RayTr. 1080p\n|:--|:--:|:--:|:--:|:--:|:--:|:--:|\nRadeon RX 7800 XT|+51%|+44%|+40%|+113%|+99%|+96%\nRadeon RX 7900 XT|+14%|+11%|+10%|+56%|+50%|+49%\nRadeon RX 7900 XTX|–4%|–4%|–2%|+33%|+31%|+32%\nGeForce RTX 4070 Super|+34%|+27%|+21%|+41%|+28%|+24%\nGeForce RTX 4070 Ti|+23%|+17%|+13%|+29%|+17%|+15%\nGeForce&nbsp;RTX&nbsp;4070&nbsp;Ti&nbsp;Super|+14%|+11%|+9%|+13%|+10%|+9%\nGeForce RTX 4080|–2%|–3%|–4%|–4%|–5%|–4%\nGeForce RTX 4080 Super|–4%|–5%|–5%|–6%|–6%|–6%\nGeForce RTX 4090|–27%|–24%|–21%|–29%|–27%|–23%\nGeForce RTX 5080|–14%|–12%|–10%|–15%|–13%|–11%\nGeForce RTX 5090|–43%|–36%|–29%|–45%|–39%|–33%\n\nNote: Performance improvement of the GeForce RTX 5070 Ti compared to the other cards. The respective other card is then _100%_.\n\n&nbsp;\n\n&nbsp;|Asus TUF OC|Galax 1-Click OC|MSI Gaming Trio OC+|MSI Vanguard SOC|MSI Ventus 3X OC|Palit GameRock OC\n|:--|:--:|:--:|:--:|:--:|:--:|:--:|\nCooling|Air, 3 Fans|Air, 3 Fans|Air, 3 Fans|Air, 3 Fans|Air, 3 Fans|Air, 3 Fans\nDimensions|TripleSlot, 33x14cm|TripleSlot, 30x12.5cm|TripleSlot, 34x14cm|QuadSlot, 36x15cm|TripleSlot, 30x12cm|QuadSlot, 33.15cm\nWeight|1616g|1300g|1301g|1937g|1060g|2186g\nClocks|2295/2588 MHz|2295/2467 MHz|2295/2572 MHz|2295/2588 MHz|2295/2482 MHz|2295/2512 MHz\nReal Clock (avg/median)|2785 MHz / 2827 MHz|2746 MHz / 2790 MHz|2747 MHz / 2782 MHz|2785 MHz / 2835 MHz|2759 MHz / 2805 MHz|2819 MHz / 2872 MHz\nTDP|300W (max. 330W)|300W (max. 320W)|300W (max. 330W)|300W (max. 350W)|300W (max. 300W)|300W (max. 330W)\nRaster Perf. (2160/1440/1080)|+2% / +1% / +1%|_100%_|+1% / +0% / +0%|+2% / +1% / +1%|+1% / +1% / +0%|+2% / +1% / +1%\nRayTr. Perf. (2160/1440/1080)|+2% / +1% / +1%|_100%_|+1% / +0% / +0%|+2% / +1% / +1%|+1% / +1% / –2%|+2% / +1% / +0%\nTemperatures (GPU/Memory)|61°C / 64°C|63°C / 68°C|63°C / 68°C|59°C / 60°C|68°C / 70°C|63°C / 68°C\nLoundness|30.8 dBA|29.5 dBA|24.3 dBA|23.9 dBA|40.9 dBA|29.4 dBA\nReal Power Draw (Idle/Gaming)|17W / 279W|21W / 279W|19W / 268W|18W / 274W|18W / 287W|28W / 292W\nPrice|$1000|$750|$980|$1000|$900|$1000\nSource:|[TPU](https://www.techpowerup.com/review/asus-geforce-rtx-5070-ti-tuf-oc/)|[TPU](https://www.techpowerup.com/review/galax-geforce-rtx-5070-ti-1-click-oc-white/)|[TPU](https://www.techpowerup.com/review/msi-geforce-rtx-5070-ti-gaming-trio-oc/)|[TPU](https://www.techpowerup.com/review/msi-geforce-rtx-5070-ti-vanguard-soc/)|[TPU](https://www.techpowerup.com/review/msi-geforce-rtx-5070-ti-ventus-3x/)|[TPU](https://www.techpowerup.com/review/palit-geforce-rtx-5070-ti-gamerock-oc/)\n\nNote: Just the values of the default BIOS were noted throughout, as _complete_ information including performance values are only available for that BIOS.\n\n&nbsp;\n\nList of GeForce RTX 5070 Ti reviews evaluated for this analysis:\n\n- [ComputerBase](https://www.computerbase.de/artikel/grafikkarten/nvidia-geforce-rtx-5070-ti-test.91379/)\n- [Hardware & Co](https://hardwareand.co/dossiers/gpu/test-de-la-geforce-rtx-5070-ti-plus-interessante-que-la-rtx-5080)\n- [Igor's Lab](https://www.igorslab.de/msi-geforce-rtx-5070-ti-ventus-als-msrp-karte-im-test-interessanter-chip-fuer-gamer-aber-ventus-kommt-von-ventilator/)\n- [KitGuru](https://www.kitguru.net/components/graphic-cards/dominic-moass/msi-rtx-5070-ti-ventus-3x-oc-review/)\n- [Linus Tech Tips](https://www.youtube.com/watch?v=NnhU2ZvHb10)\n- [PC Games Hardware](https://www.pcgameshardware.de/Geforce-RTX-5070-Ti-Grafikkarte-281031/Tests/Release-Preis-Test-Benchmarks-vs-5080-1466041/)\n- [PurePC](https://www.purepc.pl/msi-geforce-rtx-5070-ti-ventus-3x-recenzja-test-wydajnosci-cena-premiera-blackwell)\n- [Quasarzone](https://quasarzone.com/bbs/qc_bench/views/93577)\n- [SweClockers](https://www.sweclockers.com/test/40649-msi-rtx-5070-ti-ventus-3x-oc-gor-vad-den-ska)\n- [TechPowerUp](https://www.techpowerup.com/review/galax-geforce-rtx-5070-ti-1-click-oc-white/)\n- [TechSpot](https://www.techspot.com/review/2955-nvidia-geforce-rtx-5070-ti/)\n- [Tom's Hardware](https://www.tomshardware.com/pc-components/gpus/nvidia-geforce-rtx-5070-ti-review-asus)\n- [Tweakers](https://tweakers.net/reviews/12960/nvidia-geforce-rtx-5070-ti-waar-de-rtx-50-serie-leuk-begint-te-worden.html)\n\n&nbsp;\n\nSource: [3DCenter.org](https://www.3dcenter.org/artikel/launch-analyse-nvidia-geforce-rtx-5070-ti)",
    "comments": [
      "Yeah so the 5070ti is functionally identical to the 7900xtx in raster. Lots of people were saying the 7900xtx was much faster, but 3% is margin of error that can swing either direction depending on game selection.",
      "Yo, this took a lot of time to compile. Appreciate it man. \n\nIt's the least worst of all the cards released so far. It's 11-14% faster than a 4070TiS depending on the res. It's also 6% cheaper than the 4070TiS. Put the two together, and it's about 20% better for the same price. Which is the bare minimum for gen-on-gen in my completely arbitrary opinion.\n\nEdit: this is presuming you somehow nabbed a MSRP card. The real price seems to be $900.",
      "msrp mia",
      "People would cherrypick the data they want.",
      "Can’t tell you how many times I’ve heard “the XTX is way faster than the 4080 Super in raster”. These people don’t live in reality.",
      "I've had one yesterday tell me that 7900XTX is plain 20% faster because in one (out of whole 5) games tested by GN at 1440p XTX was like 17% faster. Disregarding than in the rest of those it was at best 10% faster and in any wider benchmark it never broke even 10% properly.",
      "boast versed weather coherent sheet violet trees friendly long payment\n\n *This post was mass deleted and anonymized with [Redact](https://redact.dev/home)*",
      "And the moment you turn on DLSS/RT then that margin gets trampled.\n\nOnly thing holding back the 5070ti now is the low stock price",
      "Man, I thought the 4070 struggling to consistently match the 3080 was sad, but now the freaking *70 Ti* card flat out loses to the previous gen 80 card? Can't even punch *half a tier* up?\n\nI guess once (if?) they come back down to MSRP that will make them good enough value... but you can also look at it as: 5 years after the 3080, you get slightly less than 4080 performance for slightly more than 3080 MSRP. If 40 series killed performance per dollar advancement then 50 series is dancing on its grave",
      "To be fair, even used 4070 ti super cards are going for much higher than its msrp on places like ebay.",
      "Some people live to cherry pick data because that confirms their beliefs. Maybe they are destined to be cherry farmers! \n\nThat's why i always appreciate what this OP is doing on his website because these sort of aggregation of many reviews is the only way we can get the big picture.",
      "Very comprehensive comparison",
      "Have any reviewers found that their cards have the ROP issue?",
      "Not really, when it's not cheaper than the 4070ti super, but ok, maybe some models are in the US.\nEssentially it's a relaunch of the 4080/4080 super. Same price, same performance.",
      "Yeah, definitely not a 1:1 comparison when the 50 series doesn't really sell at MSRP with most vendors. Still an interesting comparison though nonetheless.",
      "I nabbed one at MSRP (PNY) to replace my 7900xt. Raster increase is meh but buying for the DLSS4 over FSR and RT upgrades.",
      "I think someone should do a gen-to-gen performance comparison between Nvidia's various generations, on a per tier, apple-to-apples basis. Because I think an 11-14% uplift from a whole 2 year generational gap is probably not that great. Yeah it's technically a better deal than the previous gen, but not really.",
      "And it *should* hit MSRP eventually. Even the 3070 and 4070 did after a while.\n\n(And, of course, pretty much every gen before that, MSRP was just a higher price to make the always-lower street price seem like a better deal, like it is for every other kind of product. That was normal, and should be again, if competition ever starts being a thing again in the GPU space. All eyes on you intel).",
      "Can't wait for my RTX 5070 (non-ti) \n\nHope it will get the same treatment",
      "Always love these posts"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "rtx 4080",
      "4080",
      "4080 super",
      "rtx 4080 super"
    ],
    "title": "New PC build completed w/ 14700K & RTX 4080 SUPER",
    "selftext": "Setup: \nCPU:  i7 14700KF \n\nCooler: Arctic liquid freezer lll 360 AIO \n\nGPU: PNY 4080 Super XLR8\n\nMOBO: MSI z790 Carbon wifi ll\n\nRAM: G.skill Trident Z Royal Neo \n\nSSD: Samsung 860 evo\n\nCase: Cooler master H500p mesh \n\nUpgraded from my old setup that had a 7700k and an evga 2070 super from 2019, this was well over due!\nYes I could’ve waited and got a 5080 but i built this right after Christmas and didn’t really want to wait and I’m glad I didn’t get a 50 series GPU 😅😂\n",
    "comments": [
      "Looks great! The 4080 super is a fantastic card - I’d say you made a smart choice to not wait for the 5000 series!",
      "4080 Super is a beast of a card and it can still play games with PhysX lol",
      "Why on earth would you buy into lga1700 now?",
      "Not sure where you buy your CPUs but in Canada where I’m located a 7800x3d is 620$ while the 9800x3d is $689 plus tax.\nI got my i7 14700k for 449$ with the money I’m saving I could almost get another 14700k for a backup",
      "4080, 4080 Super, and 5070 Ti are all effectively equivalent in performance so you definitely accomplished your goal",
      "i would agree it’s not the greatest idea right now\n\nhowever some people only upgrade CPUs like every 7 or 8 years\n\nI went from a 4690k to 14700k",
      "You sound like you're rationalizing with yourself. Enjoy your 5080 bro don't sweat it",
      "Nice build. Your card is the big brother to mine (4070 Ti Super XLR8). Enjoy!",
      "Yes beeing a Gamer and Not buying a x3d is Just Madness",
      "32 bit CUDA based Physx* I play games all the time I got a msrp 5080. You know what I don’t miss and will never notice other than 1 titles in my steam library out of all the games I’ve collected for the last 13 years when I checked? Metro series and you know it actually works just fine with physx on or off too! \nI don’t own Batman, but that paper effect seemed cool! Worth a 10-20% difference for a few games for sure 🤥.\nDon’t let the haters make it seem like anything besides the drivers being bad makes this series bad.\nWould I prefer to have 32 bit cuda support, for sure, would I buy last gen over current for the same price? No.",
      "Regarding the other response to this comment, if you didn't already know (I'm sure you do, it's been impossible to avoid on Reddit) just make sure your BIOS is updated to the version that fixes the degradation issue or later and you'll be alright.\n\nIntel deserves a lot of shit but a build put together a couple months ago with a new 14th gen after the issue was fixed will be alright till you next want to upgrade.",
      "Yeah I have the newest bios update for my z790 Msi motherboard (march 13) with a undervolt on the cpu, mind you only did this yesterday. \n\nI’ve had the pc for about 2-3 months now I’ve been learning a lot about this so hopefully no degradation/ damage happened in the 3 months of owning it.",
      "why, if someone started out on latest\nmicrocode right now?",
      "A lot of people buy a cpu/mobo combo and stick with it for years. By the time OP is ready to upgrade it will be to AM6 or whatever Intel is doing. Pretty simple.",
      "That's a Beast!!",
      "Nice cable management. I still need to do mine😂",
      "I wanted a 4080 super so bad....\nCouldn't find one, ended up on a 5070 ti",
      "Hell yeah twins man it’s a great card!",
      "why are you being such an ass lmao",
      "PSU is a Seasonic 1200w"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "4080",
      "4080 super"
    ],
    "title": "4080 Super with Banana for Scale",
    "selftext": "Actually hilarious how large graphics cards are getting",
    "comments": [
      "This checks out because all bananas are the same size!",
      "Where is the mini-banana for scale for the banana? How will I know how big the banana is?",
      "I have a dream.",
      "All bananas are equal",
      "yeah... *insert comedically large banana w/ a comedically large 4080S*\n\nhttps://preview.redd.it/hvgkwzmjmfgc1.jpeg?width=3406&format=pjpg&auto=webp&s=4df7b3c90bcfb00edb1f117a232bae39c741f5b6",
      "I think all 4080s and 4090s are bigger than that.\n\nI actually think is good they could shrink the coolers a bit with the 4080s, probably the die is a lot more efficient.",
      "Is the banana metric or imperial?",
      "How did you get the banana? 3 minutes in and it's out of stock.",
      "Ah I read somewhere these have the 4090 FE coolers so assumed this is the same.",
      "Nope, same exact size.",
      "there's bananas in Europe?",
      "It’s a cost saving measure. Cheaper to have one production line than two.\n\nLike with what they did with the ps5 recently. Create 1 skew while before they had to entirely separate products with the disc and no disc.",
      "I bet you can’t run crysis with that banana",
      "Now we need a 4070 ti super for the bananas scale",
      "I was surprised at the size of this card, I read the first reviews but nothing prepared me for the actual size. Never thought of measuring the space within the case allocated for a video card. Had to pull out the unused CD/DVD trays out of the case then move my two hard-drive cages around to get it to fit length wise (Define R5 case). Card is the 999 PNY version,\n\n... and I thought my 3080 was big.",
      "GPU alone is like mini PC already",
      "But not as ripe",
      "> Smaller die have higher heat densinity.\n\nYes, but more refined nodes lead to more efficient dies too.",
      "How is everyone getting them so fast? Mine is still waiting to arrive at the FedEx Office 😔. Happy for you though, excited for mine.",
      "Can you flip upside down banana and take another photo? She seems as sad as her entire series"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "4080"
    ],
    "title": "Stanfield has significantly improved fps on NV GPUs",
    "selftext": "At launch the 4080 got 59fps at 2K Ultra, way behind the 7900XT, now 4080 scored 86fps, a huge 45% uplift making it 10% faster than 7900XT.  The 3080 also received a huge 65% improvement.\n\n&#x200B;\n\n[Launch](https://preview.redd.it/vtqpxl7koric1.jpg?width=1736&format=pjpg&auto=webp&s=00c65bc559d0c39c13ec547614029a3704727f58)\n\n[Now](https://preview.redd.it/qdvhbm7koric1.jpg?width=1734&format=pjpg&auto=webp&s=346b8b2c53e8adc3533d6194012ee839b663278d)\n\n&#x200B;\n\n[https://twitter.com/Hameeeeedo/status/1751082851804631249](https://twitter.com/Hameeeeedo/status/1751082851804631249)",
    "comments": [
      "I love Stanfield.",
      "lmao I won't forget booting this game up for the first time on a 4070 Ti / 5800X3D, seeing 40-50fps at 1440p with how basic and shitty the game looked was a funny moment. \n\nThanks Todd",
      "Ah so you didn't need to buy a new computer after all? Was Todd lying? that would be a first.\n\nEDIT: Who the fuck downvoted this comment? Show yourself and we can discuss this like men. WHERE ARE YOU TODD WHY ARE YOU HIDING?",
      "The Stanfield Parable would be a good game. Narrated by Todd Howard.",
      "I went from Cyberpunk 2.0 with path tracing on a 4090 to Starfield. Atlantis was a bit of a shock. 70-80fps, and the graphics...",
      "Its hilarious that this game was *obviously* broken at launch on everything but AMD, and yet it just instantly goes directly into a benchmark suite.",
      "That’s exactly what I came from, and that def added to the shock hahah\n\nNew Atlantis is prob one of the worst looking areas in the game imo. It just has a PS3 look to it, I can’t explain it.",
      "Seems logical to me that one of the most popular games is included in hardware benchmarks. I mean.. obviously, lots of people want to see how the game runs on said hardware. Games are included due to the info being relevant to a large viewership rather than bc they are technically well suited for benchmark testing.",
      "Ahahaha love that Edit!",
      "Right? The game can look good at time, not incredible but good. Some POI are well crafted, with the right light it can be quite pretty.\n\nBut the very first city they send us to is arguably the worst. Totally agree with the PS3 feel, I can't put my finger on it, the low poly feel, vast empty spaces, terrible vegetation - anyway you played the game, you know what i mean lol",
      "It’s still a crappy game regardless of what FPS you get",
      "hungry enter nine angle cough fact afterthought heavy memory snails\n\n *This post was mass deleted and anonymized with [Redact](https://redact.dev/home)*",
      "Stanfield Panable: Ultna Deluxe",
      "I like to play some Stanfield after watching a couple episodes of Steinfeld.",
      "Same experience, but let's give credit where it's due: Stanfield has shockingly good looking food.",
      "Ok, so why do the same techtubers that use this **clearly** broken game, in their benchmarks. Then most of them refused to use cyberpunk in their RT benchmarks, and instead make sure to use games like RE4, with anemic RT that nobody recommended?",
      "hehe thanks. It went to 0 instantly as soon as I posted it and I thought to myself \"come on this has to be the least controversial thing I've ever said on reddit\". Who else but Todd?",
      "The same techtubers that dont use cyberpunk, a much more popular game in their RT benchmarks,? Makes total sense. /s",
      "Just in time for 0.1% of the ppl still playing Starfield",
      "I love Stanfield."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "4080",
      "4080 super"
    ],
    "title": "Entirely blacked out Fractal North 4080 Super build",
    "selftext": "",
    "comments": [
      "But I can see Garfield",
      "Blacked out until you power up and the RAM RGB & case lights decides to run.......👌",
      "Yes he’s been in my system since I ran a ryzen 1600 and rx580",
      "Garfield is not blacked out. 0/10. JK that's a cool build!",
      "Yeah I generally have every light set to off, I just left them on for that pic",
      "I have the Fractal Torrent under the desk. No RGB and opaque sides. Bliss.\n\nThe Torrent has it's own GPU support bracket. Does the North? If not then you should get one.",
      "Very beautiful. Very powerful",
      "The north sadly has no bracket, but I don’t think it’s super necessary for founders because they’re built stronger than most aibs particularly with better backplate screws. I’ll keep an eye on it but I don’t think it’ll ever sag",
      "Clean build👍",
      "Damn Garfield carrying the wold of the PC on his shoulders",
      "What CPU do you have?",
      "Also near silent, except for the fans on the card. That card is a noisy mf. Beautiful though",
      "5800x3D",
      "Thanks!",
      "Still a good-looking setup, hope you enjoy.",
      "It's not so much sag but the PCB cracking near the release leaver on the PCIe slot. [https://www.youtube.com/watch?v=qwpNztmyBGE](https://www.youtube.com/watch?v=qwpNztmyBGE)",
      "Heres my rainbow\n\nhttps://preview.redd.it/b9c5m205ni5d1.jpeg?width=4031&format=pjpg&auto=webp&s=e8318314900ec529ddefc7ca6c391794e3ebad6e",
      "Gorfeld.\n\nLasaga.",
      "Ccoler? And max temp? And thermal paste?",
      "RGB ruining it"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "rtx 4080",
      "4080",
      "4080 super",
      "rtx 4080 super"
    ],
    "title": "RTX 4080 Super Launch Thread",
    "selftext": "**What**: GeForce RTX 4080 Super Launch Day\n\n**When**: Wednesday, January 31, 2024 at 9am Eastern Time\n\n**Protocol**:\n\n* **Subreddit will be on restricted mode until Review Megathread is up.**\n* **Various reviews from select outlets will be posted separately for discussion purposes.**\n* This **Launch Day Megathread** will serve as the hub for discussion regarding various launchday madness. Thread will be sorted by \"new\"\n* [You can also join our Discord server for discussion!](https://discord.gg/nvidia)\n* Topics that should be in Megathread include:\n   * Sharing your successful order\n   * Sharing your non successful order\n   * Sharing your Brick & Mortar store experience\n   * Discussion regarding stock\n   * Any questions regarding orders and availability\n   * Any discussion regarding what you plan to use your new GPU for\n   * Any discussion about how you're happy because you get one\n   * Any discussion about how you're mad because you didn't get one\n* **Any standalone launch day related posts will be removed.**\n\n**Reference Info:**\n\n# [RTX 4080 Super Announcement Megathread](https://new.reddit.com/r/nvidia/comments/191pdus/megathread_geforce_at_ces_super_gpus_rtx_games/)\n\n# [RTX 4080 Super Review Megathread](https://www.reddit.com/r/nvidia/comments/1afpxem/geforce_rtx_4080_super_review_megathread/)\n\n**Links to various RTX 4080 Super Models:**\n\n# US:\n\n* [Nvidia Store (Founders Edition)](https://store.nvidia.com/en-us/geforce/store/gpu/?page=1&limit=9&locale=en-us&gpu=RTX%204080%20SUPER&category=GPU&category_filter=GPU~0,LAPTOP~0,STUDIO-LAPTOP~0,DESKTOP~0,MONITOR~0,MICE~0,GFN~0,NVLINKS~0)\n* [Newegg](https://www.newegg.com/p/pl?N=100007709%20601432394&d=4080+super&isdeptsrh=1&Order=1)\n* [Best Buy](https://www.bestbuy.com/site/searchpage.jsp?id=pcat17071&qp=gpusv_facet%3DGraphics%20Processing%20Unit%20(GPU)~NVIDIA%20GeForce%20RTX%204080%20SUPER&sp=%2Bcurrentprice%20skuidsaas&st=4080+super)\n\n# Canada\n\n* [Newegg Canada](https://www.newegg.ca/p/pl?N=100007708%20601432394&Order=1)\n* [Best Buy Canada](https://www.bestbuy.ca/en-ca/collection/rtx-4080-super-series-graphic-cards/477700?sort=priceLowToHigh)\n\n# UK\n\n* [Scan UK](https://www.scan.co.uk/shop/gaming/gpu-nvidia-gaming/geforce-rtx-4080-super-graphics-cards)\n* [OCUK](https://www.overclockers.co.uk/?query=4080%2520Super&sortBy=production_ocuk_price_asc)",
    "comments": [
      "Please do not  buy these cards from Ebay, be patient, there are a lot of cards available and even the FE keeps coming in stock.\n\nhttps://preview.redd.it/hd00o6mmqsfc1.png?width=953&format=png&auto=webp&s=7eeb0ec2e220ee671b050d82994674f92e651fb9",
      "Got an FE from Nvidia. Go fuck yourself, Best Buy.",
      "I hope “Joe’s Tech Shop” on Amazon burns down in a fire. Fckin dweeb",
      "Apparently none of these assholes want my thousand dollars\n\nEdit: PNY took my hard earned moneys",
      "My 4080 Super FE will be here next week straight from Nvidia. Upgrading from a 1080 Ti. Super excited",
      "https://preview.redd.it/lpblc1id3vfc1.jpeg?width=527&format=pjpg&auto=webp&s=661ee68cbd69dc01f585c2930efb0dcbbaeea7cc",
      "\"MrReliable-USA\" is another piece of shit scalper who deserves every bad thing that comes to him.",
      "Yeah, Best Buy, your shit is fucking bunk. Congratulations,  your reserve bullshit absolutely does not work.",
      "fighting for my life out here",
      "Who's got two thumbs, is doing a build, and patiently waited for the 4080s since it was basically a 4080 for only $999 only to cave and get the $1299 slick white ASUS because he thought it looked cool. There is no logic to me sometimes.",
      "Whoever is buying TUF 4080S from Mr.Reliable USA on Amazon for 2000 dollars - you are as big a part of the problem as the scalpers. Stop it.",
      "I got through the line, It was in my cart on best buy, I had the \"item is saved for 10 minutes\" message, then as I hit checkout with 8 minutes left the page reloaded and my cart was empty and it was marked as sold out. Fuck this noise\n\n\nEdit: got one on a restock, didn't waste any time when it was in my cart lol",
      "Exactly. Scalpers are buying the cards and posting on Ebay. They will cancel their orders if nobody buys on Ebay.",
      "here we go again.. flashbacks from 2022. Why do we need to go through all this hell to order a freaking GPU?",
      "Fucking bestbuy.  I refresh right away, get it added to cart then so im waiting like it tells me to do and all of a sudden it wants me to resign into my account and keeps saying my password is incorrect.  Which is bullshit I just logged into this.  Then its sold out.\n\nEdit: Snagged an ASUS STRIX OC from Newegg",
      "https://preview.redd.it/1mjk8nke0vfc1.jpeg?width=3024&format=pjpg&auto=webp&s=7694825bd1a716f8896e22a478477f4911ac97f5\n\nGot it at the local microcenter.",
      "So this morning I remembered these came out today while driving into work... At a stop light opened best buy app and all were sold out... Except the MSI ventus 4080 super was available. Hit buy now... I'll tell the wife later, I've got the wife math all ready to go (got a work bonus, fantasy football winnings, and can sell my 3080ti for $500-600)... GGs\n\nEdit: can't believe it's only $1029. Wild since 4080s launched at like 1200-1300",
      "Leave them a bad review for scalping",
      "https://preview.redd.it/tkeugkn111gc1.jpeg?width=4946&format=pjpg&auto=webp&s=c3efbc4e991440151176921c872b6609a335a48b\n\nArrived from Best Buy.",
      "Majority of YT reviewers are so obnoxious and insufferable about the 4080 Super. It’s a $200 price drop on a slightly improved 4080. I’m not saying they should praise NVIDIA for this refresh, but I have no idea why they’re being so annoying, derisive, and negative in their over-analyzing of the release."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "rtx 4080",
      "4080",
      "4080 super",
      "rtx 4080 super"
    ],
    "title": "Finally my GEFORCE RTX 4080 SUPER SETUP",
    "selftext": "Work or gaming, it’s always a good time. 😍",
    "comments": [
      "nice setup, but i can feel the neck pain..",
      "https://preview.redd.it/wvqczm8lajue1.png?width=1000&format=png&auto=webp&s=e61fa0d5a8dd2ae2a3b683f1b617eeb47b8b43be\n\nthe first thing that popped into my head",
      "Hells yeah, enjoy!",
      "Clean PC. 👍🏻\n\nhttps://i.redd.it/hxhzjmqqllue1.gif",
      "I haven’t experienced the neck fatigue yet. I lowered the desk and angled the side monitors so I wasn’t straining to see them.\n\nhttps://preview.redd.it/rlrcah6stnue1.jpeg?width=4258&format=pjpg&auto=webp&s=6d0d11093116ff754acd004942f3991bd64e57ac",
      "Nice setup",
      "enjoy friend great feeling right ? ! looks amazing ! i used that card well first  a 4080 than i got a super when that came out , but i used it for last two years, and there is NOTHING that card cannot do, you can overclock it to 3000mhz just like this 5090 im using right now, its the same exact card as the 5080, just undervolted :) ! noww go run something on ultra settings !",
      "what monitor arms are you using? is it a triple mount?",
      "why are the side monitors so high up",
      "💀Good movie",
      "I used the NVIDIA App to OC my GPU and I feel like I’m in Ready Player One 😂 I also have an i9 CPU running with it. Makes free time very enjoyable.",
      "I’m using the HUANUO Triple Monitor Mount for 17 to 32 inch Screens.",
      "To give more  clearance space for the directional sound to travel out the speakers on the desk. Don’t know if it makes a difference or not but lowering the monitors also works.",
      "GPU - (RTX 4080 Super)\nCPU - (Raptor Lake Intel i9 14900KF)\n\nMonitors \n2 - (27” LG 4K) \n1 - (25” 500Hz Alienware)",
      "can you send me an amazon link? been looking for one that can get my screens that high above my middle monitor.",
      "I got a PNY GeForce RTX 4080 Super off Amazon in January (€ 1.151,92), for upgrading my trusty (and still great!) GeForce RTX 3080 in my 2020 gaming PC.\n\nGreat card, looking forward to playing DOOM The Dark Ages and Elden Ring Nightreign soonish...",
      "specs pls",
      "Very nice setup, im getting a new pc with that particular cpu but rtx 5060ti. What are your computer settings to help with overheating especially with demanding games. The last time i had an intel and nividia was in 22 with my laptop. Now im switching from amd back to intel everything is new to me so any advice would be greatly appreciated.",
      "Thank you",
      "You know, there is room for a mini fridge on the left side of the desk 🤔"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "rtx 4080",
      "4080",
      "4080 super",
      "rtx 4080 super"
    ],
    "title": "Nvidia canceled my 4080 Super even though I didn't ask",
    "selftext": "Hello,\n\nYesterday, I was lucky enough to buy the new RTX 4080 Super FE directly from Nvidia, and boy, I was excited. After I purchased the card, I decided to look at the receipt, and looks like PayPal changed my address to mine instead of my cousin's, who was supposed to get the card because I was going to be at work. I called customer support, and the rep told me that he would get the escalations team to solve this issue, all I had to do was reply to the email with the new address. I asked the rep if this would cancel my order because, in that case, I could just get out of work early, and they said no.\n\n&#x200B;\n\nToday, I received an update on my request saying:\n\n\"I was able to request the cancellation on your recent order. Once the warehouse confirms they were able to stop the order from shipping, you will get a notification.\"\n\nI immediately replied stating that I never requested a cancellation and asked if they could cancel this request. I was hit with a big no as the cancellation request had already been sent.\n\nI have no words to explain this, from making my day yesterday to ruining my day today. I never requested this cancellation. This is extremely annoying as a customer to ask for something and my order gets canceled because of a rep's mistake. I tried getting another one from Best Buy, but it is almost impossible to grab, even with Hotstock notifications and refreshing the page every single second. I will probably have to wait to finish my PC, even though I'm just missing a graphics card.\n\nHas anyone experienced something like this? Any suggestions? I tried to ask the rep for a higher-up to see any possible solutions to this issue, but they kept ignoring me. They just told me to wait until they put it back in stock, but they are unsure when it will be available again.\n\nMy only hope right now is that the order gets processed before they cancel it, which I doubt would happen. Otherwise, I don't know if I'll go with a 4070 TI Super or a 7900 XTX.\n\n&#x200B;\n\nEdit: Added Super to the 4070 TI \n\nUpdate: THE ORDER SHIPPED BEFORE THE CANCELLATION REQUEST. Now I have a return request, which I’ll just ignore. ",
    "comments": [
      "Someone posted the same thing yesterday. Likely oversold. Might be why everything has been delayed.",
      "Amazon \"lost\" my 4070 Super on Monday and I still can't do anything cause they keep changing the delivery date even though it has not moved since Monday...",
      "If mine gets canceled I’ll cry I bought a whole build last night",
      "First time? This is what happens with high demand. They sell too quickly and ran out. Had to cancel orders. This is actually pretty typical. I had my 4090 order cancelled multiple times before getting one.",
      "No, it was the scalations team rep that made a mistake. They told me they tried to revert the cancellation request but didn't let them. I don't know if I should trust them on that.",
      "All responses are recorded in the ticket they made so I could send the new address. I never mentioned cancellation in the ticket until the rep sent the request. [Chat](https://imgur.com/a/asLhhR6)",
      "In this type of situation it's usually best to not ask customer support for anything, and double/triple check everything on the order is right before you place it. I've also experienced trying to buy a 4090 from nvidia's website and it went out of stock as I was trying to log into my account, lesson I learned was to check out as guest.",
      "Yeah. My ti super asus got delivered but not here. Checked with ups and it got delivered to a different address across town not even remotely the same name as mine. Refund pending in my account didnt want to deal with it. Might travel 40 miles to microcenter to physically get one and not deal with the delivery bs. Been reading alot of ppls asus cards have been getting jacked or lost.",
      "Do you have a picture of the exact email they sent? Does it actually say YOU put in the cancellation request or that one was put in?",
      "Both me and my brother snagged one yesterday, they took my money and everything. We both woke up to cancellation emails this morning. I feel like I've been robbed, waited 3 months for these cards and waited in a queue for almost an hour. What a gut punch. Absolutely terrible customer service",
      "(1) I would not feel bad about ending up with a 4070 ti super.  It's also a good card, and arguably better value than the 4080, which offers ~17% more performance for 25% higher cost.\n\n(2) that does suck about the auto cancelation. I would imagine that retailers have relatively strict rules about swapping addresses post-order (to prevent fraud), so it may be that a customer support call about addresses just automatically leads to a cancelation order.  If the item does ship maybe you can contact the shipping company to change the delivery destination? That would require jumping through  hoops too, but it might work.",
      "Any chance you or your cousin live near a Microcenter? Their stock seems good and they don't ship, so unaffected by bots",
      "The ticket never included the word cancel. The rep that canceled the other was a different person.",
      "I routinely handle cases like this for orders that span from $200 through $5,000. I can tell you, it is not on the vendor to just go ahead and ship a grand or two worth of product off somewhere when the customer contact has clearly indicated a problem with taking possession of the shipment at the given address. That's how you lose a shit ton of money in charge backs or PayPal reversals.\n\n Typically the avenue the merchant has to solve this problem, especially if they have large scale warehouse shipping, is to either cancel at the earliest possible moment, or allow the parcel to ship, and then hope the shipping lead time is long enough where an intercept and address correction has time to process in the carriers network.......at added cost to the merchant I might add. \n\nIf you're gonna spend a huge amount of money on something online, have your shit organized is what my point is.",
      "They realized the cards should be selling for $1200, ohh...",
      ">My ti super asus\n\nI read this as \"my super anus\"",
      "I have an Asus Tuff OC 4080 Super that should arrive on 2/7. I was going to return it because I lucked out and got a FE 4080 Super from Best Buy after. If you don’t end up with the card I could sell you the Asus for what I paid plus shipping?",
      "Amazon is great when they the delivery service loses a package. Dont worry, just log it with the BOT. I automatically go to the chat bot when my package is a day late and it gives me a new estimate date. When i still dont have my package by that date the system has it logged and sets me up with a “replacement or refund” option. If im not doing pick ups at best buy or microcenter I always order from amazon because ive never had a issue getting a refund when its shipped and sold by amazon.",
      "Uh, 4080 Super is $200 LESS than 4080.",
      "I work for a large online retailer and this happens constantly with both PayPal and Apple Pay orders. Changing the shipping in these orders is not a click and done process, and if there is any difference in tax levied between the two addresses, the merchant cannot change the amount they withdraw from the payment that was authorized between PayPal and your issuing bank. In most cases, these orders have to be canceled and replaced. \n\n In the end it's on you to add and validate whatever potential addresses you may bill or ship to into your paypal account before you start putting in orders with merchants, who have no control over the off-site login and validation that PayPal requires. The price you pay for a more secure transaction is the inconvenience of remembering to curate another list of addresses."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "4080",
      "4080 super"
    ],
    "title": "Noctua 4080 SUPER, a beauty and a beast in itself",
    "selftext": "",
    "comments": [
      "I usually see those priced in 4090 territory. Absolutely would not be interested at that price, but you got a damn good deal. Nice card",
      "> since I *paid* also 1050€\n\nFTFY.\n\nAlthough *payed* exists (the reason why autocorrection didn't help you), it is only correct in:\n\n * Nautical context, when it means to paint a surface, or to cover with something like tar or resin in order to make it waterproof or corrosion-resistant. *The deck is yet to be payed.*\n\n * *Payed out* when letting strings, cables or ropes out, by slacking them. *The rope is payed out! You can pull now.*\n\nUnfortunately, I was unable to find nautical or rope-related words in your comment.\n\n*Beep, boop, I'm a bot*",
      "the base 4080 is hard to compare to, since they dont produce them anymore, so its a rather \"unnecessary\" comparison. the better comparison would be over a 4080 SUPER. the cheapest one, starts at 1050€, for a GIGABYTE GeForce RTX 4080 SUPER Windforce V2 16G (collected data from geizhals.at).   \nso technically I didnt pay over MSRP for my Noctua RTX 4080 SUPER, since I payed also 1050€ (tax included)",
      "Huh?\n\nNoctua 4080 super is like 1350 or 1450 or something",
      "https://preview.redd.it/qp13t5gckeyc1.jpeg?width=561&format=pjpg&auto=webp&s=a1787c0ade6245d2515562c04878d52a61f7f8f6",
      "I have been a fan of Noctua products ever since. At the same time, I feel a bit proud because its a graficscard designed by my country and since they started in the RTX 3000 Series with their first ever cards, I was Hell over heels into these graficscards. I literally live 4km away from the Noctua HQ in vienna, and their customer support is amazing. You can directly visit the place and get replacements etc.   \nIf any of you guys read this, thanks for the continious great support and service. stay awesome ;)",
      "How much is that over a base 4080s in euros?",
      "That's a steal, dude. Forget that, even a 4080 at $1000 in my country Is itself the best deal you can get. OP got lucky I guess",
      "What the hell, your card costs 1500€ in italy.",
      "Of all the 4080 super, I want this one the most, but it costs 300$ more than any other models where I live, Jesus Christ 1,450$. The Galax and Zotac that can even be bought at 1,100$. How is the price where you live?",
      "Beauty is in the eye of the beholder, because that thing is hideous lol. Happy for you though, congrats 😁",
      "Yes I meant to compare it to other non noctua 4080s.\n\nNice deal. I might get it too when i upgrade my pc.",
      "I think you misread OP's comment.",
      "I thought it was so dusty",
      "make it all white id be ok",
      "Beauty really is in the eye of the beholder huh",
      "Beauty is in the eye of the beholder in other words. Never heard anyone claiming them awful coloured fans are beautiful. Chromax or Redux fans look decent, no idea why they didn't opt for less polarising fans.",
      "LOL  \nIts the same here. But here a regular 4080s starts from $1450 and the Noctua 4080s is $1750 HAHA",
      "Noctua fans are good looking.\n\nThey evoke the classiness of a 1972 AMC Ambassador in all brown\n\nCompare to the typical clown vomit rgb wank-fest you see in PC builds, or an all-black build that doesn't even bounce enough light off of itself to really see whats there.",
      "You're entitled to your opinion, even if it's wrong."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "4080"
    ],
    "title": "Misdirection in internet discussions and the state of the GPU market",
    "selftext": "I'm a long time reader, long time Nvidia owner, slight game dev hobbyist. I lurk around a bunch in various subreddits and YouTube comments for various tech YouTubers just to keep in tune with the market and what people are feeling, and I've found that there's a lot of misleading kinds of comments that get pushed around a lot. So much so that it drowns out the legitimately interesting or exciting things happening in the market. So I thought I'd just spit out my opinions on all these talking points and see if people respond or have interesting counterpoints. I don't intend for people to immediately change their mind about things just after reading me, I hope you read a lot of people's opinions and come to your own conclusions!\n\n## GPU prices are insane\nI agree with this statement although there's a bit more to it. Traditionally maybe 10 years ago and older, graphics cards would be succeeded by newer cards that come in at lower prices. Those newer cards would seem like such great deals, and the older cards would naturally drop in price in the market to adjust for this lost demand. Nowadays, depending on where you're from (at least what I've noticed in Australia), various GPUs come down in price very gradually over the course of their generation. Cards that would launch for $1000 USD end up around $700 USD or so by the time the next graphics cards come out. This means a couple of things:\n\n- MSRP really only indicates the launching price of the products. When considering a new card, you should consider the current prices at a certain point in time, and that means everyone's opinions are temporal and may change very quickly if cards keep bouncing around in prices. For example, the AMD RX 6600 regularly hits around $340 AUD down here, but the RTX 3050 has been consistently $380 AUD. If we compared MSRP, the 3050 *should* be a lot cheaper, but it isn't, so my opinion would be the opposite of what it currently is. But your country's market may differ to, so it's good to just check around and see what prices are.\n- The newer graphics cards seem to keep coming in at *roughly* the same price to performance ratio as what older cards are at the same time. The RTX 4090 is an insane $2959 AUD MSRP, but for its price to performance, it's remarkably close to being quite linear compared to the existing RTX 3000 cards here as well. This ties into the price fluctuating mid-generation. It does make newer releases a lot less exciting, but in general they're not *bad* value, just *no better* value (again, please decide for yourself based on your own market prices).\n- Your desire for more graphics may actually be artificially pressured. This is a bit accusatory of me, but there's a lot of people all over the internet including here who definitely push that you **need** an RTX 4070 Ti or a 4080 for 4K gaming, and will cite various games that do indeed require those cards to achieve framerates above 60 FPS when running with all the settings cranked out (if I worked at Nvidia, I would love nothing more than to tell people they need 4090s). But that also assumes that people (1) only play the newest games, (2) play these games in their generally more unoptimised states, (3) don't turn down some needless settings like anti-aliasing (it irks me how many benchmark YouTube channels will crank up MSAA in their 4K tests). If **you** generally play some older titles (and I mean like 2 years ago or older which isn't that old), or you can toy around with settings a bit, a lot of these games will still run at very good levels of detail and framerate on older cards (e.g. the 2060 can still run better looking games fine if you're tweaking in the right places).\n- I do wish cheaper cards were back on the market again. There's too many price gaps in the market (the cheapest Nvidia card you can buy here is $379 AUD, and there's no AMD cards between $600 AUD and $900 AUD). The problem isn't that the 4070 is $940 AUD, it's that by the time the rest of the RTX 4000s come out, there won't be a new GPU for under $500 AUD until the prices gradually drop again, and that's a market that I feel is just underused.\n\n## 8GB of VRAM is not enough\nThis ties into the previous point a little, but give me a moment to explain the scenario. The vast majority of users as per the Steam hardware surveys run cards with less than 8GB of VRAM. You'd also be surprised that the only GPUs that have more than 8GB of VRAM right now are the GTX 1080 Ti, RTX 2080 Ti, 3060, 3080, 3080 12GB, 3080 Ti, 3090, 3090 Ti, 4070, 4070 Ti, 4080, 4090, and the last 4 Titan cards (which stops at Pascal). For every other manufacturer, this only allows the Intel A770 Special Edition, every AMD RDNA 2 GPU from the RX 6700 and up, and the AMD Radeon VII. Besides the Radeon VII, no consumer AMD GPU released before November 2020 (2.5 years ago) has more than 8GB of VRAM. Now we've had a lot of generations of cards with exactly 8GB of VRAM, but I occasionally see some comments say that if 8GB isn't enough now, then 12GB may not be enough in 2 years time! I don't think this is as pressuring a concern for a few reasons:\n\n- The handful of newer games that are pushing this amount of VRAM are just that, a handful. They also fall into one of two camps: some games like The Last of Us are abysmally unoptimised, as seen by the horrendous graphics when you turn all the settings down, but you still require to some amount of graphics power to push. Meanwhile some other games like the Resident Evil 4 remake actually run very smoothly at 1080p60 on a 1650 Super, even with the settings on the modest \"balanced\" preset, which still looks very good! I'll let you be the judge on graphics fidelity, but I do wish more people saw how good some of these newer games still look on older hardware, even with some settings turned down. If a game looks worse with the same GPU load, that's an unoptimised game. If the game looks fine or better, that's just a game with a larger window of graphics options. If you want to play a newer game, just double check other review sites or YouTube videos to confirm whether that game runs and looks fine with your graphics card, and you'll be surprised how many cases you don't actually *need* a better graphics card to play these games.\n- Crysis should be your basis of what \"ultra\" graphics means. Crysis came out at the end of 2007, and if you try running the game at 1080p and crank every setting up to its maximum, the game will try to allocate about 2GB of VRAM. 2GB sounds fairly tame these days but you'd be surprised to hear that the highest amount of VRAM on an Nvidia card at the time was 1GB on the brand newly released 8800 GT. It wouldn't be until 2010 when the GTX 460 was released with 2GB of memory, and even then, the settings would be crushing on graphics cards until personally the Kepler based GTX 600 cards. Of course we have the memes today of \"can it run Crysis\", but that's because the highest settings were very forward looking and were never expected to run on the hardware at the time. As long as the game *could* run on current hardware and still look good with some configuration of the graphics settings, that's the victory they were seeking. Ultra settings do make the game appear better historically though as people nowadays can play Crysis with the settings turned up, making the game seem much more visually impressive than it possibly was back then. I suspect newer games (and especially some features like Cyberpunk's path tracing mode) are pushing the same graphical showcase, but realistically they expect most people to tone down settings.\n- Ultra is almost always indiscernible at 1080p for high. I don't believe ultra is a realistic or practical setting in a lot of cases for new games, and especially now that we're pushing higher quality textures and models in games again (as storage is a lot faster and larger now), at some point you realistically won't see any of this detail at 1080p. I urge you, if you have a newer graphics card and a newer game, at 1080p, turn the settings down a little bit and try and spot **any** graphical faults that are not present in the ultra preset, whether it be blurry textures or obvious polygons.\n- Allocation of VRAM is not utilisation. Unused memory is wasted memory, so if a game is able to leverage more memory allocation, it probably will. One example I bring up is Doom Eternal, which has a setting that purely determines how much memory is allocated for the texture cache. It doesn't actually affect the quality of the textures, but increasing the cache can reduce disk load. Unfortunately, back in 2021, some people (I remember a Hardware Unboxed video) touted that this setting meant that 8GB of VRAM wasn't enough for games anymore. But with an understanding of what the setting does, it doesn't actually mean the game ever needed that much video memory to make prettier images, it's purely just permitting the game to allocate that much memory. Newer games have this same issue, the new Star Wars game would just allocate basically as much memory as available.\n- If your GPU had 24GB of VRAM, you'd probably want to be able to utilise it to its fullest. You may be surprised to hear that your VRAM allocation actually will change depending on your graphics card. Like how Google Chrome can work on computers with 2GB of RAM, but will consume 16GB if you had 32GB of total memory, some games are also very greedy just to reduce calls to the OS to allocate memory, and will just take as much as they potentially want (especially because most people aren't running much GPU intensive work while playing games). There are still cases of unoptimised memory usage out there (see The Last of Us) so keep an eye out.\n- Mentioning again, this only really matters if you play games brand new. I'm going to be critical here but a lot of commenters on this site weren't alive when Skyrim came out, and haven't played it. I encourage you, even games that are 2 years old, there's a lot of great experiences that aren't the newest games, so don't let people convince you you need to get a brand new RTX 4000 card if there's a good deal on an older RTX 3000 card if you're not going to be playing a lot of brand new games like that.\n- To be critical of Nvidia, I do believe they're pulling some market segmentation to separate their higher clocking GeForce cards from the higher memory workstation cards for AI. This has meant that VRAM is kept rather lean (and I do agree we're getting to a weird point where some games would run fine if they had a bit more VRAM, and I especially agree it's not good to be paying that much for a GPU over a competitor only to have a clearly faltering use case), but I'd still say in general they're still workable. I anticipate we won't have a lot of these scenarios  soon as newer games may try and push more graphics work (most likely more raytracing passes, newer RT games do so much more work than Battlefield V/Shadow of the Tomb Raider) and will run a bit more aggressively at ultra on even the cards with more VRAM. That being said, I do believe with the rise of AI we'd find more value in cards that naturally are able to perform both graphics rendering **and** AI training/execution with high amounts of VRAM, and I do desire more VRAM in future cards **without** trading off the rest of the performance. We do run into a catch 22 though where the cards are going to become more expensive because of this though, so all I can desire is that we have plenty of options of cards for different use cases, and enough competition from AMD and Intel to drive these prices down.\n\n## xx60 class card\nThis sort of ties in with the price but this is a particular comment I see copy pasted so much around. **The name of the card means very little, especially to us.** We're in tune, we're aware of how well these cards perform, and ultimately what you should be comparing is cards at a certain price vs. their performance. We don't complain that in the past Intel i3s had half the core count of Intel i7s, and now they have a sixth so therefore they're Celeron class CPUs, and that's because we see how much relevant performance you get for the price. A current Intel i3 can definitely get more than half the framerate of an equal machine with an Intel i5, and that's why we still consider an Intel i3 somewhat valuable (although it's fair to say a little bit more money gets you a meaningful performance boost too). Similarly for GPUs, I saw that the 4070 Ti (which performs in games about as well as a 3090 while using a bit less power), when it had dipped to $1200 AUD here, seemed like a solid good card. Yes it is under half the CUDA cores of a 4090, but it's also well under half the price. At the end of the day what matters is what you can do with the card and whether it's worth that price.\n\n- The last xx90 card before the 3090 was the GTX 690, which also was an absurdly expensive card. This was back in the dual card days where it was effectively two GTX 680s in SLI, but to abstract away from that, we wouldn't complain that a GTX 680 was only half of the flagship's core count because in the end it was also half the price!\n- The 3090 was really bad value when it came out, so even though we may say that the 3080 wasn't as stripped down to the 3090 as the 4080 is to the 4090, the 3090 was also purely a chart topper product and wasn't really worth it, especially if you played only games. This has adjusted a fair bit before the stock for these cards started to diminish.\n- The Titan cards effectively were what the xx90 cards are now, and I don't recall a lot of places considering those cards the same as cards like the 980 Ti and the 1080 Ti because they had that unique name to them. Just like the 3090, they were also very poor value if you considered just games.\n- The 980 Ti and 1080 Ti were anomalously good value and as much as I'd love for cards like that to keep appearing, I think someone at Nvidia saw that they can get more profit out of charging more for cards of that calibre. Nvidia is a publicly traded business, and their one goal is to make as much profit as possible. I don't want to apologise for Nvidia, and we as consumers should do our best to only buy things that are good deals, but I think we should recognise that the 1080 Ti was *too* good a deal in our favour, and we'll only ever get a scenario like that again if there's some proper competition happening in the GPU space again.\n\n## Upgrading from a RTX 3000 card\nDon't! A lot of people here think they need the latest and greatest every generation, but in reality you don't! This ties in with the artificial desire for better graphics too, you're not missing out on much by not being a first adopter of DLSS FG technology, just like you're still not missing out even if you don't have an RTX card yet. Upgrade when you personally want to run something and you're unhappy with the performance. Usually that happens if you've upgraded your monitor to a higher resolution or refresh rate and you want to provide as many frames as you can to that monitor. But very rarely will a new game come out that just runs **and** looks worse than previous games, and as mentioned above, this is quite often due to just poor optimisation in the launch.\n\n## YouTube channels being treated as gospel\nI watch a few different YouTube channels that talk about tech (Level1Techs, Gamers Nexus, Derbauer), and the best thing all these channels provide is different areas of investigation, allowing the viewer to come to their own opinion about certain hardware. It's impossible for one outlet to actually cover all the nuance of a GPU in one video, even if they try and throw a lot of gaming and productivity benchmarks and comparing various graphics cards. For example, one thing I really enjoyed about Derbauer in the recent CPU releases is that he tested the various processors at different power levels and showed how efficient **every** new CPU could be when you drop the power levels. Obviously some were more efficient than others but it was a clear counter point to other reviewers that would put pictures of fires in their thumbnails and call the CPU a furnace. I do get frustrated a lot when a reviewer comes to the wrong conclusion after lots of valid data, but I do think as long as people talk very openly about their experiences and these reviews, people can figure out what's correct and what's not. Unfortunately there's a lot of comments that go along the lines of: \"*X reviewer said this and I'll copy paste it here.*\", and I get it that 100K subscriber YouTube channels seem more trustworthy than random comments on Reddit, but I think it's very easy for single opinions to fall into the trap of believing something just because one person said it. And, as a general Reddit and internet pitfall, we also can't blindly agree with single comments (lots of paid advertising and bots on the internet), so I think the best thing is to read multiple sources; trust but verify as they say.\n\nI hope you enjoyed reading my long soliloquy there. I just wanted to jot everything I've felt in the past few months about the market, discussions, and the games themselves. Let me know if I'm really wrong on anything because I want to understand what everyone's thinking a bit more. TL;DR, don't get upsold on hardware you don't actually need.",
    "comments": [
      ">The newer graphics cards seem to keep coming in at roughly the same price to performance ratio as what older cards are at the same time. \n\nSee, I consider that a problem. I *expect* new generations of hardware to be faster for the same price, as it used to be for decades, and still is for any other kind of hardware. \n\nI'd guesstimate that GPUs double performance roughly every 8 years, now imagine the price would do that as well...",
      "> a lot of commenters on this site weren't alive when Skyrim came out\n\nSkyrim came out less than 12 years ago. So you think this sub is full of 11 year olds?",
      ">8GB of VRAM is not enough\n\nPrepared to be downvoted into oblivion.\n\n>Unused memory is wasted memory\n\nThis is not true. Not for system memory or video memory.\n\n>Yes it is under half the CUDA cores of a 4090, but it's also well under half the price.\n\nThis is a silly comparison. The 4090 is a halo product Nvidia knows they can charge insane amounts of money for because it's the best of the best for GeForce branded cards.\n\n>YouTube channels being treated as gospel\n\nAgreed. Some tech reviewers are only a little more knowledgeable about hardware than people on Reddit. [UDF Tech's video](https://www.youtube.com/watch?v=jbS2IGK8ttw) on the 4070's VRAM was cringe.",
      "Tackling 8GB VRAM debate by comparing last generation compatible games like RE4 remake is plain stupid. By the end of this year, almost all new games will stop offering last gen support and both next (current) gen consoles have 16GB VRAM for a lot more detailed textures and shaders.\n\nAt no point should a $500+ GPU be limiting factor for growth and advancement of gaming industry. Ironic that after 8 years of PCMR hating Xbox/PS4 for holding gaming back, now we have similar copium being shared in Nvidia subreddit of all places.",
      "Sure, **but this is exactly how nVIDIA gets away by selling you less for more**.\n\nWhy sell the 4070 as 4060 Ti for 499$, when one can bump up the name and thus the price by 100$, leaving it only 30% faster than 3070 and also 20% more expensive? People will buy it and defend it online anyway, isn't it? So let's do this.\n\nUsing this tactic for almost 15 years, by the way, we reached a point where the 4060 is going to be about **4 times** worse than the flagship, **whereas GTX 480 - the flagship back then - was only 50% faster than the 460**.",
      "\"YouTube channels being treated as gospel\" \n\nCompletely agree with this last point. Rather than use various online publications and youtube videos as well as your own testing (if possible) to make a final purchasing decision, people seem to just point to one popular channel using one specific method that may not be how you'll use the product at all.",
      "The reason why 8gb VRam isn't enough  lies in the near future. So it has to be partially speculative, because it will depend on the game developers how it will creep in over time. Logically they will design their games around the specs of the mainstream gamers to not limit their audience by game specs that are too demanding.\n\nBut when you look at how modern game engines make it easy to  design large worlds with a vast amounts of highly detailed textures the developers will go to the edge of what is feasible. Look up Unreal Engine and Quixel Bridge and you'll be amazed. Which means you'll be forced to reduce quality settings much more often due to the lack of ram, while the gpu would be able to handle more if fewer complex graphics were scattered all over the place.\n\nSo, will the 16gb 4060TI be overkill? Probably. But it will still be better to have a few gigs dormant on anything that goes above 8gb, than being short a few gigs.",
      "So, not “a lot” then?",
      "3080 launched at €699, 4080 launched for €1399. It is fucking insane that some people seem to genuinely believe there's nothing wrong here.\n>what you should be comparing is cards at a certain price vs. their performance.\n\nExcellent idea! I choose the 4070 - same performance as a 3080 for €659. What the fuck are you people smoking? That's a €40 discount more than 2 years after release. Please explain to me how this is even remotely acceptable.  \n\nOP is the one misdirectng.",
      "The issue is the internet has become one big echo chamber. \n\nEveryone pretty much has to agree with the status quo.\n\nWhy because if you don't the legions of sheep on social media/internet will attack you. They will say your untrustworthy and your own fan base will turn on you. These people putting out content are not massive multi billion dollar companies they live off sponsors and merchandise sales from there fans.\n\nReality is we have gone from companies paying for endorsements to the viewer doing it instead deciding what the narrative is before its even spoken.",
      "He has his own biases. Like during the PS5 analysis where he claimed it was as fast as a GTX 1060. Crazy, and definitely influenced by how pc gamers look down on consoles. Or when he said no one uses the 20 series, despite it having a larger marketshare than equivalently priced 10 series cards. Good albeit useless techical breakdowns. I've stopped watching most of his stuff a long time ago, he comes off as a huge snob. If I want benchmarks, other places do it better with a better selection.",
      ">The handful of newer games that are pushing this amount of VRAM are just that, a handful\n\nthats today, lets talk again in six months. console vram specs will dictate future development, and if possible devs will not go through the hassle of porting a game optimized for 12.5gb to run on 8gb\n\n> Ultra is almost always indiscernible at 1080p for high \n\nthis will not be true for future ports, there will be sub 8gb vram textures, that look disgusting, and then there will be settings that look good, but exceed 8gb.\n\nTLOU is the worst example for this, watch the digital foundry livestream, high textures are almost unplayable on an 8gb card and medium looks atrocious",
      "Of course it doesn't meet the standards, because compared to the card it should have replaced in terms of specs, the 3060 Ti, it's 50% faster and has 50% more vRAM for **50% higher price** ***more than 2 years afterwards***, DLSS3 and the new features are not enough to me **for such a long wait**. For instance, GTX 1060 at 249$ was just as fast as the 980 at 549$ in less than 2 years difference, that's progress, that's how PC gaming was back in the day - of course, not anymore.\n\nThis is where the \"separate multiverse\" starts to make sense: you look at the perf/$ improvement and start to see either the **stagnation or slow improvements - which is what ultimately matters to the customers, outside naming itself, which on its own, is irrelevant**.\n\nHowever, at this moment you can start to look under the hood in the \"separate multiverse\" and you start to realize **why** this happens: the new cards were supposed to be named one tier lower and at that point, the perf/$ improvement would have been much better. Hence, if the 4070 would have been a 4060 Ti (optionally) and sold even at 499$ (mandatory), let alone 399$, as pretty much all reviewers said, it would have been a totally different proposition. \n\nFor the same price as the 3070, you would have gotten 30% better performance, 50% more vRAM and Ada goodies -> yeah, much better gen-on-gen lift.",
      "I believe the reason VRAM is such a hot topic now, is because the amount of VRAM you get compared to the GPU core it's self, are miss matched.\n\nHaving 8GB on a card would be fine if the GPU core could only put out about 30 FPS anyway. But with cards like the 3070 for example, you can get FPS on some games around 100+ when you're within the VRAM limitations. But as soon as you go over the 8GB limit, you're slammed all the way down to, let's say 20fps and it stutters like crazy.\n\nIf someone only has a monitor that outputs 60fps. They are going to want to turn up the settings untill they can't maintain the 60fps anymore. But if they hit the VRAM limit first, they then have to drop the settings again and have utilisation around 50%. At that point I'd be pretty pissed that I spent all that money on a GPU that I can only use about half of its capabilities simply because of VRAM.",
      "The most frustrating thing about the 8GB of VRAM debate is people straw manning the argument. Can cards with 8GB physically run these new AAA games at settings that look good?\n\nYes.\n\nWill 8GB of VRAM start choking cards at high or max settings on those games? \n\nYes. \n\nSo at that point it all comes down to what your performance expectations for a card are. 8GB of the RX 6600 and RTX 3050 is totally fine. But cards like the 3070Ti are powerful enough and expensive enough you’d expect them to be able to max out the game and play at good frame rates. And you could…if it wasn’t for VRAM. You shouldn’t have to be dialing back quality settings on a $600+ card you just bought to stop games from chugging due to VRAM.",
      "I think a lot of it lies in the fact that we have a lot of people who live in the \"Ultra Culture.\" People who think that turning down the settings means their card is all of a sudden not good enough. The 3070 itself is a decent card, granted you're willing to live with running everything at high settings at 1440p. The 8GB GPU market is still large, so game dev's aren't going to just release games that alienate one of the largest user bases in PC gaming. I don't think we'll see a dramatic shift in VRAM usage until 12GB+ becomes the new \"mainstream\" number, and I firmly believe we're very far away from 16GB being mainstream.\n\nI've had this very question asked me of when I responded to a forum post with HUB video showing 8GB vs 16GB stating that \"You can always just turn down the settings to high and still nab far better frame rates and IQ than you'd get on any console,\" and the question I believe was \"Why should we have to?\" Of course my response to them was \"because it's the nature of PC gaming. When you reach a certain point with graphics, older hardware, especially older hardware that was in the mid-range when it was brand new wasn't meant to maintain great performance with maxed out settings in AAA games for 4-5 years, it was meant to last a good 1-2 years before you had to seriously start messing with the settings, and expecting any more from a mid-range part is asking too much.\" \n\nSo, to surmise, it's people's, and these Tech-Tubers who insist on using Ultra settings as the go-to experience for gaming, and the stigma with having to lower your settings comes from the people who probably haven't been gaming on PC for a long time. \n\nAs someone who has spent 21 years gaming on PC, I've come to accept that I can't always have Ultra settings, no matter how much I try to will it into existence, but high isn't bad either, in some cases playing on high settings can be just as visually good as Ultra with much better performance, and when you consider that most consoles can't even run these settings to begin with, at anywhere near the frame rate that a mid-range card like the 3070 can means I'm already getting a vastly superior experience even if I have to tone it down a bit.",
      "One specific channel, ur argument is wrong because everyone is saying 8gb is no longer enough EVERYONE",
      ">   GPU prices are insane  \n I agree with this statement although there's a bit more to it.\n\nThere isn't much more to it other than the simple coincidence of the mining craze happening at the same time as COVID19 lockdowns that caused shortages of electronic components. And that caused shortages of GPUs/CPUs etc.\n\nThese two factors together lead to the GPU prices skyrocketing, GPU makers and sellers saw that people buy the GPUs regardless of the price, and we are not talking about just miners. When you're a GPU maker and you see that your \\~$800 card goes out of stock nearly instantly for almost double the price, you start to question why sell it for 800? Why not increase the price for the next generation... And here we are today :)",
      "In the end of the day, changing the price can make or break the product. And since current GPUs are overpriced, they are broken products.",
      "\\+1. If the price per performance ratio were constant we would be boned. A 486 33Mhz CPU cost $1,000 in 1990. If price per performance was held constant a modern CPU that cost $300 would cost over $100k!\n\nThe GPU industry scaling linearly is just a money grab that took advantage of the perfect storm of a confined market due to increased demand / reduced supply from supply chain issues / further reduced supply from due to crypto miners / more further reduced supply due to greedy scalpers."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "rtx 4080",
      "4080",
      "4080 super",
      "rtx 4080 super"
    ],
    "title": "New Build! (RTX 4080 Super)",
    "selftext": "Just got this new PC built!\nIn the rig:\n-RTX 4080 Super 16GB Gigabyte Gaming OC\n-Intel 14th Gen i9 14900k\n-64GB (32*2) 6000MHz G-Skill Trident Z5 Neo RAM\n-ROG Strix Z790-H Gaming WiFi Mobo \n-1050w Cooler Master PSU Gold FullMod\n-2 x Samsung 990 Pro 2TB\n-NZXT Kraken 360 AIO\n-NZXT H7 Flow case\n\nGonna upgrade it's aesthetics real soon!",
    "comments": [
      "Holy god that looks sick",
      "Great PC, hope you enjoy it.\n\nHoly cow, that GPU heatsink is T H I C C",
      "Awesome build! Looks sleek!\n\nI don't understand why people go for the 14900k though.",
      "what are the rgb values you're using? looks sick!",
      "Dont get sad, 3080 Ti still can kick ass!",
      "Yesssirrr!",
      "Dual boot or pure Hackintosh? :)",
      "Will get that then!",
      "Very much so",
      "Hehe, pure Windows 11 with MyDockFinder 🤫",
      "Oh, I see! Nice.",
      "Damn and here I thought my PC was good was a 3080 Ti and a 5600X. Sick build bro. Enjoy it :D",
      "super clean",
      "i have the same mobo super cool",
      "Nice build🔥did the board come 14th gen ready?",
      "Sexy, Sexy, Sexy! Nice job!",
      "https://preview.redd.it/nzawewyt1i9d1.png?width=4032&format=png&auto=webp&s=40b646f690f69f42f671c9c14d137ec5997e8ea5\n\nI guess we're sharing the same case :D",
      "That is beautiful, Dude.",
      "Why is that? Unnecessary?",
      "Yeah I opted for the 14700k in my upgrade because I felt that paying 200 bucks more for 5-10 percent more performance was not worth it plus there was just too much power draw and heat. With all the problems people are having with I9 processors I am glad I went that route."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "4080",
      "4080 super"
    ],
    "title": "Just got myself a RTX 4070Ti Super, Upgraded from 2080Ti - super happy",
    "selftext": "Upgraded to 4070Ti Super from 2080ti and extremely happy. Performance uptick of 2-2.5x and extra vram is sweet\n\nI do abit of gaming, 1440p and a lot of productivity in CAD (solidworks) so extra VRAM for CAD was more then welcomed. \n\nI was thinking of 4090 or 4080 Super but really didn't see the point - the exponential cost increase vs. performance where I am on 1440p - for me its the sweet spot especially for productivity made absolutely no sense. \nI'd rather go upper mid range and upgrade more frequently to have the features rather then pay out of my nose for something that I will not take advantage off. \n\nReally I don't see any titles now or within 12-24 month period that this card shouldn't handle on max in 1440p\n\nEspecially for CAD I need best CPU i can get (i9-13900k wins for Solidworks). GPU VRAM is the key",
    "comments": [
      "It's crazy what has happened to the GPU market. an $800 GPU is an ***upper mid range.*** \n\nBut yeah, 4070ti Super was a good choice for 1440p and your productivity. might not be the best price to performance, but a solid 1440p ultra GPU nonetheless. Glad you are liking the new upgrade.",
      "Idk why anything other than a 4090 is \"midrange\" as far as im concerned this card is a fucking hoss",
      "Because 50/60 is supposed to be entry level while 70 is midrange. 70 is now priced like enthusiast tier.",
      "Are you super happy or supper ti happy?",
      "Congrats dude! Just ordered a 4070 Ti Super to replace my 2070 Super as well and glad to hear you’re very happy with it.",
      "I am waiting for the 50 series ☺️",
      "The timeframes of the bf games you mentioned dont match up with the cards, just saying.",
      "I am waiting for my 4070 Ti SUPER! Glad to hear that you enjoy it. Many will disagree but I think it's the best price-to-value Nvidia card right now because of 16gb vram. If you stick to it you won't regret those extra 4gigs in the future, and if you consider selling it in 1-2 years I assume it will have a good resell value.",
      "Came from a gigabyte 2070 super as well. What an upgrade..youll love it",
      "Same waited this long I can hold out a bit longer on my 2060 before upgrading gonna be a massive upgrade when I do.",
      "According to Nvidia 4080(Super) & 4090 are 4k capable so upper higher range and lower higher range, but the 70 series are 1440p so upper mid range and mid midrange and the 1080p 60 series is there too. I'm not sure why it matters though as the 4070TI Super is clearly 4k capable at any modern game if you can tolerate \"just 60fps\".",
      "It's just a name though. I think what people aren't realizing is that the goal post has moved up quite a bit over time. At the time, the \"cheap\" flagship 1080 Ti was good for maybe 100 fps avg at 1440p in BF1. Meanwhile, a 4070 Super today can do more than that at 4K in BF5. If was called the 4080 Ti and it was the best available, I bet people would love it lol. \n\nI paid a lot for my 4070 Ti, but it also delivers the best relative performance I ever had. I bought midrange cards for most of my gaming \"career\" and even day one, those cards always had you compromise in some games to get good framerates. Comparatively, the 4070 Ti feels proper high end in performance where I'm checking if I can hit 120 fps rather than the 60 fps of the past. That's even before the fact that I'm gaming at a higher resolution now.",
      "Well, I don't know what you want me to tell you. AMD is not keeping up and that's just the reality we live in today. A 4060 Ti would basically double your current FPS and adjusted for inflation, it is actually cheaper than the 2060 was at release. If +100% fps for less is not good enough for you, I don't think anything will.",
      "Let’s be honest, the 4070 Ti Super is very much a high end card. $800, fully capable of running basically any gaming at 4k, stronger than any card ever released from a previous generation except perhaps 3090 Ti (close one). Hope you enjoy my man.",
      "Thats nothing. I upgraded from a 5090 super omega to a 4070 super.",
      "Word. Bought a 970 for $299 around launch. In today's US dollars , calculated for inflation, that's $385.",
      "> But also don’t fall into looking at Ultra settings. Nvidia uses Ultra settings to market the cards. When in reality GmHigh + RT reflections is indistinguishable from Ultra RT even and you get way better performance.\n\nThis has been one of the biggest changes when it comes to PC gaming.  In the olden days there used to be pretty significant differences between medium/high/ultra settings.  In most modern games I've played, medium settings are pretty shockingly close to what you get in ultra.  Games just look so good these days there are diminishing returns.  \n\nThe way people chase FPS these days is different too.  Anything over 60 used to be considered great.  Now I look at benchmarks and the games are running at 300+ fps lol.  I get that in some games that might matter, but it's pretty over the top.  We're paying $$$ for some pretty edge case performance.",
      "Well, unless you have been living under a rock, you should know that inflation has been crazy all over the world these past years. Everything has gotten more expensive. My condo has nearly doubled in value and some groceries items here have straight up doubled in price or more too. This isn't strictly an \"Nvidia gouging people\" problem, though obviously they are not helping.\n\nAlso, need I remind you how unattainable the 3000 series was for much of its life time? Insane pricing due to mining and little to no stock for weeks/months at a time. The MSRP was basically bullshit. The 2000 series wasn't super great value either. I just don't buy the \"it was fine before the 4000 series argument\". Shit, at least I can actually buy a 4000 series.\n\nDespite apparently being the worse value ever, the 4070 Ti that I own has by far been the best graphics card that I ever bought. Feels more high end than my 2080 did at the time and definitely more than the 1070 back then. I don't think it was a good deal or anything, but I paid more and I got more so I got my money's worth as far as I am concerned.",
      "I upgraded from a 4090 to a 4070 super",
      "You never know with this stuff, last decade been very hectic with crypto and COVID. Prices can always rise if nvidia decides to.\n\nAlso came down with conclusion that we only get so many seconds on this world. Not going chip out on 200€ to wait a year to be able to play some games I want to.\n\n\nBut to be fair most of the time Medium/High + RT Reflections looks indistinguishable from Ultra RT at way higher performance. So if my card can still run at those mentioned settings I am not upgrading."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "4080"
    ],
    "title": "RTX 5080FE",
    "selftext": "Was lucky enough to get one on the last Best Buy drop and came quickly. Super excited and happy, upgrading from a 4080 which I’ve already sold to cover costs and this thing will absolutely be getting worked daily. Build complete for now. Might go small form factor in the distant future. This case was an interesting purchase that needed to fit a gigabyte 4080 OC Eagle originally but my pockets are depleted for now. Super content for years to come.\n\nRyzen 7 9800x3d\nRTX 5080\n64gb Ram 6000mhz cl30\nAsrock X870e Nova WiFi \nCorsair 850x \nArctic Liquid Freezer III 360mm\n\nThank you, \n🫡\n\n",
    "comments": [
      "I have the 5080 and have no issues. I downloaded a program from tech power to verify the ROPS just in case. You are going to have a blast with that thing. 😀",
      "What a cat",
      "Good looks, just checked, 112, they’re all there.",
      "Congratulations 🤝 I have same 5080 fe and 9800 x3d",
      "How did you get it!!? I tried 2hrs and was never able to get it in the cart! Computer browser or mobile browser or app?",
      "I was in line for it several times, but no Bueno. Was trying to get one for my buddies birthday, visiting him next week 😭",
      "mine came yesterday. such a gorgeous card.  are you using a bracket on it?",
      "I got mine on the Mobile App. Been trying to buy from the Best Buy drops for 4 months and finally got one last week.",
      "Just Downloaded Expedition 33, been waiting to play this 😭",
      "Got one from the same drop it gets here soon! So excited!!!",
      "Condolences, hopefully it’s a great birthday tho!!",
      "Woohoo!!! What game are you going to try out first?",
      "Outstanding! We’ll have fun homie, summer just got allot sweeter for you. 😀",
      "Where are your TAXES! I want no taxes!\n\n![gif](giphy|3o9bJX4O9ShW1L32eY)",
      "Where do ya'll get FE cards? Is it exclusive to the US market? I think they look stunning but can't find any.",
      "now you need to watch out for assrock to not fry your cpu",
      "🫶🫶🫶🫶",
      "Google falcodrin discord. Setup notifications and you can get notified when drops happen / are happening soon. Thats how I got my 5080 FE from the Nvidia marketplace last week.",
      "Used HotStock, I’ve gotten 9800x3d, 9070xt and now this 5080, it’s all timing",
      "NVIDIA dropped on their website a couple days before , I’d missed that drop, I had a feeling they were going to drop on Best Buy soon but it was honestly a coincidence that I was awake and on my phone when it did happen. HotStock app btw"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "rtx 4080",
      "4080",
      "4080 super",
      "rtx 4080 super"
    ],
    "title": "Anyone know if this is a safe bend on the 12VHPWR cable + Build Showoff",
    "selftext": "Specs: \nCPU: Ryzen 7800X3\nGPU: RTX 4080 Super FE\nRAM: 32GB XPG Lancer ROG 6600MHZ 32Cl\nPSU: Asus Rog Thor Platinum II 1000w\nCase: Phanteks G500A",
    "comments": [
      "4080 and below aren’t affected by burning it’s usually 4090",
      "You are already better off than most people just by vertical mounting.",
      "4090 uses less power than the 3090/ti did.  So it's really all about how hard nvidia decides to push the Blackwell architecture.  With no competition at the high end fro. AMD, I think it's an easy call to reign in the power consumption and make a card that is *only* 30-40% faster, but is relatively tame in terms of power. As opposed to one that is 50% faster but consumes 600W.",
      "You're technically still within the \"no-bend\" area, but these individually pinned cables are FAR less problematic with bends compared to the adapter cable which you absolutely don't want to bend within the first 30mm off the connector. \n\nIf you want to be absolutely, 100% safe, then just release a little tension and let it bend about 1cm further up the cable. But 99.9% you won't have any issues as it sits right now.",
      "I hope you're right. TBH, my new 4080 never uses more than 300W and itis ridiculously quiet. Don't think the fans have been at more than 50 per cent.\n\nMy 308Ti took 345W.\n\nI've had to up my anxiety meds, though... 🫣",
      "5090 will ship with a complimentary fire extinguisher.",
      "Thanks. Just paranoid since youtubers were also talking about how the actual pins inside the housing could move when repositioning or bending the cable which lead to the shorts.",
      "I am right all the burned connectors are from 4090’s",
      "4090 with the 16 pin & 7950X3D, 64GB DDR5\n\nhttps://preview.redd.it/u1gy4m2pnshc1.jpeg?width=3000&format=pjpg&auto=webp&s=55b24ea8eeb7998fb44b250de04dae3e71d39b10",
      "If it's over $1000 it's getting treated like a baby.",
      "TDP is just an artificial maximum limit the manufacturer sets. It doesn't tell you anything about actual power draw. You can check the reviews with actual power usage numbers to see the 4090 draws a lot less than the 3090Ti.",
      "Seasonic had an instruction sheet with the 12vhpwr cable that they sent me that says not to bend closer than 30mm from the plug and not to go more than a 90 degree bend .",
      "You and I have very similar set ups, looks bad ass btw. My cable is just as bent as yours and have had zero issues. 4080 runs pretty quiet.\n\nhttps://preview.redd.it/lilwy635q1ic1.jpeg?width=2268&format=pjpg&auto=webp&s=0ba3c73500e889dc70068f67a622f33faa0ff935",
      "Should be fine, also note that AMD CPUs aren't optimized for anything above 6000Mhz, but you should be fine other than that. Have fun gaming!",
      "Too much power the 4090, cant imagine what 5090 will happen",
      "Well it’s a 1000 dollar GPU and it’s also a clean looking build so I wanted to share ¯\\_(ツ)_/¯",
      "This. Ampere cards would run right up to the tdp limit and then bounce off it constantly under load.  And they would instantly consume any extra juice they got by raising the limit.  Ada is very different. Most 40 series cards run below tdp at stock settings and are rarely power limited (voltage is often the active limitation on their performance).",
      "first pic is tech porn, at least for me :)",
      "https://preview.redd.it/5qy9y4mgkzhc1.jpeg?width=3024&format=pjpg&auto=webp&s=13a53ba1c31e410e75ae858765bb1f53c78c4f97\n\nIt’s fine mate ✌🏾",
      "Shouldnt matter anymore you have a 4080 Super those dont have th old H+ connector that burnt. They have a revised H++ connector that will just turn off, if it not seated properly"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "rtx 4080",
      "4080",
      "4080 super",
      "rtx 4080 super"
    ],
    "title": "Digital Foundry: More Price Cut Than Upgrade: Nvidia GeForce RTX 4080 Super Review - Is The Price Finally Right?",
    "selftext": "",
    "comments": [
      "Neither is good. The 4080 at $1200 had worse price performance than the previous gen.\n\nAnd at $1000, it's still a minimal generational improvement. It's 50% faster than a 3080 while costing 43% more.",
      "So, Looking at this title I read as it says: the performance to cost bar has finally been returned to acceptable levels.\n\nThen I think:\n\nSo all those early adopters of the 4080 are getting 99% of the performance but got to own their card for 14 months and only had to pay a 200 dollar premium? \n\nI would rather have the extra year of ownership.\n\nUnless there is some hidden feature that makes actual gains in performance (gotta be 12-15% to make sense)....why is this good? its bad, very bad. Nvida can release cards with 2-3% gains more than a year after and charge similar prices...nuts.",
      "it's crazy that while cpus also had price increases over the years, they still relatively stayed in their tiers and generational improvements are more or less worth it, but gpus are just fucking out of whack when it comes to that balance",
      "I didn’t need a new GPU a year ago, now I needed a new GPU, I was ready to buy 3 weeks ago when the rest of my build was put together so I weighed my options.\n\n $720 7900xt, $799 4070TiS, $999 XTX, or $999 4080S. At 3440x1440p playing AAA games I picked the 4080S. \n\nHad my been, $720 XT, $799 4070Ti, $999 XTX, or $1200 4080 I would have either taken the XT or XTX. \n\nThe price cut matters for new perspective buyers. \n\nIf I could have waited for the 5000 series I would have but my gpu just couldn’t play the games I wanted to play.",
      ">relatively stayed in their tiers and generational improvements\n\nno, cpus have much lower progress than gpu.\n\nAlso i feel like the \"generational\" uplift discussion completely disregards other features, like significantly better RT perf and DLSS\n\nLike people keep saying: well RT is only useable when it the framerate doesnt drop as hard. and then when they improve rt more than raster people still dont mention. Despite it being used.\n\nLike i am not advocating for these prices, but i feel like only looking at raster is an outdated metric slowly.\n\nI mean even HUB look at RT-value recently and they are not pro nvidia, considering some of their claims.",
      "I think the major two things are overall cost of GPU production has increased, the whole mining thing causing a massive shortage in 2020 gave mfg an excuse to jack up prices and then overall GPUs have a much more dramatic effect on video game performance and people like to have dick measuring contests over that and thus will spend as much on GPU as possible and skimp on CPU/RAM etc.",
      "They are the same thing. FSR 3 is FSR 2 with frame gen capabilities.",
      "have you heard of intel's 14th gen cpus? or basically their entire stack?\n\nand these new super cards do not represent a new generation. Nvidia is not marketing this 4080S to 4080 owners...\n\nI'm not sure what people were expecting with the 4080S once the specs were published",
      "Sure if you look at it that way BUT you still paid $1200 for an 80 series card.. no thanks.",
      "Well:\n\n1) the games not optimized the same on pc vs console.\n\n2) 3440x1440p is not the same as 1440p\n\n3) dlss or not at native 1440p and upscaled 1440p with the lowest possible settings the game was physically not playable. Sub 20 fps. \n\n4) the 2070s may be roughly equivalent to a ps5 but the optimization of many pc games is not equivalent \n\n5) that’s one example other recent games played ok but with lowered settings, playing on an OLED UW with reduced settings and lower frames just isn’t a great experience. Pc gaming beyond 1080p is an expensive hobby, if you’re going to pay for it why shortchange yourself?\n\n6) the performance was not to my liking, the 4080S is an absolutely insane upgrade and made my experience night and day better. 0 reason to wait over another year for a currently unannounced product. If you play that game you’ll always be waiting as there’s always a new product around the corner",
      "$200 price drop is very bad, got it.  People will whine no matter what the fuck happens.",
      "kinda funny how above you complain about nvidia here  but still support them by buying their overpriced cards. Maybe they are not so overpriced after all? and then you even bought a 4080 lmao.",
      "Love DF but more interested in seeing a video on CP2077 2.11 patch to show if the new hybrid core settings actually finally show if they do anything other than just consume a ton of energy.",
      "How so? They’re nearly equivalent in price excepting a couple instances of the the XTX having ~$40 coupons, with the 4080S outperforming the XTX by 20% across all resolutions in RT and underperforming by only about 3% max in rasterization. All while using ~50W less. IMO the 4080 is the one to buy at the $1k price point (3rd party AIB prices not so much).",
      "$699 in September 2020 dollars is $824 today",
      "The problem with this guys statement is that: yields improve exponentially. To the point of doubling the number of fully operational GPUs that are yielded from the same costs of input. \n\nNvidia is asking you to turn around and take it while they drop production costs by 50% and giving you a less than 17% discount. \n\nlol…This.",
      "blud said \"🤓if it was me i would've waited a year and bought XGPUTHATDOESNTEXISTANDHASNOPRICEPOINT\" dude, you've got me convinced, i need a gpu now but i might as well wait it out and have awful frames on the games i want to play for another year",
      "Got a FE",
      "The 4080 being priced at $1200 at the time was very likely intended to drive people to the 4090. \n\nThought process being if you were gonna shell out $1200, what’s a few hundred more for the top.",
      "I got major stutters and had to turn it back to auto"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "rtx 4080",
      "4080",
      "4080 super",
      "rtx 4080 super"
    ],
    "title": "Rtx 4080 super gigabite aero i7 14700k",
    "selftext": "Been 4 years since i made my last pc the specs are the following \n\nCase HYTE Y60\nCPU - I7 14700k\nGPU - RTX 4080 Super Gigabyte Aero\nRAM - 64 GB DDR 5 6000 MHZ HyperX Fury Beast \nMotherBoard - Asroc Z790 PG Sonic\nCPU Cooler - Corsair H150i Elite LCD",
    "comments": [
      "GPU be like: Choke me daddy!",
      "https://preview.redd.it/urz0cnc9brhc1.jpeg?width=640&format=pjpg&auto=webp&s=fd37e0b1388d5051aede3eb99976d6430537b149\n\nStill waiting my 4080 Super AERO",
      "Definitely going to starve the gpu of fresh air in that config, but it looks like you're going fora vented panel of some kind? Either that, or it needs to scooch toward the motherboard or return to a traditional position, if that's possible in this case.\n\nOtherwise, noiiice. Congratulations that's one heck of a system.",
      "Yes, i had to remove the front panel to get fresh air. I found some alternatives for this issue, but until it's arived and tested, I can't tell if it's good or bad \nhttps://jakefacecustoms.myshopify.com/products/hyte-y60-custom-vented-side-panel?variant=40436021755969",
      "I am streaming and obs alone with all my stuff was eating about 9gb of ram, had a 32 gb before",
      "Lol 4090 nowadays are 2k",
      "Still waiting for that ventilated front panel to check the temps. At the moment can't place the front panel in because of obvious reasons. Gpu teps are going crazy with that thing on at 85° C i removed the front pannel but for sure could get a lot higher in temps , after a few seconds the temps were stable at 62° C without that glass panel.",
      "I removed the front panel until i find a solution for the airflow for the gpu",
      "This case isn't allowing for horizontal mount for the GPU , I feel that this is the only issue with it , the support of the back accepts only vertical mount, What I do like on the gigabyte aero model is that the power supply for the GPU is placed down inside the radiator so in case of horizontal mount the cables are not going to touch the side pannel also comes with very good metal support directly on your motherboard scrues.\n\nhttps://preview.redd.it/nsb9764n1rhc1.jpeg?width=1868&format=pjpg&auto=webp&s=92fbbfdb0581a9156835268fca847ce060312940",
      "SWEET",
      "Looks great! I would have spent the extra money on an 4090 than a led screen for stats. But still looks great",
      "Well depends on the budget available for everyone 60% more cost for 15%-20% more performance didn't made sense for me, I also don't do much heavy processing with it except gaming and have 2x QHD 2k monitors so I don't think it would had made sense. At least for me since at 1440p it has just 5-8% more performance than the 4080 super",
      "Hyte y60",
      "that's the corsair icue dashboard and it's detected as a regular display in windows",
      "Good logic, and I have to say.....with my 4090.....im still drooling over that led screen.   \nI would love to do that. my case is blocked from view tho....so cant justify. But it looks so good.",
      "Is the LCD included?",
      "What kind of load were you putting on it? We used Cinebench to test it... The GPU in my case never broke a sweat... But the 77 degrees was my CPU... I may not have mentioned that... My hardware is in a Cooler Master HAF XB",
      "https://preview.redd.it/dqeh0x4bfuhc1.jpeg?width=3000&format=pjpg&auto=webp&s=afc920cab58299dfd60b17dea9822a8989e8442d",
      "Aready ordered a vented side pannel from here , long time until it will be delivered \nhttps://jakefacecustoms.myshopify.com/products/hyte-y60-custom-vented-side-panel?variant=40436021755969",
      "It should be"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "rtx 4080",
      "4080",
      "4080 super"
    ],
    "title": "Reminder about the screen blanking issue for 4080s and 4090s",
    "selftext": "Argh!\n\nI ran a utility to update the VBIOS, and thought I had this fixed. So when the problem propped up again, I ran into all kinds of trouble, and misdiagnosed the problem. That, uh, got expensive. I have a 4080 SUPER, and once in a while, on boot, my screen will simply not turn on. This even led to a botched motherboard BIOS update, among other things.\n\nFor PNY, I had to go [here](https://www.pny.com/company/support/nvidia-geforce), then scroll down to \"PNY RTX 4090 & RTX 4080 FIRMWARE UPDATE – NO DISPLAY\"\n\nNot only did this fix the infrequent \"blank screen on boot\" issue, but also with an issue in which either my main monitor or secondary monitor would turn on and off multiple times when coming out of sleep.\n\nAnyway, I'm just posting this because I had an awful time diagnosing the problem, and am hoping to save other people unnecessary pain.\n\n(Edit: fixed BIOS → VBIOS for accuracy and clarity)  \n(Addendum: the secondary monitor flashing on and off when coming out of sleep came back. Meh. Once it comes on, it stays on, though, so I'm not too worried.)  \n(Addendum 2: damnit, the problem came back. Fuck Nvidia.)",
    "comments": [
      "Funny they only have fixes for 4080 and 4090, because it happens with my 4070 Ti as well, getting a blank screen before Windows that is.\n\nWhat fixed it for me was setting the boot delay in the BIOS from it's default 1 second to 8 seconds.\n\nI never had this happen with my GTX 1070 on the same motherboard, 4000 series just have weird issues.",
      "On my AORUS Z790 and ASUS TUF 4090, weird things can happen if I try to boot with a DP monitor that is turned off\n\nSometimes a LED indicator on the motherboard would turn on (GPU)\n\nSometimes I would not see the BIOS Splash screen/POST, but will get display when Windows gets to the login screen\n\nSometimes I would need to turn the monitor on and off to see something, I know it posts because I would hear the Windows login sound\n\nI just keep the monitor on to avoid those problems and shut down the PC regularly, then the boot cycle is as expected",
      "I have a pny card, but my screen blanking only happened because of gsync, while using at least 3 different adobe programs. Once I turned off gsync, no more screen blanking.",
      "Never had one degrade? I have. It's not as wide open with every possible issue you ever have, must be due to CPU degradation, as people make it out to be. Keep in mind, many that are feeding fuel to the fire don't even own an Intel. They just read off the internet, and parrot in the most hyperbolic way. There are key moments, a pattern, when you have degradation. It's not \"oh I have a random issue, must be CPU degradation\".",
      "It would get stuck starting from a cold boot, with the motherboard posting LED still on and i'd have to press the reset button to restart it normally.\n\nIt's like the GPU wouldn't get initialized or something. The GPU itself works just flawless though, never any crashes. It's either 4000 series in general or 12VHPWR flaws.\n\nMy motherboard is the ASRock Z590 Steel Legend.",
      "You'd figure 1800 dollars would be enough of a premium for fixing their firmware issues. Just ASUS things I guess!",
      "I just got a tuf 4090 a few months ago and was going crazy over the seemingly random and far between screen blanking. Good to know it's not a card defect. Well at least a physical one anyway.",
      "Wait. So is this why it is happening? A VBIOS thing? I thought my 13700K might have been going toast. Is there any specifics on this issues though, so I can contact the manufacturer of my card (Palit) about the VBIOS update (their utility says no VBIOS update needed)",
      "> TheDeeGee wrote: What fixed it for me was setting the boot delay in the BIOS from it's default 1 second to 8 seconds\n\nInteresting workaround / tip - thank you, may help others  :-)",
      "toy ludicrous humor deranged badge impossible saw worthless ghost offer\n\n *This post was mass deleted and anonymized with [Redact](https://redact.dev/home)*",
      "The thing is, I don't think it's VBIOS. I'm pretty sure I did a VBIOS update earlier, and that didn't fix the problem. The firmware update that fixed the screen blanking issue was a separate \"firmware\" update.",
      "I basically have the same, its really annoying. If i turn both of my monitors on before my pc i just font get an image at all. I need to turn on only one monitor then turn on my pc and only then can turn on my second monitor. \n\nIf i want to go into the bios for some odd reason i only get an image on my second monitor and not my primary even if my second is turn off and still don’t get an image if if i turn it on.\n\nI also noticed that my second monitor randomly flickers to black for a second. Its only does it once per day, at least the ones i noticed. I’ve got a Zotac RTX 4080 trinity but i haven’t found a vbios file on their site. I’m unsure if they even provide one at all.",
      "I have this problem but the firmware is saying mine is already updated, stupid",
      "I had this issue with a 3060 so it’s not just a 4080/4090 issue. I haven’t had it with my 4080s since turning on the monitor first.",
      "Try disabling MPO (multiplane overlay) in windows \n\nhttps://nvidia.custhelp.com/app/answers/detail/a_id/5157/~/after-updating-to-nvidia-game-ready-driver-461.09-or-newer%2C-some-desktop-apps\n\nThis may help some of you especially multi monitor owners.\n\nAlso if your monitor has a low power mode switch that off as it cuts power to the Display Port in standby, this can cause issues with boot display and wake up",
      "Thanks for posting, I get this issue occasionally but have always thought it was some issue with windows HDR or DSC. I have a gigabyte 4090 and will search for a similar update",
      "Idk if it's the same problem or somehow related, but for me on a 4070ti with only 1 monitor(no DSC) and an hdmi 2.1 tv connected, the monitor sometimes doesn't show stuff on boot even though it's on, until i turn the connected tv on and then it becomes normal, like it seems it somehow made the tv the \"main\" panel when it's off and then corrects itself after it's on. \n\nAnd i even have a 5 sec post delay, I guess i could try a bigger one, not really that big of deal in the end and might not be the same thing even, maybe some intel board thing...",
      "I have this issue on my 3090 as well so it’s not just a 4000 series issue.  Seems like it’s something with the drivers.  I was using a 2 year old driver or so for a long time and updated maybe a couple months ago to a more recent driver.  \n\nSince that time, I now get the screen flickering/blanking issue at times only when first booting up and have to hard reset to fix it.  Have tried a sorts of drivers since and nothing seems to fix the issue now.  Never once had this issue until I updated to a more recent driver.",
      "I had an issue with Asus 4090 ROG Strix that sounds very similar, and I solved it by using another DP cable, guess old one was broken (or just old), never tried updating the VBIOS.",
      "Man, that's a nightmare! Glad you figured it out. That's a huge help to anyone else dealing with similar issues. Hopefully, this saves others from pulling their hair out."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "4080",
      "4080 super"
    ],
    "title": "4080 super FE vs Asus Tuf Gaming Which ones is better to buy all points would be helpful",
    "selftext": "",
    "comments": [
      "The ASUS tuf model has the 4090 cooling solution on it. That’s the one I went with. Insanely good card, and from testing the second highest stable Overclocking under the strix rog model by a couple percent. Temps at 110% (352w) power load have never went over 63 degrees",
      "Fe looks better, exhausts heat out of the back of the case which is always a good thing, has better resale value. It’s also considerably shorter which makes it easier to fit in smaller cases. Disadvantages are it likely runs hotter which doesn’t matter at all in the grand scheme of things.",
      "Resale value alone makes this a no-brainer. Go FE if you can get one.",
      "Is the TUF model just as good with the lower tier cards like the 4070 Super?",
      "Yes it is but so is the founders 4080 super founds is really nice and fits in super small placesZ",
      "FE, I got a tuf, has a noticeable coil whine and apparently asus gpus are suffering that more than others, coming from a silent and solid evga card I completely forgot it was a thing \n\nAlso there’s an annoying red light that stays on when the pc is off, and I can still very faintly hear it if I get close when it’s off, hoping this resolves itself with time, guess I’m turning off the socket to it every night now\n\nHave a decent psu using two individual sets of cables to power it too so it’s getting all its juice. \n\nEdit: noise has lessened somewhat since, new cable on the way so will see if that removes the rest, else will try undervolting\n\nFurther edit: new cable did remove the red light when device is off, however slight coil whine noise still present when device is off, and still plenty (although it did lessen a bit!) when device is on, undervolted card to help reduce it a bit but still plenty there, will look at getting it swapped and hope I get lucky",
      "Idle temps aren't super meaningful with fan stop, though.",
      "The 4080FE has the 4090FE cooler as well.",
      "All 4080’s use 4090 coolers\n\nEdit: except these new “slim” variants, of course",
      "It doesn’t matter as a traditional GPU just blows all of its heat in the case which is likely to be exhausted out of the top and back.",
      "They are very similar.  FE has a design people like more.  Tuf is much bigger but has better cooling and a dual bios.",
      "Hard to say - I think a lot of people like the design, esp. the pass-through cooler, and in terms of performance nvidia has narrowed the gap between its stock card and the board partners to the point that they aren't even able to make huge improvements in clock without lots of voltage.\n\nEither way it's not just a fad - two generations of founders cards have gone through the used market and they're always selling for more than the partner cards.  I tried to get one that way myself, in part for the look now that I have one of these silly glass-sided PCs.",
      "faulty aloof ludicrous prick coherent rinse swim sort somber vast\n\n *This post was mass deleted and anonymized with [Redact](https://redact.dev)*",
      "Same temperature but the TUF is much quieter.  Normalized volume it comes out about 4 degrees lower.\n\nhttps://www.techpowerup.com/review/asus-geforce-rtx-4080-super-tuf/39.html\n\nhttps://www.techpowerup.com/review/asus-geforce-rtx-4080-super-tuf/40.html",
      "FE all day. Love the design of the Supers. The all black looks so slick. Also fits in more cases.",
      "I went down a rabbit hole researching this and unless it’s your power supply I’m hoping that your coil wine goes away in a couple weeks",
      "I have an ASUS TUF 4080 and mine has terrible coil whine even after months of use. I've done a lot of research while trying to figure out how to make it quieter, and like you say, it turns out the ASUS TUF 40xx cards are the absolute worst when it comes to coil whine. I tried upgrading the power supply (had a 750w before) to one that's 1200w and has a 12vHPWR cable so that I could do away with the adapter, but the coil whine has persisted. :/\n\nThe only thing that has helped at all with the coil whine is undervolting. It didn't hurt performance at all, and the card is only half as loud now (but still annoying). You can find guides on how to do this on youtube if it turns out your coil whine doesn't go away after a while, which sometimes happens.",
      "I went with TUF for my RTX 4080 Super~ I live in Europe so FE cards are somewhat of a rarity & difficult to get your hands on. Meanwhile, I physically went to a local PC store and got an Asus model for an MSRP of 1150€ without any need to wait or worry that they would cancel my order without my consent or anything of the sort.",
      "It's his PSU/or environment which includes electric quality. Had an outlet in my parents house that I believe had a bunch of vdroop (weird PSU issues under load, made coil whine worse, hard crashed occasionally when other outlets wouldn't (either way PSU was pushed to around it's max, on paper/software I was pulling 800/850 watts so prolly a good bit over 850w with error and inefficiencies in wires taken into account.)) and eventually I learned that I just couldn't use that outlet. Was on the same breaker, don't know what the houses wire topology looked like tho.\n\nLong story short PSU and or power quality as well as EMI effects a lot more with modern machines than people give credit too. It's very common for people who \"Know what they're doing\" with hardware modifications to add capacitors, power bridges, increase switching freq/response of vrm, and edit a unholy amount of different areas in the vbios to turn a entry level/cheap card/board into something qthat can compete with XOC hardware. Spec is easy to hit by definition, and it is indeed meant to be that way; it lowers the barrier to enter a market segment. And also makes low spec hardware prone to errors, a single cap breaks and now whoops that line has crash-inducing vdroop, oh no I put my 4 layer Hx10 board in a ghetto rack or on a desk why am I getting errors or WHEAs out the ass, oh boy look a RT81xx can't wait to saturate my gigabit connection :P",
      "this goes for any nvidia gpu. i would personally if i have the choice go with the fe without even thinking about other options. i do not care if others are cooler or have higher clock speeds, fe cards look way better than any other (proart is really close though they look really nice too), look like an amazing collection item when you replace it and imagine the flex of having a founders edition gpu"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "rtx 4080",
      "4080",
      "4080 super",
      "rtx 4080 super"
    ],
    "title": "GeForce RTX 4080 Super Review Megathread",
    "selftext": "# GeForce RTX 4080 Super reviews are up.\n\n&#x200B;\n\n[bbbnnnnnnnh](https://preview.redd.it/yxloauzomtfc1.jpg?width=1270&format=pjpg&auto=webp&s=3d64648baea8c6295e9e2245f4b5377414760db0)\n\n# Below is the compilation of all the reviews that have been posted so far. I will be updating this continuously throughout the day with the conclusion of each publications and any new review links. This will be sorted alphabetically.\n\n# Written Articles\n\n# [Babeltechreviews](https://babeltechreviews.com/rtx-4080-super-review-a-999-repackage/)\n\n>Though slightly underwhelming, it’s worth noting that the RTX 4080 SUPER remains an excellent card for gaming. When it comes to pure rasterization, the AMD Radeon RX 7900 XTX may lead by a slim margin (we do not have one to test), but the 4080 SUPER compensates with far better RT performance. Nonetheless, NVIDIA has utilized the full potential of the GPU, avoiding any limitations on its units, although higher clock speeds and power limits might have yielded additional, albeit small, improvements.  \n>  \n>There is zero reason to consider a RTX 4080 at this time. If there is a steep sale with remaining stock or a used card you may find success there and will not miss out on much. We are very surprised that the RTX 4080 SUPER mostly ends up at 1%-4% on average over the RTX 4080 FE. Now that Nvidia’s “SUPER” refreshes are complete we still believe the RTX 4070 SUPER is the card of choice for 90% of gamers if you must have the latest and greatest or an 7800XT.\n\n# [Digital Foundry Article](https://www.eurogamer.net/digitalfoundry-2024-nvidia-geforce-rtx-4080-super-review)\n\n# Digital Foundry Video - TBD\n\n>In performance terms, there's a law of diminishing returns to the excitement level surrounding the arrival of each new Super, from the generally positive reaction to the RTX 4070 Super to the more muted response to the RTX 4070 Ti Super - and now, ambivalence with the 4080 Super improvement. The truth is, it's a pricing adjustment dressed up in a marketing announcement and this is generally fine overall - but how much of a value enhancement are we actually getting?  \n>  \n>The cost per frame values for the 4080's predecessor - RTX 3080 - are $12.52 ($12.47 normalised), so while relative value only slightly tips towards the RTX 4080 Super, at least we're looking at something fairer. In effect, this looks very much like the kind of top-end pricing that the RTX 4080 should have had at launch. If you're looking for proportionately better value, the 4070 Super is clearly worth taking a look at, based on the table above.  \n>  \n>There's one more thing I'd like to point out though. We can't ignore that reaching a certain performance threshold makes more experiences viable, especially at 4K resolution, and that may be worth paying the premium. Path-traced Alan Wake and Cyberpunk 2077 are doing things that the RX 7900 XTX never will. It's that simple. DLSS spatial upscaling, DLSS 3 frame generation temporal upscaling, DLSS ray reconstruction - they're combining to make special things happen.  \n>  \n>Ultimately, I can't help but think that if you're 'dropping' a grand on a new GPU, you should have access to top-tier experiences at 4K resolution. AMD's value is clear and present, but I think this is all worth taking into consideration. In the gallery above, you'll note that even on a top-tier AMD sponsored game - Avatar: Frontiers of Pandora - the RTX 4080 Super is ahead of the RX 7900 XTX and DLSS quality mode is delivering improved image quality over its FSR2 equivalent.  \n>  \n>In summary then, RTX 4080 Super does what it needs to do in delivering the kind of price/performance/features we didn't get at launch. Similar to the RTX 4070 Ti Super, it feels like the kind of package it should have been back in the day: expensive but not egregiously so. The price is improved then, but it arrives 14 months on from the 4080's launch and while there is a slightly better level of proportionate value compared to the rightly celebrated RTX 3080, it's still hard not to feel that this is still a pretty steep asking price for an 80-class product. At least now there is a gap for a 4080 Ti, but with the AI boom, it does feel less likely we'll ever get one.\n\n# [eTeknix](https://www.eteknix.com/nvidia-rtx-4080-super-founders-edition-graphics-card-review/)\n\n>So what do we think? I think it’s clear to see that the 4080 SUPER is a step up in everything but performance. Sure, some games can utilise the extra specs that the 4080 SUPER has, but at such a small amount, it’s still within the margin of error, and the silicon lottery comes into play too. So you could argue, why didn’t NVIDIA just price cut the 4080 and while they’ve not confirmed anything with us, we do have our theories.  \n>  \n>When NVIDIA place an order for the silicon from their partners, they are paying a specific price based on the fabrication process, and the 4080 non-SUPER never saw that change, whereas the 4080 SUPER is slightly different, as per the GPU variants naming structure, so NVIDIA has found a way to refine the process, and in turn, it’s likely costing them less money.  \n>  \n>Their costs go down, and therefore they can afford to pass those savings on, whereas simply cutting the price of an existing product that’s been made under a more expensive fab process and has already been paid for, is a completely different kettle of fish.  \n>  \n>So I’m all for this, and like I said earlier. It does seem that gamers are happy to pay more for an NVIDIA card, as seen by how much of the market NVIDIA have, and the fact that AMD has even been rumoured to say that they may stop making high-end GPUs, much like we saw with the 5000 series which topped out as the 5700 series. They simply can’t compete. That’s not to say in terms of rasterisation, high frame rate numbers, but more in terms of features, and of course Ray Tracing.  \n>  \n>So that all puts NVIDIA in a really good position and allows them, yes, to charge more money, but also to do these mid-cycle changes where money and savings can be passed on. Sure we’d all like to see it cheaper, but the 4080 SUPER is still likely to outsell both the 7900 XT and 7900 XTX by a huge margin, much like the more expensive 4080 non-SUPER already has.  \n>  \n>So definitely some food for thought. I always had my feelings about how the 4080 was too expensive, but at $1000, it’s definitely a card that really has no competition when you factor in all elements including performance, Ray Tracing, upscaling, streaming and all of the other features that separate AMD and NVIDIA.\n\n# [Guru3D](https://www.guru3d.com/review/nvidia-geforce-rtx-4080-super-review/)\n\n>The performance metrics are clear, the GeForce RTX 4080 series (yes both 4080 and 4080 SUPER) stands out, particularly in gaming performance and rendering quality. This card offers better value compared to the 4090, achieving high-level performance that facilitates 4K resolution gaming. It's ideal for enthusiast gamers who use Ultra-Wide HD (UWHD), Quad HD (QHD), or Ultra HD (UHD) monitors. The RTX 4080 features an advanced rasterizer engine that surpasses previous performance limits, thanks in part to its 10k Shading processors. Additionally, the RTX 40 series introduced a new generation of Ray tracing and Tensor cores, which have proven to be significantly more powerful. The core counts of RT and Tensor should not be the sole focus; their performance efficiency is what truly matters. Located near the shader engine, these cores have become more efficient, a fact that is evident in their output. While Tensor cores are often challenging to quantify, our observations indicate robust performance, as evidenced by the impressive results with DLSS3 technology. The GeForce RTX 4080 is versatile, delivering super performance (pardon the pun) at resolutions ranging from 2K (2560x1440) to 4K (3840x2160).  \n>  \n>Here's the reality for the GeForce RTX 4080 SUPER, its hardware and performance are commendable but the performance differential towards the existing RTX 4080 is often within a 1-2% baseline, e.g. close to nothing. While it has more shaders and faster memory, both cards are tied towards the very same 320W TGP mainly resulting in that close to NIL performance differential. The biggest benefit of the series thus is pricing. The ADA GPU architecture of the 4080 SUPER demonstrates proficient performance. It boasts about 1.5 times the raw shader performance compared to its predecessors, along with enhanced Raytracing and Tensor core capabilities. Technologies like Shader Execution Reordering (SER) and DLSS 3 further enhance the capabilities of the Series 4000, making it a standout product. Add to that features like DLSS 3.5 with ray Reconstruction and Frame generation and you are bound to be able to use this graphics card for years. The GeForce RTX 4080 is notable for its impressive performance numbers. It is particularly suitable for gamers who use Ultra HD or have a minimum monitor resolution of 2560x1440. For those who can afford it, the 4080 SUPER is a valuable addition to any high-end gaming setup. For instance, games like Microsoft Flight Simulator 2020, when combined with DLSS 3.0, achieve over 100 FPS at high resolutions. Similarly, Cyberpunk in  UHD, raytracing, and DLSS 3.5, exceeds 100 FPS. The recent move towards Ray reconstruction also moved NVIDA into that sweet spot. The card excels in Ultra HD gaming, whether using standard shading or a combination of hybrid ray-tracing and DLSS 3.0/3.5. The 4080 SUPER at $999 is now more affordable than the 4080, it still represents a significant financial commitment, offering a very nice performance.\n\n# [Hot Hardware](https://hothardware.com/reviews/nvidia-geforce-rtx-4080-super-review)\n\n>NVIDIA set out to do a few things with its [GeForce RTX 40 SUPER lineup](https://hothardware.com/news/nvidia-rtx40-super-ces2024). The ultimate goals were to improve performance, refresh its Founders Edition boards with a fresh aesthetic, and offer more value to gamers with reduced introductory price points versus the original models. Although the performance deltas separating the GeForce RTX 4080 SUPER from the original RTX 4080 are relatively small in comparison to the RTX 4070 and 4070 Ti SUPERs, it is still faster than the original. The GeForce RTX 4080 SUPER also arrives with a $999 MSRP, 20% below the RTX 4080’s $1,199 introductory price. A cool grand is not chump change, of course, but more performance at a lower price point is a good thing and we have to give kudos to NVIDIA for the move.  \n>  \n>The GeForce RTX 4080 SUPER may also put some additional pressure on AMD. Reference clocked Radeon RX 7900 XTX cards can be [found for about $960 - $980](https://amzn.to/3SD3iuF) as of this publication, which may or may not require adjustment depending on your point of view. The GeForce RTX 4080 SUPER is faster overall, for only slightly more money – assuming street prices actually hit MSRP. The Radeon RX 7900 XTX will likely be faster with many titles that don’t use ray tracing, but the scales tip in favor of the GeForce RTX 4080 SUPER once ray tracing is factored into the mix. Many rendering and compute workloads also perform better on the GeForce RTX 4080 SUPER, and the GeForce is more power efficient too. We’ll have to see how things shake out in the next few weeks, but AMD may want to run some promos at the very least, to improve the Radeon RX 7900 XTX’s current value proposition in light of today’s launch.  \n>  \n>In the end, NVIDIA’s brought its second fastest GPU down into the sub-$1,000 price bracket. That’s not cheap, but it’s a positive development nonetheless and we welcome it. The GeForce RTX 4080 SUPER is fast, power efficient, we dig the all-black aesthetic, and it is ultimately a better value for enthusiasts shopping for a high-end GPU.\n\n# [Igor's Lab](https://www.igorslab.de/en/nvidia-geforce-rtx-4080-super-founders-edition-16gb-vs-msi-geforce-rtx-4080-super-expert-16-gb-review/)\n\n>How do you make a product cheaper and more attractive without directly lowering the price and entering into a price war that you can’t (and don’t want to) win? You create a super-adequate product, even add some performance on top, sacrifice some efficiency, but can use significantly more chips in order to significantly reduce the price. The result is a new, “improved” recipe that is even cheaper than the new products from the relevant food companies. And with more content. Well, a few calories will be added to the price, but that’s peanuts compared to the purchase price.  \n>  \n>What sounds like the reverse of the daily criticism of cheat packs in the shops is certainly also calculated. In over a year, NVIDIA has certainly collected enough chips for the GeForce RTX 4080 Super and at the same time increased the yield to proudly position this product as a replacement for the GeForce RTX 4080 Non-Super. An average of 1 to 2.5 percent more performance compared to the non-Super card with a good 5% more shaders doesn’t sound so exhilarating, but at least the range outside any measurement tolerances can be proven.  \n>  \n>Of course, things that were previously unplayable are not suddenly playable, but it is at least a certain benefit that customers are happy to accept, especially as the price of the so-called RRP cards has fallen significantly. However, the board partners come into play again at this party and if you want something nicer and brighter, the price can quickly rise by 100 to 300 euros. Then the advantage is gone again and you will have to think about where to set your priorities. The first impression of the GeForce RTX 4080 Super is therefore quite positive. For the first time in a long time, NVIDIA is once again offering a card that is cheaper than the older comparison model and still remains at the top of the field in terms of efficiency. The approximately 80 percentage points compared to an even slightly slower GeForce RTX 3090 Ti are still shockingly high and they also show what the Ada generation is capable of, even if you open the tap a little further.\n\n# [KitGuru Article](https://www.kitguru.net/components/graphic-cards/dominic-moass/nvidia-rtx-4080-super-review/)\n\n# [Kitguru Video](https://www.youtube.com/watch?v=Imnin79vcSI&feature=youtu.be&ab_channel=KitGuruTech)\n\n>As the last of three [RTX 40-series Super](https://www.kitguru.net/tech-news/featured-tech-news/matthew-wilson/ces-2024-nvidias-rtx-40-super-launch-ai-laptops-and-more/) launches this month, there is no doubt the **Nvidia** **RTX 4080 Super** is the least interesting of the lot, for the simple reason that it brings no tangible performance benefit over the outgoing RTX 4080. The refreshes started strongly with the [RTX 4070 Super](https://www.kitguru.net/components/graphic-cards/dominic-moass/nvidia-rtx-4070-super-review/) coming in a good 15% faster than the 4070, while the [RTX 4070 Ti Super](https://www.kitguru.net/components/graphic-cards/dominic-moass/nvidia-rtx-4070-ti-super-review-ft-msi/) delivers performance that's a bit faster than the RTX 4070 Ti but with VRAM and memory bandwidth increased by a third. Today we've assessed the RTX 4080 Super and found it to be… 1% faster than the RTX 4080.  \n>  \n>That's right, across twelve games at 4K resolution, the RTX 4080 Super came in 1% faster on average. Nine of the twelve games tested showed a difference of less than 2%, while we saw a performance increase of more than 3% in just a single game. The differences are so marginal that the silicon lottery could well mean a higher-performing RTX 4080 would actually *outperform* a slightly below-par RTX 4080 Super, and in fact that's exactly what we did find in [our review of the Palit JetStream OC](https://www.kitguru.net/components/graphic-cards/dominic-moass/palit-rtx-4080-super-jetstream-oc-review/).  \n>  \n>As lame as that is, it's important to remember we are still talking about a very fast GPU here – it may be an entirely uninteresting difference compared to the original 4080, but it is nonetheless a very capable 4K card, averaging 73FPS across the twelve games tested. It is also second only to the RTX 4090 when looking at ray tracing, admittedly by quite a distance, but the reality is AMD has nothing that can compete in this segment if you value RT performance, given the 4080 Super proved 30% faster than the 7900 XTX over the eight ray traced games we tested.  \n>  \n>Clearly, the RTX 4080 Super is all about the new lower price-point, rather than the almost non-existent performance improvements over the RTX 4080. As a reminder, [RTX 4080 launched in November 2022](https://www.kitguru.net/components/graphic-cards/dominic-moass/nvidia-rtx-4080-founders-edition-review/) for £1269/$1199, while the 4080 Super is now hitting the market at £959/$999. Offering the same performance for a price that's £310 lower doesn't sound too bad, and it does improve the cost per frame by 26% over the RTX 4080 when looking at the launch MSRPs.\n\n# [LanOC](https://lanoc.org/review/video-cards/8957-nvidia-rtx-4080-super-founders-edition)\n\n>As far as the 4080 SUPER goes Nvidia did improve on the performance we saw with the RTX 4080 but this isn’t a huge step up in performance between the two cards, I saw an average of 3.8% improvement in our 4k gaming tests, and in some of the synthetic tests I saw less and other tests I saw up to 5%. This did help it catch up to the RX 7900 XTX at 1080p and 1440p but the XTX was still a few FPS higher at 4K. That is before we figure in DLSS 3 with frame generation and the overall ray tracing capabilities of the RTX 4080 SUPER Founders Edition which were both a big plus for the 4080 SUPER. For power efficiency, the RTX 4080 SUPER Founders Edition did drop down slightly compared to the original RTX 4080 but it was still in a different class compared to the competition from AMD. The RTX 4080 SUPER Founders Edition impressed in our noise testing, especially when under load and its cooling performance was better than I expected as well. The only downside there is that there isn’t much headroom in the cooler when it comes to cranking the fans up but as it sits I wouldn’t have any reason to want to do that anyhow.  \n>  \n>In the end, like always, it comes down to pricing. Nvidia has the RTX 4080 SUPER priced with an MSRP of $999 and the RTX 4080 SUPER Founders Edition because it comes from them directly will be at that price point. The RTX 4080 that this replaces launched at $1199. While the RTX 4080 SUPER Founders Edition isn’t a drastic step forward in performance it does offer a step up while coming down $200. Most people, myself included, weren’t a fan of the pricing of the RTX 4080 last year but I can say without a doubt that the RTX 4080 SUPER and the RTX 4080 SUPER Founders Edition with it is what the original RTX 4080 should have been. A capable performer and while not cheap you are getting high-level performance at a price that fits that is competitive. The RX 7900 XTX is right in that same price range right now and while the raster performance of the 7900 XTX was a touch higher than the 4080 SUPER at 4K Nvidia’s tech like DLSS 3 and its ray tracing capabilities help add a lot of value and push me into the 4080 SUPER camp.\n\n# [Neoseeker](https://www.neoseeker.com/Articles/Hardware/Reviews/colorful-rtx-4080-super-ultra/)\n\n>The Colorful GeForce RTX 4080 SUPER Ultra W OC is a champion at 1440p while remaining very capable at 4K with extreme quality settings, as long as you don’t expect extreme frame rates on demanding games. Games are still definitely playable at 4K with (mostly) maximum settings with averages around 60 FPS, especially if you leverage NVIDIA DLSS technology.  \n>  \n>The Colorful GeForce RTX 4080 SUPER Ultra W OC operated very quietly at both Stock and Turbo preset frequencies, and was still able to overclock extremely well. The triple 100mm dual ball bearing fans were a great match for the large heat sink cooler, and they ran quietly until forced to run at high speeds. The cooler has five 6mm heat pipes and two 8mm heat pipes that are soldered to the fins, and worked very well under load. The Colorful iGame software also worked well in both full and lite versions, reflecting my system hardware, properties, and RGB settings correctly.  \n>  \n>If you want one of the best graphics cards out on the market that is still within reach, be sure to check out the Colorful GeForce RTX 4080 SUPER Ultra W OC.\n\n# [OC3D Article](https://overclock3d.net/reviews/gpu_displays/nvidia-rtx-4080-super-five-card-review/)\n\n# [OC3D Video](https://www.youtube.com/watch?v=dflM73cx4iI&pp=ygUEb2MzZA%3D%3D)\n\n>Summing up this whole Nvidia refresh has been akin to trying to nail a jelly to the wall. Theoretically easy, hard in practise. With the RTX 4070 Super we felt it was a victim of previous Nvidia decisions about their product range and pricing. More recently, the RTX 4070 Ti, we felt, was fast enough to justify the Super tag, but affordable enough to not be offensive. Today with the RTX 4080 Super we have nothing but good things to say.  \n>  \n>Firstly we like how Nvidia have beefed up the hardware. Clock speed increases aren’t enough to justify a new model. By giving us more hardware, it makes the product more palatable. Secondly, there wasn’t a RTX 4080 Ti, so the range was less muddled to begin with. It gives the RTX 4080 Super a place in their range. Above the vanilla card, below the RTX 4090. Easy. Thirdly, the extra clock speed, and extra hardware have combined to bring more performance to the table. By pricing the Super aggressively, under a thousand pounds, it brings gaming to the enthusiast without breaking the bank.\n\n# [PC Perspective](https://pcper.com/2024/01/nvidia-geforce-rtx-4080-super-founders-edition-review/)\n\n>There you have it, another SUPER launch is in the books, and we have a very slight performance edge over the original version of the card. When comparing the new RTX 40 Series SUPER cards, by far this is the smallest performance uplift compared to the original. HOWEVER, **this card is nearly 17% less expensive than the version it is replacing**. When does this ever happen?  \n>  \n>I’m sure top YouTubers are already out there with their pensive, disapproving, disappointed, or pseudo-angry face thumbnails just killing the low single-digit increases with the RTX 4080 SUPER over its non-SUPER predecessor, but to me this launch is [All About the Benjamins](https://www.imdb.com/title/tt0278295/). All two of them, as a matter of fact. Yes, for $200 United States Dollars ***less*** than the original card, you have a new card that’s just a little faster.  \n>  \n>The End.\n\n# [PC World](https://www.pcworld.com/article/2222156/nvidia-geforce-rtx-4080-super-review.html)\n\n>While I couldn’t recommend the original RTX 4080 over the Radeon RX 7900 XTX at its chest-clutching $1,200 price, the GeForce RTX 4080 Super’s $999 price tag makes it much more competitive. In fact, I’d opt for Nvidia’s refreshed penultimate GPU over AMD’s champion now.  \n>  \n>The performance upgrades in the 4080 Super are perfunctory and negligible; it’s the price drop that matters. The Super and the 7900 XTx both deliver screaming-fast frame rates in traditional games, trading blows left and right. That’s what made the Radeon so appealing versus the original 4080, especially with Nvidia’s card having such an exorbitant markup. But by matching the 7900 XTX’s $1,000 MSRP, Nvidia’s extras help the 4080 Super claim dominance.  \n>  \n>The GeForce RTX 4080 draws *massively* less power than its AMD rival to deliver similar frame rates in traditional games. Flip on ray tracing and Nvidia holds a gargantuan lead, with stellar AI-powered features like DLSS, Frame Generation, and Ray Reconstruction pushing both speed and performance advantages to 11. Features like Nvidia Broadcast and Reflex hold deep practical appeal; RTX Video Super Resolution uses AI to make ugly videos beautiful. And Nvidia maintains a strong lead in most creative and machine learning/AI workloads if you like to put your GPU to work when you’re not playing — witness the dual AV1 encoders in the 4080 Super.  \n>  \n>Taken as a whole package — performance, ray tracing, power efficiency, features, even prosumer tasks — Nvidia’s GeForce RTX 4080 Super is the clear choice in its price range. This is the graphics card you want for 4K gaming without going over $1,000. You can often find the Radeon 7900 XTX on sale for $950 or so, but I’d still pick up the 4080 Super without hesitation given that option. At the high-end, where *everything* matters, I wouldn’t consider the AMD option unless it was on sale for $900 or (ideally) less, despite it being a fine 4K GPU in its own right.  \n>  \n>If you want 4K gaming, excellent ray tracing, and Nvidia features at a slightly lesser price, the [$799 GeForce RTX 4070 Ti Super](https://shop-links.co/link/?url=https%3A%2F%2Fwww.bestbuy.com%2Fsite%2Fsearchpage.jsp%3Fst%3D4070%2Bti%2Bsuper%26_dyncharset%3DUTF-8%26_dynSessConf%3D%26id%3Dpcat17071%26type%3Dpage%26sc%3DGlobal%26cp%3D1%26nrp%3D%26sp%3D%26qp%3D%26list%3Dn%26af%3Dtrue%26iht%3Dy%26usc%3DAll%2BCategories%26ks%3D960%26keys%3Dkeys&publisher_slug=pcworld&exclusive=1&article_name=pcworld&article_url=https%3A%2F%2Fwww.pcworld.com%2Farticle%2F2222156%2Fnvidia-geforce-rtx-4080-super-review.html&u1=2-1-2222156-1-0-0) is also worth considering now that it has 16GB of memory and a wider memory bus. It isn’t as fast as the 4080, obviously, but should still get the job done. Or if you want the ultimate gaming experience, there’s always the GeForce RTX 4090, though it’s priced at $1,600 and going for closer to $2,000 on the street.\n\n# TechGage\n\n>TBD\n\n# [Techpowerup](https://www.techpowerup.com/review/nvidia-geforce-rtx-4080-super-founders-edition/)\n\n>Averaged over the 25 games in our test suite, at 4K, we find the card only 1.5% faster than 4080 non-Super Founders Edition, which is MUCH less than expected. While NVIDIA never said \"+5%,\" I definitely expected more. It's not a power limit issue, running at max power yields another +1% only. These numbers are pretty constant across resolutions, and even with RT enabled, too. Looking at the individual games, the differences are 1 or 2 FPS, nothing you'd ever notice subjectively. While that's certainly a bit disappointing, the fact remains that RTX 4080 Super, just like the RTX 4080 non-Super, is a fantastic card for gaming. In a pure raster scenario, the AMD Radeon RX 7900 XTX is still a tiny bit faster, but NVIDIA's card makes up for that with much better RT performance. Still, I feel like beating the XTX across the board was one of the goals of RTX 4080 Super, and NVIDIA failed here. In NVIDIA's defense, the RTX 4080 Super leverages the full GPU, no units were held back, even though small additional gains could have been achieved with higher clock speeds and power limit. Compared to the RTX 4070 Ti Super, the performance uplift is 18%, the card is also 30% faster than RTX 4070 Ti non-Super. RTX 3080 Ti performance is roughly comparable to RTX 3090, which makes the gen-over-gen uplift a very solid 30%. NVIDIA's flagship, the RTX 4090 is still the undisputed king of the hill, offering almost 30% better performance.  \n>  \n>Taking a closer look at our test results, most of the games are in the 1.5% range—it's not that one game is 7% and the others are 0%, the gains are really small across the board. There is definitely some variations in GPU chip silicon quality, which affects performance due to the way NVIDIA's Boost algorithm works, but with my sample size of 9 cards tested, I think that I can confidently say that there's no way you're getting +5% out of the 4080 Super, unless you manually overclock it. Other reviewers have similar numbers, so it's not just me. Surprisingly, the RTX 4070 Super, initially considered the least exciting among the new releases on forums, showed the highest performance increase (+15%). In contrast, the RTX 4070 Ti Super, despite receiving a GPU upgrade and a 33% memory bandwidth increase, only saw a modest +5% in extra performance. Today's release could almost be labeled a \"rebrand,\" but the improved pricing certainly adds to its appeal.  \n>  \n>NVIDIA has set an MSRP of $1000 for the RTX 4080 Super and that's the real innovation here. Compared to the current $1200 for the RTX 4080 non-Super, this introduces a significant 20% discount. I have to applaud NVIDIA for that, especially, considering that there's not much competition in this segment. AMD is happy with their $970 price point for the 7900 XTX, but that changes today. RTX 4080 Super at $1000 means that RX 7900 XTX becomes unsellable unless its price is lowered considerably. The RTX 4080 Super offers superior RT performance, similar raster perf and support for DLSS—exactly what people in the premium segment are looking for. Even at $900 I'm not sure if I'd prefer 7900 XTX over a $1000 4080 Super, it's just a 10% delta. Still, $1000 is definitely not a steal for the RTX 4080 Super and what it offers—the 2024 GPU market is still expensive. If you want to save a bit of money, probably the most interesting alternative is RX 7900 XT, which currently sells for $710, but is considerably slower, which means lower detail settings or upscaling, but there's no DLSS on the card to help with that. NVIDIA has confirmed that the RTX 4080 non-Super is now end-of-life. You could potentially get a card at a good price; anything $950 and below is what I'd call \"interesting.\" If it's higher, go for the Super model, also for its better resale value. If you really must have the best, then the RTX 4090 is what you want—that hasn't changed with the release of the RTX 4080 Super, but be prepared to pay for it: +80% for an almost 30% increase in performance is tough. At the end of the day, RTX 4080 Super is disappointing in terms of the changes it brings, but it redeems itself thanks to its greatly improved pricing. While I'm sure there will be a lot of drama about the minimal gains, what the GPU market really needs is lower prices, not marginally better performance for the same price. In this regard, the RTX 4080 Super can be considered a success.\n\n# The FPS Review\n\n>TBD\n\n# [Tomshardware](https://www.tomshardware.com/pc-components/gpus/nvidia-geforce-rtx-4080-super-review)\n\n>Nvidia's RTX 4080 Super can be summed up in just a few words: It's like the RTX 4080, only less expensive. That's not to say it's *inexpensive*, as it still costs over $1,000 (after taxes), but $200 cheaper is at least something. Meanwhile, the performance side of the story is a gigantic snorefest. The RTX 4080 Super does technically offer more performance than the RTX 4080, but only by about 2\\~3 percent on average. Even a piddly overclock of an RTX 4080 could improve performance at least that much.  \n>  \n>If you were on the fence and trying to decide between AMD's RX 7900 XTX and Nvidia's RTX 4080, with the latter costing on average $200 extra, the RTX 4080 Super effectively wipes away the price difference. The only real reason to opt for a 7900 XTX now — barring any price cuts — is if you specifically want AMD's top card, or you want any GPU that has more than 16GB of memory. Otherwise, the RTX 4080 Super is almost always the better option.  \n>  \n>Yes, there are exceptions, like a few rasterization games and certain professional applications, as well as workloads that need more than 16GB (but less than 24GB) of VRAM. If you're specifically interested in one of those use cases, that's fine, and AMD is still technically about $40 cheaper for the least expensive 7900 XTX cards. At the same time, you give up access to Nvidia's DLSS features and potentially lose a lot of performance in other use cases. In other words, you 'win' in a few specific cases and lose in a lot of other situations.  \n>  \n>Ultimately, the RTX 4080 Super delivered precisely what we expected to see. It's a cheaper and barely faster take on the RTX 4080. The price means it's now in direct competition with AMD's 7900 XTX, but either one still costs as much as an entire midrange gaming PC. It's fine for what it is but doesn't offer anything new other than a stealthier black aesthetic for the Founders Edition.  \n>  \n>If you're in the market for a top-tier graphics card and can't justify doubling the price and picking up an RTX 4090, the RTX 4080 Super now ranks as the second fastest GPU overall, and it's cheaper than the existing 4080. It's slightly faster and less costly than the 4080, but we were never particularly pleased with the $1,199 launch price of the 4080 in the first place. $200 represents a welcome and necessary price correction, and unlike the RTX 3080, which was generally selling at over $1,000 for the majority of its life cycle, the 4080 Super should at least be readily available.\n\n# [Computerbase - German](https://www.computerbase.de/2024-01/nvidia-geforce-rtx-4080-super-review-test/)\n\n# [HardwareLuxx - German](https://www.hardwareluxx.de/index.php/artikel/hardware/grafikkarten/62811-punktet-vor-allem-%C3%BCber-den-preis-die-geforce-rtx-4080-super-im-test.html)\n\n# [PCGH - German](https://www.pcgameshardware.de/Geforce-RTX-4080-Super-Grafikkarte-280114/Tests/Release-Benchmark-Kaufen-Preis-RTX-4080-Super-vs-4080-vs-7900-XTX-1438917/)\n\n# ----------------------------------------------\n\n# Video Review\n\n# [Daniel Owen](https://www.youtube.com/watch?v=bppprJu-GT8&pp=ygULZGFuaWVsIG93ZW4%3D)\n\n# Der8auer\n\n# Digital Foundry Video\n\n# [Gamers Nexus Video](https://www.youtube.com/watch?v=8p6FhTBol18)\n\n# Hardware Canucks\n\n# [Hardware Unboxed](https://www.youtube.com/watch?v=fyUZ1cp4RnI&pp=ygUQaGFyZHdhcmUgdW5ib3hlZA%3D%3D)\n\n# [JayzTwoCents](https://www.youtube.com/watch?v=vfihprXzKXE&pp=ygUKNDA4MCBTdXBlcg%3D%3D)\n\n# [Kitguru Video](https://www.youtube.com/watch?v=Imnin79vcSI&pp=ygUKNDA4MCBTdXBlcg%3D%3D)\n\n# Linus Tech Tips\n\n# [OC3D Video](https://www.youtube.com/watch?v=dflM73cx4iI&pp=ygUEb2MzZA%3D%3D)\n\n# Optimum Tech\n\n# [Paul's Hardware](https://www.youtube.com/watch?v=LfW_AGA-kVI&pp=ygUKNDA4MCBTdXBlcg%3D%3D)\n\n# [Techtesters](https://www.youtube.com/watch?v=HaokHyKjq6g&pp=ygUKNDA4MCBTdXBlcg%3D%3D)\n\n# [Tech Yes City](https://www.youtube.com/watch?v=dUmadIkuH0A&pp=ygUKNDA4MCBTdXBlcg%3D%3D)\n\n# The Tech Chap\n\n# [zWORMz Gaming](https://www.youtube.com/watch?v=VFa28-KMkYA&pp=ygUNendvcm16IGdhbWluZw%3D%3D)",
    "comments": [
      "So, it was the 4070 Super that was the star of the show all along?",
      "4070 Super biggest perf increase for the same price.\n\n4070 Ti Super smaller than expected perf increase but more VRAM\n\n4080 Super negligible perf increase with a price cut",
      "4080S maybe as well be a regular 4080 OC version of any brand, just a bit cheaper.",
      "5080 at 900 max ? 😄 You know that after 12-13 months inflation also works and is taken into consideration by the greedy companies.  I don't expect anything less than 1200$ for 5080. It seems impossible.",
      "The 4080 Super is them testing if they should price 5080 at 1k, which after everyone snatching them up today they'll probably keep that price or even move it to 1.1k.",
      "Man what a ride aey Nvidia. First they start with calling the 4070 Ti 4080 but then Nvidia gets Super roasted and then they call it the 4070 Ti for $800 (still overpriced imo actually every 4K series card is overpriced). Then came the 4080 for $1200 for which they again got roasted so they release a very slightly better version of the 4080 and call it 4080 Super and reduce the price by $200. \n\nHopefully Nvidia learns something and doesn't do this again with the 5K series and maybe price the 5080 at $900 max.",
      "First, TPU shows that the 4070S gets 76% of the fps of the 4080S. That does not mean the 4080S is 24% faster, it's 1 / .76 - 1, or about 32% faster. Apply the same math to the 4K results and you get that it's about 41% faster.  \n\nSecond, if you look at the DF RT benchmarks you can find quite a few at 1440p where the 4080S is about 40% faster.",
      "Crypto boom out, AI boom in!",
      "No vram is the same",
      "the RTX 4080 is 1 year old and nvidia neglected any price cut until they repackaged it, cool.",
      "Yes",
      "Was this comment written by AI?",
      "1. A 4090 super likely won't exist. \n\n2. Nvidia heavily cut down the 4090 from full die AD102 with only 16384/18432 cores and 72/96MB L2 active. Ignoring the massive TDP on this made-up card, this is what full die AD102 would look like with Micron's 24Gbps GDDR6X, which does exist and is in their parts catalog running the same base/boost clockspeeds as the normal 4090.\n\nhttps://www.techpowerup.com/gpu-specs/geforce-rtx-4090.c3889\n\nhttps://www.techpowerup.com/gpu-specs/titan-ada.c3985\n\n4090 vs 4090 Super/Titan ada\n\n+12.5% cores, +33% cache, +14.3% bandwidth, +9% ROPs\n\n4080 vs 4080 super\n\n+5.3% cores, +2.7% bandwidth\n\nhttps://www.techpowerup.com/gpu-specs/geforce-rtx-4080.c3888\n\nhttps://www.techpowerup.com/gpu-specs/geforce-rtx-4080-super.c4182\n\n\n.......\n\nNvidia was sandbagging with the 4090, and since AMD can only compete with a 4080, they have no reason to release a faster card.",
      "Average FPS difference between 4070 Super vs 4080 super is 40%, does it remain the same when using DLSS/or it gets better?\n\nFor example at 4k with no dlss 4070 super has 70 FPS and 4080 Super has 98 FPS. \n\nIf DLSS is set on Quality, does the difference get smaller, for example 4070 SUPER gets 100 FPS and RTX 4080 SUPER gets 130 FPS (instead of 140 FPS difference).\n\nIf anyone knows please let me know, after watching 10 reviews I couldn't find exact information because dlss is so mixed and random.",
      "No but this one was.",
      "I bought a 4080 super today for my new build. For someone specing a build less than $2,000, you think this is better than bankrupting myself for a 4090 to learn ML and AI related stuff?",
      "More like a \"meh\"-gathread, am I right guys?     \nSeriously though, seems like a nice buy, considering the market, and if you were holding off on upgrading for a while.",
      "“Everyone” being mostly scalpers. \n\nDid you see how many FEs went up on eBay? One guy I saw was selling 10 of them.",
      "Had a couple Zotac cards and never had issues.",
      "I am in the exact same boat and the struggle is real because if you spend any time reading about optimal configs for AI, VRAM is undoubtedly the bottleneck and most people will tell you to get a 3090 if you can't afford a 4090.  Where I might land is to go with the 4080 super for now as it's basically a price reduced 4080 and if I find I really need additional VRAM, add in a Tesla P40 used workstation card to get a cumulative total more than 24GB (16G on the 4080S, 24GB on the P40)."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "top",
    "matched_keywords": [
      "rtx 4090",
      "4090"
    ],
    "title": "Ebay buyer stole my RTX 4090s GPU chip",
    "selftext": "TLDR Buyer bought my GPU, returned it, sans GPU chip and ram. I fought it, Ebay paid them, I kept my money I'm whole....with a PCB.\n\nI thought you all might find this interesting. I had heard rumors of this happening, but thought it was rumor/hoax.\n\nI sold an RTX 4090 couple weeks ago. Something about the buyer setoff some alarm bells. It was a huge ebayer. One of those with like 30k feedback and a storefront. Why would they pay retail for my GPU? The address was business in California and the buyer name seemed \"odd\". So I took a ton of pictures, got mega insurance, tracking etc.\n\nSame day they receive it they start a return. \"no video\". This card was pristine, I'm am engineer and I barely used it. So I get the card back and man it had seen some ...\\*\\*\\*\\*. The mounting bracket was bent up. Couple wired were crossed on the RGB.\n\nI called ebay, was nice but 100% this damaged I will go to court. Ebay said keep the card, keep the money, we will give them a one time refund. \"wow ok\". \n\nI figure maybe its salvageable and they are just stupid. I repair the bracket start an RMA. Its really bothering me so tonight before I shipped. I tore it down. Sure enough GPU is gone. \n\nSo here I sit. I'm whole, but I'm not sure what to do. \n\nI already reported them to ebay. Thinking about calling the cops. Whatcha think? I thought it was neat enough to share.\n\n\n\n",
    "comments": [
      "Wonder if the account was hacked, 30k feedback on an account is insane to throw away over whatever you could sell the chip for.",
      "Yeah, it is almost always a hack like that.  They get in, change address, wait a while, then pull several of these at once.",
      "Make a police report in his city",
      "Crazy how ebay just let them off like that... No wonder people keep doing it",
      "Idk. It gets kind of interesting. I cant provide personal info, but I traced the Buyer back to a business in California thats been reported several times to the BBB for fraud.\n\nThey have some weird overpriced hardware business, Like they sell RTX 4090s for $3-4k scamming locals idk. I agree its odd that they have perfect feedback on ebay, but it doesn't look like a hack just scum. Then again this wholes things  bizarre.\n\n*edit\n\nFolks asking me for the buyers info: Theres rules all over reddit about providing personal info. I'm mostly concerned about getting banned. It explicitly states so on the ebay sub where this started. If I give out the info and they get doxxed Im concerned it could come back to me on reddit or legally.\n\n For what its worth last night I reported them to ebays fraud department and a couple investigative orgs and will likely look into it more today. I also do not want them to prey on anybody else. I definitely understand where you're coming from. \n\nI can't take them to court \"I don't think, because ebay ate the cost. Im fine. I mentioned claims court because that was my next step if ebay hadn't stepped in and helped me. That said even if its useless I will file reports with legal agencies.",
      "Honestly, they need to be named and shamed. What if someone here considers buying their products? People need to know what store this is. Otherwise, they get to skate by on their 30,000 reputation feedback score and scam others. \n\nYou're the current line of defence against every honest buyer and seller that may come across this post. \n\nPut them out there.",
      "They aren't going to do anything.",
      "i been though this, as soon as you mention ebay and the internet your local cops are going to tell you its a \"civil matter\" and to contact ebay.",
      "Die is going straight to china for AI farms. Scummy.",
      "True, but PayPal may like the documentation for his dispute.",
      "I lost my 16 year old seller account because a video game store with more negatives than I had total feedback in thr last five years, in California, purchased a sealed xbox series x from me. It had four seal stickers at shipment. I have the serial number sticker photographed in the listing. \n\nThey returned it and left negative feedback. Stating it wasnt sealed. They returned an xbox one in a damaged series x box and the serial numbers matched my listing.\n\nEbay had all of the evidence, I had the USPS sealed the box on video, they let the seller off the hook, charged me and locked my account for investigation.\n\nI filed a police report because ebay told me to. I uploaded it.\nEbay deleted my account. 700+ feedback as a buyer and 400+’feedback as a seller gone.\n\nFuck ebay",
      "I mean almost certainly it's getting shipped off to China though I'm not sure why they need to resort to this",
      "Because us poor folk don’t get the same treatment if this done to a corporation. \n\nWe don’t get protected like CEOs and the Corporations",
      "No real way to police it I guess? They must know it's a problem if they refunded both seller and buyer.",
      "The BBB is not a government entity. It’s a commercial review site like Yelp.",
      "Sold my 4090 on eBay to someone with 1 feedback (forgot to put a requirement) and I knew there was a high chance it would be a scammer. Buyer paid immediately, I shipped the card after the weekend was over and a few hours later I got an email from eBay that the buyer has been removed from the platform and that I shouldn’t ship the gpu. I called customer service and informed them that it was already shipped (prior to that I called ups to try to have it redirected to my address but they told me that eBay has to initiate this because otherwise I would eat the shipping cost). eBay csr confirmed that the buyer has been banned from the website and that the back office would try to reroute it back to my address or if that didn’t work, I would get a full refund for the price I had it listed. 2 days later I see that the gpu was delivered to that location but I got a full refund from eBay. I googled the address and it was some sort of hub that ships internationally, so it was definitely shipped to China after that. Even with direct signature required, they were able to receive the package by a different person.",
      "FBI might be interested if so… top level chips black market is a hot national security topic",
      "Ok, so I know this is about eBay, but honestly, Amazon and Walmart have the same problem. It's everywhere now, and it's getting ridiculous. People returning the wrong item or even removing core chips and sending them back like nothing happened—it’s basically a scam at this point. Shopping online is turning into a total headache.",
      "GPU core is getting installed into another card with more VRAM. Search for 48 GB 4090.",
      "I agree. For OP to go through the process of documenting and posting this story and then withhold the offender is ridiculous.\n\nThis buyer supposedly committed a scam involving an intricate premeditated theft and fraud (among other crimes) thereby putting all sellers at risk… OP should at least provide an indirect clue that can be researched.\n\nTo take us 99% of the way there and then decide to protect the criminal puts this in “nice story bro” territory."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "top",
    "matched_keywords": [
      "rtx 4090",
      "4090"
    ],
    "title": "RTX 4090 Adapter burned",
    "selftext": "",
    "comments": [
      "Maybe you plugged in/out 31 times :⁠^⁠)",
      "Gamers Nexus would like to know your location",
      "Hope NVIDIA and its AIB are ready to honor their warranty for stuff like this for next 3-5 years ;s",
      "I dont know why it happened. I think my adapter cable is faulty. Welp i guess RMA it is\nEDIT\nCard was attached vertically. Bend was not that aggressive. Sure there was bend still this should not happen on a 2k Euro gpu PSU Corsair rmx 1000",
      "Hey u/reggie_gakil  I just sent you a direct message. Please take a look, thank you.",
      "You aren't the only one. This happened to me today as well, not as badly burned as your though. I was having a gaming session few hours ago, playing Black Desert with my dungeon party. All the sudden the screen went black and all the fans started spinning at 100%. Powered off the machine and after some inspection noticed that the power adapter was damaged. \n\nMy card is Asus RTX 4090 TUF Gaming - OC Edition\n\n&#x200B;\n\n[https://cdn.discordapp.com/attachments/1023507386805256192/1034182353741938788/rtx4090\\_poweradapter.jpeg](https://cdn.discordapp.com/attachments/1023507386805256192/1034182353741938788/rtx4090_poweradapter.jpeg)",
      "once you got your replacement card, reach out to us and we will send you a free PCIE cable to help you out a little bit!",
      "\"Back to you Steve\"",
      "Plenty of cable relief on that, possibly a defect",
      "[https://cdn.discordapp.com/attachments/513140358729957378/1032633584877576192/unknown.png](https://cdn.discordapp.com/attachments/513140358729957378/1032633584877576192/unknown.png)",
      "\"thanks Steve\"",
      "I bet they will just say it is user error.",
      "There’s gonna be a lot of melted connectors",
      "that was the setup",
      "Don't bend vertically nor horizontally. If that's the case don't give us a flexible cable to begin with.",
      "You think 5000 series is going to be cheaper? Nope.",
      "There are no fucking excuses. For a card that costs €2,000, the connector should be deep space mining grade. Of any other material except crappy plastic.\n\nPlease guys, stop justifying crappy business practices that only hurt the consumer, and encourage future graphics cards to be even more expensive with worse materials.\n\nI wish you good luck with the RMA process.\n\nEdit: changed military grade.",
      "Didn't Jayz2Centz warn about this?",
      "I guess that's the risk of...\n\nearly adapters.",
      "\"On this week's episode of Gamers Nexus.\""
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "top",
    "matched_keywords": [
      "4090"
    ],
    "title": "Getting the 5090 was genuinely impossible so I used some of the money to upgrade everything else and keep my 4090",
    "selftext": "New 9800X3D, TRYX Panorama AIO, Lian Li o11 Vision Compact ",
    "comments": [
      "You don't have a 5090? \nPff. Your computer might as well be a potato",
      "I can't see why you would get a 5090 if you have a 4090",
      "Yeah, what an outdated piece of crap. I feel sorry for OP having to settle for a 4090....",
      "4090 user here. It's terrible, really awful only having the 2nd best GPU in existence. Pure torture.",
      "Damn nice setup man. i think you can skip this gen. 4090 is till beast",
      "The only argument I have to this is if you bought 4090 at retail for 2 years ago, you can still sell it for profit and put it towards a 5090. With the stupid 5090 prices, it’s probably not worth it but it is an objectively better card when it’s not on fire",
      "This statement is actually sad, I remember when the 70 class would beat the last year top of the line. Now we struggle to even get 10 percent more than last gen.",
      "With all the reports and analysis already being done, it'd be foolish to spend that much on a 5090 when the 12vhpwr connector issue hasn't been addressed. It's just a ticking time bomb.",
      "Getting a 5090 was genuinely impossible so I used some of the money to R&D a Time Machine. I then used that to travel towards the year 2043 where I designed this futuristic as fuck looking PC which I have bought back to show you in the year 2025. I put my old 4090 in it so your caveman minds can comprehend the marvel of technology that you’re witnessing.",
      "Still the second best gaming card in the world!",
      "I feel like I've grown out of my rgb phase, but man those customizable lcd screen AIOs look so sick. Just can't justify the premium you gotta pay.",
      "wish my computer could suck with a 4090.",
      "5070 = 4090 tho, Jensen wouldn’t lie to us would he",
      "So you have a 4090? Why again do you need a 5090?",
      "Yeah, but as an owner of the best GPU in existence, I can tell you that it’s a lot of stress. \n\nPeople constantly want to see my GPU. They ask to try it out. They want to play a game with it. \n\nOne guy offered me $5,000 for it…\n\nI had to stop him and let him know, “I only paid $699 for this 1080ti when it launched… $5,000 seems too high!”",
      "Even if I had the money I'll be very afraid to buy 5090 at the moment...",
      "The trauma of not getting 5090 when already having a 4090 lol hilarious.",
      "Imagine being eager to upgrade when you already have a 4090. Please practice patience so your brain rot can recover. Or enjoy low dopamine states at most times.",
      "Yeah I have the Suprim Liquid 4090 and was debating whether to go Founders 5090. Doesn’t seem worth it considering I’m never above 49c and on 1440p.",
      "1440, forget it.\n\nSame here with 4090 tuf oc\n\nEdited: it's only taken 6 months of people saying i was wasting it on 1440p to now saying it's a good fit fwiw"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "top",
    "matched_keywords": [
      "rtx 4090",
      "4090"
    ],
    "title": "ITX motherboard installed on a RTX 4090",
    "selftext": "",
    "comments": [
      "You probably could fit a whole ITX system on the 6090",
      "You got some motherboard on your GPU",
      "Joke's on you, the 6090 is going to be an integrated PSU/Motherboard unit that you slot your other components into.",
      "I'm personally waiting for the 5090 which will also function as a gaming desk.",
      "That doesn't sound like a bad idea tbh",
      "\"Look at me\n\nI am the motherboard now\"",
      "ITX format makes no more sense to me with these cards.",
      "https://twitter.com/9550pro/status/1572272657760153600?t=9ITqDyc3g_LzajkZf6F8Ow&s=19",
      "It does with a waterblock.",
      "I wouldn't be surprised if it's the future of PC's tbf, whole computer units built onto a big GPU.",
      "That will also keep your hands warm in a cold winter. Brilliant.",
      "Is Nvidia planning to build a gpu case for 5090 that will come with an air conditioner.",
      "Sure, but then be ~~really~~ ready to shell out 5 grand for GPU+barebone systems. More proprietary tech, closed down ecosystems and solely controlled supply chains. I'd rather hope for a polyopoly.",
      "> sounds reasonable\n\nUntil you see the price tag they'd probably slap on these things.",
      "They have their own linus now.",
      "They are all just circuit boards.",
      "Is there a spec limitation for how tall a GPU can be? Considering many will have something like a big ass Noctua tower cooler on their CPU, why not have something just as tall for the GPU? You could put 140mm fans on it while having the heatsink be tall but slimmer rather than just taking up more PCIe slot space and ever more length.",
      "You're a circuit board",
      "ATX case standards set some limits, Intel and AMD boards have their own \"safe areas\" for CPU coolers also defined. Also when things go large, there are limits how many kilos of copper you can bolt on.\n\nIn general there is a point where adding more just doesn't work well and it is better to go with a waterpump and a separate radiator.\n\nFrankly personally starting to look at MO-RA3 as more and more sane option these days. Can get away with a lot smaller case with tiny waterblocks and ther just routing the problem out of the case completely. Only thing I worry about a bit is the whole mess of wiring the pump and the fans for it.. seems like bit of an arts-and-crafts project to get the extensions and make the cabling work out nicely in addition to the waterloop tubes.",
      "are you kidding? it'll keep half the house warm at idle"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "top",
    "matched_keywords": [
      "rtx 4090",
      "4090"
    ],
    "title": "Sneak peek at RTX 4090",
    "selftext": "",
    "comments": [
      "\"Eight GPUs in SLI but only takes 4 PCI slots - that way it's a compact card!\" lol",
      "It is actually funny. lol   \nImagine the amount of work he has done for this video.",
      "The absolute mad man. Huge amount of work put into this joke he built a damn PCB lol. Props to him",
      "I was amazed when he showed the PCB, so much attention to detail!",
      "Every 30 seconds, he outdid himself so much that I was aghast once again!",
      "That can of Pepsi is brilliant.  Well done.",
      "The absolute dedication to the gag is amazing.",
      "On the one hand I first assumed he just took a PCB out of something else and cut it into a weird shape.\n\nOn the other hand, the placement and markings around the non-rectangle edges seem to match up really nicely.\n\nHowever he did it, he's done an awesome job!",
      "This honestly needs more upvotes. Not only did he make a full pcb but also his own graphics for a gpu test. Funny as hell",
      "Quite inventive of Nvidia to utilise adaptive liquid cooling, having the fans powerful enough to pull in and shred that can of pepsi probably shaved a good few degrees off the temps. Wonder if coke would produce better results?",
      "are people forgetting the 690 was two chips on one PCB? soooo technically....",
      "I think the fact that the video is 4m 20s long isn't a coincidence.",
      "Hahaha - The Coke can got me.\n\nWtf though\n\nEdit : more lolz, it kept on getting better",
      "I honestly don't think the PCB is 3D printed.  The amount of work to make a 3d print look that good would probably exceed the time/cost to just make a real PCB.  \n\nHis old videos are also equally convincing.  The housing is also top notch quality mockup. Really impressive work overall",
      "i prefered the your mom joke in the benchmark but yeah, pretty good",
      "Joke? Wait, so you're saying it's not real?",
      "I was looking for somewhere to preorder...it’s not like I’m getting a 30 series...",
      "Where do I start queuing, want one within 3 MTHS of release?",
      "I love the fact that went as far as making a \"PCB\" and all the parts for this :D",
      "You guys should check out his previous videos too, they're hilarious. His first one was making the physical version of a joke card from a PC magazine."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "top",
    "matched_keywords": [
      "rtx 4090",
      "4090"
    ],
    "title": "RTX 4090 Tustin California Micro Center Launch. 9 hours left!",
    "selftext": "",
    "comments": [
      "Nvidia looking at this: \"where is all the dumb c**** that said no one gonna be buying 4090 at 1600 dollars?\"",
      "Brace yourselves. GPU on car seat posts incoming",
      "It turns out redditors are out of touch with reality once again. Imagine actually thinking this card wasn’t gonna sell like hot cakes.",
      "Well that's depressing but not unexpected. Nvidia could've charged $2,400 for this thing and people would still be lining up like this.",
      "as a former micro center tustin employee, i sincerely wish that every single one of you would go home",
      "first batch always sells\n\navailability week after launch will show us true demand on this card",
      "Woah.. And I thought showing up 30min before opening was excessive....",
      "NVIDIA's AI already informed Jensen that the card will sell well with that price.",
      "Guy at the front has been here since yesterday",
      "This is what I was thinking, don’t forget, they will have it buckled too",
      "Here we go again",
      "These people be camping outside all night. Meanwhile, Jensen is sleeping soundly wearing his comfy leather jacket.",
      "What recession?",
      "Don't worry, that's coming next gen. This was their plan to test the waters. If day 1 this card had poor sales and nobody lined up for it, then maybe there was chance of Nvidia realizing, oh shit maybe that was a tad bit too high.  \n  \nBut clearly its going to sell out day 1, and now Nvidia's going to look at this and go, awesome we're definitely raising prices again.",
      "That's what I am most interested in seeing as well. Every major GPU launch sells out. Also a good amount are probably scalpers I imagine.",
      "I'm both amazed and terrified, about equal parts.",
      "I get it, like its a fast GPU, demolishes 4K. But this basically just gives Nvidia the green light.",
      "Let's hope them scalpers are left holding the bag",
      "They'd need to be, since the seatbelt sensor will keep beeping at them if they don't.",
      "They are just buying the card to keep their homeless car or tent heated in the winter."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "top",
    "matched_keywords": [
      "rtx 4090",
      "4090"
    ],
    "title": "[Gamers Nexus] The Truth About NVIDIA’s RTX 4090 Adapters: Testing, X-Ray, & 12VHPWR Failures",
    "selftext": "",
    "comments": [
      "Finally some clarity. GN once again doing the work.\n\nEstimation of failures is 0.05% to 0.1%.\nBasically it's mostly user error with connectors that aren't fully seated (design oversight on the adapters that should have a clear audible click). Fringe cases of connectors with internal debris causing contacts where there shouldn't be.",
      "Tl;dw all cables are susceptible, even the cablemod ones\n\nAnd the cause seems to be mostly user error, with some poor design and manufacturing error thrown in\n\nIt could also be argued the user error is caused by poor design",
      "Information with actual reasearch, testing and evidence. I tip my hat to GN.",
      "Lmao, Cablemod making bank on user errors.",
      "This is why I love GN, their work is on par with what I'd expect from a vendor doing a quality control related root cause analysis.\n\nGood stuff, great analysis and testing.\n\nThe end result doesn't surprise me either.",
      "JohnnyGURU basically said the same thing and was attacked by most people on this forum.",
      "So the top likely failure cause is from incorrect insertion.\n\nAnother failure cause but less likely is from foreign object debris from manufacturing.",
      "So that msi graphic that people flamed was right.",
      "TLDW - PLUG THE DAMN CABLE IN ALL THE WAY NOT JUST MOST OR ALMOST!",
      "You already know jay is going to make a 30 minutes video copy pasting what gamer nexus says with some lame ass jokes.",
      "Funny that, how a manufacturer who actually built the fuckin things might know better than a forum full of idiots hammering at their keyboards",
      "Thanks I was waiting for someone to post this as I couldn't",
      "Tbh I would’ve bought a CableMod cable regardless, the stock adapter looks terrible.",
      "I know one conclusion I support. Igor's lab is not a good source for these \"fear gate\" news. The guy jumps the gun and is wrong often. \n\nCapacitor gate, cable gate. What next Igor?\n\nThank god we have Steve GN, Johnny Guru, etc.",
      "That was a sad event that occurred... Johnny was even confused with the toxicity of Reddit since he doesn't post here often. That says a lot about the Reddit community.",
      "So “you’re holding it wrong” with a few added steps will be the tact NVIDIA takes but benevolently offer new cables.\n\nThese should be easy to insert, give good solid feedback (CLICK) that the cable is seated, and should survive dozens of connections.  I worked in durable customer goods manufacturing and in almost all cases we treated products failing to perform as expected as a manufacturing or design defect.",
      "I was sort of shocked when i first plugged it in, there was no audible or tactile click of any kind, but pulling and repushing confirmed it was attached. Not the best design choice considering pretty much every single other plug involved in a PC's wiring clicks.",
      "When I get home from work; I’m gonna shove in that connector with all my might.",
      "The knock against JayzTwoCents at the end was just classic.",
      "That's not manufacturing error, that is poor design. Works as intended if used correctly, but goes very wrong very quickly if it meets a certain failure mode."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "top",
    "matched_keywords": [
      "rtx 4090",
      "4090"
    ],
    "title": "My 4090 build 🫠",
    "selftext": "Intel Core i9-14900K, Asus RTX 4090, 96gb G.Skill 7000mt/s",
    "comments": [
      "I can’t even afford to look at this picture",
      "Get in the pc, Shinji",
      "Comparison is the thief of joy bro.",
      "Same. I thought my new build was pretty decent. I went top tier on almost everything but got a 5080 instead of a 5090. Just couldn't justify an extra $1000+. I was somewhere around $4500 total. I knew my friend had a pretty high end PC too so I sent him pics.\n\nHe replies back saying oh, nice, that's cool. He sends me a pic of his and I zoom in, he had to have dropped over $6k. Little LCD screen just like this showing he's got a 4090.. a bunch of hard tubing custom water cooling. My guess is just those 2 things were $3500 - $4000. Man was I humbled real quick lol",
      "Phanteks case, EK water cooling loop. I see what you did there. Are those corsair fans turned on the backside for the intake or is it just my imaginaion? Noice 👌🏻",
      "Negligible difference for cooling. It's a LOOP of liquid. Google thermodynamics in liquids.",
      "It's crazy how exponentially the price of PCs increases too. Like I spent $700 on my rig with a 4060 and it plays most games on very high settings, often the highest available. I'm coming off an xbox one, so it all looks gorgeous to me compared to that. Unless I was just rolling in cash, I'd have a real hard time spending 8 times as much just to crank out a little bit higher settings. Sure, this rig will last a lot longer before needing an upgrade, but not even close to 8x as long.",
      "It looks like the loop goes directly from the CPU to the GPU? Is that correct? While that would make cleaner routing isn’t that suboptimal for cooling? Is that 3 radiators or two? I’m a n00b to this, thanks for sharing and explaining.",
      "I can barely build a computer. I would spill all that liquid",
      "I have temp sensors directly embedded in the water in several parts of my loop. The temp rise between the cpu and gpu is about 1 degree F. Water is great at storing energy. \n\nIf I turn my fans off, run the cpu and gpu at full bore and let the loop pump, the water temp takes a few minutes to rise 10 degrees.",
      "Those pipes 😍",
      "Imagine how well it can run Solitaire",
      "Absolutely beautiful. One thing I always struggle with is asthetic...mine generally looks boring lol. Some of you are artists. Well done!",
      "Phanteks NV7 👌",
      "Curious, why 14900K instead of 9800x3d? I believe 14th gen intel cpus still has that instability issue, I'd definitely choose 9800x3d at this price point especially since it's 20% faster also.",
      "All one needed to do was install the bios updates that patched those issues, test for instability / degradation, and get a replacement from intel if they found their chip degraded before the updates dropped. This issue seems pretty well behind us now, and I've personally had no problems, despite running this chip fully unlocked (at up to 350w) myself. \n\nI would probably be sticking with my 13900KS too tbh, but I got an unexpected Nvidia priority access 5090 invite and found a 9950X3D for MSRP as well.",
      "What kind of case is that ? It’s huge",
      "14900k, lol.",
      "Gonna be a pain in the arse to tear down when the CPU inevitably degrades too. 😬",
      "You haven’t experienced 240hz or buttery smooth gameplay at 200/300FPS in games. \n\nI used to say the same thing back before I purchased the 7800X3D/4080s. Comparing it to my 5600X/7700XT it’s night n day."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "top",
    "matched_keywords": [
      "4090"
    ],
    "title": "My OC'd 5080 now matches my stock 4090 in benchmarks.",
    "selftext": "",
    "comments": [
      "Money can't buy 🧠",
      "You have a 5800X",
      "Now slightly overclock the 4090 lol",
      "$3,000 spent in graphics power to test/play on a $180 processor on an AM4 board and DDR4.",
      "This what I don't get with all these posts.\n\n\"my 5080 OC is the same as my stock 4090!!!!\"\n\nAye... So... You can't OC your 4090 to have a similar linear gain vs 5080???",
      "You traded a 4090 for a 5080 which only matches if you overclock it? I mean you do you but id buy a better 9800x3d and new motherboard plus ram.",
      "That cpu bottleneck tho...",
      "Losing out on 8GB VRAM and needing to OC to achieve identical performance for a $500 savings that won't age much better doesn't really seem to be worth it.",
      "A 5800x non 3D is most certainly bottlenecking. Especially on early Unreal Engine games like this.\n\nWhat was the performance when both cards are running at stock?",
      "The 5080 OC's especially well though. Its just cool to see, no one is saying the 5080 is a better card than the 4090.",
      "Sell RTX 4090 for $1500+, buy 5080 FE for $1000 and pocket the difference.",
      "Yeah, good luck getting a 5080 for $1000.",
      "The story usually goes like: \"I sold my 4090 after the announcement hearing that the 5070 matched it, then I waited outside microcenter for 20 hours and was only able to get a 5080\" lol. So now they are stuck and can't do anything about it.",
      "I imagine lots of GPU’s can match a 4090 in a CPU bottlenecked scenario…",
      "5800x was a $450 CPU.",
      "I also have a 5800X (since launch) , 4090, and play at 4k.\n\nI’m not spending $900-$1,000 on a new CPU, motherboard, and RAM for a max of 10%-15% more performance on my 4090.",
      "This is optimal 4K performance.  You may not like it, but it is.",
      "\\*the 5800x3D was a 450$ CPU",
      "Maybec YouTuber or something",
      "I moved recently from a 5800x to a 7800x3d and the higher end FPS jump may not be that crazy, however games feel so much smoother and responsive so I can only imagine framerate stability and 1%/0.1% lows are substantially increased."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "top",
    "matched_keywords": [
      "rtx 4090",
      "4090"
    ],
    "title": "Here's all the RTX 4090 prices from Overclockers",
    "selftext": "",
    "comments": [
      "Definitely rooting for AMD.  NVIDIA corporate greed is on a whole other level now.",
      "Who can buy such expensive cards, nvidia really wants to kill their customer base, I don't want to know the price in euro something like 2300 Euro.",
      "If AMD is smart they would price their counterparts each 599$, 799$ and 999$. This move alone would net them so many Nvidia costumers.\n\nBut let's be honest they will price their cards a 100 bucks less and then act as if they have done the PC community a favour.\n\nNvidia is high on the crypto boom which doesn't exist anymore. They will probably slash prices once 30 series stock starts going down.",
      "Cheapest card in the picture is £1679,99 . Remove 20% VAT => £1399,99. \n\nIs this close to the MSRP?",
      "Its not only that too, high energy prices are becoming a factor here, and at idle it wont really be an issue, but you you are full blast pulling 200w from your cpu and 400w from your gpu, with maybe another 50-100w overhead for the rest of the computer+monitor/VR headset, and you put in some long sessions like 6 hours a day for a solid week its about 25kw, i think that works out about £5-10 of electricity a week with our sky high prices.\n\nIts not insignificant, a heavy gamer could easily be adding £25 a month on bills, i suppose if you can afford a 4090 you can afford an extra £25 a month on electric, but what if unit costs double, it could be a real problem.",
      "Yesterday it would have been $1582. Yeah our economies fucked.",
      "100% sitting this gen out.  I hope AMD pulls a rabbit out of a hat",
      "Why people think AMD care about consumers is beyond me, since AMD has proven that just like any other corporation, all they care about is profit, and they will take the piss if they can and whenever they're able to.",
      "Here in Australia the FE is around $2,959, I can only imagine the AIB prices",
      "thats $1519 USD",
      "Not looking atractive to keep buying GPUs from now on. Move on to something else. Good that I have music Instruments and skates/skateboard.\n\nSee you outside guys :)",
      "AMD aren't going to price competitively either, these people are in for a rude awakening. They'll just price slightly lower than NVIDIA's batshit pricing to reflect the lack of features and demand.",
      "Nope. These prices are out of control and it's just going to lead to a crash of the GPU market. People are going to look at consoles as a far more affordable choice for gaming and PC owners will just stick to the current cards they have now.",
      "What the fuck? This is nuts. I'm done for a few years lol. This just burns my eyes.",
      "It's unlikely they may slightly under cut. But amd is a business also and is driven by profits. It would be great if they came out and made a 4080 12gb aka 4070 competitor at 499 or 599 or something similar ,and under cut nvidia. but it's likely they will try to price as close as they can get away with",
      "4090 FE is quoted at 1959€ on nVidia's page. Can expect AIBs to cost 100-400€ more depending on the model. It's silly.",
      "Man I remember when $2000 was more than enough to build a high tier PC. Now that's just a video card.",
      "no GPU should be over $1000 USD change my mind",
      "Nvidia response \"Don't be poor.\"",
      "With PlayStations and XBox readily available now, PC gaming is looking less and less attractive.  I could buy myself and 3 friends or family a console for how much it cost for one fugly Aorus Master."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "top",
    "matched_keywords": [
      "rtx 4090",
      "4090"
    ],
    "title": "GeForce 9500 GT in a Zotac RTX 4090 box. Oh how far we've come.",
    "selftext": "",
    "comments": [
      "POV: you just bought a 4090 from Newegg",
      "Back when XFX sold Nvidia cards.",
      "And there was a time when tech was getting smaller not bigger",
      "I laughed way too hard at this. Thank you.",
      "Back when the name \"video card\" made sense",
      "That is correct.",
      "I've had all kinds of issues. I don't buy from them anymore.\n\nEdit: For example, they had a bundle on ryzen cpu, mobo and ram. I got everything assembled and it turned out the mobo did not have a bios that supported the bundled cpu. It couldn't be updated without an older cpu. I contacted customer support and they said I was shit out of luck and they do not guarantee compatibility in their bundles.",
      "now it should be \"graphics engine\"",
      "I don’t get it, is Newegg not trustworthy, or something?",
      "Never had any problem with Newegg. Customer for 5+ years.",
      "Probably a noticeable upgrade. ; )",
      "My first XFX card caught fire.\n\nLiterally caught fire, not 'started smoking' I mean there was a solid pilot light's worth of flame.\n\nXFX's response? They didn't just overnight me a new card, they upgraded me two generations and then when they realized that 1x 7750 was worse than my previous 2x 5770s, he tossed another 7750 in for me to crossfire as well so I would lose out on nothing.\n\nAlso the guys' reaction when he saw the pictures was hilarious.\n\n\"Hol^ly shit it ACTUALLY _DID CATCH ON_ ^_FIRE_?!\"",
      "You vs the guy she told you not to worry about.",
      "or \"rendering obelisk\"",
      "One of my first cards was xfx, I loved it",
      "That’s one of the dumbest takes I’ve ever seen",
      ">the overall power consumption of GPUs isn't that different (save for models like the 6950XT or 4090) than older cards with much smaller coolers. \n\nNah, it's a lot higher in general. An entire high end system with an 8800GTX would pull around 300w in game, while my 3090 alone can pull more than 100W more than that.",
      "[newegg.ca](https://newegg.ca) bundled a 5600x with a 450W Corsair PSU during the height of the COVID related PC parts frenzy. Nobody is building a 5600x system with 450W lol. Yet it sold out.",
      "It's funny you think it was ryzen 5000. It was actually a 2700x, so they've clearly been fucking people over in the same way for a long time.",
      "Lol it's OK bud, I won't talk badly about your precious newegg anymore."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "top",
    "matched_keywords": [
      "rtx 4090",
      "4090"
    ],
    "title": "New RTX 4090 Build",
    "selftext": "",
    "comments": [
      "Nvidia should offer a free smoke alarm with every purchase!",
      "Took me a moment to see the smoke detector 🤣",
      "And life insurance too.",
      "That smoke alarm is best part of the pc. 🔥🔥🔥🤣🤣🤣",
      "Today : Build\n\nTomorrow : Bonfire",
      "Corporate shitposting is best shitposting!",
      "The smoke detector really puts it all together huh.",
      "Only reason I noticed it was because I noticed that they had a single fan over the triple fan intake.",
      "The sag on that video card is already noticeable.",
      "A free get fucked or your money back guarantee too.",
      "B-b-b-b-b-b-bo-bonfire!",
      "Took me a sec, LOL",
      "Lit🔥",
      "Oh this is golden! This should be in best of 2022 album!",
      "honestly, not that bad of an idea to have all things considered. Just need to make RGB smoke alarms to match that build.  This one could work in a noctua build tho.",
      "Home owners insurance covers pc fires",
      "They will offer a free gigabyte PSU for maximum ~~impact~~  performance.",
      "Unfortunately the anti-sag braket that comes with the Gigabyte 4090 won't work in that case",
      "I mean at this point a 3d printed brace would do the job. Anything non metallic or magnetic would be better than nothing.",
      "Ah yes, to turn a profit sell a dangerous product and get paid in the form of life insurance payouts lol"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "top",
    "matched_keywords": [
      "rtx 4090",
      "4090"
    ],
    "title": "I know I'm late to the party, how I did with a RTX 4090 3 months old GPU? $800 from a friend!",
    "selftext": "",
    "comments": [
      "When’s the wedding?",
      "What did you threaten your friend with to get that price?",
      "Not that much money apparently... Your friend essentially gifted you 600-800 dollars",
      "Lol, naahhh he just need the money!",
      "5070 is 4090 performance, sell fast\n\nEdit: btw, that was sarcasm, i still have my 4090 and would never sell that boy",
      "Now pass it on to me your new friend for 300$",
      "Thats a great deal! Congrats on that card and a decent friend 👏",
      "No 5070 no where near performance of a 4090 bro\nOnly with dlss 4 nd frame gen do u get performance like 4090 , keyword like.",
      "At the moment? He gifted him 800-1000€. At least if you take the european used market as a reference. GZ op.",
      "nice. i got my bids in on 1400 bucks so you did better than me",
      "He could have easily gotten money elsewhere, and a lot more. He’s a good friend.",
      "4090 is selling for 1700 at the very least on used market",
      "You know you did well that's why you're posting it.\nEnjoy the card the 4090 is the new 1080ti",
      "pretty damn good",
      "Your ‘friend’ is a Homeless man you paid $800 to boost you a 4090 dont lie",
      "Lol no it doesn't.  U need to learn the difference between raw performance nd ai generated frames with dlss nd frame gen. If u play alan wake, I get 60fps ultra contant, maxed out no dlss or frame gen. U with a 5070 native no dlss would get 20 to 30 frames. Ull need dlss nd frame gen which causes alot of artifacts and glitches. Depending on which u set like quality balance performance etc. Dlss4 nd frame gen will give performance \"like\" 4090, meaning the only way ull get high frames is thro dlss. Doesn't mean it will out performance a 4090. Nvidia admitted 5070 is no where near the performance of a 4090. So yea its not the same shit.",
      "There’s a reason the 4090 is selling for $2.2k and the 5070 will be less than half that. Maybe one day you’ll get it",
      "god damn that look's beautiful",
      "It seems you bought yourself RTX5080 Ti. Good job! You're ahead of your time, not late at all 😂 It's both funny and tragic, but - great for you. Much better choice than anything at this moment. RTX 5090 will be good within a year, I never understand those people buying it on premiere. Burning cables with 4090, now PCI, drivers and games issues with 5090. When 5080Ti releases and there will be stable mods for frame gen on 4000 series, or just better lossless scaling or even the official multi FG support for 4000 from DLSS4, it may turn out that we'll still have better GPUs than a whole new generation. 5080Ti will become just 4090 + multi FG and if that's also taken away by a better lossless scaling or the official multi FG support, then well... It will be even more funny. So - good job, again.",
      "Man I need a friend who needs money like this lol.. 800 for a 4090 is a steal"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "top",
    "matched_keywords": [
      "rtx 4090",
      "4090"
    ],
    "title": "RTX 4090's in stock on Central Computers shelves",
    "selftext": "",
    "comments": [
      "And they’re on NewEgg right now for retail. :) Fuck Scalpers.",
      "*4090s ARE ROTTING ON SHELVES!!!*",
      "Went to the grocery store and saw food on shelves. TERRIBLE VALUE",
      "$550 MSRP over the founders is bonkers \n\n\nCould literally buy a founders 4090 + a PS5 for the price of that card",
      "Wow…the white ROG in the flesh. Too bad about the price ($150 for white…sigh).",
      "Weird. I’m not seeing any “direct from Newegg” but the same third party sellers that were scalping before.",
      "I saw behind the door of the stock room at their Sunnyvale location two days ago and there were two or three stacks of ASUS 4090s literally from floor to almost the ceiling.",
      "Time to make a video about how no one wants the 4090 and they aren't selling. Also switching to AMD!",
      "OVER $2K lmaoooo",
      "Asus basically took a 4090 FE and said, we will add one fan and paint it white and charge you the price of a i9-13900k for it 🥴",
      "👀",
      "Yep. 4090s are a thing you can buy now.  Show me some 5090s on shelves.  Now that would be news.",
      "I wore a green polo to NVIDIA HQ and they took me to the back and let me pet the creature that lays the 4090s.",
      "At least Newegg has replacement-only policy now iirc.\n\nInterestingly both anti-consumer and  anti-scalper.",
      "Where I got my Suprim X on launch day. Online Order. Highly recommend Central Computers!",
      "Yeeah where are you? Not in the US they aren’t. Closest was a pny for 200 over. Most everything is like 2-2.5k",
      "This is funny because right now nvidia and food is a terrible vlaue",
      "2nd shipment arrived. Cards about to reach normal stock",
      "Hey there! We have 5 locations in the greater San Francisco Bay Area in California! However, many of these RTX 4090s can be bought online too! Feel free to check them out on our RTX 40 Series Landing page [here](https://www.centralcomputer.com/nvidia-rtx-40-series-information)!",
      "Best computer store!\n\n![gif](giphy|fT3PPZwB2lZMk)"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "top",
    "matched_keywords": [
      "rtx 4090",
      "4090"
    ],
    "title": "RTX 4090 started burning",
    "selftext": "My new graphic card started burning, what do i do now?\nI unplugged it straight away when it started burning.\n\nWhy have nvidia not officially annouced this yet?\n\nI actually ordered a new cable before it started burning, guess i gonna need to cancel my order.\nimage: [cable burned](https://ibb.co/qDZzHzC)\n\nUPDATE: Got a replacement or refund, gonna mount the new card vertical until new adapters are send out.\n\nAnyone that can confirm if this is i stallet correctly until i get my cablemod one.\nIt is 3 PCIe cables from PSU where one is being splitted into 2\nImages:\nhttps://ibb.co/DDWBBXC\nhttps://ibb.co/5M4YvGT\nhttps://ibb.co/PN6CZJd",
    "comments": [
      "I still can't believe Nvidia is silent on this",
      "Jensen is too busy joining random girls livestreams.",
      "[https://www.reddit.com/r/pcmasterrace/comments/ynobf8/jensen\\_shows\\_up\\_on\\_a\\_random\\_livestream\\_and\\_picks/](https://www.reddit.com/r/pcmasterrace/comments/ynobf8/jensen_shows_up_on_a_random_livestream_and_picks/)",
      "For those in the comment section blaming users for not plugging it in all the way/correctly, if this adapter is this sensitive to this error why hasn't it been solved/detected during Nvidia's/AIBs quality control. This is like buying a flagship phone only to find out it explodes with the slightest tug in the charging cable. I think it's a stupid question to ask what the user was playing/doing with their pc when the plug burned. It's a freaking graphics card. It's made to play games and/or for intensive 3D rendering it shouldn't matter what you are doing when it burned up. If you can't play games with your gpu without it burning then what's point.",
      "Holy shit this is one of the worse ones. The plastic housing is all melted and only the metal core is left.\n\nWow..",
      "I sense either a recall or class action lawsuit coming.",
      "I dont know what to say but as an advice for everyone is to hold off on buying the card until Nvidia comes out with a statement, dont convince yourself that you will not be affected and wont be next, the idea of being paranoid all the time is just awful.\n\nNobody knows the real issue here, even a native MSI PSU cable got melted, there is no guarantee that 3rd party cables will not melt either as its too early to tell, some people got away with 600W while others are having it melting at 450W, its a risk that no one should take especially when Nvidia is just avoiding to even comment on this and charging $1600+ premium for it.",
      "Wait, what?",
      "In 3 years time you'll get a check for $20.",
      "amazing you can spend 2,000 for a card and they cant even make a statement",
      "Why not both?",
      "People just keeps spending no matter how Nvidia fucks it up so it is what it is",
      "That was way less creepy than I expected",
      "https://preview.redd.it/u808q11pxmy91.jpeg?width=1634&format=pjpg&auto=webp&s=ccdab304ecd88e3c58df3055a35fc8a32a50b4cc\n\nplugged it in half way for a image. Does not fit anymore all the way",
      "What model aib",
      "https://preview.redd.it/hf6n9czwxmy91.jpeg?width=1634&format=pjpg&auto=webp&s=d677ffe0f1c1f053ccd24b8d6069aff26d343d3d\n\nplugged it back in for the image, just to be clear.",
      "I see nothing wrong with that vídeo. quite the opposite",
      "Funny because the original selling point for the TUF line from Asus (like 10 years ago) was that these components went through extra rigorous testing and only used proven parts (at the expense of cutting edge or overclocking). It was supposed to be equipment you could trust to take with you on a long deployment or in unusual conditions and even came with 5 year warranties. It seems now it's just become purely a marketing term and/or aesthetic branding. \n\nA friend's laptop was a high end TUF and it keeps having dust and reliability issues with its fans after less than a year lol.\n\nMind you I think their top of the line motherboards and GPUs are probably still top quality. Even the TUF is surely a great card but it shows the wording TUF should be taken as just a marketing term at this point and is no longer an indication of extra hardware validation or proven components.",
      "Good thing EVGA pulled out of this mess.",
      "We need to burn Jensens Leather Jacket to show him how it feels"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "top",
    "matched_keywords": [
      "rtx 4090",
      "4090"
    ],
    "title": "My school project - RTX 4090 charcuterie board",
    "selftext": "",
    "comments": [
      "Nvidia: **That will be $1699 sir**",
      "Won't this end up cooking your snacks? You're going to end up with queso dip",
      "That ain't gonna cut it. Hehe",
      "So good! That's actually how people feels  with a real 4090 when playing the last 4 triple A gaming disasters",
      "That *wood* be $1699 sir",
      "the 4090 that people can actually afford",
      "Pretty cool, hope the resin is food safe though!",
      "What wood you get for fps on that card?",
      "Quadro Dip (NVidia)",
      "Hahah nice! I did the same with 2080ti when it got released.",
      "Last year everybody was like \"2023 is going to be the best year of gaming in a decade\"",
      "It is!",
      "Is it flammable? Warranty covers it right?",
      "Unless it means buying the machine to cut it 😁",
      "FE, for Forest Edition",
      "Neat project. You should post this over on r/woodworking.",
      "Clearly you're not somebody that understands the value of art.",
      "Damn that’s got green rgb too",
      "“The hero we needed but don’t deserve”",
      "That’s one powerful board! How many chops per second are you getting?"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "top",
    "matched_keywords": [
      "rtx 4090",
      "4090"
    ],
    "title": "NVIDIA GeForce RTX 5090 reportedly targets 600W, RTX 5080 aims for 400W with 10% performance increase over RTX 4090 - VideoCardz.com",
    "selftext": "",
    "comments": [
      "Oh these prices are about to HURT hurt huh. inb4 $1399 5080, $1999 5090.",
      "<Pets 1080ti> Hang in there, old friend.",
      "They learned. They learned that their greedy ass can get away with overpriced GPUs, because they know people will still buy. If only AMD were competing in this bracket they would carefully price their cards.",
      "Seeing how they significantly dropped the price of the 4080S vs the 4080 shows they knew they over priced the 4080. I hope they learned from this, they have found the ceiling for an 80 tier gpu.",
      "Are people forgetting that the 70 class always matched the previous gen’s flagship? What happened to the 1070=980ti or the 3070 being the 2080ti. It’s not like it was a long time ago. Just recently nvidia decided to be extra freakin greedy and people are forgetting this.",
      "![gif](giphy|fXnRObM8Q0RkOmR5nf)\n\nNvidia",
      "We had identical power usage rumors before last gen that were completely false.",
      "If the 5080 comes in 10% above the 4090 that would make it a ~100% upgrade over my 3080 (4090 is 87% per techpowerup), which is my personal threshold for considering an upgrade worthwhile. So that's good. \n\nIf it comes in at that performance and costs <=$1000 I'll probably get one, particularly if Nvidia announces new tech limited to the 50-series like framegen was on the 40s. Not happy about the 400w, though.",
      "The people willing to spend over a thousand bucks on a graphics card but not the top of the line model is pretty limited.  \n\nIf you’re in for a $2500 build, why not spend $3000 for the very best?  \n\nIf you’re trying to get price/performance, why not spend 1500 or less with one gen old parts? \n\nThat’s the problem of the 4080. Minimal target market.  \n\nDon’t forget that the 4070ti was intended to be the entry level 4080, they just rebranded it before release when everyone cried about two very different 4080 versions.",
      "Here's hoping my 1000w platinum PSU will be enough for the 5090.",
      "Well their actions strongly suggest the 4080 didn’t sell in the numbers they had hoped",
      "I'm so starved for info on the 50 series lol. i just click on anything about it even if it's a rumour.",
      "If it costs less than $1200 at launch I’ll genuinely be shocked. If I can actually find one for less than $1500 I’ll be even moreso.",
      "Please be affordable, please be available..",
      "To be fair the flagships are fairly inconsistent from generation to generation.\nAccording to techpowerup the 980 Ti was 31% faster compared to the 970 while the 4090 is 99% faster than the 4070. \n\nSo in one case the 1070 case the 70->70 improvement was roughly 31% (it actually was 47) but to bear the 4090 you would need literally more than twice the performance.",
      "At that point it’s earned the right to be there.",
      "I’m still rocking a 1070.  At this point I’m just gonna use it until it dies.",
      "Checkin in as guy who bought 980, 1080, 2080, and was eyeing the 4080s before deciding to wait… \n\nI’m someone who likes high-end performance, but I also keep price:performance ratio in mind.  I didn’t want to pay an extra 50% cost for 20% gains when the 80 is already getting me very high FPS, mixed with issues from higher-tier cards (3080ti failure rate, 4090 melting, etc.).  So that’s the mindset of someone in that market.",
      "THE MORE YOU BUY THE MORE YOU SAVE",
      "Cheaper....LMAO"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "top",
    "matched_keywords": [
      "rtx 4090",
      "4090"
    ],
    "title": "[Gamers Nexus] NVIDIA GeForce RTX 4090 Founders Edition Review & Benchmarks: Gaming, Power, & Thermals",
    "selftext": "",
    "comments": [
      "It's breaking all the charts in the review. Crazy seeing 0.1% lows higher than other cards' averages.",
      "Double the performance of my 3080 10gb in rasterisation and RTX (no DLSS).\n\nThat's bloody insane. If it wasn't also double the price. Extremely exciting to see such a major uplift though.\n\nEdit 262% the price of the original 3080 MSRP in UK. Ludicrous pricing.",
      "The most shocking part of this whole review to me is that Tech Jesus actually liked the FE cooler.\n\nGood job Nvidia",
      "He had a recent video where a Nvidia engineer talked about the engineering of the cooler, would recommend watching.\n\nWhile the video is pretty cool and informative, you can get a sense of why EVGA threw in the towel: the Nvidia team is well funded with airflow models, have access to the specs and actual chip way before their partners.  Stuff like detailed hotspot data is something I doubt Nvidia's partners have access to at all.\n\nYou end up entering a race where the owner is in their finishing lap when you are on the starting line.",
      "Here we go. People will forget the insulting prices and this shit will sell out.\n\nRemember when people thought the 2080ti was crazy expensive?",
      "This card is insane in every aspect. From performance to pricing",
      "Oh my god it has 0.1% lows that surpass the peak of the 3090 ti in some games",
      "Even as someone who is very anti-Nvidia as of late, very impressive product. \n\nCan't say the engineers didn't nail this card, especially with the FE cooler. \n\nI hope AMD can compete with this come November as we *really* need the competition to stay alive in this space or there will be no pricing pressure here.",
      "That the _Stuttering_ from the 4090 is as good as the 3090ti in top situations",
      "So the rumored jump turned out to be true. Nice.",
      "> If they make all the data they need available to vendors\n\nYeah, I think Nvidia's long-term game plan doesn't really involve any of those.",
      "Even in size. That thing is stupid big.",
      "This damn thing is actually fast unlike the 2080ti",
      "Let's see Paul Allen's video card",
      "Can't argue with the results, pretty impressive.",
      "Nvidias been increasing prices steadily for years now. We've went from the best cards costing 700usd in the pascal era to now costing 1600. How are you all ok with these insane prices?",
      "the lows and highs almost the same = CPU bottleneck. damn the 4090 so fast it needed faster cpus to truly flex",
      "Generally, you have your average FPS and the lows or dips. What he means is that in some games, the lowest FPS the 4090 is getting is still higher than the average of the 3090 Ti which is insane.",
      ">You end up entering a race where the owner is in their finishing lap when you are on the starting line. \n\nYeah, but I'm betting in the future it's not really good for consumers. If they make all the data they need available to vendors, we might actually get creative and innovative cooling solutions.",
      "A part of me wishes AMD makes a graphics card twice the size of a 4090 where you need 2 PSUs to run it just for lols"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "top",
    "matched_keywords": [
      "rtx 4090",
      "4090"
    ],
    "title": "RTX 4090 Performance per Watt graph",
    "selftext": "",
    "comments": [
      "So you could drop by almost 100W and lose barely any performance? Then the question is why it's not like that out of the box.",
      "Power consumption would be lower, coolers would be smaller, power delivery would be simpler, case and PSU compatibility would be improved. A few percent less performance would be a hell of a good trade-off for all that.",
      "Hello, i thought it could be useful information, so there it is  \n\n\nEdit: Some people are upset that this is not an absolute Performance per Watt chart, sorry about that  \n\n\nHere's the actual points per watt:\n\n130W = 66 / 180W = 85 / 220W = 92 / 270W = 84 / 330W = 74 / 420W = 59 / 460W = 55",
      "Thats what im planning to do. Power limit to 60%.  Once i get my 4090, in 2049",
      "Yeah. And it's not like 4090 would be shit losing 3-5 FPS tops.",
      "So this card basically uses the same amount of power as my 3080 when I slightly overclock it.  Wow, pretty damn impressive.  The 16 gb 4080 is going to be sipping power.",
      "And people were absolutely losing their minds for weeks over potential power issues with these cards. Totally unfounded, thank god",
      "These coolers are overkill. I suspect if you buy a 4090 you're paying for a 4090ti cooler.",
      "Optimum Tech (Ali) was wrong, you can undervolt just fine this gen. Spent a few hours testing it this weekend, going to get written up into a post later. \n\nI achieved almost identical stock performance with a UV of 2715 MHz at .95v volts\n\n365 vs 430 watt power draw on timespy runs.\n\n.008% performance drop.\n\n(I did have to apply my memory OC to the UV to negate 60 MHz difference. 2775 MHz stock, 2715 mhz UV)\n\nEdit:\n\n[4090 UV post](https://www.reddit.com/r/nvidia/comments/ybxa3c/there_are_two_methods_people_follow_when/?utm_source=share&utm_medium=ios_app&utm_name=iossmf)\n\nPost live\n\nCredit to u/TheBlack_Swordsman",
      "I don't know that I'd call this graph performance per watt. It's more like relative performance at various power levels, which, while useful, is not the same. If it was performance per watt, using 3dmark as in this data, it'd be measure in something like pts/watt.",
      "I'd been nearly pulling my hair out the past six months or so trying to explain to everybody this is how it would be.  Lovelace was going to be a huge performance improvement AND a huge efficiency improvement, and would be very comparable to the leap we had with Pascal.  \n\nBut anybody who wants to properly realize those efficiency gains would need to do a bit of manual tweaking to get it.",
      "Overkill is underrated. Its amazing how often my 4090 will just passive cool. Even when pushing it it’s very quiet.",
      "It's pretty much the same approach as Intel and AMD have taken with their CPUs. \n\nThey are giving you overclocked results out of the box so that the product will look good on reviews where stock results dominate and you only have a small \"overclocking\" section that normally never shows up in any further reviews or multi-GPU comparisons.\n\nThe best way to improve things is to instead apply power limits or undervolting than to try to boost it even further because the power draw goes through the roof without appreciable performance improvement. Which is honestly a good thing with the coming winter and insane electricity costs.\n\nI never thought I would be able to consider cramming a 4090 into an ITX form factor case but with undervolting that seems to be possible, putting the heat output closer to the 2080 Ti I have in it now while still delivering almost 100% performance.",
      "Marketing, review chart scamming. Let's say you put out 350W 4090, great card, super efficient, but AMD notices that If they push their 7900 to 500W they can beat your 3090 by 5% and they get all the marketing to say they have the fastest GPU, their card tops all review charts, etc. \n\n\nSo there is no downside to push your top card, a halo product to absolute limit, to squeeze just a little bit extra to ensure leadership",
      "Lol they are def over kill. I was getting over 190 fps in warzone last night on 4K resolution ultra settings, and my temps didn’t get past 58 degrees once",
      "Very useful thanks for the info!",
      "This right here is why I want to see some partner with the balls to make a \"4090 mini\" with a regular sized cooler and a 300W power limit. You could still be passive or at lease very low RPM on the fans for the vast majority of use cases. Is strongly suspect this is what the workstation version will be.\n\nIt's probably going to be similar to the A6000. Those cards performed very close to the 3090 and were running on lower power budgets and smaller coolers as well.",
      "IDK, I think the size and price are both dealbreakers.  Win for some, a disappointment for others.",
      "This card is a win imo",
      "The reason I disagree is in a perf per watt graph, the most efficient settings would be the higher bars. This is not, so while it displays similar information, I think it's a little less useful."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "top",
    "matched_keywords": [
      "rtx 4090",
      "4090"
    ],
    "title": "Newegg refunds customer who received RTX 4090 box filled with weights | Gamers Nexus offered to buy it",
    "selftext": "",
    "comments": [
      "happens to us on Amazon all the time - so many scammers out there sadly.",
      "Gotta make an unboxing video anytime you purchase from newegg",
      "I could believe it. If I want a free GPU it’s ludicrously easy to order one off Amazon, replace the card with an older generation, and return it. They don’t have time to check.\n\nQuick edit: Yes it's not actually that easy, it was a poor phrasing on my part. There have been reports of this, I am wondering if the reports a few years ago got them actually checking?",
      "He made one comment on a 3D printing subreddit about 3D printing related stuff. Another Reddit user misinterpreted the information, made a post similar to your comment that went viral, and that’s the new narrative.",
      ">Gotta make an unboxing video anytime you purchase from newegg\n\nHow long will that last? with editing software these days we may get to the point where you need to open it with an accepted 3rd party.",
      "eBay also has insane buyer protection. You can buy a scalper GPU, say it's defective and return it with exact weight. Seller will fight it, but 100% of the time eBay will believe anything the buyer says.",
      "Whoever looked at [this comment](https://www.reddit.com/r/3Dprinting/comments/y5tqbt/the_only_way_ive_ever_been_able_to_have/ism3w34) and interpreted it as \"this guy is a machinist and owns a cnc machine\" is a big fucking idiot. \n\nAnd everyone who is repeating it and adding their own twist to it without providing any sort of source is a fucking idiot as well.",
      "Take it to your nearest UPS or FedEx for “certified opening” /s",
      "eBay has screwed me over numerous times in the past. I estimate ebay has cost me over a grand as a casual seller over the years.\n\nThe worst was when I sold my HTC Vive - the recipient said it didn't work on their machine, asked to return it at my expense, I contacted them for more info and ebay just arbitrarily closed the case, refunded the buyer and left me without my headset. Still bitter over that.",
      "\"Video file not found, will reattempt upload tomorrow.\"\n\n- FedEx, most absolutely",
      "> I think he scammed NewEgg\n\nvery possible someone in shipping took it. i say that since of the weights as postal centers weigh your packages at each stop so as not to raise any red flags you need to fill it with weights. also possible someone at newegg took it and replaced it with weights for the same reason.\n\nit is also entirely possible it was stolen in the factory as it is based on pallet weight and getting two lumps of steel in a factory seems more likely than computer warehouse or a shipping center.",
      "no way any one can do this then and get refund and keep gpu",
      "Seems to depend on when and what too. As I said in another comment, I’ve had plenty of wrong RAM and HDDs contained in the right packages, though it is harder for something as big as a GPU there have been reports of it.",
      "~~Wasn't this the metal machinist who happened to receive a box full of machined metal instead of his 4090?  Odd coincidence.~~ Edit: This is untrue (see comment below).",
      "GN has a far stronger \"hard-on\" for honest journalism and integrity. They pulled their latest Hardware News video because of new information about the weights scandal that had come to light after publishing it. Don't sell them as one-sided, jaded and/or biased shills.",
      "What do you mean noticeable. Nobody notices that stuff. People are just doing their jobs not paying special attention to individual packages.",
      "It's already the narrative in this very thread. Reddit is such a weird place",
      "They 100% check large price items, it just takes them a bit of time. 2 years ago I ordered a 2x32gb kit of DDR4s from warehouse as part of my rig upgrade (+memory and full waterloop). Since it was a big upgrade, i filmed myself opening everything up, I was mainly worried with EK's block or rads being busted in shipping so I wanted to cover my ass. My DDR4 sticks had been swapped for very, VERY old memory but had been re-sealed perfectly (warranty void if broken seal was intact on all sides of the box, it as 5% off in warehouse due to the box having banged up corners).\r  \n\r  \nI contacted amazon via chat and they generated a return label for me. Some 8-9 months after that, I got an email from amazon CS saying that I had returned the wrong item in the box (the old sticks that came , meaning they actually checked), and that I should either give them 2x32GB sticks or pay the refunded price again. I re-sent them the chat log with support, the shipping tracking number with evidence of delivery and the video evidence of the swapped sticks and everything was fine.",
      "Wait, you’re telling me people were surprised to find out a pc nerd is also a 3d printing nerd?",
      "Not really, and that's not even what I'm getting at.  Nobody shipping the product is going to be analyzing the box and what was in it.  UPS isn't shaking the thing saying \"this doesn't sound like a 4090\".  They don't know or care.\n\nYou are just making an assumption it's fraud because of some coincidence you heard about.  That doesn't make it a fact."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "top",
    "matched_keywords": [
      "rtx 4090",
      "4090"
    ],
    "title": "RTX 4090 dies under warranty, won't replace it, what now?",
    "selftext": "[Resolved]\n\nSo, I bought an MSI RTX 4090 Gaming X Trio about 2 years ago, brand new, from MSI's Official Amazon pgae. My GPU has been working and being used correctly, (high quality PSU, no overclocking, ect.) Then about 2 months ago I had a serious problem and my GPU would spin up my fans to the max while my monitors lost connection but I'd hear sound.\n\n Long story short, after spending hours of my time diagnosing the issue and trying to resolve it, it was for sure the GPU at fault, so I paid $120 to have it shipped all the way to Sacramento to get it fixed, including the power cable. I got it back about a month later and put it in my pc and had the same problem within hours after they sent it back to me, put it in my Wife's computer and same issue. \n\nI called customer service back and told them of the issue, got it sent out about 2 weeks ago, and just got an email stating that it was unrepairable and not replaceable. They offered me some money back,  but not much, and said it wasn't going to be the $1,750 I paid for it because their \"3 Year warranty\" isn't actually a warranty, it's only prorated.\n\nSo, now I'm completely lost on what to do. I don't have the money I did two years ago when I was able to buy this card, and I figured it would last at least until the warranty was up (I've have Nvida and AMD cards for numerous years, and never once had a hardware issue with any of them). So what should I do? I can't get another 4090 as they are over $2,000 on the used market right now, and can't get the only card in the world that's better than it (5090) for obvious reasons. Even the 5080 is far worse than the 4090 and I'd still have to pay extra just to get that downgrade If I was even able to find one. I'm sitting here numb, at a loss. Is there any wisdom or help you guys could provide? Thank you very much.\n\n[Edit] \n\n- I just filed a compaint aginst MSI on BBB and FTC (heard back from only the BBB)\n- I also contacted the MSI spokesperson and emailed them requiring a replacement or upgrade (see resolution)\n- I also emailed Gamers Nexus like you all said. (no reply)\n\n[Resolution]\n\nSo, after a good couple of days after I made this post, MSI finally resolved my issue (as much as you can expect them too). About a day after I filed multiple of those compaints, they responded with: \"The RMA is unable to repair your card which is why we are asking if you are okay with the refund.\nPlease kindly share me a copy of your initial component purchase and I will check with RMA Dept if able to process item price refund. Thanks.\" \n\nAfter that, I sent them my recipt they asked for and I specified that I'd much rather a replacement 4090, but if that was not able to be done (it has been out of production for a few months) then I'd accept a 5080 or 5090. They then waited some more time before responding. The next time they responded was in response to the BBB contacting them and asking for a resolution, in the resolution they stated they already offered a full refund that I did not accept (They offered me hundreds of dollars less than a \"Full Refund\"). I then see in an email from the MSI spokesperson that they are going to: \"We will refund you $1748.99 as we do not have an equivalent replacements to offer\". \n\nSo, with that being said, I'll take that offer of a full refund, as that is what I paid 2 years ago. I spoke to multiple people at different times who told me that they had ZERO 5080s or 5090s in stock. Since, this resolution is more expensive than sending me a 5080, I'm inclined to think they are at least out of 5080s. This isn't the resolution I wanted, but it's good enough, as I'm tired of this fighting which isn't face-to-face, just screen-to-screen. I'd rather just have a 4090 back, but it looks like I'll be buying something different now. Likely getting an RTX 5080 with that money, or an RX 7900 XTX. They have somewhat similar FPS in most games and the prices are less than what I paid for my RTX 4090. Thank you all for the help and wisdom!",
    "comments": [
      "\"isn't actually a warranty\" is an outrageous statement given they explicitly list it as a warranty and the warranty length on their own store.\n\nYou live in the United States, they are legally required to make you whole. \n\nIn this case that means either a refund for the original purchase price or a functioning product of equal value.  It's common for MSI to play these games where they'll offer you a lower end product or less money that what you are entitled to.  If you accept those offers, you agree to taking less than you could have gotten.\n\nLet them know you are entitled to be made whole and may else wise be forced to take legal action.  Post this on other social media to put pressure on them to make it right.\n\nAll else fails, if your account of the story is correct, this is an extremely easily win in small claims court.  You will likely win by default given the cost to pay someone to travel and lodge in your state likely exceeds the value of the replacement.\n\nThe other comments in this thread telling you to just move on and buy a different card are capitulary.  All the big AIBs do this nonsense and just giving up encourages them to do this more.  Taking them to task will make them reconsider screwing their customers monetarily.",
      "Gamers Nexus has an inbox. And they are already on the MSI hate list, so there's no love lost in case it turns out that MSI should have responded more favourable here.\n\nThey might at least have some arguments to consider and/or write to MSI. Or maybe some local consumer advocate groups are in their list.",
      "Please listen to this poster. Tell them you will not settle for whatever garbage they are offering. Assuming your story is correct and there was nothing you did to prematurely shorten the life of the card.. MAKE THEM make it right. If they still refuse, file it in small claims court. If they don't have any 4090's to replace it with, tell them to send you a shiny new 5090 instead. I would not settle for less than a 5080.",
      "Gamers Nexus is crucial in dealing with these issues. Intel went non verbal after confirming that: 1. My cpu was defective (14900kf) and 2. That I had selected fast swap. After a month of no response, two days after emailing Gamers Nexus a manager replied to my ticket offering 100% refund via cheque.",
      "It's times like this that we miss EVGA....",
      "Why would you even settle for a 5080? It's objectively worse than a 4090 at stock.\n\nGet a direct replacement or an upgrade only.",
      "Tech Jesus literally saving gamers 🙏",
      "this comment should be moved to the top",
      "Yea luckily with a 4090 you can make the VRAM argument, which is just about rock solid as it comes. “I need at least 24gb of vram”… that’s another 4090 or a 5090.",
      "https://consumer.ftc.gov/articles/warranties",
      "GN would have a field day of them saying their warranty is not actually a warranty.",
      "Manguson Moss warranty act covers you under implied warranty by law, regardless of what they say.\n\nWhen I've ran into any warranty issues in the past, I've dropped that on them and they've capitulated. \n\n>**Sellers of consumer products who make service contracts on their products are prohibited under the act from disclaiming or limiting implied warranties**. Sellers who extend written warranties on consumer products cannot disclaim implied warranties, regardless of whether they make service contracts on their products.\n\n>",
      "They replaced my 1080ti a couple months out of warranty, they saw this coming a mile away.",
      "https://preview.redd.it/logm41go5gwe1.jpeg?width=1897&format=pjpg&auto=webp&s=884958a5834c6ef2c39b52222aae848fb115f816\n\nHe healed Kingpin once",
      "Agreed, I'm not seeing anything that indicates it's prorated on their website: [https://us.msi.com/page/warranty](https://us.msi.com/page/warranty)\n\nThe first part of that page is crazy though:\n\n\"The warranty term differs from one region to another. If you would like to verify the warranty term of the product bought, please kindly contact our local offices.\"\n\nThey don't disclose said extra terms and they don't even provide a number to call (easy to implement a region selector that provides the correct number) or link to where the person could even further inquire about them.\n\nThe thing is, under the Magnuson-Moss Warranty Act, companies are required to clearly and reasonably disclose these terms to customers.  They are impeding customers from learning about these said full terms in three ways:\n\n1. They don't disclose them online or at the place of sale.\n2. They require you to call in to learn full terms.\n3. They don't even provide the number for said full terms (at least not where one would reasonable expect it).\n\nIt's beyond shady that they are hiding warranty terms to such a degree.\n\nI will note though that Gigabyte's warrant IS prorated (but at least they provide the full terms FFS):  \"If a Product is near the end of a given warranty period and a repair/replacement is not possible, GIGABYTE reserves the right to offer an alternative of equal or greater value or a partial refund proportional to the remaining warranty life of the Product.\"\n\nI'm not sure when this trend started or if other companies are doing it but consumers should push back against it.  Prorated warranties make no sense for GPUs.  GPUs are not consumable products that quickly burn through their life in the mere 3 year warranty period.  Most of my GPUs last 10+ years.  GPUs are far too expensive and this is clearly a move to push customers to buy more often.  God i miss EVGA, screw these big corpa AIBs.",
      "Are you always using the same power cable with it? I was having that exact same problem with my Suprim 4090 and it turned out to be the cablemod 12VPWR. I put the squid adapter on the pcie cables for my PSU and the problem was gone.",
      "The more this guy, the more you save. ❤️",
      "A \"pro-rated\" warranty?!?\n\nSo, you buy a product with a 3 year warranty, and it fails on the last day WITHIN the warranty period, and you're only due ~0.1% of the purchase price in refund?\n\nThat's not a 3 year warranty. At all.",
      "By all measurable metric the 5080 is slower and less capable than the 4090.",
      "I miss EVGA. Sigh."
    ]
  }
]