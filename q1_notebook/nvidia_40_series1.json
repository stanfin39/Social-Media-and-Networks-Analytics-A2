[
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "4060",
      "4060ti",
      "rtx4060"
    ],
    "title": "RTX 4060 or RTX 3070 - which one for my first budget gaming PC?",
    "selftext": "Hello, I have the option to buy a second hand gaming PC quite cheaply and I can choose between RTX 4060 8GB and RTX 3070 8GB for the same price and I would like to know your opinion which one would you choose?  I have been googling a lot however I found a lot of \"buts\", the 3070 seems quite a bit more powerful with like 10-20% more FPS, but the 4060 has the new DLSS3 frame generation pushing its fps all the way to rtx 3080 level, but there is apparently an input lag issue with dlss3, but nvidia reflex seems to solve it? I am quite lost here, if I want to play modern games in QHD resolution with the best quality possible at around 60FPS, does 4060 with DLSS 3 provide better experience than RTX 3070 with DLSS 2? Are there other things to consider? \n\nI will probably buy a 34\" ultrawide QHD monitor, but I havent made my final decision, would you also choose such monitor for best gaming experience if you had $300-400 to spend just for the monitor (plus $600 for the pc so $1000 limit for the whole setup, I really dont think I want to spend $200-300 more for RTX 4060ti or rtx4070 as the FPS with rtx4060 seems high enough for most modern games in QHD)? \n\nThanks a lot for your advice.",
    "comments": [
      "Go with the 3070. The 3070 performs nearly the same as the 4060ti. The 4060 is not powerful enough for a 3440 x 1440 monitor. The 3070 will be able to use DLSS and be just fine. Frame Gen is only acceptable if you are playing a single player game. FSR frame Gen works great with DLSS.",
      "What games can a 3070 not run? Personally the only games I've ever experienced issues with were a handful of VR titles. Everything else ran fine.",
      "The 4060ti also comes in a 8GB model which performs almost identically to the 3070.",
      "Yep. 4060ti uses 160W. 3070 uses 220W. Some 3070s have a power limit of 250W",
      "Not Nvidia's framegen, which is somewhat better. But I agree framegen isn't worth the Nvidia tax alone.",
      "I traded my boys 3070 for a 2080ti due to Racket and Clank rift apart. If you didn’t play on low setting or Performance mode upscaling the game was almost unplayable due to the stuttering from a lack of VRAM. Plays fine now with all settings maxed out with DLSS quality.",
      "I don’t know if this helps but I have both 4060 and 3070 Ti. Games that support frame gen (let’s use Diablo 4) vs 3070 ti:\n\nUltra settings (1440p) / Raytracing OFF\nFrame Gen and DLSS (balanced) ON\n\n4060 (85W) 117-148 FPS\n\n3070 Ti (140W) 131-170 FPS (no frame gen support)\n\nOf course, this is paired with a 12700H (for 3070 Ti) versus 13620H (4060)\n\n\nAnother game: Assassin creed Valhalla:\n\nUltra settings / FSR ON\n\n4060 67-75 FPS\n\n3070 Ti 85-112 FPS\n\n\nIn general 30 series will have better raw power but it all depends on the watt variant of the 4060 to make it worth buying over a 3070 let’s say. They both support DLSS except frame generation is only on 40 series.\n\nInput lag is there and when frame gen is on, it feels floaty, almost like you aren’t playing the game during  frame loading? Hard to explain but latency is definitely there and idk feels off at least on diablo 4",
      "On ultrawide, it hit its limits on call of duty quite quickly so I had to use dlss performance and low settings to hit 120fps and it looked awful.\n\nFor normal games, I had to turn off all ray tracing and enable dlss to hit above 60. It physically can’t run stalker 2 above 5fps if you play at higher resolutions.\n\nIt’s doable if you don’t care for higher refresh rates or ray tracing and you don’t mind using dlss",
      "I currently have a AMD 5800x and a 3070, playing at 34\" 1440p. The 3070 can still get *decent* performance and visuals in games with DLSS, but I would not personally recommend it to someone looking for a GPU to last a few years at 1440p because of the VRAM issue, which I've ran into in games like Horizon Forbidden West and others. I wouldn't recommend an 8GB GPU full stop to anyone with a 3440x1440 display honestly, not unless that person was exclusively going to play smaller, less demanding games or old games anyway.\n\nAlso FSR3.1 support, which is needed for FSR FG + DLSS is not widespread still and the FSR3 FG mod, in my experience, is a bit dodgy with frame times in about half the games I've tried it in.",
      "In this exact situation. 3070, 3440x1440, use dlss with fsr fg on horizon forbidden west and am very happy with the performance except for when I run out of vram and it starts stuttering and loosing frames. It's never that bad though.",
      "The problem is the 3070 has 8gb vram and can’t run some games whereas the 4060 ti has 16gb although its significantly slower",
      "Ye I think. But I think game devs work with 8gb. I've not had a problem yet",
      "2080 ti is a pretty good buy as well only a few percent slower with more vram and about identical used pricing. Been trying to nudge my buddy Into picking one up to upgrade his 580 8gb he games on still.",
      "You won’t be able to run portal RTX on a 4060. My 4070 super only gets 30fps on it even with upscaling and it’s around 50% more powerful than the 4060 ti.\n\nFor anything less than a 4070, you’re better with amd because 8gb just isn’t enough.",
      "Also dlss 3",
      "3070 no questions asked, DLSS3 FG is useless when the card has 8gb of vram, check out videos by Daniel owen that show how the lack of vram causes FG to lower your fps that you start with\n\n\nIMO if you can get a 4070 or the 4070 super, go for it, you'll be thankfull for the 12gb of Vram (Hardware unboxed recently tested Stalker 2, all of 8gb cards run at 2 fps due to lack of Vram) and actually usable FG couple of years down the road as an investment, because with the 4060 and at a lesser degree with the 3070, you'll be looking at you next upgrade very very soon (unless you only play light or older games and don't plan to play the latest AAA games of course)",
      "4060 is a terrible 1440p card and so is 3070, grab 6750XT/6800 Nvidia has no good budget cards.",
      "Neither,  7700XT or 7800 at this segment.",
      "3070 all day.",
      "4080 super is more expensive than my total budget, I dont really need that much more performance mainly because I will still keep using Geforce now service in case there is a game where 4080 super is well worth it, i just want to have a home machine for those games that cant be played remotely like the new Portal 2 RTX. When I checked reviews, 4060 seemed to deliver good enough performance in 2K resolution, many games need DLSS but I dont consider that a negative. I feel like we live in an era where even midrange gpus are powerful enough to run any game on high settings, and you need high end gpu only if you really want to max out the graphics with 4k resolution, raytracing or path tracing, no DLSS or only DLSS quality etc. I remember times when even the high end gpus werent enough to run a game on full details with anti-aliasing, mainly around the Crysis 1 release (8800 ultra and then 9800gtx), I remember the most powerful gpu from nvidia had like 40 FPS there and it took 2 generations of new gpus to comfortably have 80-100 FPS with 60 min FPS. And if I have to set the details to medium in a year or 2, so be it, as long as i can still run the game decently at 60 FPS. If not I will consider selling the 4060/3070 for $150-200 (or whatever it will sell for used in 1-2 years) and upgrade to something like 4070 or maybe even 5070."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "4060",
      "rtx4060"
    ],
    "title": "Is the RTX 4060 really as bad as people say?",
    "selftext": "Hey everyone,\nI have a rtx4060 (i got a prebuilt computer because in my country individual parts cost more somehow) and I keep seeing so many negative takes about this card online, people calling it a “downgrade,” “waste of money,” or saying it’s just flat out disappointing. Honestly, it’s making me feel pretty bad about my purchase.\n\nI mostly play at 1080p, and am thinking of going 1440p and im worried about my performance. and so far, my games run great, but seeing all the criticism makes me second-guess if I made the right choice. Is the 4060 really as underwhelming as people say, or is it just internet negativity?\nWould love to hear from others who actually own this card how’s your experience been? Did you regret buying it, or are you happy with it for what it is?",
    "comments": [
      "If already have the 4060, can still optimize setting in any games that didn't perform.\n\n\n Even Intel ARC a750 8gb can perform in modern games 60+ fps with optimized settings at 1440p (and no DLSS, but XeSS ), and 4060 is more powerful. I'm running a750, so can contest to this and the 4060 is the better GPU vs a750.\n\n\nYou're fine, and sounds like if got a good deal, also even better. \n\n\n1440p presses a tax on any 8gb GPU, and 12gb, just optimize your settings in the games if run into issues with VRAM--lower texture resolution, such as medium (each game has recommended settings).\n\n\nIt's kind of overblown for the 4060, bad reputations, but you still have DLSS(the best), and can lower in game texture settings.",
      "Let me put it like this, in VRAM intensive scenarios the RTX 3060 out performs the 4060.",
      "Basically, if I can run any modern games at 60fps+ with an Arc A750 8GB at 1440p(including Indiana Jones at 80ps, B06 at 90FPS), the 4060 can too, and higher with DLSS image quality.",
      "Because the whole PC when I bought it cost me about 900 euros which is already too much but I was able to afford it somehow.",
      "8gb one",
      "Hmmm and I thought the 16gb edition was only for the 4060ti…",
      "If your games run great, you aint playing any remotely demanding games. Plenty of scenarios online about 8gb vram killing performance in new games at 1080p. Not necessarily a bad thing if it works out for you in your games.",
      "I think the biggest question is are you happy playing your own favorite games with that card right now? If yes then there should be no problem. If no then you may want to upgrade into something that is more powerful and with more VRAM too, provided you have the budget.\n\nIn the end, it's your money and your own pc. Sure it wasn't the best of choice but maybe there are circumstances which prevents you to make the better decision back then. Either monetary (maybe you didn't have enough money to afford something better back then), or simply doesn't have a clue yet about PC and its performance. I wouldn't overthink too much about it.",
      "Well, if you want to play at 1440p, then yeah. It would be.\n\nIt's the same as the 5060. It's designed as a low to mid-tier card aiming at 1080p gaming.",
      "The 4060 isn't bad, it just wasn't priced accordingly. If you're playing at 1080p you'll be fine. There are a few cherry picked examples of where you'll have to decrease settings more than you'll want to but as of now it's a perfectly satisfactory 1080p card. I'd wait another gen before upgrading, or upgrade right before the next gen drops. Then you can listen to everyone cry about availability as you're sitting snug with your upgrade.",
      "I bought an ASUS Dual GeForce RTX 4060 OC a year ago for €299,-. I decided to go with this card because:\n\n1. It was the most energy efficient gpu out there.\n2. Nvidia, so it supports CUDA and NVENC.\n3. Price/performance wasn't actually bad at all back then compared to other cards.\n\nPeople were recommending the RTX 4070 instead, but it is almost twice the price. People were recommending the RTX 3060, but the RTX 4060 is way more energy efficient. People were recommending going AMD, but AMD doesn't have CUDA.",
      "Its just bad price->performance ratio \n\nFor the money the 6800(XT), 7700xt, 7800xt are way better\n\nIf the Performance is ok for you dont worry and have fun",
      "Not really, just curb your expectations. Dont expect playing rt required games on 1080p max and get 60*fps, the vram will limit what you can do with these cards, and dont expect it at native either, you'll need dlss to run a good number of games these days even on 1080p.",
      "You should ignore all online talk and focus on YOUR OWN CONTEXT:\n\n1. What games do you play? Do they support ray tracing? \n\n2. What screen are you using? It’s cool to talk about 1440p and >180fps like many do online, but is that relevant to you? Your comment that you are “thinking of going 1440p” seems to imply that you are on a 1080p screen currently and the $$$ difference to run 1080p Ultra and 1440p Ultra, for both screen and gpu cost, is significant. \n\n3.  You are running an AM4 system with a decent CPU and a good amount of RAM for 900 euros. Such a system is well equipped to run many games on 1080p. \n\nTLDR - the 4060 is fine for 1080p gaming. If you want to go for a full 1440p gaming setup, going AM5 with a better graphics card would be advisable, but the $$$ difference is really significant (including the screen to support it). \n\nMost online talk are talking abt 4K gaming or a 1440p Ultra context, which a 4060 is almost DOA, although you can do some games at 1440p medium at probably 30-60fps. \n\nFocus on your own context, instead of getting misled by all the big talkers online. Of course a Ferrari is great, but if you can’t afford it, a Fiat is fine and perfectly functional",
      "Basicly rtx 2080 is rtx 4060 :)",
      "The price is really bad 👍🏻",
      "My girlfriend got a budget pc 1,5 years ago with 4060. She is happy af.  Games run great, she never ever have a game crash.  People act like the gpu doesnt even work or something.  She compares it to her old pc. And for her its a massive upgrade.",
      "It’s a good 1080p card and can play a fair amount of games at 1440",
      "I've got the 4060ti 16gb in my desktop and a 4060 8gb in my laptop.  Both perform admirably for me.  Expedition 33 on high settings runs beautifully at at 1080 and 4k respectively.  MSFS 2024 runs about 30-50fps on both.  It's not as bad as people make them out to be. Not the best mid tier cards Nvidia has put out, but not bad",
      "Its fine for 1080p"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "4060",
      "4060ti",
      "rtx4060"
    ],
    "title": "GPU for scientific computations and blender",
    "selftext": "Hi guys,\n\nI am building a new pc and I want buy an Nvidia GPU. My budget is maximum 500EUR but if it can be cheaper the better. I do scientific programming on CUDA and I want to get the best CUDA performance possible with that budget. I occasionally use blender also. I am not a gamer. Initially I was planning to get a RTX4060, then I read some discussions and decided to go for a RTX4060ti 16GB. Are there any RTX3000 series cards than can deliver better CUDA performance? Does it make sense to choose a 4060ti 16GB over a 4060 8GB ? Is that the best value for money option I have?\n\nPlease help.",
    "comments": [
      "The 4060ti doesn't usually have great value but if you need a lot of memory then it's very good. Blender can definitely take advantage of it. For the scientific computations you'll have to check yourself depending on the specific software you use.",
      "If ur ok with buying used gpu , then u go with a rtx 3080 it will perform better then a rtx 4060ti",
      "3080 or 3080ti with 12GB may be an ok choice (count the number of shaders times clock speed) - and if you find you need 16 or more GB then you can upgrade later. Recent comparison on Pugetsystems show 4060ti on par with 2080ti, so 3080ti should be faster.",
      "Hello u/stackoverflu   \n  \nWe wanted to create an advanced guide on enabling GPU acceleration and the best tips to speed up performance in Blender 3D and other creative apps. Whether you're a 3D artist or just looking to make your workflow smoother, we break down everything from choosing the right GPU to optimizing settings like tile size, CUDA, OptiX, and even cloud computing. Check out the full guide to make the most of your GPU for faster rendering and creative work.\n\n🔗 [Vagon GPU Guide](https://vagon.io/gpu-guide/)  \n🔗 [Guide for Using GPU on Blender](https://vagon.io/gpu-guide/how-to-use-gpu-on-blender)",
      "Thank you. I use C++ and python mainly. Which GPU has the best value for money? I am worried I might end up buying a bad one when I could have spent a little bit more and bought a good one.",
      "Thank you, I read about 3080s, still very expensive, I will look for a used one.",
      "Thank you. The 3080ti is still so expensive and it is above my budget. I will try and see if I can get a used one."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "4060"
    ],
    "title": "Need opinion to buy a GPU",
    "selftext": "Hello everyone, recently I am looking to buy a GPU. According to my budget I am comfortable with RTX 3060 or 4060. I want to play games at 1080p. Now the most important two factor more than gaming is (as I already know recent gpus will always give good FPS), streaming and AI. I want to stream at good quality at 1080p in twitch and ytube. Don't recommend AMD gpus as I already used two before and wanna experience NV. I want to have that NVENC. Also I need cuda for ai.\n\nIs 60 series NVENC inferior than 70 or 80 series?\n\nSO which should I go for? 3060 or 4060?\n\nAlso are INNO3D, Zotac and GALAX card good?",
    "comments": [
      "The NVENC is pretty much the same as far as I’m aware. \n\nTo be honest, neither of them are good cards for what you want to do. 3060 is nice with 12gb of vram, but it’s not a very strong card and will probably not be strong enough to play and stream at the same time at high quality or fps. The 4060 is not much better and is generally a terrible value card and it only has 8gb of vram.  It’s a very cut down card that should really be called the 4050. \n\nAs for streaming, as a rule of thumb, go one tier of resolution higher than what you want to play at if you want to stream as well. For example, in your case you want to stream and play at 1080p. If you’re serious about wanting to stream, then you should get a 1440p tier card to be able to do both things at the same time with good performance. \n\nI know you said you don’t want amd but at this price point they are hard to beat. If you really are dead set on either of those two, then technically the 4060 would do a better job, but you’ll probably feel that vram limitation trying to play and stream at the same time.",
      "Check rtx 4060ti 16gb instead of rtx4060 8gb. The price is not so different but the ti would do the job much better.",
      "Ok. But AMD is good for gaming only. I want nvenc and want to train AI model for which I need Cuda.",
      "In INDIA the difference is 200USD🥲",
      "Seems like your best bet is the 4060. Personally I think the 4070 would be perfect for what you’re wanting to do but that’s probably more money than you want to spend.",
      "Yeah."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "4060ti"
    ],
    "title": "Bought a 4060ti to replace my aging 1050ti",
    "selftext": "",
    "comments": [
      "Thats quite a jump. The 1050ti was great little card. Done me well for years",
      "Holy CPU bottleneck incoming",
      "Its an awesome card, but it can barely run Squad which is my favourite game, so I had to upgrade.",
      "Games are so unoptimized these days*",
      "Yeah, it has passed its prime. I had to upgrade a few years ago to a 2060 super for similar reasons, then had to upgrade again a couple of months ago to a 4070 super. Games are so demanding nowadays",
      "I looked at that cooler and motherboard it gave me pain seeing a 4060ti paired with that",
      "Hope op got a new cpu ram and new everything with the card",
      "Bruh",
      "happy for you",
      "Just got an rtx 4070 Super upgrading from RX 570!",
      "That's an LGA1151 board. So at the minimum intel 6th gen with ddr3. That specific board has a z370 chipset which is ddr4 and can go up to intel 9th gen.",
      "is that an FX CPU?",
      "Could've waited at least for RTX 12000 series then op could've gotten the 7000 series so much cheaper than the 4060 to now and better performance, silly OP",
      "Happy for you too, shareholder",
      "He just upgraded from a 4GB GPU and you think he has to worry about only having 8GB???",
      "Nice card, only worry i have is the 8GB VRAM",
      "You're not wrong. It's the release it in early access and fix it as we go business model",
      "1050ti was never a good card for its price because of rx 570",
      "😭",
      "i7 8th gen. Its an alienware board i installed into a new case (from an alienware r7)"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "4060"
    ],
    "title": "Upgraded to RTX 4060!",
    "selftext": "Went from rtx 2060 6gb to rtx 4060!! Super excited!!",
    "comments": [
      "Not a single comment is hilarious! Congrats though, can't imagine what the difference must be like.",
      "People were probably waiting for someone to make the first move to see if they're gonna shit on it or not.",
      "r/unexpectedfactorial",
      "Enjoy dude. I love this model and its a good upgrade. I bought a 4070 ventus 2x a month ago and I would have loved to have a totally black model like that for the '70. \nSorry for my english",
      "You're gonna love DLSS 3, enjoy!",
      "Some people really love to shit on it for the release price.",
      "I sure love my RTX 3.832319078 E+12889",
      "That CPU cooler looks slick. Research tells me it's a Pure Rock 2? Really like the style of it's heatpipe ends.",
      "\"sorry for my English\" types better than 90% of America. Don't apologize for your English, it's probably better than mine.",
      "Not gonna lie, being a top post on this community with my little card is something I’d never imagine happening haha 😂",
      "Enjoy the upgrade. 😁 Lol I am right now on my way to Micro center to pick up the same card. Upgrading from a 1660ti.",
      "Got the exact same card a few weeks ago and zero complaints on 1080p gaming. Enjoy!",
      "Why would they shit on it? Got this post recommended randomly",
      "I'm rocking a 4060 at 1440p, and it's completely usable. Enjoy!",
      "Yeh since it’s a 4060 and no 4090ti xxxtraoverclocked max boombada 8192gb vddr77 superdeluxepremiumneverseenbefore edition, nobody cares.. 🙄\n\n/s!!",
      "I’m not familiar with this community tbh. Just wanted to share my happiness with the relevant community.",
      "Loved my 4060! played most games at 1440p/high and got great performance on competitive games like Apex and The Finals.",
      "No, I am the stupid. It's got 8 gigs",
      "i use it at 1440p just fine.",
      "Found the legendary Ryzen 4070 user!"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "4060"
    ],
    "title": "[Gamers Nexus] Do Not Buy: NVIDIA GeForce RTX 4060 Ti 8GB GPU Review & Benchmarks",
    "selftext": "",
    "comments": [
      "60ti line up from best value product of 30x series, to the worst value product of 40x series. good job Nvidia.",
      "TLDW = Just overclock your 3060ti\n\nyou're welcome.",
      "I can‘t wait for the 4050 for my 720p Setup 👍",
      "well so far the only good value in the 40x series is the 4090, and it is damn expensive\n\nso nvidia went from buy whatever you want in 30x series to skip 40x series and hope for better price perf ratio in 50x series\n\nvery good job indeed",
      "Bro how can they make a card that barely competes with both their own hardware (3060ti) and AMDs last gen (6700xt).",
      "Generational non-leap",
      "This is E WASTE!!! Greta pls investigate",
      "New talking point for fanboys: nvidia gpus are so great theyre even outperforming nvidias own next generation replacement cards",
      "Greed",
      "Lol, it's barely a xx60 class card. Can't even handle 1080p with everything cranked up in some case.",
      "RTX 3060 Ti was on GA104 and had a 256 bit bus width. RTX 4060 Ti is supposedly a cut down AD107 die with a 128 bit bus width.\n\nThey can call it whatever they want, but that memory bus screams 50 class card. Either ways, stop being poor, and pay $400 for 1080p medium gaming.",
      "4060ti is a 4050 all but in name.",
      "\"Runs quake 3 arena at a crisp 60fps\"",
      "Well nvidia PR said “ this is a 1080p card “ lmao 399 for 1080p in 2023",
      "How could it be any worse. Its outperformed by the card its meant to be replacing",
      "Nvidia rly thinks we are stupid.",
      "man i expected worst but but dang it really  sucks lmao",
      "Generational tip-toe",
      "\"But, but, what about all the software we are getting, DLSS 3.0, Frame Generation?\" - Some idiot trying to justify a newer GPU with worse hardware than the previous generation offers.\n\nThis is 100% a skippable series, aint no way im gonna pay 400$ for same performance i could've gotten in 2020 for that exact amount of money, who is smoking crack at their HQ???",
      "just like the awful scam known as the RTX 3050 outselling all of RDNA2 + ARC combined (according to STEAM hw survey) i'm certain NVIDIA \"fanatics\" will make sure the 4060ti and 4060 are a sound success worthy or climbing the steam charts. PC gaming bleeds green after all.\n\n**Go GeForce, Go!**"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "4060"
    ],
    "title": "Just one person showed up to buy an RTX 4060 Ti for its launch in Japan",
    "selftext": "",
    "comments": [
      "that one person is probably trying to do benchmark for his new youtube channel lmao",
      "This is how it’s done people. Vote with your wallet!",
      "\"Business expense\"",
      "**Sad Violin music* *\n\nWhile Jensen wiping tears with AI paper cash",
      "On the one hand, you have articles like this that give some hope consumers would be forcing nvidias hand to lower prices. On the other hand, their earnings report shows gaming revenue higher than before the crypto boom. Its depressing as someone looking to upgrade.",
      "One too many",
      "Eh, I think the more concerning thing about the earnings report is just how much of an explosion there is in the AI/Machine Learning sector.  I worry that gaming will just become a red-headed stepchild, and voting with our wallets won’t even phase them; they’ll just put whatever horseshit out they want and laugh all the way to the bank with their AI money.",
      "Lmfao. Solid ;-)",
      "Yeah, this is why Nvidia is going to keep doing Nvidia. They have their hands in enough other things to easily stuff off their low gaming revenue.  As a customer of their GPUs, thats a bummer.. As a shareholder, I made enough to pay for a 4090 this morning.",
      "I'm sorry but Jensen is going to keep raising prices and give us less. No competition at all tbh. AMD is lacking and INTEL is just starting. NVIDIA completely dominates the segment and is the only one being innovative with Ray Tracing...AMD just copied and hasn't brought anything new to the table at all. I love AMD but they need to step it up in the GPU department, just like what they did with their CPU's! Cmon Lisa",
      "Nvidia Gaming revenue is back to pre crypto level now. It's not going to be the dominant segment of their revenue anymore but still very lucrative and they control 70-80% of the market.\n\nThey are not leaving gaming market anytime soon and still want to keep their dominance.",
      "[This](https://www.youtube.com/live/fH7KEisF_y8?feature=share) is one out of only 2 Japanese reviews I could find that actually had benchmark numbers lmao.",
      "&#x200B;\n\nhttps://i.redd.it/shrn37nbh12b1.gif",
      "what you talking about ....my business also needs my 4080....without it...my monitors don't turn on",
      "Intel is really good with their pricing though, their next gen might be some serious competition.",
      "It’s mixed. Some comments are saying it makes more sense to buy a Radeon GPU or the 3060ti. Some say the 4060ti is worth it due to its low power usage and the fact that you could probably undervolt even lower. Some comments agreeing that it’s a waste of money. Also people mentioning the 8GB. I did watch a portion of the video, not the entire thing, and they just seem to have a neutral stance on it. They weren’t really praising it but also not shitting on it. They did mention during the Star Wars game “Just look at how much it’s using! 7.42GB/8GB. That’s insane!”",
      "I'd buy it if it had 12g of vram and was $50 cheaper",
      "This makes me wonder how some of the other worst cards in the last few years, like the GTX 1630, RX 6500XT and the 8GB variant of the RTX 3060 have sold.",
      "Gaming revenue is at 2.2 bil which is the highest since the Crypto Boom era of 3.6 bil.\n\nThis number can be increased either by selling more volume or selling smaller volume at higher price.\n\nNvidia is doing the latter. Every \"name equivalent\" 40 series SKU is more expensive than 30 series except 4060 Ti (same price) and 4060 (lower price)\n\nAnd Nvidia is also pushing for more lucrative ASP product mix by upselling to higher end cards by making them look like better value vs lower end cards.",
      "I wish ppl would do it with the WHOLE 40 series, instead of accepting 1300$ 4080s and 1800$ 4090s as the new “Normal”😒 The 30 series offers enough performance for 90% of ppl…"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "4060"
    ],
    "title": "4060 is now the most used GPU in Steam",
    "selftext": "[https://store.steampowered.com/hwsurvey/videocard/](https://store.steampowered.com/hwsurvey/videocard/)\n\nhttps://preview.redd.it/n3g5w9jfu9me1.png?width=972&format=png&auto=webp&s=63e0d7cb307b37ca65344564b08b07e792ac54e9\n\n",
    "comments": [
      "Steam stats are so interesting, like who are the people using a GeForce 6800 in 2025? They last worked on Vista and XP, which steam doesn’t support anymore so probably running a modified or older version of Steam",
      "https://preview.redd.it/5oeueqeyv9me1.jpeg?width=2819&format=pjpg&auto=webp&s=e5c44e8c8fee90d212a1b3a1740b6c5ede6b4ee0\n\nHere is my little 4060 next to an Asus TUF 3080.",
      "Internet Cafes",
      "Nearly no one. If someone with an old computer logs onto Steam for playing older games that don’t work on current Windows then it’ll get added to the survey. But they make up like 0.01% of users.",
      "Simplified Chinese also up to 50.06% +20.88%",
      "Maybe in NA and EU. In other regions 4060 is the only card that people can afford and it is a great card for those regions.",
      "That's tuf bro",
      "This! They all got upgraded after closing for Chinese New Year.",
      "60 class GPUs always tend to do that, that's where most people are buying from",
      "That's still how it works",
      "[That's why.](https://i.imgur.com/J4EbZma.png)",
      "Something is wrong. No way the increases from Jan to Feb are that large. Are they even producing 3070s for it to increase 50% over 1 month?",
      "Wukong might be the reason for this, most people like to play in Chinese instead of weird English voiceovers.",
      "Yup, majority of people are not spending more than $500 every 5 years.",
      "Nah it's just the only thing people can afford",
      "https://preview.redd.it/autlgsfaabme1.jpeg?width=3024&format=pjpg&auto=webp&s=ea717f9721d9defa36a6e9e62b7f111d11ab212a\n\nHere is the same TUF 3080 next to the Gigabyte 5070 ti.",
      "At 340€, it's the only card most people can afford in EU too honestly. Not everyone is Germany or Norway",
      "Would be cool if steam modulated the results by money spent on games or time spent playing.",
      "How does steam survey work these days. I thought they offer it at random and you have a choice to accept it.",
      "Internet cafes and Country's with very expensive hardware prices, so low end GPUs are the one getting bought"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "4060ti"
    ],
    "title": "Got a 4060Ti to replace my GTX 970",
    "selftext": "",
    "comments": [
      "970 was a beast",
      "*3.5gb lol",
      "Yeah I remember this scandal when I had my 970. NVIDIA has been scamming with VRAM for years now.",
      "Yea but those 4GB are getting old now",
      "I just went from a GTX 1660 Super to a RTX 4060 before looking at all the comments about the 4060. And honestly; I have no idea wtf people are complaining over. It’s a solid card and I can run Stalker 2 on 1440p with high settings without any issues.",
      "Mostly because 4060 price to performance ratio is not great.\n\nIt’s not a bad card, but it’s bit overpriced for what it is.",
      "I have absolutely the same GTX 970 lol. Enjoy your upgrade.",
      "970 was only $330 so many didn't complain, was great for that price.\nId snap up a 5070 11.5gb that matched the previous gen top dog card for $330 🤣",
      "you are acting like the new cards are going to be available as soon as it's announced lol",
      "Enjoy it and ignore the echo chamber, as long as you're having fun with your games it's all that matters",
      "Still you get more performance per dollar on 4070.\n\nThat’s the main gripe against 4060, price to performance ratio. If you’re happy with your purchace, that’s good for you. Some might rather pay that 200 more to get more value.",
      "congratulations   \ni was going for the same card but end up with 4070 super which is 12GB  \ni wanted more Vram as i work in 3d softwares, this 4060 is 16GB which is good",
      "3.5GB Club represent!",
      "No bad cards, just bad prices.",
      "It’s the 3060 > 4060 difference and manufacturing issues where all this “static” comes from. \n\nIf you’re upgrading from a GTX or RTX2K it’s for the most part negligible. You’ll be happy with the gains.",
      "I got rtx 3060ti few months before 4060ti. dont regret much going from gtx1660.",
      "Because at the time it was launched, you could grab an rx 6700XT that has 12GB and performs on par to the 4060TI for pretty much the same price.",
      "This is a myth, check out hub video on this, 4060ti comfortably utilizes what is available. Might not take 100% of that 16gb, but these unoptimized ue5 titles still crave for vram.",
      "Imagine if the RTX 5070 will have 8gb of VRAM+4gb that'd be very slow like with the GTX 970, especially with the hefty price tag 🤣.",
      "for me, I upgraded my pc. I was using GTX 950 but now I have RTX 4060🥰"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "4060ti"
    ],
    "title": "RUMOR: 4060TI coming in May for $450",
    "selftext": "",
    "comments": [
      "So is this just 3070 performance for 3070 price. K.",
      "3070 performance, 128 bit bus, 8GB again.",
      "Omg finally, 3070 performance for 3070 price! Im so excited!!!",
      "Rumor of 8GB VRAM. Already DOA. NVIDIA wants you to spend $1100+ on a GPU or just get their monthly subscription service.",
      "Trash. Nivida's offering this gen is awful.",
      "Be happy they didn't charge 3080 money for it",
      "But DLSS 3 makes up for it /s",
      "would arguably be nvidia's worst offering this gen if it is only comparable to a 3070 considering the 3060ti was already very close to a 3070 performance wise",
      "frame generation eats up VRAM on top of RT. Literally repeating the 3070 issue. also that tech gets worse the lower in spec the gpu goes.",
      "Well they already launched the 4070 as 3080 performance for slightly less 3080 price.",
      "8GB would pass for a 4050, but a 4060/4060TI deserves 12.  My friend just bought the rereleased 2060 with 12GB FFS.",
      "with lower bit bus, same vram and lower cuda cores lol",
      "Member when xx60 cards were $250? Pepperidge Farm remembers.",
      "So third party GPUs gonna be minimum 500€ in eu. Mega rip the whole sub 500 market what a shit show. 1070 going for another year for me",
      "Yeah so technically paying for DLSS3 at that point.",
      "Here we go again. $50 more than 3060ti. Same amount of VRAM.\n\nProbably 3070 performance.\n\nMeanwhile, 3060 ti was equivalent to a 2080 Super.",
      "They're still riding high on the reputation the 10 series earned them.",
      "You literally are NVIDIAs perfect customer spending a ton of money for nothing",
      "They are purposely letting the 4000 series be sub-optimal,  just like they did with the 2000 series after that other mining boom. \n\nIt’s about manipulating people and the perception of value.   It’s almost like a good cop bad cop thing.  4000 series is the bad cop,  with is meh value, and mediocre vram.   5000 series will likely double many vram amounts due to higher density gddr7, and with the higher prices now, when they drop them by $50 next gen it will look like such a deal that it’ll create a new super cycle of buying.",
      "Can't wait for 4040 Super TI.\n\n3050 performance for 3060TI prices."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "4060"
    ],
    "title": "NVIDIA GeForce RTX 5060 Laptop GPU 3DMark leak shows 33% increase over RTX 4060 Laptop",
    "selftext": "",
    "comments": [
      "tldr:\n\n* Laptop 5060 is 1.3x faster vs Laptop 4060 AD107\n* Laptop 5060 is 1.1x faster vs Laptop 4070 AD106\n* Laptop 5060 is 1.03x faster vs Desktop 4060 Ti AD106\n\nBig unknown is the power as laptop performance is sensitive to the power",
      "Well that's def good gen over gen improvement but it's almost certain that again it'll come with 8GB vram which really started to became bare minimum for modern and upcoming AAA titles. Power probably will stay around similar levels.",
      "Supposedly 115W max TDP according to the article. Congrats to NVIDIA if they manage to pull off this performance/W on the same process node.",
      "The compute on it definitely needs more than 8GB I've encountered many situations where my 4060 laptop could push more fps but it ran out of VRAM.",
      "They are still selling 2050 laptop with 4GB of VRAM (for sub $600 though). I don't know if people can play anything recent that isn't CS2 on those...",
      "Any info on the core configuration on 5060 laptops?\n\nEdit: Listed as 28SMs/3584 CUDA cores in the TechPowerup GPU database. Sharing the GB206 die with 5070 laptops (36 SMs).",
      "Rtx 2050 is a grace of a gpu from nvidia. Barely faster than Gtx 1650. It's literally just for scamming the unaware customers imo.",
      "I'm using DLSS Q at 2560×1600 resolution and too high texture resolution or RT overflows the VRAM. For example in Dogtown CP I couldn't use RT while elsewhere I could because there are so many assets there it fills up the VRAM.",
      "I can not tell if you are serious.",
      "Because there’s no laptop 4060ti, it’s the laptop 4070 and the desktop 4060ti.",
      "Don't know how to feel about this because the desktop 4060 and the laptop 4060 didn't have as dramatic of performance difference as other gpus (like the 4070 being over 40% faster than it's laptop counterpart).\n\nIf Nvidia keeps that difference relatively the same, then the desktop 5060 might not even come close to the desktop 4070's performance. It might just be an upgraded 8gb 4060 ti.",
      "I don't get why people like you continue to say \"the computer of the chip doesn't require more\" when most of vram is due to textures and assets, if you run out of vram doesn't change if the gpu is a 750ti or a 4090.",
      "To be fair, Laptop has very good value for budget segment. Mobile 4060 gaming laptop costs like $600-700 on good sale and it is fairly hard to do better with desktop build, especially if you count peripherals and windows 11 too.",
      "This is total nonsense. This seems like you have gathered up bizarrely wrong information from kids on gaming forums taking wild guesses. \n\n*On nvidia the engineers fine tune and kinda like tailor the vram on each gpu,*\n\nThey 'kinda like tailor the vram'? \n\n*if the die doesn't use more than 8GB efficiently there's no use on putting more vram into it,*\n\nThis isn't how computers work. Either they can access it or they can't. Memory holds data. In games it fills up mostly with textures.",
      "Because the 4070 was 30-35% better than the 4060 TI. \n\nThe article said that the 5060 laptop is about 3% faster than a 4060 ti desktop. If the 5060 desktop has the same difference in performance as it’s laptop counterpart like the 4060 did, then it would be only an extra 10% of improved performance over the 4060 ti. So 13%. That would still make the 4070 17-22% faster than the 5060 if that ends being the case.",
      "I'm fine right now I just can't use RT in brand new games. I get around 50 fps which is enough since I value looks over fps and wouldn't mind 35-40fps with RT but since I don't have enough VRAM I get 10. Also I'm never going back to 1080p that looks shit. My goal is not good performance but acceptable performance at the best quality.",
      "We're all going to have to learn how to solder VRAM chips. I'll just be sticking with 4000 series for a while and hope this all sorts itself out. either their AI bs works and cards end up needing less VRAM or that whole thing flops and they actually start giving people VRAM(which they should anyways cause people are going to start turning to AMD).",
      "2050 is actually based on Ampere not Turing. It can certainly run all modern titles at lowest settings. Not well, but it will work.",
      "Gpu doesn\"t use the vram, programs and games use it and yes there should be more.",
      "https://youtu.be/Fe_JgW067-s?si=SInA5uegm2w2xT4d\nSeems to work on a low end build I just googled. \n\nTexture pool size settings will mess up fps if you don’t adjust accordingly"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "4060"
    ],
    "title": "NVIDIA GeForce RTX 4060 Ti expected to offer RTX 3070 performance for less than $500 - VideoCardz.com",
    "selftext": "",
    "comments": [
      "I'm no expert... But the 3070 already offers 3070 performance for under $500",
      "What a joke. The 3060 Ti G6X already closes the gap to the 3070 and is just slightly slower than a 3070 at this point. Now Nvidia releases a card that is 5% faster for probably 10% more money after two years🤡",
      "Absolutely. Green team hoping we don't know how to add 1 + 1.",
      "You mean $499? because thats the number I think Nvidia will price it.",
      "Which due to inflation now equals 3",
      "I really hope sales for this generation (outside of 4090) will be abysmal, so that maybe NVIDIA realized ...  bloody consoles offer a complete package for $500 while your mid-tier 128bit (!!!) card alone costs as much and requires a PC (CPU + cooler, RAM, mobo, case, kb and mouse) on top of that.\n\n3070 performance for 3070 price two years later. WTF are you doing and thinking NVIDIA?",
      "Looks like shit",
      "But 3070 already offers 3070 level performance for less than $500",
      "The headline sounds like that's a good thing.\n\nThat's awful. The article says closer to 500 bucks. That means, even if it's a bit less, same price performance point + dlss3 + better RT performance + probably less wattage.\n\nThat's a joke. That's like they release the 3070 with improved RTX features. 3070 Super would be an appropriate name.",
      "Yes, Nvidia recently phrased out the original RTX 3060 Ti with GDDR6 memory and replaced it with faster GDDR6X at the same price. The increase in memory bandwidth puts it even closer to the 3070 now as even the original 3060 Ti was like about 10% slower than the 3070.",
      "NVidia gloated to their investors that consumers are willing to pay $200-$300 more for a card then they used to. \n\nIt feels like this is so ingrained in Jensen’s head, that he now just straight up adds that number to any reasonable price for every 4000-series GPU and calls it a day.",
      "4070 rumoured with 3080 performance and price, 4060ti rumoured with 3070 performance and about or less the price.\nSo three years of technological development the only thing we get is software(dlss3) and less power usage?",
      "Fuck them",
      "😂🤣 you’re an expert in my eyes",
      "G6X refers to Gddr6x, correct?",
      "Guys, you’re killing PC gaming. What is entry point anymore",
      "fuck spez -- mass edited with redact.dev",
      "If you have a 3080 you shouldnt even consider upgrading, unless you have the 10 gb version, that i see it vram limiting the gpu at 4k at least.",
      "It is, sadly. That's why I'm staying with my 3080 OC'ed. I thought about 4090, but it is ridiculously expensive",
      "My GTX 1080 it's gonna live forever."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "4060"
    ],
    "title": "RTX 4060 TI now in TOP 5 most used GPU on Steam - Steam Hardware Survey (September 2024)",
    "selftext": "Top 10 net increases:\n\n1. NVIDIA GeForce RTX 4060 – +1.17%\n2. NVIDIA GeForce RTX 4060 Ti – +0.76%\n3. NVIDIA GeForce RTX 4070 – +0.39%\n4. NVIDIA GeForce RTX 3060 – +0.35%\n5. NVIDIA GeForce RTX 4070 SUPER – +0.35%\n6. NVIDIA GeForce RTX T10-8 – +0.21%\n7. NVIDIA GeForce RTX 3070 – +0.16%\n8. AMD Radeon 780M Graphics – +0.16%\n9. NVIDIA GeForce RTX 2060 – +0.16%\n10. NVIDIA GeForce RTX 3060 Ti – +0.14%\n\nThe current top 10 are:\n\n1. NVIDIA GeForce RTX 3060 – 5.86%\n2. NVIDIA GeForce RTX 4060 – 4.58%\n3. NVIDIA GeForce RTX 4060 Laptop GPU – 4.37%\n4. NVIDIA GeForce RTX 4060 Ti - 3.66%\n5. NVIDIA GeForce GTX 1650 – 3.64%\n6. NVIDIA GeForce RTX 3060 Ti – 3.57%\n7. NVIDIA GeForce RTX 3070– 3.31%\n8. NVIDIA GeForce RTX 2060 – 3.30%\n9. NVIDIA GeForce RTX 3060 Laptop GPU – 3.00%\n10. NVIDIA GeForce RTX 4070 – 2.91%\n\nSource: [https://store.steampowered.com/hwsurvey/videocard/](https://store.steampowered.com/hwsurvey/videocard/)",
    "comments": [
      "I remember every reviewer saying don't buy the 4060, including this subreddit. Guess it really shows that even though millions watch/read those articles, its a really really small % of the actual market.",
      "The first dedicated AMD GPU is the RX 6600 at 34th place. That's rough, man.",
      "The 4060 makes sense for markets outside of US & Canada where prices and tariffs are higher than what we see.",
      "AMD hasn't really created value in the GPU market, or at least not enough. They always release their GPUs at higher prices than they should, then in a panic bring it down but at that point it's too late. Also NVIDIA has DLSS and ray tracing that are both just significantly better than AMD.\n\nHopefully the next gen of GPUs means not just AMD wakes up but Intel also jumps in to compete more adequately with the 5060-5070 product line and drives down prices. Would be great.",
      "I see six 3060 variants in the current top 10.",
      "More people buy pre builds than build them, and most are NVIDIA, and many builders don't research.",
      "I used to pretty much exclusively buy team red cards for a long time. I built a computer with a Radeon 4850 around 15+ years ago and my computer before that definitely had an ATI card from one of the x000's series, can't remember which one. I did have an Nvidia GeForce 256 at one point earlier but I think that just came in a pre-built we purchased since I did not start building my own PC's until the mid 00's. But I basically stuck with AMD all the way until Nvidia released the 2000 series at which point I got a 2070. Been on Nvidia cards since then. \n\nI just bought a game on Steam yesterday and when I went to launch it for the first time it popped up saying two different launch options: 'Default' and 'AMD Driver graphical error fix.'\n\nIn my head I was like, 'Wow, even after all these years it still hasn't gotten better for them has it?'\n\nSwitching to Nvidia has made my gaming experience so much less frustrating. Everything just works. Every game, every driver update, everything. No thought to it. Nvidia vs AMD is like night and day, and that is coming from a huge team red fan.",
      "Indeed, in my country 4060 is $400 (same as 3060 for some reason). And everything above that is just way to expensive. 4070 is $900 and 4090 $2700 to give you an idea.",
      "News flash: both normal consumers and actual enthusiasts dont view it as a team sport. That is reserved for a small, utterly irrelevant middle ground.",
      "No one really has a choice. You either buy poor value GPUs or buy last gen and miss out on new features.",
      "AMD has to. Intel gpus, the PS5 Pro, Switch 2 and even iphones  have AI upscalers. If their new cards don't, that would be an embarrassment.",
      "It’s like watching all the GTX1060 Owners grow up and finally upgrade",
      "Thank god people don't listen to other people. Because I will defend the 4060 I've gotten to test one. I own the 4080 super now but the 4060 kind of blee me away with what it could do. Because of the hate even though its really over price. To me its not that bad. Was able to play 1080p ultra on literally every title. Also 1440p on more titles then peolle said. And with dlss it can do 1440p no problem on every title pretty much. It's a good budget card.",
      "There are people who know it's a bad value card and still buy it. If you want to buy a brand new card, not used and don't want AMD or Intel, what other choices apart from the 4060 you got? None. So 4060 it is. And TBF while it is kinda expensive for what it is it's still not that far of a 3060Ti in performance, which makes it a very good 1080p card. Most 2024 games can be played at max settings with DLSS and pre 2021 games can comfortably run at 80-100 FPS max settings at native, which is more than enough for a casual user.",
      "I live in small European country... 4060 ti is extremely overpriced here. You are forced to go 4070 (super) and up",
      "arennt mobile graphics cards underpowered in wattage so not the same at all?",
      "Its crazy to see the 3060ti at 7.23% GPU share.",
      "I think a lot of people know, but its just what they can afford.",
      "You could argue that a 1080ti is a 3060 variant too at this point. 3060 and 4060 might not have that big of a perf gap but they’re still different generations with different architecture",
      "damn! 1050ti still hanging on in 13th place!"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "4060"
    ],
    "title": "Gigabyte confirms GeForce RTX 4070 with 12GB memory and RTX 4060 featuring 8GB - VideoCardz.com",
    "selftext": "",
    "comments": [
      "Sooo the 4070 is effectively a 3080 12gb with a lower memory bandwidth",
      "And then Nvidia will point at the 3080 12 gigs stupid msrp and compare it to the 4070 and be like \"look how good this card is\" ignoring the 699 3080 10 gig card.\n\nThe 4070 better blow the 3080 10 gig out of the water but I don't think it will.\n\nAnyone else remember the days when 70 series usually matched the previous gen 80Ti flagships for way less money?",
      "Just makes the 3060ti more of a screaming value",
      "Such a joke, and I am sure the price would be also ridiculous.",
      "Nvidia is 100% losing business because of their SHIT vram. I game at 4k. I DEFINITELY would have bought a 4070ti with 16gb vram. 12 GB though? I'm now the proud owner of a 7900 xt and sitting at a cool 20GB and never have to even look at vram consumption.\n\nPaying 800$ for a card and worrying about running out of vram is an ABSOLUTE JOKE. The incompetency and greed is kind of infuriating.",
      "And ppl would still buy it. That's why Nvidia keeps doing it",
      "4060 >= 3070 >= 2080 >= 1080 TI.\n\n1080 TI had 11GB of VRAM. 4060 has 8GB.\n\nWhat.",
      "Then you realise 4060 has less VRAM than 3060",
      "Which is exactly what Nvidia wants as they still have a shelves full of them.\n\nWelcome to 2023 where the best deal is to buy 2,5 year old mid range card for 400$...",
      "Is there actually a reason the amount of vram has hardly gone up the past 7 years? It's so hard to justify their current prices with such low amounts.",
      "That's part of the joke, I say \"remember the days\" like it wasn't fucking 2 years ago lol",
      "Market segmentation. \n\nThey don't want people have access to lower cost cards that have over 10GB of VRAM.\n\nIt makes them very good for video production, academic deep learning uses and similar.\n\nThey could get away with it before because games would work but now they really don't so I think 4060 is going to be destroyed by reviews.",
      "They want the people that need VRAM to buy their pro cards",
      "Only on the Nvidia side of things. But then, Nvidia has always been holding back on VRAM compared to AMD.",
      "The 4070 has good specs but I’m still not going to pay $800 for a 70 series card. No way",
      "6700xt is ultra screaming value.",
      "I luv my 3060ti",
      "good choice really. Seeing how new games are trending, most of the Ada line up wiill have problems very soon. It's absurd that nvidia want $1200 for 16GB of VRAM.\n\nThey advertise these cards on the back of ray tracing and DLSS3, both of which take additional VRAM. 12GB should have been the minimum for this generation.\n\nYou pay that much, you should not worry about VRAM.",
      "if you want to play diablo 4, re4, hogwarts legacy, dead space, forspoken and probably more and more releases this year, do not buy a 8GB card.\n\nWhile they run, they won't run well and the hit to texture quality is the last thing you want to deal with, especially for a new purchase/upgrade it's plain unacceptable.\n\nOn your old card, it's reasonable to turn things down now after years of use but a brand new card that probably going cost around $500 and out of the gate has to lower texture quality and it's a 4GB regression from its predecessor no less, makes no sense. You are just throwing money away. \n\nI really like to see how this 4060 compares with 6700XT for example. That's like $350 right now. yeah AMD driver this and that, it's still going to be much better way to spend your money for the budget conscious.",
      "If you've got a GTX 1070 what are these people going to upgrade to? We have 2 manufactures and both are greedy, RTX 4080 is £1150 and the 7900 XTX is £1050, people have to buy one or the other.\n\nI waited for a whole year until I could get a FE 3080 for £649, even with patience now I could never get a 4080 for anywhere near that, nor a 7900 XT/XTX."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "4060"
    ],
    "title": "NVIDIA GeForce RTX 4060 Ti rumored to cost $399 (8GB) and $499 (16GB) - VideoCardz.com",
    "selftext": "",
    "comments": [
      "PCIe gen4 x8\n\nIs there no end to the trimming NVIDIA will do to Ada? So let’s recap. \n\nIt’s essentially a 3060ti “super” with a 128-bit bus, well over two years later and being sold to those with less money. These rumors about Ada being potentially spun on Samsung 8nm get more plausible with every product launch. What a joke this silicon is, in the face of what it could and should have been.  \n\nAnd the best part, all the 4070xx owners worried about vram now, bend over! Nvidia is ready for ya!",
      "I still find it how insane the upcharge is for 8GB of vram when the BGA chips themselves are like 6-8$  \nMicron  MT61K512M32KPA-24:U  is 40$ for  16GB GDDR6 and thats for a SINGLE 16GB FBGA chip, so a GDDR6X probably isnt that much more",
      "$499 4060Ti on its way to perform like a $499 3070 from 2 years ago and people will still gobble it up. Shits hilarious",
      "Suck my balls Jensen.",
      "So, they are just rereleasing a 3070 with twice the vram capacity with support of DLFG, AV1 and less power consumption for the same price after near 3 years??",
      "4th tier performance for a price that was once 1st tier. Hard no.",
      "Still too high. Need to shave $100-$200 more off.",
      "4090 vs 3090.. like +80%\n\n4080 vs 3080.. like +50%\n\n4070 vs 3070.. like +20%\n\nsee any trends yet?",
      "100$ for some vram. nvidia is forcing me to buy amd",
      "8 gigs of VRAM ain't worth 100 bucks especially considering the RX 580 8GB goes for just 70 bucks nowadays. Sure that's GDDR5 but it has a full GPU attached to it! This really is a disaster generation. If the 16gb variant was 349 then maybe, but nope...",
      "Ah cool so good to know the 4060ti has more vram then the 4070ti and the same amount as the 4080.",
      "How about $450 for the 16gb and no 8gb? What a joke.",
      "You are not buying it for raw performance.  Just dlss3+FG.  If a game doesn't support those, these will be as good last last gen.",
      "4070 TI is still the better GPU. More VRAM does not mean it's better.",
      "This is going to be a disaster of an upgrade 9-10% performance gain for the same money 3 years later. Thank you Nvidia!",
      "A 60-series Ti card in 2023 with 8GB of VRAM in 2023? Are you serious?\n\nDidn't the RTX 2060 Super have 8GB of VRAM? That was two goddamn generations ago.\n\nWith every new release the 11GB VRAM in the 1080Ti makes more and more sense",
      "This all goes back to us calling out the 4080 12GB for what it was, a 4070.  Ever since then, their product names and specs have been whack.",
      "$500 is DOA",
      "DO NOT BUY THE 8GB model. This is what a corporation does when it tests the market if you buy the 8GB model you are sending a message that we do not need higher VRAM cards. The purpose of the 16GB model whether you like the 100 dollar markup is to see if there’s enough demand for clamshell memory GPU’s. They are testing the market if the demand is higher on the 16GB it sends a message that gamers want MORE VRAM. There’s a reason for the markup they are trying to maximize profits. Skip the 8GB model even if the 16GB model is overpriced.",
      "The 8GB versions will age like shit at 1440p of course. This reminds me of the GT 1030 DDR4 that was way worse than the GDDR5 version, or the 8GB 3060 being way worse than the 12GB variant.\n\nThey're willing to outright scam people for the low end cards because many people searching in that price range, like say, soccer moms, are less knowledgeable and may pick the 8GB version because they just see the VRAM being a bit less but it's cheaper.\n\nThe only reason they unlaunched the 4080 12GB is because NVIDIA realized that people in the high-end market aren't as naive and they know better than to buy a way worse version of a card at the price they're spending. NVIDIA is not gonna fool anyone who would buy an 80 class card or even a 70 class card."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "4060"
    ],
    "title": "NVIDIA to launch GeForce RTX 4060 Ti 8GB this month, 16GB model planned for July - VideoCardz.com",
    "selftext": "",
    "comments": [
      "Why",
      "give us a 4070 16gb cmon",
      "Games are using 12GB's+ on Max settings and 12.5GB's+ is where consoles are going to sit this Gen.",
      "nvidia is pulling a knee jerk reaction, first they made the 3060 12gb as a reaction to amd's higher vram cards because of consumer perception of more vram being superior, now they making the 4060ti 16gb as a reaction to slow/low sales of their higher tier models and current evidence of \\[optimized/unoptimized\\] games performing badly and/or crashing from lack of vram.\n\nThe product stack is becoming a mess, with the higher end cards getting the perception of being shafted with less vram compared to a mid range card having more vram. Yes vram isn't \\*everything\\*, but having more expensive higher tier cards being lopsided with \"less features\" than a lower tier card just seems wrong.  \n\n\nEdit: And they know they already partially screwed the product stack when they were forced to rename the 4080 to a 4070ti, every card under a 4070ti being released was meant to have a model name reflecting one tier up (4060ti was meant to be the 4070, 4060 was meant to be the 4060ti, etc).",
      "A 16gb 4060ti but not 16gb 4070?",
      "AMD was selling 8GB cards for $250 in 2017. Why is nvidia bothering to offer 6/8GB cards in 2023? Profits and penny pinching and milking their market share/name brand from the casuals.",
      "with the current insane gpu prices, doubt u can buy anything at all for 300$. 1 gpu = 1 console right now",
      "I'm so confused with all of this. Why even bother offering 6GB VRAM cards, then release 16GB, and the next graphics card will mostly be somewhere at 8GB VRAM?\n\nI am asking because I literally have zero idea what card to pick for building a superior high-end PC? Why do people even bother with lower VRAM graphics cards?",
      "A770 8GB's are 280 Euro in Germany, quite impressive considering it's fucking Europe.",
      "I fully understand Nvidia has concluded it doesn't matter to their business, but imagine how much better their press would have been if the 70 cards simply had 16 gigs.",
      "4070 SUPER incoming!",
      "NVIDIA learned from the 1080 Ti that putting too much VRAM on a card makes people stick to their cards longer. They won't be making that mistake again. This generally only applies to affordable cards, people who buy 4090's will buy 5090's regardless.",
      "Yeah 3070ti 8gb user here, i just know something's off about my games. then hardware unboxed released that video comparing 3070 8gb vs 16gb 6800.\n\ntextures randomly not loading on 3070 because of severe lack of vram, on and off graphics quality. that's when i knew i was fucked by their planned obsolescence\n\njust over a year of usage and already underperforming; just wow, nvidia.",
      "4070 16GB when?",
      "A 4070 ti with 16gb and I would buy it in a heartbeat.",
      "This comment doesn't make sense to me. The 1080ti was the top tier card for the 10 series like the 4090 and 5090. There was no 1090. By your logic someone should have stuck with a 1080ti longer but also upgraded to a 2080ti and 3090 regardless.",
      "Next gen will be 32GB 5060Ti, with a 10GB 5080Ti.",
      "More a programmed obsolescence, nothing else.",
      "[https://twitter.com/kopite7kimi/status/1655823348411277312?s=20](https://twitter.com/kopite7kimi/status/1655823348411277312?s=20)  \n\n\nThere might be a AD103 4070 that could have more vram",
      "* Intel Arc A770: $340-350\n* AMD RX 6800: $480-500\n* PlayStation 5: $460-560"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "4060"
    ],
    "title": "GeForce RTX 4060 faces reduced supply in February, as NVIDIA prepares to launch RTX 5060 in March - VideoCardz.com",
    "selftext": "",
    "comments": [
      "They haven't even \"released\" the fucking 5090",
      "Fuck NVIDIA",
      "Nah, this launch is worse.\nI was able to get a 3090 for MSRP back then with the help of a telegram channel posting stock.\n\n\nThis time? The whole supply for DE and AT got bought up 30 minutes BEFORE launch, because some insiders got an early access and bots got the link somehow, from what I have heard.",
      "they've shut down entire production of the 4060 for the next 2 months because they are going to release a batch of 20 5060's in March.\n\nafter that, you'll have to wait 6 months for the next batch of 20 to be released.",
      "An underpowered and overpriced 8GB card getting phased out for ... another underpowered and overpriced 8GB card!",
      "“Launched” is what they call it?  Pricks",
      "so heartworming seeing this on nvidia sub.",
      "Yes underpowered. In some scenarios it's worse than the 3060 and it's rarely better",
      "Piece of shit company",
      "There are barely any 5090s. Can't believe I'm saying this but we can't blame this on scalpers. My local retailer said they were hoping to receive FOUR Astrals but they received only TWO. Only TWO for the top Asus product. They didn't even receive TUFs yet... No PNYs, no inno3Ds, MSI haven't launched Ventus yet I think... Only super duper expensive 5090s and even them in very very low quantities. It's evident that there's a massive chip shortage, and NVIDIA is to blame here; they simply haven't manufactured enough for the launch. According to retailers this will go on until at least April, and who knows what the prices will look like then with tariffs and all.",
      "“Prepares to launch” my fucking ass lmaoooo joke of a company",
      "And the second batch will cost $200 more than the first, plus extra tariffs if you live in the US.",
      "You might wanna get medication for that. \n\nR/boneappletea",
      "The people are waking up.",
      "Naw, lower gpu segment tier are always going to be high in quantity because of binning/unbinning process.",
      "But it'll be 10% faster, draw 10% more power, and cost 10% more and still have 8GB of VRAM.",
      "I swear, I'm going to lose it if even the 5060 has low supply/stock lol.",
      "They’re not making 5090, they’re waiting for bad yields on the Blackwell AI cards.  As their yields get better, GPU inventories will go down.",
      "What point are you trying to make? The RTX 4060 was $300 at release, and still is $300 today.",
      "\"prepares to launch\" ...\n\nriiiiiiiiiiiiiiiighht.\n\n![gif](giphy|rGY94yhbewtPzLdx6q)"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "4060"
    ],
    "title": "[LTT] I’m actually getting MAD now. – RTX 4060 Review",
    "selftext": "",
    "comments": [
      "might be unpopular here, but i \\*really\\* dislike using DLSS/FSR, its odd feeling and looking, id rather have good, raw performance than having to rely on gimmicks to have the experience the card should give from stock",
      "So it's roughly as powerful as a 2070 Super... which can be found for less than $200 used... while having a significantly smaller memory bus and bandwidth, same amount of VRAM, etc.\n\nThey're *really* banking on DLSS to make up the difference for these cards, but otherwise they really don't seem to give a shit.",
      "Me too, exactly. Don't get me wrong, I love the tech. However, I hate that it's being misused in my opinion.\n\nIt's being used as a crutch by lazy developers to get games running at acceptable framerates instead of optimizing them. The base game should run at at least 1080p/60 FPS without any DLSS/framegen trickery, and it should be used to achieve even higher framerates.",
      "It’s basically a more power efficient 2070",
      "Definitely not a 4060 😁",
      "DLSS has turned from a feature, allowing to push for acceptable 4K performance at the high-end into how much can a gpu be gimped to manage acceptable performance with DLSS at 1080p.\nMining has destroyed the GPU market yet again",
      "Nvidia are hurting only themselves. It would have been incredible as a $199 4050, since it literally is the 4050 using AD107. But instead they decided to call it the 4060 and now it looks way less impressive. They are hurting their brand and 40 series lineup by incorrectly naming certain gpus.",
      "They're not hurting, they're doing great as mentioned in the video. NVIDIA doesn't care about gaming anymore. They are selling AI cards like crazy at huge profit margins. They don't want to waste their precious wafers on gaming GPU's. So all you get is scraps, and a handful of high-end cards priced into the stratosphere. Welcome to modern PC gaming.",
      "It's never looked odd to me personally, but it is concerning that developers seem to be relying on it to hit decent framerates these days as opposed to making sure the base game runs well. I'm fine using DLSS, but it should be a *boost* to already good performance rather than a crutch.",
      "It doesn't matter if they do because the bus is too small.\n\nPeople are going to be shocked when the 4060ti 16GB chokes on 1440p still.",
      "I like to know that my graphics card has some sort of future proofing with this tech, but if I need it \\*now\\* in order to play those big games in stable high fps then it just has no future at all, dead on arrival",
      "Nice try Jensen",
      "Theres nothing wrong with giving consumer feedback.",
      "Which seems like a poor upgrade from GTX1070.",
      "Memory limit and bus limit, I wouldn't be surprised if its just too much for it.",
      "This over reliance on DLSS is just absurd :(, can we go back to getting faster raster performance and just leave DLSS for when it’s truly needed? It should just be an extra feature not THE main feature, tbh it shouldn’t even be used to compare scores at all…",
      "I have a 4090, game at 4K and use DLSS/DLAA when available not because I need the performance but because it makes for very stable antialiasing in motion.\n\nOther antialiasing methods like SMAA tend to have shimmering artifacts in motion while MSAA is no longer supported by pretty much anything (and has those same shimmering problems anyway). Regular TAA is generally blurry while DLSS is not.\n\nIn terms of image quality I haven't been able to tell native 4K vs DLSS Quality apart and even Balanced is only a minor quality reduction you would forget while actually playing the game instead of pixel peeping. I see DLSS basically as free performance + better image quality. It's great at 4K.\n\nBut if your native res is 1080p or 1440p, DLSS performs worse because it has less pixels to work with as the target resolution.",
      "If I were looking to upgrade my 2070 super in about a years time, what card and price (used) would people suggest? 1440p, 144hz on AAA games would be the goal",
      "You should not be using any upscaling at 1080p anyway.",
      "Cool story bro."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "4060"
    ],
    "title": "NVIDIA GeForce RTX 4060 Ti rumored to feature 4352 CUDAs, 8GB memory and 220W TDP",
    "selftext": "",
    "comments": [
      "RIP mid to low end. Clearly the pandemic didn’t screw us as hard as NVIDIA and AMD will this new gen.",
      "It's actually not all that surprising and we were silly to think it wouldn't be like this. When do companies, politicians, or anyone really, give up financial gains or power that was supposed to be temporary when that period is over? They never do. You give an inch or go along with it and that's it. This is why people should always push back at overreach and the like and say \"bullshit\" whenever they're told it is only going to be temporary. People never should have played the game in 2021 and early this year when it came to this dumpster fire of an industry. All it did was show these companies they could make those crazy scalper and allegedly low supply caused prices be the new normal and people would pay them. \n\nThe gpu industry needs to crash and burn.",
      "Seems a bit hard to believe it will come with 8GB. People already smash the 3060 Ti for having 8GB.",
      "The mid-low end is looking more and more terrible, this generation is either you get the high end or you just miss out and skip it completely, the value just isn't there.",
      "8GB on a card that will probably cost $800?\n\nYeah, no.",
      "8gb is the only reason I want to upgrade from my 3070.",
      "There is no way that memory configuration is correct.   As videocardz extrapolates those specs imply 288GB/s which is closer to the 3050 at 240GB/s than the 3060 at 360GBps.  Never mind the two 3060 ti configurations at 448 and 608.",
      "Feels good to see people finally embracing progress instead of parroting \"you don't need more than XYZ VRAM!\"",
      "Same. Can't tempt me with less than 12GB at this point, preferably 16.",
      "Plus people could stop being idiots and stop feeling as if they need to buy every shiny new product put in front of them. I buy a GPU and plan on running that beast till it's not up for the job anymore. My last decade of GPUs are below\n\nGTX 760\nGTX 1080\nRTX 3070\n\nThe 40 series can suck my nuts. What I've got now is more than enough for 1440p and it will remain. See you guys when the 60 series launches. Other than that I'm not interested.",
      "Nvidia low and mid end cards are horrible.",
      "But the chip physically supports up to 128bit bus. At 18Gbps, indeed 288gb of bandwidth.",
      "There is no logic behind a 4060 Ti costing that much. The 3060 ti was almost the best value card at $400.",
      "One theory that I have for why nvidia crippled their cheaper cards like this is the prosumer market. For davinci resolve or even machine learning you don't need the fastest GPU but you need VRAM. 3060 for example has been doing well even though it is really poor value for gaming, it is a good value for a workstation. Plenty machine learning papers were done on  1080Ti for example in my experience and this card is pretty similar if not better. It's great for a lot of people and what they do and easily accessible to buy. That's why they decided to nerf it with 8GB variant lol.\n\nI just don't think you are going to get 12GB or similar from nvidia on this class of card any time soon. It will cannibalize their other much more expensive cards.",
      "\"4060 Ti\"\n\nYou mean renamed 4050 Ti",
      "This wont get anywhere close to a 3080. It's just 34 SM lol.\n\nActually I think not even the rumoured 4070 with 46 will match a 3080.",
      "Hello stagnation. This generation is going to be a wash for everything under a 4090.",
      "Yeah, i hate that argument, my 3070 8gb was vram bottlenecking at 1440p ultra settings+ RT in some games aiming fpr 60fps.",
      "Again with the fucking 8GB of VRAM, such BS for a supposed 1440p card",
      "The 4090 is basically the perfect card in every single way, except price.\n\nHoly fuck. It costs the same as a ~~decent~~ cheap used car.\n\nThere is no way I am paying so much for a GPU.\n\nEdit: Some people seemed to have taken great objection to the phrase \"decent\". All I can say is that that's a subjective measure. It costs as much as *many* functional used cars."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "4060"
    ],
    "title": "NVIDIA GeForce RTX 4060 Ti drops €20 below MSRP in Germany, just four hours after launch - VideoCardz.com",
    "selftext": "",
    "comments": [
      "You can rip off the 4k bozos with your $1000+ GPU's but we 1080p gamers are to poor to play your price gouging game 🤡",
      "Still too expensive. Needs to drop 30% off MSRP.",
      "I wouldn't pay more that 250€ for this card. As it is now I'll probably keep my 2080s for a couple of years. No shame in lowering settings. Behind closed doors Nvidia is probably laughing about the people who are willing to pay 400€ for a XX50 card just because of the renaming.",
      "Soo.... fake confidence isn't the key to anything",
      "Pls dont buy this trash guys lets show nvidia our satisfaction with our wallets. I am not giving money to mafia anymore",
      ">obsolete\n\nJust because something better comes out does not make your card obsolete......",
      "You mean the new 4030?",
      "In a more sane world, this would be like a $250 card no?",
      "As it should, the whole stack needs renaming down a tier at the very least.\n\nNvidia can go f\\*ck itself. As a contained line-up, it looks decent enough. When you start to compare the pricing structure and VRAM uplift to previous generations, it's genuinely disgusting. It's like Intel back when they gave you a 4 core i7 as a flagship CPU for 5+ generations in a row. They had the technology, but leaked it out slowly to keep the gravy train rolling in, hugely harming technological progress and fleecing consumers.\n\nI bought my 770 for $300, my 970 for $300 and my 1070 for $350. My 7 year old, 2016, non flagship GPU marketed for 1440p with 8GB VRAM cost $350. Nvidia releasing a 2023 card marketed for 1080p 3 generations later with 8GB VRAM for $400 is nuts. Absolutely nuts, you'd have to be crazy and poorly informed to even entertain this offering.\n\nEvery time you buy an Nvidia card going forwards, you're telling them that it's okay. \"Please can I have some more pain Master Jensen, please keep bending me over year after year.\"",
      "Should drop 50%",
      "Not only is this launch an embarrassment but so is that pathetic price drop.",
      "Let's not overreact, it is a pretty good 4050",
      "Here in Australia, the 4060ti 8gb was supposed to retail for $605AUD...stores are trying to charge $729AUD.  Good luck trying to move stock, especially when 4070's are already discounted to only $200 more.\n\nUpdate:  *Day 1 of launch, and already some retailers have started dropping their prices to $599-649.  Ouch!*",
      "If it was 12-16gb i would buy instantly. Im on a 9 year old near dead 760 and need something. Site prices seem to not understand crypto days are over.\n\nAt least the 6700 xt i way looking at just dropped £30 to 350 thanks to 4060s release 😂",
      "The whole generation would have been fine if they didn't price everything up 1 tier.",
      "Jensen is too buying laughing at how much money he’s getting from AI datacenter demand to care about gaming GPUs.\n\nTheir stock just shot up 26% afterhours on AI driven earnings.\n\nThey’re forecasting an all time high for revenue in Q2 selling those pricey datacenter GPUs",
      "Eh........ you don't want this card at all. Don't worry about the price dropping. It's shit now, it'll always be shit.",
      "Meanwhile, their gaming revenue is up 22%, and stock prices up 25%. Tech influencers and tabloid sites will pick whatever they want to drive engagement.",
      "Don't do it! 8GB regret will hit hard...",
      "now lower 100€ more, add diablo code and i still not gonna buy."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "4060"
    ],
    "title": "Nvidia RTX 4060 Ti GPUs are in short supply and not because of demand",
    "selftext": "",
    "comments": [
      "They're dropping price significantly here in Canada",
      "Probably cause the card is such a shit card. Retailers are trying to get rid of the pos.",
      "Nvidia does NOT care about you if you are in the market for a low end GPU. They would rather have you subscribe to Geforce NOW instead. More profit for them.",
      "No wonder - no other card has fallen in price like 4060 Ti here - cheapest one is now here around €350 (and that includes 20% VAT/sales tax) - so the price is around $300-$310 before sales tax.",
      "I was surprised that they did a Turing-style Super refresh but didn't include the 4060 and 4060 Ti, since those were the models most in need of the Super treatment.",
      "The price for 4060 Ti 16GB is just too terrible.",
      "with a 2080 super i would wait for the 5000 series or go with at least the 4070 (super)",
      "You could remove \"Nvidia\" and place \"AMD\" or anyone you want in that first line. When did people start thinking any corporate \"cares\" about them? Your statement should be common sense yet sadly people still need to be reminded that companies only do things to profit.... all of them.",
      "it is not a shit card, that is mantra repeated in reddit since the card was released, the problem with the card was the original pricing which it was really bad, this card should be priced at 300$",
      "This is a pcgamesn article, regurgitating VideoCardz rumormill about reduced chip supply for the 4060 series, but stock seems fine in the USA right now on all online retailers so...its not in short supply.\n\nShort supply would mean its running out of stock right now. \n\nThis article talks about how future stock could be significantly reduced based on the rumor that there's a shortage of chips for the 4060 series, whos rumor source is a forum.\n\nIt's kind of a \"whatever\" news article, other than the blatant sky is falling type reposting behavior from pcgamesn.",
      "As someone who hasn't bought an AMD GPU in nearly 20 years: If that's the case then a budget buyer might as well just get an AMD card then. \n\nRT and DLSS 3 are pretty much pointless on 8GB GPUs, so the edge clearly goes to the AMD cards if you want bang for buck. \n\nEven DLSS 2 is pretty flakey on desktops at 1080p native. Personally I don't consider Upscaling worth it on a visual level until you start getting into 1440p quality modes. Blood from a stone, and all, and sub 1080p render res you don't leave a lot of detail on the floor for the  upscalers to work with. \n\nThen, you add used purchases into the equation and a budget builder has very little reason to throw money at Jensen's folly with his 450-500$ low end cards. \n\nPersonally, I wouldn't be shocked if NV eventually stops selling low end cards outside of OEM and laptop boards. The margins they want just aren't there anymore. My guess is they start doing APUs or telling people to buy geforce now at the 400$ and less price range for a discreet card.",
      "I have 2080 Super and it is basically same with 3060 ti and 4060 ti when it comes to performance except for re-bar support. Hold onto it, it’s a good card still unless you’re on 4K.",
      "Would going from 2080 super to 4060ti be worth if i get it for dirt cheap? Or is it just flat out a worse card",
      "Waiting for 5000 series as a 2080 Super owner, yep! Been struggling in new games at 4K although DLSS has extended my card's life by *a lot*.",
      "You couldn't have said it better. If you can't afford a 4070, then you should not be buying an Nvidia 40 series Gpu. Go AMD or Go used.",
      "The 3070 was just that much of a leap lol, Nvidia can’t have two hits in a roll these days",
      "You’re comparing a $300 card to a potentially $800-$900 card and calling it a bad purchase lmao.",
      "It will 100% be more than $1000.",
      "7900XT(X) exists.",
      "Have you actually tried the card or are you one of the many brainless haters who just watch a tech review on YouTube and base your opinion on that? Because I’ve actually used the 4060 and  at 1080p-1440p I could play any modern game at maxed out setting at 60 fps or close to it. You people, I swear…"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "4060"
    ],
    "title": "Nvidia GeForce RTX 4060 Ti Review: The Disappointment Is Real",
    "selftext": "",
    "comments": [
      "When the 5060 Ti launches for 900 dollars in 2026 and offers 3080 (10gig) performance, be ready",
      "Never thought I'd see Digital foundry give a negative review to an Nvidia product yet here we are lol\n\n&#x200B;\n\nI guess the card really sucks",
      "AMD will roast nvidia on social media for 64 bit bus and inevitable 8gb memory again for $450, then launch their card also with 64 bit bus, 8gb memory, 10% slower raster, 20% slower ray tracing all for $425 that goes down to $399 after two weeks and $349 within 4-6 months. Meanwhile nvidia founder cards won’t exist, partner cards will be $500 and up.\n\nIndustry is a joke lol",
      "they werent over the moon with any gpu outside 4090 .",
      "You probably don't watch enough DF then, they criticize NVIDIA for a lot of things. It's DLSS that they really like as its proven to be the best upscaler and better than native a lot of the times these days as everything has moved to TAA. Dare I say they are much more neutral than the rest of the youtubers? Instead of focusing on hate or the atmosphere of the room, they look at the tech.",
      "People forget that:\n\n1. Not everyone is upgrading from the previous gen, so they don't care about gen over gen.\n2. Some people have really old cards. They are forced to upgrade, and rather spend money on something new or familiar, than buying something old or used.\n\nThe bottom line is that people buying GPU come from all different places and walks of life, and have different reasons for buying. And the vast majority don't watch these videos or look for enthusiast discussions to make their decisions. Budget always comes first.",
      "4070 has low sales. Stuck in middle. $600 for 12GB is asking a lot.\n\nNot faster than 3080, so only good upgrade for 20xx or older owners.\n\nBut certainly much easier pill to swallow than $800 12GB 4070ti.\n\nIts been SUPER OBVIOUS since day1 - nVidia making room for \"SUPER\" 40xx models in 2024.\n\nnVidia message today. 12GB is enough!\n\nnVidia in 2024 with 4070ti 16GB.. heyy.. look.. its amazing.. its 16GB!!",
      "Then come here and downvote everyone.\n\n8GB regret will hit hard!\n\nIt's just something people need to experience 1st hand.",
      "Nvidia, it's time for a 4060 TiTi",
      "As someone that buy a nvidia 3060 12gb less than a month, I must say that I'm happy.",
      "People will buy anything with nvidia on the side of the box. The 1660 was ridiculed mercilessly for being a pile of hot garbage in reviews and right now it’s the most popular gpu according to steam hardware survey. All people seem to care about is price point and the nvidia logo these days. Nvidia can literally put a banana peal with rtx painted on the side of the box and as long as it’s $300 people will buy it",
      "did userbenchmark still rank this faster than the 7900xtx?",
      "And what exactly was the issue that DF caused?",
      "That game would of course, be GOLLUM 2! Since everyone love the first game so much.",
      "Card exists in a lineup slot that targeted 1440p last gen and now targets 1080p.  Card is not appreciably better than the 3060 Ti at 1440p outside of RT workloads. The card is regressive at 4k. It's not really a good feeling. And that's before talking VRAM.  \n\n\nFor the kind of consumer most likely to buy this card, it verges on being a 3060 Ti with lower power consumption and DLSS3 and AV1 encoding. The power consumption could be good depending on where you live, sure. But DLSS3/AV1 aren't particularly good value adds, since DLSS3's value is highly dependent on what games you play, and AV1 encoding is only notable right now if you stream to youtube. So a few years after the 3060 Ti's release, you can buy... a 3060 Ti Super. For the same price.",
      "With 6 Gigs!! For only 300$$$\n\nAnd will feature DLSS4 that makes 2 fake frames every 1 real frame",
      "it's actually insane how amd is getting all these free passes and they still fuck it up, the only one on track is intel now lol",
      "It's insane how anyone thinks AMD is going to \"save gamers\" when history has only shown they're more than willing to play second fiddle.",
      "I’ve grown to hate the word shill because of people like this. People act like they aren’t allowed to have an opinion.",
      "Sadly, some probably will."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "4060"
    ],
    "title": "[HWUB] Laughably Bad at $400: Nvidia GeForce RTX 4060 Ti Review",
    "selftext": "",
    "comments": [
      "b-but the l2 cache! NVidia even put an article out!\n\n....somehow still manages to lose to the 3060ti in some scenarios... at even 1080p. Embarassing. This is one of the worst product launches I've seen from Nvidia.",
      "Lmfao. $400/$500 for this dog shit.",
      "The \"Ti\" literally means Tiny Improvement on a whole new level",
      "Is this supposed to be a 4050 ti?  Weird.",
      "That article was obvious preemptive spin.  They knew the card was a piece of trash and they were going to get hammered in reviews.",
      "Rebranded 4050ti…\n\nCrazy to be tied to a 3060ti wtf",
      "This generation of GPU's is so pathetic, it's genuinely sad.",
      "* Gamers mostly own 8 GB GPUs\n* That means game devs are forced to optimise for 8 GB cards\n* That means we can keep releasing 8 GB cards\n* go back to the first line\n\nWhat an amazing justification from Nvidia. Truly genius",
      "It should be\n\nFor like $299\n\n&nbsp;\n\nThe only selling feature is the frame generation over the 3060ti",
      "But but the AI features that all the fan boys were pushing was suppose to make up for any shortcomings. \n\nWe need to stop falling for all these shiny new AI “features” and start pushing NVD on the right path again and have them refocus on making good hardware chips with good efficiency. I don’t like the current path they’re on by going all in on AI. \n\nFuture cards will have less VRAM and less performance cores but more AI gimmicks to make up for it.",
      "Listen, it's simple; nVidia lowered the core count, increased the prices and used marketing with DLSS 3 to make them seem faster than what they really are, dispite the negative drawbacks which will cause gamers not to enable it. Not to mention, with DLSS disabled, the supposed new cards, are just as fast as cards now 2-3 generations old, for one hell of a price increase, it's beyond pathetic.\n\nImagine an nVidia, that did the opposite, increased core count, lowered cost (as sure as hell, they saved on costs) how well these cards would be received and flying of the shelves.\n\nNo sane person that manages his finances like being screwed nVidia, it's just too bad, there are too many that didn't care or don't need to care.  Either way, you misread the market at large. Miners are not your mainstream customers anymore, for too long you sucked on their teets and those days are over.",
      "> The only selling feature is the frame generation over the 3060ti\n\nMaybe, but for example in Cyberpunk 2077, Frame Generation uses around 0.7-0.8 GB VRAM at 1080p and ~1.5GB at 4k. There's a lot of games sitting right at 8GB VRAM limit right now, which doesn't look good for the new feature.",
      "Yikes. It even lost to the 3060 Ti in one of their tests at 1080p, otherwise mostly tied with it.\n\nLooking on the bright side; the power consumption is amazingly low. And if you truly believe in the power of DLSS3 frame generation, and you mostly play the miniscule number of games which support it, it's probably still a decent step forward from Ampere. That's not a big selling point to me because the games I play the most do not have DLSS3 support.\n\nIMO this should have had 16 GB VRAM at this $400 price point. Not that it would solve everything, but it would help.\n\nBut I think that would have made the specs of the 4070 look even worse than it does now, so they didn't go for it.",
      "I admit I expected way more from the cache, and I didn't even read the article.",
      "You misunderstood. It's more cash to buy one.",
      "It's worse than 3060ti in more than one game at 1080p. How is that even possible. How do you sell a product this bad with a straight face?",
      "Imo it's a fucking 4050 TI and shouldn't have been more than $200",
      "Except they’re not.  Game developers are fed up with the VRAM stagnation from NVIDIA and they view the PS5 as the base platform.  Games will still work on 8 GB VRAM cards but they will likely have to use lower quality textures, particularity at 1440p or higher.  Both RT and frame generation increase VRAM demands, which may make it unusable at 1440p.  \n\nAs we saw with TLOU, in particular, on release it required Medium textures, which looked terrible.  After more than a month of patches, they completely reworked the textures so that Medium textures look much better, and High textures are now useable at 1440p with an 8 GB GPU (these are the textures used by the PS5).  We saw something similar with Hogwarts Legacy. \n\nI think we are likely to continue seeing 8 GB cards deprioritized in terms of the quality of the textures.  They may improve with future patches, but the day-1 experience is likely to be pretty bad.  However, games are coming out with lots of issues at release.  VRAM is hardly the only issue.",
      "How in God’s name can it be worse than a 3070? The 3060Ti was on par with the 3070 which was on par with the 2080Ti. So the 4060Ti should be at least as good as the 3080, if not better.",
      "The problem is there's no real way for cache to genuinely make up for a slow bus or limited memory at the next level.  It can potentially improve the average case, but you still have to account for the worst case scenario of cache misses, and those are going to be slow across that terrible bus, and are going to be horrendous if there's a VRAM cache miss as well and it has to go to system memory.\n\nGood - we added more cache on top of an already strong base architecture, look at this improved performance in common scenarios\n\nShitty - we cheaped out on every damned thing, but are trying to hide it by using more cache to bring 90% of calls back on par while ignoring the other 10%"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "4060"
    ],
    "title": "NVIDIA not seeding GeForce RTX 4060 Ti 16GB for reviews, AIBs hesitant to participate as well - VideoCardz.com",
    "selftext": "",
    "comments": [
      "It’s always the sign of great confidence in a product when the producer doesn’t want reviewers to get their hands on it early.",
      "Even the creator thinks they made shit.",
      "Everyone already knows precisely what the reviews will say, because this card isn't actually any different than the 4060ti 8gb, it just had more VRAM.\n\nFor $500 it's laughably overpriced to the point where I struggle to imagine any scenario where purchasing it makes sense. Given that the 4060ti is already not selling well and reviewers were unkind to it, I'm not shocked that Nvidia doesn't want to facilitate the process of having 10 huge techtubers say \"My god, Jensen's really on one today boys. Don't buy this trash!\"",
      "Great confidence that its garbage",
      "It's a nice card, it's just that it's a nice card for 200 bucks; not 400.",
      "good, don't send e-waste, save the environment",
      "$500 for the 16GB",
      "One of the comments on videocardz pretty much nailed it.\n\nIt will be exactly the same as a normal 4060ti except in the Last of Us and maybe 1-2 other games where either textures don't load properly or performance jumps off a cliff at 8GB. \n\n\nhttps://uploads.disquscdn.com/images/ddc8aecd3984b008a09f587c2583a1841ecc02949915264b8995b3e2806dcf56.png\n\nAll specs are the same including the memory speed and nothing else had horrible 1% low fps that made it stand out as a VRAM issue.",
      ":ThrowsUpInMouth:",
      "Ofc they are hesitant. \nHAVE YOU SEEN WHAT STEVE HAD TO SAY ABOUT THE 4060ti",
      "It will be sold in bulk for a discount to system integrators, who will put them in overpriced pre-builts. Maybe a few direct sales to suckers but few and far between while it’s priced at $500. If the price dips to around 350 it may be a different story.",
      "The 4000 series is a repeat of the 2000 series. Overpriced due to being released at the tail end of a cryptomining bubble that was overheating the market. Hopefully the 5000 series will be a repeat of the 3000 series, but without cryptominers to fuck it up this time. Who knows, maybe it'll be an LLM/AI VC bubble instead, but maybe not since that's not \"guaranteed\" returns for doing zero actual work, so it won't attract as many of the get-rich-quick types.",
      "It's amazing to see how great the 3000 series was received as being similar to the 1000 series with the 3080 being the holy grail after the 1080ti only to see Nvidia make absolute garbage decisions for the regular consumer two years later with the 4000 series.\nThey don't care about the regular buyer anymore, just massive companies buying their insane ai machines and server applications",
      "Remember when the flagship cards started at $500?",
      "How hard can it be just to make a decent product at a decent fucking price.",
      "Thanks Steve",
      "Hot garbage smells the worst *sniffs* is that a 4090 connector I smell?",
      "4060 Ti 16GB is launching at $500, not $400, making it even worse. I'd say it would be a good buy at about $360, but not $500. The 8GB version though, no more than $275 imo. 8 GB is gonna be too little for even low settings by 2027.",
      "They will get major discounts buying direct, in bulk. The card may cost $500 retail but if there are a bunch of unsold cards after a few months they may be able to buy a thousand of them for $325 each. Those types of sales are done in contracts that have clauses where the price can’t be disclosed. Because Nvidia/AIB partners wants to move unsold units but don’t want the public downward pressure on prices for retail.",
      "When they can make 10x per wafer in AI?"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "4060"
    ],
    "title": "GeForce RTX 4060 & RTX 4060 Ti Announced: Available From May 24th, Starting At $299",
    "selftext": "",
    "comments": [
      "4060 ti 8gb is DOA in my opinion. It's insane that Nvidia tries to sell an 8gb card for $400 in 2023",
      "So a 16gb 3070 2 years after at the same price? Ykes..yeah don't tell me frame generation cause it's on single digit games.",
      "The 16GB at $100 more is quite a ripoff, the cost of the VRAM is not that high. $50 would be much more fair.",
      "According to 3DCenter ,\n\n4060 is  +18.0%  faster than 3060-12G\n\n4060Ti-8G is  +13.3%  faster than 3060Ti\n\n4060Ti-16G is  +13.4%  faster than 3060Ti",
      "Lack of competition in a nutshell. Remember how Intel kept us on 4 cores for like 10 years because AMD CPU's were terrible until Zen/Ryzen came along? Same thing is happening now. I don't care what people say about Radeon, but NVIDIA totally dominates the GPU market with Radeon barely getting its foot in the door in terms of marketshare. Their revenues are also nothing like that of NVIDIA, and you just get the general feeling that AMD sees Radeon dedicated GPU's as a \"not really worth it\" side-project compared to their CPU and console divisions which sell like hotcakes. It costs them too much money to develop the dedicated cards but the sales are very low. They'd rather just make more CPU's which are pretty much guaranteed to sell through.",
      "4060 is $299\n\n4060 Ti 8GB is $399\n\n4060 Ti 16GB is $499",
      "That's...sad.",
      "Shittiest performance jump I've ever seen. Without FG, the gap in performance between the 3060ti and 4060ti looks terrible compared to the jump in performance between the 2060 SUPER and 3060ti.\n\nEdit:\n\n4060=3060 + 20%\n\n4060ti= 3060ti + 16%\n\n4070= 3070 + 31%\n\n4070ti= 3070ti + 42%\n\n4080= 3080 + 49%\n\n4090= 3090 + 63%",
      "4070 Ti 12GB performs between 3090 and 3090 Ti\n\n4060 Ti 16GB looks to perform like a 3070 based on the charts they provided.\n\n4060 Ti 16GB is a **downgrade** vs 4070 Ti 12GB.",
      "299 ?",
      "They should scrap the 8gb 4060ti and lower the price of the 16gb 4060ti to $399 if they want people to consider buying it. While I still won't buy an 8GB card no matter the price, the 4060 is a better deal than amd's upcoming competitor the RX 7600.",
      "Nvidia knows who the real target demographic of these 16GB cards will be and it ain't gamers.\n\nIf you need 16GB VRAM for certain workloads, the next step would be $1200 MSRP (well, now a bit lower since some time has passed) RTX 4080.\n\nYou could also risk it and buy a used RTX 3090/3090ti but that will come with almost no warranty and more performance than a 4060ti, but also insane power draw by comparison.\n\nThere are people who will gladly get the 4060ti 16GB instead as that saves them a lot of money.",
      "Looks like it slots in the middle of 3060 and 3060ti, ~10% slower than 3060ti",
      "Is 4060 8 GB as well?",
      "This generation is hilarious. Only power draw and temperatures are impressive.",
      "Releasing the 4060ti 8gb first is a dick move. They want to see how the market will react to 8gb card lmaoooooooooooooo.\n\n\n\nIf they both released at the same time nobody is buying this shit.",
      ">4060 is  +18.0%  faster than 3060-12G\n\nHolly shit, it might actually not beat my 2080, a 2 gen old card renowned for how shit it was at launch.",
      "Yeah it is",
      "How does the 4060 compare to the 3060 Ti? Surely it can't be slower than the next tier of the previous card gen?...",
      "The 4060 is slower than the 3060ti"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "4060"
    ],
    "title": "NVIDIA GeForce RTX 4060 reportedly consumes more power than RTX 3070 (220W) - VideoCardz.com",
    "selftext": "",
    "comments": [
      "Have they seen the cost of energy. Hard pass from me if so.",
      "Nevermind the cost of energy, the heat output in the summer would be actually painful. Looks nervously at 260w gpu...",
      "Everybody here taking this as no-question gospel, even though this person's claims have been wild and all over the place.  According to them, the 4090 will be released next month.  Cant take them seriously.",
      "My 3090 in my upstairs office in central Texas is already a poor choice",
      "seems they just want to push as much power as possible through smallest arount of silicon/die area to maximise profit margin and to hell with energy efficiency\n\nvery greedy will sooner pickup a series x then get a gpu that throws money(energy) and card lifespan away pushing max watts and heat, and forces me building more expensive and noisy case/system like a wind tunnel to deal with stupid heat output.",
      "My 3070 and the ac are always fighting to see who will win the 3070 comes on top and th rest of the house is like super cool and my room is sauna",
      "So you two are why Texas has the power outages lol",
      "No offense, but it gets frustrating to see people have no idea what the term efficient means as if they never had physics in school.\n\nThe RTX 4xxx series is obviously going to more more efficient than the RTX 3xxx cards, I can't believe I am even writing this. This would be the case even if the architecture would remain, simply due to the new process node. But the arch will obviously bring two years worth of improvements aswell.\n\nThe fact that NVIDIA releases higher and higher TDP configurations for certain price points is disappointing, but has literally nothing to do with the efficiency.",
      "Austin 3090 crew checking in. Here come the triple digit days with no end in sight.",
      "Undervolt or limit the power draw.\n\nEspecially undervolting pushes the power draw down.\n\nMy lowest undervolt for my 3080 is 750mv 1700mhz. It's uses roundabout half the power than stock 320w while it performance not even 10% below stock with 370w.\n\nI mainly use a different undervolt, but that one shows how far you can go.",
      "I probably would rather stick with my current 3070 if the rumoured 300W - 400W becomes the truth for 4070, i couldn't even imagine how much i am going to handle that much heat in my room that already averages at 30c ambient temp, curse of living in a hot tropical country and no AC.",
      "Why would you upgrade after one gen?..",
      "They leaked obscenely high prices for the 30X0 cards before the official announcement. Everyone here knew what they were doing. Granted with the supply chain constraints those obscenely high numbers looked like a bargain.",
      "Their cards have always been pushing past the point of diminishing returns - even when they had lower power consumption than AMD's cards. \n\nSo what's really going on is that they're inflating the difference between the generations. Like when the 2060 had a bigger GPU than a 1070. Same with this \"4060\" - if they called it a 4070, the progress from the 3070 wouldn't look impressive.",
      "I helped, but undervolted my 3080 so Abbot could get his crypto farm up and running",
      "Nah, Texas shitty privatized power grid is to blame 🥴",
      "We know but the jokes help us forget about that 😅",
      "I'm pretty sure perf/W has *never* gone down from gen-to-gen. In the case of Turing > Ampere, the perf/W gains were very small or even trivial depending on which SKUs you compare, but it was still technically an improvement. Once you compare both architectures at a more reasonable voltage, Ampere pulls further ahead in perf/W; as opposed to comparing them stock-to-stock, where they have almost the same perf/W, suggesting Ampere is tuned more aggressively out of the box than Turing so as to cancel out most of the efficiency gains of TSMC 12 > Samsung 8. I think seeing Ada running at lower voltages is going to be illuminating because I refuse to believe that the perf/W potential of Samsung 8 > TSMC 5 is anything short of significant. By all accounts Samsung 8 is a fairly crummy process (even for its era/technical specs) while TSMC N5 is, expectedly for TSMC, a great quality process. If Ada doesn't have a *substantial* perf/W improvement over Ampere when comparing both architectures at reigned in voltages, you'd have to wonder what went wrong in the engineering department.",
      "Do that 20 more years and the lowest end card will be 1000w",
      "Simply don't buy, that's the only way to force lower power draw for next gen. \n\nNvidia is making GPUs based on statistics, they have now a statistic that there was and is big demand for GPUs that are very powerful and around 300W, so they will target exactly that + try to push that power limit even higher as it is more profitable for them to boost up the clocks than increase silicon amount."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "4060"
    ],
    "title": "Breaking Nvidia's GeForce RTX 4060 Ti, 8GB GPUs Holding Back The Industry",
    "selftext": "",
    "comments": [
      "How many videos do you want to make about this topic?\n\nHUB: yes",
      "Naming a 4050 a 4060 doesnt make it work like one? Damn, Jensen almost had a good plan there.",
      "Wow. Those comparisons are absolutely brutal. Nvidia should be ashamed of a brand new $400 GPU performing like this, just because they were too cheap to give it at the VERY least 12 GB of VRAM",
      "They have over a Million subs. If you want to see higher Vram on the 60 tier from Nvidia, it will take a lot of noise to make them even think about doing it. We need more large channels to over-push this as well.",
      "8GB cards in mainstream are damaging to gaming industry. HWU and other content creators should release more of these videos.",
      "xx50 performance/vram, xx60 naming and xx70 pricing. Gotta love it",
      "Don't forget pricing it like a 70 tier card as well!",
      "I'm happy he's pointing out insufficient VRAM causing some games to lower textures as some people love to copy paste the same charts comparing 16gb vs 8gb 4060ti which says they're mostly the same on average fps but doesn't say anything about texture quality.",
      "Until tech illiterate people on Reddit stop saying otherwise.",
      "Both are bad for the industry. I'd appreciate if my card had 12gb of vram",
      "I feel like you should be able to use a 400-500$ GPU at 1440p comfortably tbh. Also the GPU being capable of 1440p gaming but only being crippled by the vram buffer does leave a sour taste in the owners mouth",
      "3060 has 12GB VRAM, 4060(ti) holds back the industry by downgrading VRAM on the same tier of card. no sane consumer who did their research is going to spend over $400 on a GPU that has the same performance as a last gen GPU and less VRAM.",
      "8GB is a joke of course, 12GB for 1440p in 2024 should be the norm\n\nHowever ’holding back’: Per steam survey, most people are on rtx 3060 and stuffs like that, for a 4060 to hold back the industry you’d need far more people to actually purchase it..",
      "For that price, then it should be 1440p capable",
      "The combination of the  half pcie lanes and 8gb  is painful.  Feel sorry for people throwing a 60 class card in an old PC and not doing the research . Even then no one really highlights the issue as most people test on modern hardware  so it doesn't impact performance. Rumour say the 5060 would be better. Just unfortune for people buying this generation on an old platform.",
      "Look man, those leather jackets don't pay for themselves.",
      ">You don't need 12GB of VRAM\n\nUntil you do.  It's always a race how much raw fidelity can publishers shit out into their games which literally compromises everything about a game in favor of raw graphics.  The only stopgap is consoles which are the lowest common denominator that they set the graphical optimization bar for.\n\nThe moment that's gone though 8gb of RAM will quickly languish.  For a modern 400-500$ GPU that's fucking trash longevity, especially with 128 bandwidth.",
      "He did because so many people still buy them, and many pre builds that are also bought commonly have them. I'd bet it outsold the 7700XT by multiples sadly.",
      "Sure, but the 126 bit bus was a design choice. They could have used a different configuration, wouldn't even have cost them more than a pittance. \n\n\nStill l, pretty hilariously bad for a mid range card to have only 8gb in 2024. \n\n\nSometimes you don't even get what you pay for.",
      "Or that's how consumer advocacy works. Amazing how much Redditor's hate other people advocating for them as consumers."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "4060"
    ],
    "title": "NVIDIA GeForce RTX 3060 ownership approaches 7% among Steam users, RTX 4060 gaining ground as well - VideoCardz.com",
    "selftext": "",
    "comments": [
      "Not surprising. Reading echo chambers like this sub or something like PCMR you'd think everyone is rocking 4070+ and plays in 2K/4K while reality is way different. \n\nBoth GPUs are budget, both do fine in 1080p and 2K to an extent in modern games.",
      "Reddit is mainly americans and western europeans. For the rest of the world GPU's are prohibitively expensive. So it's a bit of a privilege echo chamber.",
      "Remember that the 3060 has roughly the same rasterization performance as a 1080 Ti!",
      "YouTube comments would make you believe AMD has a 90% market share in both CPU and GPU with the way they talk 😂",
      "What is more insane is the fact that there are more 4090 users than ANY AMD GPU, yet, the minority is really loud online.\n\nThis really proves how stained amd gpus are, literally all my friends that went for Radeon 7000 gpu ended up returning them and going back to nvidia, plus, the public image of 90% the people i know talk shit about them, too many headcahes to justify a few couple dolars less.",
      "This will undoubtedly shock all the nerds on this sub who think that everyone's rocking a 4k display with a $1,000+ GPU 🙄  \n\n\nMost folks are still playing at 1080p on high settings, just like they were 10-15 years ago.",
      "The xx60's have always been the most popular. \n\nThe 4060s low power draw and feature set make it the best midrange card on the market.",
      "Yeah, always fun to read comments on videos with AMD Nvidia GPU comparisons.\n\nFor a company that has less than 15% market share on their GPUs, according to Steam HW stats, AMD userbase is quite vocal I'll give them that :)",
      "It's because the Nvidia user base is busy actually playing games instead of complaining about poor optimization whenever a new game launches with a mediocre FSR2 implementation and RT eating up 70% of the performance of AMD cards.\n\n/s",
      "lol 4070+ its like 7900xtx or 4080+ around here. any mention of 4070s is like a riot by AMD fanbois",
      "Hey my 1080 ti is stuck chugging along, no smoke yet.",
      "Yup the main problem is price and how there was hardly any improvement. The criticisms are justified.",
      "dont forget canadians",
      "Based on reddit in general, you'd think AMD has an 80% market share.",
      "Iam rocking a 1000$ GPU, 3060 from late 2021😅",
      "4090 owners couldn’t be bothered to turn on their PC to submit results for the survey after they finished building it and posting it on reddit",
      "RX 5700 XT user here, just replaced it  2 days ago for a 3060ti because I was sick of faulty AMD drivers that rebooted my pc randomly.\n\nSo far so good with the 3060ti, 0 crashes.",
      "Recent AMD convert here, got a deal for a 6800XT. Literally 0 complaints about the card, drivers, or anything else. Runs pretty much every game I throw at it with no fuzz. Remember, this is an NVIDIA subreddit, some bias here.",
      "The 4060 can run practically anything on ultra 1080p + DLSS",
      "I am not sure if this comment is ironic or not, but here we go: \nEven if the % of RTX 4090 owner may decrease, this does not mean, that the total amount of RTX 4090 owner is decreasing as well. I am sure it is even increasing as new people buy more 4090. \n\nBut if more people are opting to buy other cards than the 4090 than they were before, than we have a decrease in the percentage of RTX 4090 owner while the total amount of RTX 4090 keeps increasing. \n\nE.g. \nFebruary 2024: 1x4090 vs 9 others GPU bought ( RTX 4090 -> 10% share) \nMarch 2024: 2x4090 vs 28 other GPUs (RTX 4090 -> 6.66% share)"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "4060"
    ],
    "title": "RTX 4060 vs RTX 3060 12GB GPU faceoff: New versus old mainstream GPUs compared",
    "selftext": "",
    "comments": [
      "TLDR:   \n\"The RTX 4060 easily wins this faceoff. That's sort of a no-brainer and we almost felt it wasn't even worth discussing, but there's enough talk that it's good to set the record straight...That doesn't mean you should run off and sell your RTX 3060 12GB if you have one, of course. We generally want at least a 50% boost in performance to entice us to upgrade, and preferably double the performance.\"",
      "To the surprise of absolutely no one yet some people are still hellbent on recommending 3060 over 4060 for gaming purposes when someone picks between the two because of MUH VRAM.",
      "This makes me feel a lot better, I got a prebuilt with a 4060, (I’m very new to PC gaming, very first pc) and everywhere I go it’s “3060 better rah”",
      "This sub is pretty awful for recommendations in general. The 4060 aside, you often see threads like \"hey guys I want to upgrade from Pascal and only have 300$ is 3060 okay?\" and you get people replying things like \"not it's shit, save another 300$ and buy 4070 Super\".\n\nLike... yeah I guess OP should go and get a second job or something or spend another year suffering with bad PC performance while saving those 300$.",
      "4060 is a great gpu for a first build there’s no doubt about that a lot of us started out with 1650s and 1070s and the 4060 is a lot better than those. We all gotta start somewhere, I respect your situation more than a first time pc buyer who just slaps in a 4090 in there because they have a bunch of money. It’s gonna teach you to appreciate what you have and not to be greedy , in a couple years your gonna have a much better graphics card and you will appreciate the hell out of it because you appreciated your 4060 as well",
      "imagine if you listen to reddit recommendations. seriously, feels bad for the ppl who listen this non sense and choose 3060 over 4060",
      "I always felt that nvdia’s 40 series lineip could’ve been graded down but they decided not to so as to upsell us. Like how the 4070ti could be the 4070, the 4070 the 4060, the 4060 be the 4050 and so on because if you look at generational leap that would make more sense to me at least",
      "The 3060ti has a wider bus width so there's better performance for intense scenes and at 1440p.",
      "Of course the 4060 will be better. The problem is that it should be called 4050 and be sold at 4050 prices.",
      "Helped where, at 2k/4k on max settings where neither card has playable framerates? I'm looking at the THG %1 lows table and at 1080p has the edge 100% of the time, at 2k/4k like 95% of the time. If playing TLOU in 4k max settings with 15FPS is your jam then picking 3060 makes sense I suppose.\n\nThere's no point focusing on the VRAM when chip itself is not powerful enough to make use of that VRAM in gaming scenarios. Professional workloads is another matter but even there you'd likely want to have more than 12gb of VRAM anyway.",
      "I don't understand what you're trying to argue here. You literally have FPS data in the article both with averages and 1% lows where 4060 is a clear winner.\n\nReserved VRAM =/= \"used\" VRAM.\n\nYou can slap 24gb on a 1050ti and it's never going to beat 1060 6gb in gaming. VRAM is pointless when GPU is not powerful enough to take advantage of that.",
      "I remember people were recommending the 3060ti over the 4060 at launch. The pricing was close and the 3060ti does perform better.",
      "I have been downvoted so many times for calling out this bullshit.  It’s like there is a coordinated effort to shit on the 4060s.  I get that they are overpriced based on historic relative performance but I can’t even fathom picking a 3060 over them unless it was a significant price difference.",
      "You spamming with pointless posts won't make me watch anything, thanks. If you're trying to justify your purchase of 3060 then more power to you, it's not an awful card either way.",
      "How do people find 2nd hand stuff that isnt overpriced? Ive been looking on ebay from time to time and people are trying to sell old ass cards for well above 500-700$. What a steal!",
      "Wtf I started with a voodoo 2",
      "Except when the 4060ti loses to the 3060ti in 1440p due to the narrow bus width. If you insist that it's a 1080p card then sure, at 1440p, it would far a lot better with 12gb VRAM with a wider bus.",
      "And you can go watch these comparisons too both in 1080p and QHD since you have so much free time.\n\nhttps://www.youtube.com/watch?v=n-PYkZuCGk4",
      "Just like you have reputable THG article linked in the thread that you chose to ignore. But hey, spamming with random vids and leaving a dozen of MUH VRAM posts wasn't a waste of time but replying for 11th is a waste of time of course :)",
      "You’ll learn that people who obsess over pc parts fall into two camps. Those that overcompensate for wasting money upgrading each year. And those that feel the need to “defend” their old purchase and attack those that buy the new generation in an effort to feel better about no longer having the latest and greatest. Lot of insecurities both ways"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "4060"
    ],
    "title": "Just upgraded from a 1060 6gb to a 4060 ti 16gb!!",
    "selftext": "\nAfter lots of back and forth I finally decided to upgrade my pc.\n\nI used to play games all the time and found myself recently wanting to get back to it even though none of my friends play anymore (I need more online friends but idk how lol) \n\nBeen playing hogwarts legacy now that my pc doesn’t run it like a slide show and been having a great time. This pc will also be used for cad modelling (not tried yet but vram is plenty to render well) for university and eventually a job. \n\nWell worth the money to upgrade and happy with my choice! \n\nI know this card is thoroughly hated but it was the best for my budget and has everything I want!\n",
    "comments": [
      "People hate everything, if it runs the games you want and it was within your budget then it’s a good purchase! Congrats!",
      "![gif](giphy|LpkBAUDg53FI8xLmg1|downsized)",
      "Thank you and Exactly!  Most of the hate is on the price and not the performance anyway which is what really matters",
      "Cool, people look down at XX60 cards, but when is an upgrade that big, for us is great, I went from a GTX 980 4GB to a RTX 3060 8GB and it was a huge upgrade for me, plus all that new techs like DLSS and stuff",
      "I would have thought the hate was from it being choked by a 128 bit bus",
      "just FYI in Hogwarts when you cast Revelio and hear a bell chime, it's a Field Guide page nearby. The audio is precise so you can use its location to pinpoint the page nearby. Congrats on the GPU.",
      "4060 Ti is definitely faster than 1060 you got that right 😝\n\nEveryone’s real problem with these cards is they’re selling it as a 60 Class card but with a 50 Class die and memory bus.  Then pricing it for more than 60 Class cards typically are sold for\n\nAnd to explain what I was talking about with bus width.  Bus width and memory clock speed determine your memory bandwidth.  \n\nFor example, 3060 and 4060 Ti have GDDR6 so I can compare them directly.  4060 Ti has a 660MHz higher memory clock but a 64bit narrower bus which in the end results in a 72GB/s lower memory bandwidth than 3060.\n\nNow when we compare 3060 Ti to 4060 Ti it gets even worse.  4060 Ti has a 760MHz higher clock speed but a 128bit narrower bus, which results in 160GB/s less memory bandwidth than 3060 Ti.",
      "That’s one part, even 1060 is 192bit",
      ">need more online friends but idk how\n\nJust interact with people during the course of your gaming and if you feel like you would want to play with then again add them. If you do end up hitting it off just talk regularly with them and see what other games they are interested in.\n\nI met one of my closest friends through 7 days to die and its been like 8 years now. We've both grown a bit and cant play all the time but we still talk at least twice a week",
      "3060 has ray tracing...",
      "Yeah any upgrade was going to give a huge difference. Eventually will upgrade the other parts in it but for now it’s not too shabby",
      "Congrats that’s a huge jump. Hope your loving it",
      "Gpu speed will be a hinderance before any vram restriction on this card specifically with gaming.",
      "Yeah there probably was but I didn’t fancy getting a pre owned old generation gpu. Felt more comfortable with a new gen brand new gpu",
      "How does it affect performance? is 1060 faster than 4060Ti? 🤣 (I don't think so) but seriously would like to know a technical explanation",
      "The sub Reddit hates the xx60 cards but when you check the steam hardware the whole world loves them considering 4 out of the 5 most gpus are xx60 cards.",
      "I use my card for stable diffusion, so I'm also considering the 4060ti. The truth is I really just need 16gigs without breaking the bank.\n\nMy 2070S runs just fine for now though but its tiny lil 8 gigs is hurting my sanity.",
      "I bought one for my gf and it works great!\n\nBeast at stable diffusion!",
      ">The truth is I really just need 16gigs without breaking the bank.\n\nNo joke, Intel Arc could be a good pick for that",
      "I literally said specifically when gaming"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "4060"
    ],
    "title": "Nintendo Switch emulation team at YUZU calls NVIDIA's GeForce RTX 4060 Ti a 'serious downgrade'",
    "selftext": "",
    "comments": [
      "well we all knew that this card was terrible so this is just another confirmation.",
      "Nvidia should be ashamed making 8gb cards anymore",
      "Making 8GB cards isn't inherently bad, vast majority of games will be fine with 8GB in 1080p (the most common resolution by a huge margin). The problem is 8GB at this cost; pushing $400? Unless you reaaaally want DLSS and AV1 encoding, going with a better performing, higher VRAM card at that same cost or less from either AMD or even Intel for gaming seems like a no brainer. I'm not super familiar with the needs for productivity, but I'd have to assume the 8GB doesn't cut it there and productivity users will be looking at higher tier cards anyways.",
      "It's time for Intel to show up and put AMD/nVidia in their place. If Intel can bring in 4080/7900 XT performance at a decent price (£649) like how the 3080 was priced I'd for sure upgrade.",
      "Take this award for stating the absolute fact that they're charging obscene amounts of money for AV1 and DLSS3. AMD and INTEL are no brainers at that price range this gen.",
      "They’re “very reasonable” with pricing because they’re new and they have to coerce people to try them. Intel will do the same pricing games as amd and nvidia once they gain market share.",
      "Not happening.",
      "Another win for the card that is built different, the 3060Ti. Imagine if it had 16 GB of ram, it would be the 1080Ti all over again.",
      "From the article:\n\n>   The RTX 4060 Ti 8GB with only a 128-bit wide memory bus and GDDR6 VRAM is a serious downgrade for emulation when compared to its predecessor, the 256-bit wide equipped RTX 3060 Ti. You will be getting slower performance in Switch emulation if you get the newer product. We have no choice but to advise users to stick to Ampere products if possible, or aim higher in the product stack if you have to get a 4000 series card for some reason (DLSS3 or AV1 encoding), which is clearly what NVIDIA is aiming for.",
      "It’s probably because the team would know their way around hardware and software pretty well otherwise yuzu wouldn’t be so good",
      "Yeah, or another 1060 6 GB that dominated Steam hardware lists for a long time. They don't want another 1060 or 1080Ti, they were too good for consumers. Now they force you to make a compromise somewhere and buy a new card sooner. A new and a very expensive card.",
      "Not in the 4060Ti class. They've only launched a 7600XT with 8GB and that's $130 cheaper the 4060Ti. So really not the same class. \n\nThe 7900XT has 20GB and a 7900XTX has 24GB. So my guess would be that their 4060TI equivalent will have 12GB and their 4070 equivalent will have 16GB.",
      "There are few things that redditors like more than posting things that confirm how they feel and then aggressively agreeing with each other about it.",
      "It's not the amount of VRAM that's the problem for this application, it's the 4060 Ti's 128-bit memory bus paired with GDDR6, giving only 288 ~~MB/s~~ GB/s, significantly less than even the 3060 non-Ti. A lot of the time, this is mitigated by the 4060 Ti's relatively large L2 cache but not for Yuzu.",
      "You didn't read the statement, the 4060ti is literally WORSE than the 3060ti for emulation thanks to the bus width.",
      "They are.  But the 4060ti isn't an upgrade at all from a 3060ti.   In some games, a downgrade!",
      "Not sure, Intel keep improving and they've so far been very reasonable with the pricing.",
      "I'm pretty sure most developers are AMD developers just as much as nvidia developers seeing how the Playstation and Xbox consoles run on AMD hardware and triple A games are designed with consoles in mind.",
      "NVIDIA isn't trying to win the GPU market any more. They are just keeping it on life support so they don't just give it up. They are using all resources and fab space for their AI chips, which are making them mountains of money. But they still want to still stay in the GPU game, thus, higher prices are required to justify their small supply of GPUs they are making\n\nIt's priced for supply and demand, not competition.",
      "The problem is they still have 8gb of VRAM but literally cut the bus in half which means your memory is half as fast.  Now sure you can throw some \"generational uplift\" in there for maybe 10-15% but thats still only 55-60% of the last gen.  This isn't like having half the RAM, its like going from dual channel ddr4 to single channel ddr5.  Technically you have faster memory, but the system is not going to be happy."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "4060"
    ],
    "title": "NVIDIA GeForce RTX 4060 Ti specs updated to 160W TDP, now less power than 3060 Ti - VideoCardz.com",
    "selftext": "",
    "comments": [
      "Nvidia and the VRAM...\nFor the love of god",
      "5060 ti wil have 96 bit bus at this pace",
      "8GB on a $500-$600 card yet again.",
      "tldr;\n\nRTX 4060Ti Specifications -\n\nCuda Cores - 4352\n\nMemory - 8GB G6\n\nMemory Bus - 128-bit\n\nMemory Bandwidth - 288 GB/s\n\nDefault TGP - 160W",
      "at Just $599!",
      "And its going to cost like 3070ti",
      "It’s the goal. Planned obsolescence",
      "going to perform like a 3070Ti at best.",
      "Here comes all the \"But is so efficient and faster than 3060 TI\" comments",
      "Can't believe they're trying to sell a (supposedly) 1440p class card with 8GB of VRAM. Either A) they're gonna call it a 1080p card that'll max out a high refresh monitor (similar to how they marketed the 4070Ti for 1440p high refresh), or B) they'll call it a \"budget\" 1440p60 card.\n\nConsidering the 4070Ti gets [an average of 152FPS at 1440p](https://youtu.be/1mE5aveN4Bo?t=720), the 4060Ti should be about 30% less (?) - so about 106FPS, slightly faster than a 3070Ti (this is really just a guess, FYI)\n\nBut man, 8GB of VRAM... that will not age well for 1440p down the road.",
      "8gb AHAHAHAHAHAHAHAHA",
      "He can't, because in his simple mind bigger number = better and small number = bad",
      ">most likely to be equipped with 8GB GDDR6 memory. This would also be the first desktop card from this generation not to use GDDR6X technology.\n\nWTH, 8gb and smaller bandwidth while not even on gdd6X? Why does Nvidia skimp on VRAM so much?",
      "or the bruh you get Dssl3 you can play Microsoft Flight Simulator at 300 fps!",
      "8gb? No, thanks",
      "Yeah, fuck Nvidia at this point. Absolute disgusting greed on display.",
      "Ironically, despite all the heavy 4K and RT marketing, 4070ti might be lowest model to handle 4K or RT.\n\nFor existing 3060ti and even 2060 owners.. if 4060ti is so nerfed it struggles at 1440p and cant do RT.. why would you spend $$$ for that?",
      "So it'll be a 3070Ti, but at $499 at the very best and that's if they capitulate and make the 4070 non-Ti $599 instead of $699 which would also be stupid.\n\nThe 3070Ti was horrible value at $599, so at $499 this is just trash still. Has to be $449 or under to not sit on shelves and get ridiculed like the 4070Ti and 4080.\n\nGet your 3060 Ti at $399 now because things just aren't really improving, or buy used which is honestly the best option.",
      "Got 8GB on my 1080 in 2017 for 500-600 bucks. So much for inflation, you get the same thing today!\n\n/s",
      "And it's 599. Nvidia robbing mfs in broad daylight."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "4060"
    ],
    "title": "NVIDIA GeForce RTX 4060 Ti shows up on Geekbench with 4352 CUDA cores and 8GB VRAM - VideoCardz.com",
    "selftext": "",
    "comments": [
      "You guys are absolutely copious if you defend this card. This card should be max 4050Ti, calling it 4060Ti is absolute slap in the face for every customer, and defending Nvidia is showing how delusional you all are. Just look at the memory bus and the generational improvement over the last gen. \n\nHow come 4090 provides 60% improvement over 3090 and 4060Ti provides 9% over 3060Ti? This card is only called 4060Ti for Nvidia to justify their greedy pricing this gen and deserve to rot on the shelves of every store. It is absolutely disgraceful!",
      "Barely faster than a 3060ti? \n\nThats kind of lame for a double node jump worth of density improvement.",
      "3070 for the price of 3070 but 3 years later. Nice.",
      ">How come 4090 provides 60% improvement over 3090 and 4060Ti provides 9% over 3060Ti?\n\nLmao 9% improvement from one gen to the next is pure trolling on Nvidias part.\n\nYet fanboys will still lap it up",
      "A 4060 disguised as a 4060 ti that's why.",
      "Nvidia GeForce RTX 4060Ti \"4050Ti Edition\"....\n\n\nRemember guys gen on gen improvement is 74%. This gets you only 10-15% 60ti over 60ti.\n\n4070 is the true 4060ti and 4070ti is the 4070.",
      "GTX 1060 had 6GB of vram. 7 years ago.",
      "You VRAM crazies really are losing it arent you",
      "The 40 series will go down as the worst GPU gen of all time.",
      "Because AMD forgot to release any cards this gen.",
      "This should have been at best called 4050 Ti but then the entire GeForce 40 series line up is a lie/cash grab except the 4090.",
      "Dude, the vast majority of kids would be stoked to have a PC that capable. I think they'll get by if they have to turn settings down to high. That said, screw nVidia.",
      "It's a skippable generation. There's no course correction coming. Avoid it unless you have no alternatives.",
      "Its hard to justify an upgrade from my 1070Ti with these prices, and still only offering 8GB of VRAM (Looking at you, 3070)... Hopefully a 12GB model or something shows up at a reasonable price in the future",
      "9 PERCENT?? holy shit, that's DOA. what an absolutely garbage card",
      "Because they are following suit, plus AMD are only good at pure rasterization, but are lacking in other departments like CUDA, HW encoding, etc. That's what you get in a duopoly market. Let's hope Intel improves enough to really change the status quo in the GPU market.",
      "Give me 12+gb and we’ll talk. This 8gb trend needs to stop.",
      "Stick to my 2060s for another 3 years, not gonna but any overpriced new card.",
      "Nvidia’s strategy here has been amazing. Like really impressive , from a business point of view. The 4090, 4080 and 4070Ti offer new performance levels at the same performance/$ (basically) as old 3000 cards, to prevent cannibalizing 3000 sales, and effectively create new premium SKUs.\n\nNow the 3000 backlog is gone, Nvidia are replacing the lower tier price points with cards offering the same performance/$ at lower prices, but it’s just more efficient silicon.\n\nIf AMD was competing hard this would be a problem but I’m guessing they are very happy to be in Nvidia’s shadow and enjoy higher margins on their cards right now, when their enterprise business are generally in the toilet.\n\nHats off to Nvidia - I thought they were going to have a GPU market crash due to the end of crypto and the glut of 3000 cards, but they managed the transition with this pricing strategy .(and got lucky with the AI boom).\n\nIn 2025 when the next generation comes around, they will have an option to throw 60 or 100 per cent uplift on the next Gen of lower end cards to maintain share, or if this pricing holds and AMD stay quiet Nvidia will just keep soaking up higher margins. \n\nFrom a business perspective, it’s pretty wild.",
      "Current 4090 is a xx80ti class card\n\n4080 is actually an 80 class but priced like an xx80ti\n\n4070ti is an upsold and up priced 4070\n\n4070 is an upsold and up priced 4060\n\n4060ti is an upsold and up priced 4050ti/4050\n\nWith that in mind, imagine the following lineup\n\n4080ti $1199\n\n4080 $899\n\n4070 $599\n\n4060 $399\n\n4050ti $299\n\nThis gen would have sold like hotcakes and nobody would have complained about vram."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "4060"
    ],
    "title": "GeForce RTX 4060 Ti 16GB Benchmark, Can Nvidia Fix The 4060 Ti?",
    "selftext": "",
    "comments": [
      "This could have actually been a decent card. But no, let's slap a 500 dollar msrp on that shit.",
      "That joke is even funnier in EU \n\n550-600€ + for a '4060ti' that should've been named 4050ti",
      "Funny how Jensen always finds excuses for rip off pricing, lol. It's always something else at fault, either memory controller, or clamshel design, or no space on PCB... So let me ask you Jensen - who the fuck didn't allow you to design this as 12-16GB (one sided config) PCB from scratch? I'll tell you what, because you thought you'll get away with 8GB buffer on such card - but that didn't go so well, did it? And then to save on R&D, you just sandwiched it in clamshell config, and ofc put all the costs and bonus on the consumer as how typically scummy corps do. \n\nIt's outrageous how this gen there's literally no good product at anything below RTX 4080 / RX 7900 XT and even those are too pricy, but at least those have decent specs. RTX 4070 -/Ti should also be with 16GB buffer cards, not 12GB, because GPU can absolutely compute max RT settings, but 12 GB puts it on the very edge and if not mistaken bit short in some game already - and just think about 2024, 2025? Because most people buy cards to last at least for two gens and with 12GB that ain't happening without VRAM compromises and 8GB is straight up insulting. So at the end of the day cheapest okay product is RX 7900 XT at $750 and from nvidia it's RTX 4080 at $1150 - like what the fuck...? So basically fuck everyone else outside of very high-end / enthusiast level? Right?",
      "Nvidia *will* fix it.... when they release it as the 12GB/192-bit 4060 Super",
      "They can fix it by making the 16gb model the only one and pricing it at $359.",
      "Drop the price.",
      "In the UK at Scan they are selling an Asus Rog Strix 4060 Ti 16gb for £595 more than 5 models of 4070 they sell, they are also the UK stockists of the 4070 Founders Edition model which has never been out of stock and is £30 cheaper at £569. There are also many other 4060 Ti 16gb models within £10-£20 of the 4070.\n\nWho in their right mind would buy it?",
      "This card has at least one merit.\n\nVRAM matters more than cuda cores in Stable Diffusion AI image generation.  It a cheap entry for 16GB heap.\n\nedit: ++ it burns much less watts for the equivalent task on 30 series cards.",
      "Why is it that hwunboxed has shown every reviewer how to look for VRAM limitations but a lot of them still gloss over the fact that many games will literally run out of the buffer and downscale textures?\n\nEspecially places like Digital Foundry who are supposed to be the specialists in this area. Paid off much, or just incompetent?",
      "Just give us a 16gb 4070ti you filthy pricks at Nvidia.",
      "> **Can Nvidia Fix The 4060 Ti** \n\nShure it can. Call it what it is - 4050Ti, name 4070 as 4060Ti, 4080 as 4070Ti, but would it? Definetely not.",
      "Not a terrible product, but the price kills it. If it was sold for $400, it would be a decent buy. For $370 at most, it would be a great buy.",
      "If this was say 350 it would be a decent deal.",
      "This should be the 4060",
      "Because analyzing texture quality is actually a lot more work and takes more expertise than just running a built-in benchmark or some custom autohotkey script while drinking a coffee.\n\nThat's also the reason why you rarely see someone other than Digital Foundry or Hardware Unboxed talk about image quality in depth, the barrier to entry is simply a lot higher.",
      "At $300 this could be a justified frippery for budget gamers who upgrade every 24 months and can stretch the extra $50 from the 4050 but a $500 starting price (no FE) is just wild, absolutely wild.  \nHopefully the direct comparisons shown here will give the \"vram doesn't matter\" crowd pause for thought, but we all know that's not going to happen.",
      "At the current price point, the 4060 Ti 10GB is just a decoy for the 4070.\n\n[https://en.wikipedia.org/wiki/Decoy\\_effect](https://en.wikipedia.org/wiki/Decoy_effect)",
      "WTF is this generation?",
      "> Not a terrible product, but the price kills it. \n\nAlso the whole current gen of GPUs. From both companies. (Except Intel.)",
      "> My question then is:\n> \n> Would 4060TI 16GB hold out longer? (when future games would require more VRAM later on)\n\nno. because by the time the VRAM would be needed, the card will be too slow to keep up. \n\nthis is a tactic the GPU makers have done for decades at this point. slap more VRAM on a weak card to make it more appealing."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "4060"
    ],
    "title": "The Gigabyte OC low profile 4060 is way smaller than I expected. It's tiny. (3 photos)",
    "selftext": "The MSI Ventus 3X is a 3080 To",
    "comments": [
      "We need more LP cards, shit became huge yo",
      "It's a 159 mm² die with 115w tdp.. Coolers nowadays are unnecessarily gigantic.",
      "I really like how overengineered they are. This way they are practically silent",
      "Im a huge fan of big cards but this is cute as shit.",
      "Missed opportunity to put it in the middle and recreate the meme",
      "For real though. If I play any game at 4K high settings with my 4080, the temps never go above 55⁰, that tells me the cooler is way over engineered. During a stress test it maxed out at 59⁰ . \n\nI don't mind in this case, but it's still crazy. The 4080 could've been so much smaller.",
      "Let's take it a bit further and make some of those low profiles 75w as well.",
      "This 4060, if you power limit it to 75W you only lose 5% perf. They should just ship it as a 75W card.",
      "Not a Gigabyte but a Gigbit 😆",
      "I'll take over engineered and quiet. I remember when I got a fractal torrent case and the huge fans on the bottom started housing my 3070 and I never heard it over ambient noise again. Not quite the same thing but it's nice when your graphics card is cooler than it needs to be.",
      "Well the problem is that it still requires an 8-pin cable instead of running off of PCIe slot power only. Right now we have the Intel ARC A380 6GB, AMD RX 6400 4GB, and Nvidia GTX 1650 G6 4GB and they are all roughly the same tier of performance. The A380 6GB has had some major driver improvements since launch and is easily the best pick of these if you actually needed one. An RTX 4060 75w would have been a massive upgrade plus DLSS Quality at 1080p looks mostly okay which bumps performance up even further.\n\nYes it should have been shipped as a 75w variant but I bet Nvidia doesn't want anyone shipping a card with base TDP below stock.",
      "You would like it even more in person then. You can definitely tell it's small from the pictures, but it looks even smaller in person.",
      "That's what I'm saying\n\nShip it as a 75W limited 4060 without the 8-pin.\n\n4060 at 75w is the same-ish performance as a stock 4060.\n\n> Nvidia doesn't want anyone shipping a card with base TDP below stock.\n\nThey let laptop makers use the same die below 75w.",
      "my first thought lmao",
      "My brother in Christ, your money is your money of course, spend as you will;\n\nBut I'm blaming you when the 5000 series are $2000.",
      "Actually, you're right. It's like an inch taller than my Pixel 6 lol",
      "The 4060 found in desktops as well as those found in laptops utilize the *exact* same 115watt AD107 chip.\n\nTherefore, you’re technically correct, though it’s not inherently a bad thing. \n\nThis holds true for desktop 4060’s across the board; the 4060(m) performs near identically to its desktop counterpart this gen.",
      "This 4060 will only be hitting like 110w maybe 120w in games. The fans are plenty. Also, it's a little on the thicker side from the heat sink.",
      ">Coolers nowadays are unnecessarily gigantic.\n\nAs a 4090 owner... I disagree.\n\nWhy? Because it makes them quieter. Same reason I have a massive NH-D15, because it's quiet as hell. I hope we continue the trend of overly massive coolers, because the bigger they are the quieter our computers will be.",
      "Giganibble."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "4060"
    ],
    "title": "Why The RTX 4060 Ti Sucks, Really Bad! GeForce RTX 4060 Ti vs. RTX 3060 Ti, 50 Game Benchmark",
    "selftext": "",
    "comments": [
      "The new-gen card should absolutely never lose to the previous-gen card in the same benchmark. That means the hardware has regressed.\n\nThis card is a disgrace, its existence is an embarrassment to PC gaming.  I would say shame on you Nvidia, but they clearly have no shame.",
      "That's because the RTX 4060Ti is what the RTX 4060 should have been, and the RTX 4060 is the true RTX 4050.",
      "lol 12-22% slower in Doom Eternal WTF",
      "At this point, Nvidia just doesn't care.  Gamers can cry as much as they want but Nvidia's pockets are already full with the sweet AI money.",
      "Nvidia thought the advantages of the new TSMC node would allow them to cheat and bump all the 40 series cards up a tier or two.  Unfortunately for them, it's very obvious when you look at the specs, and the performance gains aren't enough to pull it off.  So we end up with this shitty 4050 masquerading as a 4060 Ti.",
      "yea i guess people cant defend that 128 bus anymore, it really does make it shitter",
      "That game loves bandwidth, the 128 bit bus really limits the 4060ti.",
      "Because of AI. LLM´s and transformers need lots of VRAM and memory bandwidth. AI is and will be 200x as large as a market for NVidia than Gamers. NVidia knows the specs required to train and run AI models, so these specs are cut down on gaming cards to make them unsuitable for running AI.\n\nTHAT is the only reason. NVidia wants the money from companies running AI, so they don´t want those companies to buy cheap geforce cards\n\nONLY reason.",
      "Imagine if Apple released Iphone 15 at the same price as iphone 13 2 years later, and 15 was actually slower than 13.\n\nIt would make fucking headlines. Nvidia are lucky they serve a niche market. Just absolute cunts.\n\nAs someone who remembers the 90s and 2000s, where I literally went from playing half life 1 on a TNT card to Far cry on an FX 5700 in 5 years, this is just an absolute travesty. Nvidia is using every fucking excuse to blame this on node progression slowing down. And AMD is just behind them coasting on selling consoles and CPUs. We literally need Intel as our saviour...lmao\n\nEdit: sorry, 2,5 years later... Eat \\*\\*\\*\\* Nvidia <3",
      "It’s just so weird they cut down the memory bus, like the die itself already has less cores than the previous version why would you gimp the bus to save a few more pennies? And then the VRAM, shit is so cheap rn why not give the lower end cards a bump to 12GB across the board? (The 3070 never should have come in an 8GB version either, that shit is criminal, even with the 3070 they should’ve known better).",
      "Since the now \"unlaunched\" 4080 12GB they just decided to name GPU in a way that pushes people to pay more and be fooled by the naming scheme. \n\nBesides the absurd 128bit bus choice (albeit in some games larger caches means you need to use less the bus bandwidth), they are good GPUs, very efficient, nice stable drivers,...but wtf those price seriously.\n\n&#x200B;\n\nFor people defending it:\n\nSome can say \"but , they consume less watt and are so efficient, Ampere just consumed too much\" it make no sense, because if a true 4050 existed it would have the actual consumption/performance of the 4060 and you'd be able to purchase it, cheaper, and have the wattage you wanted ! \n\nIt's just people applauding for more expensive options and less options, nothing more.",
      "![gif](giphy|ARb77MvJVd7Uc)",
      "I believe Jensen can barely wait to stop selling GPUs to consumers, so he doesn't have to hear gamers and youtubers whining about the absurd prices anymore.",
      "A great 1080p experience for only $399, what more do you want?????",
      "The AI bubble isn't going to burst.  This isn't mining.\n\nIt's only going to get worse unfortunately.\n\nAnd since they are making so much bank on that they 'could' make less margin on their dGPU division and give gamers some good stuff but they are in such a dominant position and AMD is doing jack all to compete that we really have to hope in Intel.  In other words, we are screwed.",
      "The conclusion of \"Just throw more cache at it\".",
      "Look at nvidias stock. That thing is almost doubled in the last 3 months. They don’t care about gamers. As long as sales are going up and AI is all the rave, they are happy",
      "The 1080Ti wasn't $1000.\n\nIt was $699 and came out in like 2017.",
      "Or if the PS5 was slower than the PS4. It would be a massive deal.",
      "I feel bad for one of my friends.\n\nHes addicted to buying pc parts, but doesnt even play games he just runs benchmarks. He bought this card, I tried talking him out of it but he doesnt listen. \"upgraded\" from a 3060ti to this.\n\nHe literally plays games from 2005 and older, at 1080p.\n\nRuns the tomb raider benchmark, never plays the game. Im like man, play the game its really good!"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "4060"
    ],
    "title": "NVIDIA GeForce RTX 4060 Ti with 16GB memory launches on July 18th - VideoCardz.com",
    "selftext": "",
    "comments": [
      "A 16GB GPU with a 128bit bus... what a waste.",
      "So ... $599 for the ASUS ROG Strix one right? xD",
      "\"Help us move these mediocre units! We've tried nothing and we're all out of ideas!\"",
      "DOA unless $350",
      "Here’s the cards you should buy:\n\nInsert card $400 more expensive \n\nInsert card 10% slower and $40 less",
      "Get ready boys. \nSteve is gonna absolutely cook nvidia.",
      "Already know what he's going to say. \n\nIgnore the price and it's a decent entry level 1080p card. \n\nDon't ignore the price and it's trash. At least the vram bottleneck is gone but the 8GB version shouldn't even exist and this should be its price at most. If you want a $500 GPU buy a 6800XT while stocks last. Although we have to give it credit on how efficient it is. \n\nOr words to those effects.",
      "800$ take it or leave it",
      "a 3060ti user should never upgrade to this. There is no performance gain outside of frame gen.",
      "16gb on the 4060ti but only 12gb on the 4070ti, the gpu which is much better for higher resolutions...\n\nThis is the thing I hate the most about nvidia atm. Pricing can go down overtime, but putting more memory on weaker cards than the stronger ones is just pure clownery.",
      "As always 2 parts. The product. The price.\n\n4060ti 4352 SP and 200W TDP is OKish. Most games playable on 1440p. But too slow for RT.\n\nAt $300. It would sell well. Good upgrade for 3060 users.\n\nBut at $400 its meagre upgrade for 3060ti users.",
      "No the hall of fame 4060ti that pulls 600w",
      "Are you aware that the the wider the memory bus, the more data can be transferred between the GPU and its memory at any given time, right?\n\nI will help you with a analogy: You have two huge water storage tanks... one full and another empty. If you connect them with a narrow pipe, and only a small amount of water will be transferred between them - it doesn't matter how huge are the tanks. If you increase the pipe diameter, more water will be transferred. Memory works in the same way. \n\nSimilarly, memory bus determines basically the lanes where the memory is transferred.... You can have a huge amount of memory, but with a narrow bus, only a portion will be used at a given time...",
      "Price to performance king!\n\nLet me show you this GTX 780 I GOT FOR FREE. INFINITE PRICE TO PERFORMANCE KING",
      "Have you considered [card that is $200 cheaper and 60% slower]?",
      "A VRAM capacity bottleneck is WAY worse than the bottleneck of a 128bit bus\n\nI don't wanna be forced to play with medium or high textures settings in the next 1-2 years, and a bazillion bit bus won't save your 8GB card when the game is trying to use 10GB\n\nEDIT: and just to be clear, I do hate the options Nvidia is giving us, this generation is pure shit and it sucks that we have to wait until 2025 for them to (hopefully) release an objectively good XX60 card",
      "That’s true, but Nvidia created this situation. We can walk through the logistics now of why it is this way, but who cares when the end result is the same. \n\nNvidia has a product line where for two generations now a lower tier card has more VRAM than a higher tier more expensive card. Making it hard to justify anything as a purchase except the flagship card.",
      "the 3060 is never far behind the 4060 in any grafic configuration,\n\nthe 3060 ti (with double the bandwith and the same 8gb) pretty much allways won against the 4060 dispite beeing way older,\n\nthe additional vram of the new 4060 wount result in better performance most of the time, the bus bottleneck is way worse than the vram one,\n\nits like buying a new top of the line gaming pc and putting ddr3 in it (if that was be possible), its would be by far the biggest bottleneck no matter the ram size",
      "And it still has the same 128 bus as the other 4060s. The extra GBs for this reason won’t matter much. Heck the GTX 1070 ti I have has twice the bus.",
      "Do you think they will really listen to us on reddit?"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "4060"
    ],
    "title": "GeForce RTX 4060 is now available for $279 - VideoCardz.com",
    "selftext": "",
    "comments": [
      "$20 and people lay down pitchforks. What a world.",
      "Damn, that's actually kinda alright value now",
      "Good candidate for a media PC utilizing RTX Video Super Resolution and AV1 encoding.",
      "Right!?? Not even 10% off!??\n\nI guess $20 is $20, and maybe that makes the budget?",
      "There is no such thing as a bad video card, just a bad price.",
      "A 3060 Ti performs better than a 4060.",
      "![gif](giphy|lgRNj0m1oORfW|downsized)",
      "There’s such thing as a performance floor",
      "jesus fucking christ its the newest gen mid-range card how is it showing its age, just because it can't play 4K fully ray traced maximum settings above 90 FPS doesn't mean its already nearing obsolete. There's more to games then enabling the path tracing option in Cyberpunk.",
      "Yeah, I was like “nobody care it’s actually a 4050 anymore?” It’s core barely bigger than those vram chips around. \n\nAnd wait a year for merely $20 discount when “supers” got “$200” upgrades is beyond my understanding.",
      "psychology tactic to remove the leading number in front. thats why $49.99 is much more appealing than $50",
      "yea call it a 4050 and price it at 159.99",
      "Hold the line. Wait for the 5000 series. You'll thank yourself later.",
      "5060 is at least one year away isn’t it?",
      "The compression artifact reduction for VSR is so good",
      "Yeah, isn't 4060 close to 2080 performance or something? That's still good to play 99% of games at high (not max) settings in 1080p, plus add DLSS3 magic.",
      "[Everything but Alan Wake 2 at 1080p Ultra](https://www.youtube.com/watch?v=OhAdZ5JWQHc), and even then you could turn it down to high settings or use DLSS quality settings.\n\nOh, [and Steam's had more then 30,000 game releases in the last 2 years](https://steamdb.info/stats/releases/), I'm sure a ton of them are amazing games that play even better because they are well optimized, cough Remedy cough cough",
      "I think they need to be at $249.",
      "Source for it being close to 2080? In terms of games, 2019 was 5 years ago I think you guys need higher standards.",
      "I bought my first pc days ago.. I have a 4060 with a i5 12400f. I played plague tale at 1440p high/mid settings with dlss and fg and I get a solid 70-80. Cyperpunk was about the same but without fg. Horizon was about that too! It's a good card very low power consumption which helps when if your tight on your budget and you can't spend extra money on a Psu. I'm considering slightly over clocking it to stretch it just a bit more! Temps all under 80c under full load of gaming! It's a great card for what it can do! Keep in mind I wanted a 4070 but that was too expensive...  I didn't go amd(even tho my first specs had amd)  I just heard it's unstable Af when it comes to some games."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "4060"
    ],
    "title": "Looks like the 4060 and 4060 TI made quite the comeback",
    "selftext": "In May only 2.82% of Steam Users were using an RTX 4060. In the latest Steam Hardware Survery however this number went up to 4.58%. The basic 4060 is now the 2nd most used GPU and even the 4060 TI is at 4th place now. \n\n[https://store.steampowered.com/hwsurvey/videocard/](https://store.steampowered.com/hwsurvey/videocard/) ",
    "comments": [
      "The 4060 and 4060Ti were always going to sell well\n\nThey're the cheapest modern Nvidia GPUs, that's predominantly what OEMs will target for uninformed buyers, who are the bulk of the market\n\nI actually think the $600-700 12400F/4060 prebuilts I see regularly are actually decent value. Plays every modern game comfortably with decent settings\n\n The ~$1000 4060Ti prebuilts are another story",
      "The Steam survey is indicative of what people can afford. That is pretty much it.",
      "It's mostly from prebuilts I'd imagine",
      "I’ve just bought a 4060 and I really like it. \n\nRuns and hides….",
      "Getting a 12400f or 5600 with a 4060 for a good price is so economical. Low power draw, budget friendly, and still can do up to 1440p in AAA games with nvidia software and high (not ultra) settings.",
      "It's not because they are great. It's because there is nothing else to buy in price",
      "So they can afford the lowest model. Shocker...",
      "I mean, this market is extremely expensive. Not surprising. I wouldn’t have been able to buy my 4070ti Super just a year ago.",
      "\"...8gb is not enough for gaming...\" Proceeds to release RX7600. What can we say..? Competition is fierce.",
      "I can believe this. Most prebuilts i see are using them and many times at decent prices too.",
      "Most of reddit (Myself included) assume someone is buying a GPU for just gaming\n\nOnce you're a non-gaming user. Nvidia are almost always the significantly better option",
      "60 class cards are always the most popular in steam’s surveys. It’s in the price class where most would buy. Mostly prebuilt and laptops also come with 60 class cards.",
      "Personally only got the 4060TI 16GB because i also like playing around with AI stuff. Otherwise i would have gotten an AMD Card in the same price range as well.",
      "60 class has always been popular because it's cheap and it's just powerful enough to play the latest games.",
      "8GB is enough for 1080p",
      "Bingo.   A lot of uninformed folk would rather a 4060 ti 16gb instead of a 7800xt.",
      "Dunno what you mean, but i remember Wukong running at close to 70 FPS with Raytracing on my 4060 TI 16GB which sounds more than enough for \"the average gamer\" who plays a few hours every now and then?",
      "Of course, they're better than the 3060 and ppl started to realize they've been lied to, at least in my opinion and view of things",
      "100% is. Two years ago $1500 builds got you ryzen 5's + 3060 or 3060ti but now the same cost gets you 4060-4070 plus ryzen 7",
      "I have got two builds with 4060 and a 4070 ti super.\nGuess what I only play games with 4060 and spare the 4070TS for work stuff, cause there isn't a single game I can't play on ultra with my 4060."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "4060",
      "4060ti"
    ],
    "title": "Would you be mad if Asus replaced your 3070ti with a 4060ti?",
    "selftext": "My ROG 3070ti just randomly died, so I sent it to Asus for warranty. After a week, they contacted me and gave me the option to switch to the TUF 4060ti 8 GB. I understand that 4060 ti is not better than 3070 ti, but it has less power consumption and new technologies. I don't think it's worth replacing my 3070ti.\n\nWhat do you guy think?\n\nI'm from Vietnam. IDK how they support in other country, but I think that ASUS in my country don't support very well to me and other. They always want to downgrade to the same price that 3070ti today compared it to the new 4060ti which price will drop after 1–2 years. It is kinda sad to be honest that I always buy stuff from Asus. I hope that Asus can see this and contact me.\n\nEdit:  After explaining that the 4060ti is not the same as 3070ti in terms of performance, either the 3070ti or better. So they requested me to wait for a few days while they present the declined solution to their supervisor and find a better solution for me. I suppose we'll have to wait and see. Thanks so much for all of your supports and advices, and I'll make sure to keep you updated.\n\nAnd i still hope that ASUS can see this post.  [u/Asus\\_USA](https://www.reddit.com/u/Asus_USA/) ",
    "comments": [
      "I would ask for a 4070 at the very least as 4070 will perform close to 3080 which is a step up for you. There's really no \"performance equivalent\" for 3070 Ti this generation so Asus is trying to shortchange you with 4060 Ti.\n\nIn fact, it's ridiculous for them to try and scam you with 4060 Ti there.\n\n* 3070 Ti was $599 MSRP at launch\n* 4060 Ti is $399/499 MSRP\n* 4070 is $599 MSRP\n\nso no matter how you look at it, they really should've replaced your card with a 4070.",
      "I would post this on r/asus. You want as much visibility on this as you can get in order for Asus to make this right.",
      "How much extra money for 4070? The 4060 Ti, even the 16GB version is definitely a performance downgrade for your 3070 Ti\n\nIf they are giving you the 8GB 4060 Ti then definitely escalate to a manager and raise some hell.",
      "Okay. For me, it's 4070 or bust. I would escalate to manager and raise some hell. It makes no sense to get downgraded to a 4060 Ti.\n\nIf it's the 16GB version, you can make the argument that MAYBE the VRAM is worth it for the future but it's still a performance downgrade regardless.\n\nIf they are giving you the 8GB 4060 Ti, do not accept. That's a straight up scam and basically valuing your card at least $200 less!",
      "They said that I have to give them extra money to get 4070 😕",
      "I'm still waiting for them to response",
      "i wouldnt settle for anything less than a 4070",
      "I'm from Vietnam. IDK how they support in other country but I think that ASUS in my country don't support very well to me and other. They always want to downgrade to the same price that 3070ti today compared it to the new 4060ti which price will drop after 1–2 years.\n\nEdit: It is kinda sad to be honest that I always buy stuff from Asus.",
      "When I bought it last year, it about 600$. And the TUF 4060ti 8gb current price today is about 480$.\n\nI'm so upset right now!!!!",
      "Nothing less than a 4070.\n\nIf Asus is unresponsive, comment on their social media pages and send messages to them directly. They will be forced to engage you, and you can make your case.\n\nIf front-line staff refuse to entertain you, go higher - contact the manager, etc. This is not about being entitled and it's not always because service staff are uncompromising. Rather, they are sometimes unable and unwilling to make decisions because they can't or won't deviate from standard operating procedures, so you need to speak to someone who can.",
      "Definitely I would, the 3070ti is around 10% faster than the 4060ti\n\nhttps://m.youtube.com/watch?v=1v4OvYIuxKQ",
      "Yeah i would, if i have a 70 class gpu I want a 70 class replacement, if 3000 series isn't available give me an upgrade it's not the customers fault they no longer have the same product for replacement.",
      "The 4060ti 16GB is a downgrade though",
      "Are they somewhere else that I can post this to ASUS to read it",
      "Do we need any more reason to boycott Asus? lol fuck that downgrade.",
      "They do not look there, they do not care.\n\nIt took them 10 weeks to get me a suitable replacement for my 6 month old 3090 and they ended up having to send me a white one (which I was fine with) because the only black one they had was a refurb with damage (which they sent me first) and even still the white one had marks on it.\n\nIt took me posting on PCMR and getting over 4000 upvotes to get something done, after someone who knew someone at ASUS saw my post.\n\nI find it amazing that companies sold parts new up to the end of 2022 and kept absolutely 0 stock for replacements. ASUS is not the only one, Corsair did it to me with a water block as well but their customer services was infinitely better.",
      "Yeah if I paid for that with a credit card I'm going to proceed with a chargeback case if ASUS won't compensate with an equivalent dollar value GPU at least lol",
      "How much in Vietnam's currency did you pay for your 3070 Ti? How much is a 4060 Ti, and 4070 in Vietnamese currency going for now?\n\nYou should try to compare it and explain to them that you will not accept the 4060 Ti and you will only accept a 4070. They have to respect you as a customer and honor their warranty. Check Vietnamese consumer rights if you have any. \n\nIf its possible in your country and you purchased with credit card see if you can get your credit card to assist you with a chargeback case, the creditor will help you through this if ASUS continues to be uncooperative with honoring their product warranty with a respectable service and replacement to you for their product failing and give you your money back possibly so you can choose a new GPU with a different manufacturer that won't short change you with a downgrade replacement. \n\nSome people might say you're getting DLSS 3 and Frame Gen but you paid the price for a 3070 Ti not a 4060 Ti. **They won't even give you the 16 GB variant.** So definitely do not accept this and try to find a way to change their mind or get your money back.",
      "Ask them for 4070 replacement or 4060ti 16 gb",
      "Thanks so much😍😍😍"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "4060"
    ],
    "title": "[Gamers Nexus] NVIDIA GeForce RTX 4060 GPU Review & Benchmarks | Prices Keep Falling",
    "selftext": "",
    "comments": [
      "40 line up so far\n\n4090: one of the best uplifts per generation\n4080: $400 too expensive\n4070ti should be named as 4070 and priced no more than 599\n4070: should be 4060ti\n4060ti: a literal scam\n4060: should be named as 4050",
      "see you at 5060 and 5070 launch fellas",
      "Came back from 2025, they're still destroying wallets 😭",
      "based on the actual performance uplift compared to the previous generation",
      "Rumor says there is this \"Ada Lovelace Next\" architecture that is scheduled for 2025 which is the RTX 5000 series. Assuming this is true, the remaining 2023 year will be 4080 Ti 4090 Ti 4060 Ti 16G 4050 6G. And then 2024 will be RTX 4000 SUPER series.\n\nThis explains why the 4000 series card so far we are getting are kind of mediocre as there is going to be lots of refreshes.\n\nIt's usually 2 years cycle per architecture, but if Ada Lovelace Next is 2025, it will be 3 years. What's with the hold up? Demand falling? I also heard somewhere Nvidia is switching to Intel fabrication? TSMC charging too much per waffle?",
      "just like the SCAM known as RTX 3050 outsold \\*ALL\\* of  RDNA 2 + ARC combined (according to STEAM HW survey) i expect this to outsell all of RDNA2 + RDNA3 + ARC combined as well.\n\nPC gaming bleeds green after all.",
      "This \"DOA\" product will probably outsell everything 💀",
      "2025, here we come",
      "Welp... this card's specs are so gimped that it actually ate up all generational gains of this gen. So sad to see.\n\nThe price is bad, but not terrible IMO. I wonder how much the price needs to come down for this card to be good value, and I think it's around the $250 mark? But if it performs like a 4050ti, costs as much as a xx50ti tier card should cost, then why is it called a 4060?\n\nA 4060 should have 10GB ram, 16 pci-e lanes, a bigger bus and more cores, and should cost around $350. Where is this card??",
      "It is a scam . That shit costs more than RX 6600 while being 30% slower . Even with DLSS on it still barely matches RX 6600 rendering natively",
      "Cant wait for this card to outsell everything else",
      ">It's usually 2 years cycle per architecture, but if Ada Lovelace Next is 2025, it will be 3 years. What's with the hold up? Demand falling? I also heard somewhere Nvidia is switching to Intel fabrication? TSMC charging too much per waffle?\n\nFabrication processes are harder and harder to improve. Then there is the current recession meaning most people don't have extra money to spend, especially at these ludicrous prices. \n\nIntel is quite far behind TSMC, I don't see that happening. They would be going backwards.\n\nBtw it's wafer, not waffle... :D",
      "If we compare it to Pascal, the 4060 actually exists, it's called the 4070.",
      "It's the Volkswagen Golf of graphics card, it's that simple. \n\nNo matter how bad it is, if it costs less than 300$ and it's called \"nVIDIA GeForce GTX/RTX XX60\", it will sell at least decently to very well.",
      "The 6700XT is even better considering raw performance.",
      "The 3060 12gb is currently a better deal",
      "oh they're learning......how to keep securing that bag bby 💰 🤑",
      "The  law is called common sense .",
      "Even at $250 it's poor value. 6600 line up offer similar performance for way less. I'd say $220 is a fair price.",
      "Personally I prefer waffles :-p"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "4060"
    ],
    "title": "NVIDIA GeForce RTX 4060 Ti is now available at $379, 5% cheaper in a month - VideoCardz.com",
    "selftext": "",
    "comments": [
      "What annoys me is that 3000 series are still expensive , why are they dropping price of this instead of 3060 ti for example..",
      "Why do people insist on comparing prices of used products to new like they're the same thing?",
      "Scams, mining cards, no warranty, etc. people just don’t want to deal with the headaches.",
      "3060ti was on sale at Best Buy for $275 since last night. For the past three weeks they've been going on sale intermittently.",
      "$300 at most for a 8gb card. Even a pc first game like diablo4 cant use best texture quality with 8gb without stuttering to hell. Lower textures look so bad too.",
      "Wow, 5% cheaper? Truly newsworthy.",
      "Where i live a 3060ti costs 360€, a 4060ti costs 450€. They're about the same performance, why would anyone go for the 4060?",
      "Nvidia hoping people are drinking the DLSS3 marketing juice super hard i guess",
      "I agree. VRAM isn't everything, but 8GB kneecaps this card's future potential.",
      "3060ti can be had on eBay for under 300. I picked up a 3060ti FE from a buddy yesterday for $250",
      "250 max",
      "they dont though, limited supply, no warranty etc",
      "I've been looking at a 6700 XT for a friend's build. Been seeing them as cheap as $350 new. \n\nDoes a 4060 Ti even come close to a 6700 XT for 1440p? (and my friend does not play many, if any, DLSS3 supported games)",
      "LOL. I am just rubbing my hands for the 4060 reviews at this point. Or even fucking worse 4050 desktop cards. low end sub 200 market is already awful with AMD which is notorious for great value mid to low ends. but Im just waiting for the inevitable 4030 comments",
      "This soon after release it is",
      "DLSS3 is actually pretty impressive, but it borders on a \"win more\" feature, where it makes a good framerate into an amazing one.  I'm really liking it in Diablo 4 where it (mostly) pegs my FPS at 180 at 1440p Ultra, rather than bouncing around in the 90-160 range.  The thing is, I already had a very playable framerate, it just made it smoother. \n  \nOn a card like the 4060ti, it seems of marginal use to me.",
      "As much as I’d want to agree with your statement of Diablo 4 being pc first, it’s definitely not",
      "Also overpriced and underperforming.",
      "When an item heats up, it expands. When it cools, it shrinks. This is how most materials react to temperature changes.\n\nIf a card is running 24/7 at a stable temperature then the rate of expansion and shrinkage is capped and doesn't happen often. The core in mining is also underclocked and running far below any gaming loads.\n\nIf you game, your card heats up and cools down multiple times over the course of minutes/hours/days meaning that the solder between the PCB and memory chips is expanding and shrinking at a faster, and more frequent rate.\n\nThe reason people used to stick their cards in the oven was to expand these solder balls under the memory enough to make contact again and temporarily run again if you want it to relate to something in practice.\n\nBecause of the physics of temperature and how materials react alone is proof as to why mining is less strenuous on the card.",
      "My first 8 GB \"1440p\" card was back in 2015, I got it for playing The Witcher 3. Radeon R9 390X.  It was only $425 back then, 8 GB VRAM on a 512 bit bus,  384 gb/s memory bandwidth (compared to 4060 Ti, 128 bit bus, 288 gb/s bandwidth LOL).\n\nSimilar price, 8 years later, same memory amount, significantly less bandwidth. Nvidia truly taking the piss."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "4060"
    ],
    "title": "NVIDIA GeForce RTX 4060 (Ti) Founders Edition has been pictured as well - VideoCardz.com",
    "selftext": "",
    "comments": [
      "What will this one be $599.99? Lol",
      "The 4060 is on AD107?\n\nThat's the xx50(ti) tier die.\n\nAnd also, 115w even on AD107? Even with the efficiency of Ada it couldn't be sub 75 for connectorless cards?",
      "Its pretty funny about couple years ago the lastest falgship costed 600 or 700$ now its the weakest one imao",
      "Price: $1600 -> $1200 -> $800 -> $700 -> $600",
      "Nvidia greed ಥ_ಥ",
      "xx50 class die for xx70 class price with xx60 name? yay, \"progress\"",
      "You say that, yet people are still buying 3060 Ti's and 3070 Ti's.",
      "Couple of years ago there was the 3000 series, the flagship was 3090 for $1500 on paper and sold around 2500+, you mean 5 years ago 1080 Ti was $700 and Titan for 1k, life is too short bro and time passes by like a train",
      "What is weird to me is that TI versions used to come later.\n\nLaunching them gives too many GPU names for an average consumer.",
      "Yeah time flies just like the prices imao\n\nThey scamming people\nIdc what people say but no fuuking way any of those overpriced piece of junk is Worth so much money",
      "Dead on arrival with 8 GB.  Unless it's $150.",
      ">The card is clearly labeled as RTX 4060, but the leaker says it might be RTX 4060 Ti\n\n>The RTX 4060 Ti is alleged to feature an AD106-350 GPU with 4352 CUDA cores. It is to feature 8GB of GDDR6 memory and only a 128-bit memory bus. Furthermore, the TDP will be reduced on this model to 160W, from 200W on the upcoming RTX 4070.\n\n>Meanwhile, the RTX 4060 is to use entry-level AD107-400 GPU instead. This would be the full implementation with 3072 CUDA cores. No changes to the memory config are expected, but the TDP should drop even lower to just 115W. Both models are to feature PCIe Gen4 x8 interface.\n\n**RTX 4070Ti -> RTX 4070-> RTX 4060Ti -> RTX 4060 -**\n\nGPU Die : AD104-400 -> AD104-250/251 -> AD106-350 -> AD107-400\n\nCuda Cores : 7680 -> 5888 -> 4352 -> 3072\n\nMemory : 12GB G6X -> 12GB G6X -> 8GB G6 -> 8GB G6\n\nMemory Bus : 192-bit -> 192-bit -> 128-bit -> 128-bit\n\nMemory Bandwidth : 504 GB/s -> 504 GB/s -> 288 GB/s -> 288 GB/s\n\nDefault TGP : 285W -> 200W -> 160W -> 115W\n\nInterface : PCIe Gen4 x16 -> PCIe Gen4 x16 -> PCIe Gen4 x8 -> PCIe Gen4 x8",
      "Power doesn't make it a 4050. Transistor count and performance relative to the top die does.",
      "Ehm, that's all they want, to create confusion as much as possible to fuck everyone as much as possible",
      "Why are you ok with a $500 60 class card at all..........",
      "![gif](giphy|3ohhwxmNcPvwyRqYKI)",
      "Not only that, people actually buy 3050´s!",
      "Tbh 8g on 3050 makes a lot more sense than 8gb 3060ti/3070/ti",
      "Out of Stock Edition will be $599. AIB versions for only $749 for that immersive 1080p experience.",
      "Why would it? Their competition is ass."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "4060"
    ],
    "title": "NVIDIA GeForce RTX 4060 rumored to feature AD107 GPU with 3072 CUDA cores - VideoCardz.com",
    "selftext": "",
    "comments": [
      "Looks great for $250. lol\n\nrtx 2060 was about half of 2080 ti for a quarter of the price.\n\nThis one is less than a fifth of 4090 probably for  1/5 of the price $350. lmao\n\nthe most blatant scam.\n\nThe identical laptop part is already benched, its about same as 3070. The performance of the card is still reasonable. If this was actually 3070 with more VRAM, I could see the appeal but it's just 3070 with $100 discount of its msrp almost 3 years later.",
      "RTX 3090 - 10496 CC (Cuda Cores)  \nRTX 3060 - 3584 - 34% of RTX 3090  \nRTX 3060 Ti - 4864 - 46% of RTX 3090\n\nRTX 4090 - 16384 CC  \nRTX 4060 - 3072 - 19% of RTX 4090 (Let me guess \"Priced competitively at $449\"?)  \nRTX 4060 Ti - 4352 - 26% of RTX 4090 (Let me guess \"Priced competitively at $499\"?)\n\nWell, f ck you NVIDIA. I really want to hope GeForce 40 series cards sales will flop hard.\n\nThe real names for RTX 4060/4060Ti should have been 4030 and 4050.",
      "Coming in at $350 is being real optimistic, borderline hopium lol. I see NVIDIA charging $500 for the 4060ti and $400-$450 for the non ti",
      "My prediction for the prices of the rest of the stack:\n\n4070: $599-649\n\n4060 Ti: $499\n\n4060: $399\n\n4050: $299-329",
      "I miss when xx50 cards was \\~$100.",
      "107 was usually reserved for the xx50 GPU tier right?\n\nIs this thing basically going to be a 3060Ti with better DLSS & FG? Yippee...",
      "Omg yea fucking right anyone is buying this shit. Pure garbage, let me guess it'll be a 82 bit bus too right",
      "We should make them change the name but not the price, so we will feel better accomplishing nothing",
      "AMD's drivers are mostly okay, but their prices are following the same bullshit increases for this gen.",
      "This is a \"GTX 960 2GB\" situation, just much worse, unless it's 250$ - and yes, it won't be that cheap, let's be honest.\n\nAt this rate, the XX60 class will not even exist in 10 years.",
      "It's amazing. When's the last time I read an \"NVIDIA GeForce RTX \\*\\*\\*\\* rumored to \\*\\*\\*\" and didn't get a sense of massive dread? I have no idea.",
      "This pricing would be gross...",
      "Don’t you dare compare the 4060 to a 3060ti. At least the 3060ti was priced accordingly and got people through the chip shortage 😂👌",
      "8GB of memory at a measly 128bit with 288GB/s is pathetic  (not only for the 4060, but even for the 4060Ti !)",
      "And 6gb vram",
      "it is not going to be faster than 3070 when it uses AD107 die lol, it might even lose to the 3060TI",
      "but we all know it will be $400 minimum, thats the problem...",
      "Don't you dare offend my poor little 3060 ti.",
      "I look like a clown every time waiting for 4060 to be a good card to upgrade from 2060 super.",
      "8GB of RAM. \n\nOh lordy."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "4060"
    ],
    "title": "First leak featuring GeForce RTX 5060 Ti 16GB shows 13-14% performance boost over 4060 Ti",
    "selftext": "",
    "comments": [
      "I know budget conscious people don't want to hear this, but the value of budget cards is ass for many years, get a good one once and you're good for many years and spend less in the long run",
      "So essentially the same performance as the 3070ti / PS5 pro.",
      "According to Digital Foundry benchmarks the PS5 Pro is roughly equivalent to a 3070 (non-ti) when you match resolution and settings.\n\nEdit: u/uExtra-Cold3276 he specifically says in the video that the 4070 is significantly more powerful than PS5 Pro based on raw numbers and the \"equivalent\" comment is due to AI upscaling.\n\nAnd that video was posted before he even had a PS5 Pro in hand to actually look at real world results. \n\nLmao you couldn't be more clownishly wrong if you tried.",
      "What were those calculations based on?",
      "Hopes, dreams, but mostly guesswork until it's actually observed by 3rd party reviewers.",
      "I don't think most people are undervolting any GPU.",
      "For me it's not the budget, but the watts. I don't want a card that pulls 300+ watts. But down clocking a higher end card is even less cost effective than the lower end slop releasing recently. Next Gen should get a node shrink, so hopefully efficiency will be better then.",
      "I'm not going to debate this with you. Digital Foundry knows this stuff a lot better than you or I. If they say it's 3070 equivalent then it's 3070 equivalent, period.",
      "> It's not comparable when the 3070 literally can not play games the PS5 pro can.\n\nIt **literally** plays all the games a PS5 pro can.",
      "FFS, what part of \"I'm not going to debate this with you\" do you not understand? Digital Foundry is right as always, and you are wrong. End of story. Now go away.",
      "5060 Ti will have same price as 4070 😂",
      "It's fine, people will say it's not for 40 series owners but instead for 20/30 series owners but it's still a shit upgrade even for 3060ti owners considering 4060ti itself only offered like 10-15% more perf at same price(yea, ignoring the 16gb card cos it ain't same price and even then if game isn't memory heavy then it isn't a significant upgrade either)",
      "It's just ridiculous how much \"mid-range\" has stagnated over the past four years; the RTX 5060 Ti is only 30% faster than the RTX 3060 Ti for roughly the same money, so that's a YoY performance increase of less than 10%.",
      "Bro said based on my calculations 😂",
      "Sure, for the enthusiasts who spend time on pc subs like this. Your average joe consumer doesn't do much or any research nor do they do any tuning after they buy a pre-built and plug it in. We are a tiny minority in the PC space, vastly out numbered by general average joe type consumers.",
      "Expected jump honestly. Don't know why delusional andies thought his was gonna get some astronomical performance jump. Was never gonna happen.",
      "Cards like the 5070Ti are pretty efficient. Most people run them undervolted and get way less than 300W while gaining performance compared to stock. I'd have to measure it but I think it sits around 220-250W most of the time",
      "%13-14 makes sense because core count is increased by %6 and power budget increased by %10.\n\nSpec increase looks very similar to 4080>5080 which resulted in a same ballpark performance uplift.\n\nOnly big difference compared to 4060ti will be at high resolution scenarios since memory bandwidth is increased more than %50. And even after that you need to have 16 gb version to see any difference.\n\nIf 429 USD price tag stays as reality, 16gb 5060ti would be much better choice compared to 4070 from last gen.",
      "Trust me bro",
      "but listen with DLSS adn Fake frame this shit is as fast as 4080"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "4060"
    ],
    "title": "[Gamers Nexus] More Marketing BS: NVIDIA GeForce RTX 5060 Ti Review & Benchmarks vs GTX 1060, 4060 Ti, & More",
    "selftext": "",
    "comments": [
      "It's crazy that a $429 5060ti is still nowhere near beating a $700 3080 from 2020. I remember buying my $300 1060 on release and it was on par with the 980 from the previous generation.",
      "It's wild to look at previous XX60 & XX60Ti cards and compare to 1-2 generations prior...\n\n* 1060 6GB is within 5% of the GTX980, and beats **EVERYTHING** from the GTX700 gen. It's 7% faster than the TITAN GTX.\n* 2060 Super was 12% faster than the 1080, and beats **EVERYTHING** from the GTX900 gen. It's 44% faster than the TITAN X.\n* 3060Ti is basically a 2080 Super, and beats **EVERYTHING** from the GTX1000 gen. It's 17% faster than a 1080Ti.\n\nThen it went to shit. TWO generations of XX60Ti don't even give the same uplift as ONE generation did before this.\n\n* 4060Ti is a coin toss between whether it even beats the 3060Ti  for any given game.  Which means it's roughly a 2080 Super... just like the 3060Ti was.\n* 5060Ti Is apparently between a 4060Ti and a 4070 non-Super. Which puts it between a 3070 and 3070Ti if you go two gens back.",
      "Hard to make any take on this card, because the MSRP might never be a thing.\n\nAt 429$ and with 16GB I still believe it's a decent buy, but I expected it to be closer to the 4070 based on 5070 vs 5070 Ti vs 40 Series scaling, I admit I was wrong.\n\nHowever I also expected it to cost at least 449$ since Leather Jacket doesn't want to sell vRAM on the cheap, so it kinda evens out, but obviously who knows what the pricing will be long-term and my standard was very low to begin with.\n\nOf course, from a generational perspective it's terrible, 3060 Ti was so much better in this regard.\n\nAt the very least, this thing is very OC'able, I have no idea why they didn't boost it to 3GHz from the get go, it would have matched the TDP anyway.",
      "Kinda sad how it has all gone to shit.",
      "Basically, it’s a slightly less awful 4060ti, thanks to gddr7 finally giving this thing alright bandwidth. The 8gb version is just to get people to spend more on the 16gb version, or for prebuild manufacturers to slap “RTX capable” on their system.",
      "I also compare a lot of these new cards to the 3080 in my head. It seems like the \"new midrange\" $500 - $700 market segment (4070, 4070 Super, 7800 XT...) has been stuck at or near that level of performance for soooo long now. 9070 XT and 5070 Ti are the first real shakeups in 5 years.",
      "\"This is our review and benchmark of the NVIDIA GeForce RTX 5060 Ti 16GB GPU\" \n\nLiterally the first sentence in the video description and it is mentioned from the start of the video. \n\nAlso, to quote Steve before they get into the benchmarks, he literally says\n\n \"Now today we only have the 16gb model, maybe we will look at the 8 later.\"\n\nNot only did you not read the video description but you apparently didnt watch the video either. Lol ur a fucking retard haha.",
      "Maybe if you live a decent country, in my area people sell 3080s for like 400-500$. And that's assuming you already have a PSU that can handle it, chances are people who shop for 60-class cards don't have a good PSU. So that's another +$$$ for the PSU upgrade.",
      "Nvidia gen-over-gen uplifts are so bad nowadays.",
      "Every (probably) review is of 16gb models, no 8gb cards were sent out",
      "\"5060Ti Is apparently between a 4060Ti and a 4070 non-Super\"  \nIt is a bit head-scartching that it cannot beat a regular 4070.\n\nSo I guess the only time that xx60 TI class card can beat a 4070 probably a 6060TI? (after 2-3 more years or so?)",
      "i dont know where youre finding those prices at...  i just checked marketplace and theyre going for 400-500 with a couple pushing 600 still.\n\ncant even get a 3060 non ti for under 300 in my area.",
      "Yea he talks about used one obviously",
      "you can buy a non-scalped 5070ti for less than that, it would be extremely stupid 😉",
      "3060 Ti is faster than 2080 super, imagine that",
      "Because there wasn’t a typical generational node change. Still on same 4n node as 40 series. Even if little bit of attention was paid before 50 series came out, this would be obvious.",
      "Next to no one is selling 3080s for $300 used lmao. If you’re going to make up lies for drama at least make it believable.",
      "The absolute state of it",
      "And yet they(5070Ti and 9070xt) aren't even faster than 4080",
      "Narrator: it won’t"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "4060"
    ],
    "title": "NVIDIA GeForce RTX 4060 Ti 8GB to launch on May 24th, a day before Radeon RX 7600 - VideoCardz.com",
    "selftext": "",
    "comments": [
      "400$ 8GB card incoming... 16GB will be 500$",
      "Are they banking on people not wanting to wait ONE day? lololol",
      "They're just banking on the 7600 also being terrible. Which it unfortunately will. 8gb of vram as well",
      "Good try but…\n\nhttps://videocardz.com/newz/amd-radeon-rx-7600-8gb-graphics-card-spotted-in-asian-store",
      "Why do AMD fanatics try to label people who buy Nvidia as making a dumb decision? Is it possible they value features differently? Is it possible they have different local pricing or availability?\n\nThe answer is yes. But AMD fanatics need to cope by belittling others' purchases as being made out of ignorance.",
      "this is said all the time here and elsewhere but man: The GPU market is absolute garbage rn",
      "That's definitely not terrible if it comes at a $250 MSRP. That's just a rumor now so we'll have to see if it actually launches at that price of course.",
      "Eh, what are people gonna do. Buy AMD cards? Lol",
      "Someone tell Nvidia ETH mining is no longer a thing.",
      "if I’m spending nearly $1000 on a GPU , I have to go Nvidia. thats just the reality of the situation.\n\nBut at the mid range, it makes no sense and hasnt really made sense since Pascal or MAYBE Turing.",
      "The video card market has been fucked since September 17th 2020.",
      "Or buy consoles instead of pc.    Actually a GPU alone is more expensive then the ps5 or xbox one X.  For a full upper range gaming pc capable of playing at a LG C2 55\" oled youre paying like 2k bucks.   PS5 + Xbox series x + TV + Gamepass for 2 years is less. Just saying (as a PC user who  paid like 1300 before covid)",
      "Unfortunately AMD has proven over the year they are not interested in making good GPUs, so why would anyone buy them?\n\nEven the AMD biased youtubers all have Nvidia/Intel builds lmao.",
      "It's a narrative pushed by AMD fanatics to try to justify AMD's poor market share. Instead of recognizing AMD's poor competition, they attack people for buying Nvidia. Anything but suggesting AMD improves.",
      "> 8GB is fine if your performance expectations are 1080p medium. Basically low end cards.\n\nJesus, this VRAM discussion has completely gotten out of proportion. My 3070 has 8GB and I game at 1440p180 on high settings just fine, granted that I don’t usually play games from the last 4-5 years which seem to be horribly underoptimized. War Thunder, PUBG, GTAV, even VR occasionally is what I run the most.\n\nNo, 8GB VRAM does not make a card “low-end” or set your performance target at “1080p medium”, that’s absolutely ridiculous. It does limit your options on games like RDR2 or AC: Valhalla, but as always it’s down to your preferences. If you’re not playing the ultra-modern, unoptimized AAA games, they are great workhorses.",
      "Well the 4090 was “only” $100 more than the 3090 at launch. But yeah for every other card they are way more expensive than the card theyre replacing.",
      "Nah its been screwed since late 2018. People love to forget that the power grab that was the RTX 2000 series existed.\n\nThat was the real time when Nvidia started their price gouging ####ery.",
      "Argue with whom? You won't find to many people arguing the opposite.",
      "lol nvidia's ego is just unbelievable",
      "8gb only? LOL"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "4060"
    ],
    "title": "[TechPowerUp] NVIDIA GeForce RTX 4060 Ti 16GB Review—Not",
    "selftext": "",
    "comments": [
      "Marking this PSA just in case someone is duped by videos, e.g. https://www.youtube.com/watch?v=tPiaWWd0xGc\n\n>We learned that neither NVIDIA nor the partners are sampling the RTX 4060 Ti 16 GB. [...] To prevent those reviewers who could somehow score cards in partnership with retailers, NVIDIA ensured there was no driver available until earlier today. Without drivers, there's no way for anyone to test the card [...]",
      "Geez, so not only did they not provide cards, they made it so no one could go through the effort of trying to inform consumers at all\n\nReally scummy stuff\n\n&nbsp;\n\nThanks for updating us",
      "Lol it costs about 7000 swedish crowns. That is 610 euros or 685 usd. Maaaaan",
      "Nvidia really fucked up in this generation...",
      "Thats a dirt bag move. Amd isn't much better tbh, but Nvidia pulling shit like this for the last year+ is why I got a 6800xt recently. I loved my 2060 super for what it was, but I'm not going to support a company with shady morales like this.",
      "Folks wanted a 16GB version and nVidia delivered! Bravo!!!\n\nNow can we have a RTX4050 with a MAX TDP of 75Watts!? Please!?\n\nThanks in advanced!!!",
      "They're going to fuck up the 50 series too.",
      "My 3070 was cheaper and you can get a 6800 XT for like 7500sek",
      "It would help if the card itself was fast enough, instead this card will be too slow for that memory to really matter.",
      "> Can they afford to though?\n\nCheck out their stock price. They absolutely can do anything right now",
      "See this comment from /u/kikimaru024 :\nMarking this PSA just in case someone is duped by videos, e.g. https://www.youtube.com/watch?v=tPiaWWd0xGc\n\n> We learned that neither NVIDIA nor the partners are sampling the RTX 4060 Ti 16 GB. [...] To prevent those reviewers who could somehow score cards in partnership with retailers, NVIDIA ensured there was no driver available until earlier today. Without drivers, there's no way for anyone to test the card [...]",
      ">Ada isn't a poor generation in terms of performance uplift, not compared to Turing anyway. The only thing wrong with the 4000 series is the price and the existence of the lower end cards I guess. If the 4070ti didn't exist and we went 90,80,70ti=70,70=60, and things were priced 25% less, everybody is happy I think.\n\nThat's.. quite a lot wrong, and having to shift the model number to make everything mid range and below look acceptable is a pretty big issue. Especially since they were planning to sell the 4070ti as a \"4080 12gb\".",
      "doubt it",
      "Nvidia be like: This card is up to 2 times faster than the 3060 Ti ! \\*\\*\\*\n\n&#x200B;\n\n&#x200B;\n\n&#x200B;\n\n&#x200B;\n\n\\*\\*\\* Tested on 1080P with DLSS upscaling on \"Performance mod\" with DLSS 3 Frame generation enabled on the Medium quality settings",
      "And get starfield \"premium\" version with one of those.",
      "Considering no one has been doing it, I'm not so sure.\nIt ruins Nvidia's forced upgrade schedule so I'm quite sure they've cracked down on that.\nThey clearly don't want their cards to have legs.",
      "The 4060ti 16gb isn’t even releasing yet!!! It’s on frickin pre-order until the end of the month!!!!!!! They don’t want consumers to know the card is trash so they are hiding it from reviewers",
      "Gotta love living with an (effective) duopoly 🥲. I understand why it's a difficult industry to start in and survive in (even without shady stuff happening), but it's still unfortunate for consumers.",
      "Ada isn't a poor generation in terms of performance uplift, not compared to Turing anyway.  The only thing wrong with the 4000 series is the price and the existence of the lower end cards I guess.  If the 4070ti didn't exist and we went 90,80,70ti=70,70=60, and things were priced 25% less, everybody is happy I think.\n\nIIRC the 2080 was roughly equal to a 1080ti in performance.  The only card which was an upgrade from the previous generation was $1200+.  It was so much worse.",
      "You forgot to mention the 3060 Ti used 1440p ultra for the comparison."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "4060"
    ],
    "title": "NVIDIA GeForce RTX 4060 is up to 18% faster than RTX 3060 in first leaked benchmarks - VideoCardz.com",
    "selftext": "",
    "comments": [
      "So new gen **60 card is slower than past gen **60ti. Remeber 3060ti is faster than 2080s",
      "Pretty sure they meant 18% faster than the \"RTX 3060\" 8GB version.\n\nSo my expectations for this card are the mariana trench ocean-rock bottom.",
      "It’s just so odd that Nvidia shat the bed so majorly on the rest of the 40 series lineup given how capable the 4090 demonstrated the tech could be. I guess they just really want to prioritize fab capacity for AI chips.",
      "The writing on the wall was when it caused EVGA to just nope out of their GPU business. Whatever EVGA learned about the Nvidia roadmap was that bad.",
      "At this stage of not being able to keep a good balance between cards they should just keep making 4080s and 4090s and scrap all the others.",
      "How dare you compare my precious 3060 12GB with this crap?",
      "With DLSS 3.0 on too, probably lol",
      "But 50% more expensive - with 25% less vram",
      "> It is literally in the article that they compare it to the 12 gb version.\n\nI downvoted you because I read the article and it does not state what version of the 3060 was used, it only refers to the 3060 12gb in one part where it talks about pricing.\n\nCan you at all clarify how you know the 3060 used was a 12gb and not the 8gb?",
      "Nice try Nvidia\n\nI still won't buy those shitty overpriced cards lol",
      "To be honest thats where NVIDIA really shines anyway. AMD is pretty much always better value for lower - mid range GPUs\n\nEdit: for clarification im saying lower AND mid range not lower mid range as one category",
      "Who cares really, show me FPS benchmarks.",
      "The Yuzu Dev's called the 4060ti a downgrade, so yeah i see your point nVidia beefed up a 4050, and called it a 4060, and that little bus is hurting badly.\n\nhttps://www.tweaktown.com/news/92003/nintendo-switch-emulation-team-at-yuzu-calls-nvidias-geforce-rtx-4060-ti-serious-downgrade/index.html",
      "I dont think they learned anything about upcoming tech. Isnt that why they quit? They said sometimes they'd find out information when the general public would and Nvidia would undercut their sales through the lineup.",
      "They had already built prototypes and engineering samples of a few cards when they decided to exit.\n\n[https://videocardz.com/newz/evga-geforce-rtx-4090-ftw3-prototype-has-been-unveiled](https://videocardz.com/newz/evga-geforce-rtx-4090-ftw3-prototype-has-been-unveiled)\n\n> What is interesting about this particular sample is that this is actually a fully working graphics card. It is equipped with a real AD102 GPU and even has working EVGA Precision software that reads all the sensor data. To make things even more intriguing, Jay was able to overclock this card to above 3.0 GHz relatively easily.",
      "You're defending one of the largest companies in the world nickle and diming on vram. Stop it.\n\nEdit: https://youtu.be/VdDr6Kb9PcY\n\nAdding for visibility, benchmarks are coming out every day. 4060 is slower than 3060ti lmfaoooooo.",
      "> loss leader \n\nthey arent losing money on any of the GPUs in the current lineup. the problem is that margins are much higher on datacenter and LLM enterprise products",
      "Bingo. One of the reasons Nvidia releases gimped GPUs with the same model name is so they can choose which version to benchmark.\n\nE.g. they want to make the 4060 8GB not look like the steaming pile of shit it is, so they'll bench it against the super-gimped 3060 8GB instead of the much better 3060 12GB.",
      "> is a loss leader \n\nThe margins on GPU are insane.\n\nThe 4080 has a BOM cost of ~300, but retails for 1200.\n\nThe BOM cost for a ryzen 4 die is ~50, plus another 25 for the IO die. Round that up to $100 BOM for single CCD and $150 for dual CCD. Single CCD selling for 200-300, dual ccd selling over 400.\n\nConsumer CPU and GPU are *not* lacking in margins.\n\nBut profiting $1000 on a GPU looks like a joke to them when they can profit $4000+ on the same thing sold to a data center.",
      "I roll my eyes at how 'blindly loyal' this sub is said to be"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "4060"
    ],
    "title": "Did my 4060 just died?",
    "selftext": "Might have been overheating it was nearly 25°C but wasnte even struggling was playing elden ring on high settings and ray tracing on medium and out of nowhere lines appeared in the screen and I immediately restarted my PC but now it's just this. I had this PC for a few months it was all new.",
    "comments": [
      "25c? that’s like \n\nfucking antarctic temperatures for a GPU. something has to be wrong because there is no way any gpu is reaching that temp unless you’re using liquid nitrogen in a AIO",
      "No is your VA monitor that died.\nAt best your monitor cable is bad or went lose.\nYou probably punched it after you lost to 0,1% HP boss.",
      "Omg nearly 25 C? Thats way too hot. Should be around 0-10C.",
      "Try reseating the GPU in the pcie slot, try using another HDMI cord, try using the VGA video output if your monitor has that, try using another monitor, there's a bunch of things you can try out before declaring it's fully cooked",
      "Idk my GPU idles at -5C …",
      "25? Bros gpu was colder than room temps near the equator",
      "That seems pretty optimal, you probably won the silicon lottery",
      "My 6800 xt reaches 30c at idle and can possibly reach 90 at the hotspot.",
      "This guy is from the lands between",
      "This guy has maidens 100%",
      "This kind of looks like a dead monitor to me. If your CPU has integrated graphics, try plugging your display cable into your motherboard and then into your monitor and see if you get a display or not. If you don't, could be your monitor or the cable itself. If you do, then yeah your GPU is probably cooked.",
      "If you can’t tell this is sarcasm. \n\nIdeal temps for a laptop cpu are 30-70C and maybe 80C, for a laptop gpu no idea, for a modern desktop gpu if you’re under 100C you’re good (50-90C is ideal), for a desktop cpu same as long as it’s under 100C.",
      "I was being sarcastic dude.",
      "Ohhh\n\nWell carry on sir. Nice chatting with ya",
      "I would probably say it’s cooked brother",
      "Reseat the gpu",
      "overheating at 25 celsius? unlikely",
      "Yes I agree with other comments, 25c is too LOW, it means something was wrong already and that something finally gave up. Now are you sure you were seeing gpu temp and not cpu temp?\n\nLuckily, being only a few months old means it should be still under warranty",
      "25°C is not even a hot summer day...",
      "It may be the monitor. 25c is not even idle temps for a GPU…"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "4060"
    ],
    "title": "Use RTX 3080 or stay on RTX 4060?",
    "selftext": "A friend is upgrading and offers me a free RTX 3080 but I already have RTX 4060, overall in gamings 3080 is faster but the card is older, and might break over time while my 4060 is brand new. I don't really play some heavy games, and I'm fine with my card.\nAlso we will probably trade cards, I get his he gets mine.\nOpinions?\nR7 3800x\nRTX 4060\n16gb RAM\n2560x1080 ultra wide monitor.\n\nEDIT: sry but selling is not really an option, it would be a gift from friend, I can't just make money out of it, also we would exchange our cards. He says he would like to use it for flawless scaling dualGPU (or try to use).",
    "comments": [
      "The 3080 will outperform and outlast the 4060 in all fronts especially on casual usage.",
      "If the 4060 can barely beat the 3060, and you're getting offered a 3080, why wouldn't you take it if has more of everything and 10gb.",
      "It's a better card.  Take it.",
      "For free? I would take it. If your PSU can handle it. It is solid upgrade, except warranty and power consumption.\nBut if you are going to repaste it and change pads, it should be fine for years to come",
      "This. Lol.  Pc components usually don't just die. Shit all my gpus have been used. My 3080fe I got last Jan for 300 and it's amazing. Bought my 5800x3d 3 months ago for 250.  Most cpus and gpus will last longer than they are worth anything\n They will be ewaste someday before most die. \nIm finally getting a new gpu this year only cause I run a large uw and the 3080 just isn't powerful enough. And i plan on gettinf the 5k2k lg oled. So I'll get a 5080fe in like 6 months or so hopefully when the stock issues end",
      "A few parts do have a decent likelihood of dying before they’re ewaste. In order from most to least likely:\n- HDDs\n- Fans\n- PSUs\n- SSDs\n\nAgree for all other PC parts though",
      "He doesn't need to repaste and change pads. It's a few years old. Stop scaring people. Ive repasted many cards and haven't touched my 3080fe. I got it used last jan for 300ish and it runs cooler than most others still.  There is zero reason to EVER repaste and change pads unless there is an issue with temps or you enjoy it. Shit I repasted my old 1070 and changed the pads that's in my server and it did NOTHING. Lmao. Zero difference. Well, maybe 1 degree. But I dont pay THAT close attention. \n\nBut otherwise yes. Homie should do this in a heartbeat. 3080 shits on a 4060.\n\nIt will be fine for years to come without everrrrr touching it. Maybe in a decade. But even then, if it's not over heating and thermal throttling, there is zero reason to repaste.  People do it because they enjoy it, not because it needs to be done.  Some got defective cards throughout the years of different gens and are sooo desperate they try fixing it instead of returning it. Which is sad",
      "Immaterial. Frame generating from 30 fps is garbo.",
      "If free, absolutely take them up on it. the 3080 is a beast of a card and at absolute worst you still have the other card as a backup. So who cares if it breaks ya know? It isnt like you will be worse off.",
      "You can still use the upscaling and ray reconstruction part of DLSS 3. You only lose access to frame generation, which I barely ever use and I have a 4080. 3080 is so much faster than 4060 that frame gen is not a concern at all",
      "fyi you can also undervolt the 3080, and keep it at 280w while having same or even better peformance in most games, you can go more aggressive if you’d like even less power",
      "take it",
      "I agree. Chances are the average gaming pc will be ewaste before any part dies. Consumer SSDs are definitely problematic. Only reason I put them last is because I’m an HPC engineer talking from an enterprise perspective. Enterprise SSDs are leagues ahead of consumer SSDs for reliability.",
      "Unless you need the AV1 encoder & DLSS Framegen, you can keep the 4060. Otherwise, everyone else has said the 3080 is the superior card. You get it for free, and have 2gb more of VRAM + better performance.",
      "I would take the 3080. Much much faster than 4060, like 65% faster, with more VRAM.",
      "I'm casual, don't have skills to repaste. I asked others to build me a PC. And I will probably not upgrade for many years, that's why I'm considering staying on newer card.",
      "C’mon man, why would he sell a gift?",
      "Beefy? I’d have a 750W",
      "Yes, 30-series was one of Nvidia's best in recent memory. Only issue is 10GB on the 3080. Still more than the 4060, but they really should have given it at least 12, minimum.",
      "Then sell both and get a 5070 or 5060ti 16gb. Ask your friend if he's fine with you doing this first of course."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "4060"
    ],
    "title": "My 4th PC Build (4060 & i5-12400F)",
    "selftext": "",
    "comments": [
      "Cutest little twink pc.",
      "I never comment on builds but man do I ever like the look of the good old mustard and ketchup cables.",
      "negative, all 4070 and above are 200mm+, case gpu length max is 195, mine was shorter yet was still a SUPER tight fit. ty tho, cheers!",
      "well said and nice observation! curse this psu for non modularity (gpu side crammed) but surprisingly its gold rated 🤩😏",
      "Looks good! A silly question, there is space for a 4070 super dual fan?",
      "Thanks for the info! Happy gaming!",
      "thx! 🫶💝 its the ZZAW A1P (Zen Zone Art World A1 Plus) 5.8L and comes with a x16 gen 3 riser",
      "What?",
      "Looking good! What case is that btw? Been meaning to downsize the living room PC now that I have a low-profile GPU to throw in it.",
      "JBL goat",
      "ZZAW A1P (Zen Zone Art World A1 Plus) & FSP Group FSP400-60FGGBA",
      "i agree, amen\n\nhttps://preview.redd.it/n1t03wvwp6wd1.png?width=361&format=png&auto=webp&s=0dae160fcc09d954f5a6b6f2b470b233ec53e0ae",
      "😋😼💖❤️‍🔥",
      "Wow thanks! That's surprisingly cheap for a little case like this. Is there a way to do a more conventional layout inside with a low-profile GPU, or is it strictly sandwich layout?",
      "What case and power supply are those?",
      "Nice!",
      "beautiful",
      "Toight",
      "what a cute lil thing. i wanna give it a lil kiss on the cheek 😘",
      "Look great and well thought out. Have you test the CPU temps? I would be a little worried about the air getting in the top."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "4060"
    ],
    "title": "RTX 4060 is an amazing GPU, at least for me.",
    "selftext": "So, because of the immense level of hate this card has gotten, I'm here to defend its merits, just a bit ;-)\n\nFIrst of all, I am playing LORERIM (4000 mods Skyrim modlist) at ultra settings with ENB on at 60FPS constant, 1080p resolution, and that blows my mind. Because of the 8GB memory I have to use VRAMR and frame gen to avoid stutter but still.... I can play possibly the most demanding game exisiting now at ultra settings at 60FPS, with a 300 EUR GPU, with no perceived input lag on a controller, and I'm delighted and amazed!\n\nSecond, the 4060 ony draws around 100-115 watts at full load, mening I'm saving in time A LOT of money, here in Italy.\n\nThirdly, I love all the various Nvidia playback and recording codecs and tweaks including frame gen, visual enhancements and upscale to the point I watch youtube at low res (cell phone conection, up in the mountain) upscaled to fullHD and I added Losslesscaling on top to watch Studio Ghibli movies and anime at double frame rate, which is TERRIFIC, let me tell you.\n\nLastly, if you bought a 700 to 3000 USD card drawing anything from 200 to 500W, well that's your choice and be happy with that!\n\nJust let me know your frame rate and setting in a game like LORERIM cause if it compares with mine...\n\nWell, with your money you do what you want ;-)\n\nThere are many reasons why this is the first or second most bought card in 2024 and 2025. I hope I explained a few.\n\n\\---You are free to continue with the hate if that's what you like to do but remember: If you do not like a product nobody forces you to take it (with some exceptions: like the c...d v..xx which, by the way, nobody has ever truly forced you to take)---\n\nTake care everyone and enjoy your games",
    "comments": [
      "Cool that you're using a lot of mods, but you realize that Skyrim is a 14 year old game by now right? None of this is impressive.",
      "The best GPU is what our money can buy. Comparission is the theft of joy. Enjoy what you have",
      "scripts that run on the cpu. the base game engine is still the same. the webpage for the mod itself says its optimized for medium specs so suggesting that the 4060 is doing more work than it should is silly",
      "Not a bot, man. Truly madly deeply not a bot ;-) Not even a fanboy of Nvidia. AMD cards might be great as well, or not, depending on the card. Just a happy customer.",
      "4060 is a fine card, my time with it gaming at 1080p was perfectly acceptable. Demanding games needed DLSS quality to be enabled but that's what it's there for.\n\nA lot of the people jumping on the negativity bandwagon on a thread like this will be banging on about VRAM. Coming from a 2060 which only had 6GB of VRAM, 8 felt like plenty for the resolution. Most games I could run high textures at 1080p without breaking the limit.\n\nAnd there's price. My 1660 super new cost as much as the 4060. So for me the price was reasonable too.",
      "Yeah, Im also rocking 4060 I borrowed from my brothers, its really capable once you start using DLSS on perfomance. I have it on 1440p and its more than enough if you dont want 180FPS+ \n\nPeople are hatin on it cause the reviewers told them so! Its a great GPU, now if only the price was great too! :D",
      "It's an amazing GPU until you run out of VRAM.",
      "The salt here is heavy. I'm glad the card checks all of the boxes for you. It's refreshing to see someone with some actual optimism on Reddit. I have a 4060 Ti 16GB that I got at a steep discount. The power draw is really appealing for my use cases. Keep enjoying your card and just ignore 90% of Redditors. They just like being angry.",
      "If someone bought a 4060 to play games at 4k then that's just dumb. It's designed for 1080p.",
      "This is extremely weird, it’s like complain about a tractor poor highway capabilities.\n\nIt is a 1080P card.\n\nThe 4060 simply can’t run modern games at 4k.\n\nEven if it had 34GB of vram, it isn’t because of the vram, it doesn’t has the freaking performance for it.\n\nFor gods sake, I have a 4090, my average frame rate in games from 2021 to 2025 at native 4K single player games , is of about 80-100fps.\nWith some running at 120 but others at 40-50 too.\n\nConsidering the 4090 is 3 times faster and more powerful that would mean the 4060 would have an average of 26 to 33 fps on this games.\n\nThis is without RT.\n\nWith RT my 4090 averages about 60fps at native 4k.\n\nConsidering the 4090 is like 4 times faster than the 4060 with rt, that means an average of like 15 fps at 4k with RT for the 4060 EVEN IF IT HAD 32Gb of VRAM.\n\nAnd if you  are using the 4060 to play older games at 4k, 1) older games are much lighter on vram use, so it might not be a problem anyway\n\n2) most older games don’t have 4k textures, so you get some anti aliasing advantages from doing 4k but you are mostly wasting fps.\n\nExtremely niche and weird scenario to buy a 4060 yo play old games at 4k.\n\nThe reality is that 9/10 people buy the 4060 for 1080P gaming at Wich res it has sufficient VRAM and it simply doesn’t has the raw performance to be vram bottlenecked at higher resolutions too.\n\nLike I said, they made tests where they compare it to similarly performing AMD cards at higher resolutions too, with the AMD card pulling much further ahead in this resolutions, due to its higher vram, than it does at 1080p. Wich ON PAPER suggests that VRAM is actually choking the potential performance of the 4060.\n\nBut then when you actually take your time, to check the numbers on this reviews, you see things like the AMD card getting 30fps and the 4060 getting 25FPS. And it’s like yeah but no one wants to play like that, what would be the actual performance difference is they used dlss performance at 4k so that they can get 60?\n\nWell it eliminates the vram bottleneck, since the internal res is now 1080P again and bam, similar performance again.",
      "Trying to enjoy your purchase in this sub?\n\n*Fatal mistake. Last mistake.*",
      "I’ve built systems with 4060s for 3 friends of mine, and it is super rare and super hard to find a game where you run out of vram at 1080P resolution.\n\nOr to be even more precise, to find a game where VRAM is limiting the raw performance capabilities of the card.\n\nBecause yes, it can run out of vram at 1080P when playing a game with PATHTRACING for example.\n\nBut it is also not capable to hit even 25FPS with Pathtracing, Pathtracing is meant for 1,000€/$ + GPUs it’s an experimental feature, not meant to be used on an entry level 280-300$ GPU anyway.\n\nWith normal settings with wich you can actually at least hit 60fps, there’s very few games, if at all, where the 4060’s 8GB of VRAM are a limiting factor.\n\nThe vram of the card is very on par with the performance capabilities of the card. People get confused a lot with this:\n\nit’s not about x youtuber proving it can run out of VRAM, wich x settings, it’s about:\n\n-yeah but are YOU going to play the game at THOSE SETTINGS despite it meaning you are getting 35-45 fps average? Or would you actually either turn off RT or turn on DLSS quality? To get at least 60+ fps?.\n\n -I would turn on dlss or turn of RT.\n\n-then you won’t run out of vram, because either of those choices reduce the vram consumption SIGNIFICANTLY. \n\n-oh…\n\nA 3080 10GB is actually more tight on vram for 1440P gaming for example.\n\nOr an 8GB cram 3070 used for 1080P wich is seen a lot too, that card will push settings that it’s VRAM might not be able to follow. it’s easier to find examples for this 2 cards.\n\nBut someone buying let’s say the 12 gb 3060 instead of a 4060 despite it being 15-20% slower just for the 4fb of vram, is very ignorant.",
      "OK? None of that changes the fact that Nvidia is making the deliberate decision to pair extremely powerful GPUs with not enough VRAM. Adding more VRAM would not raise costs that much anyway.\n\n\nWe had mainstream 8GB GPUs 7+ years ago. The upcoming 5060 is going to be as powerful as a 2080 TI which had 11GB of VRAM. This is bad for the environment, bad for the consumer, and bad for game developers.\n\n\nEdit: and to add on, that super power efficient GPU isn't actually as efficient as you think it is. It's limited by the 115w power cap that is way too low.",
      "That’s awesome it works for you. Enjoy!",
      "Doubt its as demanding as cyberpunk with PT or maxed out alan wake 2. Try those and reality will hit your face. Plus 60 fps with framegen must be absolute disaster of a experience.",
      "The upscale comes from the 4060 itself, not from Losslesscaling. It auto-upscale low res videos in browsers when the resolution is below HD.",
      "Cause I'm enjoying my Gpu ;-) In spite of all the hate. I care nothing about Nvidia or AMD or Bill Gates... I'm just counterbalancing the misinformation by simply stating I'm more than fine with it.",
      "I created my new RIG recently with a DDR5 ram-motherboard, all quality components from the case to the Nvme SSD, so I'm fine with that. I spent around 1000EUR but I saved A LOT with the 4060. A lot of GPUs costs more than my whole new pc.",
      "I have a 4060/13620h laptop that runs cyberpunk at 1080p with path tracing using dlss quality/framegen at 60-70 fps (or 80ish if I change to dlss balanced). Honestly it still amazes me that I can have that level of graphics on a laptop.",
      "You are right: always 1080P, as my LCD TV."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "4060",
      "4060ti"
    ],
    "title": "DLSS 4 is the savior for RTX 4060 and 4060TI with 8GB VRAM",
    "selftext": "Seriously the new Transformer Model is an absolute Game Changer for the 60 Cards from 40 Generation.\n\nSo far my 4060 TI could barely handle Raytracing at 1080p with Quality DLSS and it still looked like Dogshit in Cyberpunk 2077.\n\nNow with the new Transformer Model i can lower it down to Balanced on 1080p or Performance on 1440p with RT set to Ultra. Without Frame Gen its around 55-60 FPS now and looks almost like Native.  VRAM Usage hovers around 7GB only. With the addional Frame Gen it gets to around 110-120FPS and 7,2GB Vram usage. The Input Lag is almost non existant because of the good Base Framerate. With old DLSS to archive this quality i had to use Quality DLSS which gave me around 30Fps without and 55/60 with Frame Gen with a huge Input Lag.\n\nBefore Nvidia released DLSS 4 i was sure to buy the new 5060TI 16gig when it releases but now i will definatly wait for the 60 Generation because DLSS definatly gave the 60 Cards of previous Generation new Life for 2-3 Years for sure.\n\n  \nHow are your experiences with the 4060 and TI with DLSS 4 so far?\n\n  \nThank you Nvidia!",
    "comments": [
      "Why doesn't my nvidia app don't detect the new driver? \nIt's already released right? \nMine still said 566 is the latest.",
      "Yeah its released. The whole Nvidia App does have Trouble with DLSS4 right now. Best Thing U can do is uninstall everything with DDU and then manully Install The new Driver which includes The Nvidia App. And then activate DLSS 4 globaly with the Profile Inspektor Tool and The Tool DLSS Swapoer. Because some Games are still greyed Out for DLSS Oberried eben after fresh Install. The are plenty of Guides on YouTube in how to do it with Profile Inspektor and DLSS Swapoer.",
      "Dlss 4 saved 1080p gaming for me",
      "You Capitalise words In a Weird way.",
      "Ah ok just wanted to check your CPU wasn't bottlenecking you.\n\n\nI only recently upgraded from a 5 3600 to a 5700x3D and couldn't believe what a difference it made.",
      "This guy ate all the marketing hype and is happy about it",
      "That's some serious copium. U have a 4060ti so almost the lowest of the lowest 40 series. U aren't hitting 100+ frames maxed out cyberpunk bro.",
      "This is black magic!  I'm suddenly playing CB 2077 in 1440p with RTX ultra and it looks and runs amazing on a RTX 4060.",
      "I feel like it’s very heavy on compute, and could use a lot more polished, especially compared to DLSS 3. Currently performance mode is as heavy as balanced or quality upscaling using the old DLSS on a 4060. More powerful cards don’t seem to take as big of a hit. With the latest drivers it’s outright broken in Control. \n\nI can see it’s potential though. Tried it in Witcher 3, and the stability in motion is fantastic. Normally with TAA or any temporal upscaling, the image blurs significantly in motion. But with DLSS 4, things are very sharp, and that barely changes when moving around. Vegetation is a bit unstable though for some reason when standing still, and other artifacts show up.",
      "They're not neglecting users using their cards for work purposes. They make an entirely different product line exactly for that use case.",
      "What CPU do you have? \n\n\n\nI have a 4060 (non Ti) and use 1080p Quality with RT and I get my 58 capped FPS pretty much consistently.\n\n\nI have every setting set to High, with RT lighting set to Ultra.",
      "The speed is the same, but I load 11 to 15gb vram easily in cp2077 going path tracing and forcing hires textures",
      "He's playing a single player game lol. Who cares.",
      "Tbf, it's nvidia who had 8GB VRAM in a 400 dollar card",
      "Ok i thought it was mine only.\nThanks 👍",
      "My CPU is only bottlenecking in Dog town at The pyramid in Phantom Liberty DLC. But yeah Phantom Liberty DLC asks for 8core CPU and Mine is 6. I Plan on upgrading to 5700x3d too, awesome price to Performance and it gives me The two Missing cores and gives a few more years Out of my system. 5600x is great but The additional L3 Cache From 5700x3d is Just too tasty",
      "I got everything on very high and ultra If possible Not Just high ;) And i use a Ryzen 5600x",
      "At least RTX Mega Geometry is promising in Alan Wake 2 the first game its in. \n\nThis feature is for all RTX gpus 😁",
      "I agree, I'll try it out too. I'm glad the feature isn't exclusive for 50 series",
      "Nvidia should probably rethink the scaling presets with the new model. They could definitely go one step lower, below current ultra performance, would be useful for 4k."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "4060"
    ],
    "title": "Should I buy 3060 or 4060 in 2024 for my first pc ?",
    "selftext": "I'm confused about which graphic card I should buy since there are mixed reviews on 3060 saying its better than 4060 but is 3060 really worth it to buy in 2024 because I want to be future secure aswell please any kind of insights would help",
    "comments": [
      "You want better performance? Buy the 4060. You wanna spend less money? Buy the 3060.",
      "You want better performance? Go second hand and buy a 3070 or even 3070 ti for the same price.",
      "4060 is obviously better for performance. 3060 is just very popular cause it was a budget card which supports ray tracing",
      "i) Some high refresh 1080P GPU suggestions:   \n- For around 285-330 USD, the RTX 4060 8GB or RX 6700XT 12GB   \n- For around 370-390 USD the RTX 3060 Ti 8GB   \n- For around 370-399 USD the RX 6800 16GB or RTX 4060 Ti    \n- For around 390-430 USD the RX 7700 XT 12GB     \n- You can also look for a good quality used RTX 3070 or 3070 Ti.   \nii) Nvidia GPUs have slightly better upscaling (DLSS 3.X) and Nvidia RTX 4000 GPUs support better frame generation (even though AMD's frame generation has also been improving lately).    \niii) Look at Techpowerup's review of the RTX 4060 (https://www.techpowerup.com/review/msi-geforce-rtx-4060-gaming-x/31.html), and the average FPS:   \n   **At 1080P:**   \n   The RX 7700 XT 12GB averages 137.9 FPS   \n   The RX 6800 16GB averages 132.3 FPS   \n   The RTX 3070 Ti 8GB averages 128.2 FPS    \n   The RTX 3070 8GB averages 121.3 FPS   \n   The RTX 4060 Ti 8GB averages 116.5 FPS  \n   The RX 6700 XT 12GB averages 110.1 FPS     \n   The RTX 3060 Ti 8GB averages 106.4 FPS  \n   The RTX 4060 8GB averages 96 FPS",
      "I think bro likes both his kidneys more",
      "Why was my 2060 a good 1440p card back then but now 3070s and 4060ti are considered a 1080p cards? Do people benchmark only with the most demanding games these days?",
      "My guess is the 8gb vram. Reviewers hit the popular games which is usually the most demanding title needing a good chunk of vram. We are seeing even 1080p some games above 8gb vram. 2060 was more entry level 1440p i feel but better suited as a high fps 1080p card ideally.",
      "4060 for sure. It runs cooler, uses less power, has frame generation support via dlss, is more modern and will save you money on the long run depending on energy prices at your place.",
      "4060.",
      "You want to buy the future performance? Wait and buy 5070",
      "UE5 isn't the problem, the dipshits making the games are. The industry layoffs are unironically a good thing, because no one can justify taking 7+ years to make heaving piles like Starfield and Concord.",
      "Gigabyte is an aib they make amd and nvidia cards. They get the gpu chips from nvidia or amd and then make their own boards and coolers around it. So at their core it is still an nvidia gpu with gigabytes name and cooling solution on it.",
      "Objectively it’s true that it supports ray tracing. Whether you’d want to play a game while it’s turned on using this card is another question entirely.",
      "easily the 4060 then.",
      "😂😂",
      "I will say 3060 12 GB",
      "The 4060, so you can use DLSS 3 if needed.",
      "2060 released at the end of a console gen, so it could mop the floor with any game. Now look at the UE5 garbage...",
      "“Burned out from crypto mining” isn’t a thing. Ppl thought it affected the card but it’s been debunked",
      "are they the same price? then 4060"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "4060"
    ],
    "title": "AMD Radeon RX 7600 and NVIDIA GeForce RTX 4060 Ti 3DMark performance leaks out - VideoCardz.com",
    "selftext": "",
    "comments": [
      "So wait let me see\nHmm..... \nNot worth it",
      "I'm an AMD fan and have a 7900XTX in my PC (6900XT in my prior PC), and am very very happy with it. \n\nIf the 7600 8GB is over $250, let alone $300, it's DOA. People would be much better off with a 4060 for the same price since the performance is so close, but the 4060 will use less energy and have a more robust feature set. Look at current prices of the 3050 VS the much stronger 6600-6650XT to see an example of what will happen if the 7600 launches at the same price as the 4060.\n\nAMD has huge margins this generation. All they need to do to claim some market share is keep their prices as low as possible. That's what you have to do if you want to gain market share, but it seems they just don't care enough and are happy about remaining a distant 2nd to Nvidia.",
      "Only 35% uplift 6600 to 7600\n\nMassive 10% uplift 3060ti to 4060ti\n\nGreat job Nvidia.",
      "Was pretty much a given.",
      "I don't think discrete GPUs are a core item in their business model. I get the choice to prioritize Ryzen over Radeon back when they were teetering on the edge of bankruptcy. Since then, they are on a much more solid foundation but I just don't think they are making the investments in GPUs like Nvidia does.",
      "The turtle vs snail race that we all have been waiting for... \n\nOmfg the turtle blasted that snail!\n\nWhat a beast, I would pay top money to possess such portentous performing specimen",
      "Yet more evidence that every card this generation was bumped up the product stack name list at least once.",
      "They raised the price from $650 RX 6800 XT to $900 for the ~~RX 7800 XT~~ RX 7900 XT. I think AMD thinks so",
      "Or AMD prices theirs just barely cheaper than Nvidia and we all lose",
      "Strange results since my 3060ti scores close to the 4060ti in time spy (\\~13100 graphics)",
      "So should I just keep my 3060ti",
      "Narrator: 5000 series, was in fact, worse than the 4000 and 2000 series.",
      "We already are because there is no competition anymore. RDNA3 is a flop.",
      "BUT BUT BUT 8GB of VRAM IS PLENTY AND MORE CACHE MEAN BUS NO SMALLER\n\n*4060Ti 9% off of 3060Ti in 1440p*\n\nThis means the 16GB 4060Ti for $500 will likely lose to the 3070 in 1440p till the 3070 runs out of VRAM.",
      "Hope you are wrong. We really need competition in gpu market, else we are fucked…",
      "Yes. Just wait till the 5000 series. That’s what I’m doing. 4000 series ain’t the play.",
      "Yeah but hardly. It's a new gen, it shouldn't be that close.",
      "Also worth noting that most likely the 7600 won’t come in at the same price as the 6600. Which is good since the 6600 MSRP was terrible. \n\n$299 is the most this card can reasonably be sold for. To be a good pick $249. We will have to see I guess.",
      "I mean, that’s Intel.  But (a) can they actually catch up and overcome starting up drivers from nothing? and (b) it’s Intel, and they showed in the CPU market for years exactly how little interest they have in providing value unless directly forced to do so by AMD.  Nvidia at least has historically “competed against themselves” sometimes, even when AMD was well behind.  Though recently they look more like Intel.",
      "The comparison video that nvidia made between the 3060ti and the 4060ti in returnal shows around 30-40 fps and it had frame generation on. That card is a joke..."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "4060ti"
    ],
    "title": "4060ti 8gb or 16gb",
    "selftext": "I want to upgrade my pc because my gtx 1050ti served me well after 6 years.\nI want to get a 13400f with a rtx 4060ti but idk if it’s worth 100usd extra to get the 16gb version( I mostly play fivem, cs and vr games) the res I play in is 1080",
    "comments": [
      "Neither Card is worth it, watch gamersnexus reviews on the 4060 ti and HUB on the 16GB variant if you don't believe me. Your much better of getting a 4070 non super, If thats out of your budget and you need a gpu NOW cause your 1050 ti died. Either get and amd 7800 xt, 7700xt, or a used 3080, as all three cards will perform way better than the piece of garbage known as the 4060 ti. If you need a new Nvidia GPU now and AMD is not an option then get a 4060 Non Ti for $100 cheaper.",
      "4060Ti is not garbage, not at all, it’s just badly priced product.",
      "Price is everything, when it comes to how good a gpu is. If they had called the 4060 ti a 4050 ti and priced it at 249$ it would be a really good gpu.",
      "don’t care what other say here, i’ve a 4060Ti. it performs well in all the games i play at 1440p\n\nEdit: i have the 8gb variant of it, and it runs amazing on all the games i throw at it.",
      "No",
      "You gotta love people that ask advice then not listen to any advice given.",
      "To poorly quote Zachstechturf\n\n“There are no bad GPUs, only badly priced ones.”\n\nA GT1030 you picked up for 5 bucks is technically a good deal. If all you want is a GPU that can output video, play the lightest of games, and can fit in pretty much any case, there you go.",
      "people just don’t understand that not everyone has unlimited cash. and for what it’s worth, 4060Ti is a very capable card which requires so less of power.",
      "please do NOT get a 4060ti for those use cases. Any AMD or Nvidia card will be just fine for those applications. Get a 6800, 6800xt, 7700xt, 7800xt, used 3080, or 4070 non super PLEASE. The will perform so much better it isn't even close.",
      "The only time the card makes sense is inside space and power constrained itx builds. It is a solid 1080p card. I personally enjoy mine and went with 16gb as well. Despite what people say it can and does perform in 1440 and 4k.",
      "\"Spend more money if you have money\"",
      "Ehh since Vr is pretty demanding, compared to traditional  1080p gaming I would get  a 4070 non super and its 12GB of VRAM. 8GB on a 128bit bus on the 4060/60ti  is not gonna provide an ideal experiance.",
      "I think they want justification more than advice but it may be budget reasons more than anything.",
      "7800xt",
      "They’re both bad. If the 4060ti 16GB is in your budget, then find a way to stretch it to the 4070, or buy used 30 series.",
      "I have the 8gb one as well and I play literally everything at ease and I'm coming from a 3050 laptop🤷🏼‍♀️\nI don't understand degrading someone just because they have a different opinion than you Jesus fuck grow up people and get the dicks out of your ass",
      "All the 40 series cards are a horrible value, but at least if you get a 4080 or 4090 you’re getting more power than you can get elsewhere so there’s an inherent value there. \n\nI have a 4080 myself, it was stupidly expensive for a gpu for me, I would have just stayed on 30 series had I not gone up to that tier at least",
      "Well its because its not worth the 100",
      "Dude, I'm using a 4060 TI right now and it's not bad. It actually runs all the games pretty smoothly",
      "Rendering and ai apps benefit a lot from double vram. As for games, there are games than run way better on 16gb version than 8gb, even at 1440p many games use 10gb or above, 16 is overkill a bit for that since you will not reach it, but 12 gb is must these days"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "4060"
    ],
    "title": "My first shock when switching from a 2060 to a 4060 TI: Frame Generation works way better than I imagined. Pure black magic",
    "selftext": "&#x200B;\n\nhttps://reddit.com/link/17twmrf/video/sarvzdi2000c1/player",
    "comments": [
      "The only thing that needs some black magic is your driving skills 🤣",
      "It really is a game changer. I went from a 2070s to a 4070 and I can max out pretty much all my games now.",
      "Bro I swear it's not my fault, this car is just horrible haha",
      "I've consistently found those that oppose or throw shade at it the most, are the users that can't actually use it, and have never seen or played a game with it on themselves, with their own eyes and hands.\n\nBasically like DLSS2, right up until FSR came out, at which point compatibility was touted as the only thing that matters and DLSS needs to go die in a fire already.",
      "It does, *yeah*. I' have to confess, even my mind was so set on the *initial findings from DF* with the spiderman footage and glitches - I failed to check what progress has been made. It's...quite something! I can not see artifacts anymore - it's just too consistent. DLSS is visible - obviously - but that's partly what I want and partly par for the course. There is no better AA to my eyes, period.\n\nPersonally I can't use Frame Generation that happily and readily since I my eyes crave for distortion and tear free images =) \nBut once you can live without any VSNYC, and just accept that your response-time-feeling is at the original framerate (and not what you visually perceive) - it's rather nice!\n\nDLSS and RTX go hand in hand for me, and have been ever since I got the 3070 around early 2021. Cyberpunk, even then, was **CLEARLY** where I personally would like games to go: Embrace ray/pathtracing for what it is and utilize it. The new Overrive Mode (let's just call it that, I don't want to confuse others further) is my default now. Yes, Phantom Liberty demands everything from my rather light rig, but I can't unsee what profound differences the Overdrive mode CAN make. And DLSS and now FG enable my PC to do just that. \n\nBut I can also see why so many - who do not have seen it in action themselves - have reservations. Wouldn't we all?\n\nFor anyone super curious, I'd recommend the recent Digital Foundry Roundtable video. Yeah it's long, but this is seachange-level, emerging technology. So it's not that trivial to get the implications - at a glance.\n\n*Have fun Lucas!* =)",
      "DLSS 2 still destroys FSR 2, especially on lower resolutions but even on 4K performance",
      "It's an actual ram kit 2x24gb btw",
      "I totally agree ppl under sale it so much (hardware unboxed). I can see there reasoning but to a casual like myself If I didn’t know it was there I would think it was native same with dlss. It wasn’t until I built my new pc that o learned about rasterization v native.\n\nPs I also came from a 2060 super and I never new that raytracing was so amazing but dlss and frame gen allows me to run Alan wake 2 and cyberpunk at such high settings I’m blown away",
      "It's not THAT bad.\n\nAlso, the car OP is driving is the first car you get in the game.",
      "That's how I felt when I used DLSS for the first time. I'm hoping frame generation will feel the same way the next time I upgrade.",
      "it is black magic IF you are able to maintain framerate over 60fps, preferebly 70-80. If goes under 60fps intro 30 40s then you will know its not so black that magic",
      "I use that excuse in real life too",
      "How so? Im playing Cyberpunk in 4k with Path tracing and my avg fps in the city with FG is around 80 FPS, without it probably around 45. I dont see any problems. Game feels and looks good",
      "Feel me i went from 1660 ti to 4070",
      "I'm upgrading from a 1070ti to a 4070ti. Haven't tried DLSS not even once so I don't know what to expect.",
      "To be fair, driving in Cyberpunk is just awful",
      "That won't hold up in court.",
      "1440p on the 4070, on the 2070s I was on 1080p.",
      ">and just accept that your response-time-feeling is at the original framerate (and not what you visually perceive)\n\nThis was the weirdest thing for me when I first got my 4080 recently. So weird to see like 80-100 fps and still have it feel like 40-50 in terms of responsiveness. Still for some games, I will absolutely take that over the slower responsiveness and lower framerate.",
      "But if it's the type of game where split second reaction time or ultra precision aiming isn't strictly necessary, and the choice is between low frame rates and the slow responsiveness or high frame rates and slow responsiveness, then I would choose the higher frame rate pretty much every time.\n\nSo it's very clearly not just \"free\" frames, but I absolutely see the benefit in certain situations."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "4060"
    ],
    "title": "4060 to 5060ti?",
    "selftext": "So I bought a 4060 a month ago (my mistake) and I saw that the 5060ti just came out. I was thinking of returning my 4060 and buying the 5060ti instead, should I do it? (16gb version) \n\nAlso my gpu before 4060 was 2060 so it will be a huge upgrade",
    "comments": [
      "Why do you want the 5060ti?",
      "Get the 16gb card. Good luck.",
      "I would never 8gb. It's basically criminal in 2025",
      "depends on pricing if its worth or not but not really looking so hot based on reviews its equivalent of a 3070 ti",
      "get rid of that 8gb card at all costs I don’t care I will argue with anyone here it’s unacceptable\n\nif you can get a 5060ti at Msrp go for it, i’m in UK/Ireland for GPUs today on overclockers there was a 5060ti 16gb  for £399 ready to add to basket \n\nDefinitely return that card seriously- I would recommend Intel to you for better price to performance, but I assume you are pretty set on staying with Nvdia \n\n5060ti is not amazing value, it’s okay uplift 15-20%+ from the 4060ti which was just a terrible GPU anyway\n\nIs it worth £120 more than a b580? (£275 on price runner quick check) fuck no, but if you want multiframe gen and good 1080p performance then go for it \n\nJust please return that 4060 I don’t want you having to experience VRAM issues it should be illegal to market a card released in 2025 as a modern gaming card with 8gb of VRAM",
      "Because it seems like a good card especially with dlss and compared to the 40 series it seems better so",
      "You’re so tired you don’t even fight Nvidia anymore, just rolled over and recommended the 16GB, I feel you man🤣",
      "I don't really want to change to Intel because I have seen the card isn't that really stable and even if they have fixed it then it feels like the 5060ti is the better option for me. And If I don't get it, what card am I supposed to get? I want my PC done before summer and I need a good graphics card, I got pushed to buy the 4060 and I was hesitant but my friend said that the b580 is shit so I believed him but here I am returning it. So all I want is a 500€ gpu. (I live in Sweden and everything is 100€ over MSRP here)",
      "4060ti is the same cost as a 5060ti in my country and the 9070 got released with a price tag of about 950 so I don't think any AMD GPU is gonna compete. But if you have recommendations tell me",
      "Was a genuine question. Makes sense!",
      "he’s nowhere near a 9070 in pricing? he’s obviously looking budget oriented, that 9070 is mid range (9070xt around upper mid range) for £500, which none of them are so he isn’t anywhere near that for pricing",
      "Sorry you're getting so many god awful comments. I hate the 60 series but at most return the 4060 and get the 5060ti. \nBut i HIGHLY reccomend checking local fb marketplace etc for used. At your budget new is rough. I got a 3080 LAST Jan for just under 300$",
      "both cards are ass . 5060Ti sounds good on paper it ass but better than 4060 10000%",
      "If you can still return 4060, do it. 5060ti approximately %50 faster than 4060 and considering it's 16gb, yeah it would be a nice upgrade.",
      "Good luck getting one",
      "Yes, if you can still return. But definitely buy the 16gb one",
      "Yes, do this.\n\nIt'll be much better.",
      "you might be better off getting a 7800xt instead, if you got another 100€ to spend.\n\nIt all depends on your budget but I would either get a 5070, 7800xt or above.\n\nThat will get you well into 1440p which Im not sure the 5060ti is good at.",
      "No. If the 9070’s out of your budget. You’re much better off getting an Intel Arc B580 (12 GB) or a used 4070 or better.",
      "It's like a 10% performance bump, way too low for it to be worth the trouble isn't it? If you can return the 4060 and get a 16Gb version then it's very worth. For a 8Gb? Not really"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "4060"
    ],
    "title": "NVIDIA GeForce RTX 4060 Ti 16 GB Review - Twice the VRAM Making a Difference?",
    "selftext": "",
    "comments": [
      "![gif](giphy|7wk6RQYXDDytXalsL4)",
      "wtf, Memory Bus 128 bit",
      "The extra Vram helps only in situations where the only limit was vram.\n\nWatch the HWunboxed review of the 4060ti, they show in certain games (plague tale, Callisto etc) you get rid of the huge FPS drops and stutters simply by having 16gb. You also get rid of the low quality texture issue caused when the GPU can't hold enough textures in memory that you'd have on other games (Halo infinite, forspoken etc).\n\nHowever in games that aren't maxed out or are using under 8gb vram, there is literally no difference, since the card is exactly the same unimpressive GPU and still takes an L to the 3070 more often than not.",
      "Probably at a higher resolution than 1080p or with RT yes, but performance will probably drop below 60fps anyway because this GPU is too slow.",
      "like a GeForce 2 Mx 64mb",
      "Wtf, that sounds like it should be a USB stick not a PCIE GPU lmao",
      "Even at 1440p it didn't make a difference.\n\nAt 4k you need a more powerful GPU anyways.",
      "Even if you ignore the competition and only focus on Nvidia's lineup, the price/performance is terrible. You could get a brand new 4070, which is a significantly more powerful card, for just $80 more. Of course, that upsell is the main reason the 4060ti 16GB exists.",
      "There are 2 issues with the 4060ti around memory, capacity and bandwidth. 16gb on a 256bit bus is what the price they are targeting should have and they give out 128bit and 8gb. Solving one helps but it still leaves the narrow bus.",
      "Can't wait for them to release the 4050 with only 64 bit bus",
      "It really wasn't, and still isn't.",
      "I don't understand why these reviewers only look at games to measure and compare performance. When CPUs are released, reviewers don't just look at gaming fps (aside from techtubers) but also productivity-related computation. I've been saying for a while that it's pretty clear this card wasn't primarily made for gamers in mind, aside to address the \"we need vram\" crowd.\n\nHow many benchmarks compare Blender performances on CPU? Or Unreal Engine compilations? Or compression? Or even video rendering? Why is it that we can't see simple things like rendering on GPUs? How does this card handle CUDA use cases? How does it compare to the 4060ti 8gb since it now has twice the memory for seemingly larger sets of data to work on?\n\nConstantly looking at only one aspect of a card (gaming) and basing its performance efficiency solely on that is tirelessly beating a horse that's been long dead and is probably dust by now.",
      "For me it's the price it falls down at. It could age better than the 8 GB but at that price you're better paying some more and getting a 4070 with 12 GB of GDDR6X VRAM which should comfortably carry you through to the next console gen.",
      "AMD already did that with RX 6500 XT. 64 Bit Memory Bus, No video encoders, 4GB of VRAM AND 4 PCIE LANES",
      "Allocation doesnt equal actual usage.",
      "so, still not a worthy upgrade from 2060?",
      "Used 3080 all the way",
      "It does, in some situations. Hardware Unboxed has a good video on the 4060 Ti 16GB.\n\nI wouldn't buy the 8GB card in this day and age. Not a chance.\n\nThe 16GB I would, but not for $500. At that point you would be better off with a 6800 or a 6800XT.",
      "So you'd pay $100 for the extra 8GB of VRAM? Nevermind the fact that it's already overpriced at its original price, the extra VRAM is also overpriced. NVidia double dipping on the unsuspecting.",
      "I mean if allocation causes the 8gb card to fall into single digit frames per second, does the distinction matter?\n\nHardware Unboxed showed that the 16gb does much better with 1% lows."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "4060"
    ],
    "title": "RTX 4060 vs RTX 3060 12GB",
    "selftext": "As above, I’m relatively poor (not in the literal sense but I can’t go above £270 for a GPU especially with Christmas coming up, so these are my options atm. \n\nIf it matters I’m currently running an i510600k and a 1660ti. I only use a 1080p monitor but could see myself getting a 1440p one in the new year. I also use the quest 3 quite a lot and my 1660ti isn’t fantastic for that tbh. \n\nI’ve heard the whole debate on how the 4060 is a bad card for the money, please don’t recommend AMD, I don’t know very much about gaming pcs and I’d like to use a brand I’m comfortable with. \n\nWhich one should I get and why? Thanks in advance.\n\nETA: Feel like it’s a matter of time before I get dogged for saying no to AMD, I wasn’t aware there were no compatibility issues, feel free to recommend AMD cards and I’ll do my research, I just have no idea how the naming system works for them so it’s hard to tell what is what.",
    "comments": [
      "I mean, it's fine if you say please don't recommend Nvidia I just want AMD. But if you say it the other way they'll just downvote you to hell. That's just reddit being dumb so just ignore them. \n\nFor your question, the 4060 is clearly the better choice.",
      "You'll be fine. The 4060 is a super efficient GPU and only uses around 100W, maybe 150W with overclocked model under full load. Theoretically a 300W psu is enough but they don't really exist these day so they recommended 550W, but 450W is more than enough for an old gen i5 and a 4060",
      "The 4060 is just flat out better in 95% of scenarios, in games like RE4 Remake, the VRAM of the 3060 makes a difference, but generally the 40 series is just outright a better pick if similarly priced.",
      "OP I see you're from the UK, I buy used GPUs from cex as they have a 2* year warranty. You could probably get something better with your budget from there.\n\nI have a 3080 tuf I bought from cex and it works flawlessly.\n\n* Edit: They just changed it to a 5 year warranty on all electronics!",
      "4060 is straight up better 99% of the time, anyone who says otherwise is hard coping, lol, with FG this gap grows further",
      "If you're happy to go used, you can pick up an rtx 3070 for about £250-£270 from CEX with a 5 year warranty. That would perform better than the 4060 and would allow a more pleasant experience at 1440p",
      "No compatibility issues. AMD is now even good for VR. (It wasnt in the past)",
      "The 4060 is around 60% faster than the 1660ti according to Tech PowerUp. You also get access to DLSS which really helps a lot if you want to try 1440p",
      ">please don’t recommend AMD\n\n>I don’t know very much about gaming pcs",
      "Rx 7600xt has double vram and little btter peroformance, with similar price ¯\\\\\\_( ͡° ͜ʖ ͡°)\\_/¯",
      "I’ve just done some digging and realised I have a 450w Corsair PSU, will the 4060 cause my pc to explode?😭",
      "I’d definitely get the 4060 or if u can find a good priced Rx 6700 xt/6750 xt. I know what you mean by sticking with what your comfortable with, I’ve been used both brands as I went from a rtx 3050 laptop to a Rx 7900 xt then to the rtx 2080 ti currently and I can definitely say that amd is good, go with whatever u find for cheaper and better value. Personally tho once u learn amd softwares it’s a lot better in my opinion but either way you’ll have a good experience",
      "RX 6700XT would be the best bet for your budget. Beats both the RTX 3060 and 4060 in raster, and is about equal to the RTX 3070 while having more VRAM, though it is slower than both the 3070 and 4060 at ray tracing. Though no card at this budget is great at RT anyway. No compatibility issues, will run perfectly fine.\n\nIf you get it, just make sure to use DDU (display driver uninstaller) to reset your GPU drives, then download the latest ones from AMDs website.\n\nThat said, your post didn't have your PSU listed. If you're below 550ish watts, and don't want to get a new PSU, the 4060 is your best bet. It's quite a bit more power efficient than the 6700XT",
      "Do you have to get it right this moment? Can you wait 4+ months? Probably you can get a 5060 at that time if you can. \n\nI would not buy a 4060 personally. The lowest I'd go in the 40 series is the 4070 for under $500 otherwise the 4070S at $600. Failing that, I would get the 3060 if it was under $280 or so. Especially if you want to switch to 1440p. The second you come onto reddit in a few months asking why your 4060 sucks at 1440p, the same clowns telling you to get it now will just tell you \"4060 is a 1080p card you shouldn't expect it to perform at 1440p\" despite the fact that you mentioned it in your post. \n\nI don't know why anyone uses reddit for GPU info in the first place. Just go onto youtube and watch GamersNexus and HUB. That's honestly all you need. They will tell you not to get the 4060 though.",
      "I wouldn't really factor in fg when it chews through so much VRAM and is supported in so few titles",
      "There is 0 need for DDU going from Nvidia to Nvidia my friend didn't even use it when upgrading from a 1050 to a 6950xt he just uninstalled the drivers through windows and has had 0 issues almost 2 years later",
      "The notion that buying a 3060 is a better choice than a 4060 is due to a lot of misinfo. The 4060 is going to be better 99% of the time for most tasks and will only lose to the 3060 in scenarios where the VRAM is a bottleneck. Again, this will almost never happen at 1080p and if it happens, you turn the textures settings down one notch and/or you use DLSS, and it'll be okay. I have been enjoying the latest AAA releases and I never had an issue, I don't know if the VRAM will represent more of an issue in the future, but by the time it does I'll probably have a more powerful card.",
      ">  I don’t know very much about gaming pcs \n\nSo you should probably listen to people who do instead of tying yourself in knots with weird preconceptions.\n\nRegardless, the 4060 is a weird card. On paper and on average it is better than a 3060, but in a lot of particular programs it is equal or dramatically worse. It is worth checking individual benchmarks for programs you care about.\n\nMost likely you could get a way better card on the used market, or leftover last gen parts, like an RTX 3070, RX 6700 XT, ect.",
      "What are the used prices? Are they half-price or 25% off? If so, that would be a great deal for a used card that comes with a 2-year warranty. You guys in the UK are lucky! \n\nBut then again, IIRC, aren't PC parts way too expensive there anyway?",
      "In addition, running cooler means better longevity. I think a lot of people here are ignorant of just how much heat can shorten the lifespan of electronics. Over time it'll cause the solder to weaken, corrode, and/or eventually fail. It can also cause premature failure of certain types of capacitors. (I used to repair electronics)."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "4060"
    ],
    "title": "GeForce RTX 4060 Ti Review Megathread",
    "selftext": "# GeForce RTX 4060 Ti Founders Edition (and MSRP AIB) reviews are up.\n\n[GeForce RTX 4060 Ti Founders Edition](https://preview.redd.it/5iopxqeb9l1b1.png?width=6000&format=png&auto=webp&s=bdb071a1aaf274bc9c54f90c6d5301f4c68b62a5)\n\n# Below is the compilation of all the reviews that have been posted so far. I will be updating this continuously throughout the day with the conclusion of each publications and any new review links. This will be sorted alphabetically.\n\n# Written Articles\n\n# [Babeltechreviews](https://babeltechreviews.com/the-399-rtx-4060-ti-8gb-review-a-decent-buy-for-1080p/)\n\n>The RTX 4060 Ti is compact and amazingly efficient compared to the RTX 30 series and its 40 series brothers. The idle fan stop is huge for us, and support for AV1 encoding is stellar for a lot of streamers at this price.  \n>  \n>Not everyone cares about DLSS and its effect on an image. For this, he RTX 4060 Ti performed above the RTX 3060 Ti in most cases but barely at around 10% faster at 1080p. It was also well above the RTX 2060 but loses in almost every game to the RTX 3070 at 1440p.  \n>  \n>However, the RTX 4060 Ti user base will see enough significant performance gains on 20 and 10 series cards to be able to make this a worthwhile consideration.  \n>  \n>For a hundred dollars more you could buy an RTX 4060 Ti 16GB when it releases or a current AMD offering – for now but the rumor mill is swirling with a pending release. This would have been a slam dunk if there was no 8gb version and instead we had a $300-400 RTX 4060 Ti at launch. The lineup of cards would have been perfect and much more appealing to nearly every gamer.  \n>  \n>We do implore you to look at our upcoming DLSS 3 comparison of the current generation. This technology is finally allowing Nvidia to realize the dream that has been ray tracing. We can now maintain great performance while having the full suite of RTX features on an mid-level card. Safe to say, we give the RTX 4060 Ti a wait and see recommendation. The RTX 4060 Ti 16gb and normal RTX 4060 in July should be interesting to compare!\n\n# [Dexterto](https://www.dexerto.com/tech/nvidia-rtx-4060-ti-8gb-founders-edition-review-2152821/)\n\n>The RTX 4060 Ti 8Gb is a GPU built on compromise. It does offer good performance in many titles, and can even perform at 1440p. For $399, your money extends further thanks to the DLSS 3 technology and other goodies like AV1 encoding. However, you have to know exactly what kind of resolution you are targeting ahead of time. Things like the smaller bus width, 8GB of VRAM, and small generational uplift are disappointing. DLSS 3 does go some way to smooth those issues over, but it’s not the be-all-end-all for graphics cards.\n\n# Digital Foundry Article\n\n# Digital Foundry Video\n\n>TBD\n\n# [Guru3D](https://www.guru3d.com/articles-pages/geforce-rtx-4060-ti-8gb-(fe)-review,1.html)\n\n>Despite its high pricing, this card has commendable capabilities in the Full HD space. The 32L2 cache ensures that performance metrics are fully adequate for this specific monitor resolution. Nevertheless, NVIDIA appears to be increasingly reliant on technologies like DLSS3 and Frame generation. It's prudent to maintain some vigilance here as the pendulum seems to be swinging rather heavily towards AI solutions for enhancing performance. Regarding the shader rasterizer engine aspect, this card merely meets expectations. NVIDIA sets the card's price at $399, a price point previously seen with the 3060 Ti. However, this is a reflection of the cryptocurrency mining era where prices soared due to artificial inflation, and for some reason, they remain high. Despite this, the card's overall performance for Full HD resolution is satisfactory and with the aid of DLSS assist, it even excels. A simple manual tweak allows users to gain an additional 5% performance from the card. This more competitively priced graphics card is becoming accessible to a broader base of end-users. While NVIDIA strongly advertises the DLSS technology as a revolutionary tool, we hope they won't neglect the significance of raw rasterizer shader performance in their future offerings. Performance may vary in situations less dependent on the CPU, potentially being slower in DX11 yet quicker in DX12. When compared to the Radeon Series 600/7000, the RTX 4000 exhibits superior ray tracing performance, indicating noteworthy progress in this domain. Furthermore, the DLSS3 + Frame generation technology enables the GPU to achieve exceptional outcomes in compatible games  \n>  \n>As an objective assessment, the RTX 4060 Ti 8GB exhibits very respectable performance, especially within a Full HD and even 2560x1440 mindset. Its shader engine performance is satisfactory, and the addition of DLSS3 and frame generation aid substantially improves its functionality. NVIDIA continues to lead in raw Raytracing performance. This graphics card's 32MB L3 cache is particularly effective at this resolution, though cache misses can result in the system resorting to a narrower 128-bit wide bus with only 8GB of graphics memory. However, at QHD and UHD you're bound to run into memory limitations, also keep in mind that DLSS frame generation will consume VRAM when used. While this could potentially cause issues, the card seems to handle such scenarios well. The RTX 4060 Ti 8GB graphics card boasts enough performance, solid build quality, and appealing aesthetics. However, its pricing is a notable drawback. With a price tag of $399, it is considered far too expensive for a mainstream product. Considering the decline of the mining trend, many would expect a lower price point, ideally below $300, $250 even. But the regular 4060 will take that spot, we raise serious concerns as to what is happening with the graphics card market. Nevertheless, the RTX 4060 Ti series remains an attractive option for PC gamers. It delivers ample performance, particularly for QHD gaming when utilizing DLSS3 and Frame generation features. Additionally, it offers a mild overclocking capability. The founders edition showcases an appealing design, efficient cooling, and pleasant acoustics. Overall, it demonstrates commendable energy efficiency. Despite its strengths, the card's starting price of MSRP $399 is a deterrent for many potential buyers. The RTX 4060 Ti, positioned as a notable progression for users with significantly dated graphics cards, holds potential as an initial RTX choice for numerous gaming enthusiasts. While it is still a (barely) recommended choice for mainstream PC gamers coming from the GTX series, the disappointing price tag should be taken into consideration as a serious objection. \n\n# [Hot Hardware](https://hothardware.com/reviews/nvidia-geforce-rtx-4060-ti-gpu-review)\n\n>The MSRP for new GeForce RTX 4060 Ti 8GB cards starts at $399, which is on-par with the RTX 3060 Ti's launch price (and the 2060 Super's). In this price band, the GeForce RTX 4060 Ti is a clear winner. It's slightly more expensive than the typical Radeon RX 6700 XT, but offers significantly more performance. The GeForce RTX 4060 Ti is much lower priced than the average GeForce RTX 3070 Ti, however, despite competing pretty well with that card.  The 8GB of memory on this first GeForce RTX 4060 Ti will be off-putting for some gamers, but turning down some detail has always been a requirement for mainstream GPUs. And if that 8GB frame buffer is a deal breaker for you, the GeForce RTX 4060 Ti 16GB will be available in July for $100 more.  \n>  \n>All told, the GeForce RTX 4060 Ti isn't going to be a particularly exciting upgrade for anyone with an RTX 3070 or better, but if you're still rocking that GeForce GTX 1060 or an RTX 2060-series card, the GeForce RTX 4060 Ti will be a massive upgrade, not only in terms of performance but in power efficiency and feature support. If you're considering a mainstream GPU upgrade and have 400 bucks budgeted, the GeForce RTX 4060 Ti would be a fine choice. If, however, you can save up some additional coin, the [GeForce RTX 4070](https://hothardware.com/reviews/nvidia-geforce-rtx-4070-ti-review-with-asus) is a big step up in performance if you, can swing it.\n\n# [Igor's Lab](https://www.igorslab.de/en/nvidia-geforce-rtx-4060-ti-founders-edition-8-gb-review-with-160-and-175-watt-power-limit-plus-oc/)\n\n>Of course, an assessment is always subjective and the price will certainly have to play a role. But to put it emotionless: You almost get the gaming performance of a GeForce RTX 3070 with 75 watts less power consumption. The GeForce RTX 4060 Ti, which costs 439 Euros (RRP), also just undercuts the RTX 3070 with a current street price of 450 Euros. Whereas the RTX 3070 had an MSRP of 499 Euros at that time.  \n>  \n>The GeForce RTX 4060 Ti is at least 9 percentage points faster than the RTX 3060 Ti 12 GB and it needs 60 watts less than the predecessor. Which brings us to the demand that the cards should not only be faster, but also more efficient. This is exactly the case here. You save over 30 percent in electrical energy and are at least 9 percent above the performance of the old card, which had an RRP of 399 euro at the time, but currently costs at least 415 euro. Thus, inflation also has an impact. However, this makes the old card completely obsolete. And there is somehow a monetary standstill.  \n>  \n>The GeForce RTX 4060 Ti with the AD104-351 is a cleverly placed card in the lower mid-range that doesn’t have to fear any direct rivals from AMD in this generation, which is unfortunately also noticeable in the price. In terms of efficiency, NVIDIA once again sets standards that AMD really has to be measured against. If and when the RX 7700 series will come and if we will see 16 GB or 12 GB memory expansion again, that is still up in the stars. But gamers live in the here and now and there are simply no alternatives at the moment if you want the complete feature set including high-quality super sampling and AI. Because the Radeon RX 7600, which will be launched tomorrow, should be significantly slower (if the performance rumors are true)  \n>  \n>Except for the outdated Display Port connector and the meager 8 GB memory expansion, I hardly see any drawbacks that would speak against this card in the GeForce RTX 4060 Ti. Except for the price, but that is unfortunately exactly where the comparable offers are. Thus, the big miracle is once again missing. New costs almost as much as old and you have to look for the added value at the socket and can at least be happy about a bit more performance. That is something in today’s times, since the demands on sensations have already been reduced. The bottom line is that it fits and if the street prices come into play even more, it will even be considerably cheaper.\n\n# [KitGuru Article](https://www.kitguru.net/components/graphic-cards/dominic-moass/nvidia-rtx-4060-ti-review/)\n\n# [Kitguru Video](https://www.youtube.com/watch?v=R943CbDTq_s)\n\n>Just stopping to think on what this GPU is capable of gives me a tinge of regret. It's genuinely a technical marvel that Nvidia has been able to take the AD106 GPU, a die that's *less* than half the size of GA104, and yet it outperforms it while offering vastly improved efficiency. This could have been a fantastic entry-level GPU, as befitting its die size, but at £389, AD106 is in a different class entirely.  \n>  \n>At that price point, we may as well come out and say it – 8GB VRAM simply does not cut it anymore. We covered this topic extensively in our video review, but for this class of product, such a meagre frame buffer is an absolute dealbreaker in 2023. That's not to say 8GB VRAM is useless or won't run new titles, but the way the industry is going, 8GB GPUs really need to be considered entry-level in my opinion, RTX 3050-type products which target 1080p gaming at Medium or High settings. Not something that's almost £400 and in this performance tier.  \n>  \n>I also think it's important to distinguish between game benchmarks and the actual experience of playing a brand new title on day 1. Many reviewers, myself included, test more mature games that have finished their update cycle – this provides us with the stability we need when trying to benchmark dozens of GPUs, while also mitigating the potential of having to restart our testing due to a new patch that significantly changes our results. From that perspective, plenty of 8GB cards could still be considered viable, at least for 1080p max settings as indicated by the bulk of our benchmarks today.  \n>  \n>The real problem for 8GB cards has been well and truly exposed this year when trying to play a number of new titles on launch day. The Last of Us Part 1, Forspoken, Callisto Protocol, Hogwarts Legacy, Resident Evil 4 Remake… the list goes on. Poorly optimised ports or not, the fact remains there is a growing number of games where 8GB GPUs simply had a very rough time of things when trying to play at launch, and if this is happening *now* – what will things be like one, two, three years down the line?  \n>  \n>Unfortunately, I think this is a very straightforward review to conclude – I can't in good faith recommend the **Nvidia RTX 4060 Ti 8GB** at its current asking price of £389. It's barely an improvement over its predecessor in terms of raw performance, its narrower memory interface reduces performance at higher resolutions, and 8GB of VRAM is simply not enough. The RTX 4060 Ti needs a hefty price cut to have any chance of viability considering its limitations.\n\n# [LanOC](https://lanoc.org/review/video-cards/8738-nvidia-rtx-4060-ti-founders-edition)\n\n>As far as performance goes, the RTX 4060 Ti, when tested at 1080p which is where Nvidia is targeting, runs right with last generations RTX 3070 but from AMD the RX 6750 XT does have 5 FPS on it on average across our tests. The problem you will run into with the RTX 4060 Ti is that if you go beyond 1080p up to 1440p or 4k the performance in comparison to the 3070 or even the 3060 Ti drops. Ada has its huge L2 cache which takes a lot of load off of the memory bus and that works really well. But because of that they have gone down to a 128-bit memory bus which works great at 1080p but that and the 8GB of VRAM start to get to their limits at the highest resolutions. That isn’t to say that in our testing 1440p or 4k wasn’t playable, it was. But if you are looking longer term and considering upgrading to a higher resolution monitor before your next video card upgrade, there are going to be better options that will offer that flexibility better. That said 1080p is still the most popular resolution by a HUGE margin and that is going to still be the case for a very long time. The RTX 4060 Ti also adds in DLSS 3 capabilities which in our testing gives huge performance improvements in the games that support it. Even in older DLSS 2 games the 4060 Ti saw bigger improvements than last generation's cards. I was also surprised with the compute performance, I expected it to be similar to the RTX 3070 but in Blender and Passmark’s GPU Compute test, it was outperforming the RTX 3070 Ti and running close to the RX 6800 XT.  \n>  \n>In the end, the RTX 4060 Ti is in an interesting spot in the market. At its intended resolution it performs well. But like with the RTX 4070, AMD’s last generation of cards being marked down cause trouble when it comes to just per raster performance. DLSS 3 and its ray tracing capabilities help compete there. But once you get out past 1080p the performance drop brings this a little too close to the last generation 3060 Ti for me. That said for me, this might be the ideal card for my compact SFF LAN rigs. Its low power draw helps keep things cool and doesn’t require a giant card and I know for sure that I’m not going beyond 1080p for my LAN rig for a long time now because I don’t have any interest in dragging a larger monitor to events.\n\n# [OC3D Article](https://www.overclock3d.net/reviews/gpu_displays/nvidia_rtx_4060_ti_fe_and_gigabyte_eagle_review/1)\n\n# [OC3D Video](https://www.youtube.com/watch?v=etjw3cHZhuc)\n\n>So far all of the Nvidia 4000 series cards have proven to be an unqualified success. It doesn't matter which card you go for, you'll be getting the kind of performance, in every title, that will leave you grinning. We know that purchasing something as expensive as a graphics card is a mighty investment, and you never want to be left wondering exactly what your outlay has got you that you didn't have before. Until now it didn't matter what game you wanted to play, or what setup you had, you could grab one of the 4000 series and be pleased with your purchase.  \n>  \n>The RTX 4060 Ti is still good, but it's the kind of card that represents the tipping point where you have to have some qualifiers and caveat emptors that weren't there on the 4080 or similar. Price wise the RTX 4060 Ti comes in at around the same MSRP as the RTX 3060 Ti had at launch, and there is something of a performance increase just from raw hardware over that card, somewhere around the 8% mark. Not really enough to justify the outlay, particularly if funds are tight. Of course if you're running a RTX 2060 then you'll be blown away at how much faster the new card can run.  \n>  \n>Where the waters get cloudier, or at least where you need to pay closer attention, is exactly what you're planning to play on the RTX 4060 Ti. If it's a title that relies solely upon hardware horsepower, such as Horizon Zero Dawn, then you could come away from this latest Nvidia offering feeling a little disappointed. Certainly in comparison to the feelings we got once we'd finished with the RTX 4080 or even RTX 4070 Ti. But, and it's a big, world pie-eating champion sized but, if your title of choice supports DLSS 3 then the difference between the 4000 cards and the 3000 ones is stark.  \n>  \n>Now we know that it's difficult to say that the RTX 4060 Ti is a bad card as such, because it allows you to run those games which do support the newest Nvidia DLSS 3 and FrameGen technologies in all the buttery-smoothness you could hope to see. It's just that the list of DLSS 3 games isn't massive, and certainly there are some notable omissions, so if you're going to be just relying on the amount of oomph the card has just as it is, then you really need to pay close attention to the card you already own and how the RTX 4060 Ti compares.  \n>  \n>Clearly if you're looking to start your Gaming PC owning journey and want to do so without getting on your knees in front of your bank manager, then the RTX 4060 Ti is a great starting place. If you already own a recent-ish graphics card and have specific games in mind, then you need to look a little closer at the nitty-gritty of things, which is a first for the 4000 series of Nvidia cards which have, until now, been wholehearted recommendations. If you have got a PC already then the Gigabyte Eagle and its use of the PCIe 8 pin power input might be enough to tip the balance towards that rather than the new-fangled power connector on the Nvidia card. The RTX 4060 Ti is still good, though we're just reaching the point where Nvidia have trimmed the hardware to fit a price point so much it's not the quantum leap forwards that the other cards in the Ada Lovelace range have been when compared to extant cards.\n\n# [PC Perspective](https://pcper.com/2023/05/nvidia-geforce-rtx-4060-ti-founders-edition-review/)\n\n>Looking back only a few years, I think a card like the RTX 4060 Ti would meet expectations for a xx60 Ti card – which is to say that it effectively matches the performance of the previous-gen xx70 card, and adds current-gen features. But we live in the post-RTX 30 Series era now.  \n>  \n>While many actual gamers were left empty-handed during the dark times (f\\*\\*\\* Ethereum, anyway), the RTX 30 Series was a BIG upgrade over the RTX 20 Series, and *list* pricing was very good for the performance level.  \n>  \n>My favorite card last generation was the RTX 3060 Ti, and for its elusive MSRP of $399 it was the card I would have bought with my own money. Think about this: it was faster than the $699 (and up) RTX 2080, cruising past heavyweights such as GeForce GTX 1080 Ti and Radeon RX 5700 XT. And this begs the question, was the RTX 3060 Ti too good? It certainly set expectations for the next generation of GeForce cards **very** high.  \n>  \n>Seeing only modest raw performance gains over the previous generation xx60 Ti card here isn’t very exciting, but there are architectural improvements with the RTX 4060 Ti that stretch the lead to more impressive levels. I didn’t cover things like content creation, where this generation offers a better experience.  \n>  \n>This card wants you to use DLSS 3 + FG, and if you get it, use this. Regardless of what you’ve watched (or possibly even read) about DLSS 3 and Frame Generation, the tech does greatly increase the framerates and perceived smoothness of games, and in games that support the DLSS 3 + FG combination the RTX 4060 Ti crosses into enthusiast 2560×1440 territory – at least based on the FPS numbers I was seeing.  \n>  \n>Now, about that VRAM thing. 8GB is certainly a useful amount, but there have been multiple (and heavily-documented) examples of recent titles that want as much as they can get. I would love it if this card had 16GB, and while I could pontificate about public companies maintaining margins on products amidst rising component costs, the fact is that gamers don’t care about how well company X is doing. They all just want cheap GPUs with lots of VRAM, as far as I can tell.  \n>  \n>The fact that a 16GB version of the RTX 4060 Ti will be made available is definitely a good move, but it isn’t coming until July. I would have loved to see it launch alongside this card, but the additional $100 for the 16GB RTX 4060 Ti does push it into a different market segment. We will have to wait and see if AMD answers with something compelling, and creates some pricing pressure. I think we’d all love to see a price break on components for this increasingly expensive hobby.\n\n# [PC World](https://www.pcworld.com/article/1925928/nvidia-geforce-rtx-4060-ti-8gb-review.html)\n\n>It all depends on your answer to the question posed right up top: Are you willing to pay $400 for a 1080p graphics card with 8GB of memory in the year of our lord 2023?  \n>  \n>The GeForce RTX 4060 Ti delivers absolutely outstanding power efficiency, leading ray tracing performance, [modern AV1 encoding](https://www.pcworld.com/article/1375901/tested-nvidias-geforce-rtx-4090-is-a-content-creation-monster.html), and fast 1080p gaming for high refresh rate monitors, backed by Nvidia’s knockout software suite: [DLSS 3 Frame Generation](https://www.pcworld.com/article/1662185/what-is-dlss-3-nvidia-geforce-rtx-ai-feature-explained.html), [Nvidia Reflex](https://www.pcworld.com/article/393646/tested-how-nvidia-reflex-can-make-you-a-better-esports-gamer.html), [RTX Video Super Resolution](https://www.pcworld.com/article/1525299/nvidia-rtx-video-super-resolution-tested.html), and Nvidia Broadcast are just *some* of the killer features available to the RTX 4060 Ti, with DLSS 3 *only* being available on Nvidia’s newest GPU in this price segment. If you’re still on a GTX 1060 or RTX 2060, the RTX 4060 Ti will be a fantastic upgrade (albeit expensive).  \n>  \n>The RTX 4060 Ti is also a deeply uninspiring upgrade gen-on-gen when it comes to raw GPU horsepower, only besting the RTX 3060 Ti by 9 percent at 1080p resolution and 7 percent at 1440p. It has fewer CUDA, RT, and tensor cores than its predecessor, which is disappointing. It flat-out loses to the RTX 3070 at 1440p, which is even more disappointing.  \n>  \n>So: Are you willing to pay $400 for a 1080p graphics card with 8GB of memory in the year of our lord 2023? I’m not, especially with DLSS/FSR advantages minimized in this segment. (Given the RTX 4060 Ti’s overall performance, I don’t think the $500 16GB version will be very appealing when it launches in July either.)  \n>  \n>That said, I’d hold my horses if I could. Nvidia already teased a $299 RTX 4060 with DLSS 3, AV1, and extreme power efficiency for July. Plus, the [rumor mill is screaming](https://go.redirectingat.com/?id=111346X1569483&url=https://videocardz.com/newz/amd-radeon-rx-7600-gpu-specs-confirmed-navi-33-xl-with-2048-stream-processors-and-8gb-vram&xcust=2-1-1925928-1-0-0&sref=https://www.pcworld.com/article/1925928/nvidia-geforce-rtx-4060-ti-8gb-review.html) that AMD could launch a $300 Radeon RX 7600 any minute now. That price point is a lot more palatable for 1080p gaming on 8GB if you don’t need Nvidia’s deep feature set.  \n>  \n>The GeForce RTX 4060 Ti would have been more appealing if it offered 16GB of memory for $399 and ditched the 8GB option, or offered 8GB of memory with the same level of performance for $300 to $325. As it stands, Nvidia’s RTX 40-series upgrades remain uninspiring at best and this GPU sadly falls into a no-man’s land of sorts. Look elsewhere.\n\n# [TechGage](https://techgage.com/article/nvidia-geforce-rtx-4060-ti-creator-review/)\n\n>One thing to be clear about here is, the look we’ve taken at this RTX 4060 Ti so far has revolved entirely around creator. It may be that its gaming prowess is much more lucrative, and we do plan on investigating that more soon. A major selling-point of the RTX 4060 Ti is DLSS 3 + Frame Generation, and that’s one that doesn’t impact many on the creator side quite yet. Our experience with Frame Generation so far has been great, but as we called out in the intro, it’s best used when the baseline (+ DLSS) FPS is high enough that input latency won’t be a problem.  \n>  \n>When most folks seek out a new GPU, they want the satisfaction of knowing that it will last them long enough until a substantial architectural upgrade comes along. What’s frustrating, then, is knowing that your GPU is capable of more, if only it weren’t held back by its framebuffer.  \n>  \n>In this particular round of testing, we saw that the 8GB RTX 4060 Ti rendered Blender’s *Charge* project slower than the 12GB RTX 3060, but in scenarios where VRAM wasn’t an issue, it had the ability to inch ahead of the RTX 3070 Ti. We’ve seen in the past that even a simpler workload like Adobe Lightroom export can lead to the 12GB RTX 3060 outperforming technically superior (aside from VRAM) GPUs.  \n>  \n>We’re still trying to properly assess whether or not 8GB can be declared a real issue for most people in reality, because not everyone creates complex projects that actually uses so much memory. But if you *do* create complex projects, encode really high-resolution video – or just plan to in time – you’re going to want to do yourself a favor and opt for more memory if you can.  \n>  \n>We understand that GPUs are more expensive to produce than ever, but the RTX 4060 Ti feels more like a speed-bumped product than a proper upgrade, versus RTX 3060 Ti, and while Frame Generation is nice, it’s not going to matter if it doesn’t impact what you use a GPU for.  \n>  \n>Overall, the RTX 4060 Ti isn’t a bad GPU; we just feel like the only thing holding it back in creator workflows is the 8GB framebuffer. We feel like we’ve finally reached the point where 12GB feels like the new sweet spot for creator workloads.\n\n# [Techpowerup](https://www.techpowerup.com/review/nvidia-geforce-rtx-4060-ti-founders-edition/)\n\n>Averaged over the 25 games in our test suite, at 1080p resolution, the RTX 4060 Ti is able to match last-generation's RTX 3070 and the older RTX 2080 Ti. The gen-over-gen performance improvement is only 12%, which is much less than what we've seen on the higher-end GeForce 40 cards. Compared to AMD's offerings, the RTX 4060 Ti can beat the RX 6700 XT by 8%, even though that card has 12 GB VRAM. The Radeon RX 6600 XT, Red Team's \"x60\" offering, is even 37% behind. With these performance numbers, the RTX 4060 Ti can easily reach over 60 FPS in all but the most demanding games at 1080p with maximized settings. Actually, the RTX 4060 Ti will capably run many games at 1440p, too, especially if you're willing to lower a few settings here and there.  \n>  \n>As expected, ray tracing performance of RTX 4060 Ti is clearly better than its AMD counterparts. With RT enabled, the RTX 4060 Ti matches the Radeon RX 6800 XT, which is roughly two tiers above it. AMD's Radeon RX 6700 XT is a whopping 30% slower. Still, I'm not sure if ray tracing really matters in this segment. The technology comes with a big performance hit that I find difficult to justify, especially when you're already fighting to stay above 60 FPS in heated battles.  \n>  \n>GeForce RTX 4060 Ti comes with a 8 GB VRAM buffer—same as last generation's RTX 3060 Ti. There have been heated discussions claiming that 8 GB is already \"obsolete,\" I've even seen people say that about 12 GB. While it would be nice of course to have more VRAM on the RTX 4060 Ti, for the vast majority of games, especially at resolutions like 1080p, having more VRAM will make exactly zero difference. In our test suite not a single game shows any performance penalty for RTX 4060 Ti vs cards with more VRAM (at 1080p). New games like Resident Evil, Hogwarts Legacy, The Last of Us and Jedi Survivor do allocate a lot of VRAM, which doesn't mean all that data actually gets used. No doubt, you can find edge cases where 8 GB will not be enough, but for thousands of games it will be a complete non-issue, and I think it's not unreasonable for buyers in this price-sensitive segment to to set textures to High instead of Ultra, for two or three titles. If you still want more memory, then NVIDIA has you covered. The RTX 4060 Ti 16 GB launches in July and gives people a chance to put their money where their mouth is. I'm definitely looking forward to test the 16 GB version, but I doubt the performance differences can justify spending an extra $100.  \n>  \n>NVIDIA made big improvements to energy efficiency with their previous GeForce 40 cards, and the RTX 4060 Ti is no exception. With just 160 W, the power supply requirements are minimal, any beige OEM PSU will be able to drive the RTX 4060 Ti just fine, so upgraders can just plop in a new graphics card and they're good to go. Performance per Watt is among the best we've ever seen, similar to RTX 4070, slightly better than RTX 4070 Ti and Radeon RX 7900 XTX; only the RTX 4090 and RTX 4080 are even more energy-efficient.  \n>  \n>NVIDIA has set a base price of $400 for the RTX 4060 Ti 8 GB, which is definitely not cheap. While there is no price increase over the RTX 3060 Ti launch price, the performance improvement is only 12%, and the mining boom is over—these cards don't sell themselves anymore. To me it looks like NVIDIA is positioning their card at the highest price that will still allow them to sell something—similar to their strategy in the past. Given current market conditions, I would say that a price of $350 for the RTX 4060 Ti would be more reasonable. Still, such high pricing will drive more gamers away from the PC platform, to the various game consoles that are similarly priced and will give you a perfectly crafted first-class experience that works on your 4K TV, without any issues like shader compilation and other QA troubles. For GeForce 40 series, NVIDIA's force multiplier is DLSS 3, which offers a tremendous performance benefit in supported games. Features like AV1 video encode/decode and (lack of) DisplayPort 2.0 seem irrelevant in this segment, at least in my opinion. Strong competition comes from the AMD Radeon RX 6700 XT, which sells for $320, with only slightly less performance. That card also has a 12 GB framebuffer, but lacks DLSS 3 and has weaker ray tracing performance. I don't think I'd buy a $400 RTX 3070, or a $320 RTX 3060 Ti—I'd rather have DLSS 3. If you can find a great deal on a used card, maybe consider that. AMD is launching their Radeon RX 7600 soon, which goes after the same segment as the RTX 4060 Ti, if the rumors are to be believed, so things could get interesting very soon.\n\n# [The FPS Review](https://www.thefpsreview.com/2023/05/23/nvidia-geforce-rtx-4060-ti-founders-edition-video-card-review/)\n\n>If you are coming from an older GPU, such as a GTX-level video card, or a GeForce RTX 2060-level video card from 2019, the new GeForce RTX 4060 Ti is a good upgrade path for you. At $399 you are still shopping in the same price point you might have paid way back then, and will be getting a substantial upgrade in performance and features. If, however, you want to upgrade from a previous generation video card at this same price point, such as the GeForce RTX 3060 Ti, the new GeForce RTX 4060 Ti does not have enough meat on the bone at this price point.  \n>  \n>However, if you are coming from an equivalent video card from AMD in the last generation, such as the Radeon RX 6650 XT, then the GeForce RTX 4060 Ti offers a substantial upgrade. It will provide huge performance gains over the Radeon RX 6650 XT in pretty much everything. It will also provide playable and usable Ray Tracing image quality in games, something the Radeon RX 6650 XT could never deliver. It will also give you DLSS and DLSS 3 support, something that will be a big upgrade from any older GPU.  \n>  \n>Therefore, if you are rocking a GPU from AMD’s last generation, or several generations past on the NVIDIA side, then the GeForce RTX 4060 Ti could potentially be a good upgrade path for you. It just depends on what you have, where you want to go, and the price point you want to stay at.\n\n# [Tomshardware](https://www.tomshardware.com/reviews/nvidia-geforce-rtx-4060-ti-review)\n\n>Nvidia's RTX 40-series has been controversial for a variety of reasons, and the RTX 4060 Ti will continue that trend. It's not that this is a bad card, as the efficiency shows significant improvements over the previous generation. The price of entry, relative to the RTX 3060 Ti, also remains unchanged. The problem is that Nvidia's trimming of memory channels and capacity is very much felt here, and we can only look forward to similar concerns on the future RTX 4060 and RTX 4050.  \n>  \n>The performance ends up being a bit of a mix, with native rendering showing only relatively minor improvements compared to the prior RTX 3060 Ti. There are even some instances where the new card falls behind — specifically, any situation where the 8GB VRAM and reduced bandwidth come into play.  \n>  \n>Mainstream graphics cards are never the sexiest offerings around. In this case, we've had similar levels of performance from the RTX 3070 and 3070 Ti since late-2020 and mid-2021, respectively. Granted, those were both nearly impossible to find at anything approaching a reasonable price until mid-2022, so getting a replacement that's hopefully readily available will certainly attract some buyers. Just don't go upgrading from an RTX 3060 Ti, or you'll be very disappointed in the lack of tangible performance improvements.  \n>  \n>As we mentioned earlier, we'd feel a lot better about the RTX 4060 Ti if it had 12GB of memory and a 192-bit memory interface. Nvidia likely decided to go with a 128-bit bus and 8GB of VRAM around the time the RTX 30-series was shipping, but we still feel it wasn't the ideal choice. At least there will be a 16GB 4060 Ti in July, but the extra $100 puts you that much closer to getting an even better card like the RTX 4070. Or maybe AMD will have a new generation RX 7700/7800-series card priced at $500 or less by then.  \n>  \n>Anyone using a graphics card at least two generations old will find a bit more to like about the RTX 4060 Ti. It's not a huge boost in performance over the 3060 Ti, but it does come with some useful new extras, like AV1 encoding support. It's also a more compact card than a 3060 Ti, so it can fit in a smaller case, and it ran cool and quiet in our testing.  \n>  \n>The bottom line is that you could certainly do worse than an RTX 4060 Ti. You could also do a lot better, if by \"better\" you mean \"faster.\" Its just likely to cost you a whole lot extra to move up to the next faster Nvidia graphics card.\n\n# [Computerbase - German](https://www.computerbase.de/2023-05/nvidia-geforce-rtx-4060-ti-8gb-test/)\n\n# [HardwareLuxx - German](https://www.hardwareluxx.de/index.php/artikel/hardware/grafikkarten/61026-geforce-rtx-4060-ti-mit-8-gb-im-test.html)\n\n# [PCGH - German](https://www.pcgameshardware.de/Geforce-RTX-4060-Ti-8GB-Grafikkarte-279648/Tests/Release-Review-Benchmark-Specs-Preis-1419889/)\n\n# ----------------------------------------------\n\n# Video Review\n\n# [Der8auer](https://www.youtube.com/watch?v=SIugY8lDJhY&pp=ygUHZGVyOHVlcg%3D%3D)\n\n# Digital Foundry Video\n\n# [Gamers Nexus Video](https://www.youtube.com/watch?v=Y2b0MWGwK_U)\n\n# Hardware Canucks\n\n# [Hardware Unboxed](https://www.youtube.com/watch?v=WLk8xzePDg8)\n\n# [JayzTwoCents](https://www.youtube.com/watch?v=995Vu55tpfM)\n\n# [Kitguru Video](https://www.youtube.com/watch?v=R943CbDTq_s)\n\n# [Linus Tech Tips](https://www.youtube.com/watch?v=_B6vtMa-US4)\n\n# [OC3D Video](https://www.youtube.com/watch?v=etjw3cHZhuc)\n\n# Optimum Tech\n\n# Paul's Hardware\n\n# [Techtesters](https://www.youtube.com/watch?v=pfB-sZHumNo)\n\n# [Tech Yes City](https://www.youtube.com/watch?v=M1kQO1xseR4)\n\n# The Tech Chap",
    "comments": [
      "Waste of sand",
      "the reviewers who give the 4060 ti a good rating are out of their minds",
      "I see this as a good opportunity to weed out the dishonest outlets from my bookmarks.",
      "Jay pulled his video lol",
      "Unfortunately, it seems the 4060 Ti is a complete trash...\n\nI will wait once again for the next generation and hope the 5060 / 5060 Ti is a better deal than this one.",
      "Dishonest or incompetent, whatever the reason it's a good way to weed out the trash",
      "It's news to me that he has standards.  He took it down because of the incredibly negative response from reviewers that have credibility.\n\nLOL, this is a direct quote from his now-deleted video: \"Like Jay said at the unboxing, this card is doing great at 1440p.\"  He then goes on to praise NVIDIA's decision to use a 128-bit memory bus with the larger L2 cache.  The review concludes by stating that the 4060 Ti is an \"amazing card\" and has the \"potential to be the new GTX 1060.\"  The video honestly sounds like an advertisement NVIDIA paid them to produce.  Absolute trash.",
      "Silicone is a rubber-like substance, I don't think it's made from sand.\n\nSilicon sure is though!",
      "He's recovering from major surgery, didn't even host the video.",
      "1080ti ganers, it is safe to upgrade to the RX 6700XT.",
      "Nvidia lost the budget market to AMD's previous generation of cards lmfao",
      "This hurts his credibility since he can’t stand by his own opinion. Like can you really believe he didn’t read his data before recording a video?",
      "He said the 4060Ti is amazing value and will last you for years. Which is NOT true, considering it has only 8GB VRAM.",
      "Guru3d 's review is a perfect example of them being nvidia shills for quite some time now, the conclussions and performence charts from them were soo heavily in favour of nVidia while in reality its not that much of a difference between AMD and nVidia cards.... While GamersNexus basically mops the floor with nVidia... guru3d yet again provides userbenchmark levels of review.Thanks guru3d for reminding me why I stopped taking your reviews seriously",
      "I’ve seen you comment practically the same message over and over in this thread. It’s really weird to be a fanboy of a multibillion dollar company bruh. I promise you’re not getting a Christmas card from them",
      "It is an entry level PCIE 4.0 8x card. A PCIE 3.0 motherboard will further reduce the performance by 5%, making it virtually identical to a 3060 ti at 1440p.",
      "This feels like it should had been a 4050ti, but has double the price",
      "Practically every card this gen has been this way. The die size tells us everything.",
      "I hate to use an overused meme, but the reviewers giving the 4060Ti positive reviews is huffing some serious industrial-grade copium.",
      "So did AMD which is rough lmao. The 7600 is looking to perform and cost exactly the same as the 4060 non ti. Horrible value"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "4060"
    ],
    "title": "It's getting Even Worse... RTX 4060 Ti tested on a PCIe 3.0 System | [der8auer]",
    "selftext": "",
    "comments": [
      "Not much of an \"upgrade\" option is it.....",
      "I wanted to upgrade the GPU in my brother's PCIE 3.0 system, which has a Ryzen 5700X CPU. Before the launch it seemed like it would be a decent upgrade over his 1660 super, but now that it's out, the 4060 Ti here costs more than a used 6800 XT and with that limited memory bandwidth, it's not clear if there will be enough of an uplift to even feel the change in performance, at least in some memory intense games. I just don't understand who is this gpu for. I kind of doubt that the majority of 1080p gamers have PCIE 4.0 and up.",
      "so for older systems you might as well just get a 3060ti which has the full x16 slot, if you want this level of performance",
      "So it takes two jetplanes to take it down? That's pretty good ngl.",
      "The 4090 is the only homerun this gen. The 4070ti was only saved from total disaster by reviewers telling Nvidia this is not a 4080 and Nvidia having enough brainpower to name swap it. But 4070ti still a lackluster gen over gen improvement when you factor in 200 extra dollars to get that improvement over prior gen",
      "For $150-199 is OK.",
      "It feels like it’s for people who buy prebuilts and are going to have this or a 50ti slotted in who have no clue what anything is except how much ram it has and they don’t want Nvidia over AMD because of past experience or they heard bad about it.\n\nFor informed buyers maybe someone who is budget building a system for competitive games or gtaV who is going to get way more bang out of av1 encoding than anything else.\n\nThat’s all I can think of. Still think this and the 4060 sell well just on Nvidia momentum and supply strain hangover.",
      "stop pandering to their BS",
      "Thanks for the TLDW",
      "Either that or a 6700XT",
      "It's a fair price for what it is, a 4050 card... If you check the numbers on how generation to generation performance this is not a xx60 TI card, those were equivalent to xx80 cards from the previous generation. But if you check for xx50 and it's performance upgrade it becomes clear this is exactly that card.\n\nI have no idea why a 4060 will be released at all when this card doesn't serve any purpose.",
      "The PCIE penalty sucks so much, I know several people like this too. With 8700K, 9900K, etc. This will really piss off so many potential buyers with perfectly adequate CPU power.",
      "DLSS 3 is NOT in every game and thus only is a selling point for people who play bascially only those games since otherwise they cant get any advantage out of it.\nDLSS 3 is so overhyped by nvidia and some people and although its a good feature for high refresh rate, its not nearly as good as it sounds from marketing.",
      "Nice write up. They have a minimum word count per reply right? Do you get paid more by writing more and formatting?",
      "Looks like a 50 card to me. Size of a 50 card, lanes of a 50 card, bandwidth of a 50 card, performance of the last gen 60 card. Not sure where you're getting 10-15% uplift, the GN benchmarks show only 2% gain on 1080p and an actual loss of performance on 1440p and 4k. The card can't even do 1080p on Control. \n\nI guess you're looking at frame generation for that 10-15% I guess whatever, but it's not like previous 50 series GPUs had FG either. Personally don't think FG should count as performance uplift, since it's just a software lock and not a fair comparison in my mind but whatever I guess.\n\nI'll keep calling it a 50 series and you can call it a 60 series, we're just going to have a difference of opinion on that.",
      "3060Ti was better than 2080 \n\n4060Ti is worse than 3070",
      "Got my son one last month and it's been rock solid.",
      "My i7 4770 bottlenecks my 1070 badly so....\n\nFrame gen is only useful when you are already getting 60gps without it",
      "The motherboard is a B450.",
      "You will run into cpu bottleneck for sure. I did an “upgrade” from gtx 1070ti to rx 6600xt on my i7 3770 and to my surprise the AMD gpu is utilized better than the lower tier gpu."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "4060ti"
    ],
    "title": "Deciding between a 4070 super and a 4060ti 16GB",
    "selftext": "I do a lot of 3D and CGI work so vram is important, however I also play games often and it is a major hobby of mine. Which do you guys think would suit my needs better?",
    "comments": [
      "4070 super is a way better option at that price point, so go for it",
      "2, 3 months? What about scalpers? B580 is still sold out.",
      "Get a used 4070ti super. The 16gb VRAM and power make it the ultimate 1440p card in my opinion. It can also do 4k 60hz on most games.",
      "I’m not sure how much a difference the VRAM will make your work but the 4070 super is significantly faster than the 4060ti in games.\n\nYour best bet would be a used 3090",
      "Wait to get 4070ti super it is ur best option and deserves ur waiting time",
      "nah, second hand market is where its at. OP might be able to score the 4070 TI or TI super for the same price as 4070S since some small amount of peeps gonna upgrade from 40 to 50 (yes people actually do that for some reason)",
      "If only i had a penny someone asked a simple 'this or that' question and the best reply is 'spend more'.\n\nWhat's fun is if he originally asked about the 'spend more' item, you guys would suggest something even more expensive lol",
      "Nobody is scalping Arc in any relevant volume. They just didn't have the volume and will continue to have no volume.",
      "So there won't be rtx 50 shortage on release?",
      "Puget Systems reviewed the RTX 4000 Super cards (including 4070 and 4070 Super) for productivity tasks: https://www.pugetsystems.com/labs/articles/nvidia-geforce-rtx-40-super-series-content-creation-review/   \nTLDR:   \n\"Last, the GeForce RTX 4070 SUPER is the only model to come with a small increase in price ($600 vs $550) and power draw (220 W vs 200 W). In terms of performance, the gains depend on what you are doing. Performance in DaVinci Resolve and Premiere Pro was largely on par with the RTX 4070 non-SUPER, although it showed some great performance gains of around 16% for both GPU-based rendering and Unreal Engine.\"",
      "The people telling you that the 50 series will be widely available and that you have to wait actually don't have a clue and are just taking a wild guess. Either way, do whatever, just don't buy the 4060, it's trash with its 128bit bus length.",
      "There’s a massive difference in performance between a 4060ti and a 4070super",
      "Dude that card will be like 800",
      "Every professional 3d artist will tell you to get nvidia.",
      "Well we still gotta wait for people to sell their old cards. The new GPUs haven't released it.",
      "4060ti because of Vram which will be beneficial for those applications.",
      "Yup. Thinking about the 4060? Get a 4070. 4080? Get a 4090. Thinking about the 4090? Wait for the 5090.\n\nNinja edit: i have a feeling a lot of those comments are from kids (<18 yrs old) who have their parents buy stuff for them so they don't fully comprehend the financial aspect. It just doesn't compute. That, or rich people/trust fund babies who also don't comprehend being on a budget.",
      "My only cope is that there wasn't a 4070 super shortage, was able to buy it right at microcenter the same week so maybe it won't happen.",
      "Work takes priority over games so grab the 16gb card at the expense of gaming performance. Ideally you should be looking for an used 3090.",
      "Ah yes microcenter... if you are in US lucky you I guess."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "4060"
    ],
    "title": "3070 or 4060? ",
    "selftext": "Title, I’m making a new build and truly cannot decide between the 2 at such a similar price point. The CPU I’m going with is a R5 5700 with 32GB DDR4 Ram. I see that the 3070 tends to have higher frame rate, but people also say that the 4060 is faster. I’m looking to spend 300-350 if there’s any alternatives, also willing to buy used.  \n\n\nEdit: Currently looking at used 3080s right now. If you see this in the after this edit then please let me know if the 5600x will pair well with a 3080! Thanks to everyone ",
    "comments": [
      "Don't go with the 5700, because it's a 5700G with the iGPU disabled (only 16 MB L3 and no PCIE 4.0 support).  \n5600 is better than 5700, and its cheaper.  \n\n> I see that the 3070 tends to have higher frame rate, but people also say that the 4060 is faster.  \n\nWho said the 4060 is faster? 3070 has 27% more performance than 4060, on average. If they're the same price then go for 3070. \n\nAlso check the price of the 4060 Ti, it's slightly worse than 3070, but has much lower power consumption and some newer features that 30 series lacks, so if its similar price you should go for it.",
      "3070 is better. 4060 -could- use frame gen to close the gap somewhat, but frame gen is not no-strings-attached free FPS. It requires more VRAM and introduces input lag.\n\nAlso, at a limited budget, you will probably find better deals with an AMD card unless you absolutely refuse to use AMD / absolutely must have nVidia features. If OK with used, that budget could get you an RX 6800 XT used, which outright destroys both of those cards.",
      "This ^^^^ \n\nRead this u/ApprehensiveSouth604. Don't go with the 5700. Either get a 5600x/5600 or a 5700x or better. The 5700 is limited in performance and slower than a 5600/5600x despite having 2 extra cores",
      "I know this is an Nvidia sub but the RX 6800 is around the same price and raster performance level but with 16 GB VRAM",
      "Well they are both GPUs, RT really isn't a consideration at this performance level (I assume OP is aiming for 1440p gaming). Obviously DLSS is better than FSR. 8 GB of VRAM is not enough for several titles at 1440p unless you want to drop textures/settings. It is simply stating an option.",
      "Do not bother with the 5700, it performs [WORSE](https://www.youtube.com/watch?v=OCuVEuFIkew) than a 5600. You can get a 5700X cheaper or a 5800X for just a little bit more.\n\nHere in the UK, a 5700 is £160 on Amazon but they also have a 5700X for £159 or a 5800X for £162.\n\nHad a quick look on Amazon US. 5700 is $171, 5600X is $138, 5700X is $165 or the 5800X is $178.\n\nAs for the GPU, out of these two, I'd go for the 3070.",
      "3070 is faster. Whoever told you 4060 is faster is gaslighting you and themselves.\n\nAlso, don’t get the 5700. Get the either the 5700x or the 5600/5600x instead.",
      "Like the regular 4060? That’s practically a 3060. I’d take the 3070.",
      "Just to clarify, would you recommend a 5600, 5600, or 5700x? \n\nAs for the 4060 Ti, it’s about 390-410 range for new and around 320-400 used. I think I’ll stick with a 3070 but try find a used 4060 ti for the same price like you said.\n\nEdit: I have just found a 3070 Ti used for around $370 which I will be getting",
      "> Imagine there beeing a burger subreddit, where someone asked if people prefer mustard vs katchup on their burger and people would go: just eat a pizza.\n\nI don't think that is a very good analogy, mister",
      "Terrible analogy. Classic reddit moment.",
      "3070 can FSR 3 mod any game that has frame gen to be on par with the 4060 to be fair.\n\nedit: Maybe even surpass. The 3070 is basically the 4060Ti 8GB anyways.",
      "I dont think its right to compare a 3070 laptop with a fully fledged 3070 for your pc and no, 3070 is good enough to run heavy titles like cyberpunk at ultra with dlss and ray tracing enabled",
      "he didn't say anything about streaming, so idk why you're telling him to look at codec support. besides, AV1 isn't supported by most streaming platforms.",
      "3070 is light-years ahead of a 4060\n\nAnother option that costs about the same used is a 2080ti, 11gb VRAM and it can almost match a 6900XT in some games",
      "8gb is enough vram for 1080p not including unoptimized, demanding titles (looking at you hogwarts legacy and starfield.) 12gb is currently more than enough for almost any game at 1440p, but there are a few that exceed it. \n\n\nThat said, 16gb is useful to have considering how much vram use has been going up in New releases.\n\n\n3070 ti is also gross, it's a 3070 with gddr6x and some other minor differences. It's a 2-4% difference in most games",
      "> Just to clarify, would you recommend a 5600, 5600, or 5700x? \n\nYou named 5600 twice, but yea, 5600 is the best option. The two extra cores of the 5700X do almost nothing in games.  \nJust avoid the 5700 as it's a scam. The name could make you think that 5700 is just a lower clocked 5700X, but it's an entirely different CPU, with half the L3 cache and no PCIE 4.0 support.  \n\n> Edit: I have just found a 3070 Ti used for around $370   \n\n/u/DryClothes2894 has said that [you can get a 3080 on Facebook or eBay for $350](https://www.reddit.com/r/nvidia/comments/1dgilgq/3070_or_4060/l8r0qix/?context=3), so if he's not full of shit you can find a better option.",
      "The 4060 is either way the worst possible card you could buy for its 300 dollar price tag, way too many options that are significantly better, including its predecessor 3060",
      "yeah it was the VRAM and no I don't want to turn down settings only because I don't have enough VRAM.",
      "3080 used is the way to go if going Nvidia with that price range. 5600x will do well with it generally"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "4060"
    ],
    "title": "Why do people say that the RTX 4060/4060 ti are bad value?",
    "selftext": "I plan to build a gaming PC as soon as I have the money to, and having never done it before, I'm not exactly knowledgeable about what to look for.\n\nBut from what I can tell, the 4060 ti seems like the best value? What am I missing?\n\nI should probably mention that the price range I'm hoping to buy in is $300-500 for the GPU, and hoping to keep the total build cost under $1500. So the top-end cards are right out, \"great value\" or not. But when I go to https://gpu.userbenchmark.com/Compare/Nvidia-RTX-4090-vs-Nvidia-RTX-4060-Ti/4136vs4149 it seems like the 4060 ti gets you about 40% of the \"best\" for under 20% of the price? And I've seen multiple people saying that the 4090 is the best-value of the 4000 series.\n\nAm I missing something? Should I be looking at something other than the 4060 ti if I'm wanting a decent gaming PC in that price range?\n\nI'm hesitant to buy secondhand just because secondhand=no warranty, and also a few years of wear and tear would ostensibly mean fewer years I could expect the card to function. If secondhand is off the table, does that suddenly make the 4060 ti a better value? Is my problem that I'm comparing it with other 4000-series cards?\n\nBasically, bottom line, my budget is as I said above, and I want a PC that can comfortably run any game at 1080/60 with high settings (including VR), and that I can expect to at least run a new game for years to come.\n\nAs far as comparing it with other brands, I'm open to another brand if I'll get better performance for that price range, though I'm interested to at least try out raytracing, so I would like the card to at least be capable of it.\n\nIf the 4060 ti is, in fact, not the best buy for me, I'm open to suggestions - I'm just confused because it seems to be the most powerful card I can buy new in my price range, yet every opinion I see about it isn't good.",
    "comments": [
      "In a vacuum, the 4060ti kinda-sorta looks like a decent value.  \n\n\nThen you realize that Nvidia is charging $100 more for a card that *barely* outperforms the last generational equivalent (only 10-15% gains, on average) since it's got an inferior memory bandwidth and less VRAM.  Normally Nvidia's software solution would even things out, but DLSS and the like look like shit @ 1080p, and the 4060ti isn't really powerful enough to shine @ 1440p.  You could spend the extra $100 and get 16GB VRAM, but doing that versus getting a 7800XT would be ludicrous.  \n\n\nIt's just a really bad value compared not only to Nvidia's other current offerings (price/performance-ratio for the 4070S blows this thing out of the water) but also historically it just completely misses the mark of what folks expect from a 60ti-series GPU.  That being said, the market space right now for GPUs below $600 is just shitty in general, so you might not have much choice, OP 🤷‍♂️",
      "The issue you've done here is use userbenchmark",
      "\"I think AMD products aren't great\" That's where you're wrong",
      "While you're not wrong from my understanding comparing things like 2 Nvidia cards would be fine on that site because they're nvidia biased\n\nI do agree though, much better less biased sites.",
      "Amd can do raytracing aswell\n\nIt's not worth sacrifising so much performance for raytracing especially when you are only going to barely touch it but amd cards can do raytracing but not as good as nividia at the same level so the 7800xt will be 10-15% faster than a 4070 but can still do raytracing but probably at the same level as a 4060-4060ti",
      "7800xt performs 10-15% better than a 4070",
      "For 1500 budgets (not including peripherals) you should be able to go to 4070 s or 70t s",
      "I just bought a 4060 off of Amazon for $330 brand new. No complaints so far.",
      "Holy fucking shit, another victim of UserBenchmark bullshit. \n\nAs said before the 3060 is within 5-8% slower than the 4060, but for more money. A classic Nvidia “fuck you because I said so” move. \n\nIt’s not a bad card, it’s just priced horrible, and that’s the “drastic” prices cuts now. The 3060 with a decent overclock will preform better than the new card with a cheaper price tag. \n\nIf you have a budget for $500 it’s a no brainer get the 7800XT. And if you can find a sale a 4070.",
      "So, pulling up a couple Amazon listings,\n\n- The [particular 4060ti 16gb I was thinking looked like a good deal](https://www.amazon.com/ZOTAC-Graphics-IceStorm-Advanced-ZT-D40620F-10M/dp/B0CMJQZQC6/ref=sr_1_2?crid=1VHHIFIOLZA3R&dib=eyJ2IjoiMSJ9.6eHye-U6cH0MyXWk8CgU09eJYwXSfPDBV800GMsAnOaB8u1Lx6V3CvhEdDcyvZEnm0oKwd_PHn9V4pOlDG6R0d6-Kcz0r-5QABfxS7W-1II8e9QonptLYy38Nh8H0RBrMZ4lv-Hh4QPLrs9TO5r-wUBVjrHn7MJGAXow-4cK5SRmgnySazSR01YJyy1XdVxDBLNfLHbkG__LL7wQbgeOsRfRZd25jqB9HveDa-18ZOw.nqWvBmcYkcXaiZ8_k881cq_IdWmoP43zhMIWseXamt4&dib_tag=se&keywords=zotac+4060+ti+16gb&qid=1709168597&sprefix=zotac+%2Caps%2C421&sr=8-2)\n- The [first result for 7800XT](https://www.amazon.com/GIGABYTE-Graphics-WINDFORCE-GV-R78XTGAMING-OC-16GD/dp/B0CGHQ32S2/ref=asc_df_B0CGHQ32S2/?tag=hyprod-20&linkCode=df0&hvadid=675601120473&hvpos=&hvnetw=g&hvrand=7157679133117890673&hvpone=&hvptwo=&hvqmt=&hvdev=c&hvdvcmdl=&hvlocint=&hvlocphy=9033548&hvtargid=pla-2203607072058&psc=1&mcid=f402c1df37773e29a1dc2c56dcfa7cda&gad_source=1)\n\nHow much better off am I with the second, for $70 more? And in what way am I better off - raw performance? Are there any upsides/downsides to picking a Radeon card over Nvidia to consider, aside from raw numbers?",
      "You are correct. But people don’t know why userbenchmarks is bad. They just repeat that is it bad because others say it is bad. \n\nIt’s difficult to compare non like products.",
      "I'm thinking I'll go with the 4070 Super, or maybe just a 4070. I like the idea of the bells and whistles Nvidia does better (dlss and raytracing come to mind) even if I doubt I'll use them much, and I have a family member who likes Nvidia and has recommended them.\n\nThat said, honestly I'm wondering how much use I'll even get from the extra power compared to the 4060 I was looking at at first, because the gtx 970 I have right now is adequate for me. The only reasons I'm upgrading at all are\n\n- there were a few other things I wanted to upgrade with my PC so I decided I might as well do everything\n- a few edge-case games performed worse than I was happy with\n\nAnd a 4060 is, to my understanding, about 2.5x as powerful as the 970 I'm mostly satisfied with. Only reason I let myself be persuaded to bump up to a higher one is because more headroom=future proofing.",
      "They aren't, the issue is just the pricing is insane on all GPUs.\n\nIt looks like a bad value but also, when you have 3060ti selling for same price as a 4060 with similar performance and newer features like frame generation.\n\nI am seeing 4060 for 399.99 and a 3060ti is 429.99\n\nThe 4060 is also more power efficient if power consumption matters to you.\n\nI think people are just upset that in the performance of the 4060/ti vs 3060/ti disparity is so damn close at a very similar price point.\n\nIf you can snag a good deal on a 3060ti there is 0 reason to not choose it over the 4060.\n\nThere's no way the 4060 is a 'bad value' when it's cheaper than it's previous generations performance equivalent.\n\n[benchmark](https://youtu.be/a8gnnSQuDrY?si=7tVKzQa81xf0v8JO) shows the 3060ti and 4060 essentially neck and neck.",
      "I don’t know what you had in mind for your build, but you can easily get a 4070 super in the $1500 budget.\n\nAfter tax of 10% this build comes out to $1525\n\n[PCPartPicker Part List](https://pcpartpicker.com/list/DN239c)\n\nType|Item|Price\n:----|:----|:----\n**CPU** | [AMD Ryzen 5 7600X 4.7 GHz 6-Core Processor](https://pcpartpicker.com/product/66C48d/amd-ryzen-5-7600x-47-ghz-6-core-processor-100-100000593wof) | $213.95 @ Amazon \n**CPU Cooler** | [Thermalright Frozen Edge 69 CFM Liquid CPU Cooler](https://pcpartpicker.com/product/WhYRsY/thermalright-frozen-edge-69-cfm-liquid-cpu-cooler-fe240-white) | $46.59 @ Amazon \n**Motherboard** | [ASRock A620M Pro RS WiFi Micro ATX AM5 Motherboard](https://pcpartpicker.com/product/kvWJ7P/asrock-a620m-pro-rs-wifi-micro-atx-am5-motherboard-a620m-pro-rs-wifi) | $129.99 @ Amazon \n**Memory** | [TEAMGROUP T-Force Delta RGB 32 GB (2 x 16 GB) DDR5-6000 CL30 Memory](https://pcpartpicker.com/product/WFVmP6/teamgroup-t-force-delta-rgb-32-gb-2-x-16-gb-ddr5-6000-cl30-memory-ff4d532g6000hc30dc01) | $104.99 @ Newegg \n**Storage** | [TEAMGROUP T-Force Cardea Z44Q 2 TB M.2-2280 PCIe 4.0 X4 NVME Solid State Drive](https://pcpartpicker.com/product/pJ3gXL/teamgroup-t-force-cardea-z44q-2-tb-m2-2280-nvme-solid-state-drive-tm8fpq002t0c327) | $105.99 @ Amazon \n**Video Card** | [Asus DUAL OC GeForce RTX 4070 SUPER 12 GB Video Card](https://pcpartpicker.com/product/QksV3C/asus-dual-oc-geforce-rtx-4070-super-12-gb-video-card-dual-rtx4070s-o12g-white) | $629.99 @ Amazon \n**Case** | [Fractal Design Pop Air ATX Mid Tower Case](https://pcpartpicker.com/product/3nD7YJ/fractal-design-pop-air-atx-mid-tower-case-fd-c-por1a-01) | $59.99 @ B&H \n**Power Supply** | [Montech TITAN GOLD 850W 850 W 80+ Gold Certified Fully Modular ATX Power Supply](https://pcpartpicker.com/product/fJFbt6/montech-titan-gold-850w-850-w-80-gold-certified-fully-modular-atx-power-supply-titan-gold-850w) | $94.99 @ Amazon \n | *Prices include shipping, taxes, rebates, and discounts* |\n | **Total** | **$1386.48**\n | Generated by [PCPartPicker](https://pcpartpicker.com) 2024-02-28 21:06 EST-0500 |",
      "User benchmark is a crazy source lmao",
      "The 4070 is just a way better value. And tbh I think in every generation of Nvidia cards the 70 was the best value",
      "That’s not the issue when it isn’t wrong. The 4060 is actually one of the best price to performance cards from the 4000 series. The problem is Redditors are high refresh 1440p gamers or 4k gamers. Throw in that amd offers much better value at the low end. \n\n75%+ user 1080p or lower for their settings.  \n\nIf someone insists on nvidia, and they want to be 1080p high fps gamers or 1440p60 fps gamers, then get a 4060.\n\nThe 4070(ti) is not a card worth getting imo. The super series changes my opinion slightly. It just feels silly to spend 500-900 dollars on a card that won’t give you 5+ years of high end gaming at your current resolution.",
      "Took a quick look on Amazon, and found a Gigabyte 4070 12gb for $530 after a coupon, vs the 4060ti 16gb I was looking at is $430.\n\nWould the 23% higher cost give me more than a 23% better card? And looking at the 4070 Super, would the 40% higher cost get me more than 40% better card?\n\nMy budget's kinda fluid since I don't have the money and will need to save up regardless, all the budgeting does is determine how long until I can afford it.",
      "Amen! If you are interested on a gaming PC, way more than 20% of your budget should go to the GPU. Otherwise you are overspending in other parts with diminishing returns.",
      "I wouldn't get a a620 motorboard. Especially when you can get a better b650 motherboard for pretty much the same price."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "4060"
    ],
    "title": "1 of a kind RTX 4060 Ti",
    "selftext": "I won this GPU on Instagram from MSI and thought I would share some pictures of it. It is a one of a kind, custom modern warfare 3 RTX 4060 Ti (16GB version). The backplate has a RGB connector. All came in this awesome case 👌🏻",
    "comments": [
      "You think they would give away like a 4070ti or something at the minimum for a modern giveaway. Very cool nonetheless",
      "I am really not in a position to complain about the prize. I gave the card to my son who had a GTX 1650 Super. So it is a solid upgrade for him 👌🏻",
      "https://preview.redd.it/b1tarvflfnsc1.jpeg?width=1076&format=pjpg&auto=webp&s=6e132f1f45424f4a884dd1ed59ffd65182983406",
      "Wow, I just made the same upgrade, 1650 to a 4060, and it is a fucking insane difference",
      "shit was free bro... no need to be greedy xd its hella cool GPU either way xd",
      "My thought exactly! I am really happy!",
      "I think the 4060 Ti is a nice card despite the animosity the community has for it.",
      "I think the animosity comes from how absolutely beastly the 3060Ti was for the price when it released compared to previous gen, and the 4060Ti absolutely did NOT follow in its footsteps. It struggles to beat the 3060Ti by more than 5% and even performs *worse* in some games.  Doesn't help that the 4060Ti uses a 128-bit memory interface when the previous gen 3060Ti is 256-bit.\n\nThe 4060Ti itself is a decent card, if you aren't comparing it to previous gen. It's hard to argue with a free current gen GPU though, I wouldn't complain if I got a free one lol",
      "Coming from a Radeon 580 to a 4060 Ti. I agree, im overwhelmed with the possibility of games now lol",
      "Indeed. Kind of missed that lol. My bad. But still, 4060 isn’t that bad, it’s just priced badly. But if you get it free that’s awesome",
      "Awful pricing but a good card nonetheless",
      "Wow people actually get the giveaway cards?!",
      "Why do people have to come around and just straight up shit on things. Its free which makes it amazing regardless of what sort of card it was.",
      "Dunno why you got reddit DV. This was the first thing I thought of too. Ppl are strange.",
      "Damn 🔥🔥🔥 gaming in style",
      "Underrated part of this. For sure!",
      "I main a 4070 Ti in my desktop and recently bought a 4060 laptop. I’m surprised how well it compares to my desktop. Apparently the laptop 4060 has the same gpu core as the desktop 4060 and roughly the same performance which isn’t the case for most mobile discrete graphics. It feels like having a full ps5 or series x that I can play anywhere.",
      "Op is good father.",
      "Your son has bragging rights now for a 1 of a kind gpu ig.",
      "Well, you can’t beat free 99."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "4060"
    ],
    "title": "RTX 4060 Ti / 4060 Announcement Megathread",
    "selftext": "# This thread is best viewed on new Reddit.\n\n[GeForce RTX 4060 Family Image](https://preview.redd.it/uv1e9gfhmj0b1.jpg?width=1920&format=pjpg&auto=webp&s=77f014a17a7662c7bc0abfa8db51b63103e5bc4f)\n\nRTX 4060 Ti and 4060 have been announced here. The goal of this megathread is to provide everyone with the best information possible and consolidate any questions, feedback, and discussion to make it easier for NVIDIA’s community team to review them and bring them to appropriate people at NVIDIA.\n\n# GeForce RTX 40-Series GPU information:\n\n# [Official Spec Sheet Here](https://www.nvidia.com/en-us/geforce/graphics-cards/compare/?section=compare-specs)\n\n&#x200B;\n\n||**RTX 4060 Ti 8GB**|**RTX 4060 Ti 16GB**|**RTX 4060**|\n|:-|:-|:-|:-|\n|**GPU**|TSMC 4N AD106-350|TSMC 4N AD106-351|TSMC 4N AD107-400|\n|**Transistor**|TBD|TBD|TBD|\n|**Die Size**|TBD|TBD|TBD|\n|**Transistor Density**|TBD|TBD|TBD|\n|**GPC**|TBD|TBD|TBD|\n|**TPC**|TBD|TBD|TBD|\n|**SMs**|34 SM|34 SM|24 SM|\n|**TMUs**|TBD|TBD|TBD|\n|**ROPs**|TBD|TBD|TBD|\n|**Base Clock**|2.31 Ghz|2.31 Ghz|1.83 Ghz|\n|**Boost Clock**|2.54 Ghz|2.54 Ghz|2.46 Ghz|\n|**CUDA Cores**|4352 CUDA Cores|4352 CUDA Cores|3072 CUDA Cores|\n|**Shader FLOPS**|22 TFLOPS|22 TFLOPS|15 TFLOPS|\n|**RT Cores**|34 3rd Gen RT Cores|34 3rd Gen RT Cores|24 3rd Gen RT Cores|\n|**RT FLOPS**|51 TFLOPS|51 TFLOPS|35 TFLOPS|\n|**Tensor Cores**|136 4th Gen Tensor Cores|136 4th Gen Tensor Cores|96 4th Gen Tensor Cores|\n|**Tensor FLOPS (FP8)**|353 TFLOPS|353 TFLOPS|242 TFLOPS|\n|**Memory Interface**|128-bit|128-bit|128-bit|\n|**Memory Speed**|18 Gbps|18 Gbps|17 Gbps|\n|**Memory Bandwidth**|288 GB/s|288 GB/s|272 GB/s|\n|**VRAM Size**|8GB GDDR6|16GB GDDR6|8GB GDDR6|\n|**L2 Cache**|32 MB|32 MB|24 MB|\n|**Max TGP**|160W|165W|115W|\n|**PSU Requirement**|550W|550W|TBD|\n|**Price**|$399 MSRP|$499 MSRP|$299 MSRP|\n|**Release Date**|May 24|July 2023|July 2023|\n\n# Performance Shown\n\nBe sure to wait for independent benchmarks\n\n**RTX 4060 Ti vs. RTX 2060 SUPER**\n\n* 2.6x faster than RTX 2060 SUPER w/ Frame Generation\n* 1.6x faster than RTX 2060 Super in rasterization\n\n**RTX 4060 Ti vs. RTX 3060 Ti**\n\n* 1.7x faster than RTX 3060 Ti w/ Frame Generation\n* 1.15x faster than RTX 3060 Ti in rasterization\n\n**RTX 4060 vs. RTX 2060**\n\n* 2.3x faster than RTX 2060 w/ Frame Generation\n* 1.6x faster than RTX 2060 in rasterization\n\n**RTX 4060 vs. RTX 3060**\n\n* 1.7x faster than RTX 3060 w/ Frame Generation\n* 1.2x faster than RTX 3060 in rasterization\n\n# Power Comparison\n\n&#x200B;\n\n||RTX 2060 Super|RTX 3060 Ti|RTX 4060 Ti|\n|:-|:-|:-|:-|\n|Idle (W)|10W|12W|7W|\n|Video Playback (W)|15W|19W|13W|\n|Average Gaming (W)|168W|197W|140W|\n|TGP (W)|175W|200W|160W|\n\n&#x200B;\n\n||RTX 2060|RTX 3060|RTX 4060|\n|:-|:-|:-|:-|\n|Idle (W)|8W|8W|7W|\n|Video Playback (W)|14W|13W|11W|\n|Average Gaming (W)|138W|170W|110W|\n|TGP (W)|160W|170W|115W|\n\n&#x200B;\n\n# Power Supply Requirement (RTX 4060 Ti Founders Edition)\n\n[GeForce RTX 4060 Ti Founders Edition Power Supply Requirements](https://preview.redd.it/yt9g64ekmj0b1.jpg?width=1350&format=pjpg&auto=webp&s=44dc736df51136eef379cdf3d7d4487416fae581)\n\n# GeForce RTX 4060 Ti FAQ\n\nNvidia posted this FAQ on their forum. Link here: [https://www.nvidia.com/en-us/geforce/forums/geforce-graphics-cards/5/519266/geforce-rtx-4060-family-faq/](https://www.nvidia.com/en-us/geforce/forums/geforce-graphics-cards/5/519266/geforce-rtx-4060-family-faq/)\n\n**How does the RTX 4060 Ti perform compared to previous generations?**  \n\nThe GeForce RTX 4060 Ti is on average 70% faster than the RTX 3060 Ti with Frame Generation, and 15% without Frame Generation, across a suite of modern graphically demanding games at 1080p. Compared to the RTX 2060 SUPER, it’s 160% faster with Frame Generation, and 60% faster without Frame Generation.\n\n**How much power does the RTX 4060 Ti use?**\n\nRTX 4060 Ti is ultra-efficient - it has average gaming power consumption of 140 Watts, while the RTX 3060 Ti averages at 197 Watts when tested across 22 games at 1080p, 1440p, and 4K.  The recommended system power for an RTX 4060 Ti is 550W, although this may vary depending on graphics card model clocks and other components in your system.\n\n**Why does the RTX 4060 Ti have an option (16GB) with more graphics memory than the RTX 4070 & 4070 Ti (12GB)?**\n\nThis can happen occasionally based on the underlying GPU architecture; for example the RTX 3060 had more memory than the RTX 3070. With a 128-bit memory interface, it is not possible to outfit the RTX 4060 Ti & 4060 with 12GB of graphics memory. The memory configurations compatible with a 128-bit memory interface are 8GB and 16GB. However, the GPU itself is what mostly defines their performance, and that’s why GPUs are named the way they are. \n\n**Is 8GB VRAM enough for modern gaming titles at 1080p?**\n\nYes. GeForce RTX 4060 Ti and 4060 are able to run a wide range of modern games at over 100 fps at 1080p in our testing. In most games, both versions of the GeForce RTX 4060 Ti (8GB and 16GB) will deliver the same level of performance. There are a handful of games which play best at the “High” settings preset on the 4060 Ti (8GB) and “Ultra” settings on the 4060 Ti (16GB).\n\n**How does the frame buffer and memory subsystem on the RTX 4060 Ti differ from the prior generation?**\n\nThe RTX 4060 Ti has either 16GB or 8GB of graphics memory, compared to 8GB on the prior generation RTX 3060 Ti.\n\nThe RTX 4060 Ti’s L2 cache is 8x larger with a size of 32MB (versus 4MB on RTX 3060 Ti).\n\nThis allows us to store data much closer to the execution cores on a very high speed memory interface, with super low latency. This reduces the amount of traffic going across the memory bus to access the graphics memory.\n\nBy having a large L2 cache, we can get considerably more performance out of our GPUs without needing as wide a memory bus. Ultimately, the RTX 4060 Ti memory subsystem delivers better efficiency and better RTX gaming than the RTX 3060 Ti. \n\n**How can I measure the graphics memory usage of a particular game?** \n\nVarious tools attempt to measure graphics memory usage, but they don’t accurately report how much is actually needed to render a scene. Instead they are reporting how much memory is requested by the game, which varies for many reasons and shouldn’t be used as an indicator of how much the application actually needs. We’ve seen that games will request more memory on graphics cards that have more memory, simply because it’s freely available to them.\n\nInstead of using these memory measurements, we recommend looking at the “1% low” framerates instead, which more accurately convey the actual gaming experience.\n\n**What type of power connector do the RTX 4060 Ti and 4060 use?**\n\nThe RTX 4060 Ti (8GB) Founders Edition has a 16-pin PCIe Gen 5 connector. It can be powered by 1x PCIe 8-pin connector from the power supply to the adapter in the box.\n\nCertain partner models of the RTX 4060 Ti (8GB or 16GB) may use 1x PCIe 8-pin connector. \n\nThe RTX 4060 will be available in partner models powered by 1x PCIe 8-pin or 6-pin connector, or by PCIe Gen 5 connector.\n\n**How many NVENCs and NVDECs does RTX 4060 Ti and 4060 have?**\n\nRTX 4060 Ti and 4060 have one 8th Generation NVENC and one NVDEC.\n\n**Which games implement DLSS 3?**  \n\nFor a complete list of all DLSS supported games and applications, please refer to our official list that we regularly update here:  [https://www.nvidia.com/en-us/geforce/news/nvidia-rtx-games-engines-apps/](https://www.nvidia.com/en-us/geforce/news/nvidia-rtx-games-engines-apps/)\n\n# Other Announcements\n\n* **4060 Family Video**:  [https://www.youtube.com/watch?v=i0iC2VQgwes](https://www.youtube.com/watch?v=i0iC2VQgwes)\n* **A Deeper Look At VRAM On GeForce RTX 40 Series Graphics Cards**: [https://www.nvidia.com/en-us/geforce/news/rtx-40-series-vram-video-memory-explained/](https://www.nvidia.com/en-us/geforce/news/rtx-40-series-vram-video-memory-explained/)\n* **Win 1 of 460 GeForce RTX 4060 & 4060 Ti Graphics Cards In Our $150,000 Summer of #RTXON Sweepstakes**: [https://www.nvidia.com/en-us/geforce/news/win-rtx-4060-ti-graphics-cards/](https://www.nvidia.com/en-us/geforce/news/win-rtx-4060-ti-graphics-cards/)\n* **DLSS Brings AI-Accelerated Performance To Over 300 Games & Apps, Including D5 Render, Now Featuring DLSS 3**: [https://www.nvidia.com/en-us/geforce/news/300-dlss-games-apps-d5-render-dlss-3-update-available-now/](https://www.nvidia.com/en-us/geforce/news/300-dlss-games-apps-d5-render-dlss-3-update-available-now/)",
    "comments": [
      "Ok. I’ve read enough. Here’s my conclusion. If you NEED a GPU this year, ie: first computer, your GPU failed, your business is expanding, keep researching which 40 series is best for you. But, it your current setup works, wait. The incremental improvements just don’t matter.",
      "Half the 3060 Ti's die size and bus width for the same price. What a rip-off.",
      "I agree, I have a 3060ti and am not gonna fall for their frame generation bait. Give me a real performance increase",
      "NVIDIA, why are you not comparing the 4060Ti with the 3070? Hmmm",
      "Excuse me, but why would you go into this generation expecting that you should upgrade from 3060ti to 4060ti? At least wait one more generation if you're not going up the tier ladder, that's just common sense.",
      "nVIDIA loves people like you, who only look at the name instead of the specs.\n\nThis 4060 imposter is literally the new 1050 Ti specs wise, which was **139**$ back in the day.\n\nJust a hint: compare this to 4090 then the 1050 Ti to the 1080 Ti (the flagship back then) and tell me what you notice.",
      "$300 for an entry level, my oh my have the times changed. Such is life.",
      "Wow, those prices are bad. I bought the 4070 for a lower price than the 4060ti 16gb is supposed to cost.",
      "GN: https://www.youtube.com/watch?v=cQPGh2L6rB0\n\n\n\nHUB: https://www.youtube.com/watch?v=ocAi9y4n1UQ",
      "The ps5 can't run everything. \n\n\nIt uses upscaling just like pc gamers do.",
      "500$ for 4060ti 16 GB VRAM while there is RX 6800 16 GB that has been some time on the market for the same price and has more performance  . That is a huge rip-off from Nvidia side",
      "Only non-Ti 4060 seems moderately interesting; 8GB Ti just feels DOA. 4060 at the very least seems like a decent choice for a new card for a first time builder whos planning out a mid range system, just that VRAM will always be the concern here.",
      "Agreed. I upgraded my 1060FE to a 4070FE. Not everyone is sitting on a 3060 or better already. In fact, I'd argue 30 series owners shouldn't even be looking/commenting on the value of a single gen bump.\n\nFor the horde of 1060 and 2060 owners though, the 4070 or 4060 Ti 16GB are compelling. I'm inclined towards the 4070 for the performance bump, but the 16GB isn't bad if someone is worried about VRAM.",
      "I don't think you read their comment correctly. They are saying this looks like a good card to upgrade from the 10 series or lower. Not a good upgrade for 3060TI owners, nor potentially 2080+ owners.\n\nAs always, wait for actual tests to be completed/reviews.",
      "4060ti at 400 is no surprise. The 16gb version at 500 is ridiculous however. I thought Nvidia was responding to the criticism with the 16gb version, but they're not. They're either A. Afraid of consumers figuring out how much 8GB of VRAM actually costs them (20 dollars) or B. the 16gb version exists to upsell people to the 4070.",
      "My problem with this cards: Nvidia is doing the same move they did for the other 40 series cards, they are calling the card as the card the tier above it (so calling a 50 card as a 60 card) and then pricing it as the tier above the name they assigned to the card (so the \"60\" card which should be a 50 card is also priced as if it were a 70 card).\n\nI find it very bad that the 4060 Ti and 4060 launched with 8 GB in the first place and it is even worse that the 16 GB 4060 Ti costs 100 dollars more than the 8 GB version, imagine paying 499 dollars for a what is in reality a 4050 Ti: that ain't good happen right? Well, this is the sad reality.",
      "\"The incremental improvements just don’t matter.\"\n\nWhat if your GPU still works but its something like a 1070 or older? The improvements should be good enought.",
      "Keep simping for Nvidia and next time you'll get X107 die for 500$",
      "Because it's probably the same performance level for $100 less + DLSS 3 (for the 8GB version) or the same performance level with more VRAM for the same price + DLSS 3 (for the 16GB version)",
      "That's a tier up the ladder upgrade. Also, 3060ti was a lot better than 3060 in the 30 series generation.\n\nUpgrade from 3060ti to 4070 and that will be a decent upgrade as well. Or don't, because you should probably wait for RTX50 series instead."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "4060ti"
    ],
    "title": "Should I buy 4060ti or rx 7800xt ?",
    "selftext": "So I'm finally planning to upgrade from my 1060 3gb to either of these.\n\nI know 4060ti is equivalent to 7700xt and I should rather consider 4070s BUT \n\nIT IS ( 4070) $100 MORE THAN 7800xt.\n\nSo Recommend accordingly please.\n\nI plan to use the pc for : \n\n- Content creation, edits and Projects ( Softwares like After Effects, Premiere, Blender, etc). So will be rendering stuff frequently.\n\n- Gaming on max 1080p 75hz, don't care about 2k , it's fine if it's just playable on that resolution ahahaha. Only Care about actually playing the game to be up to date. That's it!\n\nBudget is $500\n\nThanx all.",
    "comments": [
      "The 7800XT is over 35% faster in games, if the apps you use need cuda then Nvidia, but anything else, amd.",
      "This is a wild take. 5080 is the 3rd fastest GPU in the world right now. 5080 or faster ? Seriously?",
      "Bruh the 7800xt it’s stronger and better Nivida is just there to gank yo money. I’m a video editor and have a 7800xt and a R9 paried together it’s smooth as butter",
      "Can you wait less than a month? Nvidia is expected to release the RTX 5060 and RTX 5060ti within the month of April 2025. I do not know the price range, but I expect the pricing for both would be between 330 and 500 dollars and the trend for the RTX 5060ti 16 GB would likely move toward the 600 price point immediately after release.",
      "There is no question.  \n\n\nIf you just Gane 7800xt\n\n\nIf you need to do work, 4070 or 4060ti.",
      "7800xt no doubt is better in games",
      "So a 7800xt shouldn't be a problem, but it's pretty overkill for 1080p 75hz, save some money and get a 7700xt",
      "What power supply?",
      "Who said 4060 ti is equal to 7700xt? 7700xt is 30% faster than 8 gb 4060 ti, go see benchmarks",
      "I feel like if you're looking at a 4060ti and have a newer CPU then the Intel b580 is way better value than a 4060ti lol. \n\nIt's not the strongest card, but has very good overclocking room, is cheap and has 12gb of VRAM. 4060ti just seems nonsencial at the price range mentioned",
      "You can't afford a decent Rendering Gpu, but you can afford it to wait a few minutes longer with an Amd gpu, and you get more value for your money",
      "Nice take, true tho",
      "7800XT will do the job just fine.\n\nPaying more than 250 bucks for a shitty nerfed 3060Ti makes no sense. Might as well buy a used 3060Ti/70 then.",
      "I love my 7800xt, its huge tho but every modern game you get 2k60fps",
      "Both cards will easily handle any game at 1080",
      "Browse around on subreddits for the applications you're going to use or might use in the future. Read recommendations from the software itself, and look for experiences others are having with AMD and which cards they're using. AMD GPU's have issues or simply perform poorly with SOME productivity applications, and other times they're perfectly fine.\n\nAsking in mostly gaming enthusiast subs aren't going to get the answers you're looking for.",
      "OP look into how nvenc/nvdec will help you in content creation.\n\nPrices are coming down fast atm for the 50 series. Just get a 5070 at this point.",
      "7800xt no question",
      "7800 XT it's not even close",
      "Can future proof yourself with a 9070xt"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "4060"
    ],
    "title": "Steam Hardware Survey (August 2024) – RTX 4060 Mobile surpasses GTX 1650!",
    "selftext": "Top 10 net increases:\n\n1. NVIDIA GeForce RTX 4060 Laptop GPU – +1.34%\n2. NVIDIA GeForce RTX 3060 Laptop GPU – +0.50%\n3. NVIDIA GeForce RTX 4050 Laptop GPU – +0.20%\n4. NVIDIA GeForce RTX 4070 Laptop GPU – +0.19%\n5. NVIDIA GeForce RTX 4070 SUPER – +0.17%\n6. NVIDIA GeForce MX450 – 0.15%\n7. NVIDIA GeForce RTX 3050 – +0.11%\n8. NVIDIA GeForce RTX 4070 Ti – +0.10%\n9. NVIDIA GeForce RTX 4070 Ti SUPER – +0.10%\n10. AMD Radeon(TM) Graphics – +0.10%\n\nThe current top 10 are:\n\n1. NVIDIA GeForce RTX 3060 – 5.36%\n2. NVIDIA GeForce RTX 4060 Laptop GPU – 4.41%\n3. NVIDIA GeForce GTX 1650 – 3.80%\n4. NVIDIA GeForce RTX 3060 Laptop GPU – 3.39%\n5. NVIDIA GeForce RTX 3060 Ti – 3.33%\n6. NVIDIA GeForce RTX 4060 – 3.31%\n7. NVIDIA GeForce RTX 2060 – 3.06%\n8. NVIDIA GeForce RTX 3070 – 3.06%\n9. NVIDIA GeForce GTX 1060 – 2.86%\n10. NVIDIA GeForce RTX 4060 Ti – 2.81%\n\n[https://store.steampowered.com/hwsurvey/videocard/](https://store.steampowered.com/hwsurvey/videocard/)",
    "comments": [
      "I really thought there would be more than **0.98%** users with a 4090, but I guess these subreddits / forums paint a very wrong picture.",
      "Subreddits of tech companies usually attract enthusiasts",
      "You got downvoted for being rude, it was well deserved.",
      "1% is still a ridiculously high percentage when you consider the amount of older PCs there are and the cost of the part",
      "Sounds like you *really do* care. \n\nSave everyone around you a headache, and keep your forked tongue behind your teeth.",
      "Using a 4060 on a laptop right now, absolute beast for the price ao it's definitely worth it",
      "There are more 4090 users than ANY dedicated radeon gpu from any generation, thats insane.",
      "Shit 1 % is a lot considering the price",
      "Turns out not alot of people have $2.5k to drop on a laptop :(",
      "For Laptops: The 4050 only got 6 GB of VRAM and is quite a bit slower than the 4060 while being priced to high in comparison.\n\nThe mobile 4070 still only got the same 8GB of VRAM than the 4060 while being only a bit faster and more expensive. If you want a real performance uplift you need to go with the mobile 4080 and thats just priced to high.\n\nSo the mobile 4060 just got the best price/performance ratio.",
      "interesting that no ones into xx50 and xx70s.\n\nus there a reason why everyone has the xx60s?",
      "Yet reddit would have you believe there is lots of amd users as they encourage people to get it. Food for thought how representative subs are",
      "Cheap barrier of entry and Nvidia brand name.  Despite having shit performance to the dollar the name sells to dumb chuds.  Edit: this is in reference to the 4060.  You see 4060 in prebuilts everywhere and people are buying it.  Hell, before I entered the market I was eyeing up a 4060 Ti 16gb \"just cause I wasn't ever gonna need more than 1080p 60\" nvidia and the performance of the 60 series GPUs the past decade until I started looking into things a bit more.  A 4060 on launch can't do what a 1060 6gb on launch without compromises (DLSS, framegen are compromises and even then you may not be able to max out some titles).  \n\nIn general XX60s are pretty good value but this generation is particularly bad + the demand caused massive price surges that still haven't come down.  I bet money that Nvidia was banking on AI/Crypto to be continually big which is why they charged ridiculous prices on the 40 series on launch + launched shit tier high margin 4060s. Thankfully AI is seemingly a passing consumer trend and crypto is dying like it fucking should. \n\nOnly by 2024 are we seeing (relatively) good value GPUs (4070 Super, 4080 Super, 4070 Ti Super).",
      "Marketing. The xx60 GPU used to be the go to mid range option, but the 40 series screwed us all over. The 4060 is an awful card for its price but many people don't understand that and think they are getting a great card. Why do you think we don't have a 4050 this generation? Because the 4060 is the 4050. In fact the 4060 performance is sometimes worse than the 3060.",
      "They don't paint wrong pictures, there's just more users who prefer to stay lowkey. The proportions of gamers who even posts in Reddit compared to the actual number has a huge gap. To be honest, I'm surprised there are 0.98% of people who even has a 4090. I expected less than 0.80%.",
      "hey guys look at me i think the 8 year old $40 gpu is a potato !! haha get it like the food?",
      "Whats that Radeon Graphics? Its the integrated gpu?",
      "Yes.",
      "4070 laptops are about 500 (low tgp) to 1000 dollars more where I live lmao, that and the fact the difference between the 2 isn't as big compared to desktop version, like 18% better I think\n\ni got my lenovo loq 15 for a decent price so there is that",
      "cant believe there's more 4090 users than rx580. Dang"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "4060"
    ],
    "title": "[Daniel Owen] RTX 4060 Early Benchmarks!!! Cyberpunk RT Ultra 1080p w/DLSS vs 2060, 3050, 3060, 3060 Ti, 4060 Ti",
    "selftext": "",
    "comments": [
      "So it wasn’t just Jayztwocents nvidia tricked. \nThere was a reason they don’t want 1440p results shown. \nGlad gamers nexus are staying true to themselves and refuse to sell out for a early upload date",
      "Gonna go ahead and call it: Reddit is wrong and the 4060 will sell like hotcakes.\n\nGamers don’t care about cuda cores and memory bus width. They’ll see a shiny new 4060 on the shelves for $299 and buy it. It will smash literally every game at 1080p, and they won’t be withheld from any current features like Dlss 3",
      "jayztwocents make the most click-bait videos ever with his stupid face all over the thumbnail. I'd rather watch gamernexus or hardware unboxed or paul's hardware or linus tt",
      "They really want to push this dlss thing to make it look like new gpus are so much better lmao",
      "I usually watch Daniel Owen, gamers nexus and DerBauer for gaming benchmarks, temperatures and an honest opinion. \n\nI can’t take JayZtwoCents serious after he claimed AMD GPUs Are dying Video",
      "thats some dank prices lmao new 3060 tis are still 350+ here lol",
      "Of course it will sell. Look at 3060, it was hardly better than 2060 super so pretty similar to how meh 4060 is and it's the most popular 3000 series card.\n\nAlso, 4060 probably looks pretty damn good for people upgrading from their sluggish 1060 etc to modern times.",
      "I'm really interested to see the 4060 vs 3060 Ti in a wide range of titles. In theory on average the 3060 Ti should be ~10% faster at 1080p with the gap rapidly widening at higher resolutions. With the sale prices we've seen recently it'll be interesting to see what reviewers find. Best new prices I've seen:\n\nRTX 3060 12GB: $259.99\n\nRTX 3060 Ti: $274.99\n\nand the 4060 is $299.99",
      "Well Owen is fine, need to give him credit for being honest in the vid, he makes it clear that the things he can show is forced by NV, he even uses \"NV approved settings\" phrase, lmao\n\nI like his way",
      "Dude, it's actually such a disingenuous sales strategy. These cards are NOT any better than their predecessors. Lower Cuda core counts, lower tensor core counts, lower rt core counts, smaller bus width. \n\n\nThey are inferior in almost every single way that matters. They're 100% being inflated by software gains/dlss 3.0. \n\n\nSuch a scummy move from nvidia this whole generation. The added price increase is just salt on the wound and an absolute slap in the face. Absolute unchecked greed. They need a huge reality check. This \"4060\" has the specs of a 50 tier card. Everyone sees that, and this card will sell just as poorly as the 4060ti in all of its flavors. I'd go so far as to say anyone buying a 128bit bus width card is actively sabotaging their gaming experience.",
      "Have many people been saying it will sell poorly? I think the general consensus is the GPU sucks (especially in the face of now discounted 30 series GPUs) but of course consumers will eat this GPU up. This or the 6GB 4050 will be gunning for top spot on the Steam Hardware Survey in a year or so.",
      "Frame generation has acceptable results if you already reaching 60 fps natively . Otherwise it only adds latency to a already not best input delay ( when getting  sub 60 fps )",
      "1) the interpolator has lower quality information to work from at lower framerates, since the frames it uses to generate the \"tween\" frame are further apart temporally. this results in greater artifacting  \n2) the generated frames are visible longer at lower framerates, making artifacts more noticeable  \n3) the more frames you have to begin with, the lower the latency penalty is  \n\n\nthese three together mean that dlss FG undoubtedly gives better results when interpolating at higher base framerates",
      "The less frames you have, the less smooth it is and shows the limitations of the frame generation even more. It's not just a latency problem.",
      "Dlss 3 at same settings as amd & intel has 50% lower latency. But if he says FG is situational, then dlss, reflex & Rt is situation as well. Yes im aware by situational he means you need 60fps, but I beg the differ, I think dlss 3 + reflex at 50fps probably has lower latency than non-reflex 60fps",
      "I don’t know how ppl are still taking him serious, \n\nAll he does is hot takes and as you said clickbait",
      "He didn't hide anything, open from the start, it's fine.",
      "To be fair the 3060 launched at a time where GPU demand was just at and obscene level.",
      "I gave up on cyberpunk. I have the 4090 and the newest update. It crashes within a few min every time.",
      "It's not just shiny reflections. And Cyberpunk doesn't look like shit, far from it"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "4060"
    ],
    "title": "AMD Radeon RX 7600S RDNA3 laptop GPU tested, 6% slower than RTX 4060 without raytracing",
    "selftext": "",
    "comments": [
      "Began the Underwhelming Releases have.",
      "Honestly the rest of the 7000 series were underwhelming too. Cards that cost almost as much as Nvidia cards, spend more power, can do only pure rasterisation and don't have any other capabilities for gaming or professional work. Paying a grand for a card like that is just a bad deal unless you only play pure rasterisation at native res.",
      "Both Nvidia and AMD slowly but surely killing PC gaming",
      "So you're telling me that a Navi 33 7600S loses to a AD107 based RTX 4060? Sheesh, we truly reached bottom of the barrel for mid/low-end GPUs.",
      ">spend more power,\n\nLeast we got the amusement of seeing the biggest fanatics suddenly do an about face on the topic of powerdraw and efficiency.",
      "When it comes to amd vs nvidia gpus power draw /power efficiency doesn't matter. When it comes to Intel vs amd cpus it does.  Duh",
      "Well, it seems this is a generation to skip... Let's hope the next one is good enough...",
      "> When it comes to amd vs nvidia gpus power draw /power efficiency doesn't matter.\n\nOnly with GCN and RDNA3. With RDNA2 it's the consumers top concern and every watt is vital!",
      "Most games won't go full path tracing until the consoles are capable of it.",
      "Higher FPS > RT all day",
      "Which is why i think more people should be a little more disappointed in AMD's ray tracing designs/gains.  These directly translate to the consoles.  Since console drive a lot of development and design for future games, having them holding back the industry kind of sucks for all parties involved.\n\nI'm not even saying that nvidia is doing the right thing, but clearly with the amount they keep putting RT into console games, they'd REALLY appreciate if they could put it in properly and i don't see them being able to do that next gen without some sort of custom RT cores on an updated pro console.",
      "AMD look certainly more interested in consoles but PC still one of the core and fundamental field for NVIDIA",
      "Looking at rapid growth of „AI” it can quickly change. Nvidia bet everything on AI for a reason, Jensen is a smart man. Machine learning doesnt depend on consumer cards iirc",
      "But people buy NVIDIA just because of its name and everyone else do... according to some very successful clown youtubers I wont name that feel the duty to correct a \"wrong\" market",
      "And Kopite7 has suggested a couple of times that the plan for desktop 4060 is 3072 shaders... 24x128... AD107",
      "Yep, everyone buying a $300 gpu should be able to run 4k ultra with full path tracing! Anything less is unacceptable!",
      "Let's not pretend the barrier of entry to PC gaming is very high. $600 will get you playing all the new AAA games just fine.\n\n[PCPartPicker Part List](https://pcpartpicker.com/list/Pgxx78)\n\nType|Item|Price\n:----|:----|:----\n**CPU** | [AMD Ryzen 5 5500 3.6 GHz 6-Core Processor](https://pcpartpicker.com/product/yq2WGX/amd-ryzen-5-5500-36-ghz-6-core-processor-100-100000457box) | $96.99 @ Amazon \n**Motherboard** | [Asus Prime B450M-A II Micro ATX AM4 Motherboard](https://pcpartpicker.com/product/kthmP6/asus-prime-b450m-a-ii-micro-atx-am4-motherboard-prime-b450m-a-ii) | $79.99 @ Newegg \n**Memory** | [TEAMGROUP T-Create Expert 16 GB (2 x 8 GB) DDR4-3200 CL16 Memory](https://pcpartpicker.com/product/MRcG3C/teamgroup-t-create-expert-16-gb-2-x-8-gb-ddr4-3200-cl16-memory-ttced416g3200hc16fdc01) | $33.99 @ Amazon \n**Storage** | [Silicon Power P34A80 1 TB M.2-2280 PCIe 3.0 X4 NVME Solid State Drive](https://pcpartpicker.com/product/VXyqqs/silicon-power-p34a80-1-tb-m2-2280-nvme-solid-state-drive-su001tbp34a80m28ab) | $45.99 @ Amazon \n**Video Card** | [Gigabyte EAGLE Radeon RX 6600 8 GB Video Card](https://pcpartpicker.com/product/G9ytt6/gigabyte-radeon-rx-6600-8-gb-eagle-video-card-gv-r66eagle-8gd) | $199.99 @ Newegg \n**Case** | [Deepcool MATREXX 40 3FS MicroATX Mini Tower Case](https://pcpartpicker.com/product/36gFf7/deepcool-matrexx-40-3fs-microatx-mid-tower-case-dp-matx-matrexx40-3fs) | $59.99 @ B&H \n**Power Supply** | [Thermaltake Smart BM2 550 W 80+ Bronze Certified Semi-modular ATX Power Supply](https://pcpartpicker.com/product/xQpmP6/thermaltake-smart-bm2-550-w-80-bronze-certified-semi-modular-atx-power-supply-ps-spd-0550mnfabu-1) | $54.99 @ Amazon \n | *Prices include shipping, taxes, rebates, and discounts* |\n | **Total** | **$571.93**\n | Generated by [PCPartPicker](https://pcpartpicker.com) 2023-04-21 12:07 EDT-0400 |",
      "Wherever you see that, it's because of the card utilizing rasterisation as a crutch, the heavier the RT implementation,  the worse the xtx card would do. The 7000 series could at least be said to be capable of turning on RT compared to the 6000 series. But if you want to see the pure RT power of the 7900xtx, then the game you want to look at is path traced Cuberpunk. That game has pure RT lighting, and there it's roughly on par with the 2080ti. The 7900xtx gets beaten by even the 3070, the 3090 leaves it behind in the dust.",
      "Yeah, both Mobile and Desktop 4060 are based on AD107. Worse yet, the 4050 Desktop (The other AD107 based card) will have fewer SM than Mobile version and only 6GB VRAM (96-bit).",
      "Is there no end to the torrent of bad news? At this rate it'll be nothing but prayers for Intel to switch things up"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "4060"
    ],
    "title": "Clock speeds for custom GeForce RTX 4060 Ti GPUs confirmed by retailer",
    "selftext": "",
    "comments": [
      "8gb vram ez pass",
      "No one should be buying an 8gb in the 60 class in 2023. [No one should be making it in the first place](https://www.youtube.com/watch?v=3qJHbihLmcA&t=3690s).",
      "8GB of VRAM pretty much turns this into a 1080p card. A year down the road this will be terrible for 1440p, this should have had 12GB. It would've at least made it a good budget 1440p option.",
      "You are actually delusional if you think this card can’t do 1080p.",
      "Then why would anyone waste a ton of money for a 1080p card if they already have plenty of better options?",
      "Its probably going to be around $400-500 for RTX 3070 like performance, bullshit pricing.",
      "You people are insane lol",
      "Agree Nvidia entire RTX line up is F up. \n\n4080 should be using AD102 with 20GB 320bit bus.\n\n4070ti/4070 should be using AD103 with 16GB vram\n\n4060Ti/4060 should be using AD104 with 12GB vram.",
      "I just got my self a 3060ti",
      "40 series had a huge increase in on-die cache. Similar to what AMD calls their infinity cache.",
      "I have a feeling that 2310 is the base clock while 2685 is the boost clock, so they aren't directly comparable. 16% is way too much.",
      "They became the apple of gpus",
      "The hysteria is real, people are losing their shit over a few awful ports.\n\nAlmost feels like subconscious guerilla marketing for an exuse to sell low range cards at a higher price with more VRAM just because a couple of games are optimized like shit.",
      "2685MHz vs 2310MHz is a 16% difference.\n\nedit:\n\nModel | Clock Speed\n---|---\nPalit 4060TI DUAL | 2310\nPalit 4060TI DUAL OC | 2685\nPalit 4060TI STORMX (NES6406T**S**19P1)  | 2670\nPalit 4060TI STORMX (NES6406T**0**19P1) | 2535",
      "It's a great card. Really satisfied with mine, run everything I've thrown at it mostly on high/ultra 1080p.\n\nThere's always 'better' cards out there, so don't worry about it, in case you were.",
      "It looks like crap on paper, and will probably be very expensive for an entry level card. But people on a budget don't have too many sub $400 options these days.\n\n&nbsp;\n\nAs always, wait for Gamers Nexus to review it.",
      "I have a 3060ti doing 1440p ultrawide. I know it can do 1080p I just wouldn't bother. I won't bother buying another card until I get a reasonable priced 16gb card there's no point in buying a card with less VRAM than a console even if it just 1080p",
      "Couldn’t we already get 3070 performance for $500 by buying, *checks notes* a 3070?",
      "Thats actually very important for people with old mainboards who support only pcie gen 3 x16",
      "If you are homeless, just buy a house"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "4060"
    ],
    "title": "Replacing my 1060, RTX 4060 and RTX 3060 are selling for the same price. Which should I get?",
    "selftext": "As per title. I was going to actually stretch my 1060 for another couple of years and get a 6060 (I was weirdly invested in keeping it going for ten years :P :V) , but it caught fire in a freak accident and I need to buy a new GPU (alongside a completely new system).\n\nRight now, in my country, the 3060 12GB and 4060 8GB are selling for about the same price. Which would this sub suggest I purchase?",
    "comments": [
      "4060, easy choice. More DLSS features, more efficient, a little faster. 8 GB is embarrassing for them, but realistically if you're playing on lower resolutions it's not that big of a deal.",
      "4060",
      "40 series for the added benefits of DLSS and frame generation would be my choice.",
      "Common sense getting upvoted? Is this Reddit?",
      "*benefit of frame gen. Rest of DLSS features, as in upscaler and RR denoiser, are awailable on all RTX cards.",
      "3060 for 12GB of vram\n\n4060 for Frame Generation and better power efficiency \n\nFyi, there are games where the 4060 loses to the 3060, and the 4060 only has 8G  of vram, so keep that in mind.",
      "The 4060 isn't a terrible card (it's not good, that bandwidth is trash) but it's the pricing that's a doublewhammy of garbage.",
      "WaIt UnTiL tHe 5060 lAuNcH\n\nIn all seriousness the 4060 is still the better choice if the price is the same, it got shit on at launch since it was more expensive and basically the same performance without dlss etc.",
      "Yeah, I'm sticking to 1080p for the medium term because I just don't have the cash to upgrade to a 1440p or 4k monitor, and tbh even if price wasn't an object, I'd still stick at 1080p because I value frames over resolution.",
      "I have a 3070 with 8 gb. You'll be absolutely fine for 1080p, none of my games struggled to run",
      "Yeah I'm gonna have to disagree on the 1440 part.\n\nIt's one thing if the generational uplift is bad but that in some cases a 3060 ti can be on par with it even if early in launch is seriously trash especially when you can note the smaller bandwidth - very clearly cheapening out was occuring.\n\nNot only that but the 8gb versions very obviously suffer from performance issues when VRAM is maxed out.",
      "If the 4060 and 3060 are selling for the same price, it’s a no brainer to get the 4060. Even if it’s 8GB compared to the 12GB 3060 it still gets outperformed by 4060",
      "to be fair, I don't anticipate ever progressing beyond 1080p gaming for a **long** while.",
      "At 1080 and even 1440p the 4060 isn’t a bad card. Its actually pretty solid, but It’s just not the best card you could get for the price and performance. That combo has given it a bad reputation.",
      "I actually have a 4060 and have tested it. Obviously it’s not going to be a perfect 60fps playing online fps games, but It can indeed do 1440p with story games. No offense but I find people who speak about what the 4060 can’t do have never actually used one and are really just guestimating based on what they’ve read online.",
      "4060 easy choice, why?\n\n1. More efficient  (performane Per watt)\n2. Frame Generation feature (better than FSR3)\n3. 15% better performance",
      "I would agree. I just upgraded to a 4060 from a 1060 6gb and it's night and day. But I'm old and still do 1080",
      "As long as the v ram is limited under 8 it can run any game 🏃...just have to tweak some unwanted settings, that have little to no effect to game quality....(For 1440p/1600p)..@ 1080p won't lack vram as of now.",
      "Yea I meant it as satire as people will tell you to wait.\n\nPersonally I'm also waiting for 5070/5080 depending on price/performance but going half a year or more without a gpu to save a couple bucks and gain a bit of performance isn't worth it. Just get it now and enjoy it!\n\nBut good on you for not upgrading every release, it can be very tempting.",
      "Haha. My 3070ti serves me fine for 1440p but I have worked my ass off this summer while everyone else took their vacations so thought I could give myself a bonus of a 5070/5080 if the price to performance is good on either.\n\nCurrently 14 hours into a 24hour shift lol another 12 tomorrow and the day after as well haha."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "4060"
    ],
    "title": "Disregarding the price, does the 4060 Ti 8GB a decent 1080P card for me?",
    "selftext": "Prefers:\n\n-Power Efficient\n\n-Acceptable/At least Playable Ray Tracing Performance(in games like Cyberpunk)\n\n-Can handle the most demanding titles at decently high settings at 1080P.\n\nThere is a 16GB version. Does the extra cost of it worth the better lifespan or headroom for Ray Tracing+FG that uses a lot of VRAM? Or is sticking to an 8GB fine?\n\nAs much as I wanted to go to the RTX 4070 Super it's just too over the top for my resolution.\n\n\n",
    "comments": [
      "Things like FG, Ray tracing, and path tracing are pretty VRAM heavy. Ultimately, if you wanted to use those, I would start with a 4070s and up.",
      "The big issue people had with the 4060 and 4060 ti cards were pricing and positioning. The card is fine for 1080P, but at launch didn't offer any significant performance gain but a higher price tag. (IMO if nVidia had called the 4060 Ti the 4060, and the 4060 the 4050, then cut $10 off the MSRPs reviewers would have been taking about what a jump in performance they offered instead of how they were more expensive but performed about the same as the 3000 series counterparts.)",
      "IMO, 4060 class of cards are not really meant to do RT with extremely demanding RT games like Cyberpunk. FG also requires more VRAM on top of RT, plus, you must already be outputting more than 60 fps for FG to be not janky.\n\nDLSS, sure, but using DLSS on 1080p is less than ideal.\n\nAll in all, if you want to run very demanding RT games, 4070 is the absolute minimum I would get, with 4070s being a good starting point.",
      "30 fps with frame gen? So like 15 fps, the input lag is ridiculous at that point, plus FG has to many artifacts because each generated frame is staying on screen for too long, since the base fps are super low\nI’d say 50 fps is the least you want to get to activate frame gen.\n\nThis was really shitty advice, I’m not going to discuss if you enjoy it or not, but this you are describing is a really terrible experience for 90% of the people interested in a game like cyberpunk.",
      "8gb is almost never enough for Raytracing",
      "Yes, they are VRAM-heavy, but at 1080p DLSS quality, 8GB is enough. I speak from experience; I play Cyberpunk 2077 with path tracing, ray reconstruction, and frame generation at DLSS 0.72 resolution (better than quality) at approximately 75 fps. As you can imagine, this is the most demanding game that I play, so everything else runs more than fine.",
      "Honestly, if you want to use ray tracing I'd recommend a 4070 super even at 1080p. Sure, 1440p is the optimal res for that card, but ray tracing is still really heavy even at 1080p.",
      ">PT \n\nNo way in hell PT works for you. It barely work on my 4090 at 1440p with DLLS SR and FG, and my GPU is over 6 times faster.",
      "My 4090 works fine, it is even above average in Firestrike.\n\nKid me considered 12 FPS San Andreas \"smooth\", does not mean it was. If you play at 30-40 FPS you must be at 540p and use FG. FG adds insane lag and artifacting if you are at low FPS, is is unusable under 40.",
      "8gb of VRAM is definitely not enough if u wanna play recent triple A games at max settings. Looking at the memory usage per process with MSI Afterburner, games like Ghost of Tsushima, Ratchet and Clank, and TLOU (though this game is severely unoptimized so imo it shouldn't rly be considered) are using up over 8gigs of VRAM.",
      "30fps is unplayable to most people, not even casual gamers. Bare minimum to cope for me personally would be like 45+ fps since at least as long as you aren’t turning your screen fast you can feasibly watch the environment as you stand still.",
      "i7 13620 \n\nDamn, people really didn't like my comment",
      "Well check the new system requirements for Star Wars Outlaws. It could be a good indication for the new coming AAA games. \n\nI recommend min 4070",
      "What’s playable FPS to you?",
      "Its not about what people like, the 4060ti is just a bad choice for a sub $350 GPU.  Raw raster will be better for cards in OPs price range. Once you start getting to the -70 seires and above frame gen and dlss3 really start to shine and make them the best choices. Every other commentor is telling them to just spend $200 more, and Id say to do so to, but if you really want a $300 gpu a 7600xt will be much better.",
      "I get 120FPS with those exact same settings on my setup...",
      "30 singleplayer or console stable no dips. Although games like Cyberpunk I perfer at least 40fps stable capping it on my 120hz display looks fairly nice. Definitely not a ideal fps for sure it's playable. Frame time and pace matter more though as long as it's not stuttering and frames are nicely paced 30fps looks better than a unstable 60.\n\nEdit: I don't play competitive games and mostly console, my laptop ain't a gaming laptop but, it has surprised me tho",
      "[https://www.youtube.com/watch?v=dDQav43OHtY](https://www.youtube.com/watch?v=dDQav43OHtY) here is some comparison in CP77",
      "Cyberpunk running at 1080p w/ RT Overdrive with DLSS Quality will get you framerates in the 40s. If I were you, I would upgrade to something that gets you **at least** 60fps, ideally more. It'd be a bummer to upgrade to something and games already don't run as well as you'd like.\n\nThe 4070 Super isn't overkill at all for that resolution",
      "I don't think people here like Radeon bro. It is the far better option in this price bracket but I'm assuming this guy wants to spend extra on a geforce card. But you are right, geforce starts getting interesting at the 4070 and above."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "4060"
    ],
    "title": "GeForce RTX 4060 is the worst GPU launch in recent times - 3DCenter.org",
    "selftext": "",
    "comments": [
      "Nvidia: \"Hold my beer... again.\"",
      "They are gimping their gpus so much, so that anyone who buys it will be forced to upgrade sooner, and overcharging in the process.\n\nLimited vram, small memory bus, cheap components, limited overclocking, terrible value compared to what's out there already, no price/performance over previous gen, burnt power connectors, shifting naming scheme up a tier, marketing BS, and so on.\n\nAnd they struggle to outperform last gen too.\n\nGlad we live in a time where the average gpu buyer are well informed.",
      "Or just shift down the entire range except for the 4080 and 4090?\n\nSo:\n\n* 4070 Ti 12GB as the 4070 12GB\n* 4070 12GB as the 4060 Ti 12GB\n* 4060 Ti 16GB as the 4060 16GB\n* 4060 8GB as the 4050 8GB\n\nAdd a 16GB 4080 Ti to the list and it's quite OK, IMO. Where I live, prices are kinda close to where Pascal was at launch, adjusted for inflation, with the 4080 not being priced too well.",
      "It's such an underwhelming generation, I would love to swap out my RTX3080 for the 4080. But the knwoledge that I paid 719 for the 3080 at launch and the 4080 is basically double that for 50% more performance. Doesn't feel like a good value. Could go to the 4090. BUt paying 1800 for just a GPU feels like.....I rather spend that on other stuff in my life at this point.",
      "I'm gonna hold how many beers they want if that means they hit their head into a wall so hard they are forced to come back to their senses and stop throwing up crap",
      "i mean it's not like you have to upgrade every generation either.\n\nI don't think there was really a compelling reason to upgrade from the 1080 ti for the last 6 years and i *like* RT and DLSS.",
      "What they should do:\n\n4060 16GB 256bit bus for $299, Ti was unnecessary.",
      "4090 has a correct name and ok price. \n\n4080 has correct name but a bad price. \n\nEvery other 40 series GPU has both wrong name and bad price.",
      "I think most prefer Nvidia due to the power of DLSS. Not that AMD isn't good, just that the Nvidia architecture revolving around DLSS is important to many. Also AMD isn't much cheaper at all these days. The best thing we as a consumer can do is vote with our wallets and wait until we get a GPU that's worth the money (hopefully the 5 series Nvidia or 8 series AMD).",
      "Performance of 4080 is ok. MSRP of 4080 is not ok.",
      "It's sad when the 3060ti outperforms the 4060.",
      "The 4060 is a decent 3050 successor and should be $250 maximum, though even that is too high.\n\nIf Nvidia wanted to cheap out on memory this generation, I would take a 10GB 160-bit 4060, 12GB 192-bit 4060 Ti, 14GB 224-bit 4070, and 16GB 256-bit 4070 Ti. And they would have to raise the core counts at least half a tier from where they are now. The 4070 shouldn't have the same number of cores as the 3070, even if there's architectural improvements. That's Nvidia taking all the node density benefit for their bottom line instead of buyers' benefit. Oh plus it's $100 more.",
      "> Shit GPUs\n\nNot for gaming\n\n> Horrible drivers\n\nNot anymore",
      "Worst GPU launch *so far*",
      "Fab costs may have gone up, but die sizes went down. It's unlikely NVIDIA has worse margins than before the crypto boom.  \n\n\nAMD prices are just following NVIDIA prices; they price their cards at NVIDIA's equivalent minus 10-20% to account for feature difference. The sudden prelaunch pricecut on the 7600 is as clear evidence of that as I've ever seen. They're not playing for market share. They're just playing to make money with what they can sell. It's not price fixing, because it's not an agreement between AMD and NVIDIA or anything. But they don't have the incentive (or perhaps the ability, depending on how much silicon is available to buy) to try to push harder than they already are. Then add in that consumer GPUs are probably low on the list of each company's concerns (NVIDIA is worried about selling AI chips and other B2B sales; AMD is more concerned about console contracts, the server market, desktop CPUs, and so on), and it's just an ugly picture.  \n\n\nMarket just sucks ass because the companies don't feel a need to be competitive. It's an effective monopoly/duopoly. Intel GPUs are the only thing I really expect to cause change, but they've got a lot of driver cleanup to do before they've a viable option for the regular consumer who expects things to Just Work. And I think Intel is only trying to be more competitive than AMD, not overtake NVIDIA, so their impact might not be too big in the end anyways. Wish things were better.",
      "I’m buying used because I don’t want to support the high prices",
      "Horrible AMD drivers is a city legend now . Everyone tells it but no one seems to have any proof that it's real",
      "That’s exactly what NVIDIA doesn’t want to do. They are screwing the whole generation to make sure the prices stays high and the 90 model is head and shoulder above the 80 model (and not just a mere 10%).\n\nIf they can give 50%+ increase across the board for the 5000 without raising prices, the 5000 will be the best selling gen ever.",
      "I don't agree completely with that. I think there's also a big share of people still thinking AMD drivers are bad and Nvidia just gives confidence. (Not my opinion, just stating what i've heard)",
      "Shitty AMD drivers don’t exist, they can’t hurt you"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "4060"
    ],
    "title": "New leak confirms the upcoming GeForce RTX 4060 Ti GPU - VideoCardz.com",
    "selftext": "",
    "comments": [
      "8GB of Vram in 2023? Sad...",
      "8GB 128 bit?!\n\n3060Ti has 256 bit!",
      "Don't worry, 4050 will have 6gb!",
      "Are they though, taking advantage? lol",
      "AMD absolutely is!\n\n...by charging +100 on their cards to undercut Nvidia by $50 or so! Everybody gets fucked, just some fucked harder than others depending on what color condom the gpu manufacturer is wearing. \n\nIsn't competition grand?",
      "AMD or Intel doooo something!!!\n\nThis is ridiculous.",
      "They tried an AMD and vastly increased the cache which allowed them to shrink the VRAM bus width. AMD cards do really well at 1080p and 1440, but seem to lose out at 4K with the larger cache but smaller VRAM bus width. Also, they are pairing higher clocked memory chips so that negates some of the bus width shrinking with the total GB/s being higher despite half the bus width.\n\nEdit: the 3060 Ti has 532 GB/s and the 4060 Ti has 288 GB/s, so the 3060 Ti has 184% bus width compared to 4060 Ti.\n\nThe xx60 series is really a step above low end xx50 series so the performance may be more in line with that for 4000 series versus the better than average 3060 Ti performance for 3000 series generation, which is probably what makes the 4060 Ti feel so lackluster and blah as a product.\n\nThe 3060 Ti performance was on par with 2080 and 2080 Super and sometimes knocking on the 2080 Ti’s door. The 4060 Ti might perform closer to the 3070 as opposed to the 3080 Ti 12GB that would put it in line with 3060 Ti performance increase over previous gen cards.\n\n2nd Edit: I think Nvidia blew up performance tiers for 3000 series and are kind of resetting those performance tiers a bit with 4000 series and that is IMHO partly why the performance of 4000 series, save the 4090, feels so disappointing. You got more bang for your buck and more performance with xx60 and xx70 series cards with the 3000 generation than we are seeing with 4000 generation.\n\nWith the 3000 series there was hardly any performance difference between the 3080 12GB, the 3080 Ti 12GB and the 3090 24GB, they were kind of bunched up at the top end. The lower series cards gave you better than usual performance so it was good, except for the crypto boom prices. I think those dynamics among others, are what is causing us to feel less than thrilled about 4000 series cards. I’m not thrilled about the new $800 mid tier price, but I can’t buy gas for $1.50 a gallon anymore either. I could afford a top trim level half ton pickup if I could buy one for late 90’s prices, but now the cost 2-3x that price and I cannot afford that. It stinks when Boomers with money are willing to pay that price and keep those prices in the stratosphere and out of my reach. I think the current gen price and performance feels similar, I am getting a much better and feature rich truck in 2023 than a 1999 model, but it has a price tag to match.\n\n3rd Edit: for some generation on generation comparison of xx70 series cards; GTX 1070 Ti vs RTX 2070 SUPER vs RTX 3070 Ti vs RTX 4070 Ti - Test in 8 Games\nhttps://www.youtube.com/watch?v=ru3HXlaXpW0",
      "Lmao and it's 128 bit...wtf are they doing\n\nAnd here I was hoping the clock speeds and bandwidth would help the measly 8gb too",
      "They actually *downgraded* the amount of vram from the rtx 3050 8gb, to the rtx 4050 6gb\n\nAMD and Intel must be laughing their asses off while they take advantage of this opportunity",
      "Looking at the power draw figures, seems to me that the 4070 is the new 3060ti",
      "Nvidia: yes",
      "How else are they supposed to artificially make their cards obsolete in a single generation?",
      "I honestly think Nvidia is just taking advantage of the lack of market competition while they can.  They have to know Intel is coming for the mid and low range.  And based on how arc is going, it’s easy to think how battlemage and celestial will do so easily.\n\nIntel was smart and went immediately for Nvidias two strengths.  RT and AI/dlss/xess.  And in RT they are totally killing it.  Intel could easily eat Nvidias lunch in 2-3 years.\n\n….but all Nvidia has to do is lower prices…so maybe not a threat?",
      "For a low cost of 999$",
      "128 bit what\n\nEdit: Pcie x8 what",
      "Even 3060 has 192 bit",
      "Yeah that's what I meant LOL AMD simply raises their prices right along with Nvidia. Maybe Intel will save us? lol",
      "They are probably waiting for price/performance confirmation so that they can price their gpus $50-100 lower/higher depending on nvidia gpus performance.\n\nTheir usual strat, price it depending on their competitors price",
      "AMD is in the same price hike boat as Nvidia.\n\nThere was an interview in which the ceo denied keeping production low to keep prices high and later confirmed that between the lines by mistake.",
      "I upgraded my 1080ti to a 3080 10gig and it's been great at 2560x1440."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "4060"
    ],
    "title": "RTX 4060 8GB or the 3060 12GB? which one will you recommend?",
    "selftext": "they are both at the top of my price range (around the same price), and i don't want to get an AMD card. and i can't skip this gen too sadly...  \n\n\n12GB is more VRAM, but Banchmarks shows the 4060 is faster overall..  \nwhich card u think will last me longer for 1080P gaming at 120-144hz?  \n\n\nthx!",
    "comments": [
      "Gen on gen performance should never be so close that this is even a question, the sad state of affairs.",
      "rtx 4060 no good.",
      "Look, everyone is disappointed in the 40 series for minimal performance gains, but if the two are similar prices, the 4060 is just objectively the better GPU. It's around 20% faster in most games and has DLSS 3. At 1080p, theres really only one game where it loses to the 3060 due to VRAM (RE4 Remake). If you're gaming, it's not really a debate over which is the better card.",
      "Jesus...right?  This is reddit for fucks sake.",
      "They’re just renamed. They renamed a 4050 as an “RTX 4060”, a 4060 as an “RTX 4060 Ti 16GB”, 4060 Ti as an “RTX 4070”, 4070 as an “RTX 4070 Ti” but with slight bump in specs.\n\nWhile the 4080 and 4090 are fine, it’s just that the 4080 has a terrible msrp.",
      "Don't you come on here with your reasoned arguments.",
      "I know you're asking between these two cards, but I would recommend a used 3060 ti. It has better performance, and is great at undervolting if you care about power consumption.",
      "3060",
      "For 1080p gaming the 4060 will be the winner. If a game comes out that exceeds your 8GB of VRAM you can just lower a couple settings and be fine. It also has Frame Gen and runs lower power",
      "this is me doing it",
      "Yes, it does have more VRAM.  \n\n\nYes, it is going to be more future-proof outside games with FG.  \n\n\nYes, it is sometimes equally as fast especially in games like Last of Us where you need more VRAM and might even have issues due to the narrow bus.  \nBut this point is more debatable because it is generally at least equal or faster if not VRAM limited.  \n\n\nYes, it is generally cheaper after the 30 series price cuts.",
      "But the 3060 8GB was the ugly step-child to the 12GB card, with worse characteristics than the 1060 3GB to 6GB release. It was a complete cash grab by Nvidia during the peak of crypto for the consumers that didn't want to 'subject' themselves to a 50 series card.",
      "Yeah there's a huge gap between 4080 and 4090 perf.\n\nThey'll bring out a 4080ti to slot in there at some point, where the 4080 should have been",
      ">if you plan to do stuff with AI than the 3060 for the vram but the 40xx series is faster with AI\n\nthis seems contradictory to me.. any chance u can rephrase that so i'll understand what u mean plz?",
      "Also worth noting if you plan on gaming with emulators the 3060 and 3060ti are better than their 40 series counterparts as the bus width gimps them badly in emulation.\n\nAlso depending on the models and platform some ai apps benefit from the larger bus width and greater vram.",
      "For only gaming at 1080p prob 4060, but its not a gpu for 120hz+ anyway.\n\nFor gaming at 2k with lower settings/cranking vram settings or using mods, 3060 12Gb.\n\nFor 120hz+ u will need to go lower settings anyway with 4060.\n\n12Gb is also better for some types of creative work and software like AI tools, game engines etc.\n\nIt depends, but do note games having issues with 8Gb gpus is only the start, it will get worse soon.\n\nTruth is, nv offerings are terrible, entry gpus should be now at least 12 Gbs.",
      "Used cards are perfectly fine. I got a 3070 last month which was used for mining for about a year and runs perfectly fine no issues",
      "I can get 120fps in a lot of games on my weaker Rx 6600xt. I'm sure there is lot of games you can still get 120fps on with a 4060 of you turn ray tracing off, and textures down to medium-high.\n\nDLSS3 uses between 1gb and 2gb of VRAM it seems. So you have to turn your other settings down further to not get bad stutter from going over 8gb total usage.",
      "thx :)",
      "great point thx"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "4060"
    ],
    "title": "4060 vs 3060ti",
    "selftext": "Hi there. I was looking forward to upgrade from a 1650, and had these two cards in mind. In my country the gpu prices are generally a bit higher than normal. Used these cards go for around the same price, at about 300~ dollars. I get how the 3060 ti is better in terms of raw performance. But wouldn't DLSS and FG Make 4060 a better choice? I mainly want high fps on 1080p since I have a 280 hz 1080p monitor. I am also really confused about why people recommend 3060ti if you can get much more fps on the 4060 using dlss and fg. Any help would be highly appreciated, thanks!",
    "comments": [
      "isn't that thing like 50% more costly, that is not \"abit\"",
      "5060 will be out soon and is going to be a fair bit faster than the 4060 and get 4x FG, so maybe wait for that.",
      "3060ti performance wise. A lot of games have frame gen mods and lossless scaling exists so if you can get a 3060ti that's cheaper than a 4060.",
      "With a 30 series card you’ll have access to fsr framegen and dlss. 4060 has dlss framegen over the 3060ti but otherwise the 3060 ti is the stronger card",
      "4060 have better 1% lows.",
      "Dang, well then i understand",
      "Dude dont get your info from reddit comments, there are plenty reputable youtubers that talk in detail about this stuff. Most people here are echoing what they saw in those videos. Gamer nexus, hardware unboxed, digital foundry, etc... good luck !",
      "Difference in feature is only the frame gen for 4060, dlss 4 is accessed by 3060 ti as well. It comes down to whether you want to use frame gen whenever you can or not. 4060 also is brand new (I assume) and longer warranty compared to used now",
      "Get a used 3070 over either",
      "I would go with 3060ti. Performance is close to 3070. You can watch comparison videos on youtube.",
      "If you can look around at options with more than 8GB VRAM, it's just something to think about.",
      "Used 3060ti or 3070, both still crush most games",
      "3060 Ti is faster",
      "I wouldn't put any money on an 8gb card at this point.",
      "Would definitely recommend the 4060 over any 3060. 100% you won’t regret it.",
      "3060 ti is more powerful than 4060 in the case of :\n1) It gives you high performance than 4060 ,like high graphics games,video editing etc .\n2) it is faster than 4060.\n3) it is better for long term uses .\nEven though the 4060 is newer, the 3060 Ti is stronger overall.\nThe only difference is that 3060 ti is older than 4060 and 4060 have a support of DLSS3 .( Which is not that much usefull)\nSo the conclusion you should buy 3060ti",
      "Definitely go for 4060, lower power consumption, dlss4 works better on it and framegen is a nice feature, also 3060ti had problems with memory in the past, not sure if it was ever fixed (only on models with Hynix memory, not Samsung). Just beware that 8 gigs isn’t much, maybe save some money and get something with 12 or 16 gigs of vram. Or maybe get a 3060 and upgrade when rumoured 5060 super with 12 gigs comes around",
      "Any difference between physical gpu card and clpud gpu resources?",
      "I would always go for the newest generation of gpu and cpu.  \nSo 4060.\n\nMy girlfriend got a prebuilt budget pc about a year and a half ago with 4060. That pc is great. Can play all the games we want and they run great, no problems.",
      "I can't spend that much, unfortunately :("
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "4060"
    ],
    "title": "Coming from a 2060 - is the 3060 12 GB or the 4060 a better upgrade?",
    "selftext": "It's not urgent or anything but I'm thinking about an upgrade. At the moment I have an RTX 2060, which is fine, but it's been a decent while and I'm thinking about an upgrade. I see a lot of bad press about the 4060, saying its not worth it, but every test I've seen shows it outperforming the 3060, even the 12 gb model. Granted, its not too big of an improvement but I digress.\n\nI also do a lot of video editing and motion graphics, besides gaming. \n\nDo y'all think the 3060 12 gb, or the 4060 is a better upgrade? At the moment they're only a $50 difference, the 3060 being $250 ish and the 4060 being $300.",
    "comments": [
      "This sub is damned, OP asks a super simple question. Option A or option B and if so why? And then people still say \"forget A & B, get C wich is just $250 more expensive\"",
      "4060 for frame gen",
      "Do you have a moment to talk about our savior AMD Radeon 6700 XT?",
      "Don't listen to people who don't know how the architecture between series of gpu's work, doesn't matter if the 4060 has 8gb, it outperforms the 3060, if you want you could get the 4060 ti, but the 4060 is amazing, it also depends on the rest of the set up you have, the least cpu I'd pair with it is a 11700 or 12400, good luck!",
      "This is the answer, OP: even bad frame-gen is pretty great, but if you can run a game >45fps it’s a fucking black magic spell that doubles your frame-rate and makes you more attractive and intelligent in real-time while running.",
      "This sub is damned, OP asks a super simple question. Option A or option B and if so why? And then people still say \"forget A & B, get C wich is just $250 more expensive\"",
      "no youre so right barely anyone is giving me a straight answer, i really only need one or the other",
      "lmaoo real",
      "I honestly don’t think the 4gb of vram makes a difference for the 1080p resolution these cards are intended for. The 4060 has the advantage of having one of the lowest TDPs seen in recent memory. If it matters to you it uses 115w vs 170w. Which should also translate to lower heat output. I think I’ve read somewhere that the 4000 series has some sort of improvements for creative work but it was irrelevant to me so it didn’t stick. You could look into any performance differences in the applications you use.",
      "Agreed 4060 is the way to go here.",
      "Thing that screws the 4060 up is the 128 bit bus width.\n\nNvidia screwed up on the 40 series. \n\n4070 series above is the only reasonable ones my opinion.\n\nOverwise look at AMD. Truth is I hate asking people to go AMD because they fanboys think they the good guy but the truth is they both shit in the same basket.",
      "The 4060. If you're gaming at 1080p your don't need 12 GB of vRAM. You're just never going to use them.\n\nThe 4060 is faster, has newer features such as frame generation and is more power efficient so it runs very cool.\n\nIf you do machine learning or stimulation calculations that are GPU accelerated then maybe the 3060 would be better. Otherwise, the 4060 is objectively the better card.",
      "If you have $300-ish 6700xt I'd take that in a heartbeat.\n\nBetween those 2 it's kind of a toss-up. If you need the vram get the 3060. Otherwise I'd say the 4060. But then again the 6700xt is a better buy at roughly the same price as the 4060",
      "Just get a 4090",
      "These comments help me as I also have a 2060, thank you OP",
      "I'd say 4080, but maybe he could stretch a little bit and go for the 4090",
      "I've got a r5 3600, and a b450 tomahawk max mobo, does that change anything?",
      "1000000% - 4060",
      "3060 is not much better than 2060 (15-20%) aside from double the memory. If you cant get above $300 then get the 4060, also not much faster than 3060 but it adds up. Personally id save up for the cheapest 4070 i can get, or find secondhand 3080/ti.",
      "Ye bro needs to just get the 4070ti and call it a day."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "4060"
    ],
    "title": "Can the rtx 4060 be used for 1440p gaming?",
    "selftext": "I only play story based single player games so I don't need 100+ fps on the highest detail settings, can 4060 run most 2020 to 2025 games at 1440p at at least 40+ fps?",
    "comments": [
      "Yes, I ran one for about a week or so while I transitioned from RTX 4090 to 5090.\n\nI play at 3440x1440 so even higher res than the typical 2560x1440. Some games like PUBG require that you turn down the texture settings because the 8GB of VRAM just cant cope at that resolution, even though the card is powerful enough. I was getting VRAM hitching at high and ultra settings.\n\nOther games like BF2042, I could play maxed out with ultra settings (no Raytracing) with DLSS set to \"performance\" , I was getting 70-100 FPS. Which was incredible and the game really looked good! I was using the latest DLSS 4 forced through Nvidia APP.\n\nIf all you want is 40+ FPS I think the card is absolutely capable, but I do think in certain games you will run out of VRAM before you run out of power. The 4060 is stronger than a 1080 Ti, it can use more than 8GB of VRAM, if the game uses DLSS, this wont be an issue, but you may have to compromise on some games that dont use that tech, like PUBG. I would strongly encourage you to get a card with more VRAM, just for futureproofing, but the card did impress me.",
      "I know what the actual number is, but read what Nvidia said man. The EFFECTIVE number is much higher, due to less calls to VRAM.",
      "If you optimise the in-game settings you should be able to target 40fps or above in most. But it’s definitely better suited for 1080p. \n\nIf I was you I’d watch some benchmarks on YouTube that mimic your system to see how it performs.",
      "I don’t want to go over this again, but Nvidia has explained that the massive L2 cache increases effective vram bandwidth on 40 series cards massively due to far less calls to VRAM. My own experiences playing at 3440x1440 reflect this. \n\nYou can not compare the bus width to 30 series because of this very big architecture change. Effective bandwidth for the 4060 is close to 500 GB/s because of this change.",
      "Sure it can, though you might need to dial back on textures and raytracing settings on some new games due to VRAM limitations. Some games may even auto reduce details or disable certain graphic options, when they detect too little VRAM.\n\n\nIf the game you are playing is not VRAM limited, then 40fps and more should be quite easy to get with a bit of upsampling (DLSS4 @1440p is now actually good!)",
      "Yes, I recommend the 16gb version of the 4060 ti as it seems considerably better performance at higher settings in 1440p. I have a 4060 ti 16gb and run 1440p maxed out settings and get 100+ FPS in most games.",
      "It can but some games you will be vram limited.",
      "8gb is gonna hurt badly at that resolution, in Indiana Jones for example, jumping from 1080p to 1440p will force you to go from medium to low textures (with dlss on top), It is also gonna hurt Frame Gen usage in games like Horizon FW, Ratchet & Clank, and Tsushima... games are getting more vram hungry now since we start to get more and more games designed with the PS5 as the primary target. Buying a card that barely fits the Minimum vram requirements of upcoming games like Doom The Dark ages is not a good idea.",
      "It’s a tough time right now to get a higher VRAM Nvidia card. I would encourage you to look for 16 GB 4060 Ti or maybe get lucky on fb market place and find a 4070 for cheap. \n\nBeing so close to the 5060 launch, I’d just wait for that.",
      "Yeah it should be fine. My 4060 laptop can play cyberpunk maxed out no rt with dlss performance at slightly above 1440p. If I turn on ultra performance it'll be 90 FPS. \n\nI think most games should be fine if there is upscalling if it's a newer title. You might have to drop settings to medium at times but it should still be a decent experience. \n\nIf it's something new like mh wilds where the game is poorly optimised and heavy you'll likely have a bad time and need to do everything low + frame gen.",
      "Yes, 4060 can output an image in 1440p, but it is better to take 4070 so that there is less load",
      "Yep, no issue on majority of games, if you are willing to have some settings mid/low. But I’m ok with that.\nI even use some at 4k. Mildly old games run like butter… love my 4060 ❤️",
      "Depending on your current CPU and motherboard, an Arc B580 would be a better choice if it's available at MSRP in your market.\n\nOtherwise a 4060 would probably work, but you'd need to lower settings to Medium at least for more demanding titles, and forget about ray tracing.",
      "Yes, just be sane with the graphics options.",
      "Yes I'm currently using a 4060 laptop for 2560×1600 and with DLSS Quality I get 50-60 fps in Alan Wake 2 at Medium, Cyberpunk at Ultra, Control at high + full rt and it can run older games (like ac Odyssey, rdr2, kingdom come deliverance (1)) on max settings without any upscaling. The 4060 has more power than people give it credit for.",
      "Nothing crazy but yeah it'll be good enough\n\nKeep in mind, you will run out of VRAM if you're playing the latest AAA games - I had a VRAM bottleneck in Final Fantasy 16 with a RX 6600 XT",
      "I believe in supporting my fellow gamers who literally just wanna game.\n\nIf we can pool some people together on this thread to hit your cash app or whatever you use with some dough to help add to your budget I got $20 🙂\nIf 9 other ppl joined me you should be able to get atleast a ti 🙏🏻",
      "I’d defiantly try to get atleast a used 4060-ti since they’re a dime a dozen and not a ton more if you can float the cash.",
      "Understandable, they were just $450 three months ago when I got mine and they are now $700+...... Absolute insanity. I'm sorry you happen to be attempting to get a rig during this rough time in the industry.",
      "Then I would get AMD. AMD is way better at lower budgets."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "4060ti"
    ],
    "title": "Rtx 4060ti vs rtx 5060ti",
    "selftext": "Hello lads, \nI come to ye with a very quick question of what's worth it?\nShould I get rtx 4060ti 16gb brand new for 400euro or should I spend a quiet bit more (for my standards) and yet rtx 5060ti 16gb brand new for 500euro ? \n",
    "comments": [
      "go for the 5060ti buddy",
      "5060Ti 16GB is stronger than the 3070Ti and has double the VRAM...",
      "Is 12gb of vram enough now a days for new titles ?",
      "+%20 raw performance + faster VRAM + mfg for %25 more money is a deal i would take.\n\nEdit: if you can find better 4070/4070s deal, take those deals. Both cards are better than 5060ti especially if you won't gaming at higher than 1440p res.\n\nWhat are the 4070/4070s/4070ti/5070 prices in your country? We only know 4060ti 16gb and 5060ti 16gb prices for now.",
      "I would personally wait until it drops or get something from amd, like a 9070 if you can afford it or if it is priced reasonably. Another option is a used 7900xt or 7900gre, as well as any used nvidia 4000 series card that is at least a 4070 super\n\nUnless you're coming from an absolutely piece of shit card, you shouldn't get either xx60ti card.",
      "Yes, especially cause a 5060ti with 16GB will still perform worse. More VRAM on a lower tier card only makes sense if you have specific scenarios where the cards speed doesn't matter as much but you need the VRAM, like AI stuff.\n\nFor games, VRAM is nice but a 4070 or 5070 will perform way better, even at 12GB of VRAM. Those cards are great for 1080p and 1440p gaming and the 5070 can even do okish at 4k. The 5060ti, even with more VRAM, can't even think of running 4k.\n\nMost games nowadays use somewhere between 6-10GB of VRAM with a few games using a bit more. Keep in mind that even a 3080 10GB was performing better than a 5060ti at higher resolutions despite having 6GB less VRAM.",
      "Tom'sHardware recently compared the 2 GPUs (https://www.tomshardware.com/pc-components/gpus/rtx-5060-ti-16gb-vs-rtx-4060-ti-16gb-gpu-faceoff).    \nTLDR:    \n\"The RTX 5060 Ti 16GB easily beats the RTX 4060 Ti 16GB in every conceivable metric. There's only one potential advantage to the 4060 Ti, and it's nebulous at best: It supports PhysX and 32-bit CUDA (though both are likely deprecated and will fade away in the coming months).\nIn contrast, the 5060 Ti 16GB offers about 20% higher gaming performance on average, across nearly all tested resolutions and settings. It's also about 20% faster in AI workloads and 3D rendering, and about 17% faster in a selections of professional applications.\"",
      "I installed 5060 ti 3 hours ago and I had 1 game crash in oblivion remaster and 2 crashes cyberpunk 2077.",
      "The cheapest rtx 5070 in my country is 580 quiet a gap from 400 initial price i was looking at haha",
      "I personally thought the 5060 looked pretty good on that graph I think it fits were I would imagine it but he also did it in a rush but I think the $5060 is definitely a great card at $300",
      "Alright I get ya mate. What about if I can get a used 4070 for 450 euros? Would that be a better deal than brand new 5060ti 16gb for 500?",
      ">+%20 raw performance + faster VRAM + mfg for %25 more money is a deal i would take.\n\nThat's a deal? Remember when technology advanced so you would get more performance at a better price?",
      ">5060 Ti 16GB offers about 20% higher gaming performance on average, across nearly all tested resolutions and settings. \n\nSo OP pays 25% more for 20% more performance...",
      "Currently I've got a 1080p monitor, for sure I won't be changing the monitors within the next year or two. Both of them I'd get brand new, that's why I'm wondering which one is a better deal.",
      "They are relatively close, 4070 is %10 better overall but i would take 5060ti because it's 16gb and brand new.",
      "The 5060 ti has mfg so it's actually 40% more performance /s. \n\n\nThough I would think that 5060 ti is worth it especially if OP wants to play at 1440p.",
      "Imo that additional €80 is well worth it though. 40% more performance over the 5060Ti.\n\n20% more cost over the 5060Ti 16GB but you get 40% more performance.",
      "I had frustrations with not running Indiana Jones at as high settings as I wanted, but I haven't had trouble getting any other game to the visual: performance sweet spot I want",
      "On a 4600 ti more vram equals shit. Gotta check the benchmarks, or ask grok or chatgtp. Don't trust nvidia redfit sub, too many shills here.",
      "Alright, I thanks for information:)"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "4060"
    ],
    "title": "Should I go with the RTX 3060 or get the RTX 4060 instead",
    "selftext": "I'm planning to upgrade from a GTX 1050 TI",
    "comments": [
      "Either card will get you about 3x the performance as your 1050 Ti.  The 4060 is newer and consumes less power than a 3060.  I say 4060",
      "yeah DLSS 4 is good...",
      "meh... I hate what NVIDIA did to -60 series GPU",
      "4060 if you can afford it",
      "100$ ~ more rtx 5060 ti 16gb",
      "Honestly, B580",
      "5060Ti has 16GBs for around $500. A little worse than a 7800XT but it does have DLSS4 and MFG.",
      "Same Price rtx 5060 Dlss 4 / 7800 XT fsr3",
      "4060 ti new or 3060 Ti used depending on budget.  If you are tight on cash and can get the 3060 ti a lot cheaper, save the money to upgrade in another 2-4 years.",
      "It's a pretty good 1080/1440 card, it is capable in 4k but will most likely suffer tremendously, crazy how I bought a windforce trio for $333 taxes included last october, wanted to sell since I got a 5080 windforce, just checked it and it's going for $470 like what? Safe to say I'll keep it for a streaming pc because it is a strong performer and msrp is basically impossible for anything these days.",
      "What about VRAM? I'm not sure if 8GB is enough for 1080p in 2025",
      "just save up for the 5060ti u get more vram and you can play most modern games",
      "In that Case I think the RX 7800 XT would be a better choice",
      "Its not really a problem with a 12400f, imo.",
      "4060 is stronger than 3060",
      "Budget ?",
      "Budget? What is your cpu?",
      "40 series.",
      "4060.  Especially if you play single player games. That FG can come in handy",
      "4060 for being able to use FG . I jse 4060 . Highly recommend it for 1080p gaming"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "4060ti"
    ],
    "title": "4060ti review from a normal gamer.",
    "selftext": "Só, I always had the **60 series. I had a GTX 970 and after that,1060..1660 and 2060. I'm not a hardcore gamer by any means. I had always 60hz monitor and always played capping my games at 60fps.\n\nBut recently I grabbed a 4060ti and this is the first time I feel the necessity to get a higher refresh rate monitor. To fully use my GPU with frame generation. \n\nI saw a lot of people saying that 3060ti is a better choice. I don't disagree. BUT that depends where.u live. I'm from Brazil. Here the 3060ti costs more than the 4060ti. Let's say the 4060ti cost 200usd and the 3060ti cost 300usd\n.\nHere in Brazil jan2024 the ,4060ti is the best choice by far. If u buy a 3060ti ur literally paying more to have a little bit less performance in some games but losing the new features.\n\nMy point is, this gpu is not bad at all. But the choice depends where u live for sure. \n\nMine is a Msi card and holy fuck it has a good temperature. I'm playing Alan wake 2 and I never saw her pass 63degrees. \n\nCheers from Brazil,sorry about my English, not my native language and I was practicing without a translator haha",
    "comments": [
      "$200? it cost $550 canadian. For $200 usd no one would say it is bad.",
      "There aren't bad cards just badly priced products which is exactly what 4060, 4060ti is.",
      "Likely just saying it’s 2/3 the price of a 3060ti in his country",
      "I always changed to next one because I always had someone buying them from me. And since Im not someone who can buy the best or the next big upgrade because I live alone. Pay all the bills AND have some health conditions I always got a little upgrade by little. This is the first time I really got a big one compared to the last",
      "Lmao, why are you so mad? \n\nSmall upgrades aside, wouldnt someone who used all of these, actually have valid opinions on how they perform in relation to each other?",
      "Fun Fact: \n\nIf you limit every single gpu in existence to consume exactly 100W of power rtx 4060 ti will be ranked as N1.",
      "4060Ti is not a bad card. Its just too expensive to have only 8GB Vram in 2024. But for now its a good 1440p gpu.",
      "Reddit is ultra NA focused so most people only take NA into consideration regarding tech to recommend, while a 4070 might be $500-$600 in the land of the free, our little third world countries sell them for upwards of €900-€1100, whereas the 60 series is always a lower price, either close to msrp or below it. Got one for €282 new :P",
      "In your original comment you didn't say \"desktop GPU\", it said \"every single GPU in existence\" which includes the 4090m.",
      "True, in my country 4060 and 4060ti cost the same price as 3060 and 3060ti. I think there is no reason to buy 30xx series gpu in this situation",
      "Like said depends on which country u live. Maybe because the 3060ti it's hard to find here it costs more now. But the 4060ti can give u room down the road because of frame generation. What I tried to say is that if the 2 cards are almost the same price then yeah the 3069 ti is a better choice. BUT HERE the 4060ti is by far the best choice not only because is cheaper but because of dlss3 and stuff",
      "The 3060ti is only a better choice if it is far cheaper. The 4060ti 8GB performs very similar to a 3070, with a lower power draw.  The 4060ti is a  great 1440P (minus raytracing) card and an even better 1080P high FPS / ray tracing card.",
      "By 3060ti they mean used 3060ti which can be had for around $200. 4060ti is a disappointing card cause it's barely faster than its predecessor, same 8gb vram with smaller bus. But i guess it is to be expected cause 4060ti has the same msrp as 3060ti, if factoring in inflation it is a bit cheaper + Nvidia new price gouge.",
      "Yeah but that also depends on where you live.",
      "No, the 4090m would perform better than the 4060 ti at 100 watts🤓☝️",
      "16gb is the only interesting model for me",
      "Modded framegen doesn't work with VRR yet like DLSS 3, so I wouldn't say it's as good as a 40 series card. You might see your monitor's refresh rate counter change, but it's not actually \"synced\" to the generated frames, so you get a much less smooth experience compared to what VRR should give you at those framerates.\n\nThe latest version of FSR 3 that's in the new Avatar game (and the version used to in the mod) has this exact problem, and was pointed out by Digital Foundry.\n\nThe whole point of framegen is to be used with a proper VRR display with Reflex turned on in-game to mitigate the latency. Otherwise, the framerate boost you see is barely making the game look better other than pumping fps numbers up, because you're just seeing judder.",
      "Do we really think we are going to see cards again under $300?",
      "I don't judge him haha it is weird but I always had some minor gains. Now after the 2060 I really feel it was a worthy upgrade. Maybe I'll skip 5000 series and try to get a **70 next time. Save some money from now on",
      "I bought the 16gb VRAM version over the 4070. Don't regret one thing. I use LLMs so it's a great card. Even managed to play Alan Wake 2 with path tracing on ultra without framegen and am now playing Cyberpunk with path tracing as well."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "4060"
    ],
    "title": "I just completed Portal with RTX and even on a humble 4060 it was an amazing experience. Can't recommend enough.",
    "selftext": "",
    "comments": [
      "First time I really tested full ray tracing and it's stunning. Lights and shadows behave very naturally and the way light pours through the portals really adds to the experience. It was my first time completing Portal in general (I had only played Portal 2 before) and I'm glad I found out about and played this version.",
      "I'm on an ancient i7-4790k (on an even older Z87 board) + MSI RTX 4060 8GB Ventus 2x. 16GB DDR3.\n\nI switched back and forth between 1080p and 1440p and also between the different DLSS modes. Performance depended a lot on the room I was in, but it was always nicely playable, i.e. between 40 and 60 FPS.",
      "4790K? holy shit, man",
      "Jesus",
      "Regardless of the newly earned graphical fidelity, it still is an amazing game which made me go on to play the successor (it still looks nice, although not \"RT\" nice, perhaps use ReShade for that) and some of the popular mods.\n\nThe humour and style easily outshine any graphics but it's still nice to see those classics receiving a refresh after all those years .\n\n*-This message is free of any companion cube mentions, thanks for your understanding-*",
      "whats your cpu+gpu combo? and resolution?",
      ">I have Portal 1 on Steam already\n\nJust type in \"Portal with RTX\" in Steam Store search bar and you can get it for free as a separate library entry.",
      ">*\"I switched back and forth between 1080p and 1440p and also between the different DLSS modes. Performance depended a lot on the room I was in, but it was always nicely playable, i.e. between 40 and 60 FPS.\"*",
      ">the successor (it still looks nice, although not \"RT\" nice\n\nIt's being worked on, thanks to a generous programmer by the name of xoxor4d who has been modding the base game for a few weeks and some other people who are hunting for bugs, it is now largely functional. You can support his work and gain early access to the mod here [https://ko-fi.com/xoxor4d](https://ko-fi.com/xoxor4d)\n\nhttps://preview.redd.it/lkkixi4ivmzd1.png?width=480&format=png&auto=webp&s=b6e27b2d97681f4395b280ac13fa50efe266acc1",
      "Doom is probably the worst example as it’s probably the most optimised game that exists for its visuals haha",
      "It's really impressive. Half-Life 2 is getting the same treatment, and looks even more impressive in the recent hour long demo they did of Nova Prospekt. \n\nMy TI 4060 can run it very well even at 1440p, but needs fairly aggressive DLSS and frame generation to keep the FPS up around 80 or so, where I like it. Thankfully DLSS is extremely effective on this game, so you can go performance and it still looks great at 1440p in motion.",
      "Surprising RT didn’t kill your CPU, as it’s not just GPU intensive",
      "Funny, I tried Portal RTX a few months ago and it wouldn't run for more than a minute before crashing. Either it's my PC or it had a good patch recently.",
      "Those screenshots look amazing. Is this just from Ray tracing? (I'm still using my gtx 1070 😂)",
      "I imagine that the future generations of gamers who play Portal the first time will be playing it on Portal RTX and will be like \"damn thats a good game\" without knowing how people played it without path tracing 40 years ago.",
      "Yeah ... before that I was playing DOOM Eternal 1440p Ultra Nightmare at 60 FPS with RT on - on an (overclocked) **4670k**. 🤯 I did have occasional FPS drops, but upgrading to the 4790k fixed those.\n\nThis whole build project (i.e. upgrading an 11 yo PC) started as an experiment and turned out a reality check. If you have a game that's not too CPU-intensive, your CPU barely matters. You can make do with a $25 CPU if you have to (bought the i7 for EUR 30 and will soon sell my i5 for EUR 5-10). You'll have to fiddle a bit, but it's doable and many games are absolutely enjoyable. Sometimes even with RT, at least with an RTX card.",
      "It was “RTX’d” by Nvidia Lightspeed Studios iirc. The fan project for HL2 RTX looks to have at least as much work going into it.",
      "Haven't played it yet, what settings you running?",
      "Wow, that is stunning! The Portal I remember was mostly sterile white walls and not much in terms of reflections...",
      "Good lord that looks amazing.  Will have to check it out at some point.  Thanks for sharing!"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "4060"
    ],
    "title": "Thinking about upgrading to a 4060",
    "selftext": "I want to upgrade to a 4060 from a 1660 ti, but the $300 price is making me want to wait. I was thinking about waiting until the 50 series releases to see if there will be some kind of sale. Do y'all think there will be any \"significant\" price drops anytime soon?\n\n\n\nEdit: The reason why I haven't really considered any alternatives is because I'd like to really stick to Nvidia drivers. I'm set on the 4060, and I hate having to think about alternatives when I already made up my mind. Someone mentioned that I should wait for the 5060, but I'm not looking to spend more than $300 for a card right now. Plus, the 5060 is rumored to have a 16 pin connector, which I only have an 8 pin. I don't need to upgrade my power supply for the 4060, but I will likely need to upgrade for the 5060, depending on the specs.",
    "comments": [
      "Intel B580 or 5060 (1-2 months?). 4060 makes no sense now.",
      "B580 is cheaper, faster, more vram. No reason to get a 4060",
      "B580 is the best option, but if you're afraid of Intel drivers the 7600 is still cheaper than a 4060 with basically the same performance.",
      "im pretty sure the b580 has better rt perf than the 4060",
      "You are the reason why nvidiia charges their prices lmaoo\n\nThe dickriding goes crazy",
      "The dickriding is justified though. Nvidia is far ahead when it comes those features they mentioned and more. There is a reason why nvidia is #1 by a wide margin.",
      "B580 if available for you now would be better choice for the vram. 3060 with 12gb also. Try to get at least 12gb now as new games requirements now is making 8gb the bare minimum\n.",
      "Unless things change 5060 is leaked to also be 8gb lol. But the 5060ti is possibly going to be 16gb... Gotta love Nvidia they keep better Vram off cards they know would increase its longevity. Give the 5070 16 gbs of Vram nah x.x",
      "Agreed. Never thought I'd say this but. Intel is rhe way rn.\nBut let's be honest, the 4060 was always shit for the price anyways.",
      "What about all the raytracing they could do on the 4060! /s just in case.",
      "RTX HDR and DLSS are too good for me to give up also. Not my problem the competition can't match them.",
      "> wait for the 5060, but I'm not looking to spend more than $300 for a card right now\n\nwhat makes you say it will be above 300?\n\n>  Plus, the 5060 is rumored to have a 16 pin connector, which I only have an 8 pin.\n\nany card with 16-pin comes with an adapter.\n\n>  I don't need to upgrade my power supply for the 4060, but I will likely need to upgrade for the 5060\n\nyou don't unless your psy is below 350W.",
      "im a believer of that too 95% of the time, but imo this is one of the cases where its 5% because the new GPUs (from AMD, NVIDIA) are right around the corner (January 2025) and it wouldnt hurt much waiting. \"Perpetual loop of waiting\" doesn't really apply in this case because its just waiting a few weeks before deciding, its a different situation. \n\nIts like not getting an iPhone at full price a week before the new one releases, even tho you are feeling like you want to buy right now.\n\n(unless there is a very specific circumstance that *required* him to have a GPU ASAP)",
      "I just did a mini itx build and bought a zotac 4060 for this reason. I think it will be a fair while that small form factor 5060 cards will come out.",
      "Yeah I know they dont care as much as they used to but they dont want to lose that 10%. It still a lot of money",
      "Buy an Arc B580. if you want a 4060 you probably aren't gonna be using the Nvidia features like cuda or tensor anyway so.",
      "Honestly I've been seeing used 3080 on the market around the 300 to 500 mark which heavily outperforms those cards, I would keep an eye on the used market, just because it's newer doesn't mean it will outclass the older higher series cards they have less ray tracing performance",
      "Lowkey get the b580, ray tracing is roughly the same you still get a good upscaler, plus sense your worried about the power supply the b580 or get a b570 both will use a single 8 pin on some models it’ll use 2",
      "All 16 pin cards have an adapter in the box anyway. Barely anyone has 16 pin psus.",
      "Go 4060, 1080p king card atm"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "4060"
    ],
    "title": "[HUB] Best Value 1440p GPU That You Should Buy, Radeon RX 6700 XT vs. GeForce RTX 4060 Ti",
    "selftext": "",
    "comments": [
      "TLDW: Don't buy 8GB card for 1440p in 2023.",
      "Seems NVIDIA is putting too much premium on DLSS 3 support. Makes sense only if all games support it.",
      "DLSS 3 is not gonna save you from the lack of vram",
      "You like a company that pretty much scams their customers",
      "Cuz that's not what the vid's about? But there's a 3060 ti in every shown game",
      "Cant confirm that.\n\n3070 user here and ran out of VRAM @1440p in several games now. (Forza Horizon 5, Dying Light 2, Uncharted, The Last of Us....)\n\nLatest example would be Diablo 4, which does not run out of VRAM, but simply does not load all textures even on medium with DLSS on balanced.",
      "Depends on the titles\n\n8GB of VRAM is starting to show its limits on newer games",
      "Because the 3070 and 6800xt have a similar price in many markets, it’s really not that hard to work out",
      "> Where's the 3070?\n  \nIt's about 4% faster than the RTX 4060 Ti at 1440p and 20% more expensive - doesn't make sense to include it.",
      "The 6700XT came out a little over 2 years ago.",
      "We're discussing 4060ti here. Which has 8gb. Are you lost?",
      "Both?",
      "What is up with people commenting without watching the video. He literally has a 3060TI included for comparison. And they had an earlier video showcasing 3060TI against 4060TI.",
      "OFA (the hardware used for Frame Generation) has existed since 2000 series but Ada's OFA is 2.5x faster vs Ampere.\n\nWith Frame Generation being very latency sensitive, anything slower will provide with even worse experience. And people already complaining about the increased input latency with Frame Generation on 40 series. Imagine the outrage if they released it on previous generation.",
      "Wondering when my 10gb 3080 will become problematic at 1440p...",
      "\"I haven't watched the video yet, but here's my suggestion.\"\n\nBruh",
      "Some reason being current market price. Also he recently compared the 6800xt to the 3080 and the 3080 came out ahead.",
      "Looking at their original review of the 6700XT, it was slightly better than the 3060Ti as can be seen here: https://www.techspot.com/review/2216-amd-radeon-6700-xt/",
      "Because for performance they are practically identical. You will get similar framerates between DLSS and FSR the only big difference is image quality.",
      "Locking the feature out from even the 3000 series users is a major fail in my books.\n\nDon't tell me the might GA102 chip can do massive AI workloads but it can't do DLSS 3...."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "4060"
    ],
    "title": "8GB 4060 ti vs 12GB 5070?",
    "selftext": "I currently have an 8GB 4060 ti. I bought a prebuilt about 6 months ago for $600 and that was card in it. I have a chance to get a 12GB 5070 for $550, and I’m wondering if it’s worth it? I have a 4K ultrawide monitor, but obviously I have to change the resolution and aspect ratio in most games to play them. I’m not sure if the upgrade to a 5070 would give me the same performance I get in GeoForce Now, for example.\n\nThoughts? All this is still somewhat new to me. ",
    "comments": [
      "The RTX 5070 is approximately 50–60% more powerful than the 4060 Ti. It should be capable of running games at 4K resolution with medium to high settings at 60+ FPS, or at 1440p on ultra settings with 80–100 FPS, depending on the game.",
      "If this [video](https://youtu.be/9QJnuytLjjw?si=vs3yxB-ufDt9acmx) is accurate, seems to be a sizeable performance uplift, but will largely depend on the rest of your build and what games you play",
      "As someone who just got a 5070 from a 3060ti, I say yes! Most games I play on 4k get 100+ frames. The only game that has given me below 100 is expedition 33 and that game is just really graphical and still get 90-100.",
      "That's a whole lot of monitor for that little GPU lol. \n5070 will be much better, for sure",
      "Make sure you have a big enough PSU to upgrade.\n\nI'd do the math if it's under 750.",
      "Get 50 series, either 5060ti for 1080p or 5070 for 4K",
      "The jump is gigantic in FPS. You can even move the settings slider up more because of the VRAM difference so your games will look better!",
      "I'd advise stretching your budget a little more and get the 5070 Ti. Faster than the 5070 by a decent margin and comes with 16GB VRAM. If you want something that'll be just a little more \"future proof,\" that extra VRAM will be helpful down the road. Right now, 5070 ti comes with a free copy of Doom: The Dark Ages, but sounds like you already have that. Would have made the higher price hurt a little less.\n\nOr, if you're willing to go AMD and live near a Microcenter, get the Asrock 9070XT for $700. I think it pops up on Newegg for $729 if you're lucky to catch it in stock. Only $100-130 more and trades blows with the 5070 ti in games. Downside is that FSR4, while a large improvement for AMD's upscaling, isn't supported on as many games as DLSS. People are using Optiscaler and modding files to use it on more games, but that's extra steps to get upscaling.",
      "Thanks! That makes me feel better. I’ve been trying to research and there’s some people that say it’s a huge difference, then there’s some people that say it’s not noticeable or it won’t give a huge lift. I never know what to think lol.",
      "And this is why I posted here lol. \n\nI guess I’d need to get a new PSU? Mine says the max is 650 watts so I’m 100 watts shy. Damn.",
      "What’s the best way to tell which PSU would be compatible with my PC?",
      "So many people love to hate on the 50 series because of the bad launch, smaller generational uplift than normal, and the generally lower than desired VRAM, but they're pretty good cards.  You'd obviously see an uplift going from a 4060 to a 4070, so you'll see a better uplift going to a 5070",
      "I'm not good at computing wattage, you should look up a guide. Or use a wattage calculator.\n\nI'd guess you'll probably be OK with 650W, but you're outside of Nvidia's recommendation, and you won't have a lot of margin for error.",
      "Okay! I found a couple of PSU’s from Corsair that are in the $100 range and are 750 watts. Just not sure how to check to make sure if a certain PSU is compatible with my PC. I’ll do some more googling. Thanks!",
      "as a 4060 owner at 4k you need more horsepower. i get 100fps solid at 1440 with 4060 on ffxcas",
      "depending on your goals you might prefer a 5060ti with 16gb",
      "My processor is a AMD Ryzen 5 8000 series. The PC came with 16gb of ram but I upgraded to 32gb. Not sure if that changes anything. \n\nI’m playing games like Doom: The Dark Ages. Currently it runs fine at a lower resolution and aspect ratio. I decided to try the GeoForce Now service and played it on that, and man being able to play at a higher resolution, 21:9 aspect ratio and not having to lower any other settings is pretty amazing. So that’s the primary reason I’m wanting to upgrade. Just not sure if a 5070 will give me that same performance that I want.",
      "Unfortunately my max budget would be in the $600 area. My first choice would be a 5070 ti or a 5080, but that’s too much of a stretch for me right now.",
      "Native resolution on it is 3440x1440. But it says it supports 1440x900? Not sure if that’s what you were asking\n\nEDIT: after some googling I realize that 3440x1440 is not 4K lol. So I don’t have an actual 4K monitor. But I still can’t play most games at its native resolution unless I crank down a lot of setting to low to medium",
      "I have a 5070ti and the difference is huuuge, specially with mfg x4, then this thing skyrockets"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "4060"
    ],
    "title": "GeForce RTX 4060 becomes the most popular GPU among Steam players",
    "selftext": "",
    "comments": [
      "It’s mostly because of prebuilds. \n\nNvidia liquidated a massive amount of them to prebuild companies and the overwhelming majority of $1000 ish PCs have a 4060. \n\nPrebuild companies scooped up a ton of the 50 series cards too and lowkey pisses me off. \n\nI can’t find a 5070Ti at retail anywhere but I can get many prebuild PCs delivered in 48 hours with one 🙄",
      "And people all around were claiming that it would be a huge flop",
      "Liquidated them to prebuilt companies at a discount meanwhile still impossible to buy them standalone for MSRP\n\nnvidia sucks man",
      "Its perfect for local pc building shops that sell prebuilts, most prebuilts in my area use 4060s.",
      "Problem is it's the only readily available GPU that's often going for or below MSRP, you can snag a 4060 for less than 300",
      "I always liked RTX 4060 tbh. Imo the idea of low power consumption xx60 series card is better than power guzzlers like 3060 Ti.\n\nHell even it's GDDR6X version more power hungry than 4070 Super.",
      "Just like people on this sub hailing the failure of the 50 series when the reality is that most owners are probably pleased",
      "Now thats sad 😌",
      "Nvidia knew it from beginning. Even if its bad for the price. Sad.",
      "I don’t think DYI is that huge of a market, right?\n\nMost people will buy prebuilts and there are almost non with AMD GPUs and most in the 800-1000 € area come with a 4060.",
      "Well, look at the prices of the other cards. Still sucks because after we (blindly) normalized sub console resolutions on entry level cards, we are normalizing medium and low textures as well, unless you are willing to pay premium... which is silly since these cards dont come bundled with an eight core Ryzen, a 1 TB nvme, a gamepad, a mini PC case, nor carry the whole 16gb of graphics memory OFC.",
      "That's because they are in so many gaming laptops.",
      "*most common",
      "Article is based on the recent steam survey which is being widely considered inaccurate due to wild swings of representation of hardware and software.\n\nThis ain't it chief.",
      "The general market is dictated by prebuilts, and they have different priorities.",
      "So much coping in the replies",
      "Hey, I was about order my first build, But the 4060 in my cart ($300) is now $360-$460 and climbing. Sold out in some retailers as well. \n\nCan anyone make a vague prediction of what I can expect the next month?  My current build already exceeded my budget without this price hike. 3060Ti is looking great right now but I'm really into the frame gen in the 4060. \n\nThanks",
      "Because the only one they can find",
      "lol normies are so funny",
      "In one month:\n\nLanguage - Simplified Chinese +20.88%\n\nIntel CPU +5.14%\n\nSo my guess is that they over counted Chinese internet cafe systems again. Lunar new year occurred during last January to early February so a lot of people probably just logged in on Internet cafe systems during traveling."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "4060",
      "4060ti"
    ],
    "title": "Geforce rtx 4060 8gb or Geforce rtx 4060ti 16gb?",
    "selftext": "I need an upgrade from my gpu and was looking for a 4060 or nvidia gpu.I don’t know which one i should get.Amd will also be considered but i heard there were a few problems with amd.",
    "comments": [
      "It's like asking if you want a 1998 honda civic vs a 2017 toyota camry. Or a pack of Ramen noodles vs a bowl of Ramen at Ramen Tatsu-ya. Or a 3 inch cucumber vs a 12 inch molded dong with suction cup. Or an old 9\" Sylvania tv/vcr combo tv vs a 35 inch plasma tv. Or...\n\n\n\nAmd is fine, 7700xt is around that price I think (new that is)",
      "4060ti would be the better choice, 20% faster then the standard 4060 and offers 16vram.",
      "No problems with AMD but if you wanna go Nvidia I would highly recommend a 4070 or 4070S, it has quite a bit more impressive performance.",
      "The one with more memory ofc lol",
      "Everyone here is acting like the 4060 ti is the obvious choice, but is it? Cause where I'm from it's almost twice the price and you definitely aren't getting twice the performance...",
      "Out of the two the 4060ti is best but I would not buy it. You can get the 7800xt for less but more performance .\n\nhttps://www.tomshardware.com/reviews/gpu-hierarchy,4388.html#",
      "Team suction cup 🐙",
      "More like do you want the Mustang with the v6 or the v8.",
      "idk the cucumber/dildo comparison really inserted your point pretty deeply.",
      "For the price range of the 4060ti i would go AMD. On the same price range you could maybe get a 7800xt, if you check benchmarks amd is way better value.\nI would say you check out 7800xt/7700xt vs 4060ti benchmarks and decide for yourself",
      "Neither.\n\ninstead of the 4060 go with the Intel Arc B580  \nInstead of the 4060ti 16GB go with the 7800XT",
      "I had the same dilemma, ended up buying a 4070 instead..",
      "ti, memory is king",
      "Id you don't need Nvidia features then AMD options in this price bracket have more vram and raw performance. \n\n6700xt / 6750xt / 7600XT / 7700XT / 7800XT\n\nOver the last year my 7900XT hasn't had any issues.",
      "Pretty sure the 7800 XT is way better for the same money\n\nI switched from Nvidia to AMD after the 30 series, with a 6700 xt ( great for the money ) and then a 7900 GRE, and they've both been very performant for the price \n\nIf you can live without DLSS, I'd go AMD. My 7900 GRE doesn't really need upscaling at 1440p in most games.\n\nI would also honestly bet the 6700xt is better than the \n4060 in raw performance, but more VRAM, and are usually a little cheaper than the 4060 too ( my info may be outdated )",
      "AMD doesn’t have any more issues than Nvidia.",
      "You probably meant RTX 4060 ti 8gb or RTX 40600 ti 16gb. If it's the same price, obviously the 16gb but otherwise the extra isn't worth it at all. Only if you train neural networks or do cad or other creative stuff",
      "Arc b580 or b570",
      "What current GPU do you have, what are you other current components. Pairing a GPU is as important as make or model. I would vote AMD for value. If you want to pay NVIDIA tax, check Zotac store and CamelCamelCamel.com for amazon warehouse deals. My vote is wait for the 5070!",
      "[4060 Ti](https://www.zotacstore.com/us/zt-d40610h-10m-o)"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "4060"
    ],
    "title": "Whats the opinion on RTX 4060 Ti nowadays?",
    "selftext": "Looking to upgrade from a GTX 1080. Moving my build into an ITX form factor. Looking at the posts here, people said to skip the RTX 4060 Ti and go for a used RTX 3070(/Super) as its much better value, but most of those comments are a year old.\n\nWhats the opinion on RTX 4060 Ti now?\n\nI’m debating it because the lower Wattage = good in an ITX case.\n\nEDIT: Seems like the concensus is screw the 4060 series, get a used 3070 for the price or save up for a 4070. Thanks everyone!",
    "comments": [
      "Still overpriced shit, with 128bit bus.",
      "I got one despite the negative comments in this sub. I managed to get a discount so wasn't considerably more than the 4060 but was a stretch to go up to the 4070.\n\nI run a 1440p ultra wide, and for my needs it's been solid. I mostly play older games though, so I guess that's a big factor. Currently playing Shadow of the Tomb Raider fully maxed and it hasn't struggled, but Forza Horizon 5 has complained a few times about low memory when full Ray Tracing etc is on (I got the 8GB variant).\n\nI think the 8GB will probably hold me back on AAA titles in the future, but for now I'm not bothered.\n\nYou can get bogged down in benchmarks all day long, but to be honest just get the best you can afford if you want longevity.",
      "I would get 7800XT or 4070 and up.\n\nHowever for ITX rigs, 4060 series has insane efficiency. AMD has nothing that even comes close.\n\n4070 uses like 200 watts stock. Very good for small itx builds too.\n\n4060 series including Ti is a big step down in performance but has unmatched performance per watt. Only buy this, if you can't house a 200 watt GPU in that ITX case. There's pretty small 4070s",
      "I have the zotac 16 GB version. I play 1440p, just not ultra wide like the parent comment. No complaints from me, most of the games I play have settings maxed out, cyberpunk being the only exception but I don't have to turn it down much to get a steady 60 fps. If you play above 1080p, the extra $50 or so is definitely worth it for double the memory.",
      "4060ti is a 100% skip for a reason... It matches and LOSES to a 3060ti in some instances.  Used 3070, 3080 or new 4070 those are what you should consider tbh.  But if you only want to buy new the RX6800 or 7700xt is the pick under $500 all day long.",
      "4070 super is still the best value, and powerful enough to keep your system happy for years. except of course, video memory. but 16gb is so much more expensive than 12.",
      "It has always been a great card price horrendously. If you can find one for cheap, sure.\n\nIt goes for the same price often in many regions around the globe, as a 6800. Picking a 4060 over a 6800 immediately qualifies the buyer with the \"stupid\" title. Unless you specifically need encode/decode or cuda, no sane individual would buy it for that price.",
      "Depends on it's price still, it generally costs a lot more than the base 4060, with the same problems and not much better performance. Look at some benchmarks of it compared to other GPUs, to start.",
      "The price difference is at least $200 where I am for a RTX 4070, $300 diff for a Super, so quite a big jump. It is something I *might* consider, but it's a stretch and not sure I want to spend THAT much for the amount of gaming I do (life gets in the way, you know how it is).",
      "Isn't there a 16GB version",
      "Honestly, trying to push to 4070 super would be hugely beneficial. Pretty sure it's best value for money Nvidia 4000 series card. But as someone has said, there are some pretty tiny 4070s cards out there.",
      "Both versions are overpriced. \n4060 Ti should be under $350 as it barely beats a 3070 often loses.",
      "From what I'm seeing, the difference is around $75 where I am, with average 15-25% FPS increases in 1440p depending on the game.",
      "Dual fan 4070 super exist like Asus dual or msi ventus",
      "Cherry picking one again.\nOverall performance: https://www.techpowerup.com/gpu-specs/radeon-rx-6800.c3713\n\nCompany fanboys are incredibly sad.\nThere's also nothing wrong with buying a 4 year old GPU as long as it still has support.",
      "I never said it was faster/better than a 4070, I'm talking about buying a 6800 instead of a 4060ti 8gb.\nCan you even read?",
      "get a used 3060 ti for 200 dollars and be happy with it.",
      "Sounds similar to the situation I'm in. I'm on 1440p, but not ultrawide. So might actually be alright for me? I don't tend to play the most recent games, and also don't mind turning the settings down a little.",
      "3060 ti power consumption is atrocious bro.",
      "Yes, great idea. Except my card is better than AMD 7600 according to them. \n\nhttps://gpu.userbenchmark.com/Compare/Nvidia-GTX-750-Ti-vs-AMD-RX-7600/2187vsm2114669\n\nStay away from them. Dont be stupid."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "4060"
    ],
    "title": "4060 or 4070",
    "selftext": "been needing an upgrade for a while and the price of the 4080 and 90 are too much. so it comes down to the 60 or 70 both are better than what I currently have (2080) \n\nI want to know how long it will last me. I got my 2080 back in 2019 and it had lasted this long now it's no longer viable and struggles to play anything\n\nand no I am not waiting for the 50 series if I can't afford a 4090 I definitely cannot afford the 50s and don't get me started on the scalpers  ",
    "comments": [
      "4060 is basically a 2080 on newer architecture so it's a sidegrade at best.\n\n4070 / Ti / Super is the only logical choice between the two.",
      "4070 ti super",
      "B580 has more or less 2080 performance, it's a sidegrade at best, as a B580 owner",
      "4070 obviously. The 4060 will not age well at all. I would recommend an Intel B580 personally",
      "like you said its a gamble i don't like buying used when it comes to important components like GPUs just to maybe save 50-100 bucks.",
      "H.264 on AMD is trash, HEVC is much better but slightly worse than Nvidia. AV1 encoder on RX7000 is legit better than Nvidia, although slightly. \n\n\nI play PCVR on Quest 3 and Nvidia cards choke the AV1 encoder at max bitrate and 200mbps, while AMD cards purr right through.",
      "4070 or 4060ti 16gb",
      "If RX7800xt is much cheaper than the 4070 in your region go with that I wouldn't get a 4060 coz it won't provide any performance increase maybe even a slight decrease",
      "At this point the proper play is to wait for the impending economic collapse. Tariffs will turn the cards into unobtanium. \n\nDemand will falter, prices will plummet and then a grey market channel will emerge allowing you to buy a more cost-effective piece of hardware sans the tariff tax.",
      "Just hold on to your GPU for a month. The RTX 5000 and RX 8/9000 series will be announce next month and the price may change for both of those GPUs.\n\nI have been using a RX 7900 XTX and my only issues were at release for the first few months.\n\nI have been jumping between Nvidia and AMD GPUs for the part 15 years and I must say beyond DLSS upscalling, there is no reason to buy to pay more than 10% for a NVidia GPU, when compared to a AMD one with the same performance.",
      "4060ti 16GB??? Lmao, 7800XT is $20 more for so much more performance with the same vram amount.",
      "I've got a rx 7900xtx and it's a great card I've got no issues with AMD",
      "Your first paragraph is a point I dont see brought up enough. Being an early adopter always poses some small risk and I dont want to get unlucky. Whether it's the card itself or the heatsink/fans Id rather buy something thats been out for a while and its reliability is already a known factor.",
      "Not buying a 50 series because of scalpers make sense, but why not wait for it to release to possibly see the cost of used options drop? Maybe a 4070 ti or 4080 used would fit your budget once those people inevitably buy the 5080? \n\nObviously a gamble but still.",
      "Um why do you think a 4060 is better than your 2080....? They are both very similar in terms of performance, at least at 1080p, I'd wager at 1440p the 2080 is better in most cases...\n\n\n4070 would be the minimum upgrade I would do, ~50% more performance and memory, but I'd say the 4070s or the 7800xt are probably where I'd be looking.",
      "I’d say it depends on the resolution of your monitor.  But like others say the 4060 isn’t much better than the 2080, if at all. Also if you don’t have a  1440p monitor not really worth the 4070 imo.",
      "If you have the money obviously bigger is better, but contrary to what you might read, the 4060 is a fine card for now, and I suspect for the next 3 years as well. After that with the next console generation who knows",
      "B580 is better than 4060.  \n7800XT is better than 4070.",
      "If it only between 4060 and 4070 then get the 4070, if you can afford it go for 4070 Ti, otherwise try looking at 4070 or 4070 super. There also AMD option like 7800xt, and 7900xt, but if must be Nvidia then yeah 4070 or 4070 super what you want.\n\nI got the 4070 mainly because I got it in pre-build deal I saved money on my budget at the time.",
      "Either go for 4070 super or 4070 ti super"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "4060ti"
    ],
    "title": "Went from a 1660 Super to 4060Ti",
    "selftext": "",
    "comments": [
      "Great card. I have one, just a bit pricey.",
      "Enjoy brother, went from a GTX 1060 to a 4090 a few weeks ago.",
      "Thanks, I got it on sale 420USD shipped for the 16gb",
      "Just went from 1660ti to 4070 and it’s heaven",
      "Wow, it fits perfectly :D",
      "Compare to my MSI 2fan 16gb, yours is HUGE! The card is actually pretty good. Especially with VR... despite me really wishing I waited for a 4070ti super 😅",
      "Yup, was scared it wouldn’t",
      "It’s about 700 USD in Sweden due to sales taxes, that’s ridiculous and we already lose 30% of our salaries because of income taxes",
      "Congrats! Please get a GPU support bracket",
      "oh boy, is so hard to look",
      "Mine was 517€ but consider we have 22% vat here…",
      "I got one of those stand. It’s like a little pole \n\nI put it all the way at the other end to hold it up",
      "Yeah lmao more like 25x, I had a good amount of cash lying around and found myself at Microcenter for the first time since 2021 and it just so happened they had 7800x3D’s and a one singular PNY 4090 left in stock. Plus, I’m gaming on 4K now instead of my old 1080p 60hz monitor. \n\nI’m no longer allowed to go to Microcenter by myself now.",
      "Big upgrade!  Enjoy!",
      "I bet the improved CPU cooler made a big difference as well.",
      "That's such a crazy jump, how much is the performance uplift? 5x?",
      "Yup I got a 850watt psu\n\nThe 400 watt it came with could not run a 4060",
      "Really only 5x? I was expecting 15-20 times",
      "7800x3d needs to get commission for enticing new buyers to the video card market",
      "Enjoy it king!"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "4060ti"
    ],
    "title": "Going from a 1060 to a 4060ti has been immense",
    "selftext": " \n\nI know this card has gotten a lot of hate recently but since i had a card from 2016 and wanted the new nvidia features (DLSS3 mainly) this was the gpu that made the most sense.\n\nIs it a good value gpu ? Not really at all.\n\nWas it a good upgrade from my old gpu ? Well cyberpunk went from 20 fps to over 120fps with dlss enabled so that was massive. At 1440p resolution.\n\nThat said its not a gpu that makes sense if you are with a 3xxx series card. It makes 0 sense to upgrade and its terrible value for anyone that has recent gpus.",
    "comments": [
      "Don’t listen to other people’s shit, if you’re happy with it than that’s great.",
      "I went from a 1080 to the 4070ti and holy cow!! Was it a huge upgrade! Playing high settings elden ring at 4k with a fix 60fps on my tv. What a beautiful image. I feel like the jump from the 1k series to the 4k series is definitely worth it",
      "If you're happy with it, so be it. It's not a terrible card, per se, but they're charging a lot more than it's actually worth. Calling it a 4060ti is a lie, and charging $400 for it is insane. Of course the uplift over a 1060 will be great, but for $400 you could have bought a used 3080 and had significantly better performance and more vram/memory bandwidth. That's why there's so much hate for the 60 series, and in all honesty it's justified.",
      "It's not a good value card, it's barely an upgrade from last gen 3060 ti.\n\nHowever it is a good upgrade from his 1060",
      "went from a 1660  to a 4060 dam DLSS3 at 80-90fps is awesome I can play Cyberpunk at ultra RT and at 280$ dam I'm really happy",
      "We have to remember that the youtuber reviewers and peeps are almost always comparing to last gen. They don't consider a lot of the market which is still using 10 series cards or 20 series cards. They just look at 30 series and are like \"yeah its really bad\" when anyone with an old card sees it as a huge upgrade even if its expensive. \n\nThe truth is that 99% of gamers do NOT upgrade gen to gen. Its retardedly expensive to upgrade gen to gen.",
      "Til 1060 was released in 2013.",
      "I only say this because I just had to do this a couple of days ago, but the 4060 at $300 still outperforms the 3060, and the 3070 is $500. \n\nSometimes, $300 is all you have.",
      "I’m not trying to argue that the 4060ti is a good card for the money, but it’s certainly better than the one you had. I might have recommended a used 3070/3080 for $325-400, but sometimes people have budgets they’d like to stick with, or are uncomfortable purchasing used hardware. One thing I will say about the 4XXX cards is they are quite efficient, so if that’s an important factor, I can see  the value of your decision.",
      "Upgraded from a 1660ti to a 4070 two weeks ago and I've been so impressed with it that I've essentially stopped frequenting this sub because of how GOD AWFUL the advice here can be.\n\nEveryone's either too well off and experienced in building a pc that everything you suggest is wrong, or too poor to buy a new pc but knows everything about the latest hardware so they'll dislike even the tiniest of components that detract from what they think future hardware should be, and what price it should be (while never owning it).\n\nI benchmarked CP2077 with RT Overdrive and got 90 - 120 fps, something I thought for sure wouldn't be possible. \n\nMy advice for people is to read up on latest hardware here, make notes on suggested hardware, and then go to a few physical stores to talk to people IRL who are experts in the field on what they think.\n\nReddit is full of very negative and unhappy people who will try to rain on parades.\n\nThat, or they'll suggest buying an AMD when you're clearly talking about NVIDIA cards.",
      "> youtuber reviewers and peeps are almost always comparing to last gen.\n\nWell of course. What else are they going to compare it to? If a new generation offers worse price performance, it's still bad even if someone with hardware from 10 years ago would see benefits.",
      "Still better than an RTX 3060.",
      "1060 is 7 years old.",
      "Yeah i spent the last 6 years focusing on other things other than gaming and it was enough to play the ocasional multiplayer video game from time to time",
      "Im happy for you getting a new gpu and enjoying it.\n\nUsing half of your post justifying your purchase is kinda the truth tho.\n\nIs the 4060 a good gpu in itself? Hell yeah it sure is. But for the current price it typically gets sold at it's just a very bad deal which isn't possible to defend. Even the biggest fan boy has to admit that money could have spent way better if someone would pay the \"full\" retail price.\n\nIt just isn't possible to defend it in any shape or form which doesn't speak against you can enjoy it on a personal level",
      "I recently upgraded to a 4060 8GB, it's on Amazon for $289 which is great for me.",
      "Must be huge, 1080 to 4070 ti is probably pretty close to 3x. \n\n I RMAed a 3080 for a 4070 Ti and already felt the 30% performance jump haha",
      "WHERE did you find a 4060 to $280 out the door??",
      "Don’t claim FSR 3 will win over FG until we see it. Just because it works everywhere doesn’t mean that it will win over DLSS. We said that the last time FSR 2 was shown off and DLSS still looked dramatically better to the point that both would be implemented anyways.",
      "Yeah, he wrote a lot of nonsense when the biggest difference is that it's a card from 2016 to a 2023 card. OP's point on 3xxx series not having a point in upgrading is valid. But here is this Cheetos finger slob of a dude that thinks it's worth it lmao."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "4060"
    ],
    "title": "4060 vs 4060 ti",
    "selftext": "[PCPartPicker Part List](https://pcpartpicker.com/list/gnHRcH)\n\nType|Item|Price\n:----|:----|:----\n**CPU** | [Intel Core i7-8700 3.2 GHz 6-Core Processor](https://pcpartpicker.com/product/C9hj4D/intel-core-i7-8700-32ghz-6-core-processor-bx80684i78700) | $186.00 @ Amazon \n**CPU Cooler** | [ARCTIC Freezer 13 36.4 CFM CPU Cooler](https://pcpartpicker.com/product/99DwrH/arctic-freezer-13-364-cfm-cpu-cooler-acfz13) |-\n**Motherboard** | [Asus TUF B360-Plus Gaming ATX LGA1151 Motherboard](https://pcpartpicker.com/product/fBF48d/asus-tuf-b360-plus-gaming-atx-lga1151-motherboard-tuf-b360-plus-gaming) |-\n**Memory** | [Kingston ValueRAM 16 GB (2 x 8 GB) DDR4-2666 CL19 Memory](https://pcpartpicker.com/product/DBRYcf/kingston-valueram-16-gb-2-x-8-gb-ddr4-2666-cl19-memory-kvr26n19s8k216) | $58.94 @ Amazon \n**Storage** | [Kingston A400 240 GB 2.5\" Solid State Drive](https://pcpartpicker.com/product/btDzK8/kingston-a400-240gb-25-solid-state-drive-sa400s37240g) | $27.99 @ Amazon \n**Storage** | [Western Digital Caviar Blue 1 TB 3.5\" 7200 RPM Internal Hard Drive](https://pcpartpicker.com/product/MwW9TW/western-digital-internal-hard-drive-wd10ezex) | $36.93 @ Amazon \n**Video Card** | [Gigabyte WINDFORCE OC GeForce GTX 1050 Ti 4 GB Video Card](https://pcpartpicker.com/product/9V2rxr/gigabyte-geforce-gtx-1050-ti-4gb-windforce-oc-video-card-gv-n105twf2oc-4gd) |-\n**Case** | [Corsair Carbide Series SPEC-01 ATX Mid Tower Case](https://pcpartpicker.com/product/vYrcCJ/corsair-case-cc9011056ww) |-\n**Power Supply** | [Antec High Current Gamer 520 W 80+ Bronze Certified Semi-modular ATX Power Supply](https://pcpartpicker.com/product/VCxfrH/antec-power-supply-hcg520m) |-\n**Monitor** | [Asus TUF GAMING VG249Q 23.8\" 1920 x 1080 144 Hz Monitor](https://pcpartpicker.com/product/zKbCmG/asus-tuf-gaming-vg249q-238-1920x1080-144-hz-monitor-vg249q) | $182.00 @ Amazon \n | *Prices include shipping, taxes, rebates, and discounts* |\n | **Total** | **$491.86**\n | Generated by [PCPartPicker](https://pcpartpicker.com) 2024-07-05 03:02 EDT-0400 |\n\nhttps://www.asus.com/displays-desktops/monitors/tuf-gaming/tuf-gaming-vg249q/\n\nThis is my 2018 gaming pc and monitor. I need an upgrade from my gtx 1050 ti. Which one should I pick for 1080p 144hz experience between the 4060 and 4060 ti?\n\nBtw, before you recommend me a cheaper and better AMD gpu, keep in mind that it doesn’t work well with Fortnite performance mode, and I play Fortnite the most. https://www.reddit.com/r/AMDHelp/comments/17xpszj/fortnite_performance_mode_amd/\n\nYou can recommend me older Nvidia gpu’s if needed too.",
    "comments": [
      "If you do anything like Stable Diffusion, also consider the 16GB 4060ti version. Very good for AI and image generation.",
      "Yeah but I mentioned and gpu’s aren’t good for performance mode in Fortnite because they are poor for drops.",
      "interesting",
      "I was going to suggest 7700 xt but then I saw this is the Nvidia subreddit.",
      "If you want to upgrade to a newer platform, the Youtube channel Scattervolt has build guides for different price points, with parts list included:     \n700 USD PC Build: https://www.youtube.com/watch?v=9ywZChvfft4   \n1000 USD PC Build: https://www.youtube.com/watch?v=NnoaWdarBvg    \n1200 USD PC Build: https://www.youtube.com/watch?v=ZajzDXSVLWs",
      "12400f a decent b660 board and faster ram",
      "I already have the Kingston a400 ssd 960gb. Is it good enough for Fortnite installation?\nAlso, what if I get a new build like that instead, is it a better solution?\n\nhttps://pcpartpicker.com/list/4h8jTY",
      "https://www.techpowerup.com/review/nvidia-geforce-rtx-4080-super-founders-edition/31.html pick one that you like, looks like the 3080 is at almost 144 fps in every game",
      "It is better but not by much. Just get something cheap. Rx 7600 maybe is good option too. You will not use dlls at 1080p. Just get rx 6600. But look up benchmarks online.",
      "No definitely not, the 3080 works fine with a 12400f",
      "Thats better.",
      "Thank you!\nBtw, do you know if I should get this western digital Nvme ssd on this link? Or my sata Kingston is good enough? Also, is Nvme for the pc build should be with or without heatsink?",
      "Your complete build needs an overhaul, a locked i7 with slow ram, a new gpu won't give you it's full performance",
      "- The RTX 4060 Ti is the better gaming GPU vs the RTX 4060 (albeit poorly priced).    \n- You could also buy a used RTX 3070   \n- The RTX 4060 and 4060 Ti offer frame generation      \n- For some perspective, look at Techpowerup's review of the RX 7800 XT (https://www.techpowerup.com/review/amd-radeon-rx-7800-xt/31.html, the average FPS:   \nAt 1080P:   \nThe RTX 4060 Ti 8GB averages 119.5 FPS      \nThe RTX 3070 8GB averages 121.3 FPS   \nThe RTX 4060 8GB averages 96 FPS     \nAt 1440P:    \nThe RTX 4060 Ti 8GB averages 86.9 FPS      \nThe RTX 3070 8GB averages 90.4 FPS   \nThe RTX 4060 8GB averages 69.6 FPS   \nLook at the data and make up your mind.",
      "Thanks!\nBut I don’t know what works the best for my current system with a 144hz 1080p monitor refresh rate",
      "Thanks!\nDo you have Nvidia recommendations too?\nAlso, if you had my pc, which parts would you upgrade and what Nvidia gpu would you choose for a 144hz 1080p monitor?",
      "But I’m not sure I can afford a new build, so I think of fixing this one.\nWhat parts would you get?",
      "Thanks!\nWhich one is the best for 1090p 144hz monitor?",
      "Yes I would think you should get 144 on most if not all games on 1080p",
      "Your parts are not bad and perfectly fine for a cad like the 4060.\n\nSo i actually disagree with him that you need a new build. You certainly do not."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "4060"
    ],
    "title": "I am upgrading from a GTX 970... is it worth getting a RTX 4060 Ti then, OR should I still go for the RTX 3060 Ti?",
    "selftext": "Is it worth getting a RTX 4060 Ti since I am moving up from a very outdated GPU? Or is it still worth getting RTX 3060 Ti at this point? I was already saving up to get the **ASUS Dual NVIDIA GeForce RTX 3060 Ti V2 OC Edition** model, but I was also waiting for the 4060 Ti reviews. I see that these reviews' results been mixed to say the least... so, since I am very outdated regarding GPUs, I would like to hear from you all. Thanks in advance, people!\n\nBy the way, with my new build I intend to play games at 60 fps with 1080p resolution in the near future, but also want to jumpstart (very late lol) to 4K \"soon\". Would the 3060 Ti be enough for 60 fps @ 4K?\n\n&#x200B;\n\nRest of my (future) specs:\n\nIntel i5-13600kf\n\nAsus B660M-A D4\n\n16GB DDR4 (with possibility to add more slots)",
    "comments": [
      "Don't bother with an 8GB card.\n\nThis is in no particular order\n\n1. Used 3080\n2. 6800XT on sale\n3. 7900XT on sale\n4. 4070\n5. 6700XT on sale\n6. used 3060 Ti or 3070, if really cheap\n\nEDIT: Also, If you have to, cut your processor down, look at a 12600K or a cheap Ryzen 7K if it's on sale somewhere. You will notice almost no difference in performance between them, your primary limiting factor is going to absolutely be your GPU.",
      "4070",
      "Get the 4070",
      "The 4060 ti will not respond to extra VRAM as well as the 70 class cards will. It is hampered by bus width and other things that prevent it from fully utilizing the extra VRAM.",
      "Don't go for any 4060 version they offer. It's a dead end card that has no future.\n\nAfter seeing their whole lineup I decided that the only card that makes sense from nVidia is the 4070. Find a good deal for it and switch. I made a jump from a 1060 to a 4070 and it's been great.\n\n4060/TI/TI 16GB - don't have the cores, memory size or bandwidth to be a worthy upgrade over anything.\n\n4070TI - is an overpriced card for 12GB and while it has more fps than a 4070 it's not worth 200$ more and in the end if a game in the future proves to be too difficult for a 4070 to handle, a 4070TI will have the same issue due to the same 12GB and bandwidth. There was a reason why everyone flipped out when this card was called 4080 12GB. It's terrible value.\n\n4080 - is an abomination because of it's insane price. It should be 800$ (and 4070TI should not exist). It's literally over 100% price hike above a 4070 and yet in most scenarios it gives around 50% more fps, you do the math if this checks out.\n\n4090 - is a monster but outside of financial scope of most people on this planet.\n\n&#x200B;\n\nThat's why I picked a 4070, it will be a breeze on my current 1080p monitor and can handle most games I play in 4k with or without DLSS/FG.",
      "Get a last gen AMD card, much better Price to performance",
      "The 4060ti 16GB is just a 4060ti with 8GB more vram, that's it nothing else, so it'll perform near identically to the 8GB and only exists because the \"muh vramz\" ppl were vocal enough to will it into existance, so nvida decided to milk them for $100 extra. Having more vram won''t help the card in 99.5% of scenarios as it's the memory bandwidth that's the limit.",
      "I picked up a 3070 on flea bay for $270~ (also coming from a 970!) and it was a great improvement. IMO you won’t get AAA ultra ray tracing with any of those cards (3070, 3060ti, 4060ti) at 1440p (with a decent consistent frame rate), but 1080p should be fine.\n\nIf I had it to do again I might have gone with a used 12gb 3080, but I couldn’t find anything at a good price.",
      "Agree, but 8gb cards can be good as well if you're on a budget. Used 5700xt, 6600/6650 series can be great value in the $100-$200 range.",
      "Save money on the CPU and go for a 4070. The 4060 ti is a trash gpu.",
      "Don’t get a b660 with a k series, get the 12400d",
      "I won't tell you not to go for the 13600KF, because for the future it's pretty good, although you could go for the 13500 which is cheaper. It is a very solid processor.  \nRegarding the GPU, neither 3060Ti nor 4060 nor 4060Ti are worth it, you should go looking at the 4070",
      "13600k can handle literally any gpu on the market.",
      "Don't buy either. Spend a bit extra for a 3080 12gb or a 4070.",
      "The 4060 Ti has the issue of a 128 but memory bus, making its 1% lows FAR worse. I wouldn’t recommend pairing either of these with a 13600K, though.",
      "The 3060 ti has no 12GB version.",
      "13400f*",
      "Another way of looking at it.\n\n3060 > 4060 - about same fps same $300\n\n3060ti > 4060ti - about same fps same $400\n\n3070 > 4070 - price jumped from $500 to $600,  +25% fps, 12GB and Diablo4 \nIts an actual upgrade.\n\n3080 > 4080 - yes its 25-30% faster. But $700 to $1200 is MASSIVE. \n\nnvidia should EITHER lower price or make 4060/ti faster.\n\nWhat prices should be?\n\n4060 - $250\n\n4060ti - $350\n\n4070 - $500\n\n4070ti - $700\n\n4080 - $875",
      "Same exact boat. It's the only justifiable one this gen for me. >.<",
      "https://preview.redd.it/5bd38pi0z7ab1.jpeg?width=1080&format=pjpg&auto=webp&s=b0d511425c192eb10b4e0d164894fd1b1d91f10b"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "4060"
    ],
    "title": "The RTX 4060 Ti shows the hard limits of Nvidia's Frame Generation technology",
    "selftext": "",
    "comments": [
      "So, you can actually lose frames with FG?\n\nThat's amazing.",
      "It looks like at 4K it's just too much for the 4060, but it's still interesting that it's a Lovelace card that demonstrates why FG wasn't enabled with the much lower performing OFA units on 30 series cards, rather than just giving an actual demonstration with the 30 series though.",
      "It seems that FG is intended more as an help to the CPU bottleneck than the GPU, in which case it is most used and advertised.",
      "Thank that to the pathetic bus",
      "It will def be a mess, some people are not ok with the quality of Frame gen right now and i bet that tech will look even worse.",
      "Thats because a 3090 TI has the same \\~ FG performance as a 4070 Ti.\n\nThe 3080 / 3090 would likely have acceptable FG Performance similar to a 4070.\n\nSo they are obviously not going to want to demonstrate that.",
      "Who said their OFA units were comparable?\n\nTheir OFA is 2.42 times slower (Official Nvidia specs from the Optical Flow SDK)\n\nBut the OFA task is run simultaneously with a separate workload, so a 4000 series is waiting on that task to finish away, meaning the extra time to run OFA for the 3000 series cards is less impactful than it seems.\n\nAlso:\n\n[Someone decompiled the FG Cuda kernel and confirmed that the 3090 TI and 4070 Ti would have similar performance.](https://www.reddit.com/r/nvidia/comments/11ge42z/frame_generator_ofa_and_tensor_cores_usage/)",
      "**Admittedly I only ran into issues with Frame Generation on the RTX 4060 Ti when I was being naughty and making it run games at 4K. The card isn't designed to be used at this level, its frame buffer is too small, its memory bandwidth too low, and its GPU too weak. So I shouldn't be surprised that even Frame Generation couldn't help it. But I didn't really expect it to** ***harm*** **my frame rate.** \n\n **Using the technology at 1080p or 1440p certainly delivered the fps increase I was expecting. At 4K, however, there are times when turning on Frame Generation actually decreases performance compared with DLSS alone.** \n\nSo only an issue at 4K, a resolution that isn't realistic or practical for a low end card with 8gb VRAM.",
      "Same thing happens with the 4090 if you try FG at 8K resolution. Its just too much info to process and you dont gain any performance and chug.\n\n It explains why FG is so locked down in its current state. With how much weaker amperes ofa is it probably wouldn't gain any performance at all at 1440p /4k even with a 3090.\n\nhttps://youtu.be/AWgc0_V9w0I\n\nHe tested it here at 1530 also with spiderman which showed the same scaling",
      "The problem is that even running 4K with DLSS (so internal rendering way below 4K) frame generstion was still decreasing performance. The issue is not 4K (if it was, DLSS would fix it). It seems to be memory limitation/issue. Or perhaps the tensor cores are just underpowered somehow.",
      "It was never intended to be. Nvidia will continue to farm their sheep",
      "Seeing this just makes me more concerned about FSR 3 either being a mess from an image quality. Or won't work on just \"any\" card. It would take some magic for that to be acceptable quality and it's doubtful they'll surprise us seeing as FSR is just worse than DLSS.",
      "That's right. It was always marketed at helping in CPU bound games. If the GPU is the bottleneck, it won't help.",
      "Does not sound futureproof.",
      "Frame gen can induce problems with 8GB even at 1440p. So not just 4K.",
      "And what about 2 years from now? Maybe we will be seeing games that frame gen overwhelms the GPU at 1440p as well? \n\nThis REALLY doesn’t bode well for this card long term.",
      "I think the problem is when you maximize the entire GPU like he does. In 8k in Flight Simulator it stays at around 30fps and with FG it drops to around 20fps. I think it would work in the scenario that if you have 30fps, you limit the fps with the in-game limiter to 20fps and let the GPU breathe a little bit and then turn on the FG and get double around 40fps. \n\nFG is not free I saw it on my RTX 4080 in A Plague Tale Requiem in 2k 60fps GPU usage is 50% with FG you get 120fps and 65% usage. So about 15% usage go on FG with benefit of 120fps and smoothness. That's why I think you have to have a little headroom, he didn't have it in Flight Simulator, I believe it can be extracted, I haven't tested it yet, but I'll try it.",
      "Control has had a texture streaming bug since launch. I get the feeling someone tested it on a 4060 Ti, saw the textures not load, and then blamed the card without doing any further testing.",
      "the OFA units are  2.4x slower, what makes you think they're comparable?",
      "They announced that like 8 months ago, there is still nothing. It's unlikely to be good."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "4060"
    ],
    "title": "I’m upgrading my 4060 to a 5060ti do I need to use ddu?",
    "selftext": "This is my first pc and I’m not very knowledgeable on what to do.",
    "comments": [
      "No, these two are on the same drivers so it would be pointless unless you’re getting performance issues.",
      "Swap the card and perform a clean driver installation using the Nvidia driver installer. No need to use DDU in this case",
      "So all I need to do when I get the 5060ti is unplug the 4060, plug in the 5060ti and I’m good to go? That’s all?",
      "Well the majority of people who have commented say otherwise?",
      "Is there any bad things that can happen from using ddu?",
      "I have recently swapped my 4060ti for a 4070 super and all i had to do was update the drivers through the nvidia app and it worked perfectly.\nThat said both of my gpus were in the same series so im not 100% sure it applies when upgrading from 4000 series to 5000, but i think you’ll prolly be fine doing the same thing i did",
      "Just reinstall drivers",
      "Hey mate I just got the gpu and installed it, I went on the nvidia app and reinstalled the drivers and everything is looking good. I just had a Quick Look on cyberpunk with path tracing and it’s phenomenal.",
      "I have msi afterburner installed on my pc aswell, I don’t have any overclocks I just use it to monitor performance. Will I need to uninstall that or anything else before installing the gpu?",
      "The person who is selling me the gpu said to just go on the nvidia app and reinstall the drivers and that’s all I’ll need to do",
      "Yes. Your screen may turn off/on when you boot into Windows, similar to how it goes during a driver install, but that's about it. I'd suggest you reboot your PC afterwards if it does but that's about it.\n\nIf you don't see any other issues no need to mess with the DDU.",
      "It saves profiles per GPU, you don't need to",
      "When you say reboot do you just mean turn my pc off and back on?",
      "I always check the nvidia app for drivers and I’m up to date right now. When I install the 5060ti will new drivers show up on the app that I’ll need to download? Like does it detect it’s a different card and therefore show you more drivers you can install.",
      "That’s good then",
      "No, I mean this:\n\nhttps://support.microsoft.com/en-us/windows/restart-reboot-your-pc-110262aa-fc79-1c33-7b00-c140ae3a6dac",
      "Bro literally just said those two cards use the same driver.",
      "No, nothing. Before DDU I would recommend to download the latest driver for the 5060 ti and after the computer turned off just swap the cards and install the driver. This is the safest solution.",
      "Oh right yeah.",
      "Honestly I'd still suggest you do a reboot even if the screen doesn't go off/on.\n\nSwap GPUs, load up Windows, spend a few minutes doing something other than playing a game, like open a browser and check reddit for a bit, then reboot PC. \n\nAs long as you don't see any obvious issues after that, like performance in games suddenly being a lot worse, or all games crashing (though RTX50 has a number of crashing issues at the moment) then you should be good to go."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "low",
    "matched_keywords": [
      "4060ti"
    ],
    "title": "4060ti 8gb vs 5060ti 8gb - what should I buy",
    "selftext": "I getting around to updating my current pc (Ryzen 5500, GTX 1660) and am unsure about what gpu to get as they are both equally price. It seems obvious to get the newer 5060Ti but a lot of the videos and reviews I've seen have been quite negative. If I do choose the 5060Ti is it also worth splashing the extra cash and getting the extra vram. TIA",
    "comments": [
      "the answer is 5060 Ti, 16GB",
      "5060Ti 16GB, 8 gb in 2025 is not very useful.",
      "[this should help](https://youtu.be/QKjKMsEVBIU?si=3J3WsDzVp13PheGl)",
      "None: [https://www.youtube.com/watch?v=QKjKMsEVBIU&ab\\_channel=HardwareUnboxed](https://www.youtube.com/watch?v=QKjKMsEVBIU&ab_channel=HardwareUnboxed)",
      "Neither...both are extremly bad cards, especially with the 8GB VRAM models. The 16GB VRAM models are better but still pretty bad. For builds on a tight budget however at least usable.\n\nYou didn't really mention your budget here but you'd definitly be better off if you could get a used 4070(s).",
      "In my opinion u can get any of 12gb vram cards, if u need it for gaming try amd cards, if u need nvidia then 4070s may be at good price on used market.",
      "Neither, get the 16GB.\n\nI know that isn't exactly helpful but the price is close enough that the 8GB makes absolutely no sense. 5070 is an option but we're talking at least £100 more there, it's £50 more for the 16GB 5060Ti and the longevity it will enable makes it a no brainer.",
      "Definitely get the extra vram. The 5060 TI 16 gig is one of the better options in the current line up. Performs better than its predecessor and has a reasonable vram allotment.",
      "Reviews are negative because it's a very disappointing performance uplift from 4060 Ti, but it's still a performance uplift. If they cost the same, then 5060 Ti is a no-brainer. You really should *not* be buying an 8 GB card in 2025 though.",
      "Then why didn't you buy an 8gb card instead of a 12?",
      "Okay fair it's not useless, just not worth buying new in 2025.",
      "You definitely need at least 12GB VRAM on a modern card.",
      "Neither, 8gb cards should be absolutely avoided in 2025",
      "5060ti. Definitely not the 4060ti. \n\n  \n  Why not the 3060ti, 2060, 1060, or 960??? Why go older??",
      "Do not get any 8GB cards. They belong to the trash. 12GB is the absolute minimum in case you can't afford foods. Other than that, get 16GB card.",
      "You can get a used 3060 ti or 3070 for 200$ to 250$.  If you're e-sports focused (8gb buckets you there) I would go with one of those cards.",
      "save up a bit more for 5060ti 16",
      "I personally bought 5070 with 12gb vram. Should hold in current generation games. Will get a new pc around when gta6 or elder scrolls 6 releases on pc. 5070 will be enough for me until then. I got it for 700 euro. The 5070 ti was 1200 euro here where I live. So the most bang for the buck for me, was 5070. Also chat gpt 4.0 did a 30 min research, and even if the 5070 was more expensive, it still told me that 5070 was the most value for money compared to the other 50 serie gpu's. Redditors will disagree because \"vRaM\" and because their favorite content creators didnt give them green signal to buy 5070.\n\nAnyway, I think you will get a good budget pc whatever you chose of the 50 serie. My girlfriend uses 4060, a budget prebuild she got from me for christmas 2023, and that card is not holding back, and thats maybe the most hated card I have heard about. It's great, so why wouldnt 5060 be great? Its not like you gonna play 4k modded games in 180hz either. But you can play pretty much all games with 5060. I wouldnt buy 4060 ti because its old, newer is better. Same goes for cpu's. Better with a newer generation i5, than an older i7.",
      "4070 is a bad price on the used market, better off getting a 5070.",
      "Depends on the situation. I got 5070 for 700 euro while 5070 ti was 1200 euro. I played starfield yesterday for hours, and was constantly 110-170 fps, zero stutters, and this is with old intel cpu.\n\nI only needed a gpu for the next 1-2 years, until I plan on building new pc for gta 6 release on pc. Which will be either 5090 or 60 series if thats available, and I already have saved up money for it. Then this 5070 pc will be a spare/guest pc.\n\nIf you also do some proper research outside of listening to content creators, but objective facts, you will see that the 5070 actually is the most performance vs cost.\n\nI tried amd 9070 for two months and returned it due to stutters, unstable fps etc, and that one was more expensive than the 5070.\n\nIt's a thing now to be stuck on the vram and say that the card is \"useless\" etc. It's really frustrating to listen to. Not because I care too much about what others are thinking, clearly not since I went against the audience here, but the fact that no people on this planet, are able to think for themselves anymore. They are straight out independent of what other people think, and others opinions."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "rtx4070"
    ],
    "title": "Is it worth to but RTX4070 now?",
    "selftext": "Hello, I bought new monitor and my almost 8 years old GTX1070 can't handle well right now. I wonder if spending money on RTX4070 is good choice atm? \n\nI found RTX4070 Gigabyte version with 3 fans for 725$ in my country, it has best reviews at store page. I'm using my GTX since 2017 right now and I'm feeling that it's not enough (I'm playing mainly racing games). For example Forza Motorsport 8 is making almost stable 60fps on medium 1080p but my new monitor gonna be 1440p and I can feel right now it's gonna kill my GPU. I want to try it also with 3 monitor so it's gonna end my performance for good I believe.\n\nWhat's your thoughts about it? \n\nMy CPU is AMD R5 7600x \n\nAlso I wonder if my PSU can handle everything (Im not gonna OC anything)\n\nMy psu is Corsair RM750x\n\nR5 7600X\n\n7 fans \n\n1 sata sdd, 1 m2 disk \n\nThanks for any help! :3\n\n&#x200B;",
    "comments": [
      "I just upgraded to a 4070 FE. It was a little expensive but a much better value than the 4070ti. I think from a 1070 especially with features like frame gen, you're gonna be blown away. I run it at 1440p and love the results so far. With 12 GB Vram you should be good for a while although no promises with how the gaming industry is going. \n\nYour CPU and psu are a great pairing for it. It's a super efficient card rated around 200w. I run it on a 650w psu with no issues.\n\nIt all comes down to how much you want to spend. At 1080 you would be safe with even a 4060, it would still be an insane upgrade from a 1070, although everyone hates the card for the value. If you're for sure going to 1440 and want to be good for a while I wouldn't go below a 4070 or 12gb vram\n\nEdit: spacing",
      "The 4070 has a bad reputation due to the overall value ($/fps) but it is a VERY capable 1440p card.\n\nIf the price feels right for you and the 4070ti is too much of a price increase then i would say go for it. youll be very happy with the performance at 1440p and that shouldnt change for a few years. on top of that youll have access to additional features that should only get better as time goes on due to the nature of AI and machine learning.\n\nYour PSU is more than sufficient for your setup.",
      "Yes, I love my 4070. You’re in for a treat if you’re coming from that card. I undervolted and slightly underclocked it and it’s pulling anywhere from 20-80 Watts. Extremely power efficient.",
      "The RTX 4070 is a really good 1440p GPU, but it is still a bit overpriced. Maybe wait a few weeks for Black Friday/Cyber Monday to get a better deal.  The RX 7800XT is also a good choice from AMD.",
      "I was using Nvidia gpu's whole my live I would like to stick with them even if AMD would be a little better. Also I dont really like used stuff I prefer new pc parts (yeah Im weird) so I would go for 4070. \n\nThanks for help!",
      "In my opinion, it's the only card worth buying right now.",
      "I don't think the bus will be much of a limit on this card. It's main limit is it's raw power.\n\n\nOut of all the cards out right now the 4070 is one of the best, limited only by it's price for the performance being kinda meh.\n\n\nI have one for the record, never been bandwidth starved at 1440p and mostly playing around 80-160 fps in various games. Also it's almost silent. Loving it.",
      "I upgraded from a 2080 to 4070 and the experience has been great. It's more than enough for 1440p. The only game that pushes the 4070 to it's limit is Cyberpunk 2077 but that's with path tracing enabled and even then you still get 60-80 fps with maxed out settings.",
      "I think I should buy it even more and will be 100% happy with it",
      "I'm 100% happy with it now that I have the latest features to try and i doubled my performance upgrading from a 3060.\n\nMy rationale was save the money from a 4070ti and use it to update to the next generation if i really want to upgrade again.",
      "Wow, thanks for all answers, I didint expect so many.\n\n4070 Ti in my country is over 1000$. It's almost whole my salary, and I think I dont want to spend that much on GPU. Its just too much for me.\n\nIm playing mainly Racing games so I think Ray tracing would be awesome for me because I like overall graphics.\n\nI have read all your answers and I'm 90% sure I should go for it. \n\nAlso, what 4070 would you recommend me?\nGigabyte seems like good way to go but never had this card, never had any card model except MSI.\n\nAgain, thank you for all help!",
      "u gaming on 60 fps max? that doesnt sound like ur gpu is even half used",
      "Thanks! I worried about PSU because bequiet! calculator said it will be 83% usage of my PSU but now Im not worried about it",
      "I don't know why people care about $/FPS, it will always flavor cheapest cards, 4090 have the worst ratio of all cards, If you want really good ratio get 6600. That's why I always said to get best GPU you can in your budget",
      "Ray tracing isn't must have for me but having RT would be something new and I would really love to try it",
      "What a retard are you, lol. He literally wrote he wouldnt like to spend as much as 4070 Ti, and you are suggesting him to buy 4090",
      "According to techpowerup it would be a 250% increase. I was actually shocked to see the 1070 is on par with the 3060 lol insane how good the old gens were. Grain of salt though that's just an estimate each game varies. [techpowerup 1070](https://www.techpowerup.com/gpu-specs/geforce-gtx-1070.c2840)\n\nAlthough as an anecdote I play cyberpunk and went from ~70 frames mid settings no RT to ~100 frames max settings W/ RT. Massive difference especially with frame gen",
      "I just upgraded from an Arc A770 today after growing tired of uncharted 4 breaking and requiring a driver rollback to become playable again. Now the game runs flawlessly at 4K locked 60fps whereas before…when it would work, it was 30-45fps usually. \n\nI’m trying to ignore the fact that it cost me $600 but my logic was I was this close to giving up on pc anyway and eating the cost of a ps5. I do IT for a living and the last thing I want to deal with these days is my own tech not just working.",
      "Your PSU is fine, the 4070 isn't that power hungry. I have a Asus 4070 TUFF with a 850 gold plus PSU and it runs with no dramas. Card wise it's pretty good, you can hit good fps in 1440p with high tuned settings in most games.\n\nStable diffusion and machine learning is also good on it with decent render times but you're hard gimped by the vram at 12gb. It would otherwise be an absolute beast of a card if it had more VRAM. \n\nSpeaking of which though you also have AMD's 7800 XT that has similar performance minus RT with more VRAM for lower price depending on where you are. Between the latter if you have the budget and don't care about RT or ML/Stable Diffusion I'd grab whatever's lower and on sale. \n\nIf AMD does get their shit together with RT, ROCM and ML Net their cards though the 7800 XT and 7900 XT/XTX would probably definitely be the better option in the long run but I wouldn't hold my breath.",
      "Last Gen's 80 Series is today's 70. Add in excellent power efficiency and the latest technology, it can last quite a while into the future for 1080p and 1440p. No matter what the reviewers say, be it good or bad, buy it if you can afford it if it will make you happy. For the better part of the last 3 months, I'm contented with my purchase! It's paired with a 5600X and I've been loving Remnant 2. I'm looking forward to Lords of the Fallen."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "rtx4070",
      "4070",
      "4070ti"
    ],
    "title": "Personal comparison between MSI RTX4070 and Sapphire 6950XT in 20+games",
    "selftext": "**Disclaimer: I purchased all the products in my benchmarks and reviews, NO sponsors**\n\nFollowing my last weeks review on the 6800XT, this week I decide to review the 6950XT since they are *very close in price when the 6950XT go on sale every few days*. The full comparison can be found [**here**](https://www.bilibili.com/video/BV1Gh411L7VS/). Added timestamps for each test.\n\n&#x200B;\n\nI also included some [direct records](https://www.bilibili.com/video/BV1Em4y11781/?spm_id_from=333.999.0.0) on the benchmark process since some people questioned that I'm faking results. The previous [6800XT review](https://www.bilibili.com/video/BV1dg4y1j7Up/#reply163148112976).  Note here in Assassin's creed Valhalla is tested using 90% resolution, I  will be updating it to 100% as well as the result when I retest. For  every other card they are all at 100%\n\nI will also be comparing the 4070ti I purchased earlier this year as well as 7900xtx and 4090 later\n\nA few mentions:\n\n1. RTX  4070 beats 6950XT and 6800XT in RT, but it's still too weak even when  combined with DLSS 3.0 to have a smooth experience (with dlss 3 it gets  35 ish fps when it works, but it can be broken and get even lower than  native). You have to dial down the settings, for example in cyberpunk  2077 ultra preset the 4070 gets around 17.5FPS AVG, 6950XT around 14 FPS  AVG, the 6800XT around 12 FPS AVG. In Hogwarts test scene all 3 cards  are a lag fest at highest present.\n2. RTX  4070 when faced with VRAM limitations such as in the Last of Us Part I,  will use system ram to compensate, at least that's what rivatuner tells  me. The 6950XT uses around 14GB when the 4070 uses around 22GB, and the  frametime variance is larger on the 4070\n3. Some  games I tested but not shown on video include the witcher 3 next gen,  total war III etc. In those games AMD cards have some strange behaviours  where the FPS and frametime are **a lot** better than off recording. I can't see why that is so I didn't include those\n4. 6950XT is using the OC bios settings from Sapphire\n5. The power efficiency between the 6950XT and 4070 in this bench is 325W/200W=1.625X, if using silent bios then it is 300/200=1.5X\n6. When games support DLSS 3.0, the 4070 is most likely getting higher FPS than 6950XT with no upscaling\n\nThe system I used is\n\n13900k 5.6/44\n\n2x16GB DDR5 6800c34\n\nMSI Z790 carbon\n\nSN850X 2 TB\n\nHX1000i\n\nDrivers: AMD 23.4.1 WHQL and Nvidia 531.61 WHQL\n\nTimespy extreme for 6950XT\n\nhttps://preview.redd.it/ymbw9v9qk2xa1.png?width=2425&format=png&auto=webp&s=a392e4ba20fecd10935e74daf714628b13c956af\n\nRTX 4070\n\nhttps://preview.redd.it/rvp496msk2xa1.png?width=2427&format=png&auto=webp&s=e66d584085d6f9ba25148c355e6f280f30d8f402\n\nThe games reviewed are:\n\nA Plague Tale Requiem 0:35\n\nAssassin's Creed  Odyssey 1:09\n\nAssassin's Creed Valhalla 1:48\n\nBorderlands 3 2:20\n\nCall of Duty Modern Warfare 2 2:52\n\nCyberpunk 2077 3:27\n\nDying Light 2 Stay Human 3:58\n\nF1 2022 4:34\n\nFar Cry 6 5:17\n\nHitman 3 5:48\n\nHogwarts Legacy 6:22\n\nHorizon Zero Dawn 6:57\n\nMarvel's Guardians of the Galaxy 7:26\n\nMiddle-Earth  Shadow of War 8:03\n\nRed Dead Redemption 2 8:36\n\nShadow of the Tomb Raider 9:11\n\nThe Callisto Protocol 9:40\n\nThe Last of Us Part I 10:14\n\nWatch Dogs Legion 10:59\n\nJustice Online 11:39\n\nDLSS 3.0 tests 12:23\n\nSummary 14:50",
    "comments": [
      "This makes no sense. 4070 performs like 3080.\n\n3080 is perfectly fine for RT.",
      "Totally depends on the game. My old 3060ti would happily run ghostwire with rt on and dying light 2 with rtgi and stay above 60fps @1440p dlss quality. My 4070 does so with ease especially with frame gen on dl2 and cyberpunk. At 1440p a 4070 is beyond bare minimum to enjoy rt on in games imo.",
      "I’ve noticed that if you undervolt and scale down power consumption on the 6950 XT to roughly 200W, it keeps most of its performance and you can get raster performance that beats a 4070, in case anyone cared about power consumption. Scaling it down to 225W matches stock reference 6950 XT, though I know in this review it uses an OC version.",
      "It is, because there is a larger frametime variance and the difference between VRAM and RAM even if you turn off all monitoring software you would still notice the stutters here and then. This is also confirmed using the frametime graph, if you take a look from **10:30** in the last of us test, the frametime graph is fluctuating constantly on the 4070 but the frametime graph is fairly flat on the 6950XT",
      "So I don’t think the 4070 is powerful enough to take advantage of RT. Although running cyberpunk 2077 at max settings RT off 1440p with dlss 3.0 on quality I was getting 155 fps.",
      "I don't understand the path traced cyberpunk result. It runs far better than that in every benchmark I've seen",
      "The 4070 is also a great undervolter though",
      "Its the bare minimum for RT imo.\n\nAnything weaker than a 3080/4070 RT is not worth it.",
      "when RTX 4070 is leveraging system ram....how much of difference did you notice while playing....is this noticeable by regular gamer while playing without enabling any fps or frametime counters.",
      "Thank you for the nice comparison",
      "Which part are you referring to? I don't think I showed my path tracing result?",
      "> You have to dial down the settings, for example in cyberpunk 2077 ultra preset the 4070 gets around 17.5FPS AVG, 6950XT around 14 FPS AVG, the 6800XT around 12 FPS AVG. In Hogwarts test scene all 3 cards are a lag fest at highest present.\n\nsorry thought this part was about overdrive. but the fact that it isnt just makes it even more confusing? How was your performance that bad? \n\nhttps://youtu.be/LVovUcHnwws?t=379\n\nDigital Foundry's video on overdrive shows a really good framerate at 1440p balanced DLSS with frame gen on - even frame gen off is better than your result. that said can't really tell what your resolution is from your video",
      "All my benchmarks are done at 4K, highest preset available for each game except rdr2 where I manually maxed out everything other than anti aliasing. I haven't shown any raytracing results because they are not really playable at 4K max, even with FSR or DLSS 3. Maybe when you combine dlss 2 and 3, but that was not the focus on my tests.\n\nFor cyberpunk RT specifically I selected raytracing ultra preset and turned off FSR/DLSS manually and under this condition the 4070 scored around 17.5FPS AVG. I did run some path tracing results and the 4070 got about 8 FPS AVG...",
      "lol what. My 4070 does RT very well"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "rtx4070",
      "4070"
    ],
    "title": "Gigabyte 4060ti Gaming Oc (cheapest 4060ti) vs Ventus-2x 4070 (cheapest 4070) with 100W/130W/160W/175W/185W/200W Power Limit in Kombustor Benchmark",
    "selftext": "&#x200B;\n\n[RTX4060 vs RTX4070](https://preview.redd.it/6h7x8unq3chb1.png?width=1860&format=png&auto=webp&s=7c1581adfa2d65a86ca3b99a2cd7ddcdca00fe15)\n\nSomewhere around 120Watts, RTX4070 surpasses RTX4060ti. Depending on PSU limitations, RTX4060ti could be better for 100Watt scenario (also cheaper).\n\n\\-----\n\nNote: Gigabyte has better binned GPU because furmark was taking 10Watts less than normal Kombustor benchmark. This is due to shaders being higher quality than the graphics pipelines. The opposite is in Ventus 4070... It just can't clock as high as base boost.\n\nFurmark 4070: 2205 MHz boost\n\nFurmark 4060ti: 2850 MHz boost\n\nNote2: both cards are +150MHz overclocked on only GPU. 100Watt test was not possible by just power slider because of minimum limit. So it was achieved by flattening the voltage curve at some point.\n\n&#x200B;\n\nNote3: plugging monitor to 4060ti gives  +100 points on 185Watt (rather than switching renderer from nvidia control panel). So there is only 1/50 performance difference caused by 1080p frame data moving here and there.",
    "comments": [
      "There's another related thing you can check. Power efficiency on the same card when you lock clocks and/or power limit. For example, I found out that my 2060 is just as power efficient at 1600MHz, at higher voltage, as at 1200MHz. Probably because the VRAM power consumption stays the same and the voltage at 1200MHz is meant to maximize stability, not efficiency. So even if you want to lower power consumption as much as possible, there's no point going lower than 1600MHz.",
      "Looks like Ada cards are needlessly overclocked and show **much** better power efficiency when being power limited. Though it's not limited to NVIDIA, it's the same for AMD and Intel GPUs/CPUs.\n\nRTX 4070 at 160W is super efficient and runs circles around RTX 4060 Ti.\n\nThanks a ton for your work!",
      "Vram power of 7900xtx is like 60watts. Its a lot when you downvolt.",
      "Memory must be 25-30 watt. So by downclocking memory, maybe gpu-bottlenecked algorithms can get even further boost at 160W.",
      "So this tells us that both cards are heavily overpriced, especially 4070/4070Ti."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "rtx4070",
      "4070",
      "4070ti"
    ],
    "title": "Rtx4070 or 4070ti for Unreal engine 5?",
    "selftext": "I am mostly using UE5 for 3d rendering and works that require using Ndisplay too. Is there a huge performance difference between the 4070 and 4070ti? or the 4070 is good enough and i can spend my cash on ram or somewhere else?",
    "comments": [
      "Granted you have a decent enough CPU and 32GB of RAM, I’d go with the 4070Ti. The 20% performance bump guarantees it’ll sit in your system a little bit longer than a 4070. It also gives you an easier pathway to upgrade your monitor later. \n\nI have a 5800x and 4070Ti, and I just went from 2560x1440p to 3440x1440 and get just about the same performance that a 4070 would from 2560x1440.",
      "You can just turn the viewport window res up or down to your liking, so cpu and RAM are probably more important. A used 3090 is probably better just from a VRAM perspective",
      "Get the 4070ti if you can. Everybody recommends the 4070 because of better price point but the only generational upgrade 4070 has is the dlss and frame gen. Lower power draw is good but for the uplift in performance, the 4070ti is more or less a good price/perf. I’m getting the 4070ti because hardware/raster wise, it’s the better than everything of last gen.",
      "hey thanks for the reply! I am currently looking at the i9-13900k and 64gb of ram atm, is the 4070ti still needed in that case?",
      "Well, it wouldn’t hurt to have the additional 20% performance, but with that setup and either of those two GPU’s you’d have a solid build.",
      "4070Ti is around 20% faster than 4070. It's signifcant, but the bottleneck with that faster GPU is that they both have 12GB GDDR6X of VRAM.\n\nThe Ti should have had 16GB then I would have got one. Considering that I think the 4070 is a much better price point so that's what I got and highly recommend it."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "rtx4070",
      "4070",
      "4070ti"
    ],
    "title": "RTX 4060ti vs RTX 4070 vs RTX 4070ti for 3D & Adobe Products",
    "selftext": "Hi friends,\nI'm looking to buy a new desktop and I been scrolling through alot of posts about nvidia graphics cards\n\nRTX 4060ti has 16gb vram so I thought it would be good for 3D work, however I saw people slam it as it isn't much of a upgrade from 3060 thus not worth the money. I saw that the 3060ti was released in 2021 and although it is recommended for 3D but not sure if it is worth it as it is quite dated.\n\nRTX 4070 has pretty good reviews but it only has 12gb and most people were talking about it in gaming standards instead of 3D work.\n\nRTX 4070ti has 12(?) and 16gb but it is more expensive than 4070.\n\nI heard you need 16gb vram for 3D work but some people say 12gb is fine for rtx4070 due to the speed of rendering esp if you are a hobbyist. \n\nI heard 8gb vram is not recommended for 3D work so I'm not looking at the 4060.\n\nWill like to hear your thoughts about what's suitable for 3D work specifically.\n\nLooking not to break the bank too!",
    "comments": [
      "3d work is too vague. What do you do ? Are you a beginner ? Or a pro ? \n4070 should cover most of your needs, if you needed more than that i don’t think you’d be asking the question"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "4070"
    ],
    "title": "My dad is offering me his RTX 4070 after being gifted a new pc. I have a RTX 3080 and my brother has a gtx 1080 I'm conflicted, help please.",
    "selftext": "So my dad got a new, top-notch pc from a friend who works at AMD. He has offered me his RTX 4070. I kinda feel stupid because a month before the 40 series released I bought a used RTX 3080, a new i9 10900k and a 850W PSU. My brother on the other hand has a GTX 1080 and a 750w PSU. Should I give my RTX 3080 to my brother as a hand me down or should I tell my dad to gift the RTX 4070 to my brother for his birthday since his psu is lower wattage than mine. Also, my brother has an intel i7 as a CPU.\n\nEdit: im keeping the 3080 unless i see reasons why the 4070 look is more sexy for me lol. Its just i didn’t want to stress my brothers psu so much. He would appreciate it either way he gets hand me downs when i upgrade anywah\n\nEdit 2: holy shit my phone is being pinged like crazy this subreddit has is super active lol\n\nEdit 3 (final): im taking the 4070 and will trade it in for a 4070 super or 4080 when i sell my dads other pc parts",
    "comments": [
      "Hand your brother the 3080 and keep the 4070",
      "the 3080? sure. btw that 3080 has 3 pcie or 2? make sure his psu has the recommended connectors.",
      "Give him the 4070. 3080 to a 4070 is negligible enough in uplift to make no serious real world gain for you. \n\nThough, if he's still rocking a 1080, chances are good the rest of the hardware is nearly as old. Possible CPU bottleneck.",
      "Ok i hope his 750w psu can handle it.",
      "I'd HIGHLY suggest an undervolt though. My 3080 peaks at 270w instead of 360-400 and has the same performance.",
      "Just give your brother your 3080, that’s what I would do. He’s not going to complain about not getting the 4070 when he’s getting a nice upgrade himself for free.",
      "-RTX 40/50 series runs the new DLSS 4 transformer model upscaling/ray reconstruction better than RTX 20/30 series cards\n\n-Extra +2GB VRAM (assuming they have the 10GB card)\n\n-DLSS framegen support (can be hit or miss)\n\n-Lower power consumption by ~120w\n\n......................\n\nIf they have the 3080 12GB, it will be a small downgrade moving to the 4070. If it is the 3080 10GB, those extra bonuses are probably worth the free swap in even if it is only a sidegrade.",
      "His psu is a cx750 it has 3 pcie outlets",
      "I've had a 350w 3080ti with a 650 PSU for years with no issues. \nHe will be fine",
      "You’ll see no performance boost from going to a 4070, would be better for your brother to have it instead unless you need 2x frame gen",
      "Hes not a big complainer lol. Its just i dont want to fry his pc",
      "If OP's getting the card for free, there's no reason not to take the offer.  Sure, it's a sidegrade based on pure raster performance, but better DLSS and frame gen is a straight upgrade.",
      "3080 to 4070 is a downgrade in raster.",
      "3080 is slightly faster vs 4070 but 4070 has more VRAM, more features (Frame Generation) and more efficiency.\n\n3080 recommended PSU is 750w so your brother can use it.",
      "4070 uses significantly less power. That's enough reason for me.",
      "The 3080 is way more power hungry and powerspikes more than the 5070ti lol..",
      "Yes, about 1-2%...\n\nHis statement that the performance difference is negligible in the real world is perfectly valid.",
      "My 650 can handle 5070ti so he will be more than fine",
      "Oh dont worry, 750w is perfect for 3080, I believe this is my current setup. And he can undervolt 3080 which is probably a good idea. I undervolt mine.",
      "I've been using a 3080 with a 650w psu for the past 3 years and haven't had a single issue. I have a Ryzen CPU though. His Intel probably uses a little more."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "4070"
    ],
    "title": "Is a new basic 4070 Super for $450 good price?",
    "selftext": "",
    "comments": [
      "That is a unbelievable price buy it immediately.",
      "Get that shit asap before someone else does",
      "This card has been at my local Walmart for a few days now. The employee said it is new. My current card is a 5700 XT from AliExpress, and I only need to play games at 60 FPS at 1440p",
      "fyi PNY is not basic, they make great cards and even workstation ones.",
      "I'd buy it in a heartbeat if I saw a 4070s for that price. In Canada they're like a 1,000.00+ if you can even find one.",
      "it's probably gone already lol",
      "I feel like a man dying of thirst watching another man drown",
      "About 2 months ago I paid $580 for a MSI Ventus 2X 4070 OC. Not even a Super, just an OC edition, and I thought that was a great deal. Since the 50 series launch, even those are going for around $850 now.",
      "Update: Thanks everyone, I will go get it tomorrow if it is still available.",
      "Especially the XLR8 model, which is PNY’s flagship",
      "Go for it.",
      "Hopefully supply will stabilize and you will be able to buy cards at msrp again.",
      "With the 4070 you can enable NVIDIA DSR and render many games in 4K at 60 FPS. On a 1440p monitor, this gives very crisp graphics and you can disable AA in many cases.",
      "I took basic as meaning not-Ti model.",
      "MFG is the only new feature, everything else is available on 40 series.",
      "Guys I got a 5090 for $12 is that a good price?",
      "Its stronger and more recent",
      "return it man, bad deal!  4060 is no good.",
      "...yes? Are you not aware that there is a 4070 Super and a 4070 Ti Super?",
      "I just got that same card for the same price at my local Walmart!\n\nhttps://preview.redd.it/jcwj5eexbvne1.jpeg?width=1080&format=pjpg&auto=webp&s=56bf493be33e7d131c8ec859ceb51b71a58c9d60"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "rtx4070",
      "4070",
      "4070ti"
    ],
    "title": "Rtx3070ti busted. What should I go next?",
    "selftext": "Hi everyone, as of the title, my 3070ti is busted badly. I have a b550 pro ac mobo and planning to get the 4000 series. For my budget the best I could get is either the 4070 s, 4070 ti or at max 4070ti s. From what I've researched the 4070 gap with 4070 s is too big and as it goes higher the gap is smaller for the price worth. I usually play single player open world games at 1080 or 1440 in the future or even 4k max. I'm using ryzen 7 5700g currently and if get the 4070s, i can spare some change and get the 5800x3d. So do you think i should go for that or stay with my 5700 g and go all out for 4070 ti s? Thanks in advance. \n\nUpdate: Thanks to everyone's suggestion, i went with rtx4070 s and 5700x3d combo. The games are so smoother now and I get so much value for my buck. ",
    "comments": [
      "What do you mean busted? How? I’d go 4070 super and get a 5700x3d off of aliexpress for 150 or so",
      "4070 super at least",
      "Get 4070 series.\n\nI'd not bother going Ti SUPER if I were you. Especially not if you can find a cheap 4070 on sale.\n\nAre you playing esport games, demanding AAA games or both? The CPU mostly matter if you chase very high fps.",
      "Something melt within. Was wondering why I can't start any game recently until I brought it to a shop to test it out since I have no spare parts for testing.",
      "Have you tried warranty replacement? Are you sure the rest of your computer is fine as well? Good airflow in your case? Your card shouldn’t melt randomly.",
      "To be honest, the only testing they did was roll back nvidia driver, swapped the gpus and left a game idling for 3 hours. When they have no problem with the swapped gpu, they swapped back to the 3070 and play the same game and it shut down instantly. Also regrettably the warranty is over.",
      "Try changing out the thermal paste and giving it a good clean before buying a new card. Could just be overheating. And if it’s sagging a ton try running your computer horizontally or getting gpu brace",
      "What gpu they use to test? Could be PSU issue if they use less power GPU.",
      "> Try changing out the thermal paste\n\nOP, please read this comment, watch a youtube video and try it yourself before throwing out your card.\n\nI thought my card was dying last month, asked questions here, got this advice and my GPU is even better than new now."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "4070"
    ],
    "title": "GeForce RTX 5070 Ti leak: 7.6% faster than 4070 Ti SUPER in Blender, on par with RTX 4080 SUPER in OpenCL test",
    "selftext": "",
    "comments": [
      "Compared to a 4070 Ti Super.....\n\nAbout 6% more cores.  Uses about 6% more power.  Delivers about 7.6% more performance.\n\nYawn fest.  Nvidia still gonna charge $750-800 bucks for this nonsense.",
      "This is definitely the 4070 SUPER TiTi",
      "7,6% Performance boost for only a 35% price increase. What a steal ! \n/s",
      "not everyone has a 40 series gpu lmao",
      "But but nvidia said: 5070~~ti~~ = 4090 🤓",
      "Soo... It is a 4070 Ti Super Ultra!",
      "Basically they’re re-releasing the 4000 series, except the flagship is better.",
      "i mean at this point everyone can agree this is the worst generation. i was not gonna upgrade this gen anyway but this reduces my expectation for the next generation as well cuz even if they do 20% boost on 6th gen RTX it will still be relative to this subpar generation.",
      "nVidia really have the consumer GPU market by the balls. Two extremely lackluster generations and I'm still having to consider a new card because 10gb VRAM is not enough for my needs anymore. \n\nOn top of that, more money gets me a tier below what it did last time. \n\nAnd on top of *that*, the tiers have essentially been shifted down by applying higher tier names to lower tier specs.",
      "Turns out I had no idea how lucky I was when I got my 4070TI Super for 750$.",
      "I remember when a generational uplift was 20-30% faster not <10%",
      "If this is indeed 1.2x vs 4070 Ti Non Super, then here's how 5070 Ti performance will shake out (based on TechPowerUp 4K Average FPS):\n\nAgainst 40 Series\n\n* 5070 Ti = 1.1x vs RTX 4070 Ti Super (probably not worth upgrading)\n* 5070 Ti = 1.2x vs RTX 4070 Ti (upgrade might be ok if you want MFG)\n* 5070 Ti = 1.3x vs RTX 4070 Super\n* 5070 Ti = 1.5x vs RTX 4070\n\nAgainst 30 Series\n\n* 5070 Ti = 1.42x vs RTX 3080\n* 5070 Ti = 1.8x vs RTX 3070 Ti\n* 5070 Ti = 1.9x vs RTX 3070\n\nAgainst 20 Series\n\n* 5070 Ti = 1.86x vs RTX 2080 Ti\n* 5070 Ti \\~= 2.21x vs RTX 2080",
      "wow great overclock series nvidia",
      "Is this the weakest generational uplift ever?",
      "Don’t kid yourself into thinking that was a good price for that range of GPU. Market is fucked and we should not let this normalize",
      "Oh you will pay over $1000 for a 5070Ti. There's no FE which means no guaranteed MSRP and the AIB's will be well over that.",
      "~7% slower than a 4080s for $750… I guess that’s something, but then again the 4080s even with the price cut was too expensive anyways soooo",
      "There are not really any meaningful upgrades that have a decent value proposition for the > 3080 gang.",
      "Not impressive, as expected. Entire 5000 series lineup is just a refresh.",
      "What a shit generation of GPUs."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "4070"
    ],
    "title": "3080 10GB —> 4070 Ti Super",
    "selftext": "Did some freshening up on my AM4 build. Recently did a new case/AIO/fans, and now the EVGA 3080 has been upgraded to a 4070TiS. Build is dialed in and feels great. Runs cool and quietly. Couldn’t be happier.\n\n(PNY XLR8 4070TiS, 5800X3D, Kraken Elite 240, 32GB 3600mhz C16, SN850X 2TB, Strix B550-F, RM850X, H5 Flow 2024)",
    "comments": [
      "You really have to skip a generation and stay at the same tier or go up a tier in the next gen. \n\nYou want to go 3080 to either a 4090 or 5080 if you want to get a good noticeable difference.",
      "should be 25-30% for $800",
      "4070ti isn't  30% better than a 3080. It's good, went from a 3070 to a 4070ti myself, but it doesn't  feel THAT powerfull.",
      "Why bother with such a small upgrade so close to a new generation.",
      "How's the upgrade in performance?",
      "3080@10 - is still a fine GPU in most cases",
      ">my room doesn’t turn into a sweaty brothel whenever I game now.\n\nThere's hardly any difference in power consumption between a 4070 Ti Super and a 3080... Even more so if you had the 3080 undervolted like you said.",
      "Bro thinks everyone lives at NVIDIA factory and we'll be able to get the new cards since day 1",
      "Thats my plan. I have a 3080 and I play at 1440p. Getting a 5080 and sticking with 1440p for most games.",
      "What I was planning to do, but if the rumors of 1500€ are true, that is double the price my 3080 was.",
      "I set an $800 budget for a new GPU that I wanted now. This is what I got. You don’t have to be happy with it, but I am.",
      "I am currently running Stalker 2 on 4k 60hz , DLSS and all eye candy set to high.  Game runs flawless.",
      "It is, but not enough to see a \"next gen\" type of change in your visuals. Not IMO anyway.",
      "When the 50 series releases the 40 series will drop in price like the 30 series did and there's going to be more second hand listings on sub 1 year old cards.",
      "You're fully aware that operating temperature have nothing in correlation with heat output, right?\n\nThe 4070ti super is 285W, and the 3080 320W, and both will gain about the same from an undervolt",
      "Interesting upgrade choice at this time - why didn't you wait for the 5x series? The 3080 is a bit old, but it is still a good card.",
      "Bingo. Unless OP has a specific game where he was just 20% away from having the framerate he really wanted, this probably wasn't worth it. Would have been better to wait a generation or buy a 4090.",
      "Temp doesn’t matter as much as power draw—lower temp could just mean a cooler that gets that heat into the ambient environment more quickly—but if they have the same power draw, the same room will heat up by the same amount.",
      "Should also be able to get $300-350 for the 3080. Not to mention the money I’ll save on antiperspirant since my room doesn’t turn into a sweaty brothel whenever I game now.",
      "True, but I’m not concerned with any of that"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "4070"
    ],
    "title": "NVIDIA GeForce RTX 5070 Ti is 16.6% faster than RTX 4070 Ti SUPER in leaked 3DMark tests",
    "selftext": "[https://videocardz.com/newz/nvidia-geforce-rtx-5070-ti-is-16-6-faster-than-rtx-4070-ti-super-in-leaked-3dmark-tests](https://videocardz.com/newz/nvidia-geforce-rtx-5070-ti-is-16-6-faster-than-rtx-4070-ti-super-in-leaked-3dmark-tests)",
    "comments": [
      "On par with 4080 Super while also being sold at the price of 4080 Super and close to 5080 because the 750$ MSRP isn't ever happening \n\n\nlmao.",
      "so it is basically on par with 4080 super",
      "Doesn't mean shit as there is no fe edition and companies will charge 30% more than msrp",
      "10% more power , 10% more performance , 50% more expensive",
      "![gif](giphy|xUStFKHmuFPYk)",
      "4080 performance for the price of a 4080!",
      "Good luck finding one in Europe under 1200€.",
      "Alright, we can all agree 50 series performance upgrade is way worst than 20 series.\n\nThis could possibly the worst in Nvidia history.",
      "I don't live in the US. That's not my problems, but good luck living there now. \n\n\nWhere I live I can buy a carton of eggs for 2$.",
      "Yeah, seems you have to go Inno3D or PNY to get one at or near msrp based on an article I saw yesterday for planned prices in one European country anyway, possibly Germany.\n\nHopefully prices will calm a bit later in the year once demand isn't as acute as it is now.\n\nEdit: Just to clarify that I am simply listing the only two brands which will apparently have cards at msrp in the article I saw for a particular EU country and not meaning to imply that they are to be avoided. Just won't seemingly have many additional choices like a Zotac, Asus Dual etc which tend to be at msrp or just barely above it.",
      "Of course they will be. There’s thousands of people who still rock 10 and 20 series cards who are ready for an upgrade. Just because the jump isn’t massive from 40series to 50, doesn’t means it’s not worth a purchase.",
      "And it’s gonna cost over 1200-1300€ in Europe so basically more 300-400€ for a 16% performance increase. So happy I bought a 4070 Ti Super a while ago.",
      "The common price is 930 so yes",
      "Pretty much dead on arrival for us lol",
      "I did the math for 4K average and:\n\n5070TI is average 17% faster than 4070TI super\n\n5080 is average 20,5% faster than 5070TI\n\nEdit:Performance from TPU 4K should be like this for 5070TI.Looks like 4080super will be 6% faster.\n\nhttps://preview.redd.it/62ovvd7pfoje1.png?width=436&format=png&auto=webp&s=4ae8212795f14330b4f7d50af4d7a4d88ef5e0e5",
      "The 4080 is a 4080, but the 5070 ti could be anything. It could even be a 4080!",
      "Could someone please tell me if I'm mad about this or not?",
      "Yeah that was such a disappointment.\n\nThey made an FE for every card *but* the good one. One that doesn’t melt and isn’t gimped.",
      "The 5-series owners when they realise the only thing they are paying for is 4xFG.",
      "I mean.. there are like 2 cards going for MSRP. I do think the pricing overall is ridiculous, but I also think if people can wait a few or more months they will start coming down."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "4070"
    ],
    "title": "[Gamers Nexus] NVIDIA's Rip-Off - RTX 4070 Ti Review & Benchmarks",
    "selftext": "",
    "comments": [
      "\"Great product, terrible price\" should be Nvidia's corpo motto now",
      "Are we going to see RTX 4060 for 600$ and 700 Euro in the future? \n\nNvidia just lost the fucking plot. Mining is OVER. They just learned NOTHING from launching Turing after Mining crash.\n\nGN ripped Nvidia a new one, and they deserved it!",
      "This is one of the funniest reviews I have seen in a long time. Rainbow six siege segment killed me",
      "A good product at a terrible price is a terrible product. \n\nJust saying.",
      "And there it is, another overpriced card. It might be the time to take nvidias advice and just get a console.",
      "this is a $499 product in normal times",
      "this is barely better than a 3080 at 4k. I am shocked. This was going to be a 4080 card, its so bad...\n\nThe implication that basically rest of the stack in 40 series are just trash is really awful. Everything else below this card is so cut down and resource starved nobody should bother wasting money on. I dont see how the rumored 4070 even matches 3080.\n\nThe performance at 4K really shows that cache can't compensate for the drop in memory bandwidth.",
      "This is “normal times.” They have no reason to raise prices this damn high. Hell, they could lower prices (slightly) thanks to the crazy profits made during the last three years, specifically during the crypto boom. \n\nIt is clear that Nvidia are focused on AI and have no regard for the gaming market other than being a decent value proposition up-and-coming developers (who can’t afford their professional class GPUs)",
      "Yikes.   \n\n\nI'm so happy I have a 3080.",
      "Here's the video he was referencing: [Gamers Nexus loves Rainbow Six Siege - Steve Edition](https://www.youtube.com/watch?v=ILwgcJQ1xfU)",
      "Not if it falls off a truck",
      "No way 4070 will be 599 only. Its going to be 650$ or something. And then 4060Ti is 550 or 600.",
      "They cannot lower their prices because corporate profits MUST ALWAYS GROW. As they made a killing on the mining boom they must now bend themselves over backwards and make an even bigger profit, anything else will be a \"total disaster\" from the shareholders POV.",
      "I did and PC gaming is going to stagnate if these high GPU prices persist. Normal people either cannot afford them or (in my case) refuse to pay them even though I can afford it.",
      "As the gn video points out, Nvidia finally said something like \"the 3000 series continues to be the best ~~selling~~ option for most gamers\", they finally said publicly that mid and low tier gaming is to be done on 2+ year old hardware, the 4000 series is high end only, despite it being the same uplift and same naming convention of old releases that were half the price.",
      "\"you wouldn't download a graphics card\"",
      "And the 3080 smokes most everything 1440p already. This shit is hilarious. I was in for a 4070 Ti at $800 if it beat out the 3090 Ti... but yeah that's not the case at all.",
      "AMD & NVidia are just awesome! Congrats all around.",
      "Indeed, what a great duopoly we've got!",
      "rebranded 3080ti"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "rtx4070",
      "4070",
      "4070ti"
    ],
    "title": "Anyone have experience with Galakuro? (Japanese brand)",
    "selftext": "Hey everyone, I am currently running a r5 3600 with a 5600 XT that I build 3 years ago. \n\n\nI am planning to upgrade my cpu to a 5800x3d. I am a bit undecided on which GPU I should upgrade to. However I am leaning towards a 4070.\n\n&nbsp;\n\n\nI live in Japan, and while looking on Japanese Amazon at different prices, it seems like this Japanese brand named \"Galakuro\" has the cheapest cards.\n\n\nI don't know if the price difference is because of simple fact that it's a Japanese brand selling in Japan. Or if the because the cards aren't as good as others.\n\n&nbsp;\n\nSo I was wondering if anyone has any experience with this brand or their cards?\n\n&nbsp;\n\nThese specifically are 2 of the cards I am looking at.\n\n\n\nhttps://www.amazon.co.jp/GG-RTX4070Ti-E12GB-EX-TP2-Graphics-RTX4070Ti/dp/B0CC54RGP9/ref=sr_1_11_sspa?crid=1VXOZMMLBTNJ6&keywords=rtx4070&qid=1692711510&sprefix=rtx%2B40%2Caps%2C181&sr=8-11-spons&sp_csd=d2lkZ2V0TmFtZT1zcF9tdGY&th=1\n\n=4070ti\n\n&nbsp;\n\n\nhttps://www.amazon.co.jp/GG-RTX4070-E12GB-DF-Graphics-GeForce-RTX4070/dp/B0CC55CVY6/ref=sr_1_2_sspa?crid=345O8KG0IWF0H&keywords=4070&qid=1692712038&sprefix=40%2Caps%2C173&sr=8-2-spons&sp_csd=d2lkZ2V0TmFtZT1zcF9hdGY&th=1\n\n\n= 4070",
    "comments": [
      "seems like Maxsun",
      "玄人志向 was the former brand.  Not sure why they rebranded by they are fine. My 1070 was that brand.  They are basic, usually the cheapest but I had zero issues apart from my card being ugly.  Cooling and performance was inline with most other cards.\n\nAnd they also seem to be Galax now.. And make Intel ARC cards.  Interesting.\n\nAlso dospara have a range of cards around the same price: [https://www.dospara.co.jp/products/all-item?q=4070&lang=ja\\_JP](https://www.dospara.co.jp/products/all-item?q=4070&lang=ja_JP)",
      "Galakuro is Galax"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "4070"
    ],
    "title": "My 4070 SUPER FE Arrived (It came in about 16 hours)",
    "selftext": "",
    "comments": [
      "https://preview.redd.it/7qwo5z3jh6dc1.jpeg?width=640&format=pjpg&auto=webp&s=2733805076abe8cba701b236fd265c55d6c62e1a",
      "Ok.",
      "Wow it came faster than me.",
      "Informative",
      "Noted.",
      "Nothing can come faster than me though",
      "No wonder Nvidia doesn’t have to drop the prices",
      "Have fun bro, and ignore all the bad comments, it’s a great gpu for high resolution for years.",
      "I wish I could buy FE cards. All the GPU models from the other companies are usually huge.",
      "Man this has been tossed around this sub a lot recently",
      "Dildo",
      "and costs at least 200€ more, but since there will be no FE, it's likely 350€+ more, because the retailer prices are absurdly high. most 4070 ti supers are listed at the 1000€ mark. at that point you could just get the 4080 super fe, but wait, thats only another 300€ off the cheapest 4090, so go with this instead. but you know what? 50xx is announced at the end of this year, so better wait for them! \n\nseriously, there is always a better card for more money and more time, but when someone needs a gpu now, and they only need the power from a 4070 super, there is absolutely no point in spending more money and waiting longer",
      "I'm still on 1080p and am using DLDSR to upscale to 1440P and it runs great. I upgraded from a 1660 Ti that i was running for almost 5 years. Probably gonna get a 1440P OLED sometime in the future when prices are more reasonable",
      "The logo Geforce RTX it lights up?",
      "Ditto.",
      "Unfortunately it does not",
      "They don't have to drop the price, that is correct.",
      "30 seconds is my record",
      "Ah yes the real benchmark only connoisseurs know about. Was kind of disappointed that there's absolutely no plastic on the GPU to peel off.",
      "Then, have an informed opinion, from my experience and knowledge as a AAA game dev.\n\nThis card will be fine for many years. \n\nThere may be PC exclusive outliers, but nearly everything ported from console will excel on this GPU.\n\nThat gives you until the PS6/etc gen come out, circa 2028. Then a year or two after that as cross-gen ports are still a thing. By 2030 it'll be truly obsolete, as the cross-gen period ends.."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "4070"
    ],
    "title": "NVIDIA launches GeForce RTX 40 SUPER series: $999 RTX 4080S, $799 RTX 4070 TiS and $599 RTX 4070S",
    "selftext": "",
    "comments": [
      "Cant wait for comments  \"Waited 14 month and finally 4080 at decent price\". \n\nIm not a hater... but at least this will push other cards down.",
      "How is this a News and not a Rumor if CES still didn't start?",
      "That name sounds like a version of Street Fighter",
      "The bigger question is: Are those real STREET Prices,\n\na) Will you be able to get one?\n\nb) Will scalpers buy everything up?",
      "Probably got the leaked slides hours before the official presentation.",
      "100% the new card will have 4gb more vram and be almost as fast as the current 4080",
      "Typically only the used cards fall. The regular new cards just stay at their same price until they sell out",
      ">Cant wait for comments  \"Waited 14 month and finally 4080 at decent price\".\n\nNot a decent price. The decent price would 800, and I aware that we will never see it again.",
      "A couple weeks ago I posted these prices on the AMD subreddit wanting to have a legit discussion about what AMD would need to do to remain competitive and they all called me delusional that this would be the real pricing lol.",
      "Will 4070 ti Super Founders Edition exist ?",
      "We have Ti Super now ?",
      "If these cards sell out at this price point, it's all buyers fault. If they don't sell, Nvidia will have to lower prices again. This is how it is.",
      "Videocardz: \"I'm gonna pump out a dozen articles before and after CES and you're going to upvote these reddit threads bitch! It doesn't matter if its all AI generated and rewording the same thing everyday!\"",
      "For the RTX 5060 @ $800?",
      "As an owner of the OG 4080, I'm happy to see the price point of the S variant became much more tolerable. With the 4070Ti Super inched ever closer to the 4080, this means the 40 series will become a bit more accessible to gamers. \n\nProbably gonna be good till the 50 series releases.",
      "INTRODUCING THE ARR TEE EEX 4070 TITANIUM SUPER",
      "Inb4 the RTX 4070 Ti Super (Jensen's Version)",
      "Kinda regret buying my 4070Ti now lmao, maybe I should return it since I still have time and snatch this. It’s $80 more but idk",
      "It's better than the 4080 and the 4080 will be discontinued.",
      "> they all called me delusional\n\n> your post has 300+ upvotes and all top comments are about AMD will and should drop prices to be competitive\n\nPeople really will lie about an easily verifiable info just for karma. Nobody in that thread agreed to people calling you delusional."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "4070ti"
    ],
    "title": "Cyberpunk 2077 Has The Best Graphics I've Ever Seen in Any Game. Playing in 4K ULTRA + Max Ray Tracing - RTX 4070Ti - 60FPS",
    "selftext": "",
    "comments": [
      "I'm playing the Game with Pathtracing and yes, it is absolutely stunning. I love it.",
      "I still have a problem with the general graphics style. Yes it looks amazing, but something is off, or missing. I can't really describe it. The cars for example, they look like plastic cars. The buildings are somehow all so angular. The textures itself are not as good as I wish they would be. Can't describe it better. I think ray/pathtracing does much for this game. Without it, it looks just not good. There are many games that look superior to Cyberpunk, even without raytracing. That said, those games doesn't have to render such a large city - so it's hard to compare.",
      "The materials to me do not look quite right. A lot of things look like playdough and not like proper metals. People also look still very clay-like. Many textures are still very blurry compared to other games. However, the lighting and reflections etc., are obviously all without parallel.",
      "Can you post your settings? I also have a 4070ti and couldn't get anywhere near 60 fps with Ray tracing on.",
      "It's stunning indeed. Best Ray Tracing game there is.",
      "DLSS and Frame Gen on?",
      "Same. Only game so far that just driving to or from a mission I have to stop just to admire how insane everything looks",
      "Best implementation, for sure",
      "3080 with ray tracing not cracking 60 now even with dlss perf for me ..",
      "Whilst it does look good, graphical fidelity in itself is very opinionated to personal taste.  \n\n\nI'd have to argue that some scenes in RDR2 truly look stunning in terms of realism or coining the phrase of 'best graphics' .",
      "This x1000. The game has insanely good lighting/reflections and environments crafted to display that well. The textures are lacking. I was severely disappointed after hopping on yesterday to check out PL after all the “Starfield’s graphics are so much worse than Cyberpunk” comparisons only to see that at native Starfield has better textures.\n\nUnfortunately the circle jerk has started so no nuance is accepted on these things.",
      "I skip fast travel entirely when *that* song from edgerunners comes on the radio. Just chill and drive to my next objective while sobbing",
      "What it does is irrelevant when the user is telling you they feel no extra input lag at their end. Mileage will vary user to user, obviously.",
      "Reflex Low Latency is turned on automatically so that negates the input lag, can't feel no input lag when playing.",
      "You must have very low visual standards if you think 1080p with upscaling on performance looks native. On 1440p the difference between quality and performance is already quite noticeable.",
      "Laugh of the day, loved the LiTeRaLlY",
      "My 4070Ti needed path tracing and DLSS\n\nThis also helps squeeze another 10 or so FPS. I keep Path Tracing on\n\nhttps://www.youtube.com/watch?v=B03_Aa5NwIY",
      "Yep, the best",
      "Summary:\n\nTexture: High, lower if 6G VRAM\n\nMotion Blur: personal preference\n\nContact Shadow: On\n\nFacial Lighting: On\n\nAnisotropy: High\n\nLocal shadow mesh: Medium\n\nLocal shadow quality: High or Medium\n\nCascade shadow range: High\n\nCascade shadow resolution: High or Medium\n\nDistant shadow resolution: High\n\nVolumetric fog: Medium\n\nVolumetric cloud: Medium\n\nMax dynamic decal: Ultra\n\nScreen space reflection: Medium or High or Low\n\nSubsurface Scattering: High\n\nAmbient Occlusion: High\n\nColor Precision: Medium\n\nMirror Quality: Medium\n\nLOD: High\n\nCrowd Density: High, Low if CPU is weak\n\nRT Reflection: On\n\nRT Sun shadow: Off\n\nRT Local shadow: On\n\nRT Lighting: Medium or Off\n\nPath Tracing: On if you can afford it (basically needs RR)\n\n[https://youtu.be/B03\\_Aa5NwIY?t=1364](https://youtu.be/B03_Aa5NwIY?t=1364)",
      "That’s pretty impressive even for a 4070Ti"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "4070"
    ],
    "title": "RTX 4080 vs 4070 size comparison 😳",
    "selftext": "",
    "comments": [
      "The white 4090 is in the background",
      "size doesn't matter\n\n\\- 4070 owner",
      "The GPU she tells you not to worry about vs your GPU.",
      "As an owner of a white Strix 4090, yes, I can confirm. The card is an aircraft carrier masquerading as a GPU.",
      "don't talk to me or my son ever again",
      "4070 is average, OKAY!!",
      "And that's just the FEs",
      "my GPU is 3070 😟",
      "The 5090ti till just be a computer case.",
      "“Babe don’t worry he’s just a friend”",
      "To be fair, the huge 40XX cooling gives extremely excellent cooling at 70-80 degrees at full load",
      "How’s the thermals on the 4070? I find the 4080fe is completely over specd when it comes to thermals. Fans defaulted at 30% and I can’t say I’ve ever seen the card hotter then 65° lol. When let to increase it hovers at about 58°. \n\nQuietest and coolest card I’ve ever owned.",
      "Mine is a 970 😭",
      "5'11\" vs 6 foot",
      "Never was\n\nIt was always mid range.\n\n1070ti was the only 70 series i would consider high end \nSince it was only 2-4% behind the 1080",
      "Well it typically doesn’t pull more than 200W, so the thermals are pretty excellent.",
      "Honestly, yeah. I don't mind the FE's being absolute beasts in size. If you buy a 4080 or 4090 you will likely want a big case with good airflow anyways.\n\nAnd like you said, thermals are amazing. Way overkill, but then you can choose between running fans really slow, or overclocking quite a bit.",
      "Have you been on r/sffpc lately? Those people are stuffing 4090 FE into 10 liter cases\n\nE: wrong sff sub",
      "The 4090 is now a literal table, it chonk",
      "Look at Mr. Money bags here with a GPU made in the 21st century. \n\n- GeForce 256 owner"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "4070"
    ],
    "title": "NVIDIA GeForce RTX 4070 Ti officially costs $799, launches January 5th",
    "selftext": "",
    "comments": [
      "Reddit this week: \"Ew, I'm passing on that!\"\n\nReddit next week: \"Guys I was able to add to cart and checkout!!!\"",
      "And pics of 4070ti’s with seatbelts on in passenger seats. “It may not be a 4090, but it’s mine :)”",
      "This just makes the $1,199 4080 even more pointless than it already was. AMD will have to adjust 7900 series pricing too.",
      "Hey, the 3070 Ti was $599, that's only a $200 increase compared to the $500 increase for the 4080 and 3080! What a deal!",
      "So don't buy one. GPU sales are the worst in 20 years. Will will see price reductions soon if people hold out. Current pricing is to make the overstock of 3000 cards look attractive, don't fall for it people.",
      "PrEcIoUs CaRgO",
      "So it's 1000 in eu?",
      "Can’t wait for $800 60 series cards. Man, fuck this shit.",
      "I wouldn't be surprised to see a $100 price cut on the 4080 given its poor sales, particularly internationally.  It's not going to make much sense to pay 50% more for a 4080 over the 4070Ti, but I suppose that assumes you can actually get a 4070Ti at MSRP, which is to be seen, since there's no FE model.",
      "Much faster than 3090ti*\n\n* = DLSS 3.0 enabled",
      "A 70 card that costs more than last gen's 80, thanks Nvidia.",
      "The more you buy, the more you save! /s",
      "Totally agree: +40% is best value for money vs +60%!\nLets all praise Nvidia!",
      "Entry level 4050... \\**shivers*\\* ...$500?",
      "With the wife/girlfriend in the backseat",
      "do we have any hard sales numbers on the 4080 or is it all reddit speculation based on price hate?",
      "\"We have 4090 at home\"",
      "This, but people are addicted to buying stuff, it's that small dopamine rush they get when browsing for parts, completing the purchase and inserting the card. Then 2 weeks later they start to yearn for a new hit.",
      "u all complain but they gonna sell out as usual",
      "In Romania its 1300 euro with 19% VAT, on Evomag."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "4070"
    ],
    "title": "NVIDIA clearing GeForce RTX 40 inventory, RTX 4070 on short supply making room for early 2025 RTX 5070 launch - VideoCardz.com",
    "selftext": "",
    "comments": [
      "The cynic in me tells me this new generation, at least for the 5070 and below, is terrible value. Otherwise, they'd have no problem having both 4XXX and 5XXX coexist for a few months.",
      "Eh, we just have to wait and see",
      "Am I the only one who has the feeling 5090/5080 get announced before this Christmas? Like, Jensen will come in his leather jacket again and present us his Christmas present.",
      "would argue that it is the opposite, if the 5070 is better value, they will struggle to sell the remaining stock.\n\nBut that would not fit the reddit narrative of complaining about nvidia based on completely made up scenarios",
      "They were probably going to get release late Q3 early Q4, but when AMD showed that they weren't going to try and compete by Q4, they decided to shift course and wait until Q1 next year. They want people buying up the 4000 series cards for christmas. Then release the 5080/5090 with no competition in Q1.",
      "Incoming RTX 5070 at $999.",
      "It could also mean that the 5070 performs similar to the 4070 and they don't want people to buy the discounted 4070.",
      "And with 12gb vram",
      "While I don't expect anything good from Nvidia, this may indicate 5070 being actually a good upgrade over 4070. They made RTX40 and RTX30 coexist because mining overstock and same price per performance. When replacing a product at same price point either older one gets discounted or supply cut before new one comes so a direct transition happens. It is possible we are seeing second scenario here.",
      "People should be taught basic economics in school as a mandatory subject. It has applications in other day to day decisions we make but it seems to be under appreciated and not well known. It blows my mind how conspiracy brained people get when they’re like 1 question away from unravelling their entire world view.",
      "I only wish they wouldn't be stingy on the VRAM.",
      "On the contrary, people might hold off on 4000 knowing the 5’s are right around the corner and you might miss one holiday shoppers waiting for the 5",
      "I'm not after a narrative. That's specifically why I said \"the cynic in me.\"\n\nNothing would delight me more than have a 5070 clearly beat a 4080S in performance.\n\nIn my scenario, a discounted 4070S would appeal to people who didn't want to spend slightly over MSRP on a new 5070. They could coexist - unless the 4070S or the 4080S are much better value.",
      "it's a 5060 dressed as a 5070 with a price of a 5080.",
      "Lol for people that are waiting for 50 series in belief, that 40 series will drop in price. HAH NO! You are too naive.",
      "The fact that nvidia is so eager to sell out the 40 series before releasing the 50 series does suggest a lower performance uplift to me.  I think nvidia can get away with releasing a 5070 that's only a little bit faster than the 4070S, so long as (i) it has some marketable new software features, and (ii) it's not too much more expensive than $600.  But I think nvidia will get hurt their gpu market position a little (not that they care, with enterprise products selling at higher margins) if they release a product that's only 10% faster than a 4070S, but costs $800.  And that means that the 5070 and the 4070S cannot coexist around $600.",
      "Genius. This will prevent heavy discounts on Black Friday/Cyber Monday and during the Christmas fever. People could get used to discounted prices thinking about them as a norm.  \nThis way no one will be shocked in January when they'll show 5xxx MSRP. It's for a greater good - NV cares about us! /s",
      "Not holding my breath 😒",
      "People will sell their used cards when 50 series comes out to adopt the new stuff. People will prefer to buy 50 series over 40 series so naturally people will have to sell 40 series lower to account for the lower demand of those cards, and to make it so someone will actually buy a 40 series card instead of spending the extra on a 50 series card.\n\nUnless the 50 series stuff is really close to 40 series and there’s not enough 50 series for the demand then I don’t see how this happens hypothetically.",
      "4070 Ti Super being phased out (says so in the article), so good luck finding one soon."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "4070"
    ],
    "title": "NVIDIA RTX 4070 Ti is 5% faster than RTX 3090 Ti in leaked OctaneBench test",
    "selftext": "",
    "comments": [
      "The retailers in Canada are selling the 3090 TI for $2599.99, the cheapest today is $2050\n\nThe 4080 is $1699.99 in the same store.\n\nThere's something very strange and very wrong with this picture, previous gens cards prices are barely moving. $600+ for a 3060? Get fucked.",
      "Yep.\n\n\nAlso, when the 4090 is the best price for performance option, we have a problem.",
      "Cards DOA if it's 899, ah who am I kidding there will be a smorgasbord of people posting \"Just upgraded from a 30X0!\" builds",
      "If you own a 30x0 card, I'm begging you to not buy this generation unless the prices actually come down from last gen. Please don't further enable Nvidias shit pricing",
      "Honestly, these kinds of posts are so bizarre to me. Are we supposed to cheer a random person that they've spent money? Do they want us to be envious? Jealous? Why do people need to post every pointless bit of their lives online. Sorry for rant :(",
      "Wat you don't wanna see my 4090 seat belt buckled to my 99 Honda Civic?",
      "Octane performance is always faster than game performance, as its not held by CPU and other stuff. In a way, it reflects true computing performance of the GPU better than games, but obviously, if you care only about games, awesome Octane numbers wont help you.\n\nI presume 4070Ti scores about 720 points then - since vanilla 3090 is cca 650. Not bad. 3090 would still be better choice, if priced similarly, cause 24GB of vram.",
      "Bro seriously?!? You could have easily gotten $100+ more for that card.",
      "So the 4080 is 35% faster than 3090 Ti in this benchmark, but according to reviews it's roughly 25% faster in games.\n\nSo in non-DLSS 3 games the 4070 Ti will more than likely compete with the 3080 Ti/3090 rather than the 3090 Ti.",
      "I just sold my old 3060 for $250....",
      "I think the scenarios where 24 gigs of vram are useful are fair bit more niche than frame generation plus better ray tracing performance.",
      "depends where you are? I see some new 3060ti going for 400 in USA. can't say I know anyone that would dish out 350 for a 3060",
      "Nvidia is really just gonna give us 1 to 1 price to performance increase this generation........ \n\nWelp hopefully the 4070ti flops like the 4080 too so we can get price drops next year",
      "Yeah I don't get anything that is happening now. You can’t find any cards in stores except for 3060 and 3060ti and those are ridiculous expensive still for some reason and nobody wants them for those prices. They said after mining that there would no longer be gpu shortages yet it’s as bad now or worse than it was a year ago. I want a 4090 and have only been able to find a 4080 which just isn’t cutting the mustard and is going back soon. Still no luck 3-4 months later after launch finding one and even 4080s fly off the shelves in the states. Once the 3000 series glut was gone they said we’d start seeing 4090s but those have been gone for a month or more now and still ain’t shit on the shelves.",
      "Oh I won’t. Consoles are the target for most games anyways. 30x0 will be fine until ps6",
      "Scalpers/ex-miners need to cut their losses and move on. There is no excuse for any 3000-series card, in any configuration, selling for more than a 4070ti, yet if you look online, you routinely find people doing just that, likely trying to scam unsuspecting victims. It's despicable.",
      "So basically you can get that performance with an overclocked 3090 and also have double the vram",
      "If Nvidia can charge $1200 for the 4080 and people in this sub are showing it off in their build, in *this* sub after swearing it's an awful price point, what makes you think 4070 TI will cost just $700?",
      "Generally speaking, flagship products don't offer the best price to performance. That's usually for midrange products",
      "not everywhere, in Spain (like in many other countries) you can buy a 1390€ 4080, but the cheapest 4090 would be 2000€, 43% more expensive for around 40% more performance, if you're lucky, actually most 4090s are priced 2100€+"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "4070"
    ],
    "title": "merchants are receiving rtx 4070 ti.",
    "selftext": "",
    "comments": [
      "4070 ti is the removed 4080 right?",
      "Supposedly yes",
      "It's identical specs to the 12 gb 4080",
      "999 euro",
      "How much $$$",
      "> If I’m spending a £k on a graphics card, I’m gonna spend £200 more on a 16GB card.\n\nBoth are terrible choices. Skipping this generation seems to be the best choice",
      "Another card to fly onto the shelves and gather dust.",
      "All this crap makes 4080 look attractive and a 4090 an outright bargain.\n\nWTF is going on? What world are we living in?",
      "If I’m spending a £k on a graphics card, I’m gonna spend £200 more on a 16GB card. This is one of the worst times to want an upgrade with 2-year-old 3080s still holding price fairly well",
      "Well, yes, to clarify more they nixed the launch to rename it from the 4080 12gb.",
      "One might say ..\"working at intended\"",
      "thats with VAT included right? so the actual price is north of 800 euro or probably same 900USD as before...",
      "Around 21-30% slower and 4gb less. That's why it was pulled after people found out what was under the hood. \n\nhttps://www.tomshardware.com/news/nvidia-compares-geforce-rtx-4080-16gb-and-rtx-4080-12gb#:~:text=With%20DLSS%203%20enabled%2C%20the,4080%2012GB%20without%20DLSS%20enabled.",
      "Because it's really the unlaunched 12gb 4080 in a new box",
      "How does it compares to a 3090?\n\nEdit: wow, it's worse???????\n\n\nEdit2: I'm fuckin drunk, it looks like it's a bit lower than the 3090ti depending on the game but enough to be strong as 3090.\nTo be honest I'm buying it at $800 since it's the price of an old used mined 3090.",
      "Hard pass on all 40xx series cards.",
      "I wanted to wait for this card… but I have a SFF case and the measurements are identical to the 3090Ti… \n\nWhy did they make a 70 series card that large…",
      "Actually this is the oc model. Meaning the msrp would lower for no base models.\n\nLikely 800",
      "Nvidia loyalist will proclaim this as a great deal, Oh wow 3090 like performance for less than the cost of a 3090!",
      "Lol 1k"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "4070"
    ],
    "title": "NVIDIA GeForce RTX 4070 Ti now up for preorder in China for same price as canceled RTX 4080 12GB - VideoCardz.com",
    "selftext": "",
    "comments": [
      "$1000 and up for xx70 class performance is insane",
      "Waiting for 4050 for only 699$",
      "If you thought that was insane, wait until you see people posting builds with these things in them.",
      "Nvidia can go fuck itself with these prices. \n\nMining is over. People will not buy mid level cards that should cost ~ 500$ for 900 anymore.",
      "This subreddit went from \"Nobody will buy a 4080\" to \"Check out my new 4080\" real fast.  So yeah people will buy these, what else are they gonna do?  Buy a 7900 XT?  lol",
      "With the performance of a 2060",
      "So the card sucked enough for them to lower the name, but not the price.  Classic.",
      "this is such an embarrassing generation, man",
      "On a dedicated sub such as this one it will look like loads of people got one.\n\nBut looking at inventory it really looks like most people aren't wasting their money on one.",
      "There's levels of insanity from both sides of the equation -- my sister who's impulsive and terrible with money was bragging to everyone how she got her kid a gaming PC for xmas, she showed me on her phone it was some generic predator desktop with a 3060ti for the low low price of $2500 (no monitor included)\n\nThis is the same type of person that won't consult or ask anyone for input or guidance on buying X/Y/Z. So people are still lighting $1000 on fire from the other side of the market as well.",
      "2060 super*",
      "I can't figure out how prices doubled from one generation to another and people are still guzzling down whatever Nvidia offers.  \n\nIf I'm Apple/Sony/Google right now, I'd be taking notes. The only lesson learned here is that consumers (even the ones who think they're smarter than the average) can't help but buy regardless of the price. \n\nThrowing my savings into AAPL before Apple wise-up and charge $2000 for iPhones.",
      "I can see the internal Nvidia pricing meeting now...\n\n**Marketing Lead:** Sir, 4080s are not selling well, we should drop the price of the 4070Ti!\n\n**Jensen:** NO!!!  No one will want a $1000 4070 card, keep the prices high.  They'll buy the 4080s instead.  This is all going as planned...  \\*evil snicker\\*",
      "For real, the 4080 at most should be 799$ but instead they get fucking greedy and charge 1200$+ to try and get customers to spend 300$ more on a 90 series\n\nAbsolutely greedy I hope they lose millions",
      "Don't buy them, force them to lower prices to sell. But who am I kidding, you idiots will but them either way.",
      "You mean the generation of idiots buying these like it's a CoD penis enlargement skin?",
      "No, it's because of consumers that keep buying these things. What do you think would happen if everyone actually truly said \"screw this\" and didn't buy these things? That Nvidia and to a lesser extent AMD wouldn't drop the price? They're only allowed to keep doing this because people enable it.\n\nIt's frustrating when people refuse to put the blame where it is mainly due in today's world. I'd list other examples but they involve politics which is against the rules here so I'll leave it at that.",
      "I'm shocked! It's like nVidia is a greedy big corp that only cares about the bottom line and doesn't really care about gamers at all... Simply shocked...",
      "The name should be lowered 2 tiers to 4060ti though XD",
      "If prices are to remain like this, once my 3080 hits the dust I'm just going to retire to being an old man, watch Coronation Street and buy a newspaper with a television guide on it. \n\nBeing tech literate is too expensive"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "4070"
    ],
    "title": "4070 Ti Super build",
    "selftext": "Decided to upgrade to my 3070 Ti to an Asus TUF 4070 Ti Super",
    "comments": [
      "Love that efficient less flashy builds are coming back. This is beautiful op!",
      "Yes lol. The NR200p has excellent airflow.",
      "Case: Cooler Master NR200p\n\nCPU: AMD 7500f\n\nMemory: 32GB TeamGroup Vulcan 6000 mhz DDR5\n\nMobo: Gigabyte Aorus B650I \n\nGPU: Asus TUF 4070 Ti Super\n\nPSU: Cooler Master V850 SFX\n\nStorage: Samsung 990 Pro\n\nCPU Cooler: Thermal Right Phantom Spirit 120 SE\n\nFans: Arctic P12",
      "This is flashy as fuck I'd carry this to a lan party in one hand b like \"AYO! 165FPS!\"",
      "Please say the bottom of that case is vented",
      "![gif](giphy|tp4dm1ptNnQ76)",
      "I swear i don't get the concept of RGB dominated PCs, is this a disco party setup?! I mean I understand aesthetics but why such disco lights man.",
      "Looks great, congrats on the upgrade!",
      "Is this tight space efficient? Pretty sure its not. The card is gonna get hot.  If you mean it doesn’t have 50 rgb fans - then yea.",
      "It's a great compliment to those new glossy oled monitors. You can always see the RGB reflected on the screen at all times!",
      "Thanks",
      "The card has almost no air around to pull from. I think you underestimate how much difference the amount of cool air makes. It might not be enough to throttle the card hard, but the fans will definitely spin at high RPM, even at relatively low loads.",
      "I have a similar 4070 card and this case and it gets fucking loud, I think because the exhaust mostly stays in the case and has to be blown out by the cpu fans",
      "Happy as can be. Don’t really have to worry too much at 1440p. It’s quite a jump from the old system. I’m much happier with the increased VRAM as well.",
      "That's a nice, tight package",
      "Thank you for noticing",
      "Nice cock, bro!",
      "Want to go from my RTX2080 Super to a RTX4070 TI Super is it enough of a jump, I primarily do 4k any advice? Cheers in advance",
      "Hows the performance difference? I also have a 3070ti planning to get a 4070 ti super.",
      "Are you happy with the new performance?"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "4070"
    ],
    "title": "NVIDIA RTX 4080 SUPER reportedly costs $999, RTX 4070 Ti/4070 SUPER at $799/$599 - VideoCardz.com",
    "selftext": "",
    "comments": [
      "Well I was about to pull the trigger on a 7900xt, but think I’ll try and snag a 4070ti super simply for the reduced power consumption and dlss/frame gen at 1440p should be fine at 16 gbs vram for a while.\n\nIt all comes down to price, if these rumors are true it’s an instant buy, if it’s $999 then I’ll go back to the 7900xt idea",
      "For sure.\n\nAlmost 4080 level of power for 799 with DLSS + Frame Gen with 16GB VRAM? Solid 4k card, makes the 7900XTX obsolete.",
      "TiSuper vs 7900xtx is really favourable for nvidia. It is basically a $400 drop on 4080 which was similar to 7900xtx and way better in RT.\n\nAssuming 4070 is going to be like $500 now, I would get that over Super.\n\nThe only compelling product is TiSuper here.",
      "A year and a price cut later, the 4080 is still overpriced by $200.\n\nAt least the Ti Super is closer to the sweet spot with 16 GB.",
      "$599 will be like 750€ I guess",
      "4070 Ti Super is the star of the show, and all of these super variants should have been like this since the 40 series release.",
      "Pretty much. AMD is going to have to drop prices significantly if these prices are accurate.",
      "So are they all getting a price drop? A 4080 here in Canada is like 1600-1800 dollars it’s fucking stupid.",
      "It is so close to 4080 and 7900XTX that it doesn’t matter while it will outperform XTX in RT games.\n\nThe main thing is if nvidia can keep this in stock, it will be a scalping mess.",
      "The 4070Ti Super at $799 is basically what the 4080 should've been at launch.\n\nReally seems to be the most attractive option out of all cards from this mid-gen refresh. If it has any decent overclocking headroom, it should be able to match stock 4080 Super performance.\n\nIt will also, more than likely, be a huge problem for both 7900XTX and 7900XT sales, unless AMD does a price cut by at least $100-150 on each.",
      "You are forgetting the exchange rate.\n\n$599 is about 560 EUR. Even with 20% tax the price should be about 672 EUR. And not 750-800 EUR where it will be.\n\nEurope always had more expensive hardware for no fucking reason than sheer greed.",
      "I'm sorry but an 80 series card should still be 600-700. Do not cheer for nvidia",
      "yeah, most likely. and the 70ti super will be around 1k. prices here are stupid.",
      "I was just about to grab 4080S or 4070TIS but with 5xxx coming out in less than a year I’ll play the waiting game and use GFNow",
      "what is this AI work that suddenly everyone and their dad is doing?",
      "what why",
      "I keep wondering if they also have a refresh in the works.\n\nRdna3 just didn't meet expectations, and there were a lot of rumors that something went wrong that would have required new silicon to fix. So with that in mind, I wonder if an rdna 3.5 refresh could be on the way.\n\nIf the 4070ti super comes anywhere close to the 4080 for 800 bucks, even the 7900xtx at 800, which is Hella performant, won't look like an amazing deal.\n\nBut if course we need to see performance first. I'm rooting for Nvidia here. The horror of gpu prices that started in 2020 needs to be done. Inflation is what it is, but if Nvidia stops trying to gouge everybody for even a generation or two, then card prices will effectively equalize with inflation, and it won't \"feel\" so shitty anymore.",
      "Everything is overpriced",
      "We've gone from bad to ok pricing on the 40 series. Makes it a no brainer to get over RDNA3 unless AMD drastically cuts prices.\n\nStill debating exactly what I want to do. If I upgrade to 4080S then I'm going to finally make the jump to 4K. Otherwise I'll just have to settle for 4070S.",
      "I don't think the 4070ti Super is to compete with the 7900xtx, it is to sit between the 7900xt and 7900xtx. More to offer a better option over the 7900xt than anything else."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "4070"
    ],
    "title": "MSI RTX 40 SUPER leak confirms RTX 4080 SUPER and RTX 4070 Ti SUPER with 16GB memory",
    "selftext": "",
    "comments": [
      "If the prices are true then it is not worth like 4070ti super for 1,1k that's crazy expensive",
      "4070 TI SUPER is a dumb name i'm sorry",
      "that 4070 ti super looking spicy",
      "In the pic the 4070 ti super (lol name) costs 1300+ euros.\n\nExtremely DOA.",
      "Am I the only one that thinks it’s weird there’s gonna be 4070 ti super tf is a ti super 😂",
      "Calling the 4080 Super **great value** is sort of ridiculous especially considering its regular counterpart is objectively *poor value* and these listed prices are mere leaks at this stage",
      "Prices are popping up at more retailers, like [this one](https://www.meistersinger.at/shop_search.php?search_string=GEFORCE+RTX+4070&cat=0&verfug=0&man=&list=0&sort=price&order=desc) and [this one](https://www.meistersinger.at/shop_search.php?search_string=GEFORCE+RTX+4080&cat=&x=0&y=0&man=).\n\n* 4070 Super 20% more expensive than 4070\n* 4070 Ti Super 8-10% more expensive than 4070 Ti \n* 4080 Super replacing 4080 at the same price\n\nUS MSRP could be $699 for the 4070 Super and $849 for 4070 Ti Super.",
      "4070 Super Saiyan God Super Saiyan",
      "That naming scheme has big iphone Pro Max energy though",
      "Leaked prices:\n\n* RTX 4080 SUPER: 1230.30 - 1355.80 CHF  \n* RTX 4070 Ti SUPER: 1,060.40 - 1063.4 CHF  \n* RTX 4070 SUPER: 777.50 - 848.70 CHF  \n\nCurrent GPU prices in Switzerland:\n\n* [MSI 4080: 1'308 - 1'815 CHF](https://www.galaxus.ch/en/s1/producttype/graphics-card-106?filter=t_bra%3D331%2Ct_347%3D1060010&so=5)\n* [MSI 4070 Ti: 769 - 901 CHF](https://www.digitec.ch/en/s1/producttype/graphics-card-106?filter=t_bra%3D331%2Ct_347%3D1228753&so=5)\n* [MSI 4070: 527 - 739 CHF](https://www.galaxus.ch/en/s1/producttype/graphics-card-106?filter=t_bra%3D331%2Ct_347%3D1246865&so=5)\n\n\nIf these prices are correct:\n\n* 4080 SUPER will be **great value** *(more cores for lower price)*\n* 4070 Ti SUPER will be **slightly better value** than 4080 *(fewer cores but lower price)*\n* 4070 SUPER will be **worse value** than existing 4070 Ti *(fewer cores for same price)*",
      "The only problem is social media comments represent like 5% of the market.  Average Joe Gamer is buying whatever is on the shelf to replace his prebuild GPU.",
      "4080 SUPER SUPER lmao",
      "> 4070 would drop to $499\n\nUnlikely to happen with 4070 still selling very well, and 4060Ti 16GB already occupy $499 slot, so the whole lineup would have to be pushed down too.\n\n> 4070 Ti Super at $799\n\nThis may happen as 4070 Ti already ceased production.\n\n> 4080 Super at $999 or $1099\n\nThis can happen if they feel threatened by the 7900 XTX (which is gaining market share much faster than the 4080, due to aggressive discounts).",
      "It is to us as gamers to vote with our wallet and not by comments (they don't care about them)\n\nI will move to amd for gaming they are fine",
      "If the 4070 Ti was originally the 4080 12GB, then would the 4080 Super be called?",
      "Wtf are you on in wanting to upgrade already from a 40 series to another 40 series?  Same applies to rest of the 40 series owners complaining they can't upgrade because of prices.  If you can afford to upgrade (twice) every generation, you should've bought the highest or even the second highest tier card at launch.",
      "I'm still holding off until next gen. This refresh could be nice but what's the point in buying now if in Q4 we get cards that outperform all of them at lower power draw\n\nEdit: to clarify if you have like 30 or 20 series then I'd say it's worth waiting (that's the position I'm in) if you are on older than that and have been waiting years then of course go for it. Me personally I'm running a SFF case so the more power in less space I can get the better hence why I noted lower power draw",
      "lol a bs scam? wtf does that even mean? It is a NAME",
      "The average mid range GPU is $1000 or more now, what the hell happened man, I just want affordable cards again that arent my entire months paycheck.",
      "yea i find it weird but its just a name after all"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "4070"
    ],
    "title": "NVIDIA GeForce RTX 4070 Ti SUPER GPU Benchmarks Leak: Up To 10% Faster Vs 4070 Ti, Almost Matches RTX 4080",
    "selftext": "",
    "comments": [
      "4080 performance and 16 gigs of VRAM for 799 seems kinda tempting ngl",
      "That’s the 4080 we should’ve got at launch, for the 80 series cost. \n\nNvidia is a bag of clowns.",
      "The 16gb vram are what push me to it over the 4070s, tbh",
      "Think of it this way:\n\nThe 4070 super is a cut down 4070 ti die for the price of the original 4070. The original 4070 still exists as a base 1440p tier card for $549 msrp. \n\nThe 4070 ti super is a cut down 4080 die for the price of the original 4070 ti and replace it altogether.\n\nThe 4080 super is the fully realized potential of the die it is based on, everything that could be thrown at it thrown its way, for $200 less than the original 4080 and replaces that card entirely.",
      "There know exactly what they are doing.",
      "Will the 4080S really be worth the additional $200+?",
      "I'm waiting to see the difference in 4070 ti super and 4080 super. I've got an Alienware 1440p UW, so I wonder is 200 extra worth it if it's only 10-15%.",
      "Because people are clearly sick of gamery looking trash lol. AIBs need to catch up. The AMD partners are gamery but have much better looking GPUs, especially XFX and Sapphire.",
      "Everything is relative, but a 10% increase puts it in the gap between the 4070 ti and 4080. So you might as well say that the 4070 ti super almost matches the 4070 ti.\n\n10% uplift is roughly the compute increase, meaning that the 4070 ti memory system is not bottlenecking and well designed contrary to popular belief.",
      "I'm not going to disagree with that but still think 799 for what is essentially a 4080 is actually decent for once\n\nThe only thing wrong with this gpu is it's a year late and \"4070 Ti Super\" is one of the dumbest GPU names I've heard in a long time.",
      "I mean the 4070 super launched at MSRP.... These are not wildly in demand cards",
      "FE’s fit in way more cases. They don’t look like a space ship, and perform extremely well.",
      "The importance of VRAM for gaming importance has been greatly exaggerated. As evidenced by the amount of people that call the 4070Ti unsuitable for 4k.",
      "3% faster memory and 21% more shaders.  It used to be pretty normal to pay 25% extra for something that is only 10% to 15% faster at the high end. I don't think people at the top really care much about performance per dollar.\n\nFit example the RTX 3080 vs 3080ti, or even 3090.  People will argue it's cause of double the VRAM, but if going from 8gb to 16gb is a rip off for $100 on a 4060ti, then certainly going from 12gb to 24gb on a 3080 12gb to a 3090 is as well. But people would bought them anyway for 10% performance and 24gb even if COVID didn't happen.",
      "$799 for only 12gb vram was a crime. 12gb is seriously on the edge of not being enough for a 4k monitor if you want it to last 4-5 years without issue. Even at 1440p at higher settings in some games it could prove to not be enough, certainly at 3440x1440 which is very common with the Alienware ultrawides.",
      "In my opinion, yes! RTX 4070 Ti S offers great performance, but it does have a way less capable cut down version chip.\n\n>RTX 4080 SUPER graphics card will be using the full AD103-400 GPU with 10240 CUDA cores in total, 320 TMUs, 112 TOPs, and 64MB of L2 cache.\n\nRTX 4070 Ti Super comes with 8,448 CUDA cores + cut down RT & Tensor cores. [More info here.](https://www.makeuseof.com/nvidia-rtx-4070-super-vs-rtx-4070-super-ti-vs-rtx-4080-super/)\n\nEdit. 1/5 price increase, get you about 1/5 core/chip increase. If the price difference is $200, I would pay the extra. But that's just me. For most of the users, 4070 TiS is more than enough for the price.",
      "I never said you said they didn't know. I just said they know what they are doing.",
      "Incoming 7900 XTX price drop :D",
      "This is the one to get, IMO.  Of all the Super models, this is the best.",
      "If you hadn't, today you should've just waited another year and have gotten the 5080."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "4070"
    ],
    "title": "RTX 4070 Ti Super arrived early",
    "selftext": "",
    "comments": [
      "Super early",
      "Sorry yall she's a paperweight until drivers arrive.\n\nInstalled the driver but runs SUPER slow. Will have to wait for results tomorrow and gaming the next day!",
      "The retailer probably shipped it early and thought it would arrive on release.",
      "Well we have someone who has a 4080 super already lol",
      "Uhhhh…. How?",
      "Now test and publish",
      "Yeah he post in Facebook if there are drivers for his 4080 super asus rog xD",
      "![gif](giphy|jmSjPi6soIoQCFwaXJ)\n\nNvidia gonna bust his doors",
      "There weren’t supposed to be preorders but PNY put Amazon listings up too early.",
      "https://preview.redd.it/ng55mp4eb1ec1.jpeg?width=1440&format=pjpg&auto=webp&s=229e229548c5b5321b3b16799e5e3310018ac5e5\n\nHere in fb, I didn't want to put his name for private reasons.",
      "IS THIS WHOLE THING A JOKE TO YOU?!?!?",
      "I've had PNY cards all the way back to a GeForce 4 Ti4200 64mb. They're a board partner for many Nvidia professional cards, no issues with them.",
      "According to this \n\nhttps://www.cgdirector.com/cinebench-2024-scores/#Cinebench_2024_Results_GPU\n\nYour score is higher than score for 4080 - I like that but we  need 3dmark score - could you do it ?\n\nEdit: benchmarks got deleted he had score in cinebench 27k",
      "Oh I didn’t know about preordering these",
      "Post might have been removed. It was definitely stolen. He claimed his “friend was an authorized ASUS reseller” and that it was”had no serial number”.",
      "I believe they got removed. They were only PNY. Nothing I would lose sleep over. Get a Gigabyte for about the same price in a couple of days.",
      "He posted it here.",
      "I mean if you got a GPU a week early, you wouldn't put a few min in to looking for possible solutions to make it work?",
      "Benchmarks ASAP",
      "It most likely not work because the drivers aren’t out yet"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "4070"
    ],
    "title": "Upgraded from a radeon 6750xt to a 4070 ti super. Completely different experience ",
    "selftext": "Got my new gpu for $750 on prime day, it's an Msi ventus 3x black edition, which comes with a 4090 ad102 die. I decided to upgrade because I was not satisfied with my 6750xt performance in 1440p. Games like Dark tide, cp, last of us, the witcher, starfield looked like trash at high settings with fsr on. Performance was okayish, but the impact on quality was there. \n\nI also tried using amds frame Gen and it was barely usable. The input lag was too much for me and the graphics looked flickery and wanky. \n\nI wasn't expecting dlss and nvidias frame Gen to work so well! I can't even tell the difference between dlss on or off, and frame Gen gives me +40 fps with minimal input lag. I'm now playing ultra modded cyberpunk, Alan wake 2 at max settings, max rt and path tracing and it just feels smooth and beautiful. \n\n",
    "comments": [
      "I too use my pc for cp \n\nCyberpunk!!! It was cyberpunk!!! I swear! FBI, don’t raid my home!",
      "DO NOT FUCKING SHORTEN CYBERPUNK!!!!!!!!!!",
      "Welp that's the difference in a $300 GPU and a $800 GPU.....",
      "DO NOT SHORTEN CYBERPUNK!!!!",
      "FBI OPEN UP!!!!",
      "I was just stating facts, OP acting like these were competing cards and Nvidia wiped the floor with AMD. \n\nThis is like saying I got a 4090 and damn it blows the 4070ti super out of the water. But it cost twice as much. Yea well I hope it would for twice the money.",
      "LMAO BRO!!! just say CYBERPUNK! TRUST ME!!!",
      "To all the other posters: context is everything. CP in this setting obviously stands for Cyberpunk, not for Cerebral Palsy, center of pressure or central processor or what ever the hell you guys think about.  \nDid you know that there is a clothes brand named C.P. Company? Give it a rest.\n\nAlso to the OP congrats on your GPU.  \nEnjoy it to the fullest.",
      "![gif](giphy|rCqHtYuB0a9re731gG)",
      "Are you just too lazy to think for a second? It’s easy enough to determine based on context. If you can’t tell which CP they are referring to then that says more about you than the people abbreviating Cyber Punk as CP.",
      "CP is short for a bunch of other things too. if that is the first thing that comes to your mind regardless of context, then the problem is with you",
      "Thanks my g. I fell in love with cp the first time I saw it on YouTube  (cyberpunk)",
      "Nah, I’m not too stupid to understand context.\n\nAre you also offended when cerebral palsy gets abbreviated? Candlepower? You’ll be super offended by Canadian Pacific Railway’s logo: https://en.m.wikipedia.org/wiki/Canadian_Pacific_Railway\n\nIt’s hilarious you’re so offended by an abbreviation. You just need to get child porn off your mind. You think about it way too much.",
      "Downvote for the memes lol. Your comment be funny.",
      "Is there any other meaning of cp, Except the CP0.",
      "![gif](giphy|31TI3rb3fAlqdCOFuq)",
      "The 6750xt has 2080ti/3070/4060ti like performance. Manufacture aside, It’s a huge upgrade.",
      "![gif](giphy|gLLenvI8omrwPjiwQM)",
      "\"+177% performance\" tell me you've never seen the benchmarks for these GPUs, without telling me you've never seen the benchmarks for these GPUs.  \nYes, the 4070Ti is a much better GPU, but it's nowhere near 177% in general usage!  \nThe only scenarios where that could happen are extreme cases like running Blender renders with Cycles on both GPUs, while also using OptiX on the 4070Ti Super",
      "That's 2x the price so quite naturally it is almost 2x as fast"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "4070"
    ],
    "title": "NVIDIA GeForce RTX 40 SUPER launch scheduled for January 17, 24 and 31 with RTX 4070 SUPER leading the way - VideoCardz.com",
    "selftext": "",
    "comments": [
      "“4070Ti Super” is such a dumb name",
      "Is it me or does the 4080 Super not seem all that Super?",
      "Maybe the price will be super compared to the 4080. Super for us that is.",
      "You don’t trust Nvidia but they got your money anyway",
      "Praying 4070 gets a price drop for us broke people 🙏",
      "So 4070 Super, 4070 Ti Super, and 4080 Super. \n\nNvidia should’ve called the 4070 Ti “4070 Super Dee Duper”",
      "4070 Ti Super sounds so dumb.",
      "Can’t be worse than the whole DLSS numbering mess.",
      "Maybe they should call it Lousy 4080 instead of 4070ti super. Lol.",
      "I'm not so sure you know what the word \"undeniable\" means.\n\nThe 4090 is an untouchable triumph, but AMD competes everywhere else down the stack, generally offering superior value products right now. Nvidia might still win the argument when it's all said and done, but AMD is absolutely competing.",
      "I just don't trust Nvidia anymore so I got me a regular 4080 despite all the rumours, fuck it really.",
      "Crazy that we're going to have like 7 cards that are all within like a 20-30FPS delta at most.",
      "Add to this the 4070Ti was originally going to also be called a 4080",
      "Most optimistic pricing - 4070 500$ 4070 Super 600$\n\nMost realistic - 4070 550$ 4070 Super 650$ \n\nMost Nvidia pricing - 4070 Super 700$\n\nLets see",
      "Based on those rumors the 4070 Ti Super 16GB will be the go to card, but if it's till $850 like the current one I still have zero interest.",
      "*Super* **SUPER** **~~priceyS~~*****uper***!",
      "I’m still waiting for the 4090 Ti Super Extreme.",
      "4070 ain’t gonna be cheaper then $479",
      "It's so confusing because aren't the Ti's supposed to be better than the Supers? 4070 Ti > 4070 Super... but 4070 Ti Super???",
      "The vram monster that lives rent free in peoples heads.\n\nCurrent consoles only have 10-11gigs of vram available while targeting a dynamic 4k. Until a PS6 drops with 20, no game will require it. \nI understand people and disliking 8 gigs as it’s actually easy to use up at 1440p but half of steam is playing on 6-8. Textures aren’t going to skyrocket to 20 until the cards are very old."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "4070"
    ],
    "title": "I gave up on the 5070 and bought a 4070 Super FE",
    "selftext": "As the title says, my intention was to purchase a 5070 at the end of this month to replace my 2060 Super. Now, after seeing how Nvidia handled the launch of the new 5090 and 5080 I decided I was not going to take part into that. \n\nLong story short, I ended up buying a used 4070 Super FE with still 2.5 years of warranty for 590€ and I couldn't be happier. I can now crank everything to max settings on my 1080p144 monitor. The card itself looks amazing too with its all-black finish. \n\nHow did I do?  \n",
    "comments": [
      "Great idea. I might do the same.",
      "4070 super is an amazing card",
      "The goat gpu of the 40 series, enjoy it you won't miss anything by not getting the 5070",
      "The fact that the 5070 still comes with 12gb VRAM was just what I needed to convince myself to buy a 4070 Super... lol",
      "NVIDIA’s own first party benchmarks suggest only about a 3-5% raster improvement for the 5070 over the 4070S (the comparisons are all to the 4070 and the 4070S is 16% faster).  It’ll be the least impressive 50-class card thus far.  The Blackwell Tensor cores also don’t seem to provide any immediate advantage as super resolution and ray reconstruction run about as fast on Blackwell as Ada Lovelace.  Moreover multi frame gen is worthless unless you have at least a 180 hz panel (240+ makes more sense) and Blackwell has no advantage in 2x FG, which is the less niche option.  \n\nThe major DLSS upgrades are to super resolution (Transfomer model), ray reconstruction (Transfomer model), and FG 2x (AI model replaces optical flow offering a 10% fps increase and less VRAM use).  All of these are available and run just about as well on Ada as Blackwell.",
      "If you’re not getting the Ti then I honestly think the 5070 will be slower than the super. Or within margin of error on benchmarks. If you’re not going to use MFG or AI, then there’s nothing to be gained from the 50 series. \n\nI am baffled by the number of people “upgrading” from 40 series to 50 series.",
      "Hey!!! I've got a 5700x3D too like you do!",
      "You might want to hurry up because I've been looking now and just see them being shipped from outside US for absurd prices above msrp for 4000s line up. I think 4070 still has decent stock on some models but who knows how long that will last.",
      "Dear Lord, you are one of the very few people on reddit who actually understands why that move is the right move in 2025. God bless you. I hope others learn from your post.",
      "Nope, the 4070 Ti Super is the goat. 16gb Vram will make a difference in the near future",
      "It's a very good 1440p build",
      "I bought a new 4070ti super today. If I can get lucky on launch and get a 5070ti I will, but now at least I’ll have something!",
      "According to HWU the specs of the 5070 in relation to the flagship would make the 5070 a xx50ti-class card. \n\nThe 5070 today is what used to be *entry level*.\n\nThat's madness",
      "Yeah I’ve had a 20, 30, and now 40 series and 4070S is my favorite of them all for 1440p. It can run  everything maxed out usually around 100fps with no upscaling, while pulling 200W or less when undervolted, chilling at 65C in my SFF build. Path tracing is even doable with DLSS, especially with DLSS4 performance, add frame gen and you’ve got an absolutely killer card for $600.",
      "In the future ? Probably, but now 12gb is more than enough for 1440p, and by the time 12gb are no longer viable after 2 to 3 years, we'll be looking at the next upgrade anyways, \n\n\nso in pure fps per dollar value, 4070 super is the goat, seeing how with the ti super you get just 10 to 15% more performance while having to pay 33% more (200usd more)",
      "If the 5080 is anything to go off of it will be margin of error.",
      "I am going to copypasta a previous rant of mine because it helps to add context to your 300IQ decision. Here it goes!\n\nNVIDIA delivered a masterclass in brainwashing during their presentations/keynotes which has left a lot of people thinking that FG will allow them to crank up the settings/res on a demanding game and double their FPS with a card that is already struggling. To make matters worse, they also convinced people that MFG is a must-have feature for next-gen gaming. I have seen a lot of 40 series owners use MFG to justify their need to upgrade to 50 series, which is wild. No matter how hard I try, I can't seem to make the sheeple understand that FG/MFG is not meant to make a low class card perform like a higher class card, but instead, it's meant to enhance an already smooth/playable experience for people with high refresh monitors. I can only imagine how many people are counting the days until the 5070 drops so that they can get \"4090 performance for $549\" after listening to the smooth man in the slick croc jacket. \n\nThe icing on the cake for the entire 50 series is the fact that NVIDIA successfully pulled off their 4080 12GB plan from last gen by dropping every card down a class while still naming and pricing it as the higher class (not including the 5090). They know that the average user doesn't track and compare the internal hardware config for every class across multiple generations, which allowed them to pull off the scummy move right in front of everyone's eyes. Thankfully, channels like Hardware Unboxed put out an in-depth video exposing how they did it. \n\nIf you own a 30 series or older and feel like you are due for an upgrade, the 50 series is the best option available, but pricing and inventory are VERY unstable at the moment with retailers increasing the price of cards multiple times this week alone. If you can somehow find a good deal on a 40 series card, you may want to consider that first.",
      "I did the same.  I have a 3070 but man I am seeing huge gains with this 4070 super!  And I have frame generation!  Congrats man!",
      "I’m trying to but sold out everywhere at the moment",
      "I have a 4070 Super... is it just me or are they suddenly in short supply?"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "4070"
    ],
    "title": "NVIDIA GeForce RTX 4070 Ti could cost $799, at least 10% cheaper than cancelled RTX 4080 12GB - VideoCardz.com",
    "selftext": "",
    "comments": [
      "3080 was 699\n\n4070 ti 799\n\n\ni dont like where this is going lads",
      "Can't wait for the 4090Ti myself. The 4090's served me well, but it's starting to show its age. About time to move on I think.",
      "Cant wait for the 4080 ti $1400 and 4090 ti $2000",
      "Insanely overpriced. This card should be 600$ top.",
      "For anyone buying this card.\n\nPlease measure twice and purchase once… it’s the same size as a 3090…",
      "is nvidia making price to performance a linear graph?",
      "Budget PCs about to start at $2,000 🥲",
      "Heard a 4095 will come out after the 4090ti with 5% improve perfomance and $2,700 price tag. Jumping on that one, 4090 is not giving me 200fps in most games at 4k",
      "I just managed to get a brand new Gigabyte RTX 3070 Ti Gaming for 489€ and it's a beast at 1440p. Since the cheapest RTX 4080 in my country is 1500€, I don't think either the RTX 4070 or RTX 4070 Ti can beat the price to performance ratio of my 3070 Ti.",
      "Still can't believe I managed to get a 3080 FE for MSRP from nvidia's website during launch week. Apparently I should have also played the lottery.",
      "5080 for 1600$\n\n5090 for 2200$\n\n\n5070 for 1200$",
      "The $500 consoles will suddenly look more appealing to anyone still rocking a 1060.",
      "The 1070 was as fast as the 980ti for cheaper. let that sink in.",
      "Still expensive cuz it won’t be sold in stores for 800$!!",
      "Not in Europe. 1300€ minimum, guaranteed.",
      "I heard the 4095 is a six slot card that uses two boards with a factory SLI connection.",
      "NV increased price because it could. Not because inflation or TSMC N4 being more expensive.",
      "Likewise, the RTX 3070 was as fast as RTX 2080 Ti and cost half as much.",
      "5070 — $1200 — 1200W",
      "That is such bullshit..."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "4070"
    ],
    "title": "NVIDIA GeForce RTX 4070 SUPER 3DMark leak shows 18% gain over RTX 4070 - VideoCardz.com",
    "selftext": "",
    "comments": [
      "Basically 3090 level of performance",
      "For $600 that’s not terrible. I just wish the 4070 was lower in price.",
      "I know the new look isn’t a big difference, but damn it looks great",
      "Huang needs a new coat. Always needs a new coat.",
      "Not bad for a mid-gen refresh in terms of power if this is true. Really can't wait to see some real world, non-leaked benchmarks for both this and the 4070 Ti Super.",
      "We can muster a lot more graphical fidelity out of computer graphics. \n\nThe 3090 die was 628.4 mm² and 28.3 billion transistors. \n\nThe 4090 die is 608.5 mm² and 76.3 billion transistors. \n\nWe'd be completely foolish to think that isn't a massive leap and there are still even further advancements in silicon lithography from here. The main reason people say this is the end is because it gets much more expensive from here and instead of die sizes staying the same or getting smaller they will start to get bigger. \n\nApple's M3 ~~Ultra~~ Max has 93 billion transistors and rumored to be ~~about 800mm²~~ under 400mm² on the 3nm process.",
      "25% stronger than my overclocked 7800xt for 20% more money. Great deal.",
      "Except in raytracing and dlss is much better than fsr ( at 1440p i'm enabling it in any game  )",
      "4070S is gonna be a tasty card for 1440p gamers for sure.",
      "Pretty good for even 4K, if it had more VRAM (for newest games).\n\n1440p is now mainstream guys, hard diminishing graphic effects with RT or UE5 at 60-70fps avg and OLED 1440p high refresh rate monitors.\n\nI don’t think that we can muster much more graphical fidelity out of computer graphics. Unless we see some reovulationary steps and even then for most current day graphics will be very good enough. \n\nNext step AI NPC and AI crafted worlds",
      "Bro $570. I paid $500. You should definitely return it.",
      "The ti super should have the biggest leap, iirc, from pure stats. I wonder how 4080 and 4080 S compare. That one is a bit lackluster imho. Though the value is definitely much, much better. And I say that as a 4080 owner. 😂",
      "Come on bro that’s just being naive.",
      "Really wish they made one for the 4070ti super. These look so nice.",
      "I'll trade ya for universal healthcare.",
      "I am pondering if I can still return my 4070ti for the super version",
      "Just got a 7900 XT for my girlfriend for $670.\n\nSo, it kinda seems pretty terrible tbh.",
      "Seems to me that this is potentially the point where exponential increases in price are now required to maintain linear gains in performance generation-over-generation",
      "Been waiting for the 4070 to drop below $500 to pull the trigger on a new build, but at this point it makes no sense to not wait an extra couple days for the super.",
      "You don’t notice 10-20 frames? Thats massive."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "4070"
    ],
    "title": "Current 4070 Super Owners, are you happy with your graphics card? ",
    "selftext": "I have a 2080 and I’d like to upgrade. I game on 1440p and I don’t necessarily need the ray tracing/path tracing bells and whistles. I’m aware that NVIDIA is being very stingy with VRAM and that the higher end cards that have 16 GB are very expensive and more scarce.\n\nSo are current 4070 Super owners happy with your cards? Do you see them lasting another 2-3 years? Any feedback would be appreciated. Thanks!\n\nEDIT: Thanks for all of the feedback! I’m glad a great 1440p card is available for under $700 USD",
    "comments": [
      "I have no complaints. Card has surprised the hell out of me with how well it runs 99% of games. Really only ue5 titles make it seem weaker than needed",
      "I actually recently upgraded from a 2080 to a 4070 Super. Very happy with it, one thing I can tell you that the difference in performance is MASSIVE. I practically doubled my FPS in most games in 1440p. So far I've had 0 issues with the VRAM and don't expect to for the foreseeable future, and if it isn't enough in a few years I'll just tone down my settings a little or upgrade it again. Definitely go for it if you have the money, it is worth it",
      "UE 4/5 is just unoptimized garbage to begin with (and imposes TAA smear everywhere). Custom engines are still king when it comes to performance with great visuals.",
      "I just got a 4070 to replace my 1080ti and I am very satisfied. Went with the basic 4070 because I found a new one at my local micro center for 499 on sale and was to good to pass on.",
      "Yes! I upgraded from a 3060 Ti and the performance gains have been huge for 1440p.",
      "4070 super is a fucking beast, love mine. Got it 3 weeks ago",
      "To be fair, not even the 4090 can really get a consistent 4k60 in \"games\" like Stalker 2. Seems like optimization has gone out the window.",
      "That’s awesome! Is a 4070 basically equivalent to a 3080 in terms of performance?",
      "Stalker 2 runs like shit without frame gen on pretty much any GPU for instance (ue5)",
      "I see my 3060 lasting another 8-10 years lolol",
      "Dude I've got a *regular* 4070 and I have zero desire to upgrade. I am not left wanting. 2-3 years *at least*.",
      "A 4070 (without the S), is basically 3080 level at 1080p and 1440p, however at 4K the 3080 pulls slightly ahead.",
      "god i fucking hate UE and taa, they need to stop pushing taa and tsr",
      "Been using FSR 3.1 on my 3080ti along with nvidias DLSS. Getting 130fps at 3440x1440. Fuck nvidia locking the 30 series from frame gen.",
      "Yeah. Moved from a 2070S to 4070S when I got a 1440 UW. Very happy with the upgrade.",
      "Went from 2060S to a 4070 TiS so you can only imagine the results as compared to yours.\n\nWith proper use of DLSS and frame generation, you're getting way more than double the frames.",
      "UE5 is beautiful, and I don't pretend to understand why it runs like shit. It just kind of does. It's almost beautiful how much of a mess it really is",
      "and 4070 super can go much higher than that. I have mine (with an OC) at 3090ti performance, and at only 260W!",
      "I upgraded to a 4070 super like 5-6 months ago and couldn't be happier. I upgraded from a 1070.\n\nAlthough I did upgrade my mobo and cpu also at the same time.",
      "Sits between the 3080 and 3090"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "4070"
    ],
    "title": "Nvidia Nerfs The RTX 4070, Sneaky Downgrades",
    "selftext": "",
    "comments": [
      "Downgrade is still a downgrade. Am glad Steve is calling this out.",
      "They could’ve, but then people would notice the change *and* expect a lower price.",
      "Could have just called it 4070 Lite or maybe 4070 SE.",
      "Call it the RTX 4069 and sell it for 420 USD. The free meme advertising and glowing reviews would make it the most popular graphics card in human history, eclipsing the 8800 GT and GTX 970.",
      "Only Micron make GDDR6X. \n\nNumerous manufacturers make GDDR6. \n\nThere's somewhat of a shortage, and it's needed for higher tier cards.",
      "Downgrading hardware while not changing MSRP or making it readily apparent for the consumer that they are paying the same for less is still bullshit\n\nTerrible PR move.",
      "[GDDR6X shortage.](https://www.tomshardware.com/pc-components/gpus/alleged-gddr6x-shortage-could-briefly-hinder-nvidia-gaming-gpu-supply-starting-august) Only Micron produce them.\n\nI can understand NVIDIA downgrade the RTX 4070 with GDDR6, but they should have lower the price too.",
      "https://preview.redd.it/jpspbb3asrod1.jpeg?width=626&format=pjpg&auto=webp&s=f51a990fa121faeaa7e19b4a93d58746d8d02a50",
      "So what's the reason for this, pure cost cutting or limited supply and 5000 taking preference?",
      "NVIDIA \"Who do you serve?\"\n\n-Uruk- NVIDIA enthusiasts \"NVIDIA!\"",
      "Yes enough of a bother, downgrading a product **post-release** is insane. Even only a 2-5% performance reduction is crazy, why the fuck would anyone go “meh” for anti-consumer practices like that?",
      "Shrinkflation on a GPU.",
      "FFS Nvidia, just call it 4070 v2.",
      "why defend it if they can do better? theyre fuckin billionaires",
      "Their tests are gaming only and don't include productivity benchmarks like OctaneBench which are heavily dependent on memory speeds.",
      "Given they are using regular GDDR6 chips, it should have been much cheaper to begin with, even they could just replace the 4060 Ti with cheaper 4070 and they will sell tons of them.\n\nBasically GTX 1650 and RTX 3060 all over again",
      "That’s not the point, the point is they snuck this downgrade in without saying anything",
      "More like v0.5",
      "You know... This card would take over for most people if Nvidia has a single brain cell and they LOWERED THE FUCKING PRICE. \n\nWho tf will pay the same for an inferior product??... Lots of people probably but the point stands.",
      "It’s just generating outrage when they’ve downgraded a GPU that they’re targeting at the mid to high end range?? \n\nRidiculous."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "4070"
    ],
    "title": "The narrative of \"RTX 4090 is better value than RTX 4080/4070 Ti\" is false and needs to be fact-checked",
    "selftext": "The 4070 Ti & 4080 are better price/$\nThis isn't even getting into how the 4090 **[has spiked to above $2000.](https://pcpartpicker.com/products/video-card/#c=539&xcx=0&sort=price&page=1)**\n\nGPU | Resolution | Price (US$) | avg FPS | $/FPS\n--|--|--|--|--\n4090 | 4K | 1600 | 159 | 10.06\n4080 | 4K | 1200 | 124 | 9.68\n4070 Ti | 4K | 800 | 99 | **8.08**\n4090 | 1080p | 1600 | 279 | 5.73\n4080 | 1080p | 1200 | 251 | 4.78\n4070 Ti | 1080p | 800 | 221 | **3.62**\n\n\n[source for avg FPS: TechPowerUp review](https://www.techpowerup.com/review/pny-geforce-rtx-4070-ti-oc/33.html) *(25 game average)*\n\nGPU | Resolution | Price (US$) | avg FPS | $/FPS\n--|--|--|--|--\n4090 | 4K | 1600 |  142 | 11.26\n4080 | 4K | 1200 |  109 | 11\n4070 Ti | 4K | 800 |  87 | **9.19**\n4090 | 1080p | 1600 |  235 | 6.81\n4080 | 1080p | 1200 |  215 | 5.58\n4070 Ti | 1080p | 800 |  198 | **4.04**\n\n\n[source for avg FPS: TechSpot review](https://www.techspot.com/review/2601-nvidia-geforce-rtx-4070-ti/) *(16 game average)*\n\n\nGPU | Resolution | Price (US$) | avg FPS | $/FPS\n--|--|--|--|--\n4090 | 4K+RT | 1600 | 79.6 | 20.1\n4080 | 4K+RT | 1200 | 55.07 | 21.8\n4070 Ti | 4K+RT | 800 | 43.1 | **18.56**\n4090 | 4K | 1600 |  253.36 | 6.32\n4080 | 4K | 1200 |  184.28 | 6.51\n4070 Ti | 4K | 800 | 141.74 | **5.64**\n4090 | 1440p| 1600 | 383.67 | 4.17\n4080 | 1440p| 1200 |  326.4 | 3.68\n4070 Ti | 1440p| 800 |   275.4 | **2.9**\n\n[source for avg FPS: GamersNexus review](https://www.youtube.com/watch?v=N-FMPbm5CNM) *(3 games @ 4K+RT, 5 games @ 4K, 3 games @ 1440p)*\n\nYes, the cost of entry is higher than before.  \nYes, you're getting better value from AMD.  \n**No, the 4090 is not better value than the lower class cards.**",
    "comments": [
      "I imagine many that use the term better value really mean better buy. It may not be the better value by purely $/frame but it will/might be the better buy for many other reasons. Your last table showing the 4k +RT performance is an example of this. 4090 averages above 60fps while the 4070ti doesn't even come close and the 4080 is still below 60. Doesn't really matter if the 4070ti has less cost per frame if the framerate isn't even high enough.",
      "why am i even here, im fine with a 3080ti, i don't even play at 4k, im at 1440p 144hz",
      "You should upgrade when your hardware doesn't do what you want it to do, and new hardware will, whether that's the next generation or three generations later.",
      "The 4090 is the fastest card in the world and Nvidia rightly charged a premium. The fact that cards lower in the stack are even comparable in perf/$ to a halo product is the problem.",
      "If you do it by Tflops, it costs $19.35 per tflop for the 4090, $19.95 for the 4070 Ti, and $24.62 for the 4080. Tflops isn't the whole picture, no measurement is. But given the other benefits of the 4090, like vastly higher bandwidth on the VRAM, I think it's the most compelling product. Also if you go by shader cores, the RTX 4090 is .073 per core compared to .104 on the 4070. The 4080 is .123. Not to mention more Tensor, RT cores, etc on the 4090 which scale even better with price.",
      "You shouldn't upgrade every generation anyway.",
      "This is very true, especially for things like VR, where there is never \"enough\" performance. At least for now.",
      "I had a 2070 with 9900k which I had for 4 years, I finally wanted to jump to high fps 4k gaming since I got a C2 and the 4090 could play just about every game at 120+fps, with some aaa games requiring dlss to get there. \n\nThat wasn’t really possible until now, to max out 4k high fps monitors, (I’ve since added a Neo G7 for my actual monitor) in ultra and high settings, so had a new build for under 3100 with ddr5, 13700, 980 pro ssd, and 4090 and I love it, it’ll keep me through until next generation hdmi and display ports come out for several years \n\nThe value isn’t a good argument because it’s literally the only card available to really max out monitors nowadays and have a high fps RTX experience, and for that is worth it.",
      "Most people would notice a bigger visual improvement going from VA/IPS to OLED than from 1440p to 4k. Then there's obviously people with both. My LG OLED TV makes PS5 games look absolutely stunning.",
      "He got if for 1079 and a couple of hoops to jump, so he stretched his story some.",
      "I prefer refresh over AA, 140fps is soooo much better looking than 100 and below. I was playing portal rtx with dlaa at 90fps, it resets to 1080dlss on restart which goes to 140+ and the difference in feel and movement sharpness is huge.",
      "This is precisely why perf/$ is not a perfect metric. \n\nOn the one hand, yeah, if you get 80-85% performance spending for 10-12% more performance is not linear. But on the other hand, if your personal value is to chase performance or keeping it for 2-3 gens, it is best to maximise what your budget allows, even if the table does not suggest it has the best perf/$. \n\nAlso, we need to stop with \"if you can afford this product at $X you can afford this product B at $Y+200\". No I don't/can't. It does not make me \"stupid\"... It just means I do not want to stretch anything more than $X.",
      ">A lot of users here are on 3070\\3080\\3090 variants.\n\n>In that case, the 4090 is the only realistic upgrade option.\n\nThis was me sitting on a 1080 Ti looking at the 20 series going \"the only card worth upgrading to was a 2080 Ti\" and that cost DOUBLE my Strix 1080 Ti's MSRP *and* it only delivered 35% more performance.\n\nHell even comparing my 1080 Ti to the 30 series, a 3090 got me around 70-100% more performance depending on the game. It took a whopping 5 years, nearly 6, to wait for the 4090 to come out to finally offer a truly worthy upgrade path that delivers a consistent 200 to 250% more performance. GPUs have been so freaking pathetic last 4 years it's not even funny.",
      "I dont think many people ever said the 4090 is better value than the 4070 Tie. But from your own numbers it's quite clear MSRP to MSRP the 4090 is comparable or better value than a 4080.  Which is crazy. From my point of view , the whole series sucks ass and is bad value",
      "Still, the gap between the 4090 and 4080 in price/performance is quite small, and in one of the benchmarks (3rd table, 4K no-RT), the 4090 did beat the 4080 in price/performance.  \n\n\nI estimated that a better price for the 4080 would be $1,050, then it would sit between the 4090 and 4070Ti in price/performance, but closer to the 4070Ti instead of being closer to the 4090.",
      "You can definitely tell 4k at 27” and it is much higher quality than 1440p, specifically if you play games with a lot of text, like MMOs or RPGs.",
      "Yeah, 1500€.",
      "As others have said, 4090 demands a premium because it’s literally the fastest. It’s sold on performance, not value.\n\nSlower cards are sold on value, which is very poor this generation.",
      "It is actually the correct method as in most scenarios fps doesn't scale given the 4090 is CPU bottlenecked.\nThat however could change fairly soon as proper next gen games roll out, the 4090 will pull away in all benchmarks.",
      "OP is right. However, if you want to 4K game with RT, only the 4090 will do it above 60fps consistently.\n\nSo essentially its like this:\n\nWant to 4K +RT above 60fps natively, or 144fps with DLSS: 4090\n\nWant to 4K +RT with DLSS: 4080\n\nWant to 4K +RT with DLSS at lower setting, or 1440 and get best value: 4070Ti\n\n&#x200B;\n\nPS: if dont care about 60fps or above, it probably better to get a console, as the value is insanely good compared to PC GPUs."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "4070"
    ],
    "title": "Gigabyte confirms GeForce RTX 4070 with 12GB memory and RTX 4060 featuring 8GB - VideoCardz.com",
    "selftext": "",
    "comments": [
      "Sooo the 4070 is effectively a 3080 12gb with a lower memory bandwidth",
      "And then Nvidia will point at the 3080 12 gigs stupid msrp and compare it to the 4070 and be like \"look how good this card is\" ignoring the 699 3080 10 gig card.\n\nThe 4070 better blow the 3080 10 gig out of the water but I don't think it will.\n\nAnyone else remember the days when 70 series usually matched the previous gen 80Ti flagships for way less money?",
      "Just makes the 3060ti more of a screaming value",
      "Such a joke, and I am sure the price would be also ridiculous.",
      "Nvidia is 100% losing business because of their SHIT vram. I game at 4k. I DEFINITELY would have bought a 4070ti with 16gb vram. 12 GB though? I'm now the proud owner of a 7900 xt and sitting at a cool 20GB and never have to even look at vram consumption.\n\nPaying 800$ for a card and worrying about running out of vram is an ABSOLUTE JOKE. The incompetency and greed is kind of infuriating.",
      "And ppl would still buy it. That's why Nvidia keeps doing it",
      "4060 >= 3070 >= 2080 >= 1080 TI.\n\n1080 TI had 11GB of VRAM. 4060 has 8GB.\n\nWhat.",
      "Then you realise 4060 has less VRAM than 3060",
      "Which is exactly what Nvidia wants as they still have a shelves full of them.\n\nWelcome to 2023 where the best deal is to buy 2,5 year old mid range card for 400$...",
      "Is there actually a reason the amount of vram has hardly gone up the past 7 years? It's so hard to justify their current prices with such low amounts.",
      "That's part of the joke, I say \"remember the days\" like it wasn't fucking 2 years ago lol",
      "Market segmentation. \n\nThey don't want people have access to lower cost cards that have over 10GB of VRAM.\n\nIt makes them very good for video production, academic deep learning uses and similar.\n\nThey could get away with it before because games would work but now they really don't so I think 4060 is going to be destroyed by reviews.",
      "They want the people that need VRAM to buy their pro cards",
      "Only on the Nvidia side of things. But then, Nvidia has always been holding back on VRAM compared to AMD.",
      "The 4070 has good specs but I’m still not going to pay $800 for a 70 series card. No way",
      "6700xt is ultra screaming value.",
      "I luv my 3060ti",
      "good choice really. Seeing how new games are trending, most of the Ada line up wiill have problems very soon. It's absurd that nvidia want $1200 for 16GB of VRAM.\n\nThey advertise these cards on the back of ray tracing and DLSS3, both of which take additional VRAM. 12GB should have been the minimum for this generation.\n\nYou pay that much, you should not worry about VRAM.",
      "if you want to play diablo 4, re4, hogwarts legacy, dead space, forspoken and probably more and more releases this year, do not buy a 8GB card.\n\nWhile they run, they won't run well and the hit to texture quality is the last thing you want to deal with, especially for a new purchase/upgrade it's plain unacceptable.\n\nOn your old card, it's reasonable to turn things down now after years of use but a brand new card that probably going cost around $500 and out of the gate has to lower texture quality and it's a 4GB regression from its predecessor no less, makes no sense. You are just throwing money away. \n\nI really like to see how this 4060 compares with 6700XT for example. That's like $350 right now. yeah AMD driver this and that, it's still going to be much better way to spend your money for the budget conscious.",
      "If you've got a GTX 1070 what are these people going to upgrade to? We have 2 manufactures and both are greedy, RTX 4080 is £1150 and the 7900 XTX is £1050, people have to buy one or the other.\n\nI waited for a whole year until I could get a FE 3080 for £649, even with patience now I could never get a 4080 for anywhere near that, nor a 7900 XT/XTX."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "4070ti"
    ],
    "title": "NVIDIA GeForce RTX 4070Ti SUPER is 8% faster on average than RTX 4070Ti in 3DMark tests - VideoCardz.com",
    "selftext": "",
    "comments": [
      "Welp, the most promising spec is the bump from 12 to 16GB GDDR6X. That helps a lot at 4K.",
      "Nvidia just making people comfortable with $1k cards with all these shenanigans",
      "The 4070ti super is what the 4070ti should have been all along if they just hadn’t gimped it’s Vram down to 12gb",
      "Just skip two generations.\n\nPointless and wasteful to upgrade every year.",
      "Not sure about gaming but when rendering large 3D scenes on 8GB and 12GB, there is a very noticeable difference. Renders are way ~~faster~~ stable on 12 GB cards.",
      "So the 4080 Super is gonna be even more attractive if this is the case.",
      "![gif](giphy|10JhviFuU2gWD6)",
      "There’s no such thing as a future proofed GPU. The 3090 TI released for 2000 dollars in 2022 and in 2023 it had a similar performance across 4k benchmarks by a 850 dollar GPU with the 4070TI. Whatever you buy now, including the 4090, is not going to compare in performance to the 5000 series. The 4080 Super for 1000 dollars in 2024 is going to feel like a bad deal in 2025. It happened with the 30 series and the 40 series now.\n\nThat argument really grinds my gears for some reason",
      "I do texture work and honestly the 3060 12gb is such a lifesaver budget option. Now I want to upgrade but throwing so much money at something to have the same vram is kinda unreasonable - vram bump is literally the only reason I'm holding to get a 4070ti super instead of any other 4070. The 4060ti 16gb is in many ways barely an upgrade from the 3060 to be worth so much money, and the 4080 is just out of my absolute budget limit. If I didn't read so many people having issues with AMD cards and substance painter and thr Adobe 3d suite in general I'd have gotten a 7900xtx.\nI guess I could get a 3090 too, but then it becomes an issue on the gaming part of my use case, throwing so much money at something to not get the latest tech is also hard to justify. Jfc how incredibly annoying nvidia's lineup is and has been this whole generation",
      "I was hoping for similar gains like the  4070 super has over 4070",
      "I mean…..you already have a 4070ti. You were not even close to the target market for the Supers.",
      ">The 4080 is what the 4070\n\nlol no. Nothing on the 4080 makes it a 70 non ti series card. People here are really delusional if these are the expectations",
      "yeah no shit sherlock.",
      "There is no point for current 4070 Ti owners to upgrade to this anyway, the minimum is pretty much an RTX 5070 or above.",
      "You’re right. I’m looking at this as NVIDIA trying out “make good” with buyers. From specs, to VRAM, to the 4080 basically just getting a more realistic price… these should have been the specs and pricing from day one.\n\nBetter late than never I suppose. Still pricey as hell to be a PC gamer these days.",
      "You can keep that card until the 7000 series.",
      "Thing is the 4080 was always horribly priced for what it had. We'll have to see how the 4080 Super compares in benchmarks.",
      "It helps around 8% according to the 2160p benchmark.",
      "Yeah I'm confused by people with high-end 3000 cards or even 4000 cards going \"ehhhh it's not worth the upgrade\" when it's not meant to be. I'm sitting here with a 6gb 2060 though getting excited about these Supers",
      "I still believe the 3070 being 8gb was the most scummy move nvidia has made in recent years. 1070 was 8gb and that card came out literally 4 years prior to 30 series.\n\nNvidia was crafty about it. Can't have a mid range card that performs well for too long, so they hamstrung the vram to \"encourage\" upgrading sooner. There is literally no other feasible reason to keep the vram so low on that card. Even amd was offering 12gb on similar cards at a cheaper price point."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "4070ti"
    ],
    "title": "The 4070ti super is a beast",
    "selftext": "",
    "comments": [
      "I feel like the 4070 ti super is better deal than 4080s",
      "It is, has the same vram and chip, cooler.  \n\nSome cores are locked yes, but is it worth paying $200 more for just a tad more performance? I don't think so.",
      "Idk getting 20-30 fps more in demanding games is a pretty big difference. Its definetely a noticeable difference in smoothness if you're running 144hz+ monitors. And in lesser demanding games, you could be getting 50+ fps boosts for 240hz consistent gameplay. \n\nObviously still not worth the $200 more for some people, the 70ti super is probably better value but i think saying \"tad more\" is pretty relative. And I see it so much on not only this subreddit but also others because people get lost in the percentages, when imo the raw fps gains are more intuitive to understand and give direct information about the differences.",
      "Yeah, I literally paid $1000 more for like 30 FPS. Going from a 4080 to a 4090. \n\nAt 4K, it sure is worth it.",
      "Nice! I got the same card and it has been great thus far. Super quiet and aesthetically pleasing. \n\nhttps://preview.redd.it/kvkn53nxu6gc1.jpeg?width=2838&format=pjpg&auto=webp&s=fa93b9cdd54dec9cea49b42219bcb0fe3b67a76b",
      "Is my 4070 Ti still allowed in the club even if its not Super :/\n\nCongrats guys, some very nice looking builds in here, and having owned this card for the last year it's been awesome, you guys are going to love yours. 16GB VRAM would be very welcomed and thats what you guys got, for the same monies. Big W.\n\nhttps://preview.redd.it/vegt2gmtl7gc1.jpeg?width=4284&format=pjpg&auto=webp&s=c0052946876589afdb61a6cffa66a5b9fe909db5",
      "4070 TI Super here too, love it!\n\nhttps://preview.redd.it/47td807z87gc1.jpeg?width=4032&format=pjpg&auto=webp&s=820fa08a1abec60a1a68afde1a50ed7938f6e8e1",
      "Well, those Aero Gigabyte cards look awesome!",
      "I just ordered the Asus TUF Gaming OC version. Very excited",
      "Anything past the 4070 Super feels like diminishing returns for most applications, but that 16 GB of VRAM is sweet. I say the 4070S is the way to go if you upgrade often, but the Ti Super will have a bit longer lifespan. Neither are bad at all. I heard someone somewhere say you want the VRAM to “age gracefully with the card” and I think the 4070 Ti Super will do just that.",
      "It's funny how much hate this card got at launch and now that everyone sees the 4080S is basically a 4080 (which shouldn't surprise anyone given the specs) everyone is looking more favorably at the 4070TiS.",
      "Where you seeing a 4080 gets 30 more FPS over a 4070ti super?",
      "I just went from an i5-8600 and a 3060ti to an i7-14700k and the 4070ti Super and fuck me it’s a low-key monster combo. \n\nOnly issue I’m having is Ark survival Ascended - I’ve maxed everything to ultra and I get a capped 60fps - I’ve unchecked cap fps in the settings but my GPU seems to not want to go above it. It doesn’t go below it either. Just sits there happily at 60fps. Anyone know why?",
      "Even the \"regular\" 4070ti is a pretty beastly card, Man.  \n\n\nI took advantage of this situation and got a pre-built with a non-super 4070ti and an i9-13900k for $1500 the other day!  Sure, it's not as powerful as the 4070tiS, but that kind of performance for less than $2k is *amazing.*",
      "I guess we all have preferences 🤷🏻‍♂️",
      "Agree 100%. That’s why I jumped on the 4070ti super when it was released instead of waiting on the 4080s",
      ">but is it worth paying $200 more for just a tad more performance? I don't think so.\n\nFor something I can potentially use for 5+ years, yes. $200 is not much if you're already spending $800.",
      "I find this kind of autistic minmaxing \"dollar per FPS\" optimization lacking. It makes no sense unless you're running a shop and selling cards.\n\nOkay, you pay 25% more for 15% more performance. But what you should be asking is, if you're already buying a card for the price of 4070 Ti Super, is it worth paying a few more hundred for a 4080 Super, with regards to how often you upgrade and what is your budget.\n\nBecause if you upgrade your card like once per 5 years (such as me), that is a negligible difference in cost. It's already overpriced, all of it. So if you're buying, might as well get the more expensive one.\n\n(Another example to explain what I mean: If it was $1 vs $2, the difference would be +100%, but you would still go for the $2 version without question.)",
      "Love that aero card, it’s sexy",
      "Says on user benchmark 4080super is about 20% faster then 4070ti super so to me personally I can justify 200 dollars for 20%."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "4070"
    ],
    "title": "ASUS GeForce RTX 4070 SUPER DUAL with 12GB memory has been leaked - VideoCardz.com",
    "selftext": "",
    "comments": [
      "I don't understand why 4080S is not 20Gb card, 4070tiS will eat all the market share of 4080",
      "Theres no way nvidia will increase prices right? Surely since amd fsr 3 mod is working quite well now, incentive to upgrade is miniscule.",
      "That’s probably the point, 4070tiS looks much better comparatively and they silently kill off one of the worst selling cards in the lineup.",
      "Unless they go absolutely mental with the pricing or something horrible happens on the way, the 4070 ti S seems to be a potential winner for this gen, if you can't afford, or aren't willing to pay for, the 4090.   \n\n\nShould be good enough for 4k unless you go apeshit with RT too, no?",
      "They really wanna push that shit 16 pin connector huh?",
      "I’m going to skip 40 series entirely. Was gonna get one because of frame gen but then amd came into clutch and made fsr frame gen open source and it has already been modded to work with dlss in games like cyberpunk and Alan wake",
      "Yeah that fsr hack breathed new life in into my 3070. Totally content to wait out for the 50xx series.",
      "4080S is a pretty underwhelming bump to 4080 yea. But 20GB memory would require an AD102 and I wouldn't be surprised if Nvidia can get a better profit out of the AD102's in other products.",
      "Can't justify upgrading my 3060ti with these prices, 50 it is.",
      "The 4070 Super was never rumored to be 16gb. How could they justify using AD103 on the 4070 Super, but not the 4070ti that's above it?\n\nLet's be realistic guys, it was always going to be 12gb. And that's fine, there isn't a single game out there that it won't play well. 12gb is enough until next gen consoles come out, at which point you'd probably be looking for an upgrade anyway. The whole VRAM debate is ridiculously overblown and really only applies to 8-10gb cards.",
      "4080S uses the full AD103 which only has a max bus width of 256bit, so a 16gb maximum. If they wanted a 20gb variant then they would need to use a further cut down AD102 than the 4090 with a 320-bit bus, which would have been a more worthwhile upgrade as a 4080S since it would likely have around 12k cores, but the 4080S should compete directly against the 7900XTX so it keeps the 5080 bar lower.",
      "I’m playing through a heavily modded Cyberpunk run with PT on due to this mod, and it’s insane man.  AMD and modders increased the longevity of the RTX 30 series and gave a metaphorical middle finger to Nvidia. \n\nBeing able to use DLSS with a software based frame generator while being able to use other Nvidia feature like RR and Reflex is huge.",
      "Bus width and chip tier are tied to each other in this case though.\n\nAD103 on the 4080 only has a 256-bit memory bus though, so 20 GB requires GTX 970 VRAM shenanigans, where the last 4 GB run slower than the other 16GB of VRAM, due to effectively being on a 64-bit Bus.\n\nThe other option requires an AD102 chip, in which parts of the memory bus get deactivated/fused of for a 320-bit  memory bus and 20GB of VRAM. The AD102 gets used on a lot on the Nvidia ML products though, so it's less desirable for NVidia to use it for a 4080S.",
      "To acompany the Github link you got:\n\nBasically it let's you replace DLSS3 Frame Generation with FSR3 Frame Generation and use it in GPUs older than the 4000 Series, as well as pair it with DLSS Upscaling, which is something you wouldn't be able to do normally.\n\nFor more information search for Daniel Owen in Youtube, he has been making lots of neat videos testing FSR3 Frame Generation lately, both official releases and mods.",
      "Me who's still using 1080ti decade later.\n\nGuess if this dies supers seems like my only option. \n\nI only upgrade when I get double the performance for the  same launch price not sure what my options are anymore?",
      "Even if you go apeshit with RT at 4k it will probably be fine with dlss and frame generation",
      "https://github.com/Nukem9/dlssg-to-fsr3",
      "What is this? And would it help my 3060 ti get significant t improvement?",
      "> The 4070ti.\n\nToo expensive for only having 12gb of vram.",
      "For so long as console games are ported to PC from the baseline of 16gb unified mem consoles, this shall be largely true. (we target 10-12gb vram usage on console, depending on the complexity of the overworld)\n\nYou might have to trim down settings *slightly* (lets be real though, ultra preset isn't meant for these mid-ranged cards), and a 4K frame-gen buffer may be too much, but for 1440p, yes, 12GB VRAM is more than enough until the next console gen hits with 32gb unified in the late decade."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "4070"
    ],
    "title": "4070 ti super 🙃",
    "selftext": "What are y’all’s opinions on the ti super ? ",
    "comments": [
      "All the haters in the comments. If you would have got the 4080 everyone would have clowned you for the price/performance. Do you bro. It’s a awesome build",
      "The 4070 TI Super is a good card. Roughly 10 to 15 percent less performance than the 4080 Super, but at $200 less. I have one myself.",
      "Thank you, yea it always surprises me how upset one can get over another persons build lol.",
      "Yooo love the HIM symbol!",
      "Dam OP you are getting ripped in here. It's like all the cunts came out to play at once. Sweet build in either case.",
      "hey chatters, i have a 4080 super, rip into me!\n\nseriously, everyone here giving you shit prolly has a fucken 2070  😭",
      "I got the ram for free",
      "The best 40 series gpu imo. Have one myself and i am more than satisfied.",
      "this whole comment section is a redditmoment.",
      "High performance RGB ram is usually priced negligibly differently than non-RGB high performance RAM.",
      "You ever think maybe op values aesthetics a bit more than raw performance? It’s not about min maxing price/performance to the tee for everyone.",
      "Jealousy my friend",
      "It’s 80 $ 32gb ram though either way lol. I play my games , have discord open ,  music, and have no problems I’m not building a rocket ship so I think it’s fine",
      "did not expect to ever see that again lol, throwback to like 2005 for me.",
      "What is bro waffling about",
      "Bro get off OP's pocket dude. It's his money to spend it like he wants. You tripping over what someoene's else like and buy.",
      "I also have a 4070 Ti Super, a Gigabyte Aero OC model. A beautiful card that looks and runs like a champ (even in my NZXT H510i). Stays quiet and never goes above 62 degrees during gaming. \n\nhttps://preview.redd.it/vfb41u3n9m1d1.jpeg?width=3000&format=pjpg&auto=webp&s=ed1e97529f2ced80423508333b7e9f6ec61b5774",
      "Exactly , didn’t care to pay that much more for a small increase , and didn’t care to get it just to say i have a 4080. If i wanted to I honestly could just call mine a 4080 jr lol",
      "No issue",
      "I've never seen a neck beard this thick before!"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "4070ti"
    ],
    "title": "NVIDIA reportedly stops mass production of RTX 4070Ti/4080 GPUs, now focusing on SUPER variants",
    "selftext": "",
    "comments": [
      "So does the 4070ti get cheaper now because it has a successor ~~predecessor~~ or does it get more expensive because ther are fewer available? \n\nAsking as someone who still couldnt justify a 4070ti for himself",
      "Nah they'll keep them at same prices and sell them extremely slowly to people who don't know better.\n\nJust look at older gpus and cpus that many retailers still have around.\n\nOr older motherboards... :/",
      "Honestly these mid of life refreshes like 2000 supers are in my opinion such a scam. You have to know that in ~1 year or less they'll drop the 5000 series. People with 3000 series, please don't give your money to this super refreshes, save it for 5000 gen. It will be much worth it. Just my 0.2 cents.",
      "I'm not sure where this idea Nvidia needs to drop prices comes from. The PC enthusiast market has proven time and time again they'll spend absurd amounts on the latest and greatest. There's nothing to suggest a better business plan comes from slashing prices on highly demanded products.",
      "What about RTX 4070? Isn't the 4070 Super also supposed to be released soon?\n\nI hope this doesn't mean the 4070 Super will be so expensive that they'll keep producing the 599€/$ GPU because none of the new cards will be competing at that price....",
      "Exactly what happened when the 2070 super launched. Old 2070 cards remained at the same launch price on the shelf. There were a number of cases I recall where due to promos the super was actually cheaper. I had a number of friends reach out to ask why that was, assuming there was something better about the older card or that the refresh was in someway inferior based on the pricing alone.",
      "Enjoy your card man, there’s always something new around the corner",
      "I just bought a 4070ti",
      "I mean the new 3080 are still expensive as fuck even tho the 4070/4080came out like a year ago so dont get your hopes up",
      "I’m holding out. The 3070ti only having 8gb of vram pisses me off and I didn’t have much choice during lockdowns. I also overpaid for it too. I’ll be going for 5080 or 5090 next year depending on reviews.",
      "I'm old enough to remember this being what PC enthusiasts mocked Apple enthusiasts about. I remember friends buying absurdly overpriced Apple monitors, laptops, desktops and I'd just keep building PC's with my friends for dirt cheap. Kinda wild seeing PC enthusiasts sound exactly like the Apple fans did back then. \"I expect (insert wildly unnecessary attribute) and I pay for that feature\" as if its a brag or something to tout.",
      "Same.\n\n![gif](giphy|26ufcVAp3AiJJsrIs)",
      "I mean, a year is a long time. You know how much gaming you can squeeze out in that time?",
      "I’m on 3080 10gb and playing Phantom Liberty pissed me off. Vram gets full, then stutters.",
      "It's a trap.\n\nNext gen they are probably going to hardware lock you out of a feature.",
      "That won't happen, the older models stay expensive or out of stock.",
      "Still holding out until the 50 series launches. By then, there will be enough games available to justify an upgrade for people still on Turing and below.",
      "I don't agree because the enthusiasts and top level cards are not the point here. The most common card in the steam hardware survey is the 3060. Your average pc gamer isn't buying the mid tier 4070 because it's priced for enthusiasts. The 4XXX cards are too expensive across the board, not just the high end. The high end sure they can keep charging and the enthusiasts will pay but they are a small demographic. The vast majority never moved off the 3XXX series cards and in fact many gamers are still on the 1XXX series.\n\nNvidia don't want to destroy the PC gaming market and they will if PC gaming continues to be so drastically more expensive than consoles. Enthusiasts alone can't keep the PC graphics card market alive.",
      "And here I really thought the normal variants would get a bit cheaper. Silly me.",
      "fuck me i was planning on doing a 4080 build on cyber monday. Is there any information on when the release window is for the 4080 super?"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "4070"
    ],
    "title": "Microcenter is running an extra 10% off on open box. picked up a 4070 super for $494 before tax.",
    "selftext": "",
    "comments": [
      "This is the reason I wish I had a micro Center near me",
      "https://i.redd.it/kji4lq8il6qd1.gif\n\nNah, I'm legit happy for you. Good deal!",
      "I lived in the US for 7 years before having a MicroCenter closer than 6hrs away from me.\n\nNow I have one 25 minutes away. \n\nIt is as good as it sounds haha\n\nNow if only I could get 1000/1000 Fiber Internet at home, I’d be set….",
      "Jealous European here. In my country a new Asus Dual RTX 4070 Super OC edition cost €625 (VAT included). The TUF version is €709...",
      "I would have to get on a plane just to go to one lol",
      "The cheapest I can see a 4070 super on the uk is about $700 but on the other hand I have unlimited synchronous gigabit for $40 a month 🤷🏼‍♂️",
      "I got my 4070 there for $350 on tax free weekend lol",
      "i hope 1440p becomes more affordable by the time i build my own rig because at this point I'll go from 1080p laptop to 1080p PC",
      "thats even better than OP's deal damnnn",
      "I'd have to get a Visa first.",
      "And public healthcare.",
      "Not all items are shippable from microcenter. I know a lot of the good 7800x3d bundles were in store only.",
      "Have fun congrats",
      "I picked up my 3080 ti back in '22 for $760 same way. Brand new open box return. My assumption was it didn't fit their case lol.",
      "I paid $629 + tax for the same card in white at launch. I'm also pretend happy for him/her as well.",
      "The real deal is always in the comments. Congrats!",
      "Those prices are still fucked.",
      "if you want the most bang for your buck buy used parts. And if that is scary or diffucoult, id reccomend to at least try and buy a used graphics card. You can find some great deals on used graphics cards, good ones to look for in my excpreience are 1080 ti, 3070 and 3080 depending on your budget",
      "That’s why I love MC I’ve gotten a 4080 strix for $899 and a 4080 super Strix for $1,100 opened box the super still had its plastic on and everything",
      "Europe prices are fked up man :(\n\nI already have a pretty good GPU but I die inside every time I hear a youtuber talking about the price of a component. I'm always like, \"yeah I would definitely have to pay 100-200 € more than what he says\" lol. or not lol actually.\n\nI'm usually kinda glad that I'm not in the US, except when I have to build a PC."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "4070"
    ],
    "title": "Small upgrade (1070 to 4070 ti super)",
    "selftext": "Managed to get a Gainward 4070 ti super from ldcl for a great price. Thanks to the 1070 for all this years of service. It was still trucking along and it's still a great gpu for light gaming ",
    "comments": [
      "https://preview.redd.it/g84gcs2mgume1.jpeg?width=3024&format=pjpg&auto=webp&s=1e67286dda0404130a48fe239d07477b75478abc\n\n4070 tiS club !!",
      "Congrats on the 5070 Super",
      "Small?",
      "I had a ryzen 1700 until a year ago, i upgraded last summer in anticipation of a GPU upgrade. I wanted to wait for 5000 series reviews but they were all underwhelming so i started looking for used 4xxx cards\n\nI play in 4k so in most cases the CPU is chilling while the 70ti is fighting for its life",
      "611€\n\nLast weekend LDCL offered a 20% discount on their open box items\n\nThe GPU arrived in a 5070ti box and without any cable or accessory, but who cares it costed less than a 5070 :D",
      "5700X3D",
      "It's quite better than a 5070. It's just 10% slower than the 5070Ti",
      "What's your CPU?",
      "4070tiS is faster than 5070 + 4gb extra Vram.",
      "Knowing our luck, that thing will still have only 12 gb of vram",
      "I expected you to say something like 8700k considering the age of your previous GPU. Lol\n\nYou're actually good that cpu is goat just know you're bottlenecked in a few multiplayer games",
      "No, no…and no :), 5700x3d won’t even bottleneck a 4090 ;)",
      "4070 Ti Super would be the last legendary GPU.",
      "Yeah it was an amazing deal, if you are looking for a new GPU i suggest to check ldcl daily, they have good deals on open box or returned items",
      "Out of interest how much did you pay? Those are upwards of €1000 here",
      "https://preview.redd.it/v9amdmnxsume1.jpeg?width=3024&format=pjpg&auto=webp&s=739f29ffc2a395e984300d42d360a09de2346c99",
      "If you can find under 750 yes. It sits between the 4070 ti and the 5070 ti",
      "big upgrade 16gb vram enjoy!!",
      "Thermalright Phantom Spirit 120\n\nAmazing cooler, it beats many 240mm AIO and keeps up with some 360mm ones\n\nIt's almost overkill for the 5700x3d, it sits at 76°C during Cinebench testing",
      "That's a nice looking card, enjoy!"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "4070"
    ],
    "title": "Resellers Struggle to Unload GeForce RTX 4070 Ti at Inflated Prices",
    "selftext": "",
    "comments": [
      "The scalper is the lowest form of life.",
      "it just came out today…",
      "Drop that price $400 and Ill pick one up",
      "You’ve got to be a moron to try and scalp these cards",
      "Yes, and you can go online and order one MSRP right now. So Scalpers that woke up early this morning to buy as many cards as they could are about to be returning said cards back to retailers. Scalping only works when something sells out quickly.",
      "It boggles the mind that scalpers are still trying... \n\n1) Crypto is no longer a factor.  \n\n2) The chip shortage has ended.  \n\n3) The 4080 already couldn't be scalped, to the point where they returned cards en masse and retailers had to restrict returns.  \n\nIt would've only taken a few minutes of research to realize this. It just goes to show the type of idiots who do this. They just can't take a hint that scalping GPUs is done with this generation of cards.",
      "Indeed, the sales and marketing people at Nvidia have pre-scalped the cards.",
      "I love how much of a failure this launch is.   \n\n\nOne store had a stock of about 15 cards of each model and at the end of the day they WERE NOT SOLD OUT.   \n\n\nNvidia take the freaking hint.",
      "$400 : Good Guy Nvidia.  \n$500 : Ok. That's fair.  \n$600 : I feel a bit guilty buying this. But, I'll bite.  \n$700 : Woah there! Don't push it.   \n$800 : Nvidia... you've completely lost touch with reality...",
      "I had a 4070 TI sitting in my cart on Newegg and kept going back and forth if I was gunna order it but it was $985 and some change after taxes and talked myself out of it.\n\nLater today I had FaceBook memory pop up today of my first gaming rig I ever built :\nAMD Phenom II 965\n2x AMD Radeon 6950\n16GB DDR3 Ram\n1000W Xion PSU\n500GB HDD\nAXP600 Gaming Case\n\nKept the receipt in the photo and the total for all that was $1011 and some change.",
      "Just ask why would I pay that when I can get a 4080 FE at MSRP any time at Best Buy? Scalpers really are idiots this wave. And happy to watch them burn.",
      "4070 Ti Strix in Europe is 1200 Euro (1200 USD). Clown world shit.",
      "400 is a pipe dream IMO. 500 is a good price, but fuck it, I would accept it at 599$ as well. 799 is still too much. This thing was originally meant to be sold for 899. The GPU market right now is a clown fiesta.",
      "Someone on FaceSpace Marketplace was trying to scalp 4080s back when that launched with a thud and I actually messaged him saying tough break for trying to scalp a card that no one wants. Over the following week I saw him slashing the price but with the $72+ in sales tax on top of card cost, he must've finally realized returning them was the only way to recoup.",
      "LMAO GET FUCKED",
      "This is about what one would expect any 70 series cart to cost IMO.",
      "What you have to understand is that they're not tech enthusiasts. Most of them probably have not the slightest clue of how to build a PC. They don't know and don't care what DLSS3 is for because they'll never use it. They're only seeking for the opportunity to make a profit. Also, the 4090 has been highly profitable for scalpers in the USA. So, it's just natural they'll try to pull it off with every other card in the series.",
      "Back in the Radeon 6000 series days (we're back with the same numbering again lol), $1000 could get you a good full system. I built one for around $1000 too. $1200-$1400 was getting you VERY good. \n\nIt's got to be rough for kids and teens these days. They won't be getting into the hobby the same. Work for a full summer and maybe you can afford a top of the line GPU. Honestly just getting an Xbox or PS5 and saying screw PCs makes a lot more sense.",
      "The venn diagram of scalpers and nft bros is a circle i imagine.",
      ">This isn't a flagship product and it's a Thursday. Not really the sort of GPU people are going to rush out and buy, but the GPU that people who are making a build tomorrow will consider using.\n\nYou make it sound like it's a sporting event or limited run units; you don't have to go to a brick n mortar unless you just want to. \n\nMost of 30 Series at launch and 4090 sold out almost instantly on launch day. You can say it was bots, scalpers, the shortage or whoever but the demand was there and stayed strong even weeks after restock and people who were lucky enough to get a card did in fact grab one.\n\n4070 Ti is just really awful value. The scalpers know it too."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "4070"
    ],
    "title": "4070 Super Review for 1440p Gamers",
    "selftext": "I play on 1440p/144hz. After spending sn eternity debating on a 4070 super or 4080 super, here are my thoughts. I budgeted $1100 for the 4080 super but got tired of waiting and grabbed a 4070S Founders Edition at Best Buy. I could always return it if the results were sub par. Here’s what I’ve learned:\n\n- this card has “maxed”every game I’ve tried so far at a near constant 144 fps, even cyberpunk with a few tweaks. With DLSS quality and a mixture of ultra/high. With RT it’s around 115-120 fps. Other new titles are at ultra maxed with DLSS. Most games I’ve tried natively are running well at around 144 with all the high or ultra graphics settings. \n\n- It’s incredibly quiet, esthetic, small, and very very cool. It doesn’t get over 57 Celsius under load for me (I have noctua fans all over a large phanteks case for reference). \n\n- anything above a 4070 super is completely OVERKILL for 1440p IN MY OPINION*. It truly is guys. You do not need a higher card unless you play on 4k high FPS. My pal is running a 3080ti and gets 100 fps on hogwarts 4k, and it’s only utilizing 9GB VRAM.\n\n- the VRAM controversy is incredibly overblown. You will not need more than 12GB 99.9% of the time on 1440p for a looong time. At least a few years, and by then you will get a new card anyway. If the rationale is that a 4080S or 4090 will last longer - I’m sure they will, but at a price premium, and those users will also have to drop settings when newer GPU’s and games come out. I’ve been buying graphics cards for 30 years - just take my word for it.\n\nIn short if you’re on the fence and want to save a lot of hundreds, just try the 4070 super out. The FE is amazingly well built and puts the gigabyte wind force to shame in every category - I’ve owned several of them.\n\nTake the money you saved and trade in later for a 5070/6070 super and you’ll be paying nearly the same cost as one of the really pricy cards now. It’s totally unnecessary at 1440p and this thing will kick ass for a long time. You can always return it as well, but you won’t after trying it. 2c\n\nPC specs for reference: 4070 super, 7800x3d, 64gb ram, b650e Asrock mobo ",
    "comments": [
      "Yeah but if you’re worried about your electric bill you probably shouldn’t buy a 4090 in the first place lol",
      "I went from a 4090 to 4070s at 1440p 240hz and I’m pretty happy with it. My gaming experience hasn’t changed much at all.",
      "You’re still proving my point tho. If you are worried about saving 80€ a year then what are you doing buying a 4090",
      "You're probably right, but DCS and MSFS can put up a pretty big fight. It's hard to max out frames in those games unless you turn down down some settings from ultra.",
      "> this card has maxed every game I’ve tried so far at a near constant 144 fps, even cyberpunk with a few tweaks. \n\nWhat's the tweak here, DLSS ultra performance?",
      "Probably electrical bill",
      "I love when people assume everyone else knows their games acronyms /s",
      "Just me being curious but why downgrade?",
      "Well, 4090 draws 300w ish usually, but lets assume both cards at peak power, a 200w\\~ difference.\n\nIn my country that's 80€ at the end of the year with a 8h daily usage (assuming you play 8 hours a day - ah, how I miss being 16 years old...).\n\nSignificant, not outrageous. Basically running a 4070S instead of a 4090 grants you an extra AAA game at the end of the year.",
      "I like how everyone just ignores the 4070 Ti Super 😂",
      "Now saying it’s overkill it actually being overkill are two different things. Yes it runs games well at 1440. Give it 1 year. Most newer titles and dlc content will cost you 20+fps. I watched games every new season lose 15-20fps at 1440. Which basically means in the very near future you’re going to start losing fps. If they drop a 50series this year you’ll see it by Christmas. \nIf you watch some of the reviews there are titles out right now that are bumping the 12-14gb vram mark. So I’m sorry I’m not going to take your word for it over people whose literal job is reviewing these cards. The best bet was the 4070ti super. It’s going to buy you at least a couple years depending on the types of titles you’ll play.",
      "I don’t play those games, so that is helpful to know. What I do know is that the difference from ultra to high is very negligible - and a huge performance cost. I’m okay turning some settings down from ultra quality to high (keeping others ultra that I do notice) as I really don’t see a difference. Maybe it’s different in those games?",
      ">the VRAM controversy is incredibly overblown. You will not need more than 12GB 99.9% of the time on 1440p for a looong time\n\n&#x200B;\n\nThat's what they said when the 3060ti/3070 8gb came out. Yes you can turn down the graphics, but that's the same argument you can make about using a 1060/2060 and turning down the graphics which implies nobody should need to upgrade when using a 1060/2060. The key issue is the longevity of matching the peak performance of the card with the requirements of current and future games.\n\nI'm not saying you shouldn't buy the 4070S, I'm just pointing out that the justification that there will be stagnant vram requirements for \\[near\\] future games seems misguided.",
      "I might go from a 3080ti to a 4070s.. from 350 watts down to 220 would be real nice in the summers..",
      "Frame gen probably",
      "I think people are obsessed with having max setting at native and using that as a benchmark, when often games top settings provide a performance loss at no visual improvement unless you are inspecting every texture and shadow at 4k or above native. Optomised settings + DLSS + DSR > Max Settings at Native. Better presentation and often performance. It was always my understanding that max settings were designed for hardware not currently on the market on release, or at least since Crysis originally released, hence why the recent Avatar game had to 'hide' its max settings so people wouldn't be disappointed when the game didn't run well at the them. I would understand wanting run native at max fps for competitive online games, but then you would maximise optomisation surely? maybe even running regular dsr with setings as low as possible unless they made spotting enemies harder.",
      "Aren't these two heavily CPU-dependant, though?",
      "Anything above 4070s is total overkill for 1440p? So you're saying you can run Cyberpunk 2077 at MAX settings RT/PT/quality MAX MAX MAX the works? What's fps are you getting?",
      "> anything above a 4070 super is completely OVERKILL for 1440p\n\nUntil you discover DLDSR..",
      "For anything above 1440p for RT you want minimum of 4070Ti Super."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "4070"
    ],
    "title": "NVIDIA GeForce RTX 4080 & RTX 4070 get preliminary 3DMark performance estimates - VideoCardz.com",
    "selftext": "",
    "comments": [
      "Price is what I'm concerned about.",
      "Hmm, this means the 4070 would be as fast as the 3090…",
      "Just like always…the 70 tier will always match the 80Ti tier card (same as 3090) of the previous generation.",
      "The 1080Ti was a beast of a card Nvidia released cuz it got scared of what AMD had up their sleeve. But the 2070/super matched it anyways, so again what I said holds true.\n\nThis is why competition is good. When AMD wasn’t doing well, Intel and Nvidia got lazy and were milking consumers for tiny gains. Now they’re forced to innovate.\n\nAlso I don’t view RT and DLSS 2.0 as scams.",
      "and power consumption. no way im gonna keep a small fusion reactor to be able to run these babies",
      "Except for when it doesn't, like the 2000 series. But that whole set was a scam anyways.",
      ">The RTX 4080, on the other hand would be almost twice as fast as the RTX 3080.\n\nTo put this into perspective, the 8800 GTX was twice as fast as the previous flagship (7900 GTX).  This was the largest performance jump in a single generation I can recall, at least in the last 15 years.\n\nEven the GTX 1080 -- a series famous for its performance -- was only about 70% faster than the 980.",
      "So assuming 4070 > 3080, and 3080 10gb FTW = $780-ish, what are we estimating for prices on the 4070?\n\nI'm debating getting a 3080 now, or 4060/4070 later. Obviously availability is a risk if I wait. \n\nReplacing a 1080ti.\n\nEdit:  Playing at 1440p, fwiw",
      "from the link  \n4090 19k  \n4080 15k  \n4070 10k  \n\nLooks like a good jump in performance.",
      "AMD is a far better CPU than GPU maker",
      "C R Y P T O\n\n\nStrange how just as crypto crashed card supply went back to normal almost overnight.\n\nMust be those out of work gamers buying two dozen 3080s for their rigs.",
      "we all got burned by an AMD product  \n\nDon't be hard on yourself.",
      "Watch everyone freak out about their 3000 series being worth like 100 bucks because the 4000 series spanks their cards only for another global catastrophy to occur and mark up the prices of everything like crazy again",
      "Love what you got!\n\n&#x200B;\n\nDon't give in to the cycle!",
      "The smart thing is to wait and see  \nThe nice thing is to buy and play with ray tracing ON, today.",
      "For comparison, a stock RTX 3090Ti scores around 11k and a stock RTX 3090 scores around 10k",
      "Ray tracing and DLSS is not a scam, you silly goose.",
      "The 8800 GTX was a beast of a card",
      "I made the massive mistake of buying a disgustingly overpriced AMD 6900XT at Microcenter during peak pricing because I could not find an Nvidia card anywhere.  Probably one of my biggest mistakes I've ever made in PC Building since I built my first PC and got incompatible RAM.  This thing fucking sucks.   It's great when it works but I've never had so many issues.\n\nCan't wait to upgrade.",
      "That and supply shortage. Supply chain oof. And people making money off gpus"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "4070"
    ],
    "title": "Introducing GeForce RTX 4070: NVIDIA Ada Lovelace & DLSS 3, Starting At $599",
    "selftext": "",
    "comments": [
      "So $599 for 3080 /6800XT performance? When you can find a used 3080 for $450 and a brand NEW 6800XT for around $480. \n\nOr spend $30 more and get a 6950XT for $629. \n\nThis card is in a really weird position",
      "[LTT's review](https://youtu.be/nkh9VGCY8as) has the 4070 trading blows with the 3080 (minus DLSS3 FG) at $100 less MSRP & at 100w less under load.\n\n*However.*\n\nThis compared to the 3070 is 20% faster, *but crucially* also 20% more expensive. 30-series also has the advantage of a bustling used market reigning in prices on last-gen to the point where you can get 3080s for less than the 3070 MSRP — about $100-150 cheaper than the 4070 — which makes this a tougher sell for those not in need of DLSS3 FG and whom aren't *as* concerned about power draw; the 3080 can be easily be undervolted, but that's not plug-and-play.",
      "...so for $600 I get what I could've gotten 2 years ago for $700? Wow, thanks.",
      "Excuse me, is that $599 for a 70 series card, it is still April after all.",
      "Tick-tock. Nothing new.\n\nSeries 1000 - Buy\n\nSeries 2000 - Skip\n\nSeries 3000 - Buy\n\nSeries 4000 - Skip\n\nLet's see if prices \"magically\" come down for next gen. Remember the price shock of 1000 -> 2000 series? Feels the same.",
      "Don't buy this card or generation, give it a skip.",
      "To think that this would of been the 4070ti if NVIDIA hadn't changed the 4080 12gb down to the 4070ti. \n\nImagine 4070ti performing equal if not worse than a 3080 while paying $799",
      "Someone tell Nvidia Ethereum mining is no longer a thing.",
      "Buy the 6950xt instead. Unless you are absolutely hooked on DLSS 3, the AMD Card is a better deal for the price.\n\nhttps://www.newegg.com/asrock-radeon-rx-6950-xt-rx6950xt-pg-16go/p/N82E16814930088?Item=N82E16814930088&Source=socialshare&cm_mmc=snc-social-_-sr-_-14-930-088-_-04122023",
      "So, 2 years later, $100 more expensive than the 3070 and 3080/6800XT performance for $600. Hell, the 6800XT is now sold below the $600 mark. \n\nSo the only thing NVIDIA is selling right now is Frame Generation and nothing else. Love this $600 mid-range!\n\nEdit: Much more efficient than the 3070, which is the only thing I can appreciate for the 4070 right now...\n\nEdit 2: Just spotted a couple of 6900XTs for $620, which is almost 10% faster than the 4070?",
      "Considering most people go with AIBs and the unnecessary markup we get on GPUs these days, it's going to be $650+ for a 4070 vs a less than $600 3080?\n\nJust ridiculous...",
      "Missed opportunity.  This would have been a banging card at $500.  Ah, who am I kidding.  The Nvidia sheeple will still gobble this up faster than the last supper.",
      "Yep, this card is honestly in a *horrible* spot when the 6950xt is significantly more powerful and only 30 bucks more expensive. Way to go Nvidia",
      "While $600 isn’t the worst news, that limited VRAM is beginning to be a harder pill to swallow.",
      "Should I swap my 4090 for this?",
      "It'll almost certainly sell like hotcakes (I don't expect $599 to stick), but I get why people are mad, but it ignores the actual state of the market as it stands \n\nThe reality of the market is, right now, used 3080s sell for $450 - 550, and was never really a $700 product new (Outside of the lucky minority of got the FE at MSRP)\n\nSo paying $599 for a what is basically a new 3080, with warranty, 2gb more vram and FG, is attractive to a lot of buyers right now",
      "It will probably be closer to 700-800 as FEs are very limited and most people will only be able to get AIBs.\n\nEDIT: Just had a quick google search and they start around 1k euros atm lmao.",
      "Funny how \"skips\" were both after a crypto boom.",
      "Cheapest RTX 4070 models are 689€ here in Finland. And even the cheapest models seem to perform pretty well in terms of temperatures and noise levels since RTX 4070s are so power efficient.\n\nI still feel like this should have been the RTX 4060 Ti with a lower price tag. And 16GB of VRAM would have been nice for both this and the Ti-model.",
      "Keeping da 3070. Lil salty bout my 8gb vram tho"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "4070"
    ],
    "title": "5070 or 4070 TI SUPER",
    "selftext": "Hey guys, I just returned my Zotac 5070 OC because it was faulty. Now I’m considering if I should go for a used 4070 TI Super instead as I saw one listed, it has only been used for 4 months, so warranty still applies. Price is 799 for 5070 and 849 for 4070 TI Super. \n\nI don’t know much so any advice is appreciated :)",
    "comments": [
      "4070 ti S is faster and has more VRAM",
      "This, 4070Ti S with 16GB VRAM is the winner.",
      "4070Ti Super is the best Card!",
      "The 12GB of vram the 5070 has is already holding it back in some titles with heavy ray tracing. It's just not enough RAM.",
      "My Zotac 4070 Ti Super has been great.",
      "16 vs 12 . Not even close win for the 4070ti super. \n\nHowever you are not gonna get multi frame gen which is sucks because its awesome for single player games",
      "https://preview.redd.it/pcogj7ys58ue1.jpeg?width=4277&format=pjpg&auto=webp&s=33f775b63c3f8367e7b9e77d9e5018218cac4ffc\n\nZotac Solid OC 4070 Ti Super. No coil whine, 50C in full load at 2900MHZ(Undervolted, can run also at 3100MHz), HotSpot 62C. This model has the AD102 die from 4090, love it 🎉",
      "Just got a 4070 Ti Super, coming from 2060.\nAt 1440p 180hz it's superb.",
      "And is capable of playing 32 bit physx games.",
      "member that nvidia wanted to sell 4070ti as a 4080 but then changed lmao",
      "Currently has more stable drivers too",
      "4070 ti super for sure. I used to have one. Fantastic card. Value beast.",
      "4070 ti super no doubts",
      "ding ding ding 70 Ti S, Got one, glad I pulled the trigger 1 1/2 months ago on it.. has decent o/c abilities too",
      "There’s 4070 ti supers on the 4090 die? I thought they were all slightly watered down 4080s",
      "If you're going to be running 4k then definitely the ti super for the additional vram. It is a little faster than the 5070 too.",
      "The bad reviews are for 2 reasons. Still using 12gb and the power is not a generational leap. I think the 5070 is as powerful as 4070s or 4070ti non super ( forgot which ). \n\nBut to me multi frame gen is nice. I use it even when I have 5090 with games like cyberpunk. \n\nWith that being said you said cs2, if that’s all u play then u don’t need either cards. A potato can run that game.",
      "It's my biggest regret about my 4070ti.",
      "https://preview.redd.it/wk16t6i389ue1.jpeg?width=2560&format=pjpg&auto=webp&s=f22a776332e3ee7de1c5e62efccf5b427d2f0fcf\n\nThis is daily use. (1000 Mv at 2900 MHz, 110% Power, +1150 Memory) With these settings in full load, temps are between 50-55C with a hotspot of 65-68C and 200-220W. This is the sweet spot for my card regarding temps, performance & consumption. Out of the box was running at 2835MHz / 60-65C 70-77C (HotSpot) & 270-300W (in full load) so highly reccomend this curve & settings.",
      "4070tiS for sure. Faster and more vram"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "4070"
    ],
    "title": "NVIDIA GeForce RTX 4070 specs and $599 pricing confirmed, 186W average gaming power - VideoCardz.com",
    "selftext": "",
    "comments": [
      "\"We could've made it 699, so you're welcome.\" - Nvidia, probably. 😂",
      "Compared to the rtx 4090, the rtx 4070 is actually an xx60-class card, so the price increase is very large unfortunately.",
      "I think i will wait for the TI with 16gb vram.\n\nOh sh1t … wait…",
      "We are being utterly ripped off by nvidia. \nI am not a fanboy of any team in computing but I have been having nVidia cards since the GTX 760 but I will switch to team red with my next card for sure.\nI currently have a 3060Ti and I see no reasonable upgrade in the 40 series lineup with these prices.",
      "AMD isn't really any better. They are rocketing up their prices too.",
      "blistering overpriced",
      "Arguably they could have since \"better than 3080\". Of course, very few mass market consumers can afford this. Many will just go to consoles.",
      "You are correct",
      "Yeah, just like the 3070 Super, right?",
      "4090 seems like a relatively good value because of how trash the rest of the lineup is",
      "🤮",
      "In Australia they seem much better. Can get a 7900x for $1300 currently, compared to a 4080 which is $2300+",
      "It isn't.\n\nIt has 29 TFLOPS  vs 34 TFLOPS 3080ti has.\n\nAlso the memory bandwidth is only the half of the 3080 ti's so the 4K performance is going to be yikes.",
      "That's what I did. Been a PC gamer since 2000s. Never bleeding edge kinda guy but didn't shy away from more expensive GPUs. \n\nNow the Xbox series x on my LG C1 has brought me just about everything I want. Can't see a path to upgrade my 1080 right now because of how insane gpu prices still are.",
      "Pathetic but Jensen yearns for a new leather jacket. Partner cards gonna be 700€ in Europe I bet",
      "Eventually people will realize that was a one-off naming convention that only happened because the “2090” was called the 2080Ti so they had to call the upgraded 2080 a “super”.",
      "You think wrong.",
      "Nvidia can barely move the 4080 16gb, if they make a 16gb 4070ti then the 4080 would be officially dead. A 20gb 4080ti would be the only way to make that card appealing.",
      "The argument is based on the ratio of shader counts between the top card and a given card. The 3090 has 10,496 shaders, while the 3060 offers 34% of that count. The 4090 offers 16,384 shaders, while the 4070 offers 35% of that count.\n\nI don't buy it. The thing about 3090 is that it was the biggest thing Nvidia could make on Samsung. They would have liked to make a bigger part to offer more separation from 3080, but they couldn't. 4070 is cut 104 and 4090 is cut 102 like normal.",
      "Yeah, that's insanity."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "4070"
    ],
    "title": "RTX 4070 Super Launch Thread",
    "selftext": "**What**: GeForce RTX 4070 Super Launch Day\n\n**When**: Wednesday, January 17, 2024 at 9am Eastern Time\n\n**Protocol**:\n\n* **Subreddit may go on restricted mode for a number of times during the next 24 hours. This may last a few minutes to a few hours depending on the influx of content.**\n* This **Launch Day Megathread** will serve as the hub for discussion regarding various launchday madness. Thread will be sorted by \"new\"\n* [You can also join our Discord server for discussion!](https://discord.gg/nvidia)\n* Topics that should be in Megathread include:\n   * Sharing your successful order\n   * Sharing your non successful order\n   * Sharing your Brick & Mortar store experience\n   * Discussion regarding stock\n   * Any questions regarding orders and availability\n   * Any discussion regarding what you plan to use your new GPU for\n   * Any discussion about how you're happy because you get one\n   * Any discussion about how you're mad because you didn't get one\n* **Any standalone launch day related posts will be removed.**\n\n**Reference Info:**\n\n# [RTX 4070 Super Announcement Megathread](https://new.reddit.com/r/nvidia/comments/191pdus/megathread_geforce_at_ces_super_gpus_rtx_games/)\n\n# [RTX 4070 Super Review Megathread](https://new.reddit.com/r/nvidia/comments/198dish/geforce_rtx_4070_super_review_megathread/)\n\n**Links to various RTX 4070 Super Models:**\n\n# US:\n\n* [NVIDIA Website](https://store.nvidia.com/en-us/geforce/store/?page=1&limit=9&locale=en-us&gpu=RTX%204070%20SUPER&category=GPU,DESKTOP&gpu_filter=RTX%204090~13,RTX%204080~13,RTX%204070%20Ti~27,RTX%204070%20SUPER~19,RTX%204070~22,RTX%204060%20Ti~34,RTX%204060~31,RTX%203090~5,RTX%203080%20Ti~3,RTX%203080~23,RTX%203070%20Ti~5,RTX%203070~17,RTX%203060%20Ti~7,RTX%203060~10,RTX%203050~6)\n* [Best Buy](https://www.bestbuy.com/site/searchpage.jsp?id=pcat17071&qp=gpusv_facet%3DGraphics%20Processing%20Unit%20(GPU)~NVIDIA%20GeForce%20RTX%204070%20SUPER&st=4070+super)\n* [Newegg](https://www.newegg.com/p/pl?N=100007709%20601432393&Order=1)\n\n# Canada\n\n* [Best Buy Canada](https://www.bestbuy.ca/en-ca/collection/rtx-4070-super-series-graphic-cards/470700?sort=priceLowToHigh)\n\n# UK\n\n* [NVIDIA Website](https://store.nvidia.com/en-gb/geforce/store/?page=1&limit=9&locale=en-gb&gpu=RTX%204070%20SUPER&gpu_filter=RTX%204090~35,RTX%204080~61,RTX%204070%20Ti~34,RTX%204070%20SUPER~8,RTX%204070~85,RTX%204060%20Ti~32,RTX%204060~74,RTX%204050~34,RTX%203090%20Ti~3,RTX%203090~10,RTX%203080%20Ti~15,RTX%203080~32,RTX%203070%20Ti~25,RTX%203070~35,RTX%203060%20Ti~32,RTX%203060~61,RTX%203050%20Ti~24,RTX%203050~67,RTX%202080%20Ti~2,RTX%202080%20SUPER~1,RTX%202080~3,RTX%202070%20SUPER~1,RTX%202070~3,RTX%202060%20SUPER~1,RTX%202060~9,RTX%202050~3,GTX%201660%20Ti~6,GTX%201660%20SUPER~11,GTX%201660~2,GTX%201650~16)\n* [Scan UK](https://www.scan.co.uk/shop/gaming/gpu-nvidia-gaming/geforce-rtx-4070-super-graphics-cards)\n* [OCUK](https://www.overclockers.co.uk/?query=4070%2520Super&sortBy=production_ocuk_price_asc)\n\n# Germany\n\n* [NVIDIA Website](https://store.nvidia.com/de-de/geforce/store/?page=1&limit=9&locale=de-de&gpu=RTX%204070%20SUPER&gpu_filter=RTX%204090~135,RTX%204080~178,RTX%204070%20Ti~66,RTX%204070%20SUPER~16,RTX%204070~313,RTX%204060%20Ti~82,RTX%204060~210,RTX%204050~72,RTX%203090%20Ti~2,RTX%203090~10,RTX%203080%20Ti~34,RTX%203080~72,RTX%203070%20Ti~99,RTX%203070~213,RTX%203060%20Ti~137,RTX%203060~220,RTX%203050%20Ti~47,RTX%203050~144,RTX%202080%20Ti~1,RTX%202080%20SUPER~1,RTX%202070%20SUPER~2,RTX%202060%20SUPER~1,RTX%202060~22,RTX%202050~12,GTX%201660%20SUPER~29,GTX%201660~4,GTX%201650%20Ti~1,GTX%201650%20SUPER~4,GTX%201650~55,GTX%201630~4)",
    "comments": [
      "https://preview.redd.it/k0em9q6db1dc1.png?width=1192&format=png&auto=webp&s=24fcad05e7656584a0ea801eb7ab71c5ca1d3226\n\nIt's so sad to look at this already",
      "pls no one buy from these people",
      "Don’t fall for the fomo.",
      "Best buy sold out in 5 min.\n\nEDIT: 2nd time I got one in the cart and hitting checkout it was removed.\n\nEDIT: ORDERED, from nvidia had lots of site issues but it finally went through!",
      "I’d rather switch to AMD or leave gaming before I even think about turning to these scalpers.",
      "Anyone waiting for the 4070 ti super?",
      "I'm very calm... I bought a 4080 a month ago... will I cry next month? :)",
      "Money can't replace time. Just go enjoy your card and don't watch/read any reviews :).",
      "No",
      "almost hit buy now on the nvidia website but im gonna wait for the Ti Super next week.",
      "they still have stock on the US Nvidia website as of right now.",
      "process my order faster, NVIDIA!",
      "Just ordered from Scan in the UK. Arriving tomorrow.\n\nTime to retire my trusty GTX 1080 and get a taste of Ray Tracing and DLSS.",
      "I'm pleasantly surprised how well these websites have been able to handle the demand.  Best Buy and NVIDIA store had it in stock for almost the entire day here in the US.\n\nEdit: For those of you still trying to get it from Best Buy, check back periodically.  They're doing it in waves to prevent scalping.",
      "5 minutes is a lot of time to buy if you know exact release time/date",
      "How do they expect that to sell? 4070TIs sit on shelves for $200 less",
      "Just grabbed one off Amazon from 599. Upgrading from 1660 super. Stoked!",
      "any word on when nvidia will ship out the 4070 super? dont usually order from there so not sure what to expect.",
      "Amazon selling the ROG oc version for $1.2k lol",
      "Sucks that the top comments are all fear mongering the supply issue when it's really not the case. Just got a 4070 Super FE in my Best Buy cart, just to check and see if it would be difficult. Zero issues. Didn't buy it, but two and a half hours after launch you can still easily grab these. \n\nIt will be fine."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "4070"
    ],
    "title": "Colorful confirms GeForce RTX 4070 Ti graphics card, same specs as 4080 12GB - VideoCardz.com",
    "selftext": "",
    "comments": [
      "I’m glad they didn’t make it any weaker than it already is. Their deception is already obvious. Trying to hide it only makes it worse IMO.",
      "They just… they just couldn’t make it the 4070.  It had to be the fucking *4070 ti* even though there’s no 4070 yet.  So they could still try to pretend a higher price is justified after they couldn’t get away with calling it a 4080.\n\nThey couldn’t just be content with a bigger generational leap than expected and riding a clean and honest wave of sold out cards at a great price point.  Greedy asshole fucks.",
      "They will price it at 799. 4080 new price at 999. 4080ti price at 1299 and keep that 4090 price just where its at...muahahahha",
      "They weaken the xx70 memory bus;\n\nRTX 3070: 256 bits (448 GB/s)\nRTX 4070 Ti: 192 bits. (504 GB/s)\n\nGranted, the 3070 used GDDR6 while this new 4070ti is using GDDR6X.",
      "with how big the gap is between the 80 and 90 we got room for the 4080ti, 4085ti, 4088, 4089 Super and much more!",
      "Makes you wonder how shitty the rest of the product stack is gonna be don't it?",
      "Also RTX 40 cards have significantly larger L2 caches making the memory bandwidth less important. Not trying to justify their cutdown bus sizes but that was probably a factor in their decision making on the designs.",
      "Honestly, people on Reddit comparing details like this between generations feels just as disingenuous as Nvidia's handling of the 4000-series has been. It's the same reason comments always say just base your decisions off of benchmarks - these things aren't perfectly comparable between generations. The cache, memory bus, and memory type all affect the end performance and they're all different between the 3070 and 4070Ti.\n\nNvidia has plenty to catch flack for so we don't have to invent reasons. I'm personally skeptical that the higher memory bus would make a difference here. Maybe at 4K, maybe.",
      "You haven’t realized by now that Nvidia doesn’t give a fuck about PR?  They have the market by the balls",
      "I can't even imagine them doing the rest of the stack tbh.  Everything below the 4080 competes with products they already have.  Maybe in a year we might see some after 3000 series have mostly sold out of stock, but not anytime soon.",
      "I'm honestly surprised they didn't cut the die down somehow. Just makes them look pathetic if it's a match. Possibly cuda count will get a haircut",
      "Yep. Customers still lose this one.",
      "4080 is probably gonna be 1049, 999$ seems too big of a cut for nvidia",
      "Inb4 the 4060 barely outperforms the 3060 Ti",
      "*surprised pikachu face*",
      "Yes, more like 4080 pro, 4080 plus, 4080 pro max, 4080 pro max ultra, 4080 pro max ultra elite deluxe.",
      "Well it was already like that with 3060 which was about 5% faster than the 2060 super (closest ti equivalent I guess). Then there's the 3050 which *still* costs more than 2060s and performs worse lol.",
      "Nvidia's benchmarks had the 4080 12 GB bouncing between the 3090 and 3090 Ti depending on game, didn't see any where the 4080 12 GB outright beat the 3090 Ti.\n\nAIB 3090 Ti's dropped to $950 over the summer.  Assuming the 4070 Ti has an MSRP of $800, the AIB cards will be $850-900, which makes it barely better than a sidegrade.  I guess 30 series prices are a lot higher at the moment which makes the 4070 Ti look better...\n\nWould really like to see it down to $700 MSRP at the most.",
      "Too many people confuse “playable” with “Max Settings”",
      "The fake 4080 12gb version they tried to sell but then un-launched because everyone instantly realized it was a 4070 ti they were trying to put lipstick on."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "4070"
    ],
    "title": "First GeForce RTX 4070 GDDR6 debuts on Newegg at same price as GDDR6X variant - VideoCardz.com",
    "selftext": "",
    "comments": [
      "Yes, I will buy the worse product for the same price. I cannot wait.",
      "an uninformed buyer will do ,he wouldnt notice the missing \"X\" after \"GDDR6\", thats is the plan.\n\nthey did worse than that with the 3050 6GB , it is lower than the 3050 8 gb in many things not just the VRAM but didnt mentioned and didnt call it something like 3040 , also sold at high price",
      "any reviewer that got their hands on these yet? Would be interesting to see the performance difference",
      "$2k USD 5090 inbound.",
      "Standard NVIDIA practise.  \nCounting on the avarage user that doesnt search information, like parents buying things for the children.  \nLinus tech tips did a video about it the other week.",
      "550 usd for what the 4060 should have been but with worse RAM?  Hilarious.",
      "You're right! Let's just sweep the whole thing under the rug and forget about it instead!",
      "I still dont get why this can't be $499 at this point. 4060ti 16G at $429",
      "$2k? Wow you’re an optimist. I’d say $2399 at least.",
      "I never said that it would. Is it still scummy? Hell yes!",
      "It’s a no from me dawg",
      "Rt 3030",
      "Does not change the fact that gddr6 is cheaper then gddr6x, which is not translated to the customer even if it isnt slower in the end.",
      "This will be like the actual 60 class card we should have gotten -2 vram",
      "Let's be honest. They could charge almost anything for the 5090 and it would still sell out at launch.\n\nChina will be snapping up half of them through illegal back channels.",
      "Might as well go back to the GTX moniker if they keep stripping things away.",
      "![gif](giphy|7MDZS8zS1ixtJAUEul|downsized)",
      "This is why we needed AMD to succeed. NIVIDIA desperately needs serious competition otherwise we get more price gouging like this.\n\n\nFucking done with this company after my 3060ti kicks the bucket.",
      "Ya I'm waiting for the same thing, vram, bus with, pcie, nothing of which matter most than the whole performance by benchmarks",
      "the problem with amd is lack of proper competition. while raster performance is +- the same between nvidia and amd, everything else just doesn't cut it.\n\nRaytracing is 30-40% better on nvidia. DLLS is miles away from FSR. And that's just gaming.\n\nIn Poland Amd cards basically cost the same amount, maybe 20-50 dollars less. So why will a person buy a worse product for the same money?\n\nThe only Amd card that makes sense is rx 6600, because it is better that rtx 3050 8gb for the same price or cheaper. Everyelse is either not cheap enough or can't compete with nvidia at all.\n\nVRAM alone won't cut it."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "4070"
    ],
    "title": "NVIDIA GeForce RTX 4080 and 4070 get new (lower) power specs, mysterious 20GB model also mentioned - VideoCardz.com",
    "selftext": "",
    "comments": [
      "shock horror, the rumors weren't true. still not clicking the link to give them rumor ad revenue. lol",
      "Dang, at this rate we'll be back to 250W for the XX80 Ti model in a couple of weeks. /s\n\n320W for the 4080 makes a lot more sense than the dumb numbers that the rumor factories have been spinning up these past months. 285W for the 4070 still seems high compared to the 3070's 220W, but the 3070 Ti was 290W so that's close enough I guess. Maybe a 4060 Ti will fill the 200W to 220W range.",
      "Who knows until the damn cards are actually announced...\n\nI'm sure Nvidia tests a number of different BIOS variants with different power limits to \"test the limits\" of the silicon.   Likely where all the rumors of the insane TDP started with the 40 series.\n\nAt this point I really hope Nvidia goes the efficient route and brings the performance per watt to something better than the RTX 30 Series!",
      "I saw every possible configuration of the 40 series on that website. So they were right at least once. \"Just as we reported on July 21st the 4080 has x amount of y!\"",
      "Total Board Power  -\n\n4080 : 420W -> 320W\n\n4070 : 300W -> 285W\n\nThis is the Total Board Power Limit which is usually higher than the TDP\n\nThe 20GB model supposedly has specifications which are in between the RTX 4090 and the RTX 4080 , so it could be an RTX 4080Ti",
      "These are Total Board Power numbers, so the TDP numbers for these cards would be even lower. I'm guessing the 4070's TDP will be around 250W. That's 15% more power for like 40% more performance, which honestly checks out",
      "You left out the most likely possibility.  It was never 420w in the first place.",
      "after waiting for so long with my 1070ti. this is what i'm waiting for. lets fuckin go!",
      "But this is also a rumor on power draw...",
      "Are they going to saturate the market with 30 barely different models again?",
      ">I'm sure Nvidia tests a number of different BIOS variants with different power limits to \"test the limits\" of the silicon.\n\nOf course they do. \n\nBut kopite doesn't report on rumors as if these are just test configurations.  He states actual specs for model names.  Even here says \"We can expect 4070 to have blah blah\", as if these are the proper decided specs.  \n\nIt's ridiculous.",
      "Remember, people aren't buying this just for games now, they're buying for games 5-7 years down the road. I remember people telling me 3.5GB was more than enough...which sure was true in 2015.",
      "I'm so glad they finally made the distinction. I was highly skeptical, those power numbers made no sense as they would require exotic cooling solutions even on the midmarket SKU's. Especially because of the early 3090 failures due to high transient loads, it makes sense that TBP specs have gone up to avoid the same situation.",
      "Its also worth noting Nvidia builds a number of variations of each model and tests performance, cost, yield and which variant fits their end goal.",
      "Ahh I remember owning a 970. Great card, a solid 3.5/4.",
      "Isn't this also a rumor?",
      "20gb model?  <insert awwww shit here we go again meme here>",
      "Yeah a 4070/ 7700xt would be hella an Upgrade for you, almost 300% !\n\nAnd its looking REALLY good for availability and MSRP.",
      "Don’t think that’s how new rumors work… The information gets updated so unless kopite specifically mention that they are backtracking then we should be using their newest rumors to judge their accuracy.",
      "The problem is the 10GB 3080 should have never existed.  But Nvidia is notorious for setting low standards."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "4070ti"
    ],
    "title": "Call me crazy but I convinced myself that 4070TI Super is a better deal (price/perf) than 4080 Super.",
    "selftext": "Trash 4070TI Super all you want, it's a 4k card that's 20% cheaper than 4080S and with DLSS /Quality/ has only 15% worse FPS compared to 4080S.\n\nSomehow I think this is a sweet spot for anyone who isn't obsessed with Ray Tracing.",
    "comments": [
      "If a card that costs less meets your needs, it's ALWAYS a better deal than a more expensive card.  Simple as that.",
      "It's pretty normal that higher end cards will have a higher price per frame. 4080S is still pretty reasonable. 4090 is 60-100% more for 20-30% increase in performance.",
      "I'm watching Gamers Nexus review of the 4080S. Steve is showing the top 3 relative $/fps GPUs are the 4060, 4080S, and 4060ti, in that order. Nvidia's top 3 anyway.",
      "tender historical scarce merciful bells tie wise concerned dinosaurs dam\n\n *This post was mass deleted and anonymized with [Redact](https://redact.dev)*",
      "yes",
      "At this point, convincing yourself that any nvidia card is a good deal is outright mental gymnastics.",
      "Yes, this is all what it should come down to..  as long as it meets your needs, get it.  Instead all these reviews are getting in their head making them think well its only ___ dollars for ___ better performance.  Might as well get the ____.  Thats the game these gpu companies want to play with us.  Its like buying a soda at the movies.  Its only .50cents more for the large drink.. thats how they will squeeze as much money out of all of their buyers.",
      "Though things have slowed down a lot, buying a top tier GPU for \"how it's going to perform in two years\" has been a terrible strategy for the last two decades.\n\nTime and time again, the top models see huge price drops because the next generation's mid tier is competing with it. \n\nEven in the last generation this is true; A 3090 is close to a 4070ti now. If two years ago you bought a 3070 instead, you'd still have the money to buy a 4070ti today, or even better if you sell the old card.\n\nNever buy computer hardware for its future promise. Buy what you need for the games you play today.",
      "exactly, using the $/fps logic, the best deal is to just use the CPU's integrated graphics -> $0 for 10fps = infinite value",
      "Using top 3 to explain a negative performance indicator is confusing. The most expensive $/fps would be clearer imo",
      "The guy was saying dollar per fps, so higher on the list is worse since you pay more per fps.",
      "There's nowhere to run, AMD archaic tech is no viable option.",
      "Found the \"AHHHHCKKUTUALLLY\" guy.\n\nIf productivity is your need, then your card needs to meet your need.\n\nYour statement is not a good correction.",
      "I think there is a bit more nuance. The soda you will drink at once, but for GPUs it might not meet your performance needs in two years. The thought is that getting a more expensive card might save you money in the long run. Whether or not that is true is another matter.",
      "Take it with a grain of salt. There are some things a 4090 can do that a 4060 can’t despite which card is better $/fps",
      "Wasn't 4070 Super the best of all 3 Super cards when we talk about performance gains? Everybody expected 4070ti Super to be the winner here, but oh boy, how were we mistaken.",
      "It is, but at the same time for 4K, there is never enough performance. 200€ more for 15-20% more performance.\n\nNo one ever regretted more performance, only not enough. Then selling your card and grabbing something faster is a hassle and you lose money on it.\n\nIf you are on a budget, then indeed 4070Ti Super is the buy and just lower settings to High + RT Reflections, for indistinguishable visuals vs Ultra RT, at way better performance.\n\nI just decided that I am getting 4080S, as for me it was only 150€ more (1070€ vs 920€) and I can OC Asus TUF for 8% more performance (according to TechPowerUp). Which brings me near 60FPS with Pathtracing at 4K DLSS Q (or at least UW1440p Pathtracing at 60FPS on LG 42C2) and I got also PCVR. But basically 150€ is not consideration money for me and I got 2nd best card, with OC only 24% away from 4090 for 3/5 of the price (or 700€ less).",
      "That's great and all but 0 games use more than 16GB. Hell most of them don't actually use more than 12GB with a couple exceptions. \n\nUse not allocate.",
      "Even with Cyberpunk RT the difference between the two without DLSS is 4-5 fps -source Paul's Hardware. So yes you are right.",
      "nah 4070 super surely has better price perf than 4060 ti."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "4070"
    ],
    "title": "RTX 4080 and RTX 4070 Ti officially reach End-of-Life",
    "selftext": "",
    "comments": [
      "They killed the 4080 the moment it launched at that MSRP",
      "My 4080 just jumped out my window :(",
      "Doesnt mean anything but that the supers are replacing them.\n\nEnd-of-life in production only.",
      "Nah man, check your PC case for R.I.P tombstone on the GPU's backplate. Better safe than sorry.",
      "4000 series*",
      "somehow strange, my 4070 ti is now a thing of the past",
      "4090 was a decent bump compared to the 3090",
      "every 4080: I'm tired boss",
      "That's because the 7900XTX also launched at the same price range and all it had going for it was a 3% better avrage raster-only performance while losing at 10 other things including power efficiency and not drawing 100w at idle. \n\n&#x200B;\n\nPeople like to act like AMD's shit don't stink and when they don't sell they blame the consumer for not knowing AMD exists, a lie that was debunked when people started buying AMD CPUs the moment they became competitive with Ryzen.",
      "in memoriam",
      "I just wish we will see the 4080 available for $1099-$999 in real-world pricing. I don't want to see ASUS and GIGABYTE OC cards for $1150+.",
      "End-of-sale - it's called end-of-sale - not end-of-life. No more RTX 4080 or RTX 4070 Ti cards will be produced. They will be end-of-life when NVIDIA no longer supports them via software, warranty, etc. - at least a few years down the road.",
      "Yes, but both in performance and in price.\n\nEspecially considering that the rtx 3090 was really just a 3080 + 5-10%. And the 3080 cost 700, so less than half the price of a 4090.\n\nNo one complains about the 40 series because they don't like the performance itself, the issue is terrible pricing.",
      "3090 that's been mining for 3 years: you are not tired, it's all in your mind, keep 'rendering'.",
      "Yeah managed to get one on sale last week and I’m very happy with it, about twice as fast as my 3080 was, and that was a really good card to start with",
      "Didn't eol mean end of support? Odd headline",
      "Exactly. The 4000 series cards are amazing, but not at the prices they sell for. Even with the super refresh prices they're too high.\n\nFrom way too high prices to just high? Ah, yes, let's now praise nvidia for only gently fucking us instead of obliterating consumers.",
      "My 4090 just barely dodging the bullet:\n\nhttps://preview.redd.it/srpb4jegeebc1.jpeg?width=600&format=pjpg&auto=webp&s=352be0ca306036e7c9553ac213069df772c8fbec",
      "The RTX 4070 Ti will be faster, if only slightly. The question is that extra bit of performance worth \\~$82 for you, assuming you will even be able to get a 4070 Super at MSRP. Quite frankly, other than a \\~7% difference in CUDA cores, and a slightly clock decrease, the cards are almost identical. The Super will likely be about 5-8% slower than the Ti while the Ti is about 14% more expensive for you.",
      "1700 cad to usd is 1271"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "4070"
    ],
    "title": "VideoCardz: \"NVIDIA GeForce RTX 4090/4080/4070 get new rumored specs, RTX 4070 with 7168 cores and 10GB 160-bit memory?\"",
    "selftext": "",
    "comments": [
      "I’m starting to really hope at this point this is NVIDIA leaking false information to both mislead everyone and understand who’s the source that this guy has. \n\nI’m not an expert by any mean but the ‘80 sku that I’m used to go for looks very underwhelming from this data. Much higher power usage, worse quality memory, doesn’t come from the full 102 and most likely will see an increase in price. \n\nDon’t know, doesn’t look good to me even if it ends 30% faster than 3080.",
      "Wtf is Nvidia's fetish in not increasing the damn VRAM? The 4070 should have 16 minimum, it's two generations with the same average memory ffs.",
      "To be honest I expect the 80 sku to be gimped on purpose in the 4000 series. The 3080 at $699 made the 3080 Ti and 3090 look like a complete rip off so NVIDIA isn’t making the same mistake again. \n\nThe x90 sku in the 4000 series is the new x80 now.",
      "If that 4070 is 160 bit / 10 GB instead of 192 bit / 12 GB, that would suck. Might as well get a 3080 12GB if they drop hard in price instead.",
      "They've already done this on their lower-tier SKUs, for example:\n\n* 1060 6GB was basically a 980\n* 2060 was basically a 1080 with RTX\n* 3060 is barely better than a 2070, and is worse than a 2070S\n\nAnother example:\n\n* 1050 was basically a 960\n* 1650 was basically a 1060 3GB\n* 3050 isn't even a 2060. \n\nMeanwhile 3060's and 3050's are more expensive than their predecessors for less performance. How crazy is it in 2022 we have people recommending purchasing a 4-year old 2060 over a 3050 because of how terrible the 3050 is?",
      "VR gamers will continue to weep about this insulting vram.",
      "And yet again, kopite7kimi, after telling us that most of his posts are actually just speculation, does not specify in this post about specs whether it's actual information he's heard or is just more personal speculation. \n\nSo fucking sick of this guy.  Blown through any of the goodwill and credibility he had before big-time.",
      "they want you to buy again in the next three years when 10gb isnt enough",
      "You have to consider all GPUs released since 2021 were priced/specced to take advantage of the market situation at the time.  It's not necessarily something that can be repeated for the 40 series.",
      "Yeah im starting to thing these rumors are baits from nvidia. Too many changes in such little time. \n\n\nAs for your concern, actually the rtx 2080 didnt use TU102. It used TU104. Same thing with the 2080 super, the 1080 before and even the 980.\n\nThe 3080 was kinda an outlier due to competetion (RDNA2). \n\nWhether nvidia goes back to that segmentation depends on how compettive AMD will be with their segmentation. Amd will almost certainly be ver compettive on Perf this gen, \n\nproblem is, if they use N33 for the 7700xt SKU (as rumor has it) then they are segmenting just as heavily as nvidia and you can kiss your AD102 for the 4080 goodby. \n\nGood news is: there is no world where the 4080 is only 30% faster than the 3080, EVEN with only 10240 cuda cores. It will be at least 60-80% faster. (17.6% more shaders, at least 30% higher clocks and 36% higher ipc)",
      "Cost.  \nGDDR6 was damn expensive.",
      "Bingo. Gimped VRAM capacity is planned obsolescence. No excuse for cards this new generation to be using VRAM configs from 5 years ago.",
      "I don't think he's excusing nvidia for it, just putting some context around the comparisons being made to suggest that some are comparing apples to oranges.\n\nFor example the thread that spawned this mentioned the price point of a 3080 making the Ti look ridiculous, but the TI came out way later.",
      "Not credible.\n\n60% difference in cores between xx80 and xx90/80 Ti would be very abnormal.\n\nPlus a 30W TDP difference for 60% more cores and more power-hungry memory configuration is silly.\n\nThere'd have to be a vast difference in stock clocks, but then that'd mean the 4090 could be overclocked significantly (for a lot more power draw obviously)\n\nBut that's also abnormal for these days, chips are sold near the top of their clock headroom now, because competition is tight.",
      "Complement.\n\nThat's to say the 3050 and 3060 are here to stay for quite a bit. Just like the 1600 series was used as entry level during most of Ampere.\n\nEven after the 4060 launches they may keep the 3060 at a *comparatively* lower price.",
      "Okay... so corporate gonna corporate. That's no reason to excuse Nvidia for selling consumers less at a higher price.",
      "Would make somewhat sense for RTX 4060 Ti but not for RTX 4070.",
      "There is another thing to note. Pascal was a huge jump over Maxwell.  That applied across the entire stack.  Turing was ultimately pretty disappointing.  The $700 2080 was only as fast as the $700 1080 ti.  But the $450 (FE) 1070 was as fast as a $650 980 ti.  And while a 1080 was ~70% faster than a 980, the 2080 was only ~30% faster than a 1080.\n\nThe difference between the 2060 and 2080 is smaller than the difference between the 1060 and 1080.  They did this to make the unappealing 20 series look better than it was (and justify moving them to a higher price point).  The tradeoff is that to return to the old performance segmentation, we got the 30 series looking like a good jump at the high end and kinda lackluster elsewhere.",
      "> If that 4070 is 160 bit / 10 GB instead of 192 bit / 12 GB\n\nRX 6600 XT had half the bandwidth & fewer cores compared to RX 5700 XT yet performed equal or better in most games.  \nRTX 3080 is 10GB / 320 bit vs 2080 Ti at 11Gb / 352 bit yet outperforms it effortlessly.",
      "honestly, the only real user base that has a legitimate complaint are VR gamers."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "4070"
    ],
    "title": "RTX 4070 comparison chart",
    "selftext": "Hi\n\n&#x200B;\n\nUpdate 4/20 - Added Fuse column which in case of card failure can save on repair cost\n\nUpdate 4/21-  Added Gigabyte Gaming OC temps and noise are cross referenced from FE card to make them comparable and correct only normalized temp is missing. Plus this card has fuse on pcie so in case of it going bad there is a less chance of damaging motherboard.\n\nUpdate 4/22 - Added fan bearing types as ball bearing fans in equal conditions last longer, also added Gigabyte Windforce OC and Palit Dual\n\nUpdate 4/23 - LTT took sponsorship for MSI RTX 4070 GAMING X Trio lets ask him to test its vrm temps under load\n\nUpdate 4/24 - Added INNO3D 4070 Twin x2 but no noise results only have info that fan rpm is 50 less from FE card, also added links to model names for each review of pcb photos I used\n\nUpdate 5/22 - Added  INNO3D 4070 Twin x2 noise result also thanks to members support\n\nUpdate 5/26 - Added KFA2 GeForce RTX 4070 EX Gamer\n\nUpdate 5/31 - MSI RTX 4070 Gaming X tested vrm temp difference between chips which has direct contact and chip which is cooled by the air link to video -[https://youtu.be/zmN2rlbI4JQ](https://youtu.be/zmN2rlbI4JQ)\n\nUpdate 6/10 - 2 EMTEK, 2 Colorful and 1 Inno3d cards were added thanks to community member  **No-Bet-80**\n\nUpdate 6/14 - video review part 2 is out [https://youtu.be/FqmtLNmr2Bg](https://youtu.be/FqmtLNmr2Bg)\n\nupdate 6/14 - for those who are seeking more value options\n\n[https://youtu.be/Cwx6OoXTjwU](https://youtu.be/Cwx6OoXTjwU)\n\n[https://youtu.be/MWsFCrsRBj8](https://youtu.be/MWsFCrsRBj8)\n\nUpdate 7/8 - added Zotac 4070 AMP AIRO which is missing direct contact for one memory VRM chip similar to MSI 4070 Gaming X - thanks to community member\n\nhttps://preview.redd.it/f18cq3t2f83b1.jpg?width=1280&format=pjpg&auto=webp&s=74b3ccc4d27d95b1da551100e6ac794e9ae1a667\n\nI decided it will be useful to make some chart which will help choose the best option for your build.\n\nAlso I made a detail video review and comparison of each card in the table below\n\npart 1 [https://youtu.be/huVAgOBQVbo](https://youtu.be/huVAgOBQVbo)\n\npart 2 [https://youtu.be/FqmtLNmr2Bg](https://youtu.be/FqmtLNmr2Bg)\n\nThis chart is based on data I managed to find if you have more data sources please leave in thread so I can review and update the list accordingly.\n\n&#x200B;\n\nhttps://preview.redd.it/39n6gbbzh0db1.png?width=1329&format=png&auto=webp&s=5535ae9839ca6f846170d73b8872dbdb53e4b4eb\n\nChart is not based on size parametrs only as that info is available in techpowerup database [https://www.techpowerup.com/gpu-specs/geforce-rtx-4070.c3924](https://www.techpowerup.com/gpu-specs/geforce-rtx-4070.c3924)\n\nbut also cooling performance components used their cooling and many other factors which overall make card great buy or not, especially now when almost everything is in stock to choose the best one.\n\nThanks for all contributor who helping me to get more and more info for this updates.\n\n&#x200B;",
    "comments": [
      "4070 ventus 3x really bad?",
      "Yes, it is missing contact between 3 vrm chips and radiator.  Another msi card gaming x is missing 1 vrm chip contact. So I would skip them as in guru3d review you can see flir camera capturing 94c in that vrm part.",
      "The ventus series is always garbage",
      "It's not as if it will perform poorly. it's just hotter and has worse power delivery than similarly priced products",
      "No but I plan to make for 4070 ti next maybe will come to 4090 also",
      ">ASUS DUAL $600  \n>ASUS TUF $650\n\nYeah, I fucking wish. Over here, the Dual starts at €659 and the TUF at €799.",
      "Where is Gigabyte?",
      "If I was comparing performance yes but this is lets say quality of the cards comparison and if you bought quality product you can tune it to get max performance with minimal noise.",
      "shouldn't this show stock clock speeds too",
      "This info is good for us. MSI once again showing same like many times before. You simply cannot trust any product of this brand. But ofc for hardware unboxed this is best. How bad is to be paying to youtubers and cant even put thermal pads properly",
      "Asus is doing great, nice!",
      "I saw it and have all that cards covered, I need some sources for gigabyte cards especially as they can be good contenders to asus. Also I dont have high hopes for zotac but still if you will find some sources please share.",
      "Really? I have the 3080 12GB version and it seems OK (I haven't really done much testing or thermal checking, just gaming).",
      "This is chip (voltage controller or rather by full name uP9529Q 3/2/1-Phase Synchronous-Rectified Buck Controller) not mosfet. This doesnt' get hot (maximum power consumption by spec is 1.41W which of course isn't even close to it in reality) and in fact shouldn't have a need to be contacted by cooler. Mosfet (actual part that can get hot) is welcome to get cooled, but not because mosfet needs particulary a lot of cooling (most mosfets are designed with operating tempreture up to 125C, some even 150C) but because heat from mosfet can be transfered to PCB and potentially degrade PCB faster, but that is tricky subject that depends on how PCB is made and what is contact between PCB and mosfet itself.\n\nIn case of gamingX i don't see seriously any issue.\n\nVentus3X 97C for normal gaming should be fine, also because 97C came from probably power virus like load, and 4000 series aren't most of time TDP limited what means mosfets wont' get that hot (tempereture will be lower and in context of mosfets that is absolutly ok). What is important is that no one should have funny idea on ventus 3X to flash bios from higher TDP card and try to put higher load (like 240W). That could put card in \"not ok\" territory.\n\nAlso i gonna smash you for something stupid:\n\nGamingX has fuses on board. Most 4070s don't. 4070Ti gaming x(That has very similar PCB design to 4070 gaming x) is literally approved by bulldzoid that goes in detail and he clearly liked that memory power delivery is splitted from rest of board, and literally part you point out is memory power delivery part that won't have that insane load on it! GamingX by how Bulldzoid talked about it, gives idea that component quality is between great/excellent.  TUF has slighty better filtering, but doesn't have fuses that MSI has.",
      "Also for anyone reading/interested here is the review mentioned above, they show a good picture of what I believe is the 3 vrm not touching the heat sync. They go on to say they reported this concern to MSI who tested, confirmed, and deemed it \"expected behavior\". Although it sounds like it's not ideal, I suppose they say \"good enough\" 🤣😅😆😁😀🙂😐😑😒😯\n\nhttps://www.guru3d.com/articles-pages/msi-geforce-rtx-4070-ventus-3x-review,31.html",
      "> And please let me know if I will offer you two cards with similar quality but one will have vrm chips cooling another will not will you buy card without cooling and I can answer instead of you as NO you will pick card with cooling as any rational person will do. \n\nYou are clearly not electrical engineer. Thing we talk about is AOZ5311NQI and it is combo of 2 assymetrical mosfets and driver. That chip we talk about is driver and doesn't have high power output and doesn't need cooling at all because it simply doesn't get hot. Mosfets can get hot if you put significant load on it, but the chip is not mosfet. \n\nNow just to know scale of it:\n\nAccording to micron (and igor's lab as well) power consumption of single gddr6x chip is around max 2.5W per chip. We have 6 of them what sums up to 15W. \n\nAccording to micron gddr6x works on 1.35V. 15W/1.35V is 11.1A. On 2 seperate power stages that gives you load of 5.6A per AOZ5311NQI. Now search on this product on internet and look at spreadsheet. At VIN=12V VOUT=1V F=500kHz and load current of 5.6A at graphs alpha provided we see 0.5W maybe 0.6W of Ploss. On 3 diffrent components 2 mosfets and chip on the worst case scenario. Now in reality it is even lower because:\n\n- frequency of change on full load (when maximum power is used) is lower so Ploss is lower too,\n\n- Alpha provides graphs for Vout=1V, with 1.35V (gddr6x operate at) Ploss will be even lower. \n\nIn fact Alpha provides you no information below 5A because they consider it insignicant in aspect of Ploss and GPUs mostly operate in that range. Max range Alpha provides is 40A and even at that they don't provide in specification any information about needed colling only about that max operating tempreture is 125C... which this will be not even close to ever getting. Demanding a chip that will consume maybe at worst 0.1W of heat is insane. It is waste of time and because of manufacturing tolerances you might end up with situation when contact with chip prevents contact with diffrent component that gets actually hot. Absolutly stupid idea.\n\nThe reason why most VRMs is extremly overkill on most boards, is because you need to have good output filtering. With each next VRM phase comes more capacitance, and you can distribute VRMs better around components that need power decreasing distances and power losses and improve quality of power delivered. And thing is the more overkill VRM you have the less Ploss you have and also that Ploss is distributed on large area what makes it fine.\n\nIt is same discussion in motherboards case. Good motherboards have overkill VRMs and radiators on top that are essentially useless. You could rip off all those radiators and nothing would happen. When things do get toasty is combination of cheap motherboard with poor VRM design without radiator + power hungry CPU. That cheap motherboard could benefit then from radiator. Could benefit from better VRM design. Doing both is extreme overkill.\n\n> Also there is no fuse on PICE side so if your card will go bad for its bad components it may kill motherboard also but will save on gpu repair which again not so much fun\n\nASUS doesn't have fuses, Gigabyte doesn't have fuses, Palit doesn't have fuses.... MSI does have fuse at least on input from power supply and 4070ti has fuse on both PCI-E and power input. 1 fuse > 0.\n\nVentus3X case is mildly concerning because again you could have a hotter case when air inside case has let's say 40C, then you start some workload that will stress out that mosfet and you might exceed 100C, what for mosfet is still totally fine, but for PCB might not, probably there is nothing important under that MOSFET and nothing will happen but if there is inside that PCB something that could deteoriate and cause signal loss that would be big deal. But nothing to be concerned about unless you plan extreme stress testing for years...",
      "https://youtu.be/AkVqLK_mGCo",
      "It is a subsection of cooling and describes how good is organized cooling for vrm and vrm chokes. Like on MSI cards some vrm completely have no contact with radiator and running close to 100c.",
      "I had purchased a Ventus 3X 3080 Ti over a year ago for msrp ($1,200) when 3080 Ti’s were selling for nearly $1,900. It was an impulse buy as I had been wanting a 3080 Ti but couldn’t bring myself to pay anything above msrp, even during the shortage. \n\nI had known nothing about the Ventus line until I started researching my purchase a couple days after I bought the GPU and started regretting my purchase a little. So many people were bashing the Ventus 3X and it was at a time where there was little to no information in the 3080 Ti model.\n\nBut, the two main reasons I was comfortable getting the Ventus was the lack of rgb and the 350w power limit. I was planning on undervolting anyway and really liked the Ventus 3X look. Plus it only used 2x8 pcie cables which was a plus in my eyes.\n\nOnce I got my Ventus 3X I put it through extensive benchmarking and stress testing. It not only ran much cooler than I expected compared to other 3080 Ti’s, but it benchmarked in the top 20% of all 3080 Ti’s in numerous benchmarks. I even had the top score for one of the 3D Mark benchmarks for a 3080 Ti and 5800X at one point (I posted a pic on my pcpartpicker build).\n\nMy line of work and VR headset ended up needing 24GB vram shortly after so I sold my Ventus to a good friend of mine for less than half of what I paid but it was a beast of a GPU that outperformed my friends 3090’s.\n\nWhat I’m saying is that even though the Ventus does use cheaper components, depending on the price, and your wants, it may end up being everything you want from a GPU and more. Or you could get an overheating, short lived GPU. So do your research before buying!",
      "For anyone who bought ventus 4070 and can't return(me included), GPU VRM temperature is normally 10 - 20 degree higher than GPU, and this is acceptable.\n\nAs the review stated, the VRMs on our cards can take up to 150 degrees, I would say 90 degrees are no big deal. Sure if it's cooler then it's great but hey nothing is perfect, if we can't return it's not big deal.\n\nhttps://forums.tomshardware.com/threads/safe-gpu-vrm-temperature.1880490/\n\nAlso in the review, the MSI engineer checked and confirmed the temperature to be around 90, they as professionals think this is ok and expected, I trust that.\n\nLet's not worry too much because we should be more worried about our body temperature ;)"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "4070ti"
    ],
    "title": "Proud owner of 4070ti",
    "selftext": "From 6600xt to 4070ti on a 21:9 144hz monitor, i can definetly say this got me excited, I really hated the high price of nvidia, but this gpu got me excited for 780€ you get the 3090 and almost 3090ti performance. \n\nHaven't played with Ray tracing before, and didn't think it was that important but my single player games are that more exciting now because of it. \n\nNvidia gets a lot of slack because of pricing and what not (some deserved of course) but their products are top notch.",
    "comments": [
      "Also own a 4070ti. I am happy with the performance but I'm not proud of what I paid for it. I'm definitely not going to be upgrading for at least 4-5 years.",
      "780 euros for 3090 performance is fucking insane",
      "$1500.00 msrp.",
      "I'd have to agree. I also have some bittersweet feelings. Fantastic performance, not so fantastic price.",
      "Currently using the same card.  700 bucks open box at microcenter.  Zero coil whine, epic performance.",
      "Nice! I love my 4070 ti as well, enjoy it!!",
      "when it comes to buying PC hardware BF is hoax and has been for a decade now.",
      "And how much was the 3090 brand new?",
      "4070ti, there are dozens of us. But really enjoy the card.",
      "It's practically a 3090 ti with half vram, but half power draw the 3090 cost like 1200€, so for 780€ is a good price",
      "I didn't like that that 7900xtx was 1200 euros in my country and the 7900 is 950€ and 4070ti is very similar in Performance for much less money. So I went with it. It had a very nice discount. Also, a lot of folks say that this is best price to Performance card right now",
      "Yeah, let's ignore the 3080 and just focus on the much worse card instead, so that our purchase starts to make some sense.",
      "Jokes on you I'm a proud owner of an Nvidia quadro k600",
      "I have the 4070 and it’s fantastic. I couldn’t justify the extra money for the small performance increase to the ti. Both 4070 and the ti version are great cards. I’m maxing everything out at 1440p and frame gen is witchcraft",
      "6800XT performs similar to the 4070, not the 4070 Ti.",
      "Welcome to the 4070ti gang brother 😼😎 hope y9u enjoy it and it lasts long 🙏🏾",
      "Selling mine for $400'ish when 5000 series comes out.",
      "My personal reasons:\nThe performance is about the same, DLSS 3, the new architecture that supports AI, it requires almost half the wattages for it to perform about the same. It's cheaper",
      "4070 ti is better then 3080 by a fair margin",
      "3090 tdp is 350W while 4070ti is 280W, def not half."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "4070"
    ],
    "title": "4070 Drops to 549$ on Newegg",
    "selftext": "",
    "comments": [
      "You can all thank me for the upcoming price drops, I bought a 4070 yesterday",
      "Love my 4070 FE but this really should have been a $499 card, unless they went with 16GB gddr6x, which they didn't.",
      "Framegen, DLSS and RT are all worth the extra $100 over the 7800XT. \n\nYear over year, with DLSS and RT, most of the Nvidia cards since Turing have become more useful for the end user. \n\nMy 5700XT sitting in the corner of my dark, rejected PC parts closet is still just a shitty, overheating blower-fan mess.",
      "I believe it when it propagates to countries outside of NA",
      "You can’t put 16GB willy nilly onto a 192-bit bus card so it’s either 12GB or 24GB and they sure as hell don’t want the card lasting THAT long.",
      "Same",
      "I'm not sure if this helps but I bought a 4070 on Amazon two weeks ago. I checked my returns policy last night and I still had another two weeks to return if unhappy. I contacted Support and mentioned the difference of £60 over the course of two weeks and they said they don't offer a price match as such.\n\nI asked, what if I start a return, order a new one, then send the new one back in the place of the original return? They said I could do that, so I have a new one coming Sunday, to return to the Post Office down the road Monday, and I will be refunded at the original price of £589 and pay £529 from the new purchase, which will be the card going back to Amazon, because sense! And my initial 4070 stays in my desktop and continues to knock it out of the park!\n\nHonestly, things like this you can't make up...",
      "Shhh don't tell reddit that, they all say AMD is the best but we see those Steam Hardware Surveys lol",
      "By the time games require 24gb the raw compute of a 4070 wouldn't keep up anyway.\n\nWe already see this with the 4060Ti 8/16 variants. Once you crank settings up to use more than 8gb on that compute level, you're at unplayable fps anyway and the 16gb only serves to stabilize already bad fps and 1% lows.\n\nCompute and VRAM is a balance and you definitely don't want too little VRAM but you also don't want to pay for too much.",
      "Seriously tech subs on reddit often sound like a reverse userbenchmark.",
      "\\+ better power efficiency and less heat.",
      "Still 50$ over what it should be",
      ">I wouldn’t pay more than 299 for a 4070\n\n- Someone that bought a 4080.",
      "And AMD is really behind every AI innovation that Nvidia makes, people think they are going to catch up, but Nvidia keeps running away with better tech.\n\nI’m really happy that Ray Reconstruction is going to be available on all RTX gpus, gives a lot of credibility to Nvidia that we know that they aren’t artificially gating innovation from older cards.",
      "I got mine 2 weeks ago 😣",
      "Still 50$ over what it should be",
      "So tempting…buy I really don’t want to buy a card with less than 16 gb.",
      "You are making the mistake in thinking this is a true 70 class card.  It's a blatantly mislabeled 60 class card.  It needs to drop to $250 to be closer to what it's actually worth.\n\nDon't fall for Nvidia's deceit.  They are masters of deception.",
      "Maybe it’s because a 7900xtx isn’t a huge performance difference, in fact it out performs the 3080 outside of RT and is also $200 cheaper. It’s not as cut and dry as 4080 better card. Look at some benchmarks, the 7900XTX performs better on most games except things like Cyberpunk. \n\nI’d say you’d be a fool to throw away an extra $200 when you will get a smoother playing experience on the AMD GPU for less money outside RT. The 7900xt still performs decently well with RT compared to previous AMD GPUs. I know this is a Nvidia sub but come on man it’s not as clear cut of a thing as you and others in this thread are blasting",
      "o7"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "4070ti"
    ],
    "title": "RTX 3080 vs RTX 4070ti FPS benchmark",
    "selftext": "",
    "comments": [
      "I think you ran the test for the 4070Ti on lower texture resolution as the VRAM being used is lower.\n\nI recommend re running the rest with everything maxed out or near to what you did with the 3080.\n\nI have a 3080Ti with a 5800X3D and I got 106fps everything cranked to max with no DLSS etc",
      "Driver version is also different. May not make a significant difference, but it’s another variable in the comparison that should be eliminated￼.",
      "So outdated driver for 3080, different higher vram usage for 3080. Seems like someone wanted one card to look better.",
      "Refresh rate set at auto with the 4070ti instead of 144 like the 3080",
      "For real. Also, 1440p running DLSS on performance mode, why?",
      "For sure you should upgrade your CPU.... \n\nI have a 3080, can you please benchmark other games as well? Overall, there seems to be about a 20 to 25% difference between 3080 vs 4070ti?",
      "Gap would be even larger with a better cpu too wow",
      "- different driver\n- different texture settings\n- refresh rate limited with 3080\n\nYeah this \"benchmark\" is super shitty and probably manipulated to make the 4070Ti look better than it is.",
      "What about pairing a 4070ti with a 5 gen old 6 core",
      "Nvidia drivers were really shitty for MW2 on release. I don't know what version that was though.",
      "Just go read actual reviews of the 4070Ti. There are plenty of comparisons to 3080 that aren't butchered like this post is. (i.e. same driver version and settings as a bare minimum). It's about a 15% difference in favor of the 4070Ti but 4K performance is less impressive because of the memory bandwidth constraints.",
      "Glad it works for you.. I didnt pay all this money to play at 720p though :)",
      "VRAM usage is a terrible way to dictate the texture resolution. A ton of factors are played into memory usage, the 4070 ti could simply handle the memory/textures more efficiently as 1 of those many reasons.",
      "So this is a completely trash benchmark, those are two hugely different circumstances.",
      "To get an accurate test result you need to max everything out on both gpus and have updated drivers also. Come on man.",
      ">what CPU would you recommend i move to (will have to change the motherboard to accommodate it too but thats fine)\n\nWait for the 7xxxX3D series CPU's to launch and be reviewed and then decide. Might be good deals on the 5800X3D if the 7 series 3D CPU's aren't substantially better or cost too much.",
      "Lots of issues with this benchmark. One in particular being you didn't enable DLSS on the 3080, but did so with 4070 Ti.\n\nThe benchmarks are already out there so im not sure if you're trying to make 4070 Ti look massively superior than it should to justify the purchase or your testing methodology needs work.",
      "Then don't publish benchmarks if you're not going to do it properly, because as it stands, this isn't helpful.\n\nDelete this post and video, get it right, and try again.",
      "That is not how it works, you don't spend $800 to upgrade from 3080 to 4070ti. One guy posted in this subreddit and said he spent $60. His post is still on the frontpage I think. You might not get that lucky, but you usually won't spend more then $200",
      "You are massively CPU bound and leaving a ton of performance on the table with that 9600k"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "4070"
    ],
    "title": "[Gamers Nexus] NVIDIA GeForce RTX 4070 Ti Super GPU Review & Benchmarks: Power Efficiency & Gaming",
    "selftext": "",
    "comments": [
      "Man, all that hype of the 4070 ti super being the one to buy, falls off a cliff. The overhype was real.",
      "I think people were drinking the reddit koolaid too much and obsessing over things like memory bandwidth and theoretical future proofing when the actual limiting factor of the 4070ti non sooper was it's compute power.",
      "Now we'll just have to see about 4080 super since they said this gpu is \"meh\" in their view, not terrible but also not great.",
      "reviewers: \"4070 ti would be great with more vram\"\n\nnvidia: \"ok here's 4070ti with more vram at the same price\"\n\nreviewers: \"meh\"",
      "Even if 4080s is like 3%faster, at least it got a pretty big price drop and still has a good lead over 4070 ti super.",
      "price dropped from stupid expensive to super expensive",
      "At $50-100 cheaper I would agree strongly. These cards need to be cheaper across the board.",
      "there is pretty much no card you can launch nowadays that someone's not gonna say \"but it needs to be $50-100 cheaper!\".  people said it before super, super dropped the prices, people say it after super just like it never even happened.  if you push the 4070 down to $500 people are gonna say it needs to be $399, etc.\n\n[people just aren't used to the world where there is virtually no perf/$ gain from shrinking nodes anymore, and actually this is starting to eat into vendor margins despite soaring prices.](https://www.tomshardware.com/tech-industry/newer-chips-are-rapidly-becoming-far-more-expensive-tsmcs-average-wafer-price-jumped-22-in-one-year-and-nearly-all-semiconductor-industry-growth-now-comes-from-more-expensive-products)  \n\n> Indeed, the increased prices on wafers processed on the latest nodes largely contributed to almost all of the semiconductor industry growth in recent years, according to Stacy Rasgon, a senior analyst of U.S. Semiconductors and Semiconductor Capital Equipment at Bernstein Research.\n\n> \"How much has [wafer] pricing contributed to semiconductor industry growth in recent years,\" Rasgon rhetorically asked in an X post. \"Would you be surprised to learn the answer is 'More than all of it?\"\n\nsomewhat surprising to many people, but [NVIDIA's operating margins in 2023 were ~half of what they were in 2018,](https://i.imgur.com/KP6fClJ.png) at least until AI/ML took off.  Ada is just that much more expensive to make and it all comes back to TSMC and the rising costs of continued shrinks.  \n\nLike you know what company's revenue and margins have never dipped for even a single quarter?  TSMC.  Monotonically upwards.  And it's not like R&D or validation gets any easier either.",
      "Disappointing. 4080 Super is looking to be the one for me. Pretty excited to get a new GPU after 7 years.",
      "I’d say the rhetoric around VRAM is overblown too. People toss it around as a slight against NVIDIA cards without regard as to whether a card actually needs as much as they claim.",
      "Still have a 3070, can confirm it needs more ram, ultimately that was the most disappointing aspect of the product. To the point where I am considering just selling it rather than using it in my wife's PC.\n\nMy 4090 does not need more Ram.",
      "lol Exactly. People on here also laser focus on VRAM, when it's very rarely the limiting factor. You can't \"future proof\" your GPU purchases. You can have all the VRAM in the world, but the GPU will lack in throughput before VRAM legitimately crops up as an issue.",
      "I've been saying for months that this card might be a bit of a letdown in terms of performance jump over 4070Ti. The increase in core count is pretty marginal and the memory upgrade is nice but really only makes a noticeable difference at 4K.\n\nReddit love to talk up VRAM and memory bus/bandwidth all the time like it's the end all be all of GPUs, but in reality most of the time it doesn't make a huge difference until you  start maxing games out at 4K.",
      "4070S, strong value\n\n4070TIS, if you value 16gb, it's great. At MSRP it's nice.\n\n4080S, a nice price drop on a decently strong card. It's no 4090 but it doesn't have to be.",
      "Pretty sure they haven’t lost anything, more like they gained $600+ from you. People will buy the overpriced ones regardless.",
      "Gotta hand it to them, they've read the feedback and added back at least the most relevant benchmark to see where the cards lie on the spectrum of modern RT gaming, and tested Cyberpunk in a variety of settings that is larger than what I had anticipated/expected  \n\n\nI wish they tested one 3000 series card for scale (like the original 10gigs 3080) but it's fine like this, the 4070ti non-super is a decent stand-in if one goes back and compares",
      "4070ti 16GB. What a let down. But what were you expecting? \n\n\n99% of 4080 for $800. Ha!! You thought nVidia would just suddenly give 4080 away?",
      "Launched December 13, 2022\n\nI would say it's overdue for a price drop",
      "Yeah VRAM isn't what gives it performance, but VRAM is something you want more of then not enough of. I think the case could be made that 12GB doesn't age well for 4k players as we go into 2024 and 2025 game releases. I myself have hit a couple games which needed more than the 12GB on my 3080 Ti and that was with DLSS on my 4k C1. I don't think it was unreasonable to ask for 16GB on a $800+ card.\n\nThat said, the core count definitely pointed to this card being closer in performance to the 4070 Ti than the 4080. So this isn't exactly a shocking outcome.",
      "He means a price drop from the regular 4080. Here in Norway, it is 250 dollars less for the cheapest one"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "4070"
    ],
    "title": "DLSS vs. FSR Performance, GeForce RTX 4070 Ti vs. Radeon RX 7900 XT",
    "selftext": "",
    "comments": [
      "Lets see how redditors react to this after getting proven wrong, surely they'll admit that they are wrong.",
      "Surelyyyyyyyyyyyy, its not like 90% of people on this sub (where this topic was originally discussed) are just gamers talking about technologies they know nothing about and pulling information out of their ass and not actually working in the industry. Im expecting all of them to write super nice comments and admit they're wrong.  \n\n\naware",
      "Proving the clowns wrong again, that's what I like to see.",
      "they are also the only few that expose Nvidia higher driver overhead when compared to AMD. \n\nThat issue seems to get buried under other bigger news. I wish we get bigger highlight on this, so Nvidia go back and rewrite their driver to be more efficient.",
      "Everyone knows the absolutely open minded reddit community lol",
      "FSR and DLSS have identical performance at the same base resolutions upscaled so they used FSR to do a direct comparison in their original video. This video showed multiple benchmarks proving that the performance is the same. For future comparisons or major benchmarking videos they will do native resolution only and leave upscaling results to a specific section of product reviews.",
      "Lmao if they used DLSS like how some people here suggested Nvidia GPU would've been at a disadvantage, since their method favors Nvidia maybe haters here in Reddit should call the hub Nvidia Unboxed instead of Amd Unboxed.",
      "I don’t understand how anyone calls them biased, them and Gamers Nexus are about as objective as you can get. This sub and the AMD sub, or just fanboys in general, can be absolute morons at times.",
      "This reminds me of the whole Doom Eternal OST album. Nobody complained about it, until someone said it was terribly compressed, then everybody started saying the same thing like they knew what it meant.",
      "that's kinda where i'm at. i understand the desire to \"level the playing field\" in vendor comparisons, and it's undoubtably a lot of work to do every flavour for benchmarks, but if i'm using an nvidia card i'm gonna use DLSS when it's available basically 100% of the time and ultimately i think benchmarks should reflect how the consumer would use the device.",
      "Dunno why everybody thinks they are amd biased. Look at their 7900XT(X) Reviews, especially their thumbnails. I swapped my 6700XT to a 4070ti after watching mostly their content and i didn't feel like there is a bias in any direction. And i used FSR2 for the last year as well as DLSS2 now and i don't see much of a difference, so i don't mind using FSR2 in Benchmarks, if it is clear, that it doesn't favour any brand.",
      "Whenever I turn on FSR 2 on it's max quality settings the image looks blurry.\n\nWhenever I turn DLSS on on either quality or balanced the image looks like native with extra performance.",
      "This is my test result on an RTX 3080, all tests use 1440P ray tracing DLSS2 and FSR2 quality mode, use the original DLSS DLL that comes with the game, use ultra ray tracing to achieve 99%-100% gpu usage to avoid cpu bottlenecks, and screenshot the same static game area to avoid dynamic scene changes resulting in performance differences.  \n  \nCyberpunk 2077       DLSS2 85fps    FSR2 83fps   https://imgsli.com/MTY1MTg0  \n  \nHOGWARTS LEGACY  DLSS2 104fps  FSR2 98fps   https://imgsli.com/MTY1MTg4  \n  \nMarvel's Spider-Man  DLSS2 130fps  FSR2 127fps https://imgsli.com/MTY1MTkx  \n  \nThe Witcher 3           DLSS2 63fps    FSR2 62fps   https://imgsli.com/MTY1MTky  \n  \nGod of War               DLSS2 132fps  FSR2 127fps https://imgsli.com/MTY1MTk1  \n\nHow come the results of these games I tested so far are opposite to this video? from my tests, although the performance gap in these games is not big, in general DLSS2 still has a performance advantage over FSR2, not to even mention the obvious difference in visual quality.  \nAdd Cyberpunk 2077 in-game benchmark results:  \nAverage FPS results using 1440P ultra ray tracing settings: DLSS2 quality 71.51 FSR2 quality 70.19 https://imgsli.com/MTY1MjYy",
      "I was commenting on the original post and getting down voted to hell trying to explain to people why you want benchmarks between GPUs to use the same settings and people just were NOT getting it. They just couldn't comprehend why you'd want to use the exact same software settings to compare hardware.\n\nGlad hub is clearing things up. They've never been biased and this subs attitude towards them is just plain sad. Just because they don't lick Nvidia's boots on the daily like some people here do does not mean they're AMD shills lmao.",
      "> it’s the people making the who are clearly the biased fanboys, not Steve. \n\nthank you. Ive been trying to give hints under those comments without being too obvious so I dont get banned, but people, you gotta look at who is making the comment. The most prolific fanboys (nvidia, intel, or amd) are not very sneaky about it. Even the people in their favorite company's subs are annoyed with them.",
      "You whipped out your thesaurus to be confidently incorrect. First off they mentioned DLSS 2.5.1. So not sure where you're even getting frame generation from.\n\nEven if they said the newest DLSS 3.1.11 it's still just normal DLSS.\n\n\nDLSS frame gen is it's own completely separate thing. May as well not even have DLSS in its name and only called frame generation. It's a separate option in menus, with a separate dll, and a separate purpose. \n\n\n\nEven then. All frames are fake. The only distinction is where you arbitrarily draw the line in the sand.",
      "Wait didnt in the original reddit thread is just that people wanted them to do both or just none at all? (which they did the latter anyways.) \n\nJust the few were screaming about DLSS being faster (when it's main benefit is the better graphics quality you get on all levels even down to ultra performance mode compared to FSR.)",
      "FSR on 4070ti is faster in Witcher 3, in F1 22 (**by 10%),** Atomic Heart. But whatever.",
      "yes, its a shocker that testing technology in it's first iteration, 1 year ago, is slower than the competing product that at the time was already 2 years old.\n\nSo now the reviewer should look back at the data from a year ago and own up the mistake. The brain gymnastics",
      "FSR2 is literally neck and neck with DLSS 2.4 and even has better performance in some of the games in the video though? What video did you watch?"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "4070ti"
    ],
    "title": "Cyberpunk performance on 4070Ti Super OC + 14700k",
    "selftext": "I overclocked the dual fan ventus because on stock it was getting to only 65 degrees celsius max! Clock: +150 Memory:+950 stock power",
    "comments": [
      "I'm mean that cool and all but I'm pretty sure I can average 9.6 FPS with my 3060 with the same settings.",
      "Yall think a 30hz monitor overkill for that 9.6 fps?",
      "This is with path tracing activated, the most taxing raytracing available.",
      "Don’t suppose you’ve been able to test 4K?",
      "I always find it so wholesome and cute to see someone test their new GPU. Enjoy it mate.",
      "THIS is the reason why I say we’re not ready for 4k yet.",
      "Because people want to maximize visuals and performance at the same time. Frame generation might be AI but it 100% works well.",
      "This is with path tracing",
      "Turn on path tracing now and then compare :)",
      "I’m so jealous of you 4000 series owners. Holding off on playing Phantom Liberty until I get a 5090 so I can pump it to the max and really be blown away with the graphics path tracing offers. Tried the FG mod on my 3080 and at 1440p it’s ok, but feels like having major frame pacing issues.",
      "Nice. I went for dlaa and Raytracing psycho instead of dlss quality and Pathtracing. Dlaa makes details in the game look so much better imo. Give it a try.",
      "sub 1080p actually",
      "Bro got cooked he didnt deserve this 😭",
      "Getting ~65fps for the benchmark on 4k ultra with the same card paired with ryzen 7600",
      "Highly dependent on your settings. Guy there posted 83 frames with his 4070Ti, I get 50ish with a 4090.\n\nThis \"test\" is pretty much entirely meaningless unless you're comparing against the exact same settings across the board.",
      "I agree. 1440p high refresh rate is still demanding even for powerful Gpus like 4070Ti Super.\n\nWe need more power for 4k.",
      "This is 1440p",
      "keep dreaming this is path traced",
      "Did you read that as 96? Because honestly I was getting disappointed that noone that responded had fell for my decimal point joke.",
      "I completely disagree. It’s not just a style change. The lighting and shadows on the world and character models completely makes the game feel more alive."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "4070",
      "4070ti"
    ],
    "title": "NVIDIA GeForce RTX 4070 SUPER fills the 4070/4070Ti gap in first leaked benchmarks - VideoCardz.com",
    "selftext": "",
    "comments": [
      "That's a lot of cards!",
      "Waiting for 5000 cards",
      "It is slightly closer to the 4070Ti than to the 4070, so that is plus. But eventually, it comes down to pricing. For $600 it would be a good deal, but my guess is that it will sell for $700. Nvidia is doing extremely well as it is, they aren't that desperate to sell GPU for gamers at a bargain.",
      "so nothing impressive.. not sure why people even wait for the super variants",
      "I hate that we call $600 for x70 class GPUs a good deal now",
      "The 4070 Ti Super is the star of the lineup, it gets a VRAM bump over the 4070 Ti and looks to be very close to a 4080 for a lower price.\n\nThe 4070 Super and particularly the 4080 Super are less interesting.",
      "Whether any of these cards become interesting or not will come down to price.",
      "The 4070 is like a 3080 12GB, the 4070 Super is closer to the 3080Ti",
      "Do gpus ever make sense? So many times overpriced, just because.",
      "4070 already came down to 500-550$ when there are deals. So this card needs to be 600$ to make any sense",
      "These same exact conversations took place when RTX 4000 rumors were flying. \n\nIts all noise, no signal :p",
      "So the 4070super will be like a 3080 12 gb with frame gen",
      "That's great and all, but I think I'll just keep buying second-hand previous gen cards when the new ones come out because the prices are fucking stupid.",
      "At only $999 each! The more you buy, the more you save!",
      "As someone who has a 3070 and it still does a pretty good job at 1440p, I'm gonna wait for a 5070.",
      "Would buy a 4070 Super instantly if it had 16 GB.",
      ">so nothing impressive\n\n??? it's between 4070 and 4070 Ti, it's not supposed to be better than RTX 4090 or whatever you were expecting\n\nWe still don't know the pricing.\n\n>not sure why people even wait for the super variants\n\nWell, let's see... Perhaps people are waiting for the SUPER variants to be announced with the pricing so that they can make an informed decision to get the best bang for their buck?\n\nA little patience can pay off so close to the announcement. Crazy, I know.",
      "Considering RTX 5000 is still rumoured for the end of the year, unless you have to build right this second it definitely makes sense to wait. The performance increase will be *substantially* more than for these cards.",
      "Now we need 2 new gpus to fill these huge gaps.",
      "Uhm 4070 already is a 3080 12GB with frame gen. \n\nSuper is a 3080ti."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "4070"
    ],
    "title": "Kopite : RTX 4080 will use AD103 chips, built with 16G GDDR6X, have a similar TGP to GA102. RTX 4070 will use AD104 chips, built with 12G GDDR6, 300W.",
    "selftext": "",
    "comments": [
      "300 fuckin watts...",
      "Damn that power creep is real. 4070 will be using about 30% more power than previous generation. 230w -> 300w. Considering the 3070 is one of the most efficient GPUs ever in terms of performance per watt (only eclipsed by the 6700XT), it'll be interesting to see if the raw performance gains keeps it that way relative to power draw, or if this is going to be a brute force way at performance without regard for efficiency.",
      "Yep, it's pretty stupid.",
      "Nvidia designates the generation and tier/size of a chip with that name scheme.\n\nAD = Ada, the codename for next generation as (GA is to Ampere for this generation)\n\nThe largest chip is the 100, then usually 102, 103, 104, 106, 107\n\nThis generation the 3090 Ti through the 3080 use GA102. The 3070 Ti through 3060 Ti use GA104. The 3060 and 3050 use GA106.\n\nJaidon is saying boo because it suggests that the 4080 will be further from the best than the 3080 is from the 3090 Ti",
      "yah 16gb. boo AD103",
      "Ad103 is fine.\n\nThe spec ga102 used in the 3080 10 gb is almost in between the full ga104 and ga102 anyway\n\nGA 102 Full -  10752 cores / 84 SM / 336 TMU / 112 ROPs\n\nGA102 3080 10 GB - 8704 / 68  / 272 / 96\n\nGA104 full - 6144 / 48 / 192 / 96",
      "Better be a big ass upgrade over GA102… 300w isn’t that good tbh if you consider the node improvement.",
      "That will depend heavily on the power draw behavior of the card, which obviously we don't know yet. \n\nMuch of the requirement for oversized power supplies with Ampere cards is due to their tendency to create very short very high power  transients, which can exceed the capability of the power supply's output filtering capacitors.",
      "So... will an 850W PSU be enough for the 4080?\n\nEdit: The reason I asked about the 850W specifically is because it has been regarded as the best value option for most people in the last/current generation, so this is what most people (including me) bought. Getting a new PSU after paying good money for a 850W would suck.",
      "Whoa its not 8gb!",
      "Top end 3070’s can easily use 240/250 watts. Taking away the extra power needed for the added GDDR on board it really isn’t that much of a huge jump from the last gen…\nAlso let’s wait and see the performance difference. Might be 300 watts but a 30/40% jump in perf…",
      "It's fine, but disappointing, given the huge difference between the AD102 and AD102 dies. I have a feeling the crazy performance increase will be reserved for the 4090 card.",
      "They have to leave enough room for the 4080TI between the 4080 and 4090. One of the issues with the 30 series was that the higher end cards all started cannibalizing each other because they're all within 5% of each other. \n\nThis is the way it was before the 30 series and that trend should've continued with the 30 series.",
      "Not really. 300w is 300w, independent of performance.",
      "300W for a xx70 card? Jesus that a lot of juice.",
      "Oh so the new AMD cards are *that* good hm?\n\nWe customers really need to emphasis that we no longer care *just* about best performance but also power consumption. Nvidia and AMD are both running their cards way past the sweet spot just to outdo each other. Both cards would probably consume just 50% of the power at 90% of the performance if they really wanted to.",
      "Praise to the lords of Nvidia for blessing us with double VRAM!\n\n/s",
      "Uhhhh if the leaks and rumors are true, then matching 3090 performance at 300w is pretty crap considering they are reportedly switching from Samsung 8nm to TSMC 5nm (or maybe even 4nm). I guess they will just compare it to the 3090ti and claim how much of an efficiency improvement that is. Also praying that 4080 is “just” 400w…",
      "Not too impressed by the 4080 using only a 103 chip. 102 has like 70% more cuda cores.  \n\n\n4080 to 4090 will probably be as distant in performance as 3070 to 3080 this gen, even more.",
      "Well, they have to make room for the inevitable 4095ti or whatever."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "4070",
      "4070ti"
    ],
    "title": "NVIDIA RTX 4080 SUPER and RTX 4070Ti SUPER to feature AD103 GPU, RTX 4070 SUPER gets AD104 - VideoCardz.com",
    "selftext": "",
    "comments": [
      "$1100 it is then!",
      "How about some reasonable prices",
      "Looks like its not going to be a cut down 4090 after all. 4090 is AD102. May not be as powerful as previous rumors suggested.",
      "Still bummed we aren't getting a 4080Ti on a AD102 die with like 20GB VRAM and a larger bump in cores. That would be a no brainer upgrade for me at that point.\n\nAs it stands I'll probably wait and see what the pricing is on the 4080S and maybe get one next year.",
      "Ti Super lol",
      "The rumored 16GB VRAM capacity was a telltale sign anyone could see from a mile away, they'd be cutting from 384bit all the way down to 256bit, that's a HUGE waste of die space.",
      "You’re asking a little too much from Nvidia with that reasonable price nonsense/s",
      "Meh,   \n50 series it is.",
      ">4080 Ti for $699 is the level of performance I need to upgrade.\n\nthat is also just unrealistic.",
      "4080 Ti for $699 is the level of performance I need to upgrade. \n\nSeems like I'll be waiting another 2-4 years. LOL",
      "Back in the days they replaced the RTX 2080 with the 2080 Super at same price point.",
      "So gutted. Bought a 4070ti 2 months ago. I'd of waited if I knew for the 16gb",
      "4070 at 499. Doubt.",
      "4070 Ti Super looking good. Will definitely be picking one up even if it does have a stupid name.",
      "So 4070Ti bascially becomes a 4080 at a reduced price? Pretty solid card until RTX 50 series in 1-2 years.",
      "AMD just doesn't cut it for people who need CUDA and/or Raytracing for workstation tasks.",
      "And the same measly 5% increase.",
      "Currently? Sure but he said 2 to 4 years which isn't unreasonable.",
      "TLDR: cards looks good, with good prices, it can save everything (\"go 4090 or nothing\"), if prices are bad, nothing changes",
      "12GB of VRAM on $600 card is just pathetic."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "4070"
    ],
    "title": "NVIDIA GeForce RTX 4070 matches GeForce RTX 3080 in leaked tests - VideoCardz.com",
    "selftext": "",
    "comments": [
      "Not wanting to spend $600 for a 60-tier product doesn’t make you dirt poor. This generation sucks, period.",
      "What I hate about the new cards apart from the absurd rise in prices is the fact that across the board the memory buses are so small compared to the 3000 series",
      "In other news, the floor is made of floor.",
      "Could just buy a used 3090 for that much. It'd also have 24gb of VRAM vs 12 from the 4070.",
      "I m wondering what will be the 4060 and 4060 ti… \n4060 =3060ti and 4060ti =3070… \nWorst card generation ever",
      "Disgusting, the x70 is always equivalent to the X80Ti. Hike the price and make it worse value than previous gen. \r  \n\r  \n780ti = 970\r  \n980ti = 1070\r  \n1080ti \\~ 2070\r  \n2080ti \\~ 3070\n\nIt's a 3080 for $600, no one is buying this, especially with the 'low' VRAM.",
      "3070 gave 2080 Ti performance for 700$ less. 4070 does not give 3080 Ti performance, but 3080 performance at only 100$ less than the original 3080s MSRP lol",
      "People normalizing ridiculous prices, please stop this behavior.",
      "This is out of touch with the reality of the market over the past two/three years\n\nFor the vast majority of people (If you didn't get an FE) a 3080 was $1200+, for pretty much all of it's life it has never been a $700 product\n\nLook on the used market now, 3080s are $450 - 550, and that's for 10gb models, without FG as a selling point (And the loss of 2gb of VRAM)\n\nThe reality is, this card will be extremely popular at $600 (And I'll be surprised if it doesn't shoot up to $700)",
      "So. \n\nNot 1 dollar cheaper.\nNot 1 bit faster.\n\nZero progress. G. G.",
      "2070 is not a 1080ti.",
      "and thats why the initial 20 series was so poorly received.\n\n2070 super matched the 1080ti roughly (and then overtaken it in more modern titles) and was priced the same as the 2070 ($499)",
      "For only a lite price of 999$ \n\nAnd yes thats the cost in my country",
      "Everything they said is true though. \n\nThe prices suck and nobody is denying that, but the 3080 was never sold at MSRP apart from a very lucky few.",
      "2070 Super or 2080 was close to the 1080 ti, not the 2070. RTX 20 series was incredibly overpriced.",
      "I know from that post alone, that the person behind the username is absolutely dogshit with money and isn't a very nice person.",
      "Not good enough.",
      "Interesting sure. But those are software assists whose dev costs will be spread out across GPUs for generations to come. As for the reasoning behind the cost of the 40 series. I see none in raw perf metrics as far as price/perf goes. Without assists these cards are an efficiency boost w similar perf for usually a worse price.",
      "It has 12GB, which is what should be the minimum for budget cards. This should’ve had 16GB tbh.",
      "Nvidia is pretty much playing a \"monopoly\" here with their GPU prices/FPS."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "4070"
    ],
    "title": "NVIDIA rumored to be preparing GeForce RTX 4080/4070 SUPER graphics cards - VideoCardz.com",
    "selftext": "",
    "comments": [
      "Will there be a 4070 Ti Super TI?",
      "4070 Super Titi",
      "Meh. I doubt they'll be at a better price point than existing cards.",
      "4070 super sweet spot if 16GB",
      "Hey! I’m sure they’ll put the price of the other cards up so they at least look lower priced",
      "Nah bro I prefer 4070 super TiTis.",
      "OOOOF. Would much rather have a 16GB 4070 Ti Super than my current 4070 Ti",
      "Super 4070 Super Ti²",
      "They didn’t? There is no 2170 super",
      "3090ti was released half a year before the 4000 series. There’s no rhyme or reason to Nvidia’s release schedule.",
      "The current cards are not selling well according to distributors and havent been with the exception of the 4090.\n\nThis is the same strategy as the 20 series where they way over valued their products. \n\nWhat they will do is release the super at the current price points and lower the old models to clear stock or hope to.",
      "Just as I bought a 4070.\n\nListen people, FOMO is right and you should always wait for the next big thing! Learn from my mistakes.\n\n/s",
      "That Twitter account was the one that leaked the 4060ti 16gb before anyone ever mentioned. And then leaked the date and price correctly in a later tweet.\n\nhttps://twitter.com/hongxing2020/status/1655768882320375808?t=NjoQaXGgd9qbFsx-nnxspg&s=19\n\nAlso Kop said there was no news yet last time he tweeted, didn't definitively say that there won't be a refresh.",
      "I just prefer super tits",
      "Well I mean, they haven’t been stopped from giving higher VRAM to worse cards before.",
      "And when you bought rtx 4070super then 1 year later they release rtx 5070 with 50% more powerful and you keep telling that buying rtx 4070s was mistake too .",
      "This has to be a joke",
      "The 3060 coming with more VRAM than the 3080 was a head scratcher",
      "Kopeit said there is no refresh , so this article is just click bait .",
      "Historically the super versions have been worse than the Ti versions. I'd be happily surprised if it was more than 12gb."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "4070"
    ],
    "title": "Nvidia RTX 4070 with slower GDDR6 memory is on the way, according to rumors",
    "selftext": "",
    "comments": [
      "Jensen has clearly finger on the pulse and knows that inferior version of 2022 product is exactly what we are all after in Q3 2024.",
      "Up next: RTX 5070 with 7.5GB GDDR5, cuda core configuration similar to RTX 4060 Ti, beats it by 5% on average. But it costs only $400 more!",
      "Waiting for RTX 4050 with DDR3",
      "Yeah prices are already shit, at least don't make products worse.",
      "Why are there so many version of each card?\n\nI have a 4070ti and now there are like 4 different 4070s amd I can't tell you which is the best one.",
      "Nvidia originally wanted to name one of them RTX 4080 12GB, but became a 4070 Ti after backlash.",
      "Well, AMD just re-released a 2020 CPU for 20 bucks less than said 2020 CPU. Can't beat that",
      "It's all about price. If they want to sell a hamstrung GPU at the right price, I'll bite.\n\nIf the 4070 was $400, I'd have bought one two years ago.",
      "The more you buy, the more you save!",
      "Google the 5900XT.\n\n(Hint: it's just a bad bin 5950X)",
      "It is coming EoY but will be called GT 4030.",
      "The name is insane. 4070 ti super? Or as gamers nexus says, 4070 tissupper",
      "“TI” and “super” both are used by nvidia to indicate a faster version of the card. It’s like calling it a 4070 fast fast. Or a Camry xle, a Camry xle xlt",
      "Mom should I buy a 4080 super now or wait for the new slower 4070?",
      "RT 4030* because it will have a single RT core",
      "4070 ti super is the best one, it uses a cut down 4080 die, the rest are various configurations/qualities of the 4070 die",
      "so there is a problem",
      "Ah they are doing the xt line move again like with the 3xxx series.",
      "I was a fan of Nvidia, but with my 3070 being bottlenecked on VRAM, there are frankly no reasonable upgrade options within nvidia. Even a secondhand 3080 to only has 12GB for about the same price as a brand-new RX 7900 GRE which has similar power but 16GB. And if I wanted even more VRAM, the RX7900 XT is an option too.\n\nNvidia really dropped the VRAM ball.",
      "well, it's kinda different. A \"true XT\" would be just a better binned of the same model numbering or the one immediately AFTER it. So the 5800XT would be a nicer 8 core part than the 5700, 5700X or 5800X. Much like the 3800XT was just a better 8 core part.\n\nThis year, WE'RE GETTING TWO MORE CORES (than the 5900X)!!!!111\n\nI have absolutely no idea why they didn't just name this a 5950 (non-X). Or even, hell, a 5930X if they REALLY wanted to keep that X."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "4070",
      "4070ti"
    ],
    "title": "RTX 4070 Ti Super Launch Thread",
    "selftext": "**What**: GeForce RTX 4070 Ti Super Launch Day\n\n**When**: Wednesday, January 24, 2024 at 9am Eastern Time\n\n**Protocol**:\n\n* **Subreddit may go on restricted mode for a number of times during the next 24 hours. This may last a few minutes to a few hours depending on the influx of content.**\n* This **Launch Day Megathread** will serve as the hub for discussion regarding various launchday madness. Thread will be sorted by \"new\"\n* [You can also join our Discord server for discussion!](https://discord.gg/nvidia)\n* Topics that should be in Megathread include:\n   * Sharing your successful order\n   * Sharing your non successful order\n   * Sharing your Brick & Mortar store experience\n   * Discussion regarding stock\n   * Any questions regarding orders and availability\n   * Any discussion regarding what you plan to use your new GPU for\n   * Any discussion about how you're happy because you get one\n   * Any discussion about how you're mad because you didn't get one\n* **Any standalone launch day related posts will be removed.**\n\n**Reference Info:**\n\n# [RTX 4070 Ti Super Announcement Megathread](https://new.reddit.com/r/nvidia/comments/191pdus/megathread_geforce_at_ces_super_gpus_rtx_games/)\n\n# [RTX 4070 Ti Super Review Megathread](https://www.reddit.com/r/nvidia/comments/19e24bk/geforce_rtx_4070_ti_super_review_megathread/)\n\n# [\\[PSA\\] Certain MSI GeForce RTX 4070 Ti Super Ventus 3X VBIOS Causes Lower Performance Than Expected](https://reddit.com/r/nvidia/comments/19dq7le/psa_certain_msi_geforce_rtx_4070_ti_super_ventus/)\n\n**Links to various RTX 4070 Ti Super Models:**\n\n# US:\n\n* [Newegg](https://www.newegg.com/p/pl?d=4070+Ti+Super&Order=1&N=601432392%20100007709)\n* [Best Buy](https://www.bestbuy.com/site/searchpage.jsp?_dyncharset=UTF-8&browsedCategory=abcat0507002&id=pcat17071&iht=n&ks=960&list=y&qp=gpusv_facet%3DGraphics%20Processing%20Unit%20(GPU)~NVIDIA%20GeForce%20RTX%204070%20Ti%20SUPER&sc=Global&sp=%2Bcurrentprice%20skuidsaas&st=categoryid%24abcat0507002&type=page&usc=All%20Categories)\n\n# Canada\n\n* [Newegg Canada](https://www.newegg.ca/p/pl?N=100007708%20601432392&Order=1)\n* [Best Buy Canada](https://www.bestbuy.ca/en-ca/collection/rtx-4070ti-super-series-graphic-cards/475706?sort=priceLowToHigh)\n\n# UK\n\n* [Scan UK](https://www.scan.co.uk/shop/gaming/gpu-nvidia-gaming/geforce-4070-ti-super-graphics-cards)\n* [OCUK](https://www.overclockers.co.uk/pc-components/graphics-cards/nvidia-graphics-cards/nvidia-geforce-rtx-4070-ti-super-graphics-cards?sort=price_asc)",
    "comments": [
      "Ironically, on the launch of this model, I was able to snag the 4090 FE at MSRP. Thanks 4070 Ti Super!",
      "[https://www.techpowerup.com/review/asus-geforce-rtx-4070-ti-super-tuf/32.html](https://www.techpowerup.com/review/asus-geforce-rtx-4070-ti-super-tuf/32.html)\n\nLooking at benchmark averages the performance gap between a 4070ti Super and 4080 Super is probably going to be around the same as the gap between 4070 Super and 4070ti Super. I just don't see how people are getting better value proposition out of the 4080 Super. Yea, compared to the $1200 4080 it's great, but for the Supers you're getting around the same boost in raster without the 4GB of VRAM for the same price bump. I think it's easier to justify the $200 for the 70ti Super from the 70 Super over $200 more for the 4080 Super, tbh.",
      "For anyone shopping amazon, their search sucks, but here's a link to Asus tuf msrp with overnight prime shipping\n\nhttps://www.amazon.com/gp/aw/d/B0CQPXJFND?ref=ppx_pt2_mob_b_prod_image",
      "I like how I was put on the list with Best Buy to be notified when they go on sale. They sell out and I still haven't even gotten an email that they are available. I'm going to make a post in r/conspiracy.",
      "And nvidia thanks you. 😂",
      "Be nice, he edited.",
      "Yeah, I also don't get this. It's a pretty linear progression in price/performance up the stack. You can always argue \"but the 4080 Super is faster at a little more money\", but the 4070 Super is also a little slower for a little less. And the 4070 non-Super is a little slower yet, for less.\n\nI could have gotten a 4080 or 4080 Super if I wanted, the extra money isn't really a big factor, the Ti Super just happened to come in around what I wanted to spend this time around. If the 4080 Super was like 20% faster for 5% more, sure but there doesn't seem to be any GPU in nVidia's stack that gives you a huge performance for a small increase. (At least not from the x70 and up)\n\n(And I'm wary of the kind of creep where you talk yourself into \"just $100 more\" up the tree, until suddenly you wanted to spend $500, but ended up spending $1000. :P)",
      "In Europe a good 4070 Ti Super like an MSI Gaming X Slim costs 999€, that’s insane for a 70 class GPU, that’s scalper/pandemic prices, I will not give in.",
      "I'll be picking a 4080 Super up next week from Scan. Seeing as it's basically on my doorstep. Going from a 3070Ti. Only reason I'm doing it is because my son needs a GPU and doesn't have the money. So he gets my 3070Ti for free.",
      "I think it's more of a lukewarm reception where, when you're paying $800+ for a graphics card, you're in the territory in which it may be easier to feel that you may as well \"just\" spend another $200 and get a 4080 Super. That price gap also used to be $400 with the original 4080 MSRP.\n\n\nThe 4070 Ti Super isn't a bad product, but I do think it's flanked by what I consider better options. 4070 Super for more budget- and value-oriented builds. 4080 Super for those who want the best they can get without going all out on a 4090 which is a big price jump.\n\n\nMy guess is that quite a few people who are interested in this tier of GPU are waiting to snag a 4080 Super.",
      "Got the ASUS TUF OC from newegg, was going to try Best Buy but it sold out instantly.",
      "I’m going to try this next week with the 4080 super FE for my first ever GPU. Wish me luck",
      "Not fully understanding: the 4070ti Super seems to have a modest upgrade with a not-as-terrible price. And leans quite a bit into the older 4080.  Why are people hating this over the 4080 super?",
      "Prices are still stupid AF nvidia. I've bought gtx and rtx since 2010 but never again.",
      "Well im over 12gb usage on CP at 2k so anyone playing 4k should not even consider a card with 12gb of ram.",
      "Might as well have waited for the 4080 super basically just a few bucks more",
      "Within minutes after 6am pst, Best Buy wouldn't load for me and then when it actually did it said sold out. Newegg took around 8-10 mins to actually update their site. Once they did is where I got my 4070ti super TUF 👌. Upgrading from a 1070ti! Finally after so many years lol.",
      "Picked this card up at micro center today, they had plenty of inventory before they closed for the night. Originally wanted the 4070S when these cards were announced, but I do a lot of video work so while my gaming performance may be pretty close I do believe the extra VRAM benefits my specific needs, and said work can pay for the jump. I am loving the performance so far but I do think the 4070S will be a really strong purchase for most.\n\nThis is 100% how the 4070ti should have been released, so while I have no regret on the purchase I do think everyone is justified in being kinda eh towards Nvidia for this generation of cards.\n\nI’m coming from a 2070S, I will be happy for a while.",
      "Just ordered Zotac Trinity OC White cuz of its design and color via Newegg. Traded in my 3080 10 GB.\n\nhttps://preview.redd.it/jpwofk462fec1.jpeg?width=1439&format=pjpg&auto=webp&s=384693249ee75abe232a6509975f523db3b681a7",
      "The only reason anyone would need the 4080s is for 4k on Ultra settings. 4070 super and 4070ti super are plenty enough for 1080p and 1440p. Look at the benchmarks."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "4070"
    ],
    "title": "[Gamers Nexus] NVIDIA's Insane 4070 Ti Marketing, RTX 40 Laptops, & Super Resolution Video",
    "selftext": "",
    "comments": [
      "cyberpunk still hasn't released their frame generation update, yet nvidia and reviewers keep using it as a basis for claims such as \"4070ti up to 3x faster than 3090ti in cyberpunk\", it's pissing me off.",
      "Bro… 4090 isn’t even 2x a 3090Ti, it’s more like 1.7x.",
      "Probably the best marketing Xbox Series X ever received.\n\nIt's 1/5 of our latest data center supercomputing server for only $500.",
      "why im having bad feeling that games will start to launch with shit optimizations with stamp of dlss 3 to fix those fps",
      "Nvidia continues to validate EVGA's decision to stop producing their cards.",
      "The comparison to the Xbox looks absurd until you realise that this is exactly what Nvidia has in mind for their budget segment. Can't pay over $500 for a GPU? No worries, just give us $20 of your wages per month to play games on the cloud.",
      "... What reviewers? We only use the publicly available Cyberpunk version and the same version of DLSS on all NV cards.",
      "AMD is that you?",
      "Galax is launching 4070Ti in Thailand starting from $950\n\nI'm just sticking around with my 1080Ti a little longer.",
      "I saw a post here yesterday where a dude tried to defend nvidia pricing because 4070Ti is better than 3090Ti for less than half the price... Fucking stupid.",
      "Might as well take it to the grave. That card doesn’t know when to quit.",
      "Toxic jealousy..\nNice..",
      "DLSS 3 won’t fix frame time inconsistencies that you get with poor coding. A game stuck at 45fps getting boosted to 90, fine. But if that drops to 20fps native the frame generation won’t save it.",
      "Nah even AMD hasn't done shit this stupid, nVidia is expert there.",
      "Thing is Nvidia partly responsible for the up take in consoles by selling their cards to miners.",
      "AMD and nVidia working overtime to make consoles look good",
      "3X with DLSS3 frame generator.  Not native.",
      "Nvidia going full Pepsi jet with their transparency huh…",
      "> there are always 100 more idiots willing to pay the price just to say they have something.\n\ni paid the price to get framerates i can't get anywhere else. i don't give a shit about telling people what i have, i give a shit about the thousands of hours i put into gaming. i play video games, i buy video cards to play video games, not to \"say i have something\"\n\nyour username is gun freak, how much money have you spent on guns? gun people spend more on ammo in a year than i do on a GPU for 3 years. i buy zero guns and have many thousands of dollars left over to buy a 4090. i buy the lowest end models of cars and have TENS of thousands of dollars left over to buy a 4090. the interest people pay on their car loans alone buys me multiple 4090's because i've never had a car loan and never paid interest. \n\nlearn how to budget and you too can afford a 4090, of course i'm talking to someone who paid for a reddit crypto avatar, no wonder you can't buy video cards\n\nedit: but i don't disagree that video cards are more expensive than they should be now, both nvidia and amd are trying to squeeze as much profit out of us as they can. as for me i'm older and have lots more money to spend on entertainment than i used to, in the end even with these prices it's still worth the money for me. 10 years ago i'd be buying a 3060ti because everything else is too much, but when that's all i can get that's what i'd play on. i played unreal tournament back in 1999 with 350ms ping and got 20 frames per second and it was the best time of my life. modern gaming is absolutely amazing and i'm lucky to afford premium, but there is still lots of good graphics and lots of good fun to be had even at the lower ends.",
      "Yep, i cant wait to have the frame generation update, i been holding off on that game for over 2 years now after waiting for the 7 years development ffs!!"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "4070"
    ],
    "title": "[LTT] Nvidia is lying to you - RTX 4070 Ti Full Review",
    "selftext": "",
    "comments": [
      "So many people are like \"I think I'm just gonna sit this one out with my 3080/3090/Ti\" it blows my mind... \n\nlike... duh?",
      "A card not worth more than $600 including tax selling for $800 MSRP is a great example of corporate greed.",
      "Consumerism is a hell of a drug.",
      "The only 4000 series card worth buying is the 4090. If you are going to get robbed might as well get the most out of it.",
      "Imagine paying $1049 for a $600 GPU. Literally getting robbed blind\n\nYou can buy a 3090Ti used for way less",
      "I'm on a 2080 and was intrigued by getting a 40 series... until I saw the prices.",
      "It seems like Nividia is deliberately creating the pricing structure to force people to buy the next tier card....The Asus Strix 4070ti goes for $1100.  For another $200, you can get the 4080, which is a much faster card....",
      "The whole GPU gen this time is a shit show. Only good thing this time, is Intel finally showed up, now they just need to mature, so we have 3 big competitors",
      "I like how we all be upvoting these reviews here and over the next month this sub will get flooded with \"oH HeY gUyS LoOk wHaT I GoT, iSnT iT PrEtTy?\"",
      "Unpopular Opinion: I'm glad everyone hates this card because it was impossible for me to get a 3xxx series card at a reasonable price so now maybe I can get a 4070ti and finally upgrade my 5 year old card.",
      "Thing is the upgrades were decent back in the day, I went from a 780ti to a 980ti to a 1080ti, I was only with the 20 series I stopped because the gains were tiny and the price skyrocketed at that point.\n\nBefore the cards were around 550-700 think the 1080ti was a bit more at 800 but it was like 80% better than a 980ti at the time.\n\nNow cards are far more expensive but I think for some that mentality has stuck in their heads. Cause yea the 30 series was good really good (if you could get around msrp) the 40 series is just bonkers, I don't mind the 4090 being a halo product and insane prices...that's fine but the 80 series should not be 1200(assuming you can find it at that) which was basically the cost of a top halo card",
      "consoomers...",
      "The structure is to force you to pay as much as you possibly can. If someone can afford a 4070ti, then the logic is \"for $300 more, I can have way more GPU. I should just do it\". And if someone has the cashe for a 4080, then it's \"for $400 more, I can have way more GPU. I should just do it\". \n\nThe end result is that what ever your comfy budget was is now forced to the max",
      "People saying you will stick with your 3080ti or 3090 instead of this xx70 card... do you legit buy lower range GPUs a year or so after you buy an elite card? I would run that 3090 until 2027 if I had one.",
      "So true. They act like they are “settling” with their 3080/90",
      "I live in Poland and these cards are going over 1000 euros already to order, saw some over 1200 (converted from pln).",
      "Honestly this looks like a step up in their card review process.",
      "Lol not in the UK you can't. Can't even get a used 3080ti for less than £750 on eBay.\n\nThe 4070 ti has me torn. Yes it's too expensive, but our other option is a used 3080/3080ti with no warranty for the same or more. There are a few 3080 10gb going for £800, and that seems like the most sensible option.\n\nI guess when the AIB UK prices come out I'll see what it takes to replace my 1080.",
      "I'm not sure why Linus implied RTX 4070 is winning out in Cyberpunk 2077 RT due to SER. There's no SER support in Cyberpunk 2077. If there was the 40 series would turn those results into a bloodbath. \n\nPortal RTX has SER support and you can see how much that differentiates the performance between the 30 series and 40 series.",
      "> This card is better than 7900xt by every metric possible \n\nLTT shows the 4070Ti losing to the 7900XT in both 1440p and 4K raster, so how can it be \"better than 7900xt by every metric possible\"\n\n&#x200B;\n\n> Nvidia sells it 100 dollars cheaper \n\nThere is no Founder's edition for the 4070Ti, the MSRP is not a meaningful metric"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "4070"
    ],
    "title": "Proud owner of a new 4070 aero",
    "selftext": "",
    "comments": [
      "4080 with decent case and no rgb\n4070 with top case and rgb\n\nI will never understand, but grats, looks amazing",
      "Nice! I am doing a very similar build. My first color coordinated computer, the white tax is real man 😢",
      "Nice snow bunny you got there.",
      "Yeah silent monster under the table vs noise xmas tree 40 cm from where u sit. Each to their own",
      "Upgraded from a 1080 to a 4070, so really happy with the upgrade, didn’t really need much higher than that",
      "I think I understand it. They need it for decoration to also add beauty to their house. Other than that, it’s completely stupid waste of money",
      "Similair to how you have 4090 in your flair, no?",
      "Its so beautiful id be afraid to use it in case it gets dusty 🤩",
      "Thats a neat build.\n\nI got myself a 4070 for my new pc roughly a week ago but still need to build the pc because I'm missing the bracket for the cpu cooler lol",
      "I chose to just put the best of everything together this time but I definitely wouldn't have prioritized looks over hardware if I wasn't willing to choose to pretend money was no object.",
      "Don’t get it either, thanks man!",
      "With the money OP spent on aesthetics they could’ve instead got a better graphics card",
      "I think your critics are jealous. Very nice build by the way 4070 is a fine choice.",
      "Manufacturer name",
      "look at that build my man. how can you not be proud?",
      "That's a beautiful looking rig! kudos to you!\nI've got a 4070 Aero too and it's an awesome card, insanely efficient, the temps are brilliant too. I game on an ultrawide 3440x1440p and it runs everything buttery smooth at the highest settings, so screw the haters my dude.",
      "Auch. Didn’t it come with the cooler or did you lose it?",
      "Check this link: beacons.ai/tmhtech\n\nOnly upgrades now are the 4070 aero, strimer plus 11VHPWR cables, and the cooler master vertical mount v3.\n\nIf you have any questions dm me!",
      "I’m a 16 year old that earned my pc and setup within 2 years. How can I not be proud?",
      "These white builds always look clean"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "4070"
    ],
    "title": "Sorry 2070 Super, it's 4070 Ti Super time.",
    "selftext": "",
    "comments": [
      "First thing I did after installing the drivers is fire up Cyberpunk. It used to swivel between 47 and 68 fps at mostly high settings and medium raytracing. Now everything's cranked to the max, with psycho raytracing and Frame Generation enabled. I'm getting around 100 fps at the most demanding parts of the city, 88 fps with path tracing. I'm using a 1440p 144Hz monitor. God, I'm in love with this thing.\n\nFun fact: after I ran a 3DMark benchmark I got the Mystery Machine achievement, since it arrived only a day after release.",
      "Congrats you lucky duck! What's your fps uplift?",
      "What are the temps like for you?",
      "Reviews for it have shown that it doesn't get near 4080 performance unfortunately.",
      "*Sobs in 970*",
      "So far at least under 60°C",
      "That's amazing man, well worth the upgrade! Congrats!",
      "Its downgraded 4080 in this case.",
      "Unless youre standing in the desert this is not happening with ray tracing settings turned up lol. I have this card and play at maxed ray tracing settings w/o path tracing and rrc even. Its not going to pull 180 frames in the city especially without dlss. Maybe your in game resolution is not set to 1440p bc even with dsr cranked up, this just doesnt seem plausible at all at 2k.",
      "Must be a big jump with the new features and of course fps!",
      "Frame Generation has made a large difference in performance. It's my first GPU that I bought that's not used and the most money I've ever spent at once. No regrets though.",
      "I don't disagree. I'm merely speculating as to why people were disappointed with it.",
      "Can’t wait for the RTX 5070 ti super gtx.",
      "Yep, these cards run cold, especially the models with 3 fans. I got the 4070S, upgraded from a 2080. I get 75fps on Cyberpunk with the same settings. Might even run at a higher frame rate, but my monitor is only 75hz so i wouldn't know lol",
      "Thanks. I ordered the same card. It should get here on the 5th. I'm replacing a 1080ti. I tried out a 7900xt and after 2 days I am going back to team green.",
      "I went from a GTX 1080 to a 4070 TI Super.  It's only day 2, but I'm loving it.",
      "Just Changed my 4070 TI in a 4070 TI Super.",
      "Why lucky? Still plenty available on Newegg. Not selling out",
      "*Sobs in 960*",
      "This specific model cost me €990, that's like $1075. The cheapest 4070 Ti Super here is the MSI Ventus 2X OC, which is €890/$965.\n\n&#x200B;\n\nThese are my country's general prices:\n\nRTX 4070 Ti - €870 / $945\n\nRTX 4070 Ti Super - €960 / $1045\n\nRTX 4080 - €1300 / $1415\n\nRTX 4080 Super (speculation) - €1150 / $1250\n\n&#x200B;\n\nEuropean VAT go brr."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "4070"
    ],
    "title": "NVIDIA GeForce RTX 4070 specs have (again) changed, now rumored with more cores and faster memory - VideoCardz.com",
    "selftext": "",
    "comments": [
      "Old & New Specifications -\n\nSMs: 56 -> 60\n\nCuda Cores: 7168 -> 7680\n\nMemory: 10GB GDDR6 -> 12GB GDDR6X\n\nMemory Bus: 160 Bit -> 192 Bit\n\nMemory Speed: 18Gbps -> 21Gbps\n\nBandwidth: 360 GB/s -> 504 GB/s\n\nTDP: ~300W\n\nTimeSpy Extreme Score: ~10000 -> ( >11000)",
      "Another day another rumor'd spec.\n\nTune in tomorrow for the next change.\n\n*If* this is true, it's way better, and I really doubted nvidia was ever going to make an FE card that was 3090ti performance but at 400w, 300w sounds much more reasonable  and realistic.",
      "if this was true I'd get one, limit it to 200 watts and be good for a few years for work, awesome!",
      "Still wish Nvidia had gone for the full 16 GB.  I guess since the x70 has been stuck on 8 GB for **6 years**, a 50% increase to 12 GB will have to be enough.",
      ">this is actually the full configuration of the AD104 die with 60 Streaming Multiprocessors. **Such configuration was previously rumored for RTX 4070 Ti.**\n\nGlad to see the specs just got mixed up:\n\nhttps://www.reddit.com/r/nvidia/comments/wdbf3f/full_nvidia_rtx_40_ad104_gpu_with_7680_cores_and/iihk3d4/\n\nThis is a strong looking GPU.",
      "I don't believe that at all because that would imply that the extra GPU cores and performance mean nothing and it's purely a game of vram. AMD are happy to piss away money by putting purely cosmetic VRAM modules on low end cards just for the sake of marketing and they don't experience this. I assure you the key differentiating factor between the 6700XT and the 6800 is the 50% more CUs, and not the 4GB more vram.",
      "Still waiting on MSRP and actual availability (and real life price) before getting too excited, performance looks pretty darn good tho (let's see it you can finally use RTX without suffering too much performance loss)",
      "So the update here is that the reported AD104 'top end' variant that had been talked about the past couple days that everybody was freaking out about(an assumed 4070Ti-like product potentially), will actually be the normal 4070 specs, and only at 300w instead of 400w.\n\nPreviously, he had been reporting that the 4070 would be a cut down AD104 with:\n\n>RTX 4070, AD104-275, 7168FP32, 160bit 18Gbps GDDR6 10G.\n\nSo this is actually quite a big upgrade in specs, including having a full 192-bit bus(which is needed for 12GB).\n\nThough again, this is showing how kopite7kimi has been all over the fucking place with these rumors. This is a quite drastic change in claims from before.",
      "Typical leaker, shotgunning so when one of their \"leaked\" hit, they'll go like \"I told you!\"  \n\\*swipe everything else under the rug\\*",
      "I am gonna try my hardest to stick to my trusty RTX 3080.",
      "Thing is, till cards start to do 4k at over 60fps without being GPU limited on those tasks as much, 11 or 12gb is fine.\n\nDLSS and temporal AA has also drastically reduced how much  vram is required for crispness at high speed high resolution. It is not perfect, but 4k 4x msaa is far more likely to require more vram.\n\nThe only use case where I run into the limits of 12gb is VR. And well, most games are quest 2 ports that don't require all the much. But at 3560x3560 render resolution per eye and often without upsampling available or desirable, you do easily clip out of 10GB.\n\n16gb vram would therefore be mostly nice for those that play sim games in VR. Extra vram just means higher sampling resolutions aka sharper image over long distances in headset.  You don't need it at 4k most of the time. Higher resolutions are just out of reach still. And often texture quality isn't quite up to snuff even at 4k.\n\nSo I can't blame nvidia too much for what they did on the x70 and x60 series all these years. 10gb on the 3080 and 12 on the ti? Yeah... Those should have been 12gb from the start and maybe 16 for the Ti tbh.",
      "It's not kopite, it's just the nature of development. Remember the 3080 20GB that was never released but was clearly planned since that GALAX slide leaked from an internal meeting? Or those weird GA102 dies with crossed out names on the silicon (another planned version that actually did go into production but then was canceled later). That's just how it is, things are constantly changing and so the leaks are updated accordingly.\n\nThe 4070 is probably still some time away, so there's plenty of time to shuffle specs around. These updated specs are definitely a warm welcome to people looking for a 4070, will make a big difference.",
      "These specs are gonna change up to a month before announcement. The last leak is the one to judge since Nvidia can change up specs pretty close to announcement. \n\nGPU demand is cratering. Nvidia might realize it needs to improve the card.",
      "16gigs would be awesome but no one would buy the other cards then. Nvidia wants to make money and nothing more matters.",
      "To be fair, the 3070 is a decent 4K60 card if you play on sane settings.\n\nhttps://cdn.mos.cms.futurecdn.net/48PBkPwYX9ZhJjD3NoAMuW-1024-80.png.webp",
      "I doubt it will be below $600 MSRP but we'll see. A lot has changed over the last two years and inflation is at 40 year highs so one cannot really expect good news regarding the price (not to mention we're back with TSMC which is more expensive regardless). Lets just hope there's no crypto rebound again.",
      "I think it has something to do with the number of memory chips. The 3070 has 8x 1GB chips at 32 bit each = 256 bit. The 4070 will use higher density chips because of the increased capacity. Just like the 3060 12GB has 6x 2GB at 32bit each = 192 bit.\n\nSo for the 4070 to have 10GB, it would need to have 5x 2GB chips at 32 bit each = 160 bit. Since they say it's now 12GB, it would have 6x 32 bit = 192 bit bus.  \nOr I guess they could use 1GB chips but end up with 2x the bus size, which is more of a high end thing. I don't know why they wouldn't want such a big bus in a mid range GPU. Maybe it would take up too much die space or something.\n\nBut I'm just guessing. I don't know anything about this kind of stuff.",
      "> I don't know why they wouldn't want such a big bus in a mid range GPU\n\nCause increased bus width greatly increases the cost of the pcb, and also of the memory controller somewhat.\n\nIt's not the additional memory chips that makes is costly, but the increased complexity of the pcb, traces , layers, etc...",
      ">Memory Bus: 160 Bit -> 192 Bit\n\nIs there any particular reason they went from 384 Bit to 256 Bit back to 192 Bit and even below that in the old specifications?\n\nAre we gonna get another GTX 970 where they \"forget\" to mention that of 4GB VRAM, only 3,5 GB are getting the propper bus size?\\^\\^",
      "Hmm, could this mean the 4070Ti will get a better die, for example something like a AD103 or maybe the 4070Ti isn't a thing anymore and was replaced by the regular 4070? The specs look pretty solid for a regular x70 card."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "4070"
    ],
    "title": "Help Me Choose an RTX 4070 SUPER GPU!",
    "selftext": "",
    "comments": [
      "If those are your options the Asus TUF has the best power & thermal design out of those. There are better ones, they're just not on that list and generally not worth the higher cost unless you really want to OC.",
      "Just get the cheapest one",
      "ASUS TUF or MSI Gaming X Slim",
      "I always tend to favor Asus ROG and TUF models because of the extra HDMI port (3 DP, 2 HDMI). But MSI is also good. I don't tend to recommend Gigabyte given my personal experience with them (dead brand new gpu out of the box for someone I built a PC for), but I've been told they're not bad",
      "best is gigabyte gaming oc with 4 year warranty and cool temps",
      "The ones that cost 4070ti super prices so not even worth considering",
      "Get the cheapest one.",
      "I always hesitate to reccomend Gigabyte gpus because of their known fan quality issues and rma history.",
      "It literally doesn't really matter. Get the cheapest or one you like the most.  I only buy fe models cause I think all other cards are so ugly.\nI've built many systems for friends and always get the cheapest version. Never had a single issue",
      "all brands are hit or miss regarding rma",
      "It can save you from having to buy an adapter if you have more than 1 monitor or TV that doesn't have a displayport input. Most people won't necessarily need it, but it's nice to have.",
      "1) the one with extended warranty\n2) cheapest one \n3) with a free game \n4) 3 fan",
      "What are the better options?",
      "I also found PNY cheaper. Should I go for that?",
      "Bear in mind this really only matters for OC and tuning. Using stock settings the difference is almost irrelevant. Plus at 4070/S level these are overkill unless you're trying to really push things.\n\n* Asus Strix is pretty much the best option. On higher tier cards (4080/4090) the TUF's cooling is ironically better, but on 4070/Super both cards cooling is overengineered anyways.\n* Gigabyte AORUS is a second best board but not necessarily the best cooler.\n* MSI Suprim is probably the best cooling, though Strix and AORUS are *slightly* better boards. It's still a top tier board though.\n\nThere's others that compete with TUF but those 3 are better. TUF is still pretty close and cheaper, so unless you really want to go crazy there's no reason not to just get it instead.\n\nI think Colorful has a board that tops TUF but I forget.",
      "100% this",
      "Thanks, I will go for it then.",
      "I use two hdmi ports for a flatscreen and an old crt tv. So I appreciate the extra one.",
      "Maybe ive just been hearing lots about them lately, but the fans are def a common issue. If it fits your budget its probably fine but gigabyte is never my first choice.",
      "They're all the same performance wise so just go with the one that fits your build aesthetically."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "4070"
    ],
    "title": "NVIDIA GeForce RTX 4070 Founders Edition packaging leaks out - VideoCardz.com",
    "selftext": "",
    "comments": [
      "This is going to be slower than the 3080 extrapolating from the specs",
      "This is the first break with that unfortunately (at least recently). \n\n1070 = 980Ti \n\n2070 Super = 1080Ti\n\n3070 = 2080Ti\n\nAlthough I suppose it’s not a break in it, because the 4070Ti is so close with the 3090Ti, it’s just the price.",
      ">RTX 4070 is using AD104-250 or AD104-251 GPU with 5888 CUDA Cores. This model is to feature 12GB GDDR6X memory and 192-bit memory bus, so the same configuration as RTX 4070 Ti. Reduced core count allows NVIDIA to lower the power consumption to 200-250W level.",
      "They'll use frame generation to claim it's 2-3X faster on their marketing, no worries over at nvidia HQ.",
      "how does this get an FE but not the Ti",
      "AMD isn't offering anything below $900 either. \n\nThis gen looks like another skip.",
      "This exactly! And a gimped memory bus too. So many new PC builders defending the new pricing based on how much the 3 series costs don’t realize that you’re suppose to get a big uplift for a similar price bracket. These same idiots are the ones setting price expectations for Nvidia because it’s easy to separate an idiot from his money.",
      "If the FE is the same size as the 4080/4090 I’m done 😂",
      "Actually over 24 months ago now.",
      "Wouldn't surprise me if it's because they made 4080 12gb FE cards and couldn't change the inscription to 4070 Ti.",
      "The price is the most important thing though. Every 2 gens I spend my $550 and get the latest 70 and now they offer nothing. I'm switching my arse to AMD.",
      "And now we see the true reason why frame generation doesn't work on 30 series",
      "Imagine Apple charging more for every jump in performance every year, or Sony for PlayStation or Xbox, technology advances should benefit the customer not the companies margin. I can’t believe zoome are buying into this BS",
      "If its 76% of a 4070 Ti I highly doubt it will be 3080 Ti. Even 3080 10gb will be a blessing.",
      "4080 12GB FE was never planned and it wasn't announced during the initial launch.\n\nQuoting from the [Nvidia Press Release](https://nvidianews.nvidia.com/news/nvidia-delivers-quantum-leap-in-performance-introduces-new-era-of-neural-rendering-with-geforce-rtx-40-series):\n\n>The company also announced the RTX 4080, launching in two configurations. The RTX 4080 16GB \\[...\\]. The RTX 4080 12GB \\[...\\].  \n>  \n>Both RTX 4080 configurations will be available in November, with prices starting at $1,199 and $899, respectively.   \n>  \n>**Where to Buy**  \nThe GeForce RTX 4090 and 4080 GPUs will be available as custom boards, \\[...\\]  \n>  \n>The RTX 4090 and RTX 4080 (16GB) are also produced directly by NVIDIA in  limited Founders Editions for fans wanting the NVIDIA in-house design. \n\nNo reference whatsoever to a 12GB FE.",
      "The 4080 12GB was already reported as only being made by AIB partners. \n\nWhen Nvidia decided to just change the sticker to the 4070TI nothing changed for the release. \nNvidia didn’t have any produced and didn’t plan to. \n\nThey planned to make a 4070 so this is something that’s been in the works. Gotta make an FE of a card that’s probably going to lose or be just equal to a 3080",
      "This company is a mess right now. Every 5 frame drop they release a card.",
      "192 bits for a xx70 class card and 128 bits for 4060 ti \n\nThis sucks !",
      "Wow, that 4060 Ti looks *seriously* gimped with a 128-bit bus.  \nHeck, the 3060 Ti  had a 256-bit bus. Even the 3060 had a 192-bit bus. So how does a card with the Ti branding get such a gimped memory bus ?",
      "You can see the size of the card in the packaging. It's pretty small. Probably about the size of the 3070fe."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "4070"
    ],
    "title": "I expect the 4070 super to be a lot bigger than the 3060 TI",
    "selftext": "",
    "comments": [
      "Cooler size is largely dictated by thermal output of the GPU die and other board components.\n\nRTX 3060 TI: 200W ([https://www.techpowerup.com/gpu-specs/geforce-rtx-3060-ti.c3681](https://www.techpowerup.com/gpu-specs/geforce-rtx-3060-ti.c3681))\n\nRTX 4070 SUPER: 220W ([https://www.techpowerup.com/gpu-specs/geforce-rtx-4070-super.c4186](https://www.techpowerup.com/gpu-specs/geforce-rtx-4070-super.c4186))",
      "This has been the case for about a decade?",
      "Better for me. I have a small case",
      "4070 super has 220W tdp, 3060ti has 200W.\nShould have roughly the same cooler size. It's not the name that defines the size.",
      "Top tier cards sure but you could get GPUs with similar low TDP but better performance down the product stack.",
      "I was planning on building in a smaller case. This is perfect",
      "RTX 4070^(\\*): 200W ([https://www.techpowerup.com/gpu-specs/geforce-rtx-4070.c3924](https://www.techpowerup.com/gpu-specs/geforce-rtx-4070.c3924))\n\n&#x200B;\n\n&#x200B;\n\n\\*When looking at norms for gaming graphics ability, shader count, VRAM size, bus width, and even power consumption, the RTX \"4070\" perfectly fits what you'd expect for a -60 Ti graphics card. But \"70\" series cost more than 60 Ti, so they named it one higher to bump up the price.",
      "The 4070 and 4070 Super are the successors to the 3060. Nvidia moved the model numbers up by a notch to justify the massive price hikes.\n\n* 3060: 170W, 276mm^2 die, 192-bit bus ($329 launch MSRP, 2021)\n* 4070: 200W, 295mm^2 die, 192-bit bus ($600 launch MSRP, 2022)\n* 4070S: 220W, 295mm^2 die, 192-bit bus ($600 launch MSRP, 2023)\n\nMeanwhile:\n\n* 3060 Ti: 200W, 393mm^2 die, 256-bit bus ($400 MSRP, 2020)\n\nSo, it's not surprising that the 4070 Super's cooler is about the same size as the 3060 Ti's. If you look at actual silicon specs, it's a performance tier below the 3060 Ti while being 50% more expensive.",
      "Love the looks of FE cards, especially this black ones.\n\nIf only FE were avaible on my country :(",
      "Yeah makes sense. I just have gotten used to GPUs growing larger and larger every year.\n\nIt's good that they are finally coming in smaller packages while being more powerful.\n\nEdit: spelling",
      "Remember when the first pictures of 4090 engineering sample cards got leaked and they were 4x slot 600 Watt beasts everyone made fun of?\n\nThose early cards were designed with a GPU on Samsung 5nm chips in mind. Nvidia made the switch to TSMC 4nm later in the design phase and alledgedly many designs were originally still based on Samsung 5nm.\n\nThe non-Super cards are slightly oversized and meant to cool a higher TDP. AiB's could have potentially saved 10-20$ per card if they would have designed them for the actual final 4nm chips.",
      "I have been misinformed then. I always looked at the higher tier cards. I usually went for the MSI gaming series",
      "This card is what 4060Ti really should have been, but for 400-ish $/€. 50% more performance for the same power draw is exactly generational jump. As someone who has 3060Ti, I don’t see anything below 4070 as an upgrade. And then I need to spend 650 EUR or so. Thank you Nvidia.",
      "Yeah same. Just gotten used to the GPU sizes growing every year. Very happy with this card",
      "A card is a card. The only thing you are paying more for is the cooler on higher end cards",
      "It kinda has to be. The TDP of the 3080 is almost twice that of the 1080. (320W vs 180W)",
      "Yeah my first FE was the 3070 and I fell in love with them. I will only buy FE from now on.\n\nMSI came out with a similar style card but I am not sure about the price.",
      "Yeah 3060Ti actually uses 3070 GPU and memory, with some units of GPU disabled. Which is why its only 5% slower than 3070, and much faster than 3060 - although 3060 has 12GB of VRAM (the real 3060, at least).",
      "Hahaha it's just a photography light box I got for my projects.\n\nTakes a minute to get those shots. Very useful.",
      "Look on the bright side, if someone ever breaks into your home, you can use it as a weapon. It's a 3-in-1 product: a GPU, a space heater, AND a weapon."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "4070ti"
    ],
    "title": "Is 4070ti SUPER legit card for 4k gaming?",
    "selftext": "With the recent unveiling I noticed this card is still being marketed as 1440p card, but VRAM-wise and performance wise is very close to 4080 which is 4k card.\n\nWhat do you think, would be 4k gaming relevant with 4070ti Super?",
    "comments": [
      "I’ve been using a regular 4070 ti for just under a year and have been playing 4k without issue. \n\nThe 4070 ti super will last longer.\n\nEdit: to all the people asking me what games , fps count, and settings please just google or YouTube some benchmarks.",
      "There is nothing in 4070Ti Super specs that make it not-4k card and a 4080 as the 4k.\n\nIt's just marketing so people feel pressured to buy a pricier card that comes from the same chip. Don't buy into it.\n\n4070 TI Super is the cheapest 16GB/256bit bus card from the lineup and it's the best value, period. Having a few more cores won't make games magically run at 4k without issues.",
      "4K native, highest settings especially with ray tracing and high framerates? No, that is squarely a domain of the 4090. With upscaling, mixed settings and no need for high framerates - sure, it is perfectly capable.",
      "Yeah that extra 4gb of vram is significant. Only real knock against the 4070ti.",
      "The question should be rephrased to how long would it support 4k gaming for? It is not quite the standard yet.   \n\n\nWhen I had a 980 ti when it was a thing that would play GTA V, Elite Dangerous, Shadow of Mordor, Alient Isolation and more at 4k, Today it wouldnt be able to run anything in 4k.",
      "most likely, DLSS Q goes a long way tbh",
      "Stop it with these unrealistic expectations, haha. I know a /s probably is intended, but don't give any casual observers the wrong idea, haha. \n\nA GPU that does 4k native, highest settings, RT/PT and high framerates doesn't exist. Just optimise with whatever makes sense for your use case, budget, and will to splurge.\n\nThe RTX 4090 manages 19fps in Cyberpunk at 4k native, RT Overdrive preset.\n\nRT Ultra preset otherwise? 4k90 if you use DLSS Performance and Frame Gen on a 4070Ti which is still visually mind blowing. It was the flagship title to show off the slower 3090 off on release after all.",
      "Companies need to seriously STOP with this \"XXX resolution card\" thing!\n\nLet's begin by understanding why there's no such thing as a \"XXX resolution card\". If you play CS:GO, even a 1060 will easily push 4K max settings at well over 100fps. If you're playing Cyberpunk at max settings with Path Tracing at true 4K resolution (no upscaling), a 4090 will hardly make it past 20fps (at such low framerates, response times will become atrocious and turning on frame generation will only make it worse due to the input latency increase).\n\nSecond, with upscaling, the notion of a \"XXX resolution card\" goes even further down the drain. Are you struggling to run the latest games at native 4K with your card? Simple: just turn on DLSS, and you can run \"at any resolution you want\" and still get a good 4K output thanks to the magic of smart upscaling. Quality mode will make your GPU render internally at 1440p, so now you're driving just half the pixels, even though the output frame will still look very much 4K. Still struggling with performance? No problem. Pass it over to Performance mode, and now you're effectively running 1080p internal resolution. AI upscaling \"magic\" will still scale that up to 4K and - depending on who you ask - it will still look as good as native 4K (though, I'll be honest, there's quite some room for debate here). Performance mode is actually the de-facto \"standard\" for high-end 4K gaming. All of Nvidia's 4090 demos running Cyberpunk are done at DLSS Performance Preset. So, most of the 4K demos you'll see out there are, in reality, being rendered internally at just 1080p. Native 4K rendering is quickly becoming a thing of the past - so I ask you, what is a \"4K card\" when even 4090s and 4080s are rendering below 4K?\n\nAnd if 1080p is still too much for your card, worry not, you can push it further down to 720p with the Ultra Performance preset and, believe it or not, it's actually looking quite good with the latest updates (I know it because its preset I use it to play Cyberpunk with Path Tracing on my 3080 - 10GB won't cut it for Performance Preset anymore, so I'm \"stuck\" to Ultra Performance - on the bright side, I'm running the game at nearly 100fps with FSR-to-DLSS mod, so it's quite impressive being able to run such a demanding title with Path Tracing on a nearly-4-year-old-card at 100fps).",
      "DLSS at 4K is so good there's really no reason not to use it. Using DLSS Quality is basically just free performance since most of the time you can't even distinguish from native. I've found in most games Balanced and Performance look really good at 4K too.",
      "same. just rub some DLSS on it.",
      "Also with the original 4070 Ti you have 192 bit bus which was also a gimp to the card.",
      "This, it seems like there’s usually two camps of 4K gamers. Those who are fine High settings 4K 60+ and then those who want Ultra settings RT maxed 4K 120",
      "My 6950xt can do cyberpunk native 4k with some tuned settings at 60fps + -.\nFor 4k native all ultra you probably need more horsepower, but if you can settle for mostly high and some medium, a 4070ti and super is ok.",
      "even with a 4090 i use dlss Quality whenever it's available. I see absolutely no difference in image quality at 4k and GPU usage drops significantly. why use 400 watts when i can use 250 for the same results.",
      "Hi 2018 , how you guys doing back there?\n\nHere in 2024 the 3.5 version of DLSS upscaling is nearly flawless, at 4k in fact , Hardware unboxed made a video proving that DlSS quality is more often preferable to native 4k with TAA or whatever antialiasing the game comes with, in terms of resolving image clearly , smearing , artifacts etc , it simply had a cleaner overall presentation than native in more games than the ones where native was better (And that video wasn’t even done with DlSS 3.5 it was with the 2. Something version)\n\n\nHere is the link , so that you guys in 2018 see what DlSS is bringing for you in the future: https://youtu.be/O5B_dqi_Syc?si=l60_z3VoSs_AZHGC",
      "Whatever gpu you have, dlss off is stupid.",
      "That's true. But where it can, it is basically the only card that can.",
      "At 4k dlss balance or quality you get much better visual quality than native 4k with TAA. Native rendering is dead.",
      "Yeah, usually quality.\nIt doesn't really matter that much anyway if couch gaming on a 4k TV for example, and is still a legit option considering a 4080 costs 45% more and isn't drastically faster.\n\nDLSS Performance also works pretty well where you're trying to do something expensive like extensive RT reflections.\n\nStill an big upgrade over a console if you're aiming for a tidy presentation on a 4k TV and 90-120hz with optimised-high+ settings.",
      "Yep that move to 103 is significant but should have been day 1"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "4070"
    ],
    "title": "Frame gen is actually amazing. Just got my 4070 super and am surprised how it feels.",
    "selftext": "I just used PT and frame gen on CP2077 and did not notice the frame gen at all. Maybe I am blind, but it feels the same for me and even looks better ofcourse. \n\nI still dislike their pricing this gen, but PT and DLSS is one of the reasons I chose them instead of AMD. And I actually am happy I am not disappointed.",
    "comments": [
      "I just completed cyberpunk on a 4070 Super with those settings on. Left FG on for the full 200hrs and it felt and looked amazing.",
      "Legit. \n\nFiguring out I can replace DLSS:FG with FSR:FG has provided a new breath of life to my 3080. \n\nGenuinely shook at how decently it works and I can only assume DLSS:FG is considerably better still.",
      "people hating FG is generally a case of sour grapes.\n\nI enjoyed frame gen on Cyberpunk and Alan Wake 2 a lot as well OP",
      "\"New life\" to a 350w GPU that's not even old and about the same as 7800 XT? Wut.",
      "It plays at the same fps you were getting before fg ,so if you were only getting 30 fps before,it may look like 60 but it will still play at 30 ,you really need 60fps before you turn it on",
      "Op, here’s the script….\n\nNvidia: Releases new feature after decades of R&D\n\nAMD Fanboy: It’s not good, it has huge flaws. Not useable. *makes youtube video.\n\nAMD: *Releases same thing but worse….but hey, it’s open source 🤷‍♂️\n\nAMD Fanboy: ITS THE SECOND COMING OF JESUS!!!\n\n\nBefore I got my first RTX card to try out DLSS, people on YouTube made it seem like it was the worst thing ever. It was ruining games, etc. When I actually used it, I thought it worked really well and wondered where all this bad press was coming from. I wouldn’t be surprised if that’s why you were surprised with frame-gen.",
      "Simply because AMD has a frame gen system out now you will see a lot less complaints about frame gen use.",
      "> \"New life\" to a 350w GPU that's not even old and about the same as 7800 XT? Wut.\n\n3080 can only do 50fps cyberpunk PT at 1440p and decent fidelity. With FSR-FG you can push that to 90.",
      "The one thing I learned since getting a 4090 is that everyone who didn't have a 40 series GPU would regularly trash talk Frame Gen and say \"the input latency makes it unplayable, no thanks\" and \"fake frames\" etc etc   \nThe moment people actually OWN a 40 series they got nothing but praise for the tech.\n\nI can play Cyberpunk 2077, fully  Path traced, max settings. DLSS Quality + FG and I am playing it at 120fps and it is gorgeous.\n\nI used to play Cyberpunk on my old 1080ti, much worse graphics, much worse performance and it feels waaay snappier now despite the \"latency\". Obviously, if you were to play Counter Strike 2 with FG u might notice the latency, but who on earth would run that or similar games with FG ?\n\nAmazing tech, If you can, try out Phantom Liberty with Path tracing, best graphics I have ever seen in my life",
      "Old versions of DLSS were not that good but nvidia has really stepped up their game, FSR doesn't stand a chance in his current iteration.",
      "You’re downvoted but this is objectively true. If you’re getting 40fps, turn frame gen on and you now have 80fps, input latency is the same as 40fps. People are just downvoting you out of ignorance. It looks smoother but you still feel the latency of having low fps.\n\nIt’s basically great for slower paced single player games but it’s really bad for anything competitive.",
      "Yeah it’s fantastic. It’s wild to me that amd boys have always downplayed frame gen as fake frames, but now that AMD has a somewhat decent competitor those comments have disappeared.",
      "🤨",
      "I think people are starting to hate on things like frame gen and DLSS because our cards used to run the games that came out without any of this kind of trickery. Now our supposedly powerful modern GPUs need to basically render half as much just to give us the performance we want. This isnt really acceptable, devs have also started leaning on it for optimisation aswell, again not acceptable.\n\n&#x200B;\n\nA 1080ti didnt need frame gen and DLSS to get a playable frame rate at 4K in games 2 years older than it, the 4090 does. Not really technological progression is it, especially when a 1080ti was like £700 and the 4090 is £1600 minimum.\n\n&#x200B;\n\nLets also not forget you could get 2 1080ti for less than a 4090 and  SLI was still ok for support at that point, that wouldn't need frame gen to run anything from its era at 4K at very good FPS.\n\n&#x200B;\n\nDLSS is cool but GPU really need to start progressing and they really need to start costing what they are worth. As the owner of a 4090 it is not worth £1600, the GPU at most is worth £1000. I would argue our GPUs and our PCs are getting weaker comparatively.",
      "No there were literal AMD fans saying they were \"fake frames\" and the technology was a terrible idea. They said that nobody wants their GPU to create \"fake generated frames\" and that it was noticeable in gameplay that a frame was generared. Then once AMD did this same feature with FSR 3.0 and Fluid Motion Frames, they said it was a necessary feature and that it was a great thing for gamers to use.\n\nIt's just the same tactic they said about DLSS. Their fans said it was a bad feature because it reduced visual quality and introduced visual artifacts, they called it \"DLoSS\" as in a \"loss\" in visual fidelity. Then once FSR 1.0 released (which mind you is even worse than DLSS 1.0 which was pretty bad visual quality wise), they claimed it was an amazing feature that made their games smoother and better.\n\nUnless AMD does the feature first they will claim every NVIDIA feature is a waste of time. If AMD does it first then they claim NVIDIA copied AMD and can't create their own feature, which is what they said about EyeFinity. Their fans are honestly the worst group in technology fandom. All fans are delusional to an extent, but AMD fans are that little bit extra.",
      "Any DLSS mention would get bombed with comments about it not being real frames, it's not the true image, and then such posts reduced hugely when AMD finally actually had a competitor (even though it's poorer quality).\n\nFrame Generation mentions would get bombed with comments about it not being real frames, it's not the true image, \"fake FPS\", and that also reduced very shortly after AMD users had their own version.",
      "So input latency would be at 60 FPS but visually it looks like 120?",
      "> but stop being dramatic about it and say it was bigger than it actually was..\n\nAh yes, that's it! I'm just making it up! Silly me... [Well I hope you don't look at the most upvoted comment on this r/AMD thread](https://old.reddit.com/r/Amd/comments/yout1w/fsr3_are_you_interested_in_frame/) it totally doesn't say:\n\n>\"I **dont** want **increased input lag**, **unstable images creating worse image quality**, and **fake frames** that dont actually represent what the game engine and server actually see.\"\n\nI'm just misrepresenting their opinions and being dramatic! I see the error of my ways.",
      "people who have never used FG: FAKE FRAMS. FAKE FRAMES!!!\n\npeople who have used fg: This is pretty nice, actually",
      "Ridiculous.  I don't even know how the poors attempt gaming on their pathetic $700 GPUs."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "4070"
    ],
    "title": "4070 ti super or 4080 super",
    "selftext": "Im planning to buy my graphics card soon, but struggle to decide if i should get a 4070 ti super or a 4080 super, as i plan to play games at 1440p 240 hz, i have a 850 watts psu, and the current difference on gpus is about 300 difference aud, is the extra performance worth the $300?",
    "comments": [
      "The people saying the 4080S is overkill for 1440p are missing one thing: you have a 240hz monitor. \n\nI have a 4080S and I am NOT getting 240fps in non-competitive titles. \n\nBoth GPU's would hit 240 in games like RL, CS2, Mobas, etc., but it won't hit that in other games. \n\nThat difference isn't small, so make the choice based on what your priorities are and what games you play",
      "I went 4080S for 1440p@165Hz. In many games with full RT/DLSS/FG you will be glad to have 120fps.\n\nIts not overkill, lol.\n\nIf you plan to use it for a longer time, get 4080S.",
      "You also need the best CPU available, and even then you will find games that refuse to play at anything over 70 or 80 fps. Unreal Engine 5 is great for the developer but bad for the gamer. It's great in the sense that a lot of the harder work is done for you right out of the box with Unreal Engine 5. The problem for the gamer is that because of much of that hard work is already done, there isn't nearly as much manual work done for optimization. Nanite is good for what it offers to the developer because it means they don't have to make LODs manually and everything looks great as is. For the gamer, Nanite is bad because it uses a lot of resources, and it does slow down the game if it's used for everything. Lumen is great for the developer because it looks great and minimal work is required to have a nice looking scene. Lumen is bad for the gamer because it's actually not so easy to run.",
      "This sub is deeply into the \"give Nvidia as much money as possible\" team. \n\nJust note that going from 4070TiS to 4080S is a 9% increase in performance for a 25% increase in price.",
      "Reductuon in price lmao. People tend to think only US exists in the globe. It will be much more expensive in EU I’m pretty sure about that.",
      "If you are considering the 4080S wait a few months we are not very far from the January announcement of the 5080.",
      "I swear to god. Especially at 1440P, the difference tops out at like 13%. Paying 25% more money wouldn't get you the 'extra longevity' they're seeking. \n\nIt's product segmentation to just push you up another tier. Both cards will be obsolete around the same time.",
      "Maybe. Or they go up because nobody buys the new cards for the obnoxious prices and devour the used market.",
      "I just got a 4080s and I'm so happy. I have a 120hz ultra wide (3440x1440) and cyberpunk with ultra path tracing is around 80-100fps. My flight sim experienced has doubled in performance due to frame gen. Super happy coming from a 3080",
      "The irrelevant part here whether the GPU is gonna be overkill or not. No GPU is overkill my friend. You have plenty of reasons to always buy the more powerful GPU. RT/PT, High fps gaming on latest AAA games, Maxed out graphics + No Upscaling. The main question is how long you are planning on keeping this GPU? If you are not interested in upgrading to 50s series when they come out, get the 4080S. If you want you could also save that 300 and get the 4070TIS which is still super capable. ( that 300 you save is gonna be a drop in the bucket tho with how the pricing on 50s series is rumored to be so take that in account as well)",
      "Yes, this is a really good point. \n\nWhen I upgraded my GPU, my research revealed to me that it wasn't going to be worth it if I didnt also upgrade my CPU",
      "Toms Hardware GPU Hierarchy for 1440p Ultra: https://www.tomshardware.com/reviews/gpu-hierarchy,4388.html\n\n4070TiS average FPS = 122fps\n\n4080S average FPS = 133fps\n\n133fps = 109% of 122fps\n\nAnd I mean that this sub constantly pushes people to buy the most expensive option, while completely ignoring price to performance. \n\nAKA this sub's apparent motto: \"Buy the most expensive card you can afford\".  Call someone out on this, and on come the insults.",
      "Dumbest way to play games in 2024 is cranking everything up to ultra and calling it a day. U could get much more fps with optimized settings in most games without noticing any visual difference.",
      "This is the answer you're looking for, u/No_Two1580\n\nYour GPU will bottleneck your monitor, no matter which one you pick, in non esports titles. Even a 4090 won't deliver you 240 frames in single player games on ultra details.\n\nThe question is, how much do you want to stay away from your monitor maximum capabilities? If I were you, and had the money, I'd go 4080 Super.",
      "You don’t *need* a 4090 for 4k.",
      "Wdym? All benchmarks on this planet, like thousands of them, always show raster performance first. Between these two cards, the 4080s is usually 10-30 frames up, making it around 15% more powerful in raster performance",
      "4080 Super. And no.",
      "But but random people say they max out their 240hz monitors with a 4060 with full PT in cyberpunk!",
      "Would 13% extra performance not be the textbook definition of \"slightly\" better longevity?\n\nAnd most benchmarks i know talk about an 18% improvement at 1440p, not 13%. And *all* of them have the average gain of an 4080 Super (across multiple titles) in the 15-20% range.",
      "4080S is a waste of money, the difference in performance is almost negligible and it's not more future proof because of the same amount of VRAM. Go 4070 TI S or 4090."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "4070",
      "4070ti"
    ],
    "title": "4070 super or 4070 ti super for longterm 1440p gaming?",
    "selftext": "4070 super or 4070 ti super for longterm 1440p gaming?\n\n4070 super seems a pretty good deal but I dont think I will be changing my gpu for the next 3\\~4 years (the next upgrade will be moving to new mobo, cpu and ddr5). But one thing that haunts me is the 12gb vram of the 4070 super, which seems pretty low for that price and Im wondering if that will be enough for the years to come. I also have a 165hz screen but im not that eager on reaching insanely high fps on singleplayer games, I could accept 60+ stable fps. The 4070ti super offers more performance, 16gb vram but its 220$ more expensive around here.\n\nAlso, AMD gpus here are quite low demand so they are much more expensive than in US and EU, so they are quite out of question (i could go with 7900 gre or even 7900xt, but their price here dont make any sense",
    "comments": [
      "4070tiS hands down is the winner. \n\nThe 4070S may be a better value now but you can never discount the longevity of a more powerful GPU.",
      "12gb will be fine for 1440p gaming, people over blow shit out of proportion.",
      "With reasonable expectations, these GPUs will both be able to last 6+ years.\n\nNot everyone cares about pushing ultra settings on every title.\n\nEventually you'll have to lower settings a bit more with 4070S but for many people that's worth it to save hundreds.",
      "My lil 1080ti still trucking along best that she can! I've noticed some games being slower than they used to be but it was such am excellent purchase when it came out",
      "The 4070 TiS is more likely to last those years at high frame rates (120+) with fewer setting compromises, due to the extra power (not so much the VRAM). Since you do mention not minding 60+, however, any of the 2 cards should be able to keep up with that at with at least high settings for 3-4 years.",
      "I've got a 4070 and it's just shitting on every single game at 1440.. genuinely thinking of just going 4k to see some actual frame drop 😂",
      "3-4 years is not long term. that’s just every other major gpu releases.",
      "There are already games that exceed 12gb VRAM, today.\n\nPS5 and Xbox don't run games at max quality settings",
      "Didn’t realize how close the 4070 super was to a 3090ti wow",
      "Mine is still trucking along too. Wondering about a 4070 Ti Super or 4080 Super as the next step. But realistically I don’t need an upgrade just yet as most games are quite manageable",
      "I'm also a 3D artist.\n\nI played the entirety of Cyberpunk on my 4070S. 1440p + DLSS Quality + PT + FG and it was a great experience. Not once did I have any issues.",
      "This whole Vram thing is so overblown its crazy, 12gbs will be fine for a long time and its not like you need to max out every single game, the Ti super is better if you do more than just game on your pc, the extra vram, dual encoders and the 15% extra performance is worth it but if you don't need the extra vram or dual encoders then that 15% extra performance for an extra 200+ dollars isn't worth it.",
      "You should give the Frame Generation from Lossless Scaling a try, it made my 1080ti feel like new again, completely killed my desire to upgrade.",
      "Don’t listen to these people",
      "This would be a good question 5 years ago when 20 series dropped.",
      "Then make urself a small favor and be patient for 50 series.",
      "Which games need more than 12gigs at 1440p?\n\nLol this VRAM paranoia is hilarious.",
      "The 10 series was simply insane, I lasted with a 1060 6gb until like 5 months ago (went to a 4080 + 7800x3d)",
      "Makes me realize how much Nvidia is overcharging, like \"hey, do you want to go from 135fps to 150 for an extra 100% of the price?\"",
      "These guys with their step ups, in my mind it's like if I'm gonna go for a 4070ti super then whats $200 more for the 4080s.  I hate how they purposely do these segments to get you to buy up."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "4070"
    ],
    "title": "GeForce RTX 4070 Ti Super Review Megathread",
    "selftext": "# GeForce RTX 4070 Ti Super reviews are up.\n\n&#x200B;\n\n[GeForce RTX 4070 Ti Super](https://preview.redd.it/yoex906xo9ec1.jpg?width=1200&format=pjpg&auto=webp&s=5ddccd2aa72c6eb61e5bee2e341626d7c9b818dd)\n\n# Below is the compilation of all the reviews that have been posted so far. I will be updating this continuously throughout the day with the conclusion of each publications and any new review links. This will be sorted alphabetically.\n\n# [\\[PSA\\] Certain MSI GeForce RTX 4070 Ti Super Ventus 3X VBIOS Causes Lower Performance Than Expected](https://www.reddit.com/r/nvidia/comments/19dq7le/psa_certain_msi_geforce_rtx_4070_ti_super_ventus/)\n\n# Written Articles\n\n# [Babeltechreviews](https://babeltechreviews.com/rtx-4070-ti-super-review-800-for-near-4080-performance/)\n\n>Nvidia claimed a 10% increase of the previous model and we did achieve mostly that in our testing, with some slightly lower than quoted. Its obvious this card easily surpasses the original model at the same price and its really close to the original RTX 4080 performance point at significantly less than MSRP for the RTX 4080. This will change soon with the upcoming launch of the RTX 4080 SUPER at its lowered price point of $999.00.  \n>  \n>The real decision for gamers, in our opinion, looking for a card at this level is looking for a used RTX 4080 or something at this similar price. If you are looking for a new card that can compete with the RTX 4080 for lower entry cost then this is a good choice.\n\n# Digital Foundry Article - TBD\n\n# Digital Foundry Video - TBD\n\n# [eTeknix](https://www.eteknix.com/gigabyte-rtx-4070-ti-super-oc-graphics-card-review/)\n\n>So I’m going to admit. That was painful. When looking at performance and analysing the point of our content, it’s easy to get excited when we see an evolutionary jump, but that’s not the case here. It’s slightly faster, and I’m talking marginally.  \n>  \n>When you look at the specifications, this new graphics card is better in every way. There are higher core counts, there are more RT and Tensor cores, there’s more VRAM, the clock speeds are up, and really, that should be an indication of a pretty potent performance boost. However, from our pretty extensive testing, that’s not really what we see in the real world. It’s a little bit better, but does it feel like an upgrade? Not really, if I’m being honest. More VRAM is nice and does improve the 1% lows, but not as much as the fanatics in the internet comment sections would have you believe it would have.  \n>  \n>DLSS and other technologies should have seen a boost too, but in games like Cyberpunk and Hogwarts Legacy, some were up, some were down, and some were about the same, so it is splitting hairs on whether this is better or not. Not that there’s anything wrong with the performance though, it’s still largely a very great card, the performance is fantastic, but it just feels like something may be missing. I hope and honestly largely expect that this will improve with a few driver updates, as things always do. I suspect in a few weeks or a couple of months, the Super variants will have a bigger lead on the non-Super cards they are replacing.  \n>  \n>What I do like about both the Gigabyte and INNO3D cards is the cooler upgrades. Gigabyte has honed its Windforce designs over the years, and INNO3D has a great-looking product too with a 2-slot form factor. Having a premium quality cooler on this chipset showed that it can run nice and cool and quiet, while still delivering great performance overall.  \n>  \n>So overall, the 4070 Ti SUPER can be taken one of two ways. If you’re already rocking a 4070 Ti, then there is no reason to change to a Ti SUPER, and if you want more performance then you need to be looking at 4080 levels or above, but even then I’d personally wait for the 4080 SUPER to see what that brings, though I fear it could be the same levels as what we saw today. If however, you’re on something older and your heart was set on a 4070 Ti, then obviously it makes sense to pay the same, and get a 4070 Ti SUPER, though I’d seriously be questioning how much extra performance you’re going to be gaining over what you already have.\n\n# [Guru3D](https://www.guru3d.com/review/asus-tuf-geforce-rtx-4070-ti-super-review/)\n\n>The data speaks for itself, key factors here are gaming performance and rendering quality. Indeed, the RTX 4070 Ti SUPER offers better value for money compared to the 4080. This card is approaching the raw performance required for gaming at 4K resolution. It caters specifically to enthusiast gamers who typically use monitors with UWHD, QHD, or UHD resolutions, making it an ideal choice for that demographic. The rasterizer engine in the RTX 40 series significantly surpasses the performance capabilities of its predecessors. This series introduces a new generation of more potent Ray tracing and Tensor cores. Raw counts of RT and Tensor cores are not the sole indicators of performance; rather, the effectiveness of each unit is key. These cores are positioned near the shader engine, enhancing their efficiency, a fact that is evident in their performance. While Tensor cores' impact is more challenging to quantify, the impressive results observed, especially with DLSS3, indicate their robust performance. The GeForce RTX 4070 Ti demonstrates its strength across various resolutions, performing effectively from 2K (2560x1440) to 4K (3840x2160).  \n>  \n>Overall the GeForce RTX 4070 Ti SUPER delivers a robust gaming experience, and when comparing it directly to similar GPUs, it surpasses the performance range of the 3090 Ti and is close to the RTX 4080, with some variability. In a broader context, when comparing it to other GPUs like the Radeon RX 6950 XT and 7900 XT/XTX, a complex decision-making process ensues. The choice between the 4070 Ti SUPER and 7900 XTX hinges on several factors. The RTX 4070 Ti SUPER excels in ray tracing performance and boasts the added benefit of DLSS3/3.5 and at many levels is on par with more than 3090 cards. Looking at Team Red the 7900 XT exhibits a slight advantage in rasterizer engine performance, supported by its additional L3 cache. The 16GB of VRAM offered by the 4070 Ti SUPER is sufficient for most current titles, especially when playing at Ultra HD resolutions. Powered by the ADA GPU architecture, this card delivers precision and competence in gaming. The substantial increase in shader cores translates to nearly 1.5 times the raw shader performance, resulting in faster ray tracing and improved Tensor core performance. Underlying technologies such as Shader Execution Reordering (SER) and DLSS 3 contribute to the excellence of the new product and the Series 4000 overall. In conclusion, the GeForce RTX 4070 Ti SUPER leaves a notable impression and is sure to please gamers, but it comes at a considerable cost. Despite its commendable performance-per-watt ratio, its energy consumption levels remain relatively high. This graphics card is capable of handling Ultra HD gaming smoothly, particularly when enhanced with DLSS3 / Frame generation, and offers the possibility of a moderate overclock. The TUF Gaming version of the GeForce RTX 4070 Ti SUPER offers an appealing choice for users who value a quiet performance and visual appeal in their PC gaming setup. The model we tested today, which is the non-overclocked (nonOC) version, is priced at the manufacturer's suggested retail price (MSRP) of $799 for retail purchase.\n\n# [Hot Hardware](https://hothardware.com/reviews/asus-geforce-rtx-4070-ti-super-review)\n\n>At this point, NVIDIA’s blueprint with the [GeForce RTX 40 SUPER](https://hothardware.com/reviews/nvidia-geforce-rtx-4070-super-review) series is clear – boost performance at similar (or lower) introductory prices, to enhance the overall value of the line-up. The ASUS TUF GeForce RTX 4070 Ti SUPER arrives at the same $799 price point of its predecessor, but offers more cores, more video memory, and ultimately more performance across every workload. The ASUS TUF GeForce RTX 4070 Ti SUPER can’t quite catch the GeForce RTX 4080, bit it comes close in many tests, for a couple of hundred bucks less.  \n>  \n>With [recent price cuts](https://hothardware.com/news/amd-slashes-radeonrx-7900-xt-price), the [Radeon RX 7900 X](https://amzn.to/42cJYaA)T is being offered for about $710. Looking back through the numbers, that price adjustment is just about in-line with its performance relative to the ASUS TUF GeForce RTX 4070 Ti SUPER if you factor in ray tracing. In games that don’t make extensive use of ray tracing and mostly rely on traditional rasterization techniques, the Radeon RX 7900 XT may pull ahead of the RTX 4070 Ti SUPER. Today’s GPUs are about much more than gaming, however. Looking at the content creation, rendering, and other compute tests and the ASUS TUF GeForce RTX 4070 Ti SUPER outpaces the Radeons.  \n>  \n>Ultimately the GeForce RTX 4070 Ti SUPER represents additional value for gamers and creators. It arrives at the same price point as its predecessor, but effectively offers more of everything. If you’ve got the budget and are looking for a GPU its price category, the GeForce RTX 4070 Ti SUPER is the card to beat right now, and ASUS’ TUF model ticks many of the right boxes.\n\n# [Igor's Lab](https://www.igorslab.de/en/msi-geforce-rtx-4070-ti-super-ventus-3x-16-gb-in-test-desired-upgrade-with-contemporary-memory-expansion-and-under-pressure-from-amd/)\n\n>The GeForce RTX 4070 Ti Super is an excellent card in WQHD when it comes to the highest frame rates and is also quite suitable for Ultra HD. At the latest then, however, you will have to think about smart upscaling in places and this is where DLSS and frame generation come into play. Meanwhile, games such as “The Last of Us Part 1” (TLOU) look subjectively even better in Ultra HD with DLSS than native Ultra HD. This is where NVIDIA can really play to its advantages, which DLSS 2.x and, above all, DLSS 3.5 also offer in purely visual terms.  \n>  \n>However, if a game also supports frame generation and you would still be bobbing around in the less playable FPS range even with super sampling, then this can even be a lifeline to good playability. You can’t improve the latency with it, but not every genre is as latency-bound as various shooters. I would have really liked DLSS 3.5 for TLOU, but you can’t have everything. From this point of view, the GeForce RTX 4070 Ti Super completely fulfills all expectations based on the data already published. All the AI including the appropriate programs, DLSS 3.5, frame generation and the often better latencies are also good arguments. If it weren’t for the current dumping by AMD, which should be just right for the customer.  \n>  \n>The GeForce RTX 4070 Ti Super with the AD103-275-A1 is a thoroughly interesting upper mid-range card, but nothing more at the moment. Especially in view of the AMD Radeon RX 7900XT and the current price difference, it won’t sell for the really good features, but rather only for the street price. Apart from the outdated display port connection, I don’t see any disadvantages at all with the GeForce RTX 4070 Ti Super that would speak against this card, only the price has just been badly undermined by the competitor. We will have to wait and see whether the so-called OC cards justify the additional price. After all, MSI has shown with the Ventus 3X that even the MSRP card can almost perfectly convert the additional performance of the significantly increased number of shaders into adequate gaming performance.\n\n# [KitGuru Article](https://www.kitguru.net/components/graphic-cards/dominic-moass/nvidia-rtx-4070-ti-super-review-ft-msi/all/1/)\n\n# [Kitguru Video](https://www.youtube.com/watch?v=WdmZLIWGYo8&pp=ygUHa2l0Z3VydQ%3D%3D)\n\n>Ultimately, the RTX 4070 Ti Super is about as good as I was expecting considering the 10% bump in core count and the switch to 16 gigs of memory over a 256-bit interface. I will certainly be interested to see how other models compare, as if the Ventus 3X really is 5% slower than what the 4070 Ti Super should be, then that's only a further positive for the new GPU as a whole.  \n>  \n>Of course, I can only base my conclusions on what we have tested, but even then this is a strong refresh and a GPU that's well worth buying. I do believe the RX 7900 XT remains a credible option if rasterised gaming is your top priority, as it is still slightly faster overall, while [some strategically timed cut-price deals](https://www.scan.co.uk/products/powercolor-radeon-rx-7900-xt-hellhound-20gb-gddr6-ray-tracing-graphics-card-rdna3-5376-streams?utm_source=pc%20part%20picker&utm_medium=referral) only increase the value proposition. That said, I think if you are spending £750+ on a new graphics card, chances are you will be tempted by the superior ray tracing performance, DLSS support and increased efficiency of the **RTX 4070 Ti Super**.\n\n# [LanOC](https://lanoc.org/review/video-cards/8952-asus-tuf-gaming-rtx-4070-ti-super)\n\n>As for its performance, the RTX 4070 Ti SUPER has 10% more CUDA cores and Nvidia has also increased the video memory up from 12 GB to 16 GB which should help at high resolutions and help keep the card relevant in the future for longer. In my testing, this translated to a 6-10% increase in performance depending on the testing. In game at 1440p it was 5.5% faster than the overclocked TUF Gaming RTX 4070 Ti that I tested previously but at 4K this ramped up to 10% and I saw similar numbers in synthetic benchmarks like Time Spy and Time Spy Extreme which it improved 6.8% on Time Spy and 9.1% on Time Spy Extreme. This helped it catch up with AMDs RX 7900 XT, especially at 4k but the 7900 XT was on average still 3 FPS faster at 1440p. Where the 7900 XT didn’t keep up was with ray tracing performance and once you figure in DLSS which the games you are playing support it is a huge improvement. The performance improvement also helped with overall efficiency. While it has the same TGP our TUF Gaming RTX 4070 Ti SUPER did pull a hair more than our overclocked TUF Gaming RTX 4070 Ti did for power, but with the performance improvement its already great power to performance was even better. The cooler for the TUF Gaming RTX 4070 Ti SUPER ran surprisingly quiet in my testing as well and while I wouldn’t say the cooling performance was the best it did perform well keeping the card more than cool enough which when combined with how quiet it was would make me happy.  \n>  \n>As for pricing the TUF Gaming RTX 4070 Ti SUPER is launching at the RTX 4070 Ti SUPER launch MSRP of $799. This fits right in at the same MSRP as last year's RTX 4070 Ti which is it replacing. There aren’t any game partnerships right now however which is a bummer given that AMDs RX 7900 XT does come with Avatars Frontiers or Pandora. AMD did also just recently dropped the pricing on a few of their cards including the 7900 XT which now has an MSRP of $749 in response to Nvidia’s SUPER cards announcement. This does put the 7900 XT as the better value if you are looking only at raster performance, but I do think that the ray tracing and DLSS performance have a lot of value as well and that $50 difference still makes this a good pickup if you are looking for high-end performance without spending RTX 4080 or RX 7900 XTX numbers. The TUF Gaming RTX 4070 Ti SUPER specifically is looking especially appealing this time around given that there isn’t a Founders Edition for this GPU and its all-metal construction. Asus does have an overclocked model as well which will hit stores at $849.99 and a white overclocked TUF model for $879.99. They will also have a Pro Art card for that same $879.99 price point and then a Strix model as well which has a hefty $949.99 price point which is WAY too close to the announced MSRP of the RTX 4080 SUPER in my opinion.\n\n# OC3D Article - TBD\n\n# OC3D Video - TBD\n\n# [PC Perspective](https://pcper.com/2024/01/nvidia-geforce-rtx-4070-ti-super-review-featuring-asus/)\n\n>This was a refreshing review. Not just because the RTX 4070 Ti has been refreshed, and is now SUPER for the same price, but because it really lives up to the SUPER branding with double-digit gains over its predecessor. This card is being neatly dropped in to the same price slot as its predecessor, bringing quite a bit of RTX 4080 DNA along with it.  \n>  \n>You know, it’s like NVIDIA was holding out on us. They could have released the RTX 4070 Ti in this AD103 configuration, with this level of performance, all along – if they really wanted to. It would have made the original $799 price tag a lot more palatable. Or maybe they were playing chess, and now that we’ve accepted this price level they’re bringing performance in line with expectations… I think I’m babbling at this point.  \n>  \n>Bottom line, the new GeForce RTX 4070 Ti SUPER isn’t just the first card in NVIDIA’s history to be both a **Ti** *and* a **SUPER** at the same time; it’s a solid performer with a significantly better price/performance ratio than its predecessor. We can’t argue with that. And once you factor in ray tracing performance, DLSS, and Frame Generation (if you’re into that sort of thing), at $799 this is a lot of GPU in the current market .\n\n# PC World\n\n>TBD\n\n# TechGage\n\n>TBD\n\n# [Techpowerup](https://www.techpowerup.com/review/asus-geforce-rtx-4070-ti-super-tuf/)\n\n>With these performance numbers RTX 4070 Ti Super is a perfect match for 1440p with maximum settings, it's actually slightly overkill, which means that the card is a decent option for 4K monitors, too, or for 1440p at 120/144 Hz. While you won't be able to game at 4K60 at highest settings, just dropping them down a bit should help get those 60 frames and there's always the various upscaling technologies, especially if you plan on enabling ray tracing. Just like the other GeForce 40 cards, RTX 4070 Ti Super has support for all of NVIDIA's DLSS technologies: NVIDIA DLSS 2 upscaling, DLSS 3 frame generation and DLSS 3.5 ray reconstruction. On top of that you can enable AMD FSR 2 and FSR 3 in games, because those technologies work on all GPUs from all vendors. Basically this means that you'll be covered in terms of upscaling and frame generation. While DLSS 3 is definitely the leading solution right now, with best game support, AMD is pushing hard and their frame generation solution will come to several major titles in 2024. From a technology perspective, DLSS 3 is superior, because it uses the optical flow hardware unit in Ada GPUs, and NVIDIA Reflex will help bring down the input latency.  \n>  \n>The biggest selling point of the RTX 4070 Ti Super vs the RTX 4070 Ti non-Super is the increased VRAM size of 16 GB. RTX 4070 Ti's 12 GB VRAM size has been a constant topic for debate on tech forums, so it makes a lot of sense that NVIDIA is giving us a 16 GB option now, and at pretty reasonable pricing, unlike RTX 4060 Ti 16 GB. Unlike more cores or higher clocks, more VRAM will not make all games run faster automatically. Across all the 100+ game tests, (25 raster + 10 RT) x 3 resolutions, we only identified two cases where 16 GB results in a meaningful improvement over 12 GB: The Last of Us 4K and Alan Wake 2 RT at 4K. No doubt, you will be able to find more such results with other titles, too, but the vast majority of games out there will not see any meaningful improvement from the 16 GB upgrade. I'm sure that this will change in the coming years, with more and more games increasing their VRAM requirements, but I don't think that a 12 GB card will suddenly turn out to be useless in 2024 and 2025. You also have to consider that as soon as you enable upscaling, the actual render resolution is reduced, which lowers the VRAM usage significantly. Still, given all the drama about 12 GB VRAM—people can finally put their money where their mouth is and grab the RTX 4070 Ti Super 16 GB.  \n>  \n>A secondary effect of the 16 GB VRAM capacity is that the bus width is increased from 192-bit to 256-bit (or +25%). This is required, because to achieve 16 GB, you need to install eight 2 GB memory chips, each having a 32-bit interface to the GPU. With just 12 GB and six chips a 192-bit interface is sufficient (6 x 32 =192). This 25% increase in bus width leads to an equivalent increase in memory bandwidth, which should help provide an additional performance boost. Looking at my data I'm not so convinced. While the card does have slightly better scaling than RTX 4070 Ti 12 GB, the RTX 4080 is still able to pull away at higher res. It seems that what matters more for performance scaling is the L2 cache size and not the VRAM bus width. Unfortunately NVIDIA did limit the 4070 Ti Super to 48 MB L2 cache, while the RTX 4080 gets the full 64 MB.  \n>  \n>As expected, ray tracing works very well on the GeForce RTX 4070 Ti Super, clearly offering a superior experience than what Radeon RX 7900 XT, and often even RX 7900 XTX, can achieve. On average, the RTX 4070 Ti Super offers 22% higher FPS with RT than RX 7900 XT, which is quite a bit. NVIDIA's new card also shows better RT performance numbers than RX 7900 XTX in most games—if you're betting on ray tracing, then definitely opt for the RTX 4070 Ti Super. That doesn't mean that RT is unusable on AMD, it's just running considerably slower, because their cards are lacking dedicated hardware units to accelerate RT operations.\n\n# [The FPS Review](https://www.thefpsreview.com/2024/01/23/asus-tuf-gaming-geforce-rtx-4070-ti-super-video-card-review/)\n\n>Overall, when it comes to rasterized gaming without Ray Tracing, the new GeForce RTX 4070 Ti SUPER is around 12% faster than the GeForce RTX 4070 Ti. This was the common number we experienced mostly, without Ray Tracing. When Ray Tracing was used, this percentage number crept up slightly. With Ray Tracing the GeForce RTX 4070 Ti SUPER was more like 15% faster, with some outliers like Alan Wake 2. There are of course games, where the percentages were lower, around 10% or 11%, maybe even some under, as you lower the resolution. The highest differences were at 4K or with Ray Tracing.  \n>  \n>Looking at performance compared to the Radeon RX 7900 XT is more mixed. The Radeon RX 7900 XT put up a competitive fight, and in many games was as fast as the GeForce RTX 4070 Ti SUPER or faster. When looking at raster performance, without Ray Tracing, the Radeon RX 7900 XT is compelling in its performance by comparison, and this was at 4K and 1440p. More often than not, there were standout games like Starfield, or Cyberpunk 2077, or Returnal or Dying Light 2 where the Radeon RX 7900 XT seemed to get the edge on the GeForce RTX 4070 Ti SUPER. Even in Alan Wake 2, performance was equal between the cards, delivering the same experience.  \n>  \n>The one sore spot for the Radeon RX 7900 XT is once again Ray Tracing. This is going to be game dependent, and also depend on the types of Ray Tracing effects used and how heavily implemented they are. The GeForce RTX 4070 Ti SUPER has a huge lead in Path Tracing performance, as is shown in Alan Wake 2 and Cyberpunk 2077. Overall, the GeForce RTX 4070 Ti SUPER is going to deliver much higher Ray Tracing performance in games. In some circumstances, you can use upscaling FSR on the Radeon RX 7900 XT to make it playable, but this brings up the image quality of FSR at 1440p.  \n>  \n>That is an advantage the GeForce RTX 4070 Ti SUPER has, DLSS, and RTX features. When the going gets tough on the GeForce RTX 4070 Ti SUPER with Ray Tracing you can also use upscaling on it with DLSS. Overall, DLSS has superior image quality to FSR at lower resolutions, like 1440p. You will more likely want to use DLSS on the GeForce RTX 4070 Ti SUPER than you would want to use FSR on the Radeon RX 7900 XT at 1440p if you also want to get good Ray Tracing image quality. The GeForce RTX 4070 Ti SUPER also has DLSS 3.5 Ray Reconstruction support, to improve Ray Tracing image quality. In games that support it, like Alan Wake 2 and Cyberpunk 2077, its Ray Tracing image quality is unmatched.\n\n# [Tomshardware](https://www.tomshardware.com/pc-components/gpus/nvidia-geforce-rtx-4070-ti-super-review)\n\n>This isn't a generously priced graphics card, in other words, and by raising the MSRP, Nvidia probably took a more sizeable cut from its AIB partners. Still, it's certainly better than paying the same $800 for the RTX 4070 Ti — which is probably why the base price on those cards has fallen to around $740, and we've seen sales push the price as low as $720, which is still arguably too high.  \n>  \n>Is the RTX 4070 Ti Super worth the asking price? That depends on what you want to do with it. Relative to AMD's RX 7900 XT, even at its current promotional pricing starting at $709, you can certainly make arguments in favor of Nvidia's GPU. It's more power efficient, is potentially better equipped for future games (if ray tracing adoption picks up), offers access to Nvidia's proprietary DLSS features, including frame generation, and you get superior AI performance.  \n>  \n>If all you care about is rasterization performance, AMD's 7900 XT comes out ahead and offers a better value. And there are hundreds of new rasterization-only games released every year. But if you value any of those other 'extras' — even if you only think you might want to try them — Nvidia has cards at every price point that are worth a look.  \n>  \n>Ultimately, the RTX 4070 Ti Super provides some worthwhile improvements over its non-Super predecessor. If you're in the market for a high-end Nvidia GPU and you haven't upgraded in a few years, it's a great card. Just don't be surprised when next-generation GPUs come out in a year or so that have even more new features, improved performance, and just maybe not a massive generational price increase. (We can dream about that last one, right?)\n\n# [Computerbase - German](https://www.computerbase.de/2024-01/nvidia-geforce-rtx-4070-ti-super-review-test/)\n\n# [HardwareLuxx - German](https://www.hardwareluxx.de/index.php/artikel/hardware/grafikkarten/62759-mehr-speicher-zum-gleichen-preis-die-geforce-rtx-4070-ti-super-im-test.html)\n\n# [PCGH - German](https://www.pcgameshardware.de/Geforce-RTX-4070-Ti-Super-Grafikkarte-280115/Tests/RTX-4070-Ti-Super-Leistungsprobleme-BIOS-Firmware-Updates-1438677/)\n\n# ----------------------------------------------\n\n# Video Review\n\n# [Daniel Owen](https://www.youtube.com/watch?v=lDpr84DK7xQ&pp=ygULZGFuaWVsIG93ZW4%3D)\n\n# Der8auer\n\n# Digital Foundry Video\n\n# [Gamers Nexus Video](https://www.youtube.com/watch?v=QruyaA0ZrLk)\n\n# Hardware Canucks\n\n# [Hardware Unboxed (Updated Review with TUF)](https://www.youtube.com/watch?v=98ogL7ijrik)\n\n# [JayzTwoCents](https://www.youtube.com/watch?v=8U_S8vrRs-Y)\n\n# [Kitguru Video](https://www.youtube.com/watch?v=WdmZLIWGYo8)\n\n# Linus Tech Tips\n\n# OC3D Video\n\n# Optimum Tech\n\n# [Paul's Hardware](https://www.youtube.com/watch?v=PRxxc-0VfnM)\n\n# Techtesters\n\n# Tech Yes City\n\n# The Tech Chap\n\n# [zWORMz Gaming](https://www.youtube.com/watch?v=mcBr6UDV5pE)\n\n\\-----------------\n\n# [\\[PSA\\] Certain MSI GeForce RTX 4070 Ti Super Ventus 3X VBIOS Causes Lower Performance Than Expected](https://www.reddit.com/r/nvidia/comments/19dq7le/psa_certain_msi_geforce_rtx_4070_ti_super_ventus/)",
    "comments": [
      "Mann i was pretty hyped for it, these reviews do kill the hype a bit",
      "So basically not the same performance as the 4080 that many people were saying it would be.",
      "It seems like if you're considering paying 800 for a 4070 ti super, you should just take the 200 increase for a 4080 super.",
      "Agreed, between the less than stellar reviews, the lack of an FE, and my mobo/ram lost in the mail I’m just going to wait another week and try and snag a 4080S",
      "They missed the cache is cut down from 64MB to 48MB, same as 4070S. They fooled people by using the 103 die and rumors assumed that means similar or close performance.  With the same cache perhaps closer, but not here in cheap-ville chipmaker USA.",
      "The 4080 is now the top tier graphics card for gaming. 4090 will always be AI/machine learning and rich kid gaming. In short marketing to upsell to 4080S or down to 4070S.  Remember NVidia doesn’t want you to buy this card which is why no FE.  They have stockpiled enough rejected 4080 dies to do this, but can’t have it with 64MB and too close to original 4080.",
      "I'm on the lower end, was gna stretch my budget a bit for the 16gb RAM but this just makes me want to go back to the 4070",
      "People were going crazy when the specs were right in front of us the whole time.\n\n4080 has +15% cores, +33% L2 cache, slightly higher memory bandwidth, higher TBP\n\nWhy would anyone expect the Ti Super to have the same performance as the 4080??",
      "It's about 10% better than 4070S.  Honestly, if money is tight you're perfectly fine with the 4070S.",
      "Overhyped, wasn’t nearly as close to the 4080 as we thought.",
      "Was this nvidia's plan all along lol",
      "Tbh, people are on a negative train cause they wanted the world.\n\n4070 Ti normal could do 4k@60 with RT no problem - let alone 1440p. Your fine. People want to be negative.\n\nThe reality is both the 4080S/4070 ti are not good values. 4080s might be a bit better but your throwing more money into a stop gap generation. I sold my 3090 3 weeks ago and got $720 when all is said and done. I know this gen is garbage but for $100+ i can get DLSS 3, get a 10% boost, and wait for whats next.\n\n&#x200B;\n\nPeople need to stop pretending like any of these cards are great. The 4080/4080 Super isnt great either. Its why last generation cards are still selling for a boat load.",
      "I have a 3080 ti and I *hate* how it sounds like a jet engine taking off and runs so hot I have to open my window in winter to keep my room from getting uncomfortably warm. Undervolting helped some but causes games like Alan Wake 2 to crash so I ended up just going back to stock settings.\n\nI'm seriously considering a 4070 ti super or 4080 super just to have lower power needs (and therefor hopefully lower temps / quieter fans).\n\nAm I crazy?",
      "Not at all with the cut down cache. It’s exactly where it should be. 48MB cache(same as 4070S) vs 64MB on 4080.  Using 103 die means nothing beyond 16GB layout.  It’s gimped more than usual cut down cards are.  Even Tom’s hardware is listing 64MB in their review because of this assumption incorrectly.",
      "meh",
      "Text wall incoming! I just want to thoroughly share my experience with my 3080 Ti and 40 series. \n\nI’m using a Gigabyte 3080 Ti Vision OC and it seems that the heat sink is just not big enough for the stock TPD across most 3080 Ti models, causing a the stock fan curve to be aggressive and loud. Running stock, I pull about 350W average and the fan speed likes to hover around 80% which is very audible especially with my mesh panel case and open back headphones. \n\nLast month I financed and later returned a 4080 from Best Buy and it was significantly cooler and quieter than the 3080 Ti. Full load it was barely tapping 240W and the fans sat around 50%, completely inaudible from my sitting position, all while smashing the fps in ways the 3080 Ti couldn’t. Alan Wake 2 1440p everything ultra with path tracing, over 60fps in most areas without upscaling while running cool and quiet. \n\nSo after THAT experience, I worked pretty hard to get my 3080 Ti to settle down on the heat and noise and wound up with what I consider I decent under volt. My silicon isn’t great so it wasn’t stable using a lot of the common 3080 Ti undervolt values I found in Reddit. But I’ve currently got it OC’d at +120 MHz on the curve, with voltage limited to 850 mV at 1785 MHz and a power limit of 84% + a custom fan curve, which has helped reduce heat and noise immensely. Fans sit around 60-65% with power between 240-280W and only a 2-3% fps loss. Use DLSS and that fps loss is negligible. \n\nOn top of all of that, I just tried out the DLSS + FG mod and it’s worked wonders in some demanding games. With the mod and undervolt, Jedi Survivor doesn’t dip below 120fps on Ultra no RT, DLSS quality + FG on. Exact same performance increase on Hogwarts Legacy. In cyberpunk Path tracing is too demanding without a 40 series card, even with the mod, but standard RT and ultra settings was a breeze. \n\nThat said, I’ve got a 4070 Super FE readying up at Best Buy since I can sell the 3080 Ti for close to the 4070S msrp and hopefully avoid having to mess with undervolting and modding while getting 5-10% better performance.",
      "Yeah. It seems like NV intentionally wanted to upsell people to the 4080S since the 4090 is so damn expensive.",
      "[https://cdn.mos.cms.futurecdn.net/vWJtUTXRbC4od53gZm7VtH-1200-80.png.webp](https://cdn.mos.cms.futurecdn.net/vWJtUTXRbC4od53gZm7VtH-1200-80.png.webp)\n\nNot even close tbh. VR is higher resolution. The median puts it at 20%.\n\n&#x200B;\n\nIts hard to say 2K gaming and VR are two entirely different things.",
      "i was figuring the 4070 ti super for the extra vram. i play on 1440p rn but 4k is the future",
      "you shouldn't care how much better it is vs 4080 unless you're upgrading from 4080\n\nI'm upgrading from a 5 years old card, so I'm only looking at the value of the card I'm buying, not how much it changed vs another card.\n\nso from that perspective, paying much more for RTX 4080 Super seems questionable and it's irrelevant how much 4070 Ti Super is faster than 4070 Ti, the only relevant thing is how good value in absolute terms is 4070 Ti Super and how good value is 4080 Super\n\n4080 Super is still much more expensive (worse value) than 4070 Ti Super"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "4070"
    ],
    "title": "Is 4090 over kill for 3440x1440p? Or save money and go with 4070 ti / 4080?",
    "selftext": "In 3 minds with what to get! Prices on cards I like are \n\nStrix 4090 oc £1550\n\nStrix 4080 £1100 / 1150 oc\n\nStrix 4070 ti £800\n\nOr cheaper 4080 £950 / 1000\n\nCheaper 4070 ti £700 / 750\n\n\nEDIT: Went with the 4090 Rog Strix! Thanks for all your recommendations. Chose the Strix mainly as I have mostly Asus Parts & I do like the looks. It has zero coil whine. Looking forward to trying this DLDSR a lot of you have mentioned. This was probably the deciding factor for me. As it sounds pretty epic!",
    "comments": [
      "I use a 4090 at that resolution, I find it amazing.",
      "If someone can afford a 4090, they should buy a 4090. I don’t believe in GPU overkill. At 3440x1440 I’ve found numerous games that already push my 4090.\n\nAnd if you have a lot of overhead just use DLDSR for an even crisper image",
      "4090 at 2560x1440p here, 4090 is never an overkill, especially when you want RT/PT and max out all settings.",
      "I have 4090 with this resolution and its just fine. I would not change.",
      "its a 4090... there is nothing to change to",
      "People said the 1080Ti was overkill for my needs back then.\n\nThat thing gave me 6 years of incredible performance.",
      "Have the same with 165hz - it is perfect and with 24GB fit for future games!",
      "No such thing as overkill. All power will be used up eventually.",
      "Actually, I think they meant their fundamental self. They are a resolute entity in the face of torrential dynamics.",
      "This. I game at 1440p with everything maxed out with my 4090. Also prefer the higher frame rates compared to what I get switching to 4k (on a c2 OLED)",
      "If you are not satisfied with 13th gen, 14th gen will not change that, it's just a minor revision, and from the benchmark data, it seems that the 14900K is barely faster than a 7800X3D. 14th gen might overclock more, and with good memory you might see a 10% uplift over 13th gen at best. Of course, it makes sense to buy 14th gen now if you want an intel systems, but if your main reason for going 14th gen is because you are not satisfied with the performance that 13th gen offers, you might be disappointed. I mean if all you care about is gaming.",
      "He meant \"I would not change\" as to something less powerful while saving money.",
      "Still the best component purchase I ever made, and it hurt pressing the buy button at the time. \n\nIt’s what convinced me to get the 4090.",
      "That other dude is being a jerk about it but, I also do see a significant difference between 4k and 1440p. So much so I can't go back to 1440p. Similar to lower fps after playing at higher fps... once you see it, it's tough to go back.\n\nThat being said, hey if you don't notice the difference, more power to you. I mean that in a positive way. I wish I could un-notice it! Haha",
      "Same. 1440 ultra wide and FE 4090. \n\nEverything on max, works up to the 240hz limit on my screen.\n\nEDIT: Read this punks! https://www.reddit.com/r/nvidia/comments/ze3c8q/any_cpu_bottlenecks_with_4090/\n\nGenerally, as someone eloquently put it in that thread, you want your most expensive componsent to be the 'bottleneck'. I'm waiting for the 14th gen and new socket.",
      "Paying for the name",
      "Considering the amount of pixels you have to push, a 4090 won’t be overkill at all, and depending on your local prices, you can almost get a decent 4090 for 4080 Strix money. If the listed prices are representative of current prices in your market, those prices don’t look too bad.\n\nIn Denmark we REALLY get shafted with the ASUS tax.\n\nIf you want to get the most out of your budget…\n\nAre you getting the Strix because of aesthetics or because you intend to do hardcore OC, where the overbuilt board will get to stretch its legs?\n\nA 4090 is a 4090, so paying the ASUS tax won’t give you noticably more performance compared to other cards, and ASUS do not put fuses on the boards, unlike MSI and Gigabyte, so if a component blows, it’ll have a much higher risk of taking the whole card with it.\n\nConsidering how overbuilt the coolers are (with the exception of the TUF OG that has a 30-series cooler), you won’t have issues cooling even the most basic 4090. There is of course the noise aspect, and for that I’d look at card benchmarks that cover this area, because some cards will be louder than others.\n\nIf you want to OC, you could always look for cards with more headroom for power limit adjutment and vapour chamber coolers for squeezing the last drops of performance while staying cool. All of this can usually be looked up on Techpowerup’s database of graphics cards.\n\nHope you will find the right card for you and will enjoy it for a long time!",
      "Sorry what ?  13th gen cant keep up ?",
      "You should upgrade your cpu. I had the same one you do, the fps lows get a huge boost",
      "Supersampling alone hasn't been efficient in 10+ years. DLSS/DLAA or the best comb DLDSR+DLSS produce a vastly better image to a supersampled one."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "4070"
    ],
    "title": "NVIDIA splits GeForce RTX 4070 review embargo to MSRP and non-MSRP cards - VideoCardz.com",
    "selftext": "",
    "comments": [
      "MSRP will make the 4070 look better as the reviews will use cards that are of limited stock and will be phased out by more expensive AIB models.",
      "Not one comment in here actually addresses the article: why is NVidia splitting the embargo? To what purpose does that decision make?",
      "Nvidia’s really banking on frame generation being the primary selling factor on these cards.\n\nNo pricing info yet, but I’m betting it’ll be comparable to whatever the similarly-performing 3000 series card’s MSRP was.\n\nIt’s amazing that the only product this gen has produced that offers an actual raw performance increase at the same price point as the previous gen is the damned top-tier halo.\n\nApparently Moore’s law is only dead if you’re looking to spend less than $1600.",
      "Msrp card: poor value like the rest of the lineup, but probably the worst value of them all.\nNon-msrp card: even worse, so publish reviews later.",
      "You mean you don't want essentially a 3080 that's called a 4070 and priced the same as a 3080 was at launch? \n\nHow could you! It's like you don't want Jensen to be able to afford a new leather jacket!",
      "> Nvidia’s really banking on frame generation\n\nThis card is DOA. The reviews comparing the 4070Ti vs the 3080 spell it out for everyone plainly. 20% higher average FPS in non RT games for at a minimum 19% more cost. The 4070 will almost certainly be a worse buy.",
      "I want a good card for 300-400 euro's. Nvidia or AMD can't get people like me with these prices. I feel like they are ignoring a huge market. Why do we need so many models anyways.",
      "Man how times have changed. The 70 was usually the best bang for buck.\n\nNow it's the 4090?? Lmao 🤣",
      ">4070 TI\n\nDon't you mean the 4070?\n\nThanks for addressing the article. Makes sense, now!",
      "Why do people care so much about DLSS and frame generation to begin with? Games need to actually support those AFAIK while raw performance is universal.",
      "Don't worry, you're getting 8 GB of VRAM compared to 10/12, it's actually a step back from the 3080 :)",
      "Well DLSS in general is pretty ubiquitously supported these days on most GPU heavy games and frame generation adoption is going very well given how new it is.  It would be silly to not care about it.",
      "This!!! Exactly this!!! WTF is this trend for 2000 euro flagship models and 800 euro mid-tier cards! I got my GTX 980 for 450 euro and that was the flagship back then. The 4070 (not Ti) should be a 400 euro card. Same for AMD. The 6700xt replacement should also be a 400 euro card. If these companies keep releasing 800 euro mid tier cards and gimped low tier cards for 300 euro then let them eat shit! I'd rather buy a PS5!",
      "The 3090 ti was horrible value in the first place. So was the 3090 compared to the 3080.",
      "300 euros will get you 4030 GT considering NVIDIA's new pricing strategy.",
      "Cant wait for another launch where we get only a handful of MSRP cards for the first few days, but after that the only available cards will be the \"OC models\" that are 100$ more expensive for that 1% core clock increase :)",
      "Its all about the price. If its 550-600$ its \"fine\". If its anothery 800 euro card in EU - this card is DOA.",
      "I honestly feel the 4000 series GPUs below the 4090 aren't worth it, much like the 2000 series which only the 2080 Ti was worth any mention at all. The 5090 will likely demolish everything by a country mile with 2x performance gains over the 4090 in frame Gen and DisplayPort 2.1 support.",
      "Repeat of Turing, which also came after a mining period. Fuck miners and the companies that took advantage of it.",
      "Nvidia wants as much initial reaction as possible to be to the product *at MSRP.*\n\nWe can conclude that this means that the price of the 4070 will be within $200 of the Ti model, and that they're expecting the more expensive AIBs to be within $50 of the base MSRP for the 4070Ti, which obviously would make it a terrible value. \n\nMost AIBs will have an MSRP card, but there won't be much stock initially available and it won't be restocked as quickly as more expensive models, because they're not as profitable.\n\nThe 3000 series might be a bad example, because mining drastically increased demand, but most 3000 series AIBs only made a small initial stock of MSRP cards, and then for the next 12-18 months only produced/restocked their top-end models, which were often $120-200 more than MSRP.\n\nBut if there's not enough demand to keep the top-end cards selling out, it's feasible that they'll produce and restock more of the MSRP models."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "4070"
    ],
    "title": "Nvidia's RTX 4070 Will Allegedly Boost to 2.8 GHz",
    "selftext": "",
    "comments": [
      "Can we just wait for the actual announcement at this point? \n\n\nNew rumor: 4090Ti will pull 1420 watts and boost to 6.9 Ghz.",
      "New rumor: 4090Ti will automatically get popcorn kernals out your teeth. Big if true.",
      "Instant buy if true.",
      "I was waiting for a 4070, but I got tired of all the leaks and just bought the strix 3080 12gb instead.",
      "And your 3080 will still be awesome when the 40 series launches. Enjoy it!",
      "Hell yeah, I wonder what rumor is next. Maybe the 4090 ti will come with leather jacket that and be overclocked to 80085 mhz",
      "I've become disgusted with the rumors tbh, they all over the place.",
      "Yea these people full of shit at this point. There have been so many 4000 series rumors and nothing has actually been validated. Hell, remember when nvidia was reportedly launching in July according to “leakers”.",
      "New rumor: 4090Ti will be cooled by the soul energy emanating from hell.",
      "Another day, another Tweet with Kopite pulling stuff out of his ass. What else is new.",
      "Also they are not very interesting. Like who tf cares about boost clocks? They mean very little unless you are comparing identical chips.",
      "New rumor: 4090Ti will call your mother on mothers day and call you on your birthday in your dads voice and tell you \"Everything will be OK, son. I love you. And I'm proud of you. Buying  PC parts may not bring me back but you will discover new worlds and they will take you away from the crushing, painful, reality that perhaps I'm at fault for creating and then leaving you to deal with alone.  It's not your fault. I was weak. You're already a better father to your son than I was to you.. and the fact you both share my mental illness is.. [Update payment details to read more]",
      "NVIDIA: We supplied a 112 page report on why this is not feasible for us as a company at this particular time, but the TLDR is that we just really love money. Thanks for being an NVIDIA customer.",
      "I recently ordered the strix 3080 as well. (coming from a 1080.) after all that's happened the past few years, I have zero confidence that a 4000 series card will be attainable by any non-scalper for quite some time.",
      "Shoresy is that you?",
      "Oh no, the performance difference might not matter much, but the price difference could....",
      "\\*insert doom plotline\\*",
      "yeh but at this point I need a GPU now and can't afford to wait till next year to get the 4070. Given the leaks stated 599$ msrp, that means after market cards would be 699 to 750$. I paid 799$ post tax for the ASUS Strix 3080 12GB. \n\nThat 50$ is worth the uncertainty.",
      "You're a fool just like the guy you're replying to. Every time people doubt kopite, and every time they are proven wrong. Specs change during development, that's why the leaks change. So I went there, I dug up the Tweet from kopite back in January 2020 where he first drops the info of a unique PCB design of the 30-series FE cards that he got from his source. This was a nearly eight (!) months before the cards were even announced. \n\nhttps://twitter.com/kopite7kimi/status/1219322136025694208\n\nOh look, what's that? Another doubter who replied to him back then:\n\n>You seem like a troll that doesn't know what he's talking about, hey I heard wccftech has an opening you can finally join the outcasts at the lunch table\n\nSound familiar? Yeah, all the people in this thread. Of course we all know what happened. 30-series FE indeed had a unique PCB. But go ahead, tell me he just \"guessed it\", that he's never been legit, that's he's a fraud.",
      "Damn, considering I lost both my parents that’s an incredibly valuable feature. Here’s me hoping!"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "4070"
    ],
    "title": "4070 ti super or 4080 super?",
    "selftext": "Does the $200 price difference really warrant better performance or should I just save my money?",
    "comments": [
      "The performance difference is about 15%\n\nThe cost-performance scaling is not perfectly linear",
      "Neither. Don't buy Open box from Newegg.",
      "I've heard so many horror stories with Newegg open-box conditions",
      "no it's Stay away from Open box on ASUS.",
      "Performance uplift were never scale the same with money spent in the same generation, usually double the money for about 30% in mid range and worse at high end.",
      "I noticed the 4080 super it's the OC version. Check if there is a non OC one, so you can save some money, as the 4070 it's not the OC version. this way you can compare both better in price",
      "If 1440P, get the 4070 Ti super.",
      "I've bought an open box GPU which didn't have the GPU I bought in it. Someone pulled the old switcheroo.",
      "Maximizing frames vs budget is literally performance per dollar",
      "5080.",
      "Oc 4070 ti s is $750, just checked",
      "lol no. there's a reason people wanted this class of gpu, they wanted to take a peek at the state of the art game rendering tech a.k.a Path Tracing, or they wanted something more than gaming, a little bit of media productivity. Radeon at this price point is kinda hard to  justify \"hey save a little bit to get a little bit raw performance\"",
      "It's 11% at 1080p, 13% at 1440p and 15% at 4K/UHD.\n\n[https://www.techpowerup.com/review/nvidia-geforce-rtx-4080-super-founders-edition/32.html](https://www.techpowerup.com/review/nvidia-geforce-rtx-4080-super-founders-edition/32.html)",
      "Man I’ve been out of the pc gaming loop for far too long, gonna cancel my Newegg open box order than, Jesus Christ what happened they used to be top notch????",
      "Haven’t had issues with Newegg open box yet",
      "![gif](giphy|PtfccZBHY2VBm)",
      "Some people worry about overspending for diminishing returns…",
      "Because people are jerks and think other people having fun is a waste of time.",
      "Definitely buy the card that doesn't exist yet, and is likely to exist in about 10-12 months time.",
      "Yeah looks like the better deal, also why the shade on gaming lol."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "4070"
    ],
    "title": "GIGABYTE GeForce RTX 4070 Ti AERO has been pictured, comes with new 2x8pin to 16-pin power adapter - VideoCardz.com",
    "selftext": "",
    "comments": [
      "Can’t wait for +50% performance and +80% price vs the 3070",
      "Guess we won't be seeing the 4070 or 4060 at CES.",
      "There is no reason. Market is flooded with 3070 and 3060's.",
      "Id be surprised if its 30% stronger truthfully. when you look at actualy raw performance between 40 series and their respective last gen variants it really isnt that impressive to me. all of it seems like a push for frame gen, and i personally like actually rendering frames",
      "Just put a 2x8 connector on the PCB...",
      "Yay, more adapters!",
      "3090 performance and 4 GB more VRAM than the 3070. It would've been great were it not for the alleged $900 USD price tag.",
      "They don't need them to be sustained. Just last until the current stock is dried up.\n\nPeople are paying full price for two year old cards right now. \n\nThey have zero reason to price adjust as long as people are paying what they want.",
      "We already have performance graphs for this card from when the 4080 12GB was announced. It’s about as fast as a 3090, maybe slightly faster.",
      "Wait till you see the 4060 Ti specs. You'll cry.",
      "I know lots of people aren't a fan of the huge coolers, but imo they do a much better job of cooling than most standard 2.5 slot coolers. I've had multiple cards in the past that just ran too hot and loud with standard heatsinks. My 4090 has been the quietest yet despite sometimes using 400w. \n\nI'm not saying the 4070ti should get a 4090 sized cooler, but having the cooler be a bit more overbuilt than usual is a huge plus for cooling and noise levels.",
      "Why all the goofy ass connectors and adapters?",
      "The unlaunched 4080 12GB MSRP was $900\\*. I reckon the rebranded 4070 Ti will launch at $800-850\\* as it will likely be pre-adjusted for inflation and to make it compete with the 7900XT. Regardless, even if they aggressively dropped the price, it will still be far too expensive for a 70 tier card. I expect it'll be another flop just like the 4080 16GB.",
      "Nvidia said it's to save pcb space but I don't see how that's an issue for dual 8 pins...",
      "I've seen somewhere that those will only be released in Q3 2023 which is quite sad but then maybe not as NVIDIA could finally realize the new pricing is not sustainable.",
      "When absolutely every 30 series card is gone and they can introduce the \"budget\" models voor 500-600 bucks.",
      "What's nvidias fetish with new connectors? The cards with coolers grow exponentially in size but the connectors shrink.",
      "Theyre even trying to cripple the new 3060s its just one big F the consumer",
      "Bigger cooler and fans are a selling point to me.  \n\n\nA low noise PC setup is amazing, and it's usually the gpu that is the most loud component.",
      "$900 bucks? \n\nFuck\n\nSuck my hairy nuts NVIDA.\n\nThey can't sell the stock they have for the 4080s\n\nI can wait them out"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "4070"
    ],
    "title": "RTX 5060 Ti outperforms the RTX 4070 at 4K in this new leaked benchmark, 1080p also tested",
    "selftext": "",
    "comments": [
      "Wow a next gen card with 4GB more VRAM outperforms the card one tier above it from the last gen. I sure fucking hope so.",
      "I know this articles claim sounds like a given and stupid but the 4060ti was barley an uplift over the 3060ti. Therefore, if this holds true, the 5060ti just might have the largest uplift of rasterization in the 50 series. That hurt to type.",
      "And it's 2 years after so it's cheaper ! Right ? Right... ?",
      "4060ti’s true uplift is its super low tdp. You can just shove it in any old computer and play without changing the power supply.",
      "Using MFG right?",
      "flowery mighty elderly paltry cake retire ring longing piquant punch\n\n *This post was mass deleted and anonymized with [Redact](https://redact.dev/home)*",
      "$5 its only in 4k cus vram",
      "I reserve judgement.",
      "Furmark doesn’t really rely on multiframe generation.",
      "Furmark isn't good for comparing GPUs for measuring performance in points. it is designed to check if GPU have good cooling and is not faulty.",
      "And in specific games I'm sure. It's gonna the same as the 4060ti 16gig, unable to get a realistic benefit out of its vram buffer.",
      "This point isn't moot. You can throw this card in any old pre built with a 550 watt PSU. \n\n\nJust so you know, the 4060ti is the 4th most popular GPU on the planet - so you couldn't be any more incorrect about your assumption. \n\n\nRemember, pre builts are 90% of the market. Almost nobody builds their own computer.",
      "No, Nvidia's greed and Trump's tariffs are gonna it up crazy.",
      "Furmark doesn't really rely on anything except cranking voltage through your card to check thermals. That's about it.",
      "Well here's hoping.",
      "My 5090 outperforms a 4070 too",
      "Should you really be gaming at 4k on a \"budget\" oriented card though?",
      "The leaks showed it was also a very marginal upgrade. Looked like something around 5% more Cuda cores. So maybe it was wrong.",
      "My old ddr3 family computer has corsair 750 watts psu, which were already readily available, good and cheap.\n\nEven 5080 with OC is able to run on 750w psu (just not with 14900K), as it only draws 350watts at most….\n\nSo this point is moot, maybe except for those who have ancient computers ddr2 or older. Because at which point, getting a new GPU which well under spec cpu and psu is just doing it wrong all together… not only will the cpu massively bottleneck the card! But at that point PSU becomes point of failure and psu failing is the last thing you want!",
      "I got a covid stimulus check from work worth 500 euros. As only certain (larger) stores accepted these building a PC was not an option and getting a prebuilt from a large electronic shop was way cheaper.  \n  \nI did not go as far as to check if the PSU would be upgradable and blindly assumed it would be. There's no real regrets though, when the time is right I'll throw a 4060/5060 in there and I'll be good for a few more years with this machine. Next one I'm definitely building myself though."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "4070"
    ],
    "title": "[Gamers Nexus] NVIDIA GeForce RTX 4070 Super Review & Benchmarks vs. RTX 4070, RX 7800 XT, & More",
    "selftext": "",
    "comments": [
      "Its drives me nuts that his RT benchmark suite is capcom(re4)games, dying light, and F1. RE is an AMD sponsored games with low level RT, all but one are games that make people rightfully say “why use RT it just kill’s performance?”\n\nAbsent from his benchmarks are cyberpunk? Alan wake? Control? Metro? Games that, again, make people rightfully say “RT is genuinely amazing”. *and all those games* run well on all vendors. So irritating.",
      "Sooo... only me or I feel like GN lost their grip on reality with these benchmarks?  \nNo Cyberpunk? Like, the single game that is incredibly well optimized AND absolutely bends GPUS at max settings both in rasterization and in raytracing, giving a fair and square playing field? The tests on F1, GTA5 and R6 Siege feel like all testing the same thing: low impact games that scale well. We don't need 3 of them. They add latency testing because \"framerate has become comically high\" - yeah if you keep testing low detail games maybe that's why, making a solution for their own problem: just remove those benchmarks and test only on the most relevant one, which may be Counter Strike 2, and do your latency testing there, instead of being surprised a game released in late 2015 (that's 8+ years ago) has \"too high fps to matter\"?  \n\n\nRT tests on F1 22 and Dying Light? Like what the f. is the point.  \n\n\nHWU has got a much more solid benchmark suite, at least, but someone has to tell GN to stop this. When I heard they were \"refreshing\" their benchmarks suite I was \"finally\" then the result is that they added more testing to validate their testing on 8 years old games across the field. God damn.  \n\n\n/rant",
      "The performance is similar to the 3080ti in many games.",
      "Frankly, I was very puzzled by this review, especially with the RT section of it. Whether GN likes it or not, Ray Tracing is here to stay and it will be added into more and more games. Not focusing on RT feels weird for a card that literally has RT in its name.\n\nI like their data driven approach, but this review felt out of place. I was mostly curious about the RT performance in Cyberpunk and Alan Wake, since I am looking for an upgrade from my 2070 Super, either to a 4070S or a 4070TiS - aiming for a 1440p 144 Hz experience.\n\nWell, I guess I'll have to turn to other outlets for the reviews of the Super refreshes, which is a shame.",
      "TL:DW: 13-17% performance improvement over the original 4070. \n\nUsing the 17% best case scenario, under $512 the original 4070 is better price/performance.\n\nedit: basic algebra",
      "Usually like GN, but this is a terrible review. What a worthless game selection.",
      "Testing the 4090 with a 4.9ghz 12700 and then talking about \"CPU Bottlenecks\" is also really dumb",
      "GN has been super useless when reviewing GPUs",
      "yea, 2 years earlier",
      "Daniel Owen showcases all the RT games. He just dropped his 4070 vs 4070 Super video 7 hours ago.",
      "This!! So much this!! It's like they're driving an agenda with their benchmarks at this point. \"Nu-uh we can't have good looking games that scale well, gimme that 8 years old game that will do 300 fps at 1440p\"\n\nI am so stupidly triggered by this. But really anyone buying a new GPU looking at GN's testing isn't getting any use out of it.",
      "Nvidia is taking advantage of no competition. AMD is just phoning it in doing the bare minimum. \n\nIt's less a problem of people's \"willingness to overpay\" and more a problem of there has been no real competition for years unless you go full denial and start giving AMD a bunch of caveats to try and pretend the GPU division hasn't been a shit show for almost an entire decade. Actual competition would force pricing and features to be different.",
      "4070 should be a 499 MSRP for sure. should have launched there....but alas.",
      "I generally like GN but the snark lately has been a bit much and I like snarky comments. But they need to tone it down a little. It’s almost coming off as arrogant.",
      "Almost as if both Nvidia and AMD are taking full advantage of peoples willingness to vastly overpay for things.",
      "Steve's been arrogant for a long time.",
      "Before I upgraded I sold my 3080ti FE for about 750 CAD, which is about 556 USD, used tech varies everywhere though So id imagine it could be even cheaper easily",
      "Agreed. The RT bench should be games that make you want to buy a card to play them, those games exist. Also the raster bench? There are demanding raster games that should be here, theres no value in looking at GTA V. \n\n>framerates have gotten comically high\n\n*Test games that didnt release 10 fucking years ago*.",
      "GN has been doing audience polls for quite some time now in what appears to be an attempt to revamp their testing techniques and game suites. Unless they haven't implemented their updated testing methodologies, what you're seeing is a product of them listening to the average YouTuber instead of just looking at the current relevant gaming landscape as a whole. \n\nDon't get me wrong, it's good to listen to your audience, but your average YouTuber isn't really indicative of what people are looking for when evaluating cutting-edge tech with the latest games.",
      "Reading this thread, isn't it crazy how they are the most popular? People are attracted more to personality than content. Reminiscent of Simon Cowell, but less eloquent. For me, reviews aren't worth the time when the reviewer wouldn't use the product in question, lack thoroughness while taking 30 minutes, and is just a mean to an end."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "4070"
    ],
    "title": "NVIDIA GeForce RTX 4070 GDDR6 vs. GDDR6X tested: 99% performance at 1440p/1080p, 98% at 4K - VideoCardz.com",
    "selftext": "",
    "comments": [
      "I figured it wouldn't impact performance too much, but releasing it at the same price-point as the \"better\" 4070 is such a weird decision.",
      "Metro exodus non RT is an interesting outlier. 10%. But not when RT is involved.\n\nIt’s not bandwidth though, it’s handily faster than rtx 3080 which has much higher bandwidth",
      "It should be cheaper tbh...\n\nBut GDDR6 isn't all bad either because its not consuming as much power as GDDR6X, thus cooler. Should be good for itx builds.",
      "This has to be a shitty comparison. They’re using average fps to say it has “98%” performance of the lower quality card? Where’s all the other stats that actually matter for games the 1% lows and all of that? Considering the difference is the graphics ram, why not compare it that way? Only graphics benchmarks? Just some basic research on gddr6 vs gddr6x tells me that power consumption, bandwidth, among other things are significant. Why were they not tested? To give such a strong statement like “98% of the performance” with only a few graphics benchmarks and average fps for games seems lazy.",
      "Technically slower. It's like having a car that can go max speed 200 and the new model can go max speed 195.",
      "Gddr6 is slower than gddr6x",
      "Availability. GDDR6X is Micron only, but all the three major brands can supply GDDR6. Nvidia has apparently been frustrated with Micron's limited supply so moved to GDDR6 which turns out not to hurt the performance that much (in the case of 4070 though).",
      "It depends. There are outliers like Metro Exodus which actually is 10% slower.",
      "GDDR6X uses 15% **less** energy per bit than GDDR6.  \nThis GDDR6 ram is 5% slower than GDDR6X, so it will use \\~10% more energy.\n\nI can't find any upsides of this GDDR6, it looks like a inferior product.",
      "Not in my experience, I recently bought an Asus 4070S. To replace my EVGA 3080. While testing out both cards. My 3080 constantly out performed the 4070S in 4k (LGC2) in 5 games I play consistently. (BG3, DD2, MHW, RD2, and Hell divers.) The power draw and temperatures for the 4070S was obviously way better, but that's not a concern for me. I simply returned the 4070S. And will hopefully snag a 5080, or buy a secondhand 4080 for cheap. Anyone who has a 3080, just wait for the 5000 series to upgrade.",
      "Ok, is it 98-99% the price?",
      "That game is weird, the result goes back to 2% difference in max RT.\n\nAlso, the bandwidth difference between gddr6X and gddr6 is 5%, so how would performance tank 10%?\n\nIt is still faster than rtx 3080 which has higher bandwidth than it so that’s why I call it weird",
      "I dont really get it, what is the difference with the other memory?",
      "People that are surprised by this need to learn.  I was saying 1-5% performance impact and got downvoted to oblivion.",
      "but in the first place why you bought a 4070s when you have already a 3080? makes zero sense",
      "No it's 110% of the price. God bless Jensen.",
      "No. GDDR6 has lower latency. Which evens it out, mostly. It's the same GPU die, with the same power draw.",
      "Good news",
      "While the engine can only do 197.",
      "I was given a 500$ best buy gift card, by a friend. And I also had a 50$ certificate to use, so I spend like 60$ to buy this card. I'm like well, i don't mind a small upgrade supposedly this is as strong as a 3090, and I had the 10GB 3080 so I'd take the 2GB of VRAM as well. Plus better temps and power draw. By being this disappointed, and not being able to get cash from the GC. I sold it at a small loss for$ 520 to someone who wanted the card. I have that 520$ in my PC upgrades  drawer."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "4070"
    ],
    "title": "Is a 4080 super worth the $400 extra for a 2k 165hz display, or should I go with the 4070 super? ",
    "selftext": "Need to upgrade my computer for Monster Hunter and I'm trying to decide which GPU to get.  I'm not interested in going all the way to 4k 240hz (too expensive for me) so I was looking at a 2k 165hz ultrawide monitor, which is a pretty big upgrade from the 1080 60hz I got in 2018.\n\nI don't play a lot of extremely demanding games and I don't care about ray tracing or the absolute bleeding edge graphical fidelity, I just want to run MHWilds or Space Marine 2 at max settings with at least 60 fps and be futureproofed for another 3 years. \n\nA lot of the info I can find is comparing these two for 4k, but not much for 2k.  I think the 4070 super will be fine for me, but I wanted a second opinion from other people that might know more. Saving 400 bucks is quite a big deal for me, since I have to upgrade almost my entire build. ",
    "comments": [
      "Go for a 4070 ti super",
      "Or a used 4080. They're often priced about the same as a new 4070ti super. I got one for $850 last month.",
      "4070 or 4070 Super are plenty for 1440p. I wouldn’t go for the 4080 unless you want to go for 4K",
      "I am running 12700K and 4080S also on 1440p@165Hz and its not overkill at all. Playing GoW (2018) on Ultra settings and i am still using DLSS Quality to have 150+ fps.\n\nControl with RT only around 100-110fps native.\n\nI tried DLSDR on GoW and it dropped to 100fps without much of a change in visual quality, so i dropped it to 1440p immediately, lol.\n\nThus, 4080S is not overkill for 1440p at all.",
      "I just paired a 14600k with a 4080 super on a 165hz 2k monitor and the gpu is a little overkill but i like it. the problem to get stable 165hz is still the CPU",
      "I run 4080 super with 1440p monitor it’s great. I’ll continue to use it for the next 5+ years by slowly downgrading graphics setting till I NEED to upgrade lol",
      "Depends on the game.\n\nIf you want cyberpunk path traced then a 4080 is barely enough.\n\nIf you want sims 4 then a 3060 is plenty.",
      "Bought a 4080 1.5 years ago. The first game I launched was Cyberpunk and it was apparent that this gpu is not overkill at all for 1440p, somethimes not even for 1080p.",
      "Personally, I couldn't disagree more. Sure if you're trying to play pathtraced maxed settings at native, sure. But the 4070 ti super is solid for 4k gaming, so I would imagine at 1440p UW it would be fine enough.",
      "If you can get a used 4080 for a similar price, I'd do that (not sure on prices at the moment), but a 4070 ti super would be good too.",
      "You'd have to be a madman to buy a 4080s for MSRP when the 5080 is just over a month away.\n\nGo for the 4070s if you just buy now.\n\nAlso I don't know much about MH but DD2 which is on the same engine was seriously CPU heavy so I'm guessing you already have a good CPU.",
      "4070 ti super 1440. 14900kf CPU. Everything is between 80 and 120fps. All maxxed up. All the time",
      "op wants 165hz monitor not FPS ,specifically states 60 FPS , 4070 super is more than sufficient",
      "People talk about the 50 series cards like they are going to be readily available and good value at launch. Sure, if you can wait potentially 12 months for the price/inventory to stabilize then wait. Otherwise, buy according to your needs and availability today and enjoy it. You’ll be waiting for eternity if you wait for the “next” generation with your PC purchases. There’s always the “next” gen. \n\nTo answer your question, the 4080 is certainly more future proof for the higher cost. At 1440p however, the 4070 super is perfect. If you ever plan to go 4k, then get the 4080 super. If you think 4k Is far fetched and a long way away then get the 4070 and just upgrade your GPU again down the road if you ever upgrade to 4k. At that time, the 50 series should be out and established and you can use the $400 savings towards a GPU upgrade then.",
      "This. It’s good enough in a transition !!",
      "No. Especially not when the 50x series is coming within the next few months. Since the game is coming out in Feb, I’d wait to buy a used 4070/80 super (but really you only need the 4070 based on your monitor). A 4080 super will way overshoot your desired 60fps max, however, a 4070 super will do the same thing. You could even use ai super resolution scaling and run it at higher res and you’d be fine: source me with a 4070 non super and running ai 5280x1440p full max settings and rt in almost all games besides path tracing cyberpunk. Also, you could raise your fps lower limit to at least 75 if not 90-100+ with your setup and a 4070 super.",
      "Is the 4070 ti super enough for maybe 4k 70-80 fps medium settings?",
      "Path Tracing still isn’t very realistic without a 4090. I have a 3090ti and its not even playable at all",
      "I'm playing that right now with a 4080S.\n\nWith all bells and whistles turned on, including DLSS/FG/PT, about 100-120fps. Latency is plenty good enough, being the equivalent of 50-60fps.",
      "Yes he is correct \n\n2k is 1080p"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "4070"
    ],
    "title": "is 4070 enough for 4k gaming?",
    "selftext": "just recently bought 4070 and planning to buy 4k screen soon\n\nso is the 4070 enough for 4k gaming?\nwill it last?",
    "comments": [
      "The beauty of PC gaming is that you have tons of options to adjust the graphics settings to suit your own eyes and your system, but it seems the majority of people these days refuse to understand that.",
      "People on Reddit act like the 4090 is the only viable 4k 120 card and the 4080 is the only viable 4k 60 card \n\nMeanwhile you enjoy 4k 60 in 90%+ of titles at high settings. It’s absurd imo.\n\nIf I say I got 4k 60+ with my 4070 Ti, 10 people chime in and say it’s at medium/low settings, DLSS performance, or medium textures. It’s ridiculous",
      "I don’t really understand what people are talking about here. I’m running a 3080 without issue at 4K60+. Usually high graphics settings. Obviously DLSS will help you a lot. For example, in starfield I’m getting on average 70 fps at high preset without mods. Just my experience though",
      "I love this answer. People that just refuse for example that a 3060ti can play 1440p. \n\nThere's things called graphics settings, upscaling, older games, avoiding brand new brokenly optimised titles.",
      "I have a 3080 + 5900x which is probably pretty similar to 4070 and with a mix of high settings + DLSS Ultra Quality I’m getting like 75-90fps in some new AAA games at 4K. Very nice personally- not perfect but more than enough.",
      "It is kinda ridiculous. People are feeding into mindless consumerism and gaslighting others into making them think their graphics cards are redundant and useless",
      "Guides for optimized settings help alot\n\nSome settings looks effectively the same, but have huge performance benefits",
      "There’s just too many enthusiasts with very high end GPUs in this sub that have an aneurysm at the idea of playing on anything but max settings/making any sort of compromise. \n\nIf anything this place is a case study for rampant consumerism and the silly ways people justify always buying the newest and best card every generation even though the majority of the games they play aren’t even that demanding. But it hits their brains with just the right amount of dopamine.",
      "Yes you can play games at 4k for sure. I can play most games at 4k on my 3060Ti. Will you have to use DLSS? Probably. But is that ok? Yes. DLSS sometimes even looks better than native. You also might have to keep it around 60fps depending on the game if that’s alright and you might not be able to max out settings. Really depend on what you’re okay with. But idk if people just regurgitate what they’ve seen someone else say or what, but the perception of what GPU you need these days has gotten really out of whack. Like yes if you expect to max out all settings and use RT and play native 4k then yeah you probably want a 4080 or 4090, but there’s so much leeway in between all that. And lots of graphically intensive settings that can be lowered without barely affecting image quality.",
      "Yep, people upgrading every generation to get some nee flashy feature or some more performance. Mind you these are the same people who’d make fun of someone getting a new iPhone every year.\nI’m still rocking a 2080 Super, since 2018. 1440p 60FPS High settings on pretty much any game, without DLSS.",
      "4070 Ti and playing practically everything at 4k 120 with some DLSS.. Reddit is so ridiculous\n\nAside from cyberpunk with path tracing, that’s legit the only scenario I’m at 60fps \n\nHorizon 5 for example is native 4k 120 with DLAA and RT set to extreme \n\n“1440p card” according to Reddit",
      "Recently I found [this guy's channel](https://www.youtube.com/@benchmarking4386) is quite useful, you can also refer to videos from Digital Foundry, Hardware Unboxed, etc. Or you can simply Google the game's name + optimization tips, Reddit sometimes can be a really good source as well, good luck :)",
      "Depends on what games, what settings, and what framerate. Easy way for you to know is to actually go look up benchmarks of the games you play and see if you think it is enough.",
      "Lol I did 4k at 30fps on demanding games on my 1080ti years ago before upgrading to a 3080 ti. The freedom and flexibility is why I like PC so much. \n\nIt's really a shame console doesn't have these options because I'd be able to actually tune that into a way I prefer to play.",
      "It’s the idea that every setting needs to be completely cranked to ultra 4k vs. just using a balance of setting to accomplish 60-90. Even with a downgrade in graphics the pixel density helps with visuals a lot.",
      "I’d buy a 1440p OLED screen over a 4K non-OLED screen. I value HDR and response time over resolution as I’ve found that they make a bigger difference in experience and immersion.",
      "I came across this one guy that was adamant that not even a 4090 was a 4k card because it can't run every single game at native 4k maxed out including path tracing, fucking ridiculous.",
      "Cyberpunk doesn't feature 4xAA, 8xAA, 16xAA nor MSAA in general. I think you're confusing it with anisotropic filtering, which has a very small performance impact even when set to 16x, and isn't an anti-aliasing technique at all",
      "Exactly, I have 4070 and it is perfect at 1440p, 4k in newer titles suffers due to the mem bandwidth. Older games usually run fine at 4k tho",
      "It is a 1440p card. It can do 4k60 in a lot of games but struggles on the more demanding titles. It comes down to what performance you expect. \n\nIf you are upgrading from at 1080p monitor, I would just go to 1440p."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "4070"
    ],
    "title": "4070 ti that barely fits in my pc",
    "selftext": "(Yes the gpu was fixed in the second photo)",
    "comments": [
      "A 5800x cooled with a front mounted 360 aio surely has nothing to do with it.",
      "Why the downvotes. My guy really just wants his lights lol. Nothing wrong with that. You do you bro!! You show off them beautiful, albeit not necessary, lights!!",
      "i think you're gonna need a gpu holder",
      "The air cooler blocks the ram lights sorry 😭",
      "https://preview.redd.it/dlt61c8tvwwd1.jpeg?width=4624&format=pjpg&auto=webp&s=b6b52bdd0dbddc840b8c710ed8041ad810ef2880\n\nNot a problem 😜",
      "Probably downvoted because he could top mount the AIO and it would be just fine (Unless the AIO is too long for that case).",
      "join us at /r/sffpc where we put a 4090 in a 11L case",
      "Stick the rad on the roof and have it as an exhaust, and put intakes in the front. Problem solved (and better for airflow?).",
      "As someone who has built many computers I can tell you I don't think the AIO would fit up top(wouldn't be able to seat the ram) and that's probably why it's sitting at the front.",
      "I was thinking about the same.\n\nI built a PC with 4070ti super and was wondering why I had so many parts but when I lifted the card I got it. The weight is too much and definitely can cause issues in a long run. However mine is with 3 fans, this one looks like having 2.",
      "A 360 aio, on the top on a 4000d?",
      "My bad, didn't realise what case you were using and it looked like you might have had room for the rad on the roof, i guess if it all fits and your temps are fine you have nothing to worry about :)",
      "It is too long, you can see in the first photo that he could only fit 2 fans at the top, so 240/280 may be the limit for top mounting.",
      "My 4070ti fits nicely in the Corsair 7000x.\nBut that case is so huge its not supposed te be moved... I kinda like the big components",
      "Lol not pretty indeed.",
      "Dude me tooo",
      "Glad to see im not the only one who did that",
      "There's two schools of thought. It would make your internals slightly warmer but would also more efficiently cool your cpu since it would be moving cooler air through the rad. Basically, either your cpu is warming up your gpu, or your gpu is warming up your cpu. \n\nUltimately I don't think it makes much difference. The only thing that should be avoided outright is front-mounting your aio in such a way that the pump is higher up in the case than the rad.",
      "Oh yeah I def agree but hey, each of use have our own build and honestly if you spend money on your cosmetics, I imagine you would want to see them. After all, he has to look at his build everyday not us",
      "Correct It is a 360 aio"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "4070"
    ],
    "title": "Who said size doesn't matter? New 4070 Super",
    "selftext": "Nice upgrade! Went from my eVGA 3060 to the Gigabyte 4070 Super today. \n\nGreat improvement! Startfield went from 45ish FPS on Med/High settings to 90-115 on the highest settings, DLSS/Superscaling off, and temps staying under 50c.\n\nMore tests to come but the card is fantastic.",
    "comments": [
      "I went from a 3 fan EVGA 3080 to a 2 fan Zotac 4070…runs much cooler. Efficiency is king.",
      "Went from a 2080 to a 4070 Super. Very happy with the increased performance.",
      "2060 to 4070 Super here\n\nPerformance tripled or straight-up quadrupled in some of the games I played",
      "Evga applied crazy power limits that added extra 0.6% performance",
      "I have a Gigabyte 4070 Super myself and it is an absolute treat :) enjoy",
      "Why? I sold the 3080 for $420 while it had another 6 months left under warranty from EVGA (whatever that means at this point since they don’t make GPUs anymore). Added $30 on top and bought a brand new Zotac 4070 twin edge, so 3-5 more years of warranty (I haven’t looked how long it is yet, but I’ve heard Zotac USA warranty is 5 years). Yeah it’s a base model but the card only uses 200 watts max as opposed to 3080s 350 watts. The heat output difference is very very noticeable, especially now with the hot summer here. I really wanted to experience frame generation for myself and I’m definitely not disappointed. Very good feature but I would’ve never bought a 40 series specifically for frame gen. Also 2 GB more VRAM. I play at 1440p so the better performance of the 3080 at 4K doesn’t matter to me.",
      "Ah, yes... \"everyone\"",
      "Both have the same msrp, and the 4070S is around 15% faster than the 4070, not the same or less.",
      "Glad I just bought the base XC3 model as opposed to the FTW3 models with 450 watts of power……",
      "I went from a small 3 fan 3070 ti to a brick 4070, had to get a support bracket for it.",
      "https://preview.redd.it/nc09kxt2en9d1.jpeg?width=3024&format=pjpg&auto=webp&s=d99bd7d88101ba4330d38cb9ef421e97c73fe61b\n\nMy 4080s and 1060",
      "1080 -> 3080ti ✨",
      "Yeah I got two ftw3s and both computers got fried monos after a while",
      "\"A 4080 on the used market is $900-$1,000\"\n\nBrand new actually. I bought a Galax 4080 brand new for $930 in January",
      "I went from an R9 290 series (AMD) to a 4070 super AERO and I can’t believe the increase in performance",
      "same. runs cyberpunk at 120+ frames with DLSS on. more if i didn't have a crusty cpu",
      "It’s going to be a beast when I sidegrade from my 4K panel to a higher refresh 1440p",
      "Boycotting massive companies alone does nothing. Nvidia makes quarterly multi billion dollar profits without you.  \nAnd they had a market cap of $3 trillion.\n\nIf you buy another card from them, you're not boycotting anything. You're just buying their expensive old stock :v",
      "I have a whole $15.24 to my name, $1000 in spare change is a dream for me, so I suppose if I was living at home with no bills and no car, sure. It’s very attainable.",
      "We both know you're wrong\n\nHave a nice day"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "4070"
    ],
    "title": "Was hoping for an RTX 5000 series GPU but decided to go with a 4070 super",
    "selftext": "Got tired of trying to find a 5080 for my new system, and I have like no confidence in the 5000 series too especially with tarrifs, scalpers, the specs, and everything else that is going on. Was building a new rig for 1440p and hoping that the 5000 series would have more to offer (coming from a 2070). Took a long hard look at myself and asked if I *really* needed the performance of a 5080/$1200 GPU for the games that I play. I decided that, fuck no, I do not. So, I went with a 4070 Super at MSRP (lucky find). I know the CPU I alr purchased a couple weeks ago (9800x3d) is a little overkill for a 4070s, but I figured it would give me some headroom for a gpu upgrade if we see a better market a couple years from now, and that is good enough for me.\n\nI hope I made the right choice...",
    "comments": [
      "Dude. You waited 7 years for a new gpu. What's another few months. FOMO is wild.",
      "I did the same thing! Had a 2060, tried for the 5080 and failed, and said screw it I’ll go for the 4070 super I found at the Walmart near me. Paired with a 9800x3d and it’s doing everything I want for now. Will probably try to upgrade to a 16GB+ card at some point for 4k, but in multiple games I play the 4070S can do 4k near or at max graphics.",
      "I was looking for RTX 5090 on Staples the other day and I saw that some may have MSRP 4070 supers for sale. This one is $600, I think they only have them up locally to purchase in store. For my location it says 1 is available at 2 stores near me.\n\n[https://www.staples.com/pny-geforce-rtx-4070-super-nvidia-geforce-pci-express-4-0-12gb-gddr6-graphics-card-1980mhz-core-black-vcg4070s12dfxpo/product\\_24600011](https://www.staples.com/pny-geforce-rtx-4070-super-nvidia-geforce-pci-express-4-0-12gb-gddr6-graphics-card-1980mhz-core-black-vcg4070s12dfxpo/product_24600011)",
      "I'm basically in the same boat. Running a 2080 and thinking about getting a 4070 super and sitting this generation out. It's about twice as fast and will hold me over.",
      "Dang I didn't know staples sold GPUs, thats pretty sick",
      "I doubt the 5070 will be able to beat the 4070super in the first place",
      "You’ll be fine for many years. I made the jump from a 3060 Ti to a 4070TiS for a few weeks before returning for a 5080. The only reason I did was because I have a 1440p 240hz monitor and play a lot of single player games atm so it’s helping me max out games and my refresh rate. If I had a lower monitor refresh rate, I would’ve kept the 4070 no doubt. You still get access to the DLSS 4 suite and regular frame gen which is still very solid.",
      "ya seriously. im upgrading from a gtx 1080 and have no temptation at all to buy anything less than the 5000 series card at this point. In hindsight i wish i got a 4090 2 years ago but now its 5000 time.",
      "Honestly if you can find one at MSRP I would totally go for it! At the end of the day these are all luxury products, not necessities, so only go for what you feel like going for. Most of us will never use the full power of these ridiculously expensive high end gpus. Looking at stuff like the steam survey, and looking outside of reddit discussions makes you realize that the average day to day person doesn't run a super high end card.",
      "I just upgraded to a 4070 Super recently and I can tell you it is quite comfy. I only really have issues when I try to play the most demanding games on max settings at 4k, like Space Marine 2 or anything with Ray Tracing, and even then it's still playable.",
      "Wish you luck! I’m a 2070s user, think I’ll wait until the new AMD cards are released in a couple of weeks. If somehow I cant get one of those, I’ll just have to wait to see what I can get my hands on first 🥲",
      "I mean I just also realized that I don't need that powerful of a card. And I can wait until later for me to get a super high end GPU if I feel like later there is more value to be had. But right now, I cannot justify it no.",
      "It’s gonna be insane for you lol",
      "Watches OP to see if he regrets knowing one can wait till June or July when production is at full.",
      "Curious where all these people are buying their 4070s from, all I see are sketchy third party sellers and/or outrages prices.",
      "My personal rule of thumb is to wait every other generation, so I think you made an excellent choice.",
      "Don't feel bad about the CPU you are still going to get a huge in game boost even with only a 4070S. I got a massive jump on several games going from 10700k->7800x3D with a 3070",
      "If it makes you feel any better, just OC the 4070s and youll have 5070 performance more than likely.",
      "Thats the thing though, we sitted out the 40 series, but 50 series is barely an upgrade over 40, so we just wasted 2 years sitting on old gear",
      "well if you wanna look at it that way 50 series is first series from nvidia that support displayport 2.1 so everything 2017 and before has been stuck on the older dp 1.4 so should be some nice monitors coming in the future to support it"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "4070"
    ],
    "title": "Kopite: ' The original RTX 4080 12GB will become RTX 4070 Ti instead'",
    "selftext": "",
    "comments": [
      "I really wanna know who the bright spark was that suggested two different dies with different specs be the same class gpu. For such a large company this was one of the dumbest things I've ever seen.",
      "I mean the whole point of naming the 12gb one a 4080 was that they could say they didn’t increase the MSRP by way too much (from $700 to $900). Now it looks like they raised the MSRP of their 80 class cards from $700 to $1200…\n\nGlad I have a 3080 to carry me onto the gen after this.",
      "This is the best they could do? 4080 16gb should have been RTX 4070 ti and much cheaper.",
      ">Glad I have a 3080 to carry me onto the gen after this.\n\n100% this, what a screw up.",
      "That’s barely a RTX 4070",
      "4070ti for $889 LMAO",
      "another \"tradition\" is laid to rest: the next gen 70class is faster, than the current gen 80class.  \nthe real 4070 will not beat a 3080, as this \"refurbished 4080\" is already heavily cut down in cores and memory bus.",
      "And its still crap price to performance no matter what's the name. It needs to be $600-$700",
      "I wonder how insane the 4060 and 4050 will be priced. The 4050 is gonna end up being 500… lOw EnD sPeCs GuYs",
      "Opinion that people aren't gonna like: this is yet another reason the 4080 Ti will not be the magical cheaper AD102 SKU people are assuming will happen and will be AD103 instead.  This ensures that the 4080 is the lowest SKU with AD103.  Given that there are typically at least two SKUs with the same die, and the 4080 has 8 SMs disabled, a typical difference between a cut down and full die, it seems very likely there will be a AD103 SKU higher than the 4080.",
      "$700 for a 70 series card? 😲😲",
      "I really wonder what's their plan for the midrange and low-end price and performance wise. I hope AMD comes with more sensible line and pricing.",
      "Doesn't matter what Nvidia calls it, they'll still charge $900 for it anyway.",
      "Nvidia's greatest ploy was calling a 4060 a 4080 so they could back it down to a 4070 and no one would blink.\n\nIf they just moved their 70 class cards to a 192bit bus without all these shenanigans then that would have been the criticism, and it would have stuck.\n\nExcellent slight of hand, Jensen.",
      "$500",
      "Wouldn't be surprised if we see a rebranded 30 series for those or they keep selling the 30 series as the low/mid range option with increasingly reduced pricing.",
      ">192bit bus\n\nY'all really gotta stop using this 'memory bus' argument to define what class a card is.\n\nYour whole argument is right, but the reasoning isn't good.  Now that AMD and Nvidia are both using HUGE caches, it's compensating for any lack of raw memory bandwidth.\n\nA better argument is that the 4080 12GB(4070Ti) is a sub 300mm² GPU.  It's a normal midrange part ala 3060.\n\nThe 16GB 4080 is similarly using the \\~400mm² AD103 die, which is basically upper midrange, not high end.  AND it's not even a fully enabled one, so it's more appropriately comparable to something like the 3070 in reality.  How much its shader cores are reduced compared to AD102 also supports this.\n\nAnd yes, they are screwing us and will probably get away with it after only dropping the price of this 4070Ti to like $700-800 for a normal midrange part.  It should be $600 maximum and even that will still be ripping us off.",
      "Probably Jensen? Doesn't he take the high level decisions like price and naming.",
      "More like “day 1 reviews would’ve shit on this fake 4080” effect.",
      "Generally the last gen 80ti was the card the new gen 70 targeted and in most cases best or on par with it. It changed with turing and looks like there is no going back"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "4070"
    ],
    "title": "Is the 200$ price difference of the 4070 ti super vs the 4080 super worth it?",
    "selftext": "Hi\n\nIm looking at buying a 4070 ti super for about 1150$ but i have heard some say that if you are going for a 4070 ti super its better to buy a 4080 super. But is the 200$ difference worth it?\n\nThe specific GPU is a MSI RTX 4070 TI Super GAMING X SLIM.\n\nEdit: its a bit late with all these answers, But still. I know the 5000 series is coming out soon, but i sadly cant wait 2-3 months as i have to make a decision this month.\n\n  \n2nd Edit: after reading some more comments about the price. Im from Denmark, we have a big sales tax that sometimes messes a bit with prices and also since the 4070 ti super is a X SLIM for an Mini-ITX case it costs abit more.",
    "comments": [
      "i would say it depends on what you are upgrading from, the rest of your system and how long you intend on using it",
      "You can oc the stock 4080, and around we go",
      "I would say no. The 4080 Super is only like 12% better at 1440p maybe 13-14% at 4k. You can oc the ti super and can get very close to a 4080 stock.",
      "If you are mainly playing, don't get the 7900X3D, it's significantly worse than the x800/x950X3D (due to only 6 cores having the 3D cache vs the others' 8 cores).",
      "The 4080S is 18% faster than the 4070tiS but costs 25% more. \n\nWhether that premium is reasonable and worth paying is a value judgment and you need to make that decision yourself. Depends on how price-sensitive you are, whether you have a 4k monitor, if you insist on playing on ultra, etc, etc, too many variables.",
      "Unplayable, a Pentium would be more serviceable.",
      "Tariffs are likely if you're in the US though",
      "Someone else is paying? Than 4080 ofc",
      "I also do 3d drawing as a hobby and use MasterCam. is the threads is handy.",
      "It may not happen, but it's something to consider when making a purchasing decision.",
      "Im going from a ryzen 9 5900x 2070 super to a ryzen 9 7900x3d and then either a 407 ti syper or a 4080 super. im planing to use it for 4-5 years before upgrading again.",
      "Depends on your situation. If you have a PC that just needs a GPU upgrade, go for the 4080S. But if there are other components that needs upgrading as well (CPU, monitor, etc) I would go for 4070 TiS and use the extra $200 towards another component upgrade.\n\nI was in this same conundrum between these two GPUs and I decided to get 4070TiS and use the extra $200 towards a new OLED monitor.",
      "It's not significantly worse. It's about 5% worse as per any recent benchmark",
      "Honestly no. \n\nThe Ti Super is perfect at 16gb.  By the time 16gb is obsolete so will the Ti Super chip.\n\nThe 4080 Super is a great piece of silicon but will be limited by VRAM before the chip falls short.",
      "You want 4K? Absolutely worth it. You want 2K? Hell no.",
      "please buy none of them.. wait will January",
      "the tiS can do 4k too.",
      "Hm... in that case nevermind :)\n\n(I'd still go / will probably go for a 9950X3D when it comes out)",
      "I upgraded from a 3080 10 gb to 4070 ti super and I am VERY happy with efficiency and performance.",
      "Just bought this exact CPU and the 4080 super for my first PC... so freaking excited to get all my parts by next week"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "4070"
    ],
    "title": "NVIDIA GeForce RTX 4070 leak confirms 5888 CUDA cores, 12GB & 21Gbps memory - VideoCardz.com",
    "selftext": "",
    "comments": [
      "Pretty much 3080-ish performance on raster. \\~30% over 3070\n\nShould be slightly faster in RT\n\nWonder what full RT like Portal and Cyberpunk will do with SER and OMM\n\n&#x200B;\n\n$600 is ok/meh but $500 would have been good",
      "Will they use 12vhpwr for 4070 or they're going back to 8 pins? I heard a rumor that 4060 & 4060ti going to use 8 pins, but not sure about the standard 4070.",
      "Well, I already bought ti version, so this information is now living rent free in my head",
      "$600 is unimpressive, honestly.\n\nThe 3070 at $500 made people go nuts because while the 70 tier price kept creeping up, the card was giving you 2080ti performance for $500 instead of $1100.\n\nSo if this thing is basically a 3080, then what you're getting is 3080 performance for... a price slightly lower than 3080 MSRP, and actually probably equal to or higher than 3080 MSRP when it's actually on the shelves.\n\nWhat's exciting about that? The same performance for basically the same price? It's a little more power efficient and has better RT, sure, but holy shit the market is fucked if that's all we have to be excited about.\n\nThe 6800xt has been going on sale for $550, even as low as $520, for months, like since summer. The 4070 isn't impressively priced given the context of the current market.",
      "I wouldn't worry about it until the card actually launches and we see the real world price and performance\n\nIf this thing actually performs like a 3080 with 12gb of VRAM and FG, I don't expect it to sell for $599\n\nBased on the specs it's 75% of a 4070ti for 75% of the price, so the value is scaling linearly",
      "What is a bit wierd for desktop users is this is the first time in a few gens that the desktop 70 card is going to be slower than the laptop 80 card",
      "So a 3080 with a little more ram, DLSS 3 and I suspect less power draw. That's not bad really (assuming you can find one at $599.) \n\nUsed 3080s are still selling between $500-$600.",
      "320W 3080 vs 200W 4070",
      "VR is quite niche - it’s always going to cost a premium. You can’t really have a budget luxury.",
      "I feel like people's standards are super high. I did 4k with my 2080 and it looked better than my PS5. Now the 4070TI is amazing at 4k for me. I think there's two games right now, where the 4070TI can't ultra? TLOU and RE4 both come with un-optimized 8k textures so you can just reduce those and still crushes it?",
      "RTX 40 Series: “It could be worse, I guess.” Get yours today!",
      "people complained about the naming scheme, this is how nvidia solved it!",
      "Yeah, the 10xx series was the 1 great series where it really matched exactly",
      "What bothers me is that the 4070 was clearly spec-wise intended to be the 4060 segment card, just as the 4070 Ti was actually originally segmented to be the 4070, but when Nvidia realized how much generational uplift over 3000 series they were getting, they didn't want to make the same mistake of offering too much generational uplift over last year's model, especially with what consumers told Nvidia they were willing to pay, so if you were willing to pay $1200 for a 3080 in 2021, $800 for RTX 3070's and Ti's, then you should be willing to lay $800 for what should have been the 4060 ti this time around, and offering you a card that is 30% faster than the original 3070 for $100 more MSRP seems like a pretty decent deal. Until you realize that you're paying $599 in 2023 for similar rasterization performance that they offered for $699 in 2020.\n\nI'm a world where RTX 3080 12GB stock is still listed at $1200+ and 3080 Ti's for $1500+, they can and will sell a 3080ish equivalent for $600, and the AIB models will MSRP for $700-$800.",
      "I bought a 3070ti because my GTX1080 died and I had no GPU for months due to zero inventory during the Great GPU Depression, and refused to buy off scalpers. Used prices were atrocious too.\n\nSo when a GPU was actually in stock I jumped on it, still at way inflated retailer prices (just over $1000 CAN, hard to estimate because the market was such shit that you HAD to buy a bundle with MB and CPU to even get a GPU). Needed a new CPU anyways, a 5800X wasn't my first choice either but I liked it well enough.\n\nI never wanted a 3070ti, I always wanted a 3080, signed up for waiting lists, checked stock multiple times a day but was never contacted, and in June or July of 2021 FINALLY found something on Canada Computers, anything at that point was better than nothing. I could have also gotten a 6900 for around $2400 but that was too much. Despite paying too much money for what was supposed to be a mid priced card, I would be fine with it but for the VRAM. \n\nNever mined, don't even know how to. Just like to game. My wishlist if full of enough older games to get through to the next GPU gen but I'm not buying a 12GB card for $900 or paying $1500 for a 4080 or 7900XTX or $1300 for a 7900XT. \n\nGuess I should have continued with no GPU.",
      "Yes a lot of people saying something isn't a 4K card means \"this card can't run games at 4K 100fps+\" which is kind of silly. Imo any GPU that can get a solid 4K60 on most AAA titles can be considered a decent 4K card.\n\nLook at the consoles which people consider 4K devices and usually they're running games at 30 or 40fps.",
      "At least it'll be around 30% better. I would say no. I would want at least 50% or over when I upgrade.",
      "Lol, using a 3090 as comparison shows you fell for Nvidia marketing. 4070ti is what, 20% faster than a 3080 10gb but they raised the price like 14%. That’s not good at all. You just forget how shit the 3090 was, it was barely faster than the 3080.",
      "I heard it will be both. Some overclocked cards will use the 12 pin and some will use 8 pin",
      "Facts. The customer base let Nvidia walk over them with their prices. It was a shame. I was in the \"better to just play on my old PS4 until prices go down\" boat. It was definitely worth it. I saved literally thousands of dollars waiting for the 3070ti laptops to go down to $1300. I regret nothing. Everyone that bought Nvidia's overpriced garbage instead of just going to something else, you are part of the problem of why prices are so high. You and you alone."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "mid",
    "matched_keywords": [
      "4070"
    ],
    "title": "Upgrade to RTX 4070 from Titan Xp",
    "selftext": "",
    "comments": [
      "I really love how the Old FE models look, i loved my 780TI.",
      "About exactly 2x performance boost, but vastly better thermal and temp, Titan Xp easily reach 85c in game while 4070 just around 65c and almost silent from 2 feet away.",
      "The design of the FE model is so damn beautiful.",
      "It's unfortunate blower style cards just don't really work anymore with this new heat we're generating. The 4090 alone having a 450W tdp is pretty crazy compared to PCs a decade or so ago that were running fine with 400-500W for the whole system.",
      "Blower cards do work even with 450w - basically all workstation cards are still blowers.",
      "How was the jump in performance?",
      "Congrats ! It's a nice updatw with dlss 2/3 and RT !\n\nWhat is your case ? it look great !",
      "Pretty cards",
      "It's formd T1\n\nhttps://preview.redd.it/9zugfhvcc0ua1.jpeg?width=1776&format=pjpg&auto=webp&s=b19756b0518990c1ad164c7c78e463dc3cc0ff27",
      "They were so loud. I got a 1080 Ti FE, hated how loud it was in my build, switched to an ASUS version 1080 Ti after I sold the FE. Current day FE cards are a dream to have now vs any other pervious gen before.",
      "Not with the little tiny fans on these 1u rack mounts that are spinning up to 15k rpm. They sound like mosquitos.",
      "I really like this card and what it can do in this size. \n\nOne day we will get 4090 performance in this form factor. It will be glorious. It's probably like 5 years away. Until then I really like this card. Maybe it could have been cheaper but it's still fine.",
      "I mean, those cards are 6 years old. And it's definitely still more than a calculator.",
      "it's a worthy upgrade if you've been holding out since a Titan XP. \n\nit all depends on what you're upgrading from.",
      "Please don't put computer components on carpet 😬    \n\nAlso congrats",
      "1440p 240hz",
      "I can relate, I used to have a 1080 Ti FE.  I ended up throwing noise to the wayside and actually overclocked it to 2025 MHz and kept it at around 73C, but with the fans at 80+%.  Not what I would describe as “inaudible”.",
      "240 FPS should work on Low and Medium.",
      "if it's a working GPU, someone out there is using one. \n\nthe Titan XP's were nice cards. no reason not to still use one, unless it just doesn't keep up performance wise.",
      "Blower cards were always terrible. My 1080ti FE often ran at 85c."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "4080"
    ],
    "title": "NVIDIA RTX 4080 SUPER reportedly costs $999, RTX 4070 Ti/4070 SUPER at $799/$599 - VideoCardz.com",
    "selftext": "",
    "comments": [
      "Well I was about to pull the trigger on a 7900xt, but think I’ll try and snag a 4070ti super simply for the reduced power consumption and dlss/frame gen at 1440p should be fine at 16 gbs vram for a while.\n\nIt all comes down to price, if these rumors are true it’s an instant buy, if it’s $999 then I’ll go back to the 7900xt idea",
      "For sure.\n\nAlmost 4080 level of power for 799 with DLSS + Frame Gen with 16GB VRAM? Solid 4k card, makes the 7900XTX obsolete.",
      "TiSuper vs 7900xtx is really favourable for nvidia. It is basically a $400 drop on 4080 which was similar to 7900xtx and way better in RT.\n\nAssuming 4070 is going to be like $500 now, I would get that over Super.\n\nThe only compelling product is TiSuper here.",
      "A year and a price cut later, the 4080 is still overpriced by $200.\n\nAt least the Ti Super is closer to the sweet spot with 16 GB.",
      "$599 will be like 750€ I guess",
      "Pretty much. AMD is going to have to drop prices significantly if these prices are accurate.",
      "4070 Ti Super is the star of the show, and all of these super variants should have been like this since the 40 series release.",
      "So are they all getting a price drop? A 4080 here in Canada is like 1600-1800 dollars it’s fucking stupid.",
      "The 4070Ti Super at $799 is basically what the 4080 should've been at launch.\n\nReally seems to be the most attractive option out of all cards from this mid-gen refresh. If it has any decent overclocking headroom, it should be able to match stock 4080 Super performance.\n\nIt will also, more than likely, be a huge problem for both 7900XTX and 7900XT sales, unless AMD does a price cut by at least $100-150 on each.",
      "It is so close to 4080 and 7900XTX that it doesn’t matter while it will outperform XTX in RT games.\n\nThe main thing is if nvidia can keep this in stock, it will be a scalping mess.",
      "You are forgetting the exchange rate.\n\n$599 is about 560 EUR. Even with 20% tax the price should be about 672 EUR. And not 750-800 EUR where it will be.\n\nEurope always had more expensive hardware for no fucking reason than sheer greed.",
      "I'm sorry but an 80 series card should still be 600-700. Do not cheer for nvidia",
      "yeah, most likely. and the 70ti super will be around 1k. prices here are stupid.",
      "what is this AI work that suddenly everyone and their dad is doing?",
      "I was just about to grab 4080S or 4070TIS but with 5xxx coming out in less than a year I’ll play the waiting game and use GFNow",
      "what why",
      "I keep wondering if they also have a refresh in the works.\n\nRdna3 just didn't meet expectations, and there were a lot of rumors that something went wrong that would have required new silicon to fix. So with that in mind, I wonder if an rdna 3.5 refresh could be on the way.\n\nIf the 4070ti super comes anywhere close to the 4080 for 800 bucks, even the 7900xtx at 800, which is Hella performant, won't look like an amazing deal.\n\nBut if course we need to see performance first. I'm rooting for Nvidia here. The horror of gpu prices that started in 2020 needs to be done. Inflation is what it is, but if Nvidia stops trying to gouge everybody for even a generation or two, then card prices will effectively equalize with inflation, and it won't \"feel\" so shitty anymore.",
      "I don't think the 4070ti Super is to compete with the 7900xtx, it is to sit between the 7900xt and 7900xtx. More to offer a better option over the 7900xt than anything else.",
      "Everything is overpriced",
      "4080 super and 4070 super should've been the base versions"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "4080"
    ],
    "title": "NVIDIA GeForce RTX 4080 SUPER to feature 23 Gbps GDDR6X memory, full RTX 40 SUPER specs leaked",
    "selftext": "",
    "comments": [
      "seems like every day we get specs leaked on the same product, how many more leaks for the refresh before it launches early next year?",
      "> how many more leaks   \n\nthe ~~leaks~~ advertisements will continue until demand peaks",
      "Something tells me the cards will be introduced at the prices of their non-SUPER counterparts and the latter will simply disappear.\n\nNo free lunch for you.",
      "Don't forget the whopping 1.8% increase in boost clock! This is revolutionary!",
      "Ha! I doubt the 4080 super will retail for $999.",
      "Nvidia has to be intentionally \"leaking\" things to the press at this point.",
      "Personally I hoped for more Vram. Like 20 or 24.",
      "Yeah, it's just marketing these days",
      "No we just need prices. my final guess on prices\n\n4080 super - $999\n\n4070ti super - $799 (would love $750)\n\n4070 super - $599\n\nEdit - if I’m wrong I’ll sell my 3070 and use a gt710 for the rest of the year\n\nEdit 2 - No gt710 😩 upgrading to a 4070ti super 🤑\n\nhttps://preview.redd.it/u726v8ewt8bc1.jpeg?width=2306&format=pjpg&auto=webp&s=b3b28deb93010b714138b78b324412aeaea158d8",
      "They did that with the 20 series, this seems to be the most logical way of going about it, because at the end of the day super variants are just revisions, just as RX xx50 cards are.",
      "1.8% faster and 20% more expensive! totally worth it!",
      "The real question is when is 5090 going to be released.",
      "Seems hopeful.\n\nEdit: rip this guys gaming potential with that gt710.",
      "Would have to be 32 bc bus width determines memory size.",
      "Not HW, but semi related:\n\nCapcom (resident evil, monster hunter, etc) admitted to doing fake leaks a bit ago for a RE game. \n\nThey were basically just like, \"🤷‍♂️\" lol\n\nIt's just good business these days. If you drip feed small information a bit at a time it's an okay way of drumming up interest. If you \"leak\" it, it becomes \"sexy\" because of the forbidden fruit type thing, so people click even more even tho it's the exact same thing, you just outsource the PR to the community and content mills vs journalists.",
      "4080 Super looking like a complete joke unless it’s 1000. Such minimal uplift over the 4080",
      "SHUT UP AND TAKE MY MONEY!!!!",
      "The only leak I care about at this point for the SUPER refresh is confirmation on pricing",
      "4080 super is going to be at least $1100.",
      "cut down 4090 instead of building on the 4080."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "4080"
    ],
    "title": "[Gamers Nexus] Lame, But Cheaper: NVIDIA RTX 4080 Super Review, Benchmark Comparison, & Value Discussion",
    "selftext": "",
    "comments": [
      "1-3% faster than a 4080 for $200 less.",
      "Nvidia anchored that $1200 price for a little too long. These card will sell out  because of the perceived value, but they're still overpriced. I say that having bought a 4080 recently (used under $1k).",
      "Housing sells out all the time and most people would agree it is overpriced.",
      "As someone with an All-AMD build, it's hilarious to see the XTX selling at basically the same price when it loses to the 4080S in literally every category. The XTX needs to be $800, yesterday.",
      "The price drop is welcome (I bought one) but they could have just dropped the price on the original 4080 and saved themselves and the board partners a lot of bother.\n\nMaybe it's good marketing and will sell more. I dunno.",
      "4080S also didn't exist yesterday",
      "Looking at Techpowerup's bench of around 25 games, the 7900 XTX is faster at 1080, 1440p and 4k. The 4080S beats it in RT. They are currently trading blows, I'd say AMD will drop the price of the 7900 XTX.",
      "”Any product which sells out is, by definition, not overpriced.”\n\nFalse. Selling out is more to do with production size and available quantity. Nvidia could make a 4090Ti and sell it for 6K. It would still sell out if they made it in small quantities. \n\nRTX 4000 series hasnt in general been selling as well as Nvidia would like it to. They’re trying to anchor the prices higher, but especially in this market it’s simply untenable.",
      "I bought a 4080 for $1500 AUD ($990 USD) today, the cheapest 4080 Super is at its inflated Aussie MSRP of $1850 AUD ($1220 USD). \n\nHell 4070 Supers cost more than 4070 Tis here.",
      "It IS good marketing because everyone is talking about it but retailers sure aren't happy stuck with the overpriced 4080 cards nobody will buy now.",
      "People are economically illiterate.",
      "For what? The 7600 XT review is also marked with the thumbnail as \"Not worth it\". You're reading bias where there is none.",
      "This, for $1000 I don't want to see raster benchmarks. At a similar cost, AMD just cannot compete with the 4080S.\n\nHardware Unboxed 12 game average has the 4080S losing by 5FPS in pure raster. You won't notice a 5fps difference, but you will notice a massive difference in RT.",
      "They should've just dropped the price of the existing cards, but thats not how marketing works I guess :)",
      "It's not exactly \"trading blows\" when in RT performance it completely fumbles. Should drop 100 bucks minimum but even then I don't see many buying it, maybe 125 bucks so that it can compete with the 4070tiS, offering much better rasterization for the same price at the cost of RT.",
      "5% more core count, 1% boost clock bump and 5% base clock bump. Even if performance increase was 1:1 (it never is), it was never meant to be that much faster. \n\nI'm not exactly sure what all these \"disappointed\" people were expecting? Maybe next time don't set expectations to some non realistic ones.\n\nIt's a $200 price cut, that's all it is.",
      "I dont disagree with the overpriced part but the RTX 5 series might be even more expensive",
      "Pure rasterization, sure. But between the 4080 ray tracing and DLSS, and although the 7900 XTX is smaller it's way more power hungry, plus the CUDA cores for AI capability, the 7900 XTX is not competitive.",
      "You are exactly correct. 4080 chip was already maxed, nowhere to go except price cut.",
      "The way I see it, when these cards launched in 2022, both AMD and Nvidia’s offerings were overpriced, but the 7900xtx was perceived to be good value only because of that $200 price gap between it and the 4080. In a vacuum, or compared to previous gen pricing of its own cards, even AMD is taking the piss out of consumers with that price tag.\n\nNow that the 4080 Super is out at the same price, people are seeing that $1000 is too much to ask for the 7900xtx, but it always has been. The 4080S price drop is also still too much. Steve says it himself in this video, the price went from “complete insanity to moderate insanity.”\n\nIdc which “team” you’re on, we’re all getting taken for a ride."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "4080",
      "rtx4080"
    ],
    "title": "4080 Super for future AAA Games",
    "selftext": "Good evening to you pleasant people,\n\ni‘m planning to get a new gaming pc with the following specs:\n\n- AMD Ryzen 7 7800X3D\n- 16GB RTX4080 Super\n- 64GB RAM DDR5\n- 2TB NVMe SSD\n- Gigabyte B650E AORUS ELITE X ICE\n- 850W Gigabyte UD850GM 80+ Gold \n\nI‘m wondering if i‘m set for future AAA games that I can play at 60fps/4K Ultra. \n\nI was planning on playing games like Cyberpunk and Black Myth Wukong, but since UE5 is kind of challenging i‘m a bit worried about the future games that are expecting us.\n",
    "comments": [
      "I can tell you right now, nothing is future proof, plan accordingly",
      "This, there will ways be a new game that will shit on your pc especially at 4k",
      "What do people think future proofing is? Forever? \n\nIf it lasts you 5 years, it’s great for future proofing\n\n$2000 spent on a pc over 5 years is $35 dollars spent a month",
      "I personally prefer 1440p with a high refresh rate. I use an ultrawide myself.",
      "Wait for RTX 5000 Series. the 4000 Series is 2 years old now.",
      "I got 4090 early this year and it was so powerful I kept saying it is the card to have and nothing will even come close, however new games are lousy optimized for pc and I can see my cards sometimes struggling to get above 120FPS on ultra high settings with ray tracing with latest black myth wukong, so I now agree with your statement. Nothing is future proof, you can prolong your gpu lifespan by reducing quality graphic until they become really old and die or need replacement",
      "If you want longevity, 4080 Super will be solid at 1440 p for the next few years at max settings. 4k, it struggles even now with the most demanding games.",
      "I think a lot of people do what I do with GPU purchases. I tend to buy a high end GPU and lower the settings over time. High end GPUs can be relevant for close to a decade if you're realistic about settings.",
      "Most games with shit optimization nowadays are CPU limited on a 4090. The only games which can bring a 4090 to its knees on the GPU side are those with path tracing, like Cyberpunk or Wukong, and the Ubisoft games with hidden settings designed to run more on future GPUs than current ones. Given that every 50 series card except the 5090 is rumored to be slower or equal to a 4090 I would expect this situation to persist for a while.",
      "Yeah nothing is going to last a while at 4k max settings ultra.\n\nNot even a 4090.\n\nHere's a little secret for longevity - lower your resolution but maintain your preferred DPI, you'll get way more scaling performance over time.  A 4080 Super should be very good for 1440p for a while, Ti Supers as well due to their high performance and solid VRAM.  A 4070 Super, I wouldn't count on it due to VRAM getting maxed out sooner.",
      "A Gigabyte PSU.... goooooood luck with that not turning your whole pc into a trashcan. NEVER cheap out on your PSU!! Go for Bequiet or even better Seasonic!  With the ram go for dual channel cl30 6000mhz.",
      "If you can hold off a while, it's probably better to wait for 50 series if you want your system to last you as long as possible at 4k..  Or buy a 4090. \n\nThe 4080/4080s already struggles to hold 60fps at 4k in the most demanding games, like wukong, Alan wake and cyberpunk, you need both frame gen and dlss performance, if you want to use the path tracing/full ray tracing settings anyway. \n\nSo if games get anymore demanding at all, the 4080s won't manage 60fps 4k max settings. At lower settings you're probably fine for a while though.",
      "Only with raytracing at native. At some DLSS and most games can hit 60 or above depending on how much raytracing you have and what level of upscaling you are comfortable with",
      "At 4k, as long as you are not terrified of dlss, you should be set to play anything that comes out at almost max settings 60+ FPS for...a couple years atleast.\n4k IS crazy demanding and nobody knows whats comming.",
      "Imo everything is future proof as long as you’re realistic.\n1440p? Hate ne all day long but a 4080 is future proof idc how bad optimization get *it will futureproof you for years*.\n\nNow, 4k? Haha, then I completelt stand by you, if you want to play 4k forget ‘future proof’ and accept ‘need to buy new videocard every few years’ unless you like going from 60fps to 21 in some games that happen to be poorly optimized",
      "Depending on the settings in cyberpunk (i.e. full pathtracing and dlaa, no fg) I get 48.5 fps average with a 4090 on 1440p. With the same settings, but dlss quality and ray reconstruction instead of dlaa, it is roughly 90fps on average.\n\nSo: I guess \"future proof for 60fps at 4k\" may be a little too much for your config, depending on what settings you want to use. If you will go for dlss auto with FG on, it could fit better. But again \"future proof\" may not be the most realistic goal, because it depends on many factors.",
      "I'm a 4080 owner and it cannot handle maximum settings at 4K/60 right now in some games without frame generation *and* DLSS performance. Currently the compromises are hardly visible, but they won't last long.",
      "lot of times also depends on the optimization of the game though I know I only play at 1440p with a 165hz refresh rate on my 3080 Ti and it crushes most the games I have been playing the past few years",
      "This is what people don't get with future proofing. It's not about playing every game on the best settings. It's how long it can last before it can't run game.",
      "Even with DLSS it struggles to hit 60 on path traced games. I don’t disagree that it’s literally like 4 games right now, but worth pointing out that 1440p is a better experience on the most demanding games."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "4080"
    ],
    "title": "4080 super FE vs Asus Tuf Gaming Which ones is better to buy all points would be helpful",
    "selftext": "",
    "comments": [
      "The ASUS tuf model has the 4090 cooling solution on it. That’s the one I went with. Insanely good card, and from testing the second highest stable Overclocking under the strix rog model by a couple percent. Temps at 110% (352w) power load have never went over 63 degrees",
      "Fe looks better, exhausts heat out of the back of the case which is always a good thing, has better resale value. It’s also considerably shorter which makes it easier to fit in smaller cases. Disadvantages are it likely runs hotter which doesn’t matter at all in the grand scheme of things.",
      "Resale value alone makes this a no-brainer. Go FE if you can get one.",
      "FE, I got a tuf, has a noticeable coil whine and apparently asus gpus are suffering that more than others, coming from a silent and solid evga card I completely forgot it was a thing \n\nAlso there’s an annoying red light that stays on when the pc is off, and I can still very faintly hear it if I get close when it’s off, hoping this resolves itself with time, guess I’m turning off the socket to it every night now\n\nHave a decent psu using two individual sets of cables to power it too so it’s getting all its juice. \n\nEdit: noise has lessened somewhat since, new cable on the way so will see if that removes the rest, else will try undervolting\n\nFurther edit: new cable did remove the red light when device is off, however slight coil whine noise still present when device is off, and still plenty (although it did lessen a bit!) when device is on, undervolted card to help reduce it a bit but still plenty there, will look at getting it swapped and hope I get lucky",
      "Is the TUF model just as good with the lower tier cards like the 4070 Super?",
      "Yes it is but so is the founders 4080 super founds is really nice and fits in super small placesZ",
      "Idle temps aren't super meaningful with fan stop, though.",
      "All 4080’s use 4090 coolers\n\nEdit: except these new “slim” variants, of course",
      "The 4080FE has the 4090FE cooler as well.",
      "It doesn’t matter as a traditional GPU just blows all of its heat in the case which is likely to be exhausted out of the top and back.",
      "faulty aloof ludicrous prick coherent rinse swim sort somber vast\n\n *This post was mass deleted and anonymized with [Redact](https://redact.dev)*",
      "Same temperature but the TUF is much quieter.  Normalized volume it comes out about 4 degrees lower.\n\nhttps://www.techpowerup.com/review/asus-geforce-rtx-4080-super-tuf/39.html\n\nhttps://www.techpowerup.com/review/asus-geforce-rtx-4080-super-tuf/40.html",
      "Hard to say - I think a lot of people like the design, esp. the pass-through cooler, and in terms of performance nvidia has narrowed the gap between its stock card and the board partners to the point that they aren't even able to make huge improvements in clock without lots of voltage.\n\nEither way it's not just a fad - two generations of founders cards have gone through the used market and they're always selling for more than the partner cards.  I tried to get one that way myself, in part for the look now that I have one of these silly glass-sided PCs.",
      "They are very similar.  FE has a design people like more.  Tuf is much bigger but has better cooling and a dual bios.",
      "I went down a rabbit hole researching this and unless it’s your power supply I’m hoping that your coil wine goes away in a couple weeks",
      "I went with TUF for my RTX 4080 Super~ I live in Europe so FE cards are somewhat of a rarity & difficult to get your hands on. Meanwhile, I physically went to a local PC store and got an Asus model for an MSRP of 1150€ without any need to wait or worry that they would cancel my order without my consent or anything of the sort.",
      "FE all day. Love the design of the Supers. The all black looks so slick. Also fits in more cases.",
      "Gotcha. So w a fe card at least some of it is being pushed out the back",
      "I have an ASUS TUF 4080 and mine has terrible coil whine even after months of use. I've done a lot of research while trying to figure out how to make it quieter, and like you say, it turns out the ASUS TUF 40xx cards are the absolute worst when it comes to coil whine. I tried upgrading the power supply (had a 750w before) to one that's 1200w and has a 12vHPWR cable so that I could do away with the adapter, but the coil whine has persisted. :/\n\nThe only thing that has helped at all with the coil whine is undervolting. It didn't hurt performance at all, and the card is only half as loud now (but still annoying). You can find guides on how to do this on youtube if it turns out your coil whine doesn't go away after a while, which sometimes happens.",
      "It's his PSU/or environment which includes electric quality. Had an outlet in my parents house that I believe had a bunch of vdroop (weird PSU issues under load, made coil whine worse, hard crashed occasionally when other outlets wouldn't (either way PSU was pushed to around it's max, on paper/software I was pulling 800/850 watts so prolly a good bit over 850w with error and inefficiencies in wires taken into account.)) and eventually I learned that I just couldn't use that outlet. Was on the same breaker, don't know what the houses wire topology looked like tho.\n\nLong story short PSU and or power quality as well as EMI effects a lot more with modern machines than people give credit too. It's very common for people who \"Know what they're doing\" with hardware modifications to add capacitors, power bridges, increase switching freq/response of vrm, and edit a unholy amount of different areas in the vbios to turn a entry level/cheap card/board into something qthat can compete with XOC hardware. Spec is easy to hit by definition, and it is indeed meant to be that way; it lowers the barrier to enter a market segment. And also makes low spec hardware prone to errors, a single cap breaks and now whoops that line has crash-inducing vdroop, oh no I put my 4 layer Hx10 board in a ghetto rack or on a desk why am I getting errors or WHEAs out the ass, oh boy look a RT81xx can't wait to saturate my gigabit connection :P"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "4080"
    ],
    "title": "3090 Ti or 4080 Super",
    "selftext": "If you could buy a brand-new 3090 Ti for the price of a 4080 Super, which one would you choose?  \nA friend is asking me, and I'm not sure how to answer.  \nHe plays at 1440p and has a 13700k CPU.  \nP.S.: The 3090 Ti in my country is usually around 200 to 300$ more expensive.",
    "comments": [
      "4080 super lol it’s not a trick question tbh especially for\nThe same price.",
      "4080 super is a no brainer here, if you can find 3090 ti for 200-300 cheaper then you can start to consider it",
      "4080 Super is far better. The 3090 TI only if you need the extra VRAM.",
      "Same price? For gaming? The 4080 Super by a lot. Just check some benchmarks: https://www.techpowerup.com/review/nvidia-geforce-rtx-4080-super-founders-edition/31.html",
      "4080 Super",
      "Yes it seems that even the standard 4080 is better in gaming than the 3090 Ti. Thanks",
      "4080 super 100%",
      "Yea 4080 is a beast and don't forget about frame gen.",
      "I have a 4080 S, I have no friends.\n\nGet a 4080 S, be my friend.\n\nc:",
      "We can definitely forget about the 3000 series.",
      "Frame generation is amazing. 4080 super 100%",
      "4080 super is around 14% better than the 3090 ti according to techpowerup and it also supports frame gen, what's the point of getting a 3090 ti for the same price? the 16gb vram kind of sucks for future proofing since there are games that come close to that in 4k at the highest settings with all the things that take vram enabled but that shouldn't be an issue for 1440p even in the future and also if future proofing is what you are looking for then you should wait for the 50 series and hopefully the second version of those cards that is rumored to come with more vram",
      "Unless you have thhe very niche need for specifically the vram 4080 all day everyday.",
      "The 4070 Ti Super is on Par with the 3090 Ti but uses less power and has Frame Generation \n\nSo, the 4080 Super is a no brainer",
      "4080 - more is more",
      "4080 super destroys a 3090 ti. It's not even close",
      "The 4080 super is basically 1% faster than the 4080. It's just a very slightly updated version, mostly existing to make a price cut.",
      "I would always prefer 40xx series. The new technologies like DLSS or mainly Frame Generation are huge boost in some game I played and its only for 40xx series.",
      "3090 = 4070 super\n\nGet the 4080",
      "Gaming 4080 super, AI models 3090 Ti."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "4080",
      "rtx4080"
    ],
    "title": "Need help deciding 7900XTX vs 4080",
    "selftext": "Here is the thing, I bought Sapphire Nitro + 7900XTX for 1300euro. Now under the pressure of everyone around me I'm considering returning it for Gigabyte Eagle RTX4080 OC which is around 1500e. \n\nI'm gaming at UW monitor 3440x1440. Nothing special, some online FPS, RTS, city building etc. Main gaming is done on PS5. My question is if I don't really care about Ray Tracing which I always turned off when I was using 3080... Should I swap 7900XTX for 4080 and spend extra just over 200euro for 4080?\n\nI know you will say, its up to me, get 4090 etc ...but looking only these two cards...what should I do??",
    "comments": [
      "Care about raytracing -> Nvidia else Radeon         \nUsing productivity / AI -> Nvidia      \nPure gaming -> Radeon         \nNeed more memory -> Radeon         \nCare about price to performance -> Radeon else Nvidia",
      "Respect. You couldn't give me better answer. Thanks!",
      ">Care about price to performance -> Radeon else Nvidia\n\nPerhaps it's better to calculate with total cost of ownership than with just price. Depending in the use-case, the 7900 XTX over a period of 2 years can be almost 300 euros more expensive than the 4080, when considering both the asking price and the operational costs racked up during use. I helped a guy from the Netherlands our recently, he was using his PC 12 hours a day, mainly for gaming, but also consuming content. At 0.34 Euros per KWh, the 7900 XTX was almost 3x as expensive to run per week than the 4080. This resulted in the 4080 overtaking the 7900 XTX in TCO in less then a year, meaning that bay ownership day 366, the 4080 was actually cheaper than the 7900 XTX by about 77 euros. I feel like focusing on just the asking price is not the whole picture, and everyone who cares about price/performance should calculate TCO for themselves based on their own patterns.",
      "For 100usd difference might as well get the 4080",
      "Thanks everyone for you comments. Me being stupid and allowing other people opinions to rock my own decisions. GPU is a beast, working great and after reading all the comments it's not really logical to return this one and spend even more money on another card. For my need this is more then I need. Overkill you might say. Again, thanks everyone, you've been more then helpful.",
      "> At 0.34 Euros per KWh, the 7900 XTX was almost 3x as expensive to run per week than the 4080. \n\nA 7900XTX doesn't consume 3 times the power a 4080 does. There is like 20W diff in gaming and at worse 50W diff under other loads. For that to happen he would have to pretty much only watch videos.",
      "Well in theory Nvidia, but the price difference between nvidia and radeon in similar class is so big that you need to do play many hours a day, for many years to actually see the difference in the wallet (also in EU).         \n\nUnless you want to build something small factor and your PSU options are limited.   \n\nSo (TDP):          \n\n* 4070 is 190W    \n* 7800xt is 265W      \n* 4070ti is 285W      \n* 4080 is 320W     \n* 7900xt is 350W   \n* 7900xtx is 355W       \n* 4090 is 450W       \n\nSo comparing 2 similar cards ... and looking at price difference in some cases i pay as much for whole year for power usage for all stuff in my home.           \n\nYes nvidia is using less power, but in reality it us usually around 50W difference so like 1-2 \"light bulbs\".",
      "Look up the power consumption numbers from techpowerup's database. The biggest difference was during video playback, where the 7900 XTX was consuming about 10x more power. But generally, the 4080 is near the 200W mark while gaming, and the 7900 XTX is above 300W.",
      "4080 all day long :)\n\nOh and btw, there are rumors about potential 4080 Ti/Super coming in early 2024. So maybe wait a bit, and 4080 prices will drop eventually?",
      "I just did, I even have the tab still open : [https://www.techpowerup.com/review/amd-radeon-rx-7900-xt/37.html](https://www.techpowerup.com/review/amd-radeon-rx-7900-xt/37.html)\n\nTbf I watched the XT numbers instead of XTX, but the diff still isn't X3. It's 50W instead of 20 (300 vs 350).  \nAnd video playback isn't 10 times, it's x4 for the XTX.\n\nSo he would have to only watch videos when using his PC (and I suspect these numbers would look better nowadays after a year of driver updates).",
      "I don't care about power consumption tbh",
      "No, I understand that. But currently that is not an issue. I have quality 1000W PSU, big case with really good airflow and plenty of space.",
      "I should also add that Nvidia has superior AI upscaling technology that has better quality than FSR, so if your game supports DLSS, just buy Nvidia.",
      "About $3.50",
      "I think the idea that AMD is a lot less stable is pretty much false at this point. Most people I see over there that are having issues didn’t use DDU properly if at all, or are doing things outside of what the traditional use is like installing preview drivers. I have multiple systems running both manufacturers and while it is anecdotal, I’ve run into almost no issues on both. Truth is, you’re safe to go with either brand if they have what you’re looking for at the price point you’re aiming for.",
      "Unless you use Linux, in which case it is completely opposite.",
      "If you already bought a 7900XTX, and it's working fine, then why return it? \n\nAnyway, recently I've been in the same dilemma and I've been researching this topic for a month or so. I've read countless XTX vs 4080 threads on reddit. I've been watching the nvidia, amd, and buildapc subreddits, watched a lot of videos. I was leaning HARD towards the XTX initially, seemed really great value, but I slowly shifted towards nvidia. At the beginning I read it a lot that oh AMD driver issues are a thing of the past, it's really great now, people say it a lot, and I expect they'll reply the same to this comment too. \n\nSo my friend groups experience: \n I had a friend who bought a 3080, 0 issues. An other friend with 3090, 0 issues. I had a 3060ti 0 issues. My brother's 1060 never had any issues, my older 1060 the same. \n\nI had a friend who had constant driver issues with AMD GPU he bought 3 years ago. I have a friend who bought a 7800xt half a year ago, again some weird issues, black screens, crashes, and some weird stuffing handling 2 monitors, flashing screen whatever. \n\nMeanwhile some posts popped up on buildapc, where people said if you buy AMD expect to have some work to do, checking news/forums if drivers are stable or not, making sure windows don't overwrite them. Rolling back drivers if needed, tweaking settings. \n\nThen I found the threads again AMD users complaining. Rolling back drivers. Weird crashes. Huge consumption with multiple monitors. This was just a week ago: https://www.reddit.com/r/Amd/comments/16yuwgs/radeon_drivers_2392_and_3_not_working_correctly/\n\nAnd there might be some excuses, but nah i don't care fuck that if i'm spending this kind of money. In the end for me it was 4080 vs 4090, and I found a great openbox deal for 4090 and pulled the trigger. 0 issues.\n\nAlso on my 3060ti i used nvidia shadowplay a lot, nvidia broadcast's voice filter, nvidia filters in games, DLSS whenever I see it. I know amd has some great stuff too, and adrenaline is probably 100 times better than nvidia's software, but whatever at this point. Again, I almost bought an 7900XTX, but I glad I waited and spent some more time on the topic.",
      "Don't get me wrong this Sapphire Nitro+ 7900XTX really is a beast. My dilemma came from people taking shit about it so now I'm questioning my decision. But with all the answers here I'll just stick with it. I'm happy with the card, it's giving me what I need. \n\nBiggest mistake is to listen fanboyz :)) . No offense to anyone here.",
      "I kept 7900XTX",
      "Might depend on what monitors but my XTX at idle is between 10-15W, when gaming 340-350W at 90-100% utilization when at 4K  \n\n\n2 monitors, one 4K the other 2K"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "4080",
      "rtx4080"
    ],
    "title": "Grab a discounted 4080 while stock lasts or wait for 4070ti Super",
    "selftext": "Hi all, in Australia RTX4080 is already on sales (PNY Verto OC version is less than AU$1700 now, down from AU$1900). I was waiting for 4080 Super but the price in Australia is also super bloated, starting at AU$1870 (~ US$1250). \n\nWith similar performance to 4080, I can also grab 4070ti Super which starts at $1500 but Lord knows how inflated the actual price will be and whether the plebs like me even get to touch it.\n\nWhat do you guys think I should get? A 4080 now while it is still available or wait for the 4070ti Super?",
    "comments": [
      "Wait for the 6000",
      "The 4080 should be a smidge over 10% faster, which I wouldn't call similar. It's (4070ti super) is nearly exactly splitting the difference between a 4070ti and a 4080 in horsepower.\n\nSo is 10% more performance worth 13% more price???Only you can answer!",
      "\"On sale\"",
      "Wait for the 10000x series",
      "I think you should wait a bit for the actual RRP to set in for both the 4080S and the 4070Ti Super and the actual benchmark and real life performance setting in.\n\nHODL until EOFY sale as there might be some good deals leading up to it. New GPU won't go down in price significantly but you can be sure the older 4070Ti and 4080 will reduce in price for sure - hopefully at around 1,3k and 1,5k respectively.",
      "That's the 4080S over the base 4080. Here he's talking 4080 over 4070TiS",
      "I was wondering a similar thing. 4070ti in Aus is now down to what the 4070 was selling for ($1200 or so) and the 4070 is even down to below $900. \n\nInstinct is to wait but damn",
      "They can claim anything, but it's the same overall design across the five dies (none of which are thermal or bandwidth limited). In this case they are running with in a slim margin of the same clock rate. The 4070, 4070 super and 4070ti share the mid sized die. The 4070ti, 4080 and 4080 super share the next to largest die.\n\nNone of these \"new\" refreshes are \"new\". They're just new bins of the same product with more recent memory chips. Barring massive surprises, all refreshes work the same.\n\n(currently) A 4070ti super is the worst of the dies the 4080 is made on. A 4070ti is the best of it's size.\n\nIf you want to calculate what the cards are going to do, because the design itself has not changed, it's simple math. Take whatever processing ability you believe they have on that design that is ultimately setting the performance and calculate that out. Maybe it's Rasterization, maybe shader performance... Maybe you're boring and just count the total shaders, or the blocks of SM's. It will all remain relative in performance scaling because we have not changed anything in the design of the GPU dies themselves. How much of it have you enabled VS how fast are you asking it to run.\n\nThe only major difference in these mid-generation updates is that because production yields have now increased, the amount of failed GPU sections that need to be disabled to create XYZ bin based off that GPU die has now decreased. Allowing us to improve our basic bins up slightly.\n\nFor the OP, in this example we're comparing a 4070ti Super with a 4080. The card designs are the same; so the same memory and L2 cache system. On the GPU side... It's the same GPU where the 4080 has a 10.5% more hardware enabled, but is starting it's base clock at 4% slower. The net is that a 4080 should start at 6.5% faster, which is why nvidia is claiming 5%.\n\nUltimately it's the same die that has shown it wants to self overclock to a bit above 2700mhz. If this continues the newer 4070ti Super and 4080 Super will also want to self overclock to 2700mhz. So the clock difference will be a wash. (The only thing that has changed between a 4070ti super and a 4080 is a minor heat / power consumption reduction on something that was not typically power / heat limited in the first place).\n\nSo.... 10% faster in general once they all self overclock themselves.",
      "Wait for the 140X0 series!!",
      "4080 is discontinued. That is the ultimate form of shortage.",
      "Grab a $1700 4080, the super just exists for the msrp price cut. We might see further discounts to the super eventually but stock has sucked for gpus lately so who knows when.",
      "10% seems optimistic based on the specs.",
      "Hold on dear life.",
      "Nah, I'll be gopod with the OVER 9000 series!",
      "That's the point of the release. If you wait, are you willing to pay $1100 for the 4070S or $1500 for the TiS?\nThe TiS is a maybe because of the vram, but I think price:performance takes a dip and it ends up trending towards the 4080 as being another bad bang for buck card due to trying to profiteer off the vram upsell.",
      "4080 will still be better than the 70Ti Super.  If you can afford it and it's available now I'd just go for that.  The 80Super will only be 5-10% better, nothing to write home about it.",
      "I remember the days when these cards were $700...",
      "What does HODL stand for?",
      "It's a misspelling of hold",
      "Get the 4080 over the 4070 super"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "4080",
      "rtx4080"
    ],
    "title": "Should I buy the 4080 Super or should I wait for the next generation?",
    "selftext": "I'm looking for components to build a gaming PC and I was determined to get an RTX4080 Super, until, after doing so much research on Nvidia, I started getting recommended news on my phone about a possible upcoming launch of the 5000 series. Should I buy the 4080 Super or wait for this new generation and see what it offers?",
    "comments": [
      "&#x200B;\n\nhttps://preview.redd.it/wo5u415oqykd1.png?width=490&format=png&auto=webp&s=dc57362f1fc9cc821f81e7d88b64ffbf223e30ee",
      "Why not wait for the 6080? Just get the 4080 and enjoy your computer. It’s a beast of a card.",
      "Depends if you want to wait 5-6 months before building or not.",
      "I would wait for the rtx 5080",
      "I just build a PC with placeholder graphics card, waiting for next gen personally",
      "never buy a new gpu at the end of its cycle",
      "Nah, wait for the 5080. And then might as well wait for the 6080. And why stop there? 🙃",
      "3080 at 3440x1440 here. 4080s would be the first to break my +50% uplift, i do not upgrade below. Ill wait for 5xxx",
      "That's if he's lucky enough to buy one. Majority of buyers skip a gen.",
      "This. Just get it.\n\nI was asking myself that question and this is what I told myself.\n\nIf op is in UK then they have a 20% voucher on very.",
      "Wait and see what the next gen brings. You may get much better for the same money or less.",
      "If you are good about reselling your old parts on eBay/FB marketplace, etc. Then I don't see a reason not to get the 4080S now. Enjoy it for 6+ months and resell after you can secure the 5080 at a good price. You'll take a small loss but the 4080S will still be a great card for someone else to buy.",
      "Do you want a PC now? Get the 4080 SUPER. Can you wait half a year to maybe get a more attractive card? Wait. We really can't help you much here. It completely depends on your priorities.",
      "Wait for 50 series unless you are absolutely desperate.",
      "If you do wait just keep in mind you're not guaranteed to get a new card at launch.",
      "If you can find a 4080 on a good discount i would go ahead and get a 4080. I found a new 4080s with -$150 usd discount and i thought it was a fair deal. \n\nNow if budget is not an issue, like you are fine dropping $1k+ for it day one and you can wait for it for months accounting for possible supply shortage then 5000 series would be a good idea.",
      "Wait or if you really want to do it right now, get a 4070 Super which has the best value for money = less loss when the next gen comes",
      "There is always a new product on the horizon. If you want to game now, just get the RTX4080. If you want to game 9 months from now, get whatever fits your budget by than.",
      "This is what I was kind of thinking.  I'm going from a 4770k/1080ti to a 14700 and perhaps a 4060 until the 5080 is out and available.  Figure I can just flip the old cards later to some miners or whoever buys them",
      "Why is this the case?"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "4080",
      "rtx4080"
    ],
    "title": "How much difference does Clock Speed make on a RTX4080?",
    "selftext": "I am currently experimenting with my 4080\n\nWhat I discovered so far testing with Expedition 33 Epic Settings DLAA@4k\n\nClock Speed Limit 2550 vs 2800+ (no limiter except Heat)\n\nI get not even a 2FPS difference 34/35 vs 36FPS\n\nSo how much difference does this 250+ more Clock actually do? If the the practical effect seems so low?\n\nAt that point I looked at the Voltage Curve and did this \n\nhttps://preview.redd.it/3hame8slsp1f1.png?width=1375&format=png&auto=webp&s=72a6b5f9601994bf949237098d4838f4dbb151e2\n\nI looked at the mV closest to 2550 (advertised speed) dragged it up just a little (+45) to reach 2550.\n\nHow much performance am I actually losing doing this?\n\nWhen I search on the internet I can't really find an answer how much the Clock speed actually affects FPS, but it seems so marginal to be borderline not worth it.\n\nBut at the same time I don't know much about the intricacies of Overclocking/Undervolting vs Actual Benefits apart from that Undervolting reduces Power Consumption and Heat (similar to Power Limiting)",
    "comments": [
      "A 2 fps increase from 34 is still around a 6% improvement and you only increased clock speed by about 10%. In 4k I believe memory clock speed matters more for performance",
      "You have to monitor if your simple +250Mhz clock is actually sustained (which is probably not because of thermal throttling) while gaming.\n\nThe default curve is meant to make a given voltage to work with a corresponding clock speed for the whole GPU serie, no matter the binning/silicon lottery so its actually almost always overvolted for most cards.\n\nBy undervolting you get closer to how little voltage can be used by your specific GPU for a clock speed and so reducing the heat. This way your clock speed could be sustained (no thermal throttling) for any amount of time, resulting in overall better performance (especially 1% lows).",
      "thats a good point.",
      "So would it be a \"decent\" idea to try aim for a point on the curve where I know I won't get into a heat throttle and slightly raise up the clock (+50) from where the Curve point starts to get a steady Clockspeed?\n\nSince unlocked the mV fluctuates wildly as does the Clock Speed.\n\nSince as you put it, it is \"overvolted\" by default. So I basically would Power Limit the GPU not by Watt but by mV usable right?\n\nSo far when I tried to Undervolt with Guides one game or another crashes just because of my attempt at Undervolting. So for example Expedition 33 2550@915 mV occasionally crashes (feels almost random) but when I put it just 50 higher 2600 it crashes very consistently. This was tested in the very same scenarion and environment/battle just standing still when my turn is.",
      "Your decent idea is actually the exact goal of undervolting.\n\nFirst try to find a stable voltage (the point where you flatten your curve) for like 10%  lower than your base clock. Check for stability with OCCT (software).\n\nThen try to raise the clock from that voltage by small increment (always checking with OCCT) until you get close to base clock. If you are too far behind then raise the voltage.\n\nIf by the end you prefer to get a slightly lower clock speed but lowest stable voltage (my preference) or slightly higher clock but higher voltage is up to you.\n\nAlso keep in mind that all GPU are not equal (cf. binning/silicon lottery) and some will be able to deviate a lot from base settings but other not.\n\nThe position in the constructor range will also matter so for example an Asus TUF (entry level in Asus range) will in general be worse at undervolting/overclocking than an Asus Strix or Astral.",
      "So what you suggest is basically doing the reverse. You choose the clock speed and apply a lower mV 10% lower than the MSI Curve shows?",
      "Yeah you can visualize it this way or the way around.\n\nWhat is important here is to first find a voltage low enough to avoid thermal throttling (the voltage is the determinant in heat generation).\n\nThen you can aim to get the clock speed as high as possible. On some GPU it could even get higher than default clock speed.",
      "good point. What I find weird is that the mV fluctuates heavily near the temp limit which is between 79-84 (84 being the default limit in MSI) sot actually thanks for the Idea to find the mV point where I am as close to the temp limit but keeping it there instead of fluctuating.",
      "2500 is low."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "4080",
      "rtx4080"
    ],
    "title": "Is it worth it upgrading from an RTX 3090 to a RTX4080/4090 for non-gamers?",
    "selftext": "As the title says...I use my 3090 mainly for ML tasks and encoding/decoding of 4K videos. CPU=14900K, btw.\n\n**Edit:** I seem to have left out some bit of crucial information. I was hoping to sell the 3090 and use these funds towards a reasonably priced 4080/4090 once the 50-series are released.\n\nThe 14900K was a free RMA upgrade from Intel due to the Vmin shift bug form my much older 13900k. They had run out of 13900K cpus, hence the 14K free replacement. \n\nFor those unfamiliar with student funding woes in graduate school (working towards my PhD in Biomedical Engineering), sometimes you have funding, hence that's when I could afford to buy a new 13900K based desktop PC, when my 7 year old laptop suddenly and completely died on me once sunday afternoon, in the middle of my work, for no apparent reason 4 years ago. The pain and panic was insane!!! Thankfully, I had steady funding to afford a $1,500, 13K based desktop.\n\nAnd sometimes the funding goes away (3 times so far), so you are forced to borrow from Uncle Sam and live on the remaining crumbs after all tuition for that semester is paid off. In the meanwhile, you are desparately searching for other funding sources from other professors, which is difficult to get. Everyone is either broke (have no funds) or its all used by their current crop of graduate students.\n\nI say all the above to remove impressions that I was somehow 'rolling in money' and could readily afford these expensive",
    "comments": [
      "you mean 24? no 3090 has 12",
      "wait for the 50 series, also isnt machine learning vram heavy, so a 4080 wouldnt make much sense no? (im not an expert)",
      "I think 4090 is still  priced higher than 5080. \n(Based on the spec sheet), but lets wait and see until it officially confirmed.\n\nIf its still out of your budget , then get the 40 series.\nProbably it get price cut by then.",
      "Better off getting a second 3090 and an nvlink.\nGaming is really the only reason to prefer a 4090.",
      "performance wise? obviously yes\n\nsmart wise? hell no. the 5090 is literally 2 months away",
      "We don't know how much 50 series cost, and are you aware that 4090 goes for 1800 USD?",
      "Since rtx 50 is probably revealed on january (ces) \nWhy not wait for that?",
      "No, a 4080 outperforms a 3090 when the vram is usage is less than 16gb.\n\nFor machine learning workloads, it's common that Vram is the limiting factor and that the 3090 smokes a 4080.",
      "And yet here you are with a thread about maybe upgrading your 30 series flagship card to the 40 series flagship.",
      "Ok but prices should come down once the 5000 series is released. Then buy a 4080/4090.",
      "But your student budget can afford a 4090?",
      "Nah keep the 3090",
      "No",
      "Direct to the point. Thanks!",
      "A 3090 has 24gb of vram from my understanding and the only upgrade path if you need that much is a 4090 or 5090. If money was tight it (it would seem so for you since you cannot afford to wait any of the 50 series) would make sense to make the most financially feasible choice and continue to use your current hardware unless it is not servicing your needs.",
      "It has 24GBVRAM",
      "If you're on a student budget then should just stick with the 3090 which is very good already",
      "4080 is slower because of its 16gb ram. Buying another 3090 is the way to go (3090 ti much better components and vram cooling)",
      "I have a 3090. Keep holding on to it. Wait for 50 series.",
      "I appreciate your comments more than you can imagine. Thank you!!!"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "4080",
      "rtx4080"
    ],
    "title": "nVidia GeForce RTX 4080 Meta Review",
    "selftext": "- compilation of 10 launch reviews with ~3420 gaming benchmarks at all resolutions\n- only benchmarks at real games compiled, not included any 3DMark & Unigine benchmarks\n- geometric mean in all cases\n- standard rasterizer performance without ray-tracing and/or DLSS/FSR/XeSS\n- extra ray-tracing benchmarks after the standard rasterizer benchmarks\n- stock performance on (usual) reference/FE boards, no overclocking\n- factory overclocked cards _(results marked in italics)_ were normalized to reference clocks/performance, but just for the overall performance average (so the listings show the original result, just the index has been normalized)\n- missing results were interpolated (for a more accurate average) based on the available & former results\n- performance average is (moderate) weighted in favor of reviews with more benchmarks\n- for the full results plus (incl. power draw numbers) and some more explanations check [3DCenter's launch analysis](https://www.3dcenter.org/artikel/launch-analyse-nvidia-geforce-rtx-4080)\n\n&nbsp;\n\n2160p Perf.|6800XT|6900XT|6950XT|3080-10G|3080Ti|3090|3090Ti|4080|4090\n|:--|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|\nGen & Mem|RDNA2 16GB|RDNA2 16GB|RDNA2 16GB|Ampere 10GB|Ampere 12GB|Ampere 24GB|Ampere 24GB|Ada 16GB|Ada 24GB\nComputerB|63.6%|70.2%|-|67.1%|74.8%|_80.3%_|84.4%|100%|134.2%\nEurogamer|64.9%|70.2%|-|68.4%|75.9%|78.3%|86.3%|100%|128.5%\nIgor's|63.8%|67.8%|_75.9%_|63.0%|78.6%|80.4%|88.1%|100%|135.3%\nKitGuru|65.4%|71.2%|_77.0%_|68.6%|75.3%|77.4%|85.4%|100%|132.1%\nLeComptoir|62.6%|68.6%|_75.6%_|66.3%|74.3%|77.1%|84.7%|100%|136.5%\nPaul's|-|68.3%|_71.8%_|-|73.7%|75.2%|_84.9%_|100%|127.7%\nPCGH|65.6%|-|75.1%|67.3%|-|-|84.3%|100%|133.9%\nPurePC|62.7%|67.3%|_72.7%_|66.7%|74.0%|76.0%|83.3%|100%|131.3%\nQuasarZ|64.8%|71.4%|76.6%|68.5%|76.4%|78.0%|84.5%|100%|132.9%\nTweakers|65.1%|-|75.0%|68.6%|-|75.6%|_86.6%_|100%|129.2%\n**average 2160p Perf.**|**64.3%**|**69.9%**|**74.2%**|**67.2%**|**75.3%**|**77.4%**|**84.8%**|**100%**|**132.2%**\nTDP|300W|300W|335W|320W|350W|350W|450W|320W|450W\nreal Consumption|298W|303W|348W|325W|350W|359W|462W|297W|418W\nMSRP|$649|$999|$1099|$699|$1199|$1499|$1999|$1199|$1599\n\n&nbsp;\n\n1440p Perf.|6800XT|6900XT|6950XT|3080-10G|3080Ti|3090|3090Ti|4080|4090\n|:--|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|\nComputerB|65.3%|71.7%|-|67.7%|74.0%|_79.4%_|82.4%|100%|116.6%\nEurogamer|68.6%|73.4%|-|68.4%|75.6%|78.1%|84.1%|100%|114.8%\nIgor's|68.5%|72.6%|_80.4%_|71.1%|78.3%|79.9%|85.3%|100%|120.3%\nKitGuru|68.4%|74.3%|_79.8%_|69.1%|74.8%|77.0%|83.8%|100%|118.6%\nLeComptoir|65.2%|70.9%|_77.2%_|64.9%|72.4%|75.1%|81.2%|100%|121.4%\nPaul's|-|78.1%|_81.5%_|-|78.9%|79.8%|_87.8%_|100%|115.0%\nPCGH|67.9%|-|77.3%|67.2%|-|-|81.4%|100%|123.3%\nPurePC|65.1%|69.8%|_75.2%_|67.1%|73.2%|75.2%|81.9%|100%|125.5%\nQuasarZ|69.8%|76.3%|80.6%|71.9%|78.6%|79.9%|85.0%|100%|120.6%\nTweakers|69.5%|-|79.5%|69.4%|-|77.2%|_84.1%_|100%|121.7%\n**average 1440p Perf.**|**68.3%**|**73.8%**|**77.8%**|**68.9%**|**75.8%**|**77.6%**|**83.4%**|**100%**|**119.3%**\n\n&nbsp;\n\n1080p Perf.|6800XT|6900XT|6950XT|3080-10G|3080Ti|3090|3090Ti|4080|4090\n|:--|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|\nKitGuru|74.6%|79.8%|_81.4%_|74.1%|79.3%|81.4%|86.5%|100%|108.0%\nPaul's|-|89.4%|_93.2%_|-|87.1%|87.3%|_94.0%_|100%|110.1%\nPCGH|71.8%|-|80.4%|69.3%|-|-|81.2%|100%|116.6%\nPurePC|67.8%|71.9%|_77.4%_|68.5%|74.7%|76.7%|82.2%|100%|121.2%\nQuasarZ|75.0%|80.8%|84.6%|77.2%|81.5%|83.4%|86.8%|100%|111.3%\nTweakers|72.3%|-|81.8%|72.0%|-|78.8%|_83.3%_|100%|113.4%\n**average 1080p Perf.**|**75.2%**|**79.8%**|**83.7%**|**74.4%**|**79.9%**|**81.5%**|**85.5%**|**100%**|**112.5%**\n\n&nbsp;\n\nRT@2160p|6800XT|6900XT|6950XT|3080-10G|3080Ti|3090|3090Ti|4080|4090\n|:--|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|\nComputerB|45.9%|50.6%|-|60.1%|73.0%|_78.9%_|83.5%|100%|137.7%\nEurogamer|43.1%|47.5%|-|64.5%|74.1%|76.7%|85.4%|100%|140.7%\nKitGuru|46.5%|50.8%|_54.5%_|61.1%|71.3%|73.3%|82.3%|100%|137.4%\nPurePC|42.6%|45.7%|_49.4%_|61.7%|71.0%|72.8%|82.7%|100%|142.6%\nQuasarZ|49.2%|53.3%|57.2%|64.2%|73.2%|74.5%|81.6%|100%|136.1%\n**average RT@2160p Perf.**|**45.5%**|**49.7%**|**52.9%**|**61.9%**|**72.6%**|**74.8%**|**83.2%**|**100%**|**138.7%**\n\n&nbsp;\n\nRT@1440p|6800XT|6900XT|6950XT|3080-10G|3080Ti|3090|3090Ti|4080|4090\n|:--|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|\nComputerB|50.5%|55.2%|-|68.3%|75.0%|_80.2%_|83.4%|100%|120.6%\nEurogamer|46.5%|50.2%|-|67.6%|74.4%|77.5%|85.0%|100%|130.8%\nKitGuru|48.3%|52.6%|_56.4%_|66.2%|72.6%|74.4%|82.0%|100%|117.8%\nLeComptoir|47.7%|51.5%|_56.3%_|63.2%|70.8%|73.2%|79.7%|100%|128.6%\nPurePC|43.7%|46.2%|_50.0%_|63.3%|70.9%|73.4%|81.0%|100%|136.7%\nQuasarZ|55.3%|59.9%|63.1%|70.7%|77.8%|78.9%|84.9%|100%|124.1%\n**average RT@1440p Perf.**|**48.7%**|**52.7%**|**55.7%**|**66.3%**|**73.4%**|**75.6%**|**82.3%**|**100%**|**125.8%**\n\n&nbsp;\n\nRT@1080p &nbsp; &nbsp; |6800XT|6900XT|6950XT|3080-10G|3080Ti|3090|3090Ti|4080|4090\n|:--|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|\nKitGuru|52.8%|57.9%|_61.4%_|72.3%|77.8%|80.0%|86.0%|100%|109.7%\nPurePC|43.9%|47.1%|_50.3%_|63.7%|72.6%|74.5%|81.5%|100%|136.3%\n\n&nbsp;\n\nGen. Comparison|RTX3080-10G|RTX4080|Difference|RTX3090|RTX4090|Difference\n|:--|:--:|:--:|:--|:--:|:--:|:--|\naverage 2160p Perf.|67.2%|100%|**+48.8%**|77.4%|132.2%|+70.8%\naverage 1440p Perf.|68.9%|100%|+45.1%|77.6%|119.3%|+53.7%\naverage 1080p Perf.|74.4%|100%|+34.4%|81.5%|112.5%|+38.0%\naverage RT@2160p Perf.|61.9%|100%|+61.6%|74.8%|138.7%|+85.4%\naverage RT@1440p Perf.|66.3%|100%|+50.8%|75.6%|125.8%|+66.4%\nTDP|320W|320W|±0|350W|450W|+29%\nreal Consumption|325W|297W|–9%|359W|418W|+16%\nMSRP|$699|$1199|**+72%**|$1499|$1599|+7%\n\n&nbsp;\n\nFE vs AIB Models|Boost Clock|real Clock|Power-Limit /max.|real Consumpt.|Hotspot|Loudness|2160p Perf.\n|:--|:--:|:--:|:--:|:--:|:--:|:--:|:--:|\nnVidia Founders Edition|2505 MHz|2737 MHz|320/355W|304W|73°C|34.3 dBA|100%\nAsus Strix OC|2625 MHz|2859 MHz|360/420W|340W|72°C|32.1 dBA|+3%\nColorful Ultra White OC|2610 MHz|2803 MHz|350/370W|331W|76°C|40.1 dBA|+2%\nGainward Phantom GS|2640 MHz|2855 MHz|340/400W|338W|74°C|31.5 dBA|+2%\nMSI Gaming X Trio|2595 MHz|2824 MHz|320/370W|328W|79°C|26.9 dBA|+2%\nMSI Suprim X|2625 MHz|2861 MHz|320/400W|321W|76°C|26.8 dBA|+2%\nPNY Verto OC|2550 MHz|2779 MHz|320/320W|318W|74°C|26.1 dBA|+1%\nZotac AMP Extreme Airo|2565 MHz|2840 MHz|320/450W|318W|73°C|36.9 dBA|+2%\n\n&nbsp;\n\nNote: This analysis only refers to reviews that used nVidia driver 521.90 (or newer) for RTX30 cards, because older drivers can overestimate the RTX40 performance effect. Since quite a few reviewers used older RTX30 drivers for this launch, there is one task for the upcoming RX7900 launch: **Please update drivers!**\n\n&nbsp;\n\nSources:    \nBenchmarks by [ComputerBase](https://www.computerbase.de/2022-11/nvidia-aus-msi-zotac-geforce-rtx-4080-review-test/), [Eurogamer](https://www.eurogamer.net/digitalfoundry-2022-nvidia-geforce-rtx-4080-review-a-powerful-gpu-with-a-big-pricing-problem), [Igor's Lab](https://www.igorslab.de/nvidia-geforce-rtx-4080-founders-edition-24gb-im-test-schneller-als-gedacht-und-sparsamer-als-befuerchtet/), [KitGuru](https://www.kitguru.net/components/graphic-cards/dominic-moass/nvidia-rtx-4080-founders-edition-review/), [Le Comptoir du Hardware](https://www.comptoir-hardware.com/articles/cartes-graphiques/46900-test-nvidia-geforce-rtx-4080.html), [Paul's Hardware](https://www.youtube.com/watch?v=T8lS4v3-Nyg), [PC Games Hardware](https://www.pcgameshardware.de/Geforce-RTX-4080-16GB-Grafikkarte-279171/Tests/Release-Benchmark-Specs-Kaufen-Preis-1407013/), [PurePC](https://www.purepc.pl/test-kart-graficznych-nvidia-geforce-rtx-4080-vs-geforce-rtx-3090-ti-bylaby-rewelacja-gdyby-nie-zaporowa-cena), [Quasarzone](https://quasarzone.com/bbs/qc_bench/views/82726), [TechPowerUp](https://www.techpowerup.com/review/nvidia-geforce-rtx-4080-founders-edition/), [Tweakers](https://tweakers.net/reviews/10638/nvidia-geforce-rtx-4080-de-enige-echte-4080.html)    \nCompilation by [3DCenter.org](https://www.3dcenter.org/artikel/launch-analyse-nvidia-geforce-rtx-4080)",
    "comments": [
      "Sigh.\n\nYes the 4090 might actually be better FPS per $, but calling a $1600+ GPU a 'better value' and 'bang for buck performance' is disgusting. \n\nI hate this launch, but AMD coming up short with performance means they likely wont be much better. Duopolies suck.",
      "The 4090 is 38.7% faster in raytraced 4K, which means it's a better value at $1600 vs $1200.  Considering most people are buying these cards to play games at 4K with raytracing, you're get more bang for buck performance with the 4090, plus 24 GB VRAM.",
      "Thanks. 18-20% faster than 3090 Ti, 28% faster than 3090, and 48% faster than 3080 at. Gap grows with RT, 32% faster than 3090 at 1440p, which is DLSS Quality base resolution at 4k. \n\nPeople here are going to hate it, but the 4080 is selling out in the US for online retailers. Best Buy, Amazon, Newegg, all models at MSRP are gone. That doesn't go along with what some dumbass Techtubers say though, and the narrative that we want to believe. Even physical stores the MSRP models are gone, leaving only the heavily overpriced cards. In the coming months, I think AIB 4080 will remain at MSRP or under, and the 4090 will cast away its msrp models.\n\n7900XTX is likely to be 5-10% faster going with these results for $200 less at msrp. If the 4090 wasn't available and I absolutely had to pick one, the 4080 is a very easy choice between the two. DLSS3/DLAA, faster RT, and all the extras when it comes to software.",
      "The 4000 series really dumped all its stat points into raytracing.",
      "Its a great 4k card nevermind 1440p.",
      "How is it not bad? This is a new generation. You should be getting lower end cards that beat the high end of last gen for LESS. Otherwise what is the point? Will the 5090 be $3000?\n\nThe 1070 was equal to the 980Ti for $300 less, the 2060 was equal to a 1080 for $300 less...",
      "Mate, where have been the last 5 years? Last time GPU prices made sense was Pascal",
      "So 4070ti will be on par with 3090ti for $899?",
      "So twice the cost of the last gen cards and 30 percent more performance.\n\nAND less value for money than the overpriced 4090. \n\nGreat",
      "Came from a 2080ti + waterblock. I'm ashamed to say I'm used to these prices now 😔",
      "Here's a crazy stat for you. Do you wanna know how much more expensive the 3090ti was over the 2080ti? 800$. \n\nYou're literally comparing it to the largest price increase in the history of graphics cards. Ever. And I'm now comparing that with the other largest price increase, ever, in the 2080Ti compared to the 1080ti. Close to 3x in 2 gens, and now you're applauding nvidia for making 1000+ the new mid range. Fantastic.\n\nEven at 1000$ the 4080 is a hard pass.",
      "it's pretty close to raster tbh\n\n3080 10GB probably just didn't have enough memory to cut it at 4k RT, but at 1440p RT it seems pretty close in the percentages with raster\n\nand for the 4090, I suspect the raster perf is sometimes still bottlenecked even at 4k, and the card stretches its legs more often with RT on",
      "There is too much performance gap to label it the Ti",
      "If the price goes down on the 4080 it’ll be a great 1440p card. But looking at this.. just get an ampere card or an amd card",
      ">30 percent more performance.\n\nMinor nitpick, but that's not now percentages work. You divide by the lower number, not subtract it from 100%.\n\nIf you scroll down it even says the 4080 is **48.8% faster** than the 3080 at 4k and **45.1% faster** than 3080 10GB at 1440p",
      "Here is my review. It's overpriced and not worth it for any situation.",
      "No points in charisma, smh",
      "Just get a 3080 if you want to game at 1440p. Or wait for the upcoming 4080 12GB... I mean 4070Ti.",
      "If you're spending over $1k, it really doesn't make much sense to go with the 4080 to be fair.\n\nI'm not so sure that Nvidia's plan to reset the high end at above $1k will work, as those willing to spend that much will want the best, not the distant 2nd.",
      "$700 3080 in late 2020 (and the first few weeks of 2021) wasn't bad."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "4080",
      "rtx4080"
    ],
    "title": "Which 4080 super to choose?",
    "selftext": "**Hi** everyone, I'm about to buy my new monster.  \nThe last step for me is to choose between these different graphics cards:\n\n    16GB ZOTAC RTX4080 SUPER Trinity Black +€15\n    OR\n    16GB Gigabyte RTX4080 SUPER WINDFORCE +€40 \n    OR\n    16GB Palit RTX4080  SUPER JETSTREAM OC +15€ \n    OR\n    16GB NVIDIA RTX4080 SUPER (any manufacturer  according to the site) +€0   \n\nMy use will be mainly **gaming**, including a bit of VR.\n\nI have no other choice of graphics card because I want to order on Dubaro.\n\n**Which one would be the best/most suitable given the price difference?**\n\n\n\nIf you're interested, here's the rest of the configuration:\n\n    Fractal Design North XL Charcoal TG Dark \n    AMD Ryzen 7 7800X3D (8x 4.2GHz / 5.00GHz Turbo) \n    be quiet! Dark Rock 4 \n    MSI B650 GAMING PLUS WIFI DDR5 32GB (2x16GB) \n    DDR5 6000MHz G.Skill Trident Z5 NEO RGB CL30 \n    2TB WD Blue SN580 M.2 PCIe 4.0 x4 NVME (L 4150MB/s ; S 4150MB/s) \n    850W Corsair RM850e 80+Gold ATX 3.0 - PCIE 5\n\nIf you have any further advice, please do not hesitate to tell me.\n\n**Thanks to all !**",
    "comments": [
      "FYI TechTesters recently compared 9 RTX 4080 Super models (https://youtu.be/nPJR4LQ-IKc):   \n- ASUS ROG Strix OC   \n- ASUS TUF Gaming OC   \n- Gigabyte Aero OC   \n- Gigabyte Gaming OC   \n- lnno3D X3   \n- MSI Suprim X   \n- Palit Jetstream OC   \n- MSI Expert   \n- Nvidia Founders Edition   \nTLDR:   \nBest value: Nvidia FE, Palit Jetstream OC   \nGaming performance is almost the same\nfor all GPUs   \nMSI Suprim X is the quietest, Inno3D X3 is\nthe loudest   \nGigabyte cards have the lowest\ntemperatures. Inno3D X3 has the highest.\nGigabyte cards offer 1 year extra\nwarranty. Default BIOS is a bit loud",
      "Just get the FE? It’s the cheapest.",
      "offer clumsy tease aware cobweb marble lush sharp boast elastic\n\n *This post was mass deleted and anonymized with [Redact](https://redact.dev)*",
      "I went with the Aorus Master for the cooling solution. It's a huge massive card....clocks well over 2.7ghz and stays nice and chilly.",
      "i can’t on this site sadly",
      "FE is out of stock last I checked.",
      "I think i'm gonna go with the palit jetstream OC, thanks 🙏",
      "Whatever one is cheaper. They are all 99.9% identical.",
      "Cheapest one. Every one of them is almost the same.\n\nI have Gainward (same company as Palit) 4080 Phantom and it is problem free and I love it. This was the cheapest option in my region.",
      "FE is the best if not available go with Zotac Trinity.",
      "In this day and age, the standard that the FE sets ensures that 3rd party board makers have to really try to exceed the standard.",
      "Founders Edition is the cheapest, imo looks the best and has the most safe/consistent resale value if you ever upgrade.",
      "I didn't find this comparison before,  thanks 🙏  \nI think I'm going to go with the Palit jetstream OC even if I don't know this brand :)",
      "This is a good summary, but it's also worth noting that local prices can vary a lot.  Only the Tuf OC model is available in europe, which is above MSRP and thus not great.  There is also a Tuf non-OC variant (in small numbers) sold at MSRP and that card is pretty good value.\n\nAlso, the gigabyte gaming OC has very low temps, but achieves this with slightly higher fan speeds than the competition, so techtesters suggested using the quiet bios.\n\nInno3D has the highest temps and generally worst performance, but is also a true 2-slot card, so it is absolutely the best in terms of case compatibility (without actually being too hot to use in normal environments).",
      "(Im the OP) \nWhy FE ? Its not on dubaro\nShould I buy it aside my command ?",
      "ok thanks 🙏",
      "Sorry for the late comment highjack. I’m looking at a panther oc from gainward. Probably not 1:1 comparable but so far how do you like noise and temps? I read that the fan motor of gainward cards is loud. Also do you have coilewhine?",
      "If you can get the founder's edition at MSRP that is probably better value than the Palit.  They will perform similarly both in terms of rendering and temperatures, but FE has higher build quality (because Nvidia privileges itself relative to the partner cards) and potentially higher resale value (since they don't sell too many FE cards and they are highly sought after).  So saving a little bit of money for a slightly higher quality product that should hold its value better seems like the way to go.",
      "Wait, the last option is not FE? I assumed that's what it meant. Either way get the cheapest imo.",
      "Maybe from nvidias official store"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "4080",
      "rtx4080"
    ],
    "title": "[Giveaway] Black Myth: Wukong launches August 20th featuring Full Ray Tracing and DLSS 3. Tell us what you are most excited about Black Myth: Wukong for a chance to win a copy or a custom GPU backplate!",
    "selftext": "&#x200B;\n\nhttps://preview.redd.it/xt0kccrgnuid1.jpg?width=2048&format=pjpg&auto=webp&s=fcc2854c6cb80064fd11cb4d6978952cca61d3dc\n\nBlack Myth: Wukong is coming on August 20th. Dive into the enchanting world of Chinese mythology in Black Myth: Wukong, an action RPG that offers a deep narrative and stunning visuals.  \n\nPowered by [GeForce RTX GPUs and featuring full ray tracing and DLSS 3 technologies](https://www.nvidia.com/en-us/geforce/news/black-myth-wukong-full-ray-tracing-dlss-3/), the game showcases some of the most realistic lighting, reflections, and shadows.\n\n[Launch Trailer](https://www.youtube.com/watch?v=97egUiMlLZM)\n\n**Win a copy of Black Myth: Wukong or a custom GPU backplate**\n\nComment below between 8/15 and 8/20 for a chance to win a copy of the game or a custom Black Myth: Wukong GPU backplate. *(Compatible with RTX4080 / 4080 SUPER / 4090 FE)* \n\n* *What excites you the most about Black Myth: Wukong?*\n* *Which NVIDIA RTX feature (DLSS 3, full ray tracing) are you most looking forward to in Black Myth: Wukong?*\n\nTo learn more: [*\\[Link to article\\]*](https://www.nvidia.com/en-us/geforce/news/black-myth-wukong-full-ray-tracing-dlss-3/)\n\n[Terms and Conditions](https://www.nvidia.com/en-us/geforce/contests/wukong-backplate-giveaway-official-rules/)",
    "comments": [
      "I'm excited for the story of Journey to the West being brought to life as a game!\n\nLooking forward to using DLSS and Frame Gen!",
      "It’s too epicccc",
      "Reject human return to monke",
      "I am exited about all the transformations and fighting styles !",
      "I really want to play a game as a monkey! \n\nAlso, I'm not too familiar with The Sun Wukong but have some vague knowledge of it from other media. I'm curious about Chinese \"myth\" and literary figures as I've long had an interest in that of other cultures and areas of the world but I've really not been exposed to much outside of a predominantly Western scope. I'm excited to explore this world as someone with which everything in the game will be new and unexpected.\n\nAlong with that since moving across the country and rebuilding my pc into a small form factor one, I bought a Founders 4080Super. Both DLSS and raytracing are a blast to mess around with. Ray-tracing is really a lot of fun to experience but I'll say DLSS is the feature that is most appealing. Going from 1440p native maxed settings around 110 in some games to 160+ in games is awesome. I'm excited to see the world of this game and what characters we meet along the way.",
      "son goku was here.",
      "I’m excited about the gameplay \n\nI’m more excited to Ray Tracing",
      "I am excited about my GPU going up in flames when I attempt to boot up the game",
      "* Unraveling the story of the Monkey King Wukong and discovering his true destiny!\n* DLSS 3 will be nice to use to assist with performance alongside DLSS!",
      "I just would like to enter the world. Combat looks cool and it seems to be something worth checking out!\n\nDLSS3 frame gen is what I'm most keen on seeing with the game.",
      "The gameplay looks pretty cool, I guess I'm most excited about that.",
      "The lore as well as RTX technology",
      "I am exited about the visuals and the gameplay.",
      "Looking forward to the graphics and gameplay on my ultrawide. As well as the unique environments and unique characters. Having both DLSS 3 and Ray tracing will ensure a beautifully smooth experience.",
      "I like the character design and the landscape. This game looks like it will fun to play and the story sounds interesting. Because I never heard of it before.",
      "I am excited about my pc can handle it",
      "new souls like by not western devs is the most exciting part besides monkeys\ndlss 3 for sure",
      "I don't know anything about the story, so excited to get to experience it.",
      "![gif](giphy|evB90wPnh5LxG3XU5o|downsized)",
      "Most excited to play my won copy. 😉"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "rtx4080"
    ],
    "title": "RTX3090 vs RTX4070ti vs RX7900XT and RTX4080 for triple 2K screen sim-racing and gaming",
    "selftext": "Hello everyone,\n\nI have a RTX3060ti and an Intel i7 10700F with 650W 80PLUS gold psu. I want to upgrade my system to play **triple 2K screen sim-racing** and also using my 4th 2K monitor on my desk for gaming. I am torn between RTX3090 (840USD) vs RTX4070ti (980USD) vs RX7900XT (980USD) and RTX4080 (1120USD). There are a lot of criteria to consider such as 12GB VRAM on 4070ti, AMD not performing well with iRacing and having to upgrade my PSU depending on the option. I would appreciate every comment and recommendation. I do play new games and demanding titles also other sims as well. (ALL GPU's are brand new)",
    "comments": [
      "Is that ultra-wides or regulars?\n\nI'm going to assume regular 16:9. One 4K display is just shy of 8.5 million pixels. One 1440p display is just shy of 3.7 and three of them just over 11 million pixels.\n\nThis means your setup is going to be about 30% more demanding than a regular 16:9 4K display.\n\nI'm going to go out on a limb here and suggest you look for a card that can handle 4K at 30% more FPS than what you require.",
      "Firstly no, of course I have scrolled through countless blogs and reddit posts about my question but couldn't find the info I searched for and the answers were not considering triple screen sim-racing and gaming as well. Also given that the prices we have are different than posts I saw, so I wanted to get my own answers.",
      "Thank you, a very nice insight of what performance to expect. 🙏🏼",
      "I'd go 4080 or 7900xtx. I use a 7900xtx and game in 1440p ultrawide",
      "Sim racing is pretty fast pace versus, for example, flight SIM therefore i would imagine youre going to want higher frame rate. Id check with the SIM pit sub Reddit to pick their brain as well. \n\nI have a 4090 and have used a triple monitor 2k setup with my flight SIM (dcs) before and it was pretty demanding. It kind of made me nauseous because the frame rate were lower than I was used to. Just my two cents on this.",
      "I wouldn’t bother with 3090 at that price new, look at used for decent value.\n\nFyi for psu i had to upgrade to 850w from 750 as i would shutdown in intense games",
      "Thanks, I’m considering the 4080 to be a strong choice. I might go all in while I’m upgrading so 🤷‍♂️",
      "I would not put too much trust into the price points, feels like this ominous 4070 super will be a replacement for the 4070ti, including a handed down price tag.",
      "Quite a lot of pixels, I'd probably lean towards the 4080, especially if you wanna play demanding stuff on that triple screen setup.\n\nAnyway, rumors making the place about nvidia releasing new-ish cards at next years CES. If you're not in a hurry I'd probably wait till then. I doubt they gonna turn out to be more of a bargain than the current ones, but, just so you know.",
      "Personally I’m using a 4080 on a 49” Samsung G9 5120x1440 for IRacing , and a 27” second monitor for simhub. Not triples but I upgraded from a 4070ti gained up to 40fps on max settings. Personally if it’s for sim racing I’d go for the 4080 , should be more than enough for triples on high setting. Also use my rig for gaming on an adjustable seat.",
      "The RTX 4080 is the way.",
      "Strange, I run my 3090 on 650W without issues. But my CPU is taking only 110W, if you had some i9 with 300W power intake, that might be the issue.",
      "Thank you for the reply, though i don’t think I will wait for the new ones. I might upgrade to it if I can get my hands on what’s new to come 👍🏼",
      "The problem for this person is that the 4080 super won’t be that much more powerful than the 4080 so it might not be worth the wait",
      "I'd lean towards the 4080 only because of my experience with the 7900xtx. I absolutely love the card and I got it for about $250 under retail price. That being said, I had to repaste the gpu because the factory paste was terrible. My hot spot got up to 94 with a delta of 40! I used ptm7950 now my Hotspot doest get above 76 and my delta is always in the 12 to 15 range. Beautiful card now, but you shouldn't have to repaste a new gpu at this point in the game",
      "This seems more like a Powercolor issue than an AMD issue.  Sapphire and XFX cards seem to have a lot less issues.",
      "A 94C hotsppt is really not bad. The delta is not good, but they are rated for 110C, I think. If it was 100C or higher, then I'd be worried. But yeah, the thermal paste and lads should be applied better from the factory.",
      "Yeah the extra 4gb of vram might lead to extra longevity and the few more cores will also help lead to extra performance. What I’m really excites me is the 4070 super as it should have much more performance for about $600 which is right in my budget",
      "Sapphire is the best. The xfx cards are having the same issue",
      "Are you playing a bench mark?.. you can be at 0% BOTTLENECK with a 2070 Super and a 3900X.. you know you can't see 200 fps.. save your money.. unless cinebench is the best game on your system"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "4080",
      "rtx4080"
    ],
    "title": "RTX4080 custom power cable ",
    "selftext": "So I’m looking into getting a custom cable for my rtx 4080 aero from gigabyte and on cable mods website they just have ones that go from the 12vhpwr to a dual 8 pin while my card came with one that goes to a triple 8 pin would that work or is it going to harm the card in anyway the cables are rated for 600 watt draw from both 8 pin connectors ",
    "comments": [
      "I'm in the same situation. I have a xpg core reactor 850w gold psu and the only official 12vhpwr cable they offer is a 600w rated one but with 2x8 pcie connectors instead of 3. Should be enough in theory since each pcie provides up to 150w and if you add 75w from the pcie slot you get 375w which is more than the 320w tdp of the card",
      "I just got a 12VHPWR to 2x8 pin PCI-e from them after an email exchange where they claimed all their 12VHPWR cables can supply 600w. I got it last week and it can supply 125% power limit to my RTX 4080 Super, so yes it does work. :)\n\nIn the past I've owned a Vega 64 which only had 2 8 pin plugs and could pull 600w (transients) but typically 400w. It's fine as long as the cables are 18 AWG and I'm gonna guess the 12VHPWR ones are 16 AWG.",
      "MODDIY offers quite a few 12VHPWR cables. I’m using one of their 16-pin to 16-pin silicone cables in my Dan H4 H20 and a 16-pin to 3x8-pin cable in an NR200P Max, both work great."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "4080",
      "rtx4080"
    ],
    "title": "Adding 2nd rtx4080 for endering etc",
    "selftext": "Mainly for optimizing Blender, Maya, Houdini and the like....\nCurrently have 'NVIDIA GeForce RTX 4080 - 16 Go - GIGABYTE Eagle OC' mobo, with '64GB DDR5 RAM 6000 MHz Corsair Vengeance' and 'NVIDIA GeForce RTX 4080 - 16 Go - GIGABYTE Eagle OC - compatible DLSS 3' in the Pci5x16 (running x16) slot.\nWould adding a 2nd identical gpu card in the 1st Pci4x16 (running x4) make a big difference, or would it be a waste, due mainly I guess to the only 'running 4x' limitation?\nIf so what mobo would be of interest, so i can reuse my gpu, cpu (i7-13700K), ram and nvme disks, and add a 2nd gpu?\nbtw, psu is 1200w, I think it's enough for the 2nd gpu...\nThanks.",
    "comments": [
      "Yes you can run 2xGPUs for rendering. Blender and maya support it (don't know about houdini). Of course it depends on what you are rendering specifically.  \n  \nI would say that it might be cheaper to sell the 4080 and buy a 4090 than buying another 4080 and maybe replacing your current motherboard as you think you need.  \nYou get the bigger benefit of the extra VRAM on the GPU which I think will be more beneficial than another 4080. They do not linear scale. And if you insist on using the same CPU, than any motherboard you will get will most likely isn't going to be fully beneficial to the two GPUs to be used to their max potential."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "4080",
      "rtx4080"
    ],
    "title": "How to \"deactivate\" the RGB on asus tuf 4080?",
    "selftext": "I have an ASUS tuf 4080 \\[[https://www.asus.com/motherboards-components/graphics-cards/tuf-gaming/tuf-rtx4080-16g-gaming/](https://www.asus.com/motherboards-components/graphics-cards/tuf-gaming/tuf-rtx4080-16g-gaming/)\\] I'm trying to find a way to turn off the RGB color(s) on the card. Looking for software to do this. Already checked openRGB, no go.. If anyone knows a way, that'd be great. It actually got turned on somehow after I ran  evga precision, but i dont see a setting to turn it back off. I cannot install asus armourycrate, if you know anything about it, its probably the shittiest software ever developed.. You cant get it installed, ever. Thanks",
    "comments": [
      "You can just unplug it",
      "On my 3080 asus tuf, I never could get software settings to stick I just put electrical tape over the rgb. I hate rgb so much",
      "Openrgb",
      "I was able to change RGB using Corsair iCue on my 3070",
      "It doesn't work lol.. You get 1 shot with it. Only works IF you do it after a fresh OS install. After that, it's a no go. Even the uninstaller doesn't work.",
      "Try the standalone Asus Aura -\n\n[https://www.asus.com/campaign/aura/us/download.php](https://www.asus.com/campaign/aura/us/download.php)\n\nActual download link:\n\n[https://dlcdnets.asus.com/pub/ASUS/mb/14Utilities/Lighting\\_Control\\_1.07.84\\_v2.zip](https://dlcdnets.asus.com/pub/ASUS/mb/14Utilities/Lighting_Control_1.07.84_v2.zip)",
      "Ill check it out.",
      "SignalRGB will let you do just about anything to it and automatically detects it.",
      "I use SignalRGB for my Strix 4090. It should save the configuration that you set for the card and run it that way at start up as long as you don't fully disconnect power.",
      "I literally just turned mine off today on my ASUS TUF board. You just need to restart your computer and hit the Delete key a bunch of times to get into the Bios menu. \n\nFrom there, look in the top middle of the UI and click on the setting to turn off the AURA or turn off all the digital lights.",
      "Disconnect the lil 3-pin or whatever cable that powers the lights on the card. No goofing with software needed",
      "With Asus Aura , you can install it , turn the rgb off and then uninstall it while keeping the changes",
      "Couldn't get openrgb to work.",
      "Ill check it out. Asus tuf mobo? That's what i have.",
      "Doesnt work.. The gpu rgb always turns back on. And I only had this problem after I installed EVGA precision. I've done uninstalled it long ago and reinstalled windows etc.. I cannot get it to sync to where i can just use the case controllers.. If I boot into windows 10, I have a working armoury crate there and it will sync, but as soon as I reboot it goes back to everything being off except the gpu rgb.",
      "No exaggerating, it literally is not installable.. It will just keep saying it needs an update, does the update, needs update, does the update, and on and on. no functionalality",
      "Asus Armoury Crate",
      "I think that's an exaggeration, as I've installed, uninstalled, and reinstalled many times over the years without issue and only once on a fresh OS install.\n\nIf it's that big of an issue you can just disconnect the cable on the motherboard that controls the lights."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "4080"
    ],
    "title": "Anyone has the galax sg 1 click OC rtx 4080 ?",
    "selftext": "It is the only one sold at MSRP where I live but the below average price is making it look suspicious ngl.\nSo does anyone have experience with this card or any other similar galax products ? Or should I spend an extra $100 for. PNY XLR8 or Zotac AMP extreme AIRO instead ?",
    "comments": [
      "I got the galax 4090, runs great. Was one of the cheaper options here in Australia. No coil whine, runs quiet, especially at 70% PL.\nHas a fan for the backplate and a support bracket, both with RGB if that's your thing.",
      "I have the 4090 version. Runs great oc well. Only issue is finding a water block for it",
      "I do not.  I mostly buy OC cards because they're not as compact, usually have a nicer style, more speed (of course), and better quality cooling.  IMO spend the extra change on it.  I have a AORUS RTX 3080 XTREME and it still runs flawlessly, when it comes time to sell the card as well you're most likely going to get more money, RTX 5000 is going to be released soon as well",
      "What no Galax is a great brand, but only famous in asia\n\nMine runs cool and quiet, it also comes with extra top fan and sag stand with rgb. Its really stupid to be paying 100 extra for almost nothing. If you look up 4080 comparisons its a tier 2 which is very decent for the price",
      "I have one. Was a bit unsure because I have never owned a Galax card before, usually had Evga. I have absolutely no complaints about it and would definitely buy another Galax card now.",
      "I got the 4090 version. Runs great, whispers at 30% fan all day",
      "I had the Galax 4080 and it was a great card. It ran very cool and quiet and if it’s important, looked great. Also comes with a 3 year warranty.\n\nI now have the Zotac Airo 4080 which is also a great card. I’d choose whichever is cheaper or has the best warranty in your region.",
      "That card looks like those $10 mice you see on Amazon lol. But a 4080 is a 4080",
      "Bruh, its Galax, have 4090 for the first time trying Galax, and honestly, its running great and very cool.\n\nIts cheaper because they are using hard plastic shroud around the fans, which offsets the cost of aluminum.",
      "Beware that some kfa2 models have very annoying fan buzzing sound (3:16): https://youtu.be/GTsfzi09iV0",
      "Just ordered the kfa2 rtx4080 SG.👍",
      "Which is exactly why I can’t trust it no matter how hard I try 🥲 but like, where I live rx 7900 xtx (only model is sapphire nitro+) is the same price as the galax 4080 so",
      "I wouldn't worry about it. Galax isnt bad. That card in particular just has an ugly shroud design.",
      "I have it. When it's set to a solid color and brightness down it's not bad. But unicorn vomit makes everything look bad IMO. Otherwise, Galax is a great brand with much better QV than the big 3."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "4080",
      "rtx4080"
    ],
    "title": "RTX 4080 upgrade",
    "selftext": "Thinking of upgrading from my RTX2070 super into a RTX4080. Do i need a whole overhaul or should a new power supply be enough for now? My main concern is about the motherboard. But i havent seen anything thats says it wouldn't work. \n\nCurrent system is;\nRyzen 9 3900x\nAsus TUF MotherBoard X570\nEVGA 750 bronze (i have an asus thor 850 platinum ready to replace it, just been lazy)\n4 ram sticks of g.skill ddr4 16 gb",
    "comments": [
      "I’d do the 850W PSU and drop in a 5800X3D. The gaming performance difference between a 3900X and 5800X3D is pretty significant. The CPU upgrade would keep you in good shape for quite awhile. The reason to upgrade the CPU is that the 3900X has 3 CCDs of 4 cores each and the latency between CCDs is bad for games. The 5800X3D solves this issue. You’ll have higher FPS and higher minimum FPS.",
      "I did this, went from 3900x to 5800x3d since i bought a 4090. I had a 3080 and by switching the cpu only i had a notable improvement",
      "There is absolutely no reason for an overhaul. Just insall a 750w psu (some say 850w would be better but i really don't know) and youre good to go.",
      "Running 4080 FE + Ryzen 9 7900X on 750W Seasonic Focus+ Gold... system just purrs :p",
      "You should be fine (probably time to put that 850w psu in, though) pending resolution. You could always slap a 5800x3D CPU in there if you’re not satisfied.\nTo confirm, you have 16gbx4 system, so 64gb total?",
      "Just make sure the connections are good and shouldn't melt :P",
      "4080 FE is small-ish (comparatively) and [fits nicely in Fractal Design Meshify C.](https://imgur.com/4Rvk28q)",
      "What resolution and refresh rate do you play at? And what sort of games? I know in single threaded performance the 3900x is similar to a 9900K (obviously beats it in multithreaded) and from what I’ve seen the CPU could bottleneck the 4080 in some games.",
      "I would look at whether your case is big enough considering how big the cards are and be sure you somehow address the whole melting connector issue.",
      "4080s are massive. I have one and it fills the feactal torrent",
      "Currently I am running a 5800X3D + MSI 4080 + Arctic Liquid Freezer II 420  \non a BeQuiet! 700W silver. 3DMark results are above average and I didn't have any issues with Windows.\n\nStill I will buy a new PSU soon, just to be safe.",
      "Very cool, thank you. Ill keep that in mind.",
      "Awesome. Thank you for the advise.",
      "I play a bit of everything, but i like stuff like ace combat, cyberpunk, or tekken. Though usually trying to play in high or the best resolution and around 80ish or 90 fps. Though sometimes do stream and theres were im seeing some issues with fps. Or in some games causes the gpu to go tonjet mode lol",
      "My 4090 may be massive, but it fits in a Meshlicious (sub 15L), mini-itx case without a problem…",
      "I am gaming with 5800XD and 4090, PSU is 750W seasonic and no problems. I have  the power limit at 100 though and dont go for 600W"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "4080",
      "rtx4080"
    ],
    "title": "4080 or 4090 for 5120 x 1440p",
    "selftext": "Hi everyone,\nI have an ultrawide screen 32:9 5120 x 1440p (G9 neo) and I struggle to find any benchmark/review for that resolution. I've found only one so far here in this sub.\nI hesitate between a RTX4080 (1350€) and the 4090 (1999€). The price difference here is quite high thus the hesitate. I'm not sure if I \"need\" the 4090 but I'd like to play the newest games (nothing hardcore) including AAA titles and not have the need to upgrade for at least 2 generation.\nNow for 1440p I'd definitely go with the 4080, but for my resolution I'm not sure since there is almost as many pixels as 4k. CPU is a I9 13900k with DDR5.\nIf any of you is playing with the same resolution with a 4080 any feedback would be appreciated 👍",
    "comments": [
      "5120 x 1440 = 7 372 800 pixels.\n\n4k (3840x2160) = 8 294 400 pixels.\n\nSo it is a bit under 4k in pixel counts, so just watch any reviews at 4k resolution, for example this has a ton of games:\n\n[https://www.youtube.com/watch?v=l6vn6Cpd4Yc](https://www.youtube.com/watch?v=l6vn6Cpd4Yc&t=1491s)\n\n4k average is 111fps for the rtx 4080, 144 for the 4090.\n\nYour monitor is 240hz, so the RTX 4090 is the obvious choice, unless you are okay with playing medium high settings (imo looks the same as ultra), then the RTX4080 can be good enough.",
      "4090. I play at 5K there’s no reason to gimp with a 4080",
      "Buy what u can afford.",
      "980.. almost no GPU 😬\nYeah I am probably going to rewatch some reviews for 4K.",
      "I have the same monitor and a 4090, and i can say it's very good. A bit worse than 4k, but a lot better than 2k",
      "I have the suprim liquid x 4090 and I play It on the neo odissey g9 at the same resolution you are saying. You can feel It requires work, so count It as a 4k.",
      "4090 all the way, i did it from a 3080, it was frustrating with my g9 neo. Now rtx 4090 cut everything maxed out 120 fps",
      "Yeah probably gonna rewatch some tests and decide on that. Honestly, I would like to pick the 4090 but the price is just absurd doesn't sit right to me😬",
      "Im in the boat with you. I have the G9 also just not the neo. I am waiting for the 4090 but I keep wondering if all this wait and the extra 500 spent is necessary or if the 4080 that I can go pick up today would be perfect. Like if it's a difference I will easily notice I prefer to wait. But if it's things I will only notice during benchmark tests I have many other things that I could put that 500 buck towards.",
      "This question keeps popping up, same monitor too. The answers by users and responses by OP's are always the same.\n\nYou're pushing a huge res. 4090 is the answer although a 4080 will do.\n\nUsers will say this, then OP states how expensive a 4090 is. Then they say thanks and they are getting the 4090.\n\nAd nauseam. I don't get it.\n\nDoes anyone use the search bar? The same thing has been asked 100+ times. Literally the same thing, same monitor, GPUs, resolution and gaming use case.\n\nYeah, go watch reviews to tell you what you already knew before you asked.",
      "What card are you running now (if any)?\n\nYou're getting close to 4K territory, I think you can look at some 4K benchmarks and it would be pretty similar to get an idea.",
      "4090 if the price difference is something you can comfortably afford.",
      "Like a TV, always go as big as you can afford. In this case, 4090 if you can.   \n\\* By afford, I mean if you had the buy the 4090 twice, you could and be fine\\*",
      "Yes, you have to go for 4090.",
      "I have benchmarked the 4080 at this resolution. It will be fine for pretty much all games with raster. And for ray tracing, only cyber punk will need you to turn DLSS up past its quality setting.",
      "Same for me",
      "How does it compare to the 4090? I wouldn't mind having 500+ to spend on things other than the 4090 lol.",
      "Click on my profile and you can find a couple of videos that will answer if the 4080 is enough for your resolution"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "4080",
      "rtx4080"
    ],
    "title": "RTX 4080 what monitor to pair it with?",
    "selftext": "I've 400EUR budget for a monitor to use as a main monitor sided with 2 144hz 1080p monitors that I already have, I was thinking about a G5 but I've heard about tearing and ghosting, I was also considering an HP X34, what do you suggest? and should I stick with 2k over 4k?  \n\n\nThe RTX4080 is paired with an i9 13900k.",
    "comments": [
      "with that hardware I’d want to go 4k at least 100hz. Maybe 3440x1440 high refresh?",
      "Monitors unboxed/Hardware unboxed does round up videos often on Youtube. I’d go 4K high refresh.\n\n[Round up](https://youtu.be/WFfxOfZ8T_U)",
      "what would you suggest with that budget?  \n\n\nI've found a  LC - POWER 34\"  3440x1440 165hz, is the G5 better?",
      "4k 144Hz or 240Hz 1440p",
      "Man i have the same hardware and really really want that PG42UQ but it's expensive as hell",
      "Thank you for the video, we got higher prices here in Europe, I'm already thinking about spending 1\\\\2k for a good monitor in the next months, now I'm just looking for something for 400 EUR to get by.",
      "What you got now?",
      "Dell s3422dwg - dell had great warranty on monitors. \n\nOr the Samsung g5 looks great too.",
      "I own the lc power one, and really like it. No experience with the g5 though",
      "I have a old-ish Acer Predator XB271HU . It does it's job until i'll grab an OLED 4k panel",
      "Do you have any ghosting? what config you mounting?",
      "Thank you, If I don't find anything I might just stick with the G5, I'll get a new one in a few months anyways, I just needed something to get by, sadly the Dell is a little bit off price here in EU."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "4080",
      "rtx4080"
    ],
    "title": "Opinions on ZOTAC RTX4080 TRINITY?",
    "selftext": "This is the cheapest 4080 I can find and here it is cheaper by a lot. So I'm looking to get this for someone but it's important to me to know if there is anything to know about this specific Zotac card. Does anyone have this or know how it compares in terms of power draw and noise including possible coilwhine to the other 4080? Any first hand experience would be much appriciated. Any reason to not get it? Thanks",
    "comments": [
      "I used to have one. Worked fine and has great cooling just like most if not all the other 4080s. No coil whine for me and I was able to use it with an 850W PSU",
      "I have a 4080 Trinity.. fine Card.. No coilwhine.\nVery cool and silent too.. didnt See more as 60 degree Celsius Core temp.. even under full load with max powerlimit",
      "I have a 4090 FE now",
      "Got a 4090 Trinity OC. No coil whine either, stays under 70 C under full load, quiet.\n\nThe FireStorm software for RGB/OC is pretty decent to good.",
      "great 5 years warranty best",
      "No issues so far here.",
      "Good sample of satisfied customers - reviews of this card.   This is the cheapest one in my country so I'm glad to read - that the temps are good and even better - or a bonus - of no coil whine.  Hopefully, that's the case for most/ many of them.",
      "So why don't you have it anymore?",
      "Still holding up? I love the feedback from the Zotac and it is making me lean towards getting one even more.",
      "I'm happy without it outside of the fans ferociously cheap quality now. I'm on a vacation but I plan to DIY 2 Arctic 14 or 12s on it because it's absolutely not usable in my silent system."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "4080"
    ],
    "title": "Can my existing power supply support 4080?",
    "selftext": "My power supply is [Aorus P850W](https://www.gigabyte.com/Power-Supply/GP-AP850GM#kf). I use 3 pci-e slots for my 3080 and a cpu. Would it be able to handle the 4080 with 3 8 pins with an adapter? Each pci-e cable has the same power output right?",
    "comments": [
      "Got my 4090 gaming oc on a 850x. Your 4080 will have 0 issues.",
      "I am running a 4080 on my 650w ps. It all matters on what else is using power. Fans, lots of usb, SSDs, spinning disks. \n\n The recommended power supply spec for the GPU assumes you to have a few hard drives, and other things.",
      "Easy. I have a Gigabyte RTX 4090 Gaming OC running with a 12900k on a 750 Watt PSU without issues. Go for it\n\n[See here](https://imgur.com/a/5eeT1Vz)",
      "No, it's not. You need 850W minimum, not 1000W. Only foolish people say that. You can go with your PSU even with 4080-4090",
      "Wait, really?",
      "You only need a massive psu if you do stuff that maxes out both cpu and gpu. For gaming purposes, cpu doesn't use too much power and I highly doubt many people let their 4090s run at 600W.\n\nFor your thread question, I have 860W psu and I run 13700k and 4080 without any problems.",
      "hmmm i might consider getting 4090 then. thanks",
      "Should be fine",
      "My ZOTAC RTx4080 didnt Even reach 250w Most of the time",
      "I regret not buying 1000W psu because when I upgrade to 6090 (nice) I’m gonna be paying for that. Stupid.",
      "Running a 4080 and 5900x on a 600watt platinum corsair.. the recommended requirements are almost always way more than you realistically need.",
      "Yes, really. [Here](https://imgur.com/a/5eeT1Vz)",
      "I use iot with a 750 Watt PSU without problems. No overclocking of course. [https://imgur.com/a/5eeT1Vz](https://imgur.com/a/5eeT1Vz)",
      "Just so you know you would still have 350 to 380 watts of power left over if you oc the card.",
      "what, isnt 4090 requirements a 1000w?"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "4080",
      "rtx4080"
    ],
    "title": "Thinking about 4080 purchase, have a few questions",
    "selftext": "Hello. Basically I was always AMD first. Last Nvidia GPU was 8800GT. Right now I am using 6800xt. Recently I've watched Half Life RTX release and that made me want GPU with RTX support. I am looking right now at RTX4080, but keep seeing some negative reviews and advices about waiting for 4080Ti or price cut for 4080. I have a few questions:\n\n1. Is RTX 4080 is good GPU for it's own money in todays market? ( I know about comparisons about what GPU prices used to be, but I think that's in the past already and will be in future)\n2. Will 4080 perform >60fps in RTX content on 1440p?\n3. Is 750w enough for this GPU?\n\nThanks!",
    "comments": [
      "So in my opinion, the only real, genuine problem with the RTX 4080 is the price. I am a 4080 owner myself, and I absolutely love the card, and I think I'm more satisfied with it than I was when I tried the $700 6900XT. \n\nTo answer your questions first:\n\n1. The RTX 4080 is extremely overpriced, it should have been $900 at the absolute most. Not because of its quality, mainly because of how much of a hike it is after the $700 3080. It being \"worth\" $1200 is entirely a subjective matter, I am personally very content with having spent it, as I don't plan on upgrading anymore for at least 5 years, which I'm fairly confident it will make it to.\n2. Yes, especially with DLSS quality and 3.0. Natively it should easily hit 60fps across the board (maybe with the exception of Portal RTX but that's an incredibly heavy product in general). But for the average game like Cyberpunk or Spider-Man, yes you can absolutely hit over 60fps with RTX on at 1440p. If you don't believe me, look up some YouTube benchmark videos.\n3. 750w is enough for the 4080, absolutely, especially if you have an AMD CPU. One of the most phenomenal things about the 4080 is how insanely efficient it is. During normal gaming (and I play at 1440p 180hz), the average wattage I'm seeing is *200-270w*, with absolute peaks at like 320w. The transient spikes are also significantly better than Ampere's with the spikes going only as high as 380w. Its effectively 40% faster than a 3080 but ends up consuming less power.\n\n&#x200B;\n\nSo all in all, I think if you have the money, and if you can afford it, then I'd highly recommend the 4080 as a piece of hardware. The performance is awesome, the thermals and wattage are impressive and Ada is definitely a lot more efficient than Ampere was. For 1440p its a monster and its a good 4k gaming card. 16GB of VRAM also gives it a lot more room to work with than the 4070ti (which imo 12GB is way too little, games are already starting to stress 10GB cards at 1440p with RT). Theres also just the typical Nvidia superiority with stuff like video encoders and decoders (Ada has two NVENCs on the GPU so its monstrous), driver stability (I had a horrible time with my RDNA2 card), and the founders card has a 3 year warranty and is actually built fairly well, unlike the 7900xtx AMD cards.",
      "Nvidia planning on it being overpriced doesn't make it not overpriced. Its overpriced in that it shows a significant reduction in price/performance compared to any other generation, and its a poor value card. I may be glowing about the 4080 but its absolutely horrible value when you evaluate it on a price/perf measure. Its definitely not a good card for those penny-pinching their builds.",
      "1. 🤷🏻‍♂️ Would just go ahead and get a 4090, but sure. Prices aren't going down any time soon.  \n\n\n2. Depends. Minecraft RTX isn't Cyberpunk. It won't do it in Forspoken but you'll be fine in Tomb Raider. So maybe, but mostly yes.  \n\n\n3. Yes.",
      ">And have to make sure your psu has 3 pcie ports, as the 40 series adapter needs 3 separate connections to the psu . It won't be sufficient using one of the two-headed cables for 2 of the adapter plugs\n\nTwo cables are fine for 4080.",
      "With a 4080 I can play over 160 fps almost any game in 2k ultra RT max, If I switch on DLSS Quality I can reach 260+ fps, do you think this is enough for you?",
      "I have the 4080. Amazing card, great thermals and power efficient. I would wait for price drop or get a 1000w PSU + 4090. I don’t think price drop is happening anytime soon and if you are asking, probably means you want to buy soon. 4070ti is also a great option for 1440p and you can wait to upgrade to 4k + 60 series later. Personally, I regret not going 4090, but it runs way hotter and eats watts. I probably woulda went 4070ti in hindsight.",
      "See I had a 4080 then went 90 and at 1440p ultrawide I max my frames out at 170. But it’s also not using anymore power than the 4080 at that resolution I’m mainly 225-280watts only portal rtx pushed it to 350watts. After having both I woulda been happy with the 80 but I always like to buy the best one just in case a cyberpunk style demanding game comes out. I waste money is what Iv come to realize lol",
      "I guess I am also thinking about when 4k OLED become cheaper, I would love having the 4090 over the 4080. At 1440p, 4080 is perfect. I’ll most likely go UW 1440p OLED over 4k in a few years because of this.",
      "I have the Alienware oled and it’s awesome, my only complaint is I wish it was a bit brighter. Dark games there’s no better monitor. Most games are maxing out the monitor with a 4090. Or I get 60 percent gpu usage. When or if they make a 3840x1600 oled I will be buying that as that was the perfect size and resolution for me",
      "Being confident doesn’t make you correct",
      ">The RTX 4080 is extremely overpriced, it should have been $900 at the absolute most. Not because of its quality, mainly because of how much of a hike it is after the $700 3080.\n\nEh... I was telling people back in 2021 that crypto would crash in 2022, and that Nvidia would release a $1200 RTX 4080 while trying its best to restrict GPU supply in order to keep prices high.\n\nSo I don't even view the 4080 as overpriced. It was always going to be $1200 and significantly worse than the 4090. I just figured they'd try to charge $2000 for the 4090... though to be fair, the 4090 is only an 89% bin, so there's still room for a $2k+ card.",
      "Officially no, but probably yes. Though once again, it's a case of being better-safe-than-sorry.  \n\nAnd the 40 series cards are massive, so may even have to change out the case. While it's apart you may aswell upgrade PSU, future proof etc.",
      "Most 4080 recommend 850w psu atleast. So no, 750 isn't enough if you actually plan to put the card through some gaming. Always better safe than sorry when dealing with expensive tech.  I understand the manufacturers are playing it safe to cover their asses so they inflate the wattage recommendation a bit, but it powers every part in your computer, not just GPU. Everyone's build is different, they can't accurately guess each person's PC needs, so they giver a healthy minmum no. just in case \n\nAnd have to make sure your psu has 3 pcie ports, as the 40 series adapter needs 3 separate connections to the psu . It won't be sufficient using one of the two-headed cables for 2 of the adapter plugs \n\n4080 will crush any game at 1440p even at ultra settings & with Ray tracing on. And if it comes down to it, frame-generation can save the day :)  Only some outlier games that aren't optimised yet may give you issues. \n\nPrices are crap here in Australia, mainly thanks to shitty GST. But retail prices in US seem much more reasonable and definitely worth the price.   \n\nWhen you really think about it, spending US$1000 on just 1 piece of your build is insanity.  But that's just how the market is these days :(    \n\nThe 4080 is more than enough. Just like the 4090, the 4080ti will be overkill for most people.  And the Ti  variants of the 80 and 90 GPU always have insane prices, so they might not be affordable till next Christmas atleast.  I wouldn't be able to wait that long. I'd snap up a good deal on my favourite 4080 and forget about upgrading for a couple yrs."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "4080",
      "rtx4080"
    ],
    "title": "Which RTX4080 to buy?",
    "selftext": "Hello everyone,  recently I decided to go with a new GPU because my rx5700xt is getting old :( I don't want to buy a cheap card that will barely reach 60fps at 1440p. \n\nI thought about RTX 4080 but now is the question, WHICH ONE? :D There is a few of them on the market and the cheapest one actually is from ASUS TUF. I don't want to spend that much money and find out later that I could spend 100$ more and get better card overall. \n\nI am asking you for help, I am sure you know much more than I do. Is it really big difference between those cards? \n\nMy current setup:\n\nGPU - RX5700XT  \nCPU - Ryzen 5800x3D  \nRAM - 16GB 3200MHz\n\nP.S I don't need RGB or awesome looking card. I am not that kind of guy. I just need a solid GPU for some time. \n\nThank you guys!",
    "comments": [
      "The difference between different AIBs in terms of performance is almost nonexistent. A 4080 is a 4080 and there's very little variance (maybe +5% at the absolute most, usually closer to 3-4%) on more expensive OC models, which you could achieve by yourself with 5 minutes of minor effort, if you felt the need to. The coolers on the 4080 models are the same as the ones they're putting on 4090s and are massively overbuilt, so they all have fantastic cooling performance.",
      "PNY 4080 is $1230",
      "Honestly, with the 4080, most of the AIB models have very comparable performance and cooling. In my opinion it's not worth spending a lot more for a specific AIB model because that money could go towards upgrading to a 4090 which would have massively better performance. So I would probably look for one close to the $1200 MSRP.\n\nWhat's most important when deciding is looks and price. In other words, I would not spend $100 more for 5% better cooling. Just find one that looks best to you, at the price you want, and go for that. If you're in-between a few models for the same or similar prices, let me know and I'll tell you which have better cooling.",
      "You seem like you know what you are typing, thank you for your comment on that. So there is no significant diffrerences between those AIBs. I would probably go with Asus TUF version.",
      "https://preview.redd.it/hda6amqspbda1.jpeg?width=1080&format=pjpg&auto=webp&s=9d5de2454b137427cb4006ea47b34daf20d09fb4\n\nPNY 4080 has been good to me, 4080 FE is good and small, but you cant turn off the LEDs and that irked me a lot. And the PNY goes for $1199 too.",
      "I’m biased, but 4080FE. Since you can’t get it where you are, just get whichever is cheapest. They’re all basically the same",
      "You buy used 3090 or 4070ti to not get too much cpu bottleneck",
      "Where I  currently live there is no way to buy a brand new FE :( not from a official stores.",
      "Wow that's massive ! :D Your setup looks great!",
      "Thank you sir for your comment! I really appreciate it",
      "its massive compared to previous gen cards lol this gen its on the smaller side 😅 \n\nand thanks a lot i tried to make a clean setup for my PC with a red theme",
      "The only 4080 to get is the Founders Edition.",
      "I really appreciate it, thank you. I'm thinking about those models:  \n1.  Zotac GeForce RTX 4080 Gaming Trinity OC 16GB GDDR6X  \n2. ASUS GeForce RTX 4080 TUF Gaming OC 16GB GDDR6X  \n3. Gigabyte RTX 4080 Aero OC 16GB GDDR6X  \n\n\nI don't know if I should take RX6800XT or RX7900XT under consideration? What do you think? I am mostly 2K player but probably in the future I would like to play some 4K games",
      "I would definitely avoid the Zotac trinity. That's a lower end model compared to the others. The Gigabyte Aero has the best cooling and performance out of those three. The TUF is pretty close and has better build quality (all metal build), but has a smaller heatsink so temps/fan noise will be a bit higher.\n\nThe 6800XT and 7900XT's are in a different range of performance, so may be good options if you don't want to spend the money on a 4080 or don't really need the performance. But actually the 4070 Ti would be a better option than the 7900XT in most cases if you are looking for lower cost/performance.",
      "Awesome! Thank you so much sir.  I really appreciate your help!"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "4080",
      "rtx4080"
    ],
    "title": "ASUS TUF 4080 OC Available - Asus Website",
    "selftext": "Still available.  \n\n\n[https://www.asus.com/us/motherboards-components/graphics-cards/tuf-gaming/tuf-rtx4080-o16g-gaming/](https://www.asus.com/us/motherboards-components/graphics-cards/tuf-gaming/tuf-rtx4080-o16g-gaming/)  \n\n\nGood luck!",
    "comments": [
      "No one but idiot scalpers should be wasting money on these cards.",
      "It’s been a day and a half since release lol and they’re sitting on shelves at Microcenters everywhere",
      "Good luck indeed.\n\nGood luck to the scalpers to break even buying them up now and all the first adopters who pay a premium like all the 3090 ti owners before the 4090 dropped.",
      "Cards at msrp were in stock on newegg U.S. last night, microcenters well stocked still, still in-stock through your link.\n\nFirst xx80 release Ive seen in well over a decade that every single card didnt sell out in moments on release.\n\nPrice being WAY too high by about $400-$500 is the reason. Nvidia way overvalued these cards.",
      "There's some in every micro center.\n\nScalpers are selling them at a loss right now. I see them selling it for MSRP with no tax lol.\n\nThese are not going to be hard to get.",
      "Pretty much all models that launched are still in stock in the Netherlands, but considering they are 1800-2000 Euro (same amount in USD) that's no surprise.",
      "That makes no sense to sell at a loss. Scalper still could return the video card. Something else is going on. More likely a scam to rob people.",
      "no",
      ">That makes no sense to sell at a loss.\n\nDriving back to return it or being hit with a restocking fee (15% usually) or no returns can be the reason.",
      "lol ouch",
      "Found few idiots who bought it here on reddit, but well, its a fucked up release for Nvidia, they got the middle finger 🖕",
      "Please",
      "Same in Germany when I checked yesterday. The price is just stupid, no wonder they don't sell.",
      "They can go to MC and tell it doesn't work. I don't think Microcenter can legally decline even if they know it's bullshit.\n\nTheir only loss is the 4 way drive back and forth."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "4080",
      "rtx4080"
    ],
    "title": "Palit Gamerock RTX 4080 or Galax RTX 4080?",
    "selftext": "I am considering buying a RTX 4080 card from one of these brands. Price here in Japan is around the same (1400-1500 USD). \n\nHowever the only problem I have with Palit is that they only offer a 1 year guarantee, while Galax (Galakuro Gaming here in Japan) offers 3 years.\n\nWhich of these 2 cards is considered the better choice? And do you think there is a considerable risk of the cards to have a problem between the first and the third year?\n\nAlternatively MSI Gaming X RTX4080 is also currently available at a similar price, but also with only 1 year warranty.",
    "comments": [
      "Galax, has better PCB and more power phases",
      "Sure, but have you considered [this](https://news.mynavi.jp/article/20221115-2513668/ogp_images/ogp.jpg)? \n\nAs much as I'll shill for the gamerock, get the galax, 3 years is a no brainer.",
      "I have the Gamerock 4080 (was the only card I could get for less than the 4080 fe price close to launch in the UK). I'm very happy with it - super quiet and temperatures are fine (max 70C at 100% load, usually 65C). Of course only time will tell how long it lasts, but the card seems rock solid so far.",
      "I planning on buying this card. How is yours holding up?",
      "May I ask your thoughts about the OC model? Would it be worth it today? In Japan the Gamerock is the cheapest 4080 option, and OC adds 4000 jpy.",
      "Still going strong, definitely recommend it 👌",
      "I wouldn't pay extra for the OC model. I have my non-OC card overclocked by about 7% I think and it works perfectly. The max power is locked on the non-OC but that doesn't prevent increasing the clock speed.",
      "Thank you, much appreciated feedback. I didn't know about the power lock, but I'm not a great fan of overclocking. Cheers.",
      "My comment was, in addition to warranty, you get what i said. Anyway, Galax also looks neat, but he wants the look of it and throws away all the goodies he gets from galax, thats his thing in the end."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "4080",
      "rtx4080"
    ],
    "title": "Upgrading to RTX 4080 from RTX 3090.",
    "selftext": "Hey folks. Just ordered a Palit Gamerock RTX4080 OC. Just wondering if I should be worried about the adapter that comes with it? Is burning still a thing?\n\nAlso do I need a fresh install of windows 11? \n\nThank you.",
    "comments": [
      "Burning was never a thing.  Not connecting the adapters properly was.",
      "FYI: Was totally worth it... if you have the cash of course.\n\n&#x200B;\n\n100% an upgrade especially in DLSS3.0 games. Not to mention quiter and runs colder.",
      "Yes, burning is still a thing if you don't follow instructions properly. No need for reinstall",
      "Nope just make sure the cable is correctly seated in the gpu.",
      "Cable is a non issue if you have any common sense. I plugged the adapter in before I installed the card, then pcie cables after. Easier to be sure of a positive connection this way."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "4080",
      "rtx4080"
    ],
    "title": "Rtx 4080 OC values?",
    "selftext": "Hey.. i upgradet to a ZOTAC 4080 Trinity and its a great Card so far..\nBut i Like to know what are good OC Values on a RTX4080\nI can get easy +270 core (3045mhz @1.075V) and +1600mhz Memory without even hit the powerlimit\n\nI also Tried to undervolt and 2914mhz @1.000V seems stable after a few hours of gaming\n\nWhat are your OC values?",
    "comments": [
      "Is your core minimum voltage 935 mV? I think 40 series owners should all try minimum voltage undervolt. See how it performs.",
      "Gigabyte aero OC 3 GHz and 1500 mem .",
      "I flashed my msi 4080 Ventus to a Msi 4080 suprim and it’s a lot faster, then I overclocked it a little more. I think all boards are the same so you can try another ZOTAC bios for better clocks and power limits",
      "Firestrike/ TimeSpy scores?",
      "The ZOTAC AMP BIOS goes Up to 450w",
      "Not testet yet.. what are good Scores?",
      "I read another user doing “2820@0.975v, the 3dmark scrore boosted 2.5% but GPU stays within\n280w” on a 4080 Ventus OC. From what I’ve seen online (YouTube mainly. So grain of salt.) the memory overclock is the only thing worthwhile OCing. OCing the core makes it a bit unstable and your increased ~1% avg comes at a cost of significant power, extra heat and decreased/unstable 1% lows.\n\nThis is just my research, I will have a 4080 Ventus OC (cheapest I’ve seen at ~$1180) on Friday that I plan to toy around with then maybe return to Amazon if 4090 FE comes available at BB."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "4080",
      "rtx4080"
    ],
    "title": "Whats the best manufacturer of RTX4080?",
    "selftext": "Hi, just got  Zotac GeForce RTX 4080 Gaming Trinity OC, but am wondering are there any better 4080s out there in this price range? Maybe Gainward?\n\n#",
    "comments": [
      "FE",
      "A couple different reviewers highlight the performance, temp, etc. differences between the different manufacturers and they're all basically between 1-3% across the board so choose whatever's cheapest, has the best warranty, or is your own personal preference \n\nhttps://www.youtube.com/watch?v=47bBjVFp9t8",
      "They're all basically the same. I'd go with one with a good local presence for RMA purposes down the line",
      "On the 4000 series GPUs, \"Best\" is relative. For performance/thermals for day to day use, they are all essentially similar with small changes that are negligible. \n\nMajority of the difference comes down to mostly power design which for day to day use is not relevant and it's literally all over the place. I've seen 13, 14, 16, 18 and 24 phase 4080 cards and at base, they all really perform the same and no point in getting one over the other just for phases unless you're trying to set some 4080 OC records etc.\n\nIt really comes down to availability, pricing and the support that's offered in your location, that's a bigger deciding factor than which brand to get.\n\nFor example, Zotac/Gainward/Inno3d/Colorful do not have a big presence in the US compared to say Asus, Gigabyte, MSI, PNY etc, but in a lot of countries it's the other way around so it really all depends on what type of service they can offer where you are.",
      "Watch Buildzoid’s videos… learn from them…\n\nGenerally speaking (based on what I’ve gleaned from his videos)… FE models appear to provide the best overall option so far based on board design/components and power delivery…\n\nStay away from the Palit card(s).\n\nBased on overall performance testing between the various models… they all perform within the FE models by about 1-3%… yielding only a few average FPS.\n\nFE is cheapest of the models if you can get them.  Otherwise choose best available option based on price …",
      "MSI SUPRIM X if you want the coolest and most quiet air cooled RTX 4080",
      "Nvidia"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "4080",
      "rtx4080"
    ],
    "title": "RTX4080 undervolting question",
    "selftext": "So I just lucked into managing to get a 4080 FE just now from Best Buy. I have a question I'm hoping can be answered.\n\nI currently have the 3080 FE (that I now plan to sell), and I undervolt it via Afterburner. Is the 4080 as \"undervolt-able\" as the 3080 is? If it can be, is there any place ppl know of that I can find recommended starter settings?",
    "comments": [
      "Why so bitter? It took me a year to get a 3080, so I consider this lucky. Also, this comment has nothing to do with my question.",
      "All desktop cards are clocked and volted well past the point of diminishing returns. So they're all undervoltable even if they don't have a lot of OC headroom. Just from a clock cap. Or you can lower the power limit instead.\n\nThe OC Scanner can give you a good starting curve. You can cap it or use with a lower power limit.",
      "You'll find in most cases the 4080 FE uses less power than an undervolted 3080 FE. I haven't even bothered to undervolt my 4080 FE.",
      ">4080 as \"undervolt-able\"\n\nIf it's like the 4090 it should be. I wrote a topic on undervolting the 4090.\n https://www.reddit.com/r/nvidia/comments/ybxa3c/there_are_two_methods_people_follow_when/\n\nI see no reason the 4080 can't be UV.\n\nBut just a heads up, it won't take a year or any time for anyone to get a 4080. There's a bunch at Newegg.\n\nhttps://www.reddit.com/r/nvidia/comments/zr9j0q/what_is_up_with_the_notion_that_the_4080_isnt/j13730w/",
      "Is buying a poorly valued card lucky?"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "4080",
      "rtx4080"
    ],
    "title": "rtx4080 minimum vcore voltage and undervolt",
    "selftext": " \n\nDoes the new rtx4080 has the minimum vcore voltage capped at 930mv\\~935mv? it shows at the curve editor that the vcore voltage won't go below 935mv despite I've flatten the curve at 920mv.\n\nhttps://preview.redd.it/sn0wmpr92iha1.png?width=1904&format=png&auto=webp&s=f2a689055efb1eaee116ae303d5ff17553a80947\n\nmodel: pny 4080 verto edition",
    "comments": []
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "4080",
      "rtx4080"
    ],
    "title": "Question: Radeon RX 6900 XT or RTX3080 or wait for RTX4080?",
    "selftext": "Hi everybody.\n\nI`m struggling to choice to which graphic card should buy.\nI been waiting very long time, because the huge GPU prices and finally the 6900XT and 3080 are in a good price.\nHave some concern about driver issues in AMD site, my 5700xt give me enough headache.\n\n1. option:\nFound a POWERCOLOR Radeon RX 6900 XT 16 GB Red Devil Graphics Card new for £749 which is a really good price + i got from my workplace a £150 worth of gift card.\nSo i could buy it for £599.\n\n2. option:\nAsus GeForce RTX 3080 ROG Strix Gaming OC V2 LHR 10GB GDDR6X PCI-Express Graphics Card for £870, but i cant use my gift card for this, because its a different store.\n\n3. option:\nWait for RTX 4080 (12GB) which have a starting price at £949 in NVIDIA website.\n\nWhat for:\n- play in 4k\n- stream sometime\n- video editing\n\nWhat for not:\n- OC (very low skill)\n- blender etc.\n\nMy computer spec:\n- CPU - AMD Ryzen 9 3900X Twelve Core 4.6GHz\n- VGA - MSI Radeon RX 5700 XT Gaming X 8GB GDDR6\n- RAM - Corsair Vengeance LPX Black 32GB (4x8GB) 3200 MHz\n- M.2 SSD - Samsung 970 EVO Plus 1TB M.2 2280\n- 2.5 SSD - Seagate 2TB 2.5\" Barracuda 120 SATA Solid State Drive\n- Motherboard - Asus ROG Strix X570-E Gaming\n- ASUS ROG STRIX 850W 80 Plus Gold Modular Power Supply\n\nThank you for everybody who help me.",
    "comments": [
      "I have a 6900XT and a 3080. Given your options i would go with the 6900XT (cheaper w/gift card). £599 is a good cost, i paid £664 for mine a month ago. I currently have it running on SteamOS 3  and it plays beautifully. Didnt even have to install drivers at all because they are in the Linux kernel already.",
      "Same situation for me. I have a 3060 but am looking to upgrade for the longest to 6900xt now am having second thoughts if I should get the 6900xt or 3080"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "4080"
    ],
    "title": "BEWARE BUYING USED - 4080 Super missing Core & Memory",
    "selftext": "Was looking for a 4080 on Facebook and found what appeared to be a decent deal. He even sent me some videos of it working but in hindsight it probably was a different 4080. \n\nWhen I got home, I plugged it up and no post. I contacted him and no response. \n\nI am so upset I don't even know what to do right now.. ",
    "comments": [
      "The seller most likely will make another post looking to sell another one to scam someone else.\n\nJust make a new facebook account or ask a friend or family if they have one to make it look more legit and tell the seller you'll meet up with them to buy the fake card then you can deal with him.",
      "Well wasn't expecting wet work advice in r/nvidia...",
      "Damn another one bites the dust. I have seen this popping up everywhere. Sorry it happened to you man.",
      "r/UnethicalLifeProTips",
      "Damn, who we peeing on?",
      "I’m not sure, I only buy electronics with PayPal services backing me up or through normal vendors.",
      "Are they selling the chip to china or what’s the point? \n\nThese scammers even took the VRAM out??",
      "Yes they are selling it to China, the VRAMs are not that cheap either.",
      "Is there anything I can do?? Will the police even care?",
      "it is fraud, they showed you working product and its not working as described, police can care about it (use non emergency number of-course), if it was paid via bank, charge back for fraud, if it was pay pal normal payment make a claim, paypal family pay is sol. If you went to their house to pick it up, just return it and demand the money back. Nothing is stopping you from going back to the place of pickup, unless you went to mailbox to pick it up or something. If you paid cold cash then best you can do is get law enforcement involved. If you didnt already save all messages and videos etc of the sale and item \"working\".",
      "You should report it since its I think a felony assuming you paid over a certain amount. Guessing it was   a cash transaction so unlikely your getting your $ back. \n\nWhat the hell are they doing with the unsoldered chips ? \n\nWhile it doesn't help you, to others either use a secured form of payment like PayPal/credit cards so you can dispute the changes and/or bring a rig with you to validate that the card is what the seller claims it is.",
      "> What the hell are they doing with the unsoldered chips ? \n\n[Probably shipping them to China, to be soldered onto beefier boards that can push the chips to the limit, for use in AI compute farms.](https://www.techpowerup.com/316066/special-chinese-factories-are-dismantling-nvidia-geforce-rtx-4090-graphics-cards-and-turning-them-into-ai-friendly-gpu-shape)",
      "lol Even the app knows",
      "The GPU market is in so much shambles that these scams are happening EVERYWHERE, just the other day I saw a decent deal on a 4090 on marketplace and this is how my interaction went:\n\nThe person was trying to get me to pay before meetup\\*\n\n(I obviously refused)\n\nhttps://preview.redd.it/lz7mvi54xlie1.jpeg?width=1080&format=pjpg&auto=webp&s=fe53a4ee070e7e9407ed544973f7949e24ddbb7f",
      "Scammers dont do real meeting i think",
      "Dumb ones might",
      "Man, I love Horrible Bosses",
      "This is why never buy used online. I need to be able to test it in person at a police station.",
      "Fakest profile pic ever.",
      "Bring a cop."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "4080"
    ],
    "title": "Gigabyte Came Through BIG TIME – 3080 Ti RMA Turns into a 4080 Super!",
    "selftext": "I just wanted to give a huge shoutout to Gigabyte for their amazing warranty service and customer support. My 3080 Ti Vision died recently, and I was honestly dreading the RMA process. You always hear horror stories about long wait times, getting the runaround, or receiving a questionable refurb as a replacement.\n\nBut Gigabyte absolutely delivered. Not only was the RMA process smooth and relatively quick, but instead of just replacing my 3080 Ti, they upgraded me to a 4080 Super Aero! I was blown away—talk about standing behind your products and taking care of customers.\n\nIt’s rare to see companies go above and beyond like this, so I just wanted to give them the credit they deserve. If anyone is on the fence about Gigabyte, their warranty support is top-tier, and I can personally vouch for it.\n\nThanks again, Gigabyte! You’ve earned a loyal customer.",
    "comments": [
      "That's fucking sick! Grats on the upgrade. Probably the best money you've ever spent on a GPU.",
      "I did buy my 3080Ti for $1700 at Best Buy during covid, so this upgrade makes that price more worth it now!",
      "Now that’s how you do a turnaround in support, asus should take notes.",
      "Covid prices were nuts! I had to get a GPU for work, but I would have never paid $1700 for a 3080Ti for just video games.",
      "https://preview.redd.it/6k1v8sgbuwie1.jpeg?width=1290&format=pjpg&auto=webp&s=695315ec511eaeb78cff8316969ab6126ed51974\n\n🔥",
      "https://preview.redd.it/20vvuynqswie1.jpeg?width=828&format=pjpg&auto=webp&s=96f0835f87dec2f12510a215f8ac798824414f12",
      "I had a 3080 Ti Vision that I RMA'd 3x. Each time, it died due to the same reason. The final RMA, they upgraded me to a 3090 Eagle which absolutely killed my aesthetic in my build (since it's all white). I sold the 3090 Eagle for a good chunk of change and I bought an 4080 Aero at release.\n\nIronically enough, the 3090 Eagle died on the new owner about two months in. Fortunately, I was able to help them get that RMA'd.\n\nEDIT: I just thought that I should add that I echo your statement/sentiment regarding their warranty process and policy. They never gave me a hard time through all of the issues and held up their end of the bargain.",
      "Gigabyte is legit with their warranty. I had a Windforce v1 4090 fail and they sent me a brand new Windforce v2 4090.",
      "Solid warranty but damn that is a scary high failure rate.",
      "Meanwhile at gigabyte hq;\nWHO DID THIS GUYS RMA YOURE FIRED",
      "How many shares of Gigabyte stock did you buy before posting this?",
      "![gif](giphy|3o7TKMxBuO913uWyoU)",
      "Perhaps you are new here but, COVID pricing was combined with Crypto pricing... a 3080 Ti was insanely marked up. I think it capped around $2000",
      "We’re not all Reddit experts, I just clicked reply on the wrong comment and didn’t feel like rewriting or copy pasting. I assume most people would figure out the context when reading it all. It is pretty funny people think I might be a Gigabyte employee. \n\nWe should call out companies when they do things right and not just when they do things wrong, just like the same applies to people. So much negativity today! Stay positive people!",
      "so they replaced a broken windforce 4090 with a working windforce 4090, thats kinda the bare minimum for warranty.",
      "I paid 800 CAD for a 6600.. still hurts",
      "What? OP was just giving more context why they paid that much",
      "Least obv gigabyte propaganda",
      "Back when my 3090 Gaming OC died it was repaired and just died again soon after. Fortunately I‘m in the EU and got my money back after it’s second death instead of another refurbished card like they did at that time.",
      "Yeah, I was nervous after RMA #1 that they were going to pull some crap and screw me over but thankfully they didn't. They kept sending me these BS refurb units that would literally die after like 2-3 months. It was wild.\n\nHistorically, I had always gone with ASUS boards and GPU's but now they've got a customer in me for life."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "4080"
    ],
    "title": "Which used GPU do I choose",
    "selftext": "I'm building an extra system for my living room TV and am unsure which of the following used choices is the best value: a gtx1080 for $85, an rtx 2060s for $120 or an rtx 2070s for $140. My main system is a high end 4080 system where I play most of my games, but I'm debating what the best option would be for playing games casually on the TV. The rtx cards have dlss which may improve their image quality on my 4k TV but is it worth the premium over the 1080 for similar performance?",
    "comments": [
      "Install Steam link on TV and stream games from your PC with RTX4080.",
      "I'll definitely try it out though my network isn't the greatest and I do have a ryzen 7700 system already sitting there connected to the TV. My 4080 system is wired to the router but it's not possible for me to run it downstairs. Still, it may be worth the tradeoff to be able to use the 4080. I built it so everyone in my house could use it and my 4080 system is my personal computer so I want it to be somewhat capable by itself for casual games.",
      "I'd install steam link on 7700 rig (not TV), iGPU will be enough. There is built-in latency check, from my experience if you will manage latency below 30ms it is fine for casual gaming. Your TV is 4K, it shouldn't have big input lag too. This is the best option for you without spending any money at all. WiFi6 router will be cheaper too in this case if latency would be an issue.",
      "2070s",
      "Why stream which incurs input lag penalty? Just connect the display port / hdmi cable from the tv to the pc as a monitor."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "4080"
    ],
    "title": "Unlaunching The 12GB 4080",
    "selftext": "",
    "comments": [
      "Now watch them rename it 4070 and retain the 900$ price tag.",
      "Aahahahahaaa, I thought this was the onion.",
      "What we think happened:\n\nNvidia was ashamed at the feedback from Reddit and Youtubers.\n\n&#x200B;\n\nWhat probably happened:\n\nNvidia spies at AMD telling them the new 7000 would ridicule the 4080 12GB",
      "\"No need to thank us.\"",
      "Wow. I had to do a double take cause I did not believe it. A little cringe with the pics though.",
      "EVGA should be very happy about their choice to leave the clown fiesta\n\njust look at 4080 AIB sizes, it's the same as stupid 4090 next gen consoles lmao",
      "now they admit it lmao",
      "So what are the AIBs suppose to do now with all their cards with 4080 labels on them and boxes and such?",
      "Watch the first batch of cards on the streets: 40~~8~~70",
      ">So what are the AIBs suppose to do now\n\nTake their already razor thin margins and shove them right up their ass. They'll have to put a sticker on the box (or rebox), replace the serial sticker on the card, potentially cover up or completely replace any branding on the heatsink, replace the manual, and flash a new vBIOS with the correct name. All that is going to cost money, probably enough to put them in the red on already manufactured stock, and Nvidia will tell them to get fucked about it.\n\nRemember when EVGA cited disrepect as their reason for bailing? You're seeing it in real time. Nvidia does not give a flying fuck about their partners.",
      "I checked both the domain 3 times and the certificate twice. I thought I was on onion as well",
      "bruh moment\n\nNow sell the 4080 16GB for $900",
      "And also meaningless if they relaunch it as a 4070 with the same price. There would be a lot fewer complaints if the price and price/performance were good and just the name didn't fit the card.",
      "that was clear that amd has at least 4080 16gb competitor . they will beat this 12gb one with easy.",
      "While I am glad that Nvidia actually cancelled this ridiculous naming scheme it is just another move that screwed the AIB partners in general.\n\nLet's remember that they [never planned a FE edition](https://www.kitguru.net/components/graphic-cards/dominic-moass/rtx-4080-12gb-to-be-aib-only-no-founders-edition-model/) for this card so for them to just \"unlaunch\" costs them practically nothing while giving their AIB partners the burden for this move.",
      "Seriously never expected Nvidia to backtrack on it.\n\nReception of 4090 is so good that they decided to improve their PR.",
      "Or hear me out. Go back to 500$ for the 80 series like 1080 >.>\n\nThis mentality shows how Nvidia normalized insane pricing with their 2000/3000 series. \n\nThere is such a large gap between the 4080 and 4090 they are clearly setting up a strong 4080ti. Which means with their current pricing the ti will be significantly faster for not much more. And if the price did go down to 900$, you’re still dealing with a 1200$ potential ti. \n\nThe margins for these cards are higher than any 80s series before even if Nvidia pretends otherwise. (Excluding the crypto boom)",
      "The 4090 is genuinely an amazing card. And while the other cards are significantly slower, they would also have been great had they been priced accordingly. But they weren't. They are ridiculously overpriced. As a result only the 4090 looks like a \"good deal\" (relatively speaking). The 4080 16GB is still terrible value and you should never buy it. NVIDIA once again shooting themselves in the foot by ruining an otherwise great generation with idiotic pricing and tiering of their cards. If the 4080 16GB is way slower than the 4090 then that should be reflected in the price. They can take that $1200 MSRP and shove it.",
      "Now imagine AiBs at this stage, both 4080s are already at end stages of mass manufacturing pipeline or waiting boxed in some warehouse...",
      "They didn't admit shit - they were caught red handed trying to scam their user base and now they're trying to save face. \n\nIn fact, I bet they'll rebrand it a 4070 (which is exactly what it was in the first place) but still sell it for over $800 - that's about as far as you can get from admitting something was wrong."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "4080"
    ],
    "title": "GeForce 256 25th Anniversary Celebration: Enter for a chance to win a retro RTX 4080 SUPER PC!",
    "selftext": "On October 11, 1999 the GeForce 256 launched 25 years ago today!\n\nThe GeForce 256 wasn’t just another graphics card — it was introduced as the world’s first GPU, setting the stage for future advancements in gaming, creating,  computing, and generative AI.\n\n[https://www.youtube.com/watch?v=eVNvSaNFRfA](https://www.youtube.com/watch?v=eVNvSaNFRfA)\n\nWe’re celebrating the GeForce 256 all day long and as part of the celebration we’re giving away three sleeper rigs that feature the NVIDIA GeForce RTX 4080 SUPER, inspired by the golden era of PC gaming. \n\nTo enter for a chance to win one of three PCs, you can follow the specific GeForce 256 prompts on our social channels \\[[X](https://x.com/NVIDIAGeForce?ref_src=twsrc%5Egoogle%7Ctwcamp%5Eserp%7Ctwgr%5Eauthor), [Instagram](https://www.instagram.com/nvidiageforce/?hl=en), [TikTok](https://www.tiktok.com/@nvidiageforce?lang=en)\\] , or comment below an answer to the following question:\n\n***What was your favorite PC game of that era?***\n\n[Terms and conditions](https://www.nvidia.com/en-us/geforce/contests/geforce-anniversary-sleeper-build-sweepstakes-official-rules/) apply. Edit: The entry period for this will end October 18, 5PM PT. \n\n[**@peachietech**](https://www.tiktok.com/@peachietech?lang=en)**'s classic HP Pavilion rig**\n\nPowered by a GeForce RTX 4080 SUPER, this mini sleeper build based on a childhood favorite is ready for all PC games - no floppy disks needed.\n\nhttps://preview.redd.it/aojobpnmw4ud1.png?width=2048&format=png&auto=webp&s=ff9bd3811290636d59cd87b16d4aa78021502cc7\n\n[**@PCJunkieMods**](https://www.instagram.com/pcjunkiemods/?hl=en)**' eMachines rig**\n\nComplete with a \"NEVER OBSOLETE\" sticker, this PC rocks a mighty GeForce RTX 4080 SUPER for your favorite games new & old - dial-up internet not required. \n\nhttps://preview.redd.it/w0w56t8qw4ud1.png?width=2048&format=png&auto=webp&s=d42a2e1e5ad50ad3cc61040d73bd774a56ce677c\n\n[**@PCJunkieMods**](https://www.instagram.com/pcjunkiemods/?hl=en)**' classic Gateway rig**\n\nWith a GeForce RTX 4080 SUPER at the center of this classic tower design, you'll dominate the competition - just don't forget your trackball mouse.\n\nhttps://preview.redd.it/81o2d9zsw4ud1.png?width=2048&format=png&auto=webp&s=ab0aa4e61c03a7a5ffd9f3e72edf79a5f50b0fcc\n\nTo read more about the impact of the GeForce 256 [check out our blog!](https://blogs.nvidia.com/blog/first-gpu-gaming-ai/)",
    "comments": [
      "Unreal Tournament 99, and specifically DM-Morpheus was the game that convinced me to upgrade.",
      "I need an rtx gpu so that i can finally use topaz video ai bruh",
      "Half Life",
      "oh man, back when you didn't have a wide selection of PC games to choose from so you stuck with just a couple, playing them to death. The games I bounced back and fourth on were most likely:  \nHeroes of Might and Magic III, Starcraft, and Quake (as well as all its various mods you could find online.)",
      "Command & Conquer Generals was always my go-to game.  I spent so many hours in custom matches alone.  Lasers take a LOT of power!",
      "Max Payne",
      "I was a big Descent fan, so I was sinking tons of hours into Descent 3 and FreeSpace 2 in 1999.",
      "Command and conquer red alert!  Beating all my friends and they accused me of cheating -_-",
      "definitely Age of Empires 2",
      "In 1999? The free one that came with the cornflake boxes I LOVEDDDD Those",
      "Diablo 2: Lord of Destruction",
      "Tie between Quake 3 and Starcraft. I saved up all summer to get my half of a personal laptop so I could game without having to share with my siblings",
      "I have MSI 4090 Waterforce X",
      "CS 1.6and now CS2. Also, I got a video made on my gameplay on Youtube. Thanks for gaming pc",
      "Halflife!!",
      "Unreal Tournament",
      "Loved playing counter strike!!",
      "Unreal Tournament!",
      "Dude, junior year of high school playing the original unreal tournament with my older brothers in their office after work.   Some of my favorite memories of my lifetime.",
      "I would have to say half life"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "4080"
    ],
    "title": "Alleged GeForce RTX 5080 3DMark leak: 15% faster than RTX 4080 SUPER - VideoCardz.com",
    "selftext": "",
    "comments": [
      "So it's worth upgrading from the 3080, but not from the 4080. Same as always.",
      "Coming from a 3080 10GB, this sounds good enough for me. I do not understand those who don’t hold on to their cards for longer than one generation…",
      "Yeah. I've always done every other generation. Unless money is no object and you enjoy always having the latest tech.",
      "Probably going to upgrade from an ancient 1080 Ti",
      "I do every generation since graphics cards hold their value so well I just sell my old one",
      "It's funny when people complain about low uplift from 40 to 50 series so suddenly the card isn't worth it \n\nAs if the only people upgrading are those on the 40 series",
      "10-15%",
      "The 1080 Ti and 4090, both cards people who bought them Day 1 got insane value with.",
      "How much slower than the 4090 does that make it?",
      "All you need to know is the 5090 is NOT 2x performance over the 5080. \n\nBut the 5090 is 2x the price. \n\nSo, 5080 is better value.",
      "For Rtx 3080 users with the 10 GB model, its a bit more than 50% more vram! So this is a nice upgrade in a pinch!",
      "Iono though I'm pretty sure people were initially laughing at Nvidia asking who the hell would spend 1600$ on a GPU back when 4090 came out. In retrospect 4090 seems like a great value because we have re-normalized our expectations of what GPUs should cost",
      "Still not twice the performance and at least for me only 50% more Vram. I want twice the performance minimum and twice the Vram.",
      "100%. the one generation uplift is almost never worth is anyway. I am sitting on a 2070 super and i cant wait to get a 5080",
      "Value is a relative term, it's not carved in stone, just FYI",
      "Yeah but you can also OC a 4090, so its pointless talking about overclocking. Just compare stock vs stock performance. There is no guarantee your card will even be able to OC, when the 2080 Ti's came out I went through 3 cards , the first two were fucked and had to be returned and the third was stable but could only OC 30 mhz, that was it. That was all she had in her. Same case with one of the first two.\n\nYou cant go into buying a card expecting a certain level of OC performance. In my opinion the 5080 will be a very solid gaming card but the 4090 will reign supreme as the 2nd best card for the foreseeable future. Being stronger and having 8GB more of VRAM is just too good. Some folks need that VRAM for AI model/productivity work or games with large texture sizes/mods. If the 5090 supply is as restricted as they say, we may very well see 4090 values rise to $2000 on eBay. they are already at $1850.",
      "The elusive 4080 SUPER DUPER",
      "Im interested to see what will be the best price for the performance upgrade from my trusty 3080",
      "Agreed. I wondered why this comment was faring so well before I realized we are in nvidia not pcmasterrace.\n\nHad you dropped this in there, you would have been littered with responses:\n\n”1070 still going strong! Plays everything I throw at it” \n\n”1060 gang represent!!”",
      "If it's 10-15% slower than the 4090 and the 5090 is 30% faster than a 4090, doesn't that mean this is effectively something around 55% the speed of a 5090?\n\nI remember seeing the downvote brigade here disagree with the idea that 5080 is roughly half the power of a 5090. If the leak is true it doesn't seem far off... given half the cores, half the bandwidth, half of...everything more or less.\n\nNote: i'm extrapolating for gaming performance, not time spy performance. Time spy shows different numbers than typical gaming fps outcomes. Note that 3dmark puts the 7900xtx ahead of the 4080 super but in the real world it is usually behind even the 4080FE in gaming."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "4080"
    ],
    "title": "Finally replaced my 1070 with a 4080 Super",
    "selftext": "Decides to upgrade after my 1070 served me well for 8 years. My all black look is also now complete, as my 1070 had red accents in it. Ive also added a bracket to support this beast of a card. So far I’m very pleased with it’s performance.",
    "comments": [
      "![gif](giphy|xUPJPtw7LRAmTZ60rS|downsized)",
      "If I were replacing my card with a newer model, I'd sure clean the fracking thing before posting all the muck for the world to see\n\n![gif](giphy|lPNqO3u4p1gewVI4VJ)",
      "I just struggle to comprehend why you wouldn’t take 10 seconds and grab a cloth and wipe it prior to taking the photo.",
      "I believe that 1070 is from the gaming x series. What a great card, still use a 1080 gaming x 8gb, serves me well even on high graphics.",
      "Loll i swear it’s only that bottom panel the rest I cleaned 😭",
      "The time was right now, tomorrow is not guaranteed. Also 50 series is going to be very expensive with tariffs plus markup, let alone if I can find one msr. Im happy with my choice",
      "You held onto a 1070 for 8 years just to upgrade 3 days before the next gen is announced and 3 weeks until it launches???\n\nAlso, how is your PC so filthy? Does it not have a dust filter?",
      "I was very excited, didnt cross my mind",
      "Always gotta be a bunch if nitpicky debbie downers. Enjoy your gpu dude! 1070 to 4080 super is a massive fucking upgrade and you got nerds telling you bbbut you should have waited lol",
      "Damn, I remember when I replaced my 1070 with 1080ti. That was like 2x performance upgrade and I was in heaven. But this here must be insane.",
      "Those front fans disagree",
      "The dust hold sentimental value for OP",
      "Sedimental value",
      "The 4080 will make the 1070 eat the dust",
      "Yep it was honestly still kicking ass, the 10 series were works of art",
      "Been thru a lot with my dust 🫡",
      "Going from low to medium graphics on 1440p to Ultra/Extreme with RT really has been wild. Also salute to a fellow 10 series owner. The 1080ti is a beast of it’s own",
      "I get it tbh. Not that I would not have dusted it if I was in the same position, but I get it haha",
      "4080 super is a great card. Even when the new one gets announced the 4080 will still be a great card.",
      "Exactly, nothing like the internet to make you feel\nlike sh** for not being a perfect human being in accordance with a random strangers idea of perfection. Sheesh."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "4080"
    ],
    "title": "GeForce RTX 5070 Ti leak: 7.6% faster than 4070 Ti SUPER in Blender, on par with RTX 4080 SUPER in OpenCL test",
    "selftext": "",
    "comments": [
      "Compared to a 4070 Ti Super.....\n\nAbout 6% more cores.  Uses about 6% more power.  Delivers about 7.6% more performance.\n\nYawn fest.  Nvidia still gonna charge $750-800 bucks for this nonsense.",
      "This is definitely the 4070 SUPER TiTi",
      "7,6% Performance boost for only a 35% price increase. What a steal ! \n/s",
      "Soo... It is a 4070 Ti Super Ultra!",
      "not everyone has a 40 series gpu lmao",
      "Basically they’re re-releasing the 4000 series, except the flagship is better.",
      "But but nvidia said: 5070~~ti~~ = 4090 🤓",
      "nVidia really have the consumer GPU market by the balls. Two extremely lackluster generations and I'm still having to consider a new card because 10gb VRAM is not enough for my needs anymore. \n\nOn top of that, more money gets me a tier below what it did last time. \n\nAnd on top of *that*, the tiers have essentially been shifted down by applying higher tier names to lower tier specs.",
      "Turns out I had no idea how lucky I was when I got my 4070TI Super for 750$.",
      "i mean at this point everyone can agree this is the worst generation. i was not gonna upgrade this gen anyway but this reduces my expectation for the next generation as well cuz even if they do 20% boost on 6th gen RTX it will still be relative to this subpar generation.",
      "I remember when a generational uplift was 20-30% faster not <10%",
      "If this is indeed 1.2x vs 4070 Ti Non Super, then here's how 5070 Ti performance will shake out (based on TechPowerUp 4K Average FPS):\n\nAgainst 40 Series\n\n* 5070 Ti = 1.1x vs RTX 4070 Ti Super (probably not worth upgrading)\n* 5070 Ti = 1.2x vs RTX 4070 Ti (upgrade might be ok if you want MFG)\n* 5070 Ti = 1.3x vs RTX 4070 Super\n* 5070 Ti = 1.5x vs RTX 4070\n\nAgainst 30 Series\n\n* 5070 Ti = 1.42x vs RTX 3080\n* 5070 Ti = 1.8x vs RTX 3070 Ti\n* 5070 Ti = 1.9x vs RTX 3070\n\nAgainst 20 Series\n\n* 5070 Ti = 1.86x vs RTX 2080 Ti\n* 5070 Ti \\~= 2.21x vs RTX 2080",
      "There are not really any meaningful upgrades that have a decent value proposition for the > 3080 gang.",
      "Is this the weakest generational uplift ever?",
      "Don’t kid yourself into thinking that was a good price for that range of GPU. Market is fucked and we should not let this normalize",
      "Oh you will pay over $1000 for a 5070Ti. There's no FE which means no guaranteed MSRP and the AIB's will be well over that.",
      "~7% slower than a 4080s for $750… I guess that’s something, but then again the 4080s even with the price cut was too expensive anyways soooo",
      "wow great overclock series nvidia",
      "Don’t put words in their mouth, the man in leather jacket said that for 5070.\n\nhttps://preview.redd.it/2w3elf1z5xie1.jpeg?width=883&format=pjpg&auto=webp&s=a0d070d4f3be32b96f96b8bbaf7ff0050c84f869",
      "Not impressive, as expected. Entire 5000 series lineup is just a refresh."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "4080"
    ],
    "title": "Sold my 3080 while the price is right and pulled the trigger on 4080 Super.",
    "selftext": "",
    "comments": [
      "Damn, 3080 for 300 is a good deal.",
      "What was the total upgrade cost? And what price did you sell the 3080 for",
      "Got lucky on FB market place. Guy was selling this sealed box 4080s for 1000 pounds. And sold my 3080 for 300 to another person.  :) so 700 pounds.",
      "Indeed it’s an amazing deal. \nI think OP could have gotten more tbh.",
      "Can't wait another month or 2?",
      "Sold mine for £350 yesterday, and probably could have got more I reckon. They are selling for close to £400 on eBay.",
      "Crazy the size of these cards today.",
      "Wanted to, however I know I wouldn't get this deal again. Was 1000 pounds and sold the 3080 for 300. Besides given the scalper nature now days, there's no guarantee of getting 50 series card anytime soon when it launches. I wanted to enjoy my christmas break playing cyberpunk at ultra. 😄",
      "5080 is gonna be 30-40% faster for the same price ? Thats why. Expecting disappointment is as stupid as expecting the opposite. Its a matter of 2 weeks to announcement. Unless you need it RIGHT NOW theres really no reason to, especially with prices of the 4000 series being so high",
      "White Strix is the best looking model out of all in my opinion",
      ">Expecting disappointment is as stupid as expecting the opposite.\n\nLaunch is weeks away.  This your first time?",
      "Why wait for disappointment when you can get enjoyment instead, right now? \n\nMaybe a 5070 ti is a few percent better value, or a few percent faster, but unless it comes with some very crazy exclusive feature, i dont see the point in even waiting honestly. You never know nvidias greed, or how avaliability will be. But i guess we will see...",
      "Mining cards are not used at max power.  They are usually power limited for peak efficiency.",
      "His dad works at Nintendo",
      "He paid more than MSRP and 4080S have been popping up for sub £900 for the past year. \n\nGuy who sold it for £1000 must be laughing he'll be getting a 5080 on launch in 3 weeks 😂",
      ">a brand new 7800XT for ~£380. It's basically like getting another 3080 but with 3 years warranty, less power usage and 6GB more VRAM\n\nAnd with worse raytracing and no DLSS\n\nObjectively it is merely a sidegrade at best.",
      "People don't come here for facts and reasoning they come here for validation.",
      "Not sure what my upgrade path for my 3080 10gb will be. I feel like I'm stuck between a rock and a hard place.",
      "Clean, could have waited for the 50 series though.",
      "Everything you just said is wrong lmao. Funny man"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "4080"
    ],
    "title": "3080 FE x 4080 Super FE x 5080 FE",
    "selftext": "lol sorry for the horrid pictures. ",
    "comments": [
      "Damn the 4080S is a chonker never knew it was that fat",
      "He is the reason Nvidia can get away with 10% uplift generations. \n\nNvidia couldve done an Intel and put a GPU 10% slower and he still would've gone out and paid 2k$ for it. 💀",
      "Why would you go from 4080S to a 5080?",
      "Yup they just used the 4090 cooler",
      "You're the exact customer NVIDIA targets",
      "Same body/chassis, too. Kinda brilliant move -- only one spec to manufacture and stock. (Manufacturing junkie here, lol). Plus the OP 4090 FE cooler keeps my 4080 FE frosty.",
      "Because I’m a fool",
      "That's what rich means x)",
      "I have no words.",
      "consume wisely...",
      "Actually, he is. When Nvidia started engineering the 5090 and 5080 chips, employees referred to the project as \"project Ugly__God\".\n\n\nSource: Believe me, please.",
      "Bro what 💀😭",
      "Make sure u got all ur ROPs",
      "![gif](giphy|szWu9brqcBP45m36YE)",
      "Look at you being rich…",
      "He’s saying it was FOMO",
      "I respect the honesty 🫡",
      "and silent all the time!",
      "More money than sense lol",
      "There's no way you bought a 4080 Super to replace it a week later"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "rtx4080"
    ],
    "title": "Hey all! Just wanted to share my first build! Also have question about my fan placement.",
    "selftext": "Hello everyone. Just wanted to share some pics of my simple but sleek build. I prefer simple and minimal. But also I have a question specifically on the top fan if I should delete it all together. Right now I have fronts as intake, the rear and top are exhausts. I had an idea to put a fan up there and sorta use it as a spotlight shining down on the cooler but it didn’t work so well I guess lol. Maybe I’ll just turn the rgb off if the suggestions are to keep it. My setup is:\n\nCorsair 4000d\nRtx4080 FE\nRyzen 7 7800x3d\nG Skill Trident 16x2\nGigabyte aurus elite mobo\nArctis Liquid freezer II",
    "comments": [
      "Fans are fine and ideally setup.",
      "When placing fans you're thinking about airflow and aiming for a balance between intake and exhaust. You do this with the number of fans and their speed. It's a non-trivial problem because the intakes are hampered by the dust filters.\n\nIt's always better to have slightly more intake than exhaust, so I think your 3 -> 2 setup will work great. Rear and top are a classic exhaust combo because you're drawing air across the motherboard."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "4080"
    ],
    "title": "NVIDIA GeForce RTX 4080 Reportedly Getting Price Cut By Mid of December To Make It Competitive Against AMD’s 7900 XTX",
    "selftext": "",
    "comments": [
      "I hope every scalper got absolutely fucked by the 4080. That entire community is absolute cancer.",
      "They probably planned to do this from the start. Make as much money as they can up front when there’s no competition and then drop the price once AMD has an answer.",
      "The scalpers are going to be even more fuc*ed now :D",
      "Some already are. Newegg axed off their return policy for the 4080s and are doing exchange only.",
      "The buyers remorse incoming from the handful of people who actually bought one of them already.",
      "how blueballed we are to think that 1k is an acceptable price for an 80 class card",
      "They need to drop it more than 200$ tho.",
      "Delicious scalper tears",
      "Now if they'd just do the same thing for the 4090, imagine the moaning and tears from scalpers",
      "Isn't that literally every company's strategy ? \n\nYou price your product at what you can sell it for, not its value + markup.",
      "I will never spend $1000 on a graphics card. That to me is ridiculous and I'm a software engineering manager so it's not like I couldn't afford it. But the fact this has become the norm is unacceptable and predicated on obscene greed.",
      "RTX 4080: 850€\n\nRTX 4070ti: 650€\n\nThen I might think about getting a 40 series card.",
      "If both cards are $1000, then most people will choose the 4080 including me. So I'm guessing the price will be $1099, maybe $999 cause the cards barely sell at the moment.",
      "I cant emphasize enough that isn't even really an x80 class GPU.  It's direct equivalent in the Ampere lineup would be a 3070....",
      "They actually did, they 4090 FE is 100€ cheaper in the EU since today.",
      "The best way to say thank you to AMD is actually support them and buy their GPU.",
      "Because right now people aren't buying 4080s and I doubt it's because everyone is waiting for AMD. The prices is just too damn high.",
      "IMO even 7900XTX is expensive for a GPU. I don't know about all of you but 1000$ for a single GPU is bonkers to me.",
      "People have been saying this stuff since the GTX 680. It doesn't matter. Look at the performance. Do you buy based on memory bandwidth and other characteristics that make you think it slots in as a 3070 equivalent for Ada Lovelace?? No. Performance.",
      "I fear this is too hopeful."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "4080"
    ],
    "title": "Went to get a 4080 Super, but walked out with a 5080 pre-built",
    "selftext": "Went into Microcenter Thursday afternoon to upgrade from a 3060 to a 4080 Super pre-built, but apparently Microcenter messed up and didn't advertise their 4 5080 pre-builts on their website. So, they were like \"We got a 5080 for just $200 more.\" Yes please, I'll take that! Can't believe I got that lucky! Their cards sold out in the first 30 minutes after opening.\n\nEdit: Here's the other specs for anyone wondering\nAMD Ryzen 7 7800X3D (4.2GHz) Processor\nMSI Pro X870-P WiFi Motherboard\n32GB DDR5-6000 RAM\nNVIDIA GeForce RTX 5080 Graphics Card\n2TB NVMe SSD\n\nEdit 2: For those wanting more context: The 4080 S pre-built I was planning to get was $2500 and the other parts were different. For $200 more, I got the 5080, a better CPU, better RAM, and a better SSD",
    "comments": [
      "$2700 isn't terrible. Sure, it's cheaper if you can build it yourself if:\n\nA) You can find a 5080 for MSRP.\n\nB) *Want* to build it yourself.\n\nI think a lot of people forget that gaming and building PCs are not the same hobby. Some people have no desire/time to build a PC. There's a reason why pre-builds have a market. Hell, that's a big reason why consoles are still around.",
      "wow...super nice....enjoy",
      "uhhh they paid $2700 for an entire computer containing a 5080. While it could be done a little cheaper and it should probably have a 9800x3d, it's not a *terrible* deal on a prebuilt.\n\nYou'll always lose to a DIY build of course, so idk why ppl always jump to make this comparison",
      "Exactly this! Putting my specs into PCPartPicker, I paid maybe $350 max more than what I should, but for not having to pick out my parts and learn how to build it myself, I'd say that's worth it",
      "That mobo and cpu are around $700 together, with everything else I don’t see it being $2k to build it. I’m all for building over buying built, but I feel like the estimation is a little off on your end.",
      "People and their elitist egos about building their own PC, tsk tsk tsk",
      "I’m waiting for Best Buy 5080 drops but if I can’t get one after a few days I think I might just walk in and ask. Who knows?",
      "You don't get it. You have to save some money by spending hours and hours determining the exact sku of every part you want, then hunt down the parts and snap them together yourself. Otherwise, you're not a real PC enthusiast.",
      "I like that people aren't considering the other parts in the 5080 pre built compared to the 4080 Super pre built. The graphics card isn't the only thing that's different for the $200 increase",
      "Somebody that is not into building pc’s will not finish it in two hours",
      "this comment right here is why so many people prefer a prebuilt. \n\njust like the guy enjoy his pc ffs",
      "So happy for you. Great. Awesome.",
      "You lucked out man, enjoy. It’s a very capable PC.",
      "Its odd why prebuilts are looked down upon. Its the only way I got a 3080 and its the only way I am getting a 5090.",
      "Not at micro center.  Their prebuilts are just off the shelf parts.  Same stuff you'd buy.  \n\nAnd usually, they are about $150 cheaper than building the exact spec/parts machine yourself.  \n\nMC offers a great value in their Powerspec computers.",
      "The 5080 is a good overclocker and can actually perform close to a 4090 minus the vram. Go be salty somewhere else.",
      "Probably could have got a little more savings by waiting and shopping around but that’s a pita too. Sometimes you just want to be done and game already so I feel like $350 isn’t horrible for that.",
      "Imagine having this much energy for people not wanting to mow their own lawn or change the oil in their car.",
      "[Please don’t tell me you paid $2,700 for a 5080.](https://www.microcenter.com/product/689586/powerspec-g722-gaming-pc)\n\nBecause that’s the exact same specs as you posted on Microcenter’s website",
      "I am into building my PC's and it's still probably take me more like 2-4 hours from scratch"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "4080"
    ],
    "title": "[Gamers Nexus] NVIDIA’s Lost It: RTX 4080 16GB GPU Review & Benchmarks",
    "selftext": "",
    "comments": [
      "Yeah, great product. Nice performance. Nice design. Just awful price.\n\nSums up the GPU market for the last few generations, at least for me.",
      "Twelve hundred bucks lol",
      "Great card, ruined by a crappy price - at 800$, this would have been a banger and even at 900$ it would have been somewhat decent everything taken into account.",
      "1800€ for some of us Europoors",
      "nvidia hasn't realized yet that GPU mining died and that 99% of people have utterly given up on the pandemic and go outside now.",
      "they can go f themselves",
      "Oh, they know. \n\nBut they've also grown accustomed to people spending $1200 on a product that shouldn't be sold for more than $700. Since mining is dead and people are getting yanked back into their offices, NVIDIA expects their gaming customers to pick up the slack. \n\nAnd they also really need you to buy their prescalped GPUs because they want to obfuscate their sales figures so their shareholders don't take them to court (again) for lying about how much their revenue came from mining (again).",
      "Great card ruined by a stupid launch price! Wait for the inevitable price cut if interested",
      "With each passing day I become more grateful I have a 3080.",
      "Next week this sub: “my new 4080 build!”",
      "yeah feels like getting a 3080 at retail two years ago was the end of an era",
      "\"Hope AMD beat the 4080, so I can buy the next Nvidia card for cheaper\" \n\nAmazing line of thinking :), PC gamers get what they deserve.",
      "If this was a €899 card (due to bad euro value otherwise €799) i would have bought one but €1469 or more? \n\nThat's a insane price increase of at least 2.1x compared to my 3080 for only 35-45% more performance.\n\nNo way i'm gonna support this garbage.",
      "A bit? XD",
      "It's 1499-1599€ in Spain but yes a bit too much",
      "They did price them appropriately to clear 3k stock though.",
      "You think most users here are going to drop well over $1200 on a 4080?  Don't forget how miniscule the $1k+ market really is.",
      "Another gripe is the card is so much BIGGER than a 3080 which was already a big card.\n\nHopefully most can have the discipline to not spend more than $700-800 for a bottom 80 class SKU.",
      "Mucho bit 💵",
      "Especially with used 3080s going for under $400 if you look hard enough.  Even if the 4080 was $699, I'm not very fond of the 4090 sized cooler."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "4080"
    ],
    "title": "RTX 4080 vs 4070 size comparison 😳",
    "selftext": "",
    "comments": [
      "The white 4090 is in the background",
      "size doesn't matter\n\n\\- 4070 owner",
      "The GPU she tells you not to worry about vs your GPU.",
      "As an owner of a white Strix 4090, yes, I can confirm. The card is an aircraft carrier masquerading as a GPU.",
      "don't talk to me or my son ever again",
      "4070 is average, OKAY!!",
      "And that's just the FEs",
      "“Babe don’t worry he’s just a friend”",
      "The 5090ti till just be a computer case.",
      "my GPU is 3070 😟",
      "To be fair, the huge 40XX cooling gives extremely excellent cooling at 70-80 degrees at full load",
      "How’s the thermals on the 4070? I find the 4080fe is completely over specd when it comes to thermals. Fans defaulted at 30% and I can’t say I’ve ever seen the card hotter then 65° lol. When let to increase it hovers at about 58°. \n\nQuietest and coolest card I’ve ever owned.",
      "Mine is a 970 😭",
      "5'11\" vs 6 foot",
      "Never was\n\nIt was always mid range.\n\n1070ti was the only 70 series i would consider high end \nSince it was only 2-4% behind the 1080",
      "Well it typically doesn’t pull more than 200W, so the thermals are pretty excellent.",
      "Honestly, yeah. I don't mind the FE's being absolute beasts in size. If you buy a 4080 or 4090 you will likely want a big case with good airflow anyways.\n\nAnd like you said, thermals are amazing. Way overkill, but then you can choose between running fans really slow, or overclocking quite a bit.",
      "The 4090 is now a literal table, it chonk",
      "Have you been on r/sffpc lately? Those people are stuffing 4090 FE into 10 liter cases\n\nE: wrong sff sub",
      "The 4070 has a great personality"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "4080"
    ],
    "title": "Went from 4080 to 4080 Super… But for good reason.",
    "selftext": "My son was still rocking a 970 so he got my old 4080. Love the FE so far.",
    "comments": [
      "You're a good father.",
      "Thank you, a childhood of low grade PCs makes you want to compensate it somehow.",
      "You have a good pc",
      "Nice, I can't wait to get mine.  I had a good upbringing compared to others, but I sincerely can't imagine a dad supporting gaming since when I was growing up it wasn't allowed at all.  It was like bringing in satan into the home lol.",
      "https://preview.redd.it/fqmdm71x8ngc1.jpeg?width=4032&format=pjpg&auto=webp&s=106156e9ca3d78595560ae8aca053d9cd52d33f9\n\nMe and my twins build!",
      "The 4080 super looks awesome in your rig",
      "![gif](giphy|wijMRo7UZXSqA)",
      "I wish other people in the subreddit would be like this and not bash the shit out of the 4060 TI. They must be thinking I overspent on the CPU but it was just a bundle and I got the motherboard, ram and CPU for 400. Budget was 1200 and I didn’t have much time to make the list since we went for a trip to America and it was where I bought all the parts",
      "He loves Warzone and is only allowed to play on weekends (mom’s rule, he’s 10) but we love to squad up when we can.",
      "Also note. His KD is higher than mine.",
      ">My son was still rocking a 970 so he got my old 4080. Love the FE so far.\n\nnot a good reason, the best reason, gg :)\n\n&#x200B;\n\nYour PC looks really clean, it's those lian li fans that daisy chains without cables right ?",
      "Specs for those asking\n\n\n\n7800x3d \n\n4080 Super FE\n\nCorsair Vengeance 32GB 6000mhz\n\nMSI B650\n\nMSI A1000G\n\nLian Li Galahad Trinity LCD AIO\n\n7 Lian Li reverse blade SL V2 120mm\n\n5 Lian Li SL V2 120mm \n\nLian Li Dynamic Evo XL\n\nSons rig\n\n5600x\n\nGigabyte 4080 OC\n\nCorsair 32GB \n\nMSI B550\n\nMSI A850G \n\nLian Li Galahad Trinity II AIO\n\n5 Lian Li SL V2 140mm fans (intake) and 120mm \nexhaust\n\nLian Li Dynamic Evo",
      "I have no morality to bash anyone, I have one of the PCs that makes less sense in a gaming scenario. Be happy with your build, enjoy it and flip a finger to someone that tells you otherwise unless you specifically ask for an opinion. \n\nDoesn't matter if you could get 5% more performance by buying some another random GPU, if your ram is not ideal, if your case is not adequate or if the monitor is too big. It's your rig, you chose the parts and it was for sure a happy moment, and that's what matters the most.",
      "Can you adopt me?",
      "Kids have better reflexes than fathers.\nBut we have experience, which can be a hindrance.\n\nGood on your wife to regulate time.\n\nI have a policy too. I see what they get out of a game and judge time off that.\n\nI also ask questions to engage them. Like what did you learn? Did you find something hard? How did you figure it out? Or what do you think might be the solution?\n\n\nThe more feedback I get the more time I alot them for that game.\n\nDrifting on a track, sure 30mins. If they ask me more time I'll be relauntant.\n\nScience game learning about the planets, hey dad can I get 10 more mins? Sure kiddo.\n\nThanks for sharing. I hope they grow to have a positive experience with tech.",
      "Wow that black and white is one of the best looking builds I've ever seen. I'm sure your son is ecstatic. Great dad.",
      "smoggy water entertain repeat sheet erect jellyfish hard-to-find imagine disgusting\n\n *This post was mass deleted and anonymized with [Redact](https://redact.dev)*",
      "don’t let anyone tell you your gpu isn’t good enough",
      "Yea 1 cable to each group of fans. really clean.",
      "I’m an engineer by trade and my only regret was not learning how to code earlier in life. He has an interest in tech/science now so hopefully this is a good foundation for him to be better than I was."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "4080"
    ],
    "title": "RTX 4080 Super Founders Edition $999.99 In stock.",
    "selftext": "",
    "comments": [
      "You need to join a queue to buy a MSRP 4080s in 2025 lol",
      "#  \n\n**Please note: if you are in line for a high demand product, being in the queue does not guarantee a purchase.**\n\nNumber of users in line ahead of you is: **556**\n\n  \nlol",
      "Waited in a queue, forced to log on, checkout with my cart, and it wont even accept my payment what a fucking joke",
      "Can’t even buy a 3 year old card at MSRP in 2025. Market is so cooked",
      "wait in a que for the website to tell you there was an error and unable to complete transaction\\*",
      "I’m sitting this one out. \n\nAlready played this entire dumbass game during the RTX 3000 launch. Saw Nvidia were pulling the same dumb bullshit with the 5000-series and just got an AMD card instead. \n\nI’ll be back for the RTX 6000-series lmao.",
      "So, Nvidia figured out how to make a queue after all this time? And the queue still breaks on checkout? What are they even using AI for over there?",
      "there was none available to begin with the website is just bugged out lol",
      "Seems like they bottled FOMO and are turning a luxury good into a bare necessity, people need to study just how the hell they turned people into zombies, it could have been the 4080 at $1200 and people would have gobbled it up when they rejected it 3 years ago...",
      "Probably some kind of last batch but regardless the 4080S is effectively a 5080 without MFG",
      "Brother, the 5080 is only like 10% faster than the 4080S how is it dogshit lol",
      "Why are they restocking this dogshit instead of the 5080?",
      "These are all going to the resale market.",
      "to be fair this is like my trial queue to make sure my nvidia account is ready to buy 5090 should that come in stock",
      "https://preview.redd.it/av6jm2nezcie1.png?width=1200&format=png&auto=webp&s=6eddf9b61e457d5dc93a2a9f68932b476b70dabd",
      "I'm afraid the same thing will happen when AMD cards launch lol",
      "No one can buy it, I tried and so did hundreds of others , it wont accept credit card details. I only saw one person get a confirmed order in a certain very large GPU drops discord.",
      "> What are they even using AI for over there?\n\nInflating the share price temporarily.",
      "You think 5080 reviews impressed people so much they are buying all the stock available?",
      "….And they’e gone\n\n![gif](giphy|3oEduMDAgIZhBbhRwA)"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "4080"
    ],
    "title": "Upgraded from a 1070 to a 4080 SUPER",
    "selftext": "Wow! What a breath of fresh air. I knew my gpu was very lacking, and as a college student, gpu is an expensive upgrade. Very pleased with the Tuf OC that I got. No coil whine on this guy and the card runs so much cooler than my old asus dual 1070! Almost didn’t fit the case, luckily I measured before buying. Running a Ryzen 7 5800x, tuf x570, 32GB 3600, seasonic focus 1000W. All in a fractal north case!\n\nI was thinking about adding an exhaust fan here soon but honestly the thermals are fantastic right now as is. Card at full load hits 68 Celsius. ",
    "comments": [
      "&#x200B;\n\nhttps://preview.redd.it/x5hla395i5ud1.jpeg?width=735&format=pjpg&auto=webp&s=d50fa78093f7299859d190ea2adeab07baf3cf1e",
      "Nice upgrade!, avoid any comment that say \"why dont wait until 5000 series, why do u buy it when is near, blah blah...\" enjoy ur new gpu, It may be a hasty purchase, but if you want to enjoy current games and you still don't know if you'll be able to buy the next generation, it's foolish to speculate and wait for something that hasn't come out yet.",
      "Man I used to have that exact 1070, it was my first dedicated gpu, man that shit ran so hot LMAO, that 4080S is legit gonna run like a dream and super cool and quiet I’m happy for you",
      "If you're not aiming for 5090 then 5000-series looks like another disappointment",
      "Well I was looking at the leaks and it looks to be the 5080 vs 4080 will not be that much of a jump, and for the gaming I do. Which is 1440p, this is plenty for me now!",
      "Hot and LOUD. I don’t mind a loud card honestly but the fans on that old card are so whiny and high pitched I could hear it through the headphones I wear. That and the plastic body of that card had a slight rattle. One I heard it I could never unhear it. Even tried to repaste the card a few years ago to see if that would help, it in fact did not.",
      "Just jumped to a 4080 Super myself!! Enjoy those beautiful games 😍\n\nhttps://preview.redd.it/m32ojzk8r5ud1.jpeg?width=3000&format=pjpg&auto=webp&s=3bd209a9ad9ba92670f1675716db56b492fc5bad",
      "Had same thought, my 4080s should be here next week to replace my 970",
      "That’s what I’ve been seeing as well",
      "May your 1% be high and your future upgrade prices be low. Enjoy it!",
      "It is insanely big! It makes a 3090 look small...\nAbsolutely icy cool, even pushing to the max I'm at 67-68°. Thank you! Yours too!",
      "That and I got this tuf card for $100 off msrp, couldn’t pass it up.",
      "That card looks MASSIVE. How are temps? I imagine icy cold! Rig looks beautiful!",
      "Wow that’s crazy, that’s where mine sits at as well. Gonna add a noctua 120 on that exhaust here in a few days when I go to town I think. Don’t really need it tbh with my thermals. But it will help keep some of that hot air build up out. Are you running 4k games?",
      "That’s going to be one heck of an improvement. I went from 970 to 3080 and I’m astounded.",
      "10xx series were by far the best value per performance. 8GB of VRAM on a 70 class card which was released almost 9 years ago. The 4070 is 2.5X faster than the 1070, it should have at least twice the amount of VRAM.",
      "Congratulations!)\nI'm looking to buy 4070 Ti Super for myself because 4080S is much more expensive in my country (Ukraine) and considering that I'm planning to upgrade to 2k (not 4k for sure) - the card should be enough for next 4-5 years",
      "Thank you kind stranger, may the same be for you!",
      "Yeah they really overbuilt the cooler on this one, which is a welcome upgrade from the 1070. I found out that the 4090 tuf has the same cooler and heatsink as this 4080 super, should stay nice and cold.",
      "Very nice enjoy your card big dawg"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "4080"
    ],
    "title": "Upgraded from GTX 1650 to RTX 4080",
    "selftext": "Hey all, I went from ASUS TUF GTX 1650 to MSI Gaming X Trio RTX 4080 since it was cheaper than the SUPER version.\n\nI turned off the RGB since I built this PC with All black + No RGB in mind.\n\nI now gave the GTX 1650 to my brother who mainly play Roblox/MC.\n\nSpecs:\n\nMSI B650 Tomahawk Max + Ryzen 5 7600X\nArctic Liquid Freezer III - 420mm (overkill I know but I got it for much cheaper than the 360mm)\nG.Skill Flare X5 32 GB (16x2) 6000mhz CL30\nSeasonic Focus GX-850 Gold",
    "comments": [
      "From 30 fps to 300 fps",
      "Definitely, it was a struggle powering through 1440p with the GTX 1650 before getting the GPU.\n\nI initially had an RTX 3060 which gave up on me that’s why I used the GTX 1650 for half a year!",
      "That's a generation upgrade from 1080p to 4 k max with ultra settings congratulations bro 🫡🔥",
      "I assume rest of the PC was build in preparation for this move? Perhaps recently?",
      "It’s the last piece of the upgrade.\n\nI gave my B450 system with a 5600 to my brother since I got this B650+7600X combo used (with warranty left) for a bargain from FB Marketplace",
      "One giant step for bonkerschonkers",
      "Congrats! Now you can play CP2077 in all its glory!",
      "Don’t think my 3060ti heard of the fact that it can run path tracing in Cyberpunk.",
      "As someone who has a gtx 1650 mobile I don't get 60 fps in any games. Tho in some games it could just stick to 50 for longer periods of time",
      "Depends on the game. I too have a 4080 but man some games really struggle when you crank the settings up and I have to rely on VRR to help out. That’s not the GPUs fault by any means. In those same games every card struggles.",
      "i never got 60 in AAA games on my 1650, even at 1080p with fsr quality (720p) i would struggle. now my 3060 ti can run cyberpunk path tracing",
      "congrats!\n\nwill do something like that.\n\nwill go from my i7 3770 + GTX 1070 to a 9800x3D + RTX 5090 when those parts get released.\n\nalso bought a 32inch 4k 240hz OLED monitor to pair it with. unfathomably excited to build/play on the best pc you can possibly build",
      "With a 4080 you can play 4k 60fps maxed out with RT path tracing as long as you’re down with dlss and frame gen. It’s truly incredible. Just got through phantom liberty this way and I’m wanting to play through the entire thing again.",
      "Ik I was talking about high end games, tho I should add that I like to play with high graphics?",
      "That’s like a 6x performance increase. Huge!",
      "I got them all for around $350 from a dude who just wanted to get a little bit of his money back since he upgraded to the highest end stuff at that time",
      "Yup i am also not talking about high-end games, but yeh i do not play on high settings",
      "Very nice. I also like the Gaming X Trio lineup and have a 3070 Gaming X Trio myself.",
      "I’m using a Lian Li Lancool 3!\n\nThanks",
      "How much did you get the B650 + 7600X + 32GB DDR5 in total?"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "4080"
    ],
    "title": "3080Ti vs 4080 size comparison",
    "selftext": "",
    "comments": [
      "Found one of the six 4080 owners guys! *LETS GET HIM*!",
      "don't buy the 4080 please. they should learn not to price it that badly.\n\nEdit: downvote me all you want. It's still true.",
      "I am surprised people are actually buying the 4080 at this price. No disrespect but I would at least hope for nvidia to lower the price Q1 2023.",
      "I can't believe someone with a 3080ti would. What's the logic in going half a gen up with such ridiculous prices.",
      "For real, why not go all out with the 90 and actually get a smidge of \"value\"?\n\nOP is a big dumb dumb tbh",
      "Guess we'll see a $1600 5080 next gen.",
      "I would have spent some extra and got the 4090.",
      "# Don't buy 4080s!",
      "I got a good chuckle out of this.",
      "The 4080 is overpriced by at least $500, and \"upgrading\" from a 3080Ti to it? super cringe",
      "You...you bought a 4080?\n\n...*WHY*?!",
      "4080 is such a shit deal why even bother?",
      "“Cutting edge consumer tech” \n\nWe’re doomed",
      "I’ll upvote you and I’ll give you all the awards and I’ll promote your comment on all social media if you say so. And I’ll downvote all people’s comments in their comment history if they downvote you, just give me their names. That 4080 doesn’t deserve any penny.",
      "While we are getting the poor guy, what size will the 5090 be? Is it just going to be the size of a full ATX case? Maybe we go back to the days of a whole room for a computer I guess.",
      "that 3080ti he replaced this with would have as well",
      "That's the part that gets me. Upgrading from 3080Ti to this for so much money makes no sense. That's why Nvidia can get away charging this much, truly a perfect consumer.",
      "Wow ppl hate emojis around here, huh",
      "wouldn't you buy the 4090 then :O? I think the prices will fall in Dec the moment 7900 comes out.",
      "He already had a 3080Ti, its in the photo."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "4080"
    ],
    "title": "MegaLights, the newest feature in Unreal Engine 5.5, brings a considerable performance improvement of up to 50% on an RTX 4080 at 4K resolution",
    "selftext": "",
    "comments": [
      "Fix Stuttering",
      "A few important notes:  \n  \n1. MegaLights is a whole new direct lighting path in Unreal Engine 5.5, enabling artists to place orders of magnitudes more dynamic and shadowed area lights than they could ever before. It's not only reduces the cost of dynamic shadowing, it also reduces the cost of unshadowed light evaluation, making it possible to use expensive light sources, such as textured area lights. In short, MegaLights is very similar to NVIDIA's RTXDI (RTX Dynamic Illumination).   \n  \n2. As this feature heavily utilizes Ray Tracing, Hardware Lumen and Virtual Shadow Maps are required for MegaLights.  \n  \n3. The performance difference depends on how many shadow casting lights are in the scene. The more shadow casting lights are visible, the bigger performance improvement will be with MegaLights enabled.",
      "I just want Unreal Engine to stop being a stuttering shithole.",
      "Up to 50% more blurriness when moving the screen!",
      "And up to 50% more stuttering and shader compilation!",
      "Stutter Engine procrastinating on fixing the real issues.",
      "a quick glance makes it seem like its cutting down on rays and increasing denoising to improve performance. details are smoothed over in the megalight results, especially specular highlights, similar to what you'd expect from denoisers. In some cases its too much detail loss imo, like the image with the skeleton. With just hardware RT there is very obvious webbing on the skeleton but with megalights most of the webbing is lost.",
      "Nice features, but performance (traversal stutter, shader stutter, etc.) is the concern. They should spend the entire rest of the UE 5.x generation on optimization. Leave new features for UE 6.x whenever that comes.",
      "You forgot to mention the micro stutters every 10-15 seconds",
      "They're making a joke about the poor performance of unreal engine and the seeming lack of attempts to fix it.",
      "Right, like nanite? \n\nExcept that nanite is now being used as an LOD replacement, in the worst way possible.\n\nGet ready for even lazier devs misusing this feature.",
      "It is INCREDIBLY sparse and very temporaly accumulated as far as RT goes. So noise and fast movement are a great problem, especially with low diffusion shadows.",
      "Blurry smeary stutter Engine 5.",
      "yea they really do know how to dance around the elephant in the room",
      "sure just buy the new fortnite christmas bundle",
      "The future is blurry & stuttery it seems",
      "I find it hilarious how Epic shills love to claim typical UE5 stuttering is a \"developer issue\" when those same people conveniently forget that Fortnite, which is developed by Epic themselves on their own flagship engine, has well documented stuttering issues. Outside of maybe a few games, the vast majority of UE5 games have stuttering issues. If Epic's own Fortnite and most other UE5 games have stuttering then I'm more inclined to think that this problem is mostly on Epic, not so much developers. \n\nSome claim this was \"fixed\" with 5.3/5.4 but that's simply admitting that this is Epic's problem. Epic needs to cut it with this finish it as we go model and actually debut their flagship engine in a completed state considering the future of AAA (and maybe AA) gaming is going to be running on UE. Until then I'm simply not going to play any game running on UE5.",
      "Image looks too soft, details are lost.",
      "Indiana Jones isn‘t UE, nor does it run horribly.",
      ">We need to wait for games built on those engines\n\nThe irony is that Fortnite runs on the newest Unreal Engine version, and still suffers from heavy shader compilation stutters during gameplay. In the beginning I liked to believe those claims before, but even with new PC hardware (RTX 4070, 7800X3D, 64 GB RAM) it lags a lot during the first gameplay hours due to shader compilation. So since even Epic Games' own flagship game is still affected, it makes me doubtful that the newest engine builds magically fix everything."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "4080"
    ],
    "title": "[Megathread] Celebrate Cyberpunk 2077 Launch with DLSS 3.5 & RTX 4080 Giveaway!",
    "selftext": "&#x200B;\n\nhttps://preview.redd.it/rw79uqv9v7pb1.jpg?width=1820&format=pjpg&auto=webp&s=362c5ad27764853a3843c01845d8073b37e8fc63\n\n# DLSS 3.5 with Ray Reconstruction will be coming to Cyberpunk 2077 with the game’s 2.0 update on September 21st.  \n\n# DLSS 3.5 with Ray Reconstruction will be available September 26th in Cyberpunk 2077: Phantom Liberty, along with full ray tracing.  \n\nIn the Ray Tracing: Overdrive Mode, DLSS 3.5’s new Ray Reconstruction technology enhances the quality and clarity of reflections, global illumination is even more accurate, and lighting is more dynamically responsive, for an even better, more immersive, more realistic experience. \n\n&#x200B;\n\n|**Topic**|**Articles / Videos**|\n|:-|:-|\n|Exclusive Cyberpunk 2077: Phantom Liberty RTX Technology Video|[Video Link](https://www.youtube.com/watch?v=DbuKZgZpDP8)|\n|Cyberpunk 2077: Phantom Liberty With NVIDIA DLSS 3.5 & Full Ray Tracing article  |[Article Link](https://www.nvidia.com/en-us/geforce/news/dlss-3-5-cyberpunk-2077-september-21-launch/)|\n|\\[Digital Foundry\\] - Inside DLSS 3.5 Ray Reconstruction + Cyberpunk 2077 Phantom Liberty - AI Visuals Roundtable|[Video Link](https://www.youtube.com/watch?v=Qv9SLtojkTU)|\n|NVIDIA DLSS 3.5 New Ray Reconstruction Enhances Ray Tracing with AI|[Video Link](https://www.youtube.com/watch?v=sGKCrcNsVzo)|\n|Cyberpunk 2077: Phantom Liberty – Official Cinematic Trailer|[Video Link](https://youtu.be/H-2J0x6oWUg)|\n\n# DLSS 3.5 FAQ\n\n**What is DLSS 3.5?**\n\nNVIDIA DLSS 3.5 features Ray Reconstruction, a new AI model that creates higher quality ray-traced images for intensive ray-traced games and apps. \n\nDLSS 3.5 is a suite of AI rendering technologies powered by Tensor Cores on GeForce RTX GPUs for faster frame rates, better image quality, and great responsiveness. DLSS now includes Super Resolution & DLAA (available for all RTX GPUs), Frame Generation (RTX 40 Series GPUs), and Ray Reconstruction (available for all RTX GPUs)\n\n**How does DLSS 3.5 work?**\n\nDLSS Ray Reconstruction adds additional AI to the ray-tracing lighting pipeline by replacing  multiple hand-tuned denoisers and adding a combined AI model for Super Resolution and Ray Reconstruction, addressing image quality challenges associated with a denoiser and high frequency information loss during upscaling.  \n\n**Is DLSS Ray Reconstruction for path traced games, RT games or both?**\n\nDLSS Ray Reconstruction is most advantageous to games that use ray tracing heavily. Path tracing definitely falls into that category. It can also provide advantages to games that use ray tracing on multiple effects.\n\n**Can we expect Ray Reconstruction to be a separate setting in game menus like Frame Generation?**\n\nYes. There is a new Ray Reconstruction toggle available when Super Resolution is ON.\n\n**Why does Ray Reconstruction require Super Resolution to be on?**\n\nBecause Ray Reconstruction is a combined AI model with Super Resolution to address the image quality issues that occur when there is high-frequency detail loss during the denoising/upscaling stage of the ray-tracing pipeline.\n\n**Does DLSS 3.5 improve performance or take away performance?**\n\nPerformance varies based on the number of ray-traced effects. Games with multiple ray-traced effects may have several denoisers that are replaced by the single Ray Reconstruction neural network. In these cases, Ray Reconstruction can also offer a performance boost. In titles with less intensive ray tracing and fewer denoisers, Ray Reconstruction improves image quality though may have a slight performance cost.\n\n**Compatibility**\n\n* GeForce RTX 40 Series users can combine Super Resolution and Frame Generation with Ray Reconstruction.\n* GeForce RTX 20 and 30 Series users can add Ray Reconstruction to their AI-powered technologies, alongside Super Resolution and DLAA.\n\nhttps://preview.redd.it/hs0janfim7pb1.jpg?width=3840&format=pjpg&auto=webp&s=e2ef1d6bae16be8bdd7f02f8efcc84ccb4bd62d3\n\n# Giveaway\n\nSee stickied comment for the giveaway details. You will need to respond to the stickied comment for the giveaway. Use the top level comments for regular news discussion.",
    "comments": [
      "# Giveaway is here.\n\n**Respond to this comment only. Any entries not in this comment will not be counted**.\n\nYou can enter for a chance to win a RTX 4080 GPU by answering the following:\n\n*“Tell us what excites you the most about DLSS 3.5 in Cyberpunk 2077: Phantom Liberty or Cyberpunk 2077 2.0 update!”*",
      "What are the terms and conditions of the giveaway?",
      "ray reconstruction looks amazing",
      "Hi",
      "I’m excited to see the difference",
      "I’d be excited to see how much better the game will feel with all that extra performance over what I currently get.",
      "I'm excited for better water reflections and more intricate lighting details.",
      "Would love to get the 4080, so i can give it to my partner so she Can be amazed of all the fancy ray tracing, or she can take full advantage of DLSS 3.5. And that we can start to play together😌",
      "Excited that my computer won't be crying while it runs Cyberpunk and looking like cardboard!",
      "Higher detail reflections and the other benefits that come along with ray reconstruction! These were the small inconsistencies holding real time path/ray tracing back. I'm looking forward to seeing the next leap in realtime graphics!",
      "Haven't played cyberpunk for a long time but quite excited to try out the new update. \nCurrently I don't have the 40 series GPU that can use the frame generation technology.\nIt would be great to try it with a 40 series GPU. \nI would like to see that path tracing and what this new DLSS 3.5 brings to the game.",
      "I built my current rig in 1999. It was state of the art at the time. Would love to have new hardware to run Cyberpunk on a new state of the art rig.",
      "I'm very exited to see the increase in performance and the visual fidelity with DLSS 3.5",
      "I'm definitely most excited to get a 'free' performance upgrade when using RT. gonna finally buy both Cp2077 & Phantom Liberty today! thx for the giveaway!",
      "Most exciting thing about this update is that hopefully I’ll more fps!",
      "Wow, can’t even give away one top card?  Man, nvidia really must be hurting",
      "Wow, this is impressive.",
      "Raytracing",
      "Race Tracing is nice, but the high amount of fps is so awesome! Combined with high Hz Monitors its just insane :) really really big step!",
      "I am really excited to see how the technology progresses."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "4080"
    ],
    "title": "Ascended from 1080ti to 4080 Super",
    "selftext": "I was able to upgrade from 8700K - 1080ti to 9800X3D - 4080 Super last week. It felt so good together with the LG C4, 4K Oled is Amazing!  \n\n\nJust in case it’s necessary, here’s the specs.  \n\n\nCPU: 9800X3D.  \nMB: Gigabyte X870 Aorus Elite WiFi7.  \nRAM: 32GB DDR5 G.Skill Trident Neo.  \nGPU: Gigabyte RTX 4080 Super Gaming OC.  \nPSU: Lian Li Edge 1000w.  \nAIO: Lian Li Hydroshift R.  \nSSD: 1TB KC3000 (OS) 2TB P400 (Games) 2TB P220 (Media).  \nFANS: Interstellar V2.  \nCASE: Antec C8.  \nMonitors: LG C4 42 and Acer Predator X34P.  \nMnK: Mammoth 75 Wireless and X Lite Wireless.  \n\n\nYes, i cannot wait for the 5000 series, i’d rather enjoy my holidays gaming in 4K than waiting for 6-12 months for GPU Prices to normalize (Fuck Scalpers and Competition)\n",
    "comments": [
      "yeah this 1080ti and 8700k combo been smashing shit for almost 10 years. 1080ti was the best card for value ever created.",
      "I went from a 1080ti to the 4080 super this year as well! Loving it!",
      "Definitely! My old was still working, so i gave it to my sister as her work PC. \n\nI just wanted to play in 4K Oled and watch movies with the wife every weekend so i ended up with the LG C4. Money well spent.",
      "That’s a hyper jump upgrade! \nCongratulations!",
      "Thats not ascend. Just revert it and give me your 4080",
      "1080 ti is a beast",
      "I went from 2080 (basically the same as 1080ti) to 4080 and my fps more than doubled without upscaling!",
      "1080Ti still going hard too. stalker 2 60fps with some mild upscale",
      "Welp I'm still using a 1080FE. I might be stuck forever 😭",
      "![gif](giphy|26gsjCZpPolPr3sBy|downsized)",
      "It's truly an incredible piece of technology. Never to be created again at such a value. I think I paid 650 for mine, it's under a water block and still kicking ass. Only thing I wish it had was DLSS.",
      "I'm currently rocking the 1080, it's been a great card!  Just ordered a used 3080ti, not quite as big a jump as you made but should be pretty substantial",
      "You can now play cyberpunk in how it's meant to be played",
      "Still rocking my 1080ti. Nice build!",
      "It truly is! Still was working, decided to give it to mu sister as her work PC.",
      "Clean build. Gorgeous!",
      "![gif](giphy|g9582DNuQppxC|downsized)",
      "Those jumps are so satisfying.  I went from a i5-4670 and 980ti to a 5800x3D and 3800ti and remember games that struggled to maintain a sold 60 were now exceeding my monitors 165Hz limit.  RDR2 at 1440p ultra was the moment of justification for me.",
      "Cyberpunk on a 4080 Super is awesome! You’ll need upscaling to hit 60 FPS with full path tracing, though.",
      "Boy ascended directly from base form to ssj blue 😂 I am happy for you! Gaming and Christmas go together like Cloud and Tifa."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "4080"
    ],
    "title": "JayzTwoCents \"5070ti is close to 4080/S performance\"",
    "selftext": "[https://www.youtube.com/watch?v=LgAb5bmcTjk](https://www.youtube.com/watch?v=LgAb5bmcTjk)",
    "comments": [
      "Videocard pricing and availability is out of hand these days",
      "yup, Basically 5070Ti will be 900-100$ and providing a little less than 4080S. This gen is basically a refresh of the previous gen with crazier prices. Only 5090 providing more perf. but basically +25% price, power, and perf. so overall no generational improvement.",
      "This is a card that should be $600 MSRP with AIBs topping out at $750 but we're looking at $1000 yet people are still going to pay it. Clown World.",
      "The 3070 was on par with the 2080Ti. The 4070 was on par with the 3080Ti. The 5070Ti is \\*close\\* to the 4080S in performance. \n\nhttps://preview.redd.it/wp96rncsrrje1.jpeg?width=640&format=pjpg&auto=webp&s=6c0467edea824489d664a8c5b6959681e68b9241",
      "I dont think its gonna get better man",
      "It's funny how Nvidia actually tried to tell people that the 5070 was 4090 level performance. Here we are and the 5070 ti is barely 4080 performance. What a bold faced lie",
      "50 series is a midgen refresh of the 40 series if gpu cycles were 4 years instead of 2 years lol",
      "4070 was on par with a 3080 non ti",
      "Kind of not surprising. Makes me want to wait for the next cards.",
      "And it won’t change if fools buy these cards at such insane prices.",
      "\\>The 4070 was on par with the 3080Ti\n\nno it wasn't. the Super was",
      "People call this series 40 super duper or something along those lines for a reason.\n\nIf you don't already have a 40 series card and you can actually get them at MSRP, I don't even think it's too bad. They are still using the same TSMC process after all.",
      "I have said it for months, since the un-luanching fiasco really.\n\nLaunch cards are now a scam, designed to milk FOMO people out of their cash, because they **cannot** wait. The refreshes will be the real versions, the versions the cards always should have been in the first place, with the \"problems\" (i.e intentionally gimped specs) corrected.\n\nThen nvidia can spout some BS about listening to thier customers.",
      "The 4070 is not on par with the 3080 Ti. The 4070 super is more or less the same though (TechPowerUp has it as 3% worse).",
      "So basically blackwell is just one huge price increase across the board vs 4000 refresh. Fuck nvidia.\n\n5080 for 4090 price\n\n5070ti for 4080super price\n\n5070 for 4070tisuper price\n\n5060 for 4070 price.\n\nWow 5060 for 600usd that will be wild",
      "That shit is sad.",
      "You are likely thinking of the 3080 non Ti. TechPowerUp lists the 3080 Ti as 119% the performance of the 4070",
      "But he said he doesn't care. I also saw a video where Linus was asking if reviews even matter anymore because a card sells out in seconds regardless of what anyone says about it.",
      "Maybe I play video games as escapism from the fact that eggs cost $8 a dozen now lol",
      "yup. You could get a 4080S for 950$. Now they're charging you more for less. Clown world we living in."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "4080"
    ],
    "title": "Upgrade after 11 years: 780 Super to 4080 Super",
    "selftext": "After 11 years I have finally upgraded to a new build. Going from a Palit Geforce GTX 780 Super Jetstream 3 GB that I bought in November 2013 to an Asus RTX 4080 Super Proart 16 GB. My old CPU was an Intel Xeon, now I use an AMD Ryzen 9 7900.\n\nTiny new box, huge upgrade. Very happy with it. And yes, I will add a 120mm Noctua fan under the PSU, still waiting for the fan grill to arrive.\n ",
    "comments": [
      "...780 Super?",
      "Its part of palit naming \"Super JetStream\" , not Nvidia model name",
      "You are going to notice the difference, I daresay.",
      "They are already here, as expected. I couldnt care less what Nvidia will announce in January. Happy with what I have now. Will serve me well for years to come, and building in an itx case for the first time was an absolute blast. No regrets at all.",
      "waits 11 years but can't wait 10 days for concrete 5080 details :D\n\nEdit 11 (lol) days later... now we can see 40 users locked out of good framegen, and 16GB gpu for $750.. 5080 at $1000.... everyone believed the fake leaks, fell for the FOMO of tariffs... \n\n40 series users spamming reddit asking if they should sell/return their 40 series looool....",
      "Waiting for the YuO sHOuLD HaVe WaItED for tHe 5080 people",
      "Nah bro 15% performance increase max, wait for the 8090 ti super for a real boost /s",
      "This subreddit in a nutshell, at least is not another 4060 bought at full price lol",
      "Sums up the lack of optimism for the 5000 cards people have i guess.",
      "i cannot wait to spend $1700 on a 16GB gpu!!!",
      "There was no 780 Super. Super Jetstream is Palit’s name for it.",
      "You can finally play Crysis",
      "Can’t think of a single reason why? Maybe they couldn’t afford it? 🤡",
      "Why did you wait 11 years were you in a coma or something",
      "This loser is going to misguide so many of you because the 10k series was just rumored and will destroy all other cards. Just wait for those to come out /s",
      "2080 ti / 9900k is still great though",
      "He waited 11 years, he could've waited one more month.",
      "Congrats, earlier this year I build similar system in a Lian li h2O a4 case. 7800x3d same Asus GPU. It's great",
      "only takes 10 days to know",
      "not even a month at this point, but apparently pointing out that a much more powerful version of the same card is going to be released in the immediate future is the most taboo thing you can do on this sub. It's like they personally fought tooth and nail to sell it to them and they're working overtime to make sure they don't refund it and get a better newer card"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "4080"
    ],
    "title": "NVIDIA GeForce RTX 4070 Ti now up for preorder in China for same price as canceled RTX 4080 12GB - VideoCardz.com",
    "selftext": "",
    "comments": [
      "$1000 and up for xx70 class performance is insane",
      "Waiting for 4050 for only 699$",
      "If you thought that was insane, wait until you see people posting builds with these things in them.",
      "Nvidia can go fuck itself with these prices. \n\nMining is over. People will not buy mid level cards that should cost ~ 500$ for 900 anymore.",
      "This subreddit went from \"Nobody will buy a 4080\" to \"Check out my new 4080\" real fast.  So yeah people will buy these, what else are they gonna do?  Buy a 7900 XT?  lol",
      "With the performance of a 2060",
      "So the card sucked enough for them to lower the name, but not the price.  Classic.",
      "this is such an embarrassing generation, man",
      "On a dedicated sub such as this one it will look like loads of people got one.\n\nBut looking at inventory it really looks like most people aren't wasting their money on one.",
      "There's levels of insanity from both sides of the equation -- my sister who's impulsive and terrible with money was bragging to everyone how she got her kid a gaming PC for xmas, she showed me on her phone it was some generic predator desktop with a 3060ti for the low low price of $2500 (no monitor included)\n\nThis is the same type of person that won't consult or ask anyone for input or guidance on buying X/Y/Z. So people are still lighting $1000 on fire from the other side of the market as well.",
      "2060 super*",
      "I can't figure out how prices doubled from one generation to another and people are still guzzling down whatever Nvidia offers.  \n\nIf I'm Apple/Sony/Google right now, I'd be taking notes. The only lesson learned here is that consumers (even the ones who think they're smarter than the average) can't help but buy regardless of the price. \n\nThrowing my savings into AAPL before Apple wise-up and charge $2000 for iPhones.",
      "I can see the internal Nvidia pricing meeting now...\n\n**Marketing Lead:** Sir, 4080s are not selling well, we should drop the price of the 4070Ti!\n\n**Jensen:** NO!!!  No one will want a $1000 4070 card, keep the prices high.  They'll buy the 4080s instead.  This is all going as planned...  \\*evil snicker\\*",
      "Don't buy them, force them to lower prices to sell. But who am I kidding, you idiots will but them either way.",
      "For real, the 4080 at most should be 799$ but instead they get fucking greedy and charge 1200$+ to try and get customers to spend 300$ more on a 90 series\n\nAbsolutely greedy I hope they lose millions",
      "You mean the generation of idiots buying these like it's a CoD penis enlargement skin?",
      "No, it's because of consumers that keep buying these things. What do you think would happen if everyone actually truly said \"screw this\" and didn't buy these things? That Nvidia and to a lesser extent AMD wouldn't drop the price? They're only allowed to keep doing this because people enable it.\n\nIt's frustrating when people refuse to put the blame where it is mainly due in today's world. I'd list other examples but they involve politics which is against the rules here so I'll leave it at that.",
      "If prices are to remain like this, once my 3080 hits the dust I'm just going to retire to being an old man, watch Coronation Street and buy a newspaper with a television guide on it. \n\nBeing tech literate is too expensive",
      "I'm shocked! It's like nVidia is a greedy big corp that only cares about the bottom line and doesn't really care about gamers at all... Simply shocked...",
      "The name should be lowered 2 tiers to 4060ti though XD"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "4080"
    ],
    "title": "Cyberpunk 2077 DLSS 3.8 vs DLSS 4 Comparison - Massive Image Quality Improvement | RTX 4080",
    "selftext": "",
    "comments": [
      "* Bench is not mine to be clear\n* Performance wise, looks like 3-4 percent hit (least on 4080) (others reported between 0 to 5% hit on 4070/4070S, in 1440p / PT / Performance / FG)\n* Also RTSS reports higher VRAM usage from what I see (\\~500mb)\n* 1440p / Max / PT / DLSS Quality / no FG\n* 30-35fps Native\n* 57-67fps DLSS4 Quality\n\nso between 60% and 120% increase in performance with \"***no visual downgrade\"*** (at least in this example)\n\nNo wonder Nvidia is going the AI route.\n\nEDIT: Finally manage to test it - oh boy its so good. There are still some ghosting and shimering, but nothing close to what was before. Right now, running 4070S with 5600 and 32GB of RAM, doing 1440p / PT / Performance / FG - 90-120fps depending on the scene. Its just so good.",
      "I dropped the new DLSS files into Horizon Forbidden West and went from like 140-150 to 170-180 at same settings, its insane how much faster new FG is\n\nEdit: Also about 3-400mb less vram usage\n\nEdit 2: I just checked see if the almost like garbling/distortion around UI elements was still there in HFW and its seemingly gone, its an even bigger improvement",
      "Another reason the focus on AI is because getting smaller nodes from TSMC is getting increasingly more difficult which is where the biggest boost in performance/efficiency comes from. I personally think the tech is incredible and I'm happy someone in the gpu space is innovating. Hoping Intel and AMD can keep up. Competition is very important.",
      "Visual downgrade?! DLSS is noticable visual improvement compared to native TAA. And it runs at double the fps.",
      "Regarding the performance hit, does this mean we can drop to a lower preset and get better performance/IQ than before?",
      "Someone else said in the 2077 patch post that 1440p performace looks incredibly good, so my guess is yes",
      "Yeah most of the people on Reddit can’t understand we’re soon going to hit a wall where you basically can’t get past unless there’s a technology breakthrough. Screaming fake frames bad and only want better and better raster is really dumb.\n\nExpecting 40-50% raster uplift every new generation is not it.",
      "Ray and path tracing is really computationally heavy. Playing some of these demanding games with full rtx features brings every card to a crawl.\n\nGetting to playable frame rates wouldn't be possible without AI. The node advances will hopefully eventually get us to 50-60 fps with the full rtx suite in future games with AI getting us beyond that.",
      "I just tried the new patch on my LG C9 with 4k Performance mode and it looks absolutely insane! I still can't believe it. Have to wait for the mods to get fixed though",
      "Wtf? Really?!",
      "the little shimmering is completely surpassed by how everything generally looks better with DLSS quality",
      "do you consider shimmering and high frequency specular noise to be artifacts? because boy howdy does smaa have a shitton of them",
      "This is what I'm saying. Usually you need to sacrifice quality for performance. With the TNN model you are gaining performance without the sacrifice of the quality (unless some pixel peeping ofc). Its great improvement.",
      "Non-temporal AA methods you say?\n\nDLSS also looks better than SMAA or FXAA!",
      "The DLSS file will work fine but you won't get transformer unless game has the option or you force it with the upcoming app",
      "Nah bro gonna send you a keylogger",
      "Has anybody tried moving the transfomer dll to another game yet? Does it work?",
      "Just tried the same with the witcher. The new FG is insane man.\n\nEdit: Also tested on Ghost of Tsushima and similar fps gain. This is great.",
      "Cyberpunk suffered more than most on old model at anything below quality was borderline unplayable smearing and ghosting. So very few other games were that badly affected.",
      "Looks totally playable on my 32inch 4K OLED monitor.\n\n\nSome flickering on metal fences at a distance. Such a difference from the old model it is wild."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "4080"
    ],
    "title": "Upgraded from 1050 Ti to a 4080 Super. The size difference is comical!",
    "selftext": "",
    "comments": [
      "Did you eat fried chicken before opening the 4080? Lol",
      "The fingerprints are insane lol",
      "Old build: i5 8400/1050Ti/16GB3000MHz/Z370/Seasonic M12-II 520W 80+ Bronze/250GB SATA SSD and 1TB HDD/Fractal Design Focus G\n\nNew build: R7 7800X3D/4080S FE/32GB6000CL30/B650E/2TB Gen4 NVME/240MM AiO/Corsair SF750/Dan A4 H2O\n\nWent from ATX mid tower to an SFF build.",
      "I swear I didn't! It didn't look that bad off camera, idk why",
      "Performance difference is comical too.",
      "BBC - Big Black Card :)",
      "Ikr! Should have worn gloves when building lol",
      "Had a really similar experience of i5-6500 + 10603gb ATX to 4090 SFF, I’m living a dream and hope you are too!",
      "Legit thought OP sanded it down, glad it's just fingerprints.",
      "Just making jokes. Lol congrats on the upgrade. Just got my 4070 Super FE and love it! Enjoy it!",
      "![gif](giphy|UoYA5jnXE5V7u4MJh7|downsized)",
      "Nope, it's pointless. The 1050 Ti has the old hardware nvenc encoder, which isn't as good as just one of the 4080's encoders when both are using H.264. The 4080 can do AV1 encoding as well, which is even better. Performance impact is negligible.",
      "muddle shame marvelous illegal zonked person disarm literate like imagine\n\n *This post was mass deleted and anonymized with [Redact](https://redact.dev)*",
      "you’ve got some oily fingers my guy",
      "Phone cameras tend to exaggerate smudges or dust from my experience.",
      "Upgraded everything, essentially a new build.",
      "No need",
      "eSports and indie games so far. Finally can try out some AAA gaming as well.",
      "Ya but it was a SUPERCLOCKED",
      "Might also just be that it was outside in the cold. I've had it happen to a lot of different things in the past when it was at the back of the delivery van."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "4080"
    ],
    "title": "4080 + 7950x build",
    "selftext": "",
    "comments": [
      "Love the fish tank",
      "I'm a simple man. I see a glowing box and I click the arrow.",
      "This is the HYTE Y60, for anyone who is interested. I love the way it looks, honestly, but not so crazy about the fact that it's strictly vertical GPU mount only.",
      "Fuck that GPU is big. “You want me to put what where”!?",
      "Even with the pictures from the OP I don't believe anyone would buy the 4080",
      "This is my personal machine and I went for a balance of power and efficiency.  7950x CPU on the ASUS Prime 670E mobo in the 105w Eco mode.  So far I haven't been able to get the 4080 above 200w but it's not hooked up to a 4k monitor yet.  64GB DDR-5 6000 ram and dual 4TB NVMe drives pci 4x4 (between 6-7GB/sec read/write speeds).  No other drives, wanted simple and clean with everything on the motherboard.  The low power nature of this system could probably run on a 550w PSU, but it has a 1000w Thermaltake to be on the safe side.\n\nI'm not a heavy gamer, I do play games on it but my main thing is Unreal Engine development, 3dsMax, PS, things like that.  I like doing 3D art and game development for fun and practice.\n\nFull disclosure I am an NVIDIA employee but I'm not here to promote anything I promise.  Just a gamer and game developer who wanted to build a real modern rig on the latest gen hardware.  I really admire all the posts here and killer machines, so wanted to jump in with my own.  I also really admire those AMD cpu's, even with -5% speed loss in eco mode that 7950x is fast on code compiles!",
      "Yeah it is big, almost the same size as the 4090.  I wish it didn't cover up so much of the mobo, I partly got the Asus Prime because I liked the way it looked.  I also didn't plan on installing it vertically, really trying it out since it's something this case can do.",
      "It is meant for liquid cooling.\n\n[Here is mine](https://imgur.com/O1jxwZE.jpg)\n\n5900x / Asus 6900XT LC",
      "If you vertically mount an air cooling card in this case it heats up the front glass and gets bad thermals.  I'm not saying you can't do it...  It just isn't ideal.",
      ">Full disclosure I am an NVIDIA employee \n\nYou work for Nvidia and still thought buying a 4080 was a good idea?\n\nDear lord, we are all screwed.",
      "Good to see cases still have 3.5 jacks",
      "It's been weeks and I still can't find those 4090 at $1600 y'all keep talking about, all i see is scalped prices at $3000 or out of stock.\n\nMeanwhile the 4080 can be purchased everywhere for $1300 to $1500.",
      "Hyte y60",
      "What do you mean almost. They are identical, the only outside difference is the text that says 4080 or 4090.",
      "The 4080 has the same price to performance as the 4090. You pay 30% more for a 4090 and on average it's 30% faster. OP wanted low power consumption so the 4080 is a no brainer.\n\nEdit for the downvoters: facts don't care about your feelings. Go look up real world benchmarks now that both cards are out.",
      "RTX UE evangelist, so I contribute to developing the UE software that nvidia works on and also help devs understand things technically/implementation-wise.  My background is in game development (I worked at Gearbox, EA, THQ and several indies including my own).  So yeah it is something I really enjoy.",
      "4080 is a good gpu but terribly priced. But it can be bought at msrp whereas 4090 is scalped everywhere. So that extra money doesn't scale well.",
      "Gpu terrarium",
      "4080 though :(",
      "soooo….it’s not the same PC at all?"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "4080"
    ],
    "title": "MicroCenter confirms GeForce RTX 4080 US pricing, from $1199 to $1549",
    "selftext": "",
    "comments": [
      "Let the scalpers scalp this card. Only a dumbass would pay 1550 for it.",
      "No one is buying this card for close to $1599 when you can get a 4090 for that. It makes no sense.",
      "If you can afford a 4080 you might as well get a 4090.",
      "Scalpers still trying to sell 4090s lol.",
      "$1549 AIB boards are taking the piss and they know it.",
      "Was about to say, if you’re already spending $1200… but of course this is what Nvidia wants.",
      "I think they only want whales to purchase until 3 series stock is depleted, that’s when we’ll see price drops. \nHonestly I would have expected a bigger drop in 3 series at this point. Demand still must be hot. \n\nI’ll be passing until the economy adjusts the pricing to reasonable.",
      "You have to be pretty stupid to be willing to spend much over $600-700 for any 80 class card IMO.",
      "![gif](giphy|l0ExayQDzrI2xOb8A)",
      "imagine buying an OC 4080 for the same price as a 4090.",
      "It’s down to 1900-2000 on stockx and dropping fast",
      "From the amount of people that have already bought 4090's at full price or more, would not be surprised if the 4080 sells out as well. \n\nCan't believe my $699 3080 FE purchase is looking *this* good right now. I already thought the price was high. I am naïve I suppose.",
      "You’ve got just as good of a chance of finding a $1600 4090 as you do a $1200 4080…\n\nEither way, if you can’t afford a $1600 card you also can’t really afford a $1200 card.",
      "what a scam",
      "What a laughable card, so embarrassing from Nvidia",
      "Why wouldn’t you just spend $50 more for a 4090? Anyone buying a 4080 for $1550 is insane",
      "The point is they're both in the same realm of high prices especially when you add the cost of the total build. If the $400 is a big difference to you, you are almost certainly not a person that should be buying a 4080 at $1200.",
      "I don't get it. My local microcenter sold out of 3080s in the last couple of weeks, right with the new release. Those 3080s are still 850 or more. \n\nJust feels weird there is still that much demand for GPUs, ones that are 2 years old at this point.  I'd get a 3080, but at like 500 bucks and no more.",
      "I don't know. Who would pay $1200 for this?",
      "People are fixated on certain brands / models and will pay more for that. In my country, at least on launch day, the Asus cards were USD 200-300 higher than Gigabyte / MSI, and even more compared to some others. The Asus got sold out super quickly nevertheless. Nevermind they all perform pretty much the same and have similar aftersales support."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "4080"
    ],
    "title": "[Gamers Nexus] NVIDIA GeForce RTX 5080 Founders Edition Review & Benchmarks vs 5090, 7900 XTX, 4080, & More",
    "selftext": "",
    "comments": [
      "4080ti confirmed.\n\nIt's funny we thought the rtx 4080 was bad but the fps gains over the rtx 3080 were still quite significant. Now we have a 10% gain from 4080 to 5080, which is absolutely ridiculous.\n\nOn top of that, the rtx 5090 which is priced double compared with the rtx 5080 and yet it does not deliver double the performance.\n\nUnless the MFG is going to save the day, we can safely say this generation is the worst one Nvidia ever released.",
      "That's what happens when you don't have competition, welcome Nvidia to Intel era of generational uplift...",
      "RTX 4080 was only \"bad\" because of the price increase. 699 vs 1200 was ridiculous.\n\nIf the 4080 was 699 or 750 it could have been regarded as one of the best jumps gen-to-gen, especially with features like frame gen\n\nNow to be fair, this gen we did see the price get lower (1200 vs 1000, or stayed the same if we factor in the Super) but still overall its bad because waiting 2 years to get 15% uplift at the same price does not look good either.",
      "They could've skip this gen. and no one would notice. DLLS 4 update is nice, but has nothing to do with 50series.",
      "https://preview.redd.it/13lycj2d3yfe1.jpeg?width=800&format=pjpg&auto=webp&s=58a6fdd01808e9f10f9821f9b91892ad06ece3f2\n\nIt s a 5070 rebranded 5080",
      "What Nvidia did here is even worse. They made a 5070 or 5070 ti level card and named it 5080, and priced it at 999.",
      "This entire generation is just literally just FG. Genuinely they could've called the 5080 a 4080ti and no one would notice it's a \"different architecture\".",
      "Wow that's terrible, stay clear",
      "I'm more baffled by the amount of people who are like \"the 5080 is bad so I'm staying on my 1070 / 2060\". The only people who *might* have a point here are people with a 40-series card.",
      "I remember people saying Nvidia would never sleep like Intel did. LoL",
      "Is this the worst gen in nvidia’s history lmao? Even the 5090 is essentially just a 4090t.",
      "Yup the super was the price the 4080 should have been from the start. NVIDIA was smoking crack with the original 4080 MSRP",
      "He's referring to AMD not releasing a competitor to higher end cards this generation. Chill out.",
      "Nvidia are behaving like Intel did pre Ryzen. If AMD failed with Ryzen, Intel would have still kept tick–tock model and i9 would have had 8 cores or something\n\nNvidia needs the same kick in teeth but they are too far ahead",
      "And here I thought we’d just left *this* party…\n\nIt’s why I wanted to hope for Intel’s GPU efforts to be a smashing success, to keep *some* competitive pressure on nVidia, since AMD was fading.\n\nBut then Intel’s 13th & 14th generation CPUs began destroying themselves, Intel hemorrhaged money & lost their pro-GPU CEO, and may never have the $$$, the leadership, or even the technical skill to compete in the GPU market.\n\nAnd nVidia sleepwalks on gaming GPUs, both because of dominance in market share & also because, now that AI provides 9 of every 10 US Dollars of income, they have *ZERO* need to innovate.",
      "Amazing. The 5080 barely edges out AMD's 2 year old XTX 🤣",
      "This is a great chart, thanks for posting.  Where’s it from? I don’t recognize the logo.",
      "That's what they tried with the original 4080 and received massive backlash. Now they've done it again but this time there's no backlash since everyone has forgotten about it.",
      "Yeah, I've commented this elsewhere, but with my 3080 I'm kinda looking at 5070 Ti as the price bracket upgrade.\n\nBased on the 5080 benchmarks however it looks like I'll wait for 60 series, which will probably be just around time GTA 6 releases on PC. I'll just buy a wardrobe or something now.",
      "I can understand 40 series owners who typically upgrade every gen being disappointed, but for someone like me with a 10gb 3080 I'm still planning on upgrading if I can get a 5080 at msrp. 50%+ performance jumps and noticeably more VRAM will be a huge improvement compared to what I have."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "4080"
    ],
    "title": "Nvidia Korea's explanation regarding the 'Unlaunching' of the RTX 4080 12GB",
    "selftext": "Source: https://m.bodnara.co.kr/article/view.html?num=182039",
    "comments": [
      "So 4080 16GB will still be priced $1200, and what name/price will they give to the \"old\" 4080 12GB?",
      "Based on the 192-bit bus width and the >50% reduction in core count?  4060 Ti if they're being honest, 4070 if marketing get their way.\n\nEdit: And on this criteria, yes, the 4080/16 would be more accurately termed a 4070...",
      "Nvidia is just upset they got caught trying to sell a 4070 for the price of a 80-series.   \n\n\n(Even though the core itself seems to be more like 4060 with more memory than necessary)",
      "This explanation is weak because how did you not foresee that there would be confusion by marketing your cards this way?\n\nYes I know the real answer is that they're scrambling to save face after the backlash, but come on, be honest or make up a better excuse.",
      "So, was the original naming just a ploy to essentially make 4070 get accepted as 4080/16? Hmmmm...",
      "There’s absolutely no way the 4080 16GB was going to be a 4060. One would have to be pretty gullible to believe that…",
      "There's a rumor floating around that the 4080 16GB, as we've received it, was originally the 4060. Apparently nVidia had a decent chunk of the 4000 series design already done when the 3000 series launched, and the prices were always going to be this jacked up, but it was going to come with ***massive*** performance uplift. Then, they went in too hard on mining, lost a shit ton of money on making cards that never sold, and rearranged some SKUs accordingly.\n\nGoing off of that logic, it looks like the 4090 was originally supposed to be the 4080, and there's two chips we haven't even seen yet that were going to be the \"real\" 4090/4080Ti.\n\nEDIT: I was wrong, the rumor was that the 4080 16GB was going to be the 4070.",
      "Nvidia pulled it because they were like \"awww shit guys they noticed that the 12gb was garbage next to the real, full fat 16gb version, pull it now and slap 4070 stickers on it later\"",
      "I'm still not sold on the idea of the 4080 16 being like 40% (?) behind the 4090. A 102 die with 12000 cuda cores would have been more atractive for the price. It will be basically a 1500-1700€ card here in europe.",
      "I first read this as North Korea lmao",
      "4080 16GB actually fits all the historical trends of an 80-class card since Kepler, minus the Ampere series. They have all been on the x04 die of their respective generations ranging from the smallest at 294mm2 (GTX 680) to the biggest at 545mm2 (RTX 2080) and on a 256-bit bus. Again, the exception to this rule over the past decade is Ampere. The 4080 16GB on the 103 die at 379mm2 is comparable to say the GTX 980 die size.\n\nSo from a specs standpoint, its not out of the norm.\n\nWhere it doesn't fit? The ridiculous $1200 asking price. Realistically the 4080 16GB should be in that $700-$900 range.",
      "Let’s all be smart consumers and skip the 4000 series, at least for now",
      "Man that's even worse. They wanted to make a gigantic 4080 all along?",
      "This was not a mistake, this was them trying to get away with it, and it serves them right that they were torn a new one.",
      "As much as I dislike the 4080 12GB and 4080/90 pricing, that is not at all market manipulation.",
      "Well admitting that your screwing consumer with a shit 4080 and a shittier one at 3090 and 3080ti prices they must think amd will release some garbage gpus this year",
      "Only 53% of the cuda cores of their full big die. 70 class cards of the past 5 generations fall within 50%-55%.",
      "You're just plain wrong. [See for yourself](https://i.imgur.com/zFJcOG0.png)\n\nMaybe if you had even attempted to back up what you were saying you would've realized how wrong you were",
      "The 4080 16GB is more of a 4070Ti with the performance gap",
      "full fat version is still trash btw. Performance may be in line with other x80s, but it's more nerfed compared to the top end die than usual despite being 2x as expensive as any previous x80 card."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "4080"
    ],
    "title": "MSI RTX 40 SUPER leak confirms RTX 4080 SUPER and RTX 4070 Ti SUPER with 16GB memory",
    "selftext": "",
    "comments": [
      "If the prices are true then it is not worth like 4070ti super for 1,1k that's crazy expensive",
      "4070 TI SUPER is a dumb name i'm sorry",
      "that 4070 ti super looking spicy",
      "In the pic the 4070 ti super (lol name) costs 1300+ euros.\n\nExtremely DOA.",
      "Am I the only one that thinks it’s weird there’s gonna be 4070 ti super tf is a ti super 😂",
      "Calling the 4080 Super **great value** is sort of ridiculous especially considering its regular counterpart is objectively *poor value* and these listed prices are mere leaks at this stage",
      "Prices are popping up at more retailers, like [this one](https://www.meistersinger.at/shop_search.php?search_string=GEFORCE+RTX+4070&cat=0&verfug=0&man=&list=0&sort=price&order=desc) and [this one](https://www.meistersinger.at/shop_search.php?search_string=GEFORCE+RTX+4080&cat=&x=0&y=0&man=).\n\n* 4070 Super 20% more expensive than 4070\n* 4070 Ti Super 8-10% more expensive than 4070 Ti \n* 4080 Super replacing 4080 at the same price\n\nUS MSRP could be $699 for the 4070 Super and $849 for 4070 Ti Super.",
      "4070 Super Saiyan God Super Saiyan",
      "That naming scheme has big iphone Pro Max energy though",
      "Leaked prices:\n\n* RTX 4080 SUPER: 1230.30 - 1355.80 CHF  \n* RTX 4070 Ti SUPER: 1,060.40 - 1063.4 CHF  \n* RTX 4070 SUPER: 777.50 - 848.70 CHF  \n\nCurrent GPU prices in Switzerland:\n\n* [MSI 4080: 1'308 - 1'815 CHF](https://www.galaxus.ch/en/s1/producttype/graphics-card-106?filter=t_bra%3D331%2Ct_347%3D1060010&so=5)\n* [MSI 4070 Ti: 769 - 901 CHF](https://www.digitec.ch/en/s1/producttype/graphics-card-106?filter=t_bra%3D331%2Ct_347%3D1228753&so=5)\n* [MSI 4070: 527 - 739 CHF](https://www.galaxus.ch/en/s1/producttype/graphics-card-106?filter=t_bra%3D331%2Ct_347%3D1246865&so=5)\n\n\nIf these prices are correct:\n\n* 4080 SUPER will be **great value** *(more cores for lower price)*\n* 4070 Ti SUPER will be **slightly better value** than 4080 *(fewer cores but lower price)*\n* 4070 SUPER will be **worse value** than existing 4070 Ti *(fewer cores for same price)*",
      "The only problem is social media comments represent like 5% of the market.  Average Joe Gamer is buying whatever is on the shelf to replace his prebuild GPU.",
      "4080 SUPER SUPER lmao",
      "> 4070 would drop to $499\n\nUnlikely to happen with 4070 still selling very well, and 4060Ti 16GB already occupy $499 slot, so the whole lineup would have to be pushed down too.\n\n> 4070 Ti Super at $799\n\nThis may happen as 4070 Ti already ceased production.\n\n> 4080 Super at $999 or $1099\n\nThis can happen if they feel threatened by the 7900 XTX (which is gaining market share much faster than the 4080, due to aggressive discounts).",
      "It is to us as gamers to vote with our wallet and not by comments (they don't care about them)\n\nI will move to amd for gaming they are fine",
      "Wtf are you on in wanting to upgrade already from a 40 series to another 40 series?  Same applies to rest of the 40 series owners complaining they can't upgrade because of prices.  If you can afford to upgrade (twice) every generation, you should've bought the highest or even the second highest tier card at launch.",
      "I'm still holding off until next gen. This refresh could be nice but what's the point in buying now if in Q4 we get cards that outperform all of them at lower power draw\n\nEdit: to clarify if you have like 30 or 20 series then I'd say it's worth waiting (that's the position I'm in) if you are on older than that and have been waiting years then of course go for it. Me personally I'm running a SFF case so the more power in less space I can get the better hence why I noted lower power draw",
      "lol a bs scam? wtf does that even mean? It is a NAME",
      "The average mid range GPU is $1000 or more now, what the hell happened man, I just want affordable cards again that arent my entire months paycheck.",
      "If the 4070 Ti was originally the 4080 12GB, then would the 4080 Super be called?",
      "yea i find it weird but its just a name after all"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "4080"
    ],
    "title": "4080 handles Cyberpunk very well on Ultra 3440 x 1440p with Pathtracing",
    "selftext": "",
    "comments": [
      "No shit, it's a 4080.",
      "that was my first thought. \n\nI bought a 3080 at launch and THAT was playing Cyberpunk \"very well\" even with all the jankiness of the bugs and no patches.\n\na 4080 even with RT overdrive (full path tracing) should be more than fine.",
      "4090 or go home! /jk",
      "Second best gpu on the market handles gaming well, who would have thought xD",
      "Ofc, it would perform well its the “second” best gpu on the market",
      "Yeah 4080 is a fantastic card just needs to cheaper. In the UK some 4080s are same price as some 4090s it's bonkers.",
      "Same card, same resolution. Its awesome🫶🏻",
      "The amount of people who think \"my $1,500 GPU handles it well\" is a good argument against performance concerns is truly astonishing.\n\nEspecially when you nail them down and find out \"well\" means 1080p30 processed to hell and back to look like 4k60. That's fine for taking screenshots, but terrible for playing an FPS.",
      "In the UK some 4090s are twice the price of some 4080s. That is also bonkers.",
      "When it comes to heavy ray tracing titles and the path tracing, the 4080 very much outperforms the 7900xtx.  In this title for example the 4080 can put anywhere from 30 to 50 percent more fps using rt and dlss.  In most ray tracing titles expect at least a 10 percent gap in favor of the 4080.  The frame generation tech of dlss vs fsr the dlss is generally better.  Where as if you are running no rt and no frame generation the xtx is the better option if you also don't mind the extra power required because it is a bit cheaper out of the gate.",
      "Where is the fps tho? DLSS? FG?\n\nMost 4000 series from 4070 and up can do this at 1440p with DLSS and FG really.\n\nCyberpunk 2.0 + PL is an amazing game.",
      "😂 I can only imagine how good the 4090 would run this game at the resolution I’m playing at",
      "What about it? Runs and looks great even on midrange cards.",
      "The 7900 xtx is on par with the 4080 and even outperforms it in some stuff. If you add raytracing though, it is weaker.",
      "Define 'very well'?",
      "It's just a word in the settings. I don't know how else to say it. The game on medium looks phenomenal.",
      "My wallet doesn’t handle 4080/4090 though 😂😂",
      "It’s unreal how much better this is compared to starfield",
      "I get about minimum 120 fps, sometimes caps to 165",
      "7900XTX is faster in raster and has more VRAM. 4080 is more stable and compatible with its drivers and games although AMD has come far in this department too. 4080 is worse value although the XTX isn't an outstanding deal either. 4080 is more versatile being able to run RT as well as being better for productivity work like AI, engineering and CAD and stuff although you probably would look for a Quadro card instead or at the very least a 4090 for that stuff. If I had to choose at same price, I'd choose the 4080 almost every time tbh."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "4080"
    ],
    "title": "NVIDIA GeForce RTX 4070 Ti SUPER GPU Benchmarks Leak: Up To 10% Faster Vs 4070 Ti, Almost Matches RTX 4080",
    "selftext": "",
    "comments": [
      "4080 performance and 16 gigs of VRAM for 799 seems kinda tempting ngl",
      "That’s the 4080 we should’ve got at launch, for the 80 series cost. \n\nNvidia is a bag of clowns.",
      "The 16gb vram are what push me to it over the 4070s, tbh",
      "Think of it this way:\n\nThe 4070 super is a cut down 4070 ti die for the price of the original 4070. The original 4070 still exists as a base 1440p tier card for $549 msrp. \n\nThe 4070 ti super is a cut down 4080 die for the price of the original 4070 ti and replace it altogether.\n\nThe 4080 super is the fully realized potential of the die it is based on, everything that could be thrown at it thrown its way, for $200 less than the original 4080 and replaces that card entirely.",
      "Will the 4080S really be worth the additional $200+?",
      "There know exactly what they are doing.",
      "Because people are clearly sick of gamery looking trash lol. AIBs need to catch up. The AMD partners are gamery but have much better looking GPUs, especially XFX and Sapphire.",
      "I'm waiting to see the difference in 4070 ti super and 4080 super. I've got an Alienware 1440p UW, so I wonder is 200 extra worth it if it's only 10-15%.",
      "Everything is relative, but a 10% increase puts it in the gap between the 4070 ti and 4080. So you might as well say that the 4070 ti super almost matches the 4070 ti.\n\n10% uplift is roughly the compute increase, meaning that the 4070 ti memory system is not bottlenecking and well designed contrary to popular belief.",
      "I'm not going to disagree with that but still think 799 for what is essentially a 4080 is actually decent for once\n\nThe only thing wrong with this gpu is it's a year late and \"4070 Ti Super\" is one of the dumbest GPU names I've heard in a long time.",
      "I mean the 4070 super launched at MSRP.... These are not wildly in demand cards",
      "FE’s fit in way more cases. They don’t look like a space ship, and perform extremely well.",
      "3% faster memory and 21% more shaders.  It used to be pretty normal to pay 25% extra for something that is only 10% to 15% faster at the high end. I don't think people at the top really care much about performance per dollar.\n\nFit example the RTX 3080 vs 3080ti, or even 3090.  People will argue it's cause of double the VRAM, but if going from 8gb to 16gb is a rip off for $100 on a 4060ti, then certainly going from 12gb to 24gb on a 3080 12gb to a 3090 is as well. But people would bought them anyway for 10% performance and 24gb even if COVID didn't happen.",
      "The importance of VRAM for gaming importance has been greatly exaggerated. As evidenced by the amount of people that call the 4070Ti unsuitable for 4k.",
      "In my opinion, yes! RTX 4070 Ti S offers great performance, but it does have a way less capable cut down version chip.\n\n>RTX 4080 SUPER graphics card will be using the full AD103-400 GPU with 10240 CUDA cores in total, 320 TMUs, 112 TOPs, and 64MB of L2 cache.\n\nRTX 4070 Ti Super comes with 8,448 CUDA cores + cut down RT & Tensor cores. [More info here.](https://www.makeuseof.com/nvidia-rtx-4070-super-vs-rtx-4070-super-ti-vs-rtx-4080-super/)\n\nEdit. 1/5 price increase, get you about 1/5 core/chip increase. If the price difference is $200, I would pay the extra. But that's just me. For most of the users, 4070 TiS is more than enough for the price.",
      "$799 for only 12gb vram was a crime. 12gb is seriously on the edge of not being enough for a 4k monitor if you want it to last 4-5 years without issue. Even at 1440p at higher settings in some games it could prove to not be enough, certainly at 3440x1440 which is very common with the Alienware ultrawides.",
      "I never said you said they didn't know. I just said they know what they are doing.",
      "Incoming 7900 XTX price drop :D",
      "This is the one to get, IMO.  Of all the Super models, this is the best.",
      "If you hadn't, today you should've just waited another year and have gotten the 5080."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "4080"
    ],
    "title": "NVIDIA RTX 4080 SUPER tested: up to 2.4% faster in 3DMark, similar gaming performance to RTX 4080 [VideoCardz.com]",
    "selftext": "",
    "comments": [
      "Because announcing a new card with a lower price is better PR than cutting the price of an existing card.",
      "Yep. They way they would be able to not admit that the OG 4080 was always priced way too high.",
      "With what drivers exactly? On some of the benchmarks is worse than the normal 4080 which is highly unlikely.",
      "The only super thing is the MSRP. Albeit, Expect AIBs to reach original 4080 price.",
      "Because price cuts are an embarrassing admission that the 4080 was priced too high and didn't sell well. But an all new 4080 super is an amazing new value!!!!!!",
      "For someone like me who's building a brand new build I can't wait for the 4080S. I can see how people upgrading their systems are not impressed though",
      "The price is only good if you compare it in isolation to only the 4080. It is still profoundly insane, even after the cut.",
      "Ain’t nothing SUPER about it",
      "Margin of error, inconsistent benchmark etc. It's not actually strong enough to pull a noticeable lead over 4080 in any case.",
      "It still is....",
      "It’s overpriced and I spent 1200$ on mine lmao.\n\nThis is an inflated priced and everybody knows it but you. Just cause we can afford it and buy it doesn’t mean it’s not overpriced",
      "Slightly overclocked 4080s for $200 off MSRP.",
      "Marketing. Nvidia doesn't want to admit they were wrong with the 4080. I don't even care for this $999 price considering the 3080 was $699. I would have liked to see this closer to $799-$849 myself.\n\nBut that wasn't going to happen given current market/RDNA3 pricing.",
      "It should have been $800 at max",
      "I agree. After all the cost/FPS champ is the 4070 Super. Nothing else scales quite as well. The 4070Ti Super should honestly be cheaper as well. Cost tiers should be $600/$700/$800 but this is NVIDIA.",
      "What 320b bus? This is just a 4080 with 5% more CUDA cores enabled, 10240 instead of 9728. \n\nThe 4080 SUPER is a “price drop” that doesn’t hurt Jensen’s ego as badly.",
      "Yeah, idk why everyone is upset. I'm doing a new build and a 4080s seems like a fair price for the premium performance.",
      "Basically, a price cut for the 4080 would be saying \"yeah... we really messed up guys, sorry\" but a 4080 Super is like \"yo guys check this out, because we're so generous we're gonna give you this AMAZING deal compared to our last one\".",
      "I think they purposefully priced the 4080 to make people buy a 4090 instead.",
      "You can believe whatever you like. I think it's pretty common knowledge throughout the tech press and hardware retail industry that the 4080 sold very poorly.  \n\nAnd Nvidia DID cut the price (or well, it will as of this time tomorrow). that's what the 4080 Super is."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "4080"
    ],
    "title": "NVIDIA GeForce RTX 4090D with 48GB and RTX 4080 SUPER 32GB now offered in China for cloud computing ",
    "selftext": "https://videocardz.com/newz/nvidia-geforce-rtx-4090d-with-48gb-and-rtx-4080-super-32gb-now-offered-in-china-for-cloud-computing",
    "comments": [
      "I hope a YouTuber gets their hands on one to check out",
      "Linus is already frothing at the mouth to run Crysis",
      "GamersNexus will break it down and give us the cool nitty gritty. LTT will do something stupid with it. I’m looking forward to both videos",
      "I could really use one",
      "most likely AI",
      "I wonder how much they are. If they were close to the price of a normal 4090 many people would love them for local AI stuff. But I'm assuming they're quite expensive since they're mostly supposed to be a way to get around the sanctions that prevent selling the actual server GPUs.",
      "Wow that’s pretty cool, is it any good for gaming or more of a niche product?",
      "Nah, leave it to GamersNexus",
      "According to Tomshardware:\n\nThe GeForce RTX 4090D 48GB reportedly sells for around $2,500, $685 more expensive than the vanilla GeForce RTX 4090D, which has a 12,999 yuan ($1,815) MSRP.",
      "Or 4 4k games to max out brainrot.",
      "It does nothing for gaming and the 4090d is a watered down version of the 4090 in gaming specifically the 4090d does not perform as well. Thwy are not allowed to fully spec the 4090 in china so they turned down the power and other areas and named it the 4090d so they could sell it. They are just now I guess doing a version with 48gb.",
      "That's not bad, about the same as getting a 4090 and a 3090 or something I guess. Still expensive for a home user - but so is the 4090 in general.",
      "You make it sound as if the card sucks balls. \n\n>the 4090D offers only 14,592 CUDA cores and 425W TDP, compared to 16,384 CUDA cores and 450W TDP of the RTX 4090\n\nIt still has about 90% the performance, and now with twice the memory. Sounds like an AI beast to me. I wonder if it still supports nvlink",
      "Is this just another AI card to get around sanctions?",
      "Aw man. Me and the boys over on r/LocalLlama be having dreams about such a card! Come on Nvidia/AMD/Intel, launch a crazy inferencing GPU with enough VRAM for the apocalypse for us the unwashed masses.",
      "To play 16K games?",
      "Ironically most applications would take 48gb 4090d for ai over a 4090… so this just subverted the 4090 ban 1000000% and gave China better ai cards (at the consumer level) than the US.",
      "No game currently uses that much vram, so no",
      "By the time 48GB (heck, even 32...) is required by games or that it's worth it, these current GPU's themselves will be extremely slow in comparison making them pretty worthless for gaming. That's why VRAM isn't a huge deal after a certain point these days (for most games, anyway). If you're buying more VRAM because games in 3-5 years might use it, you're probably buying too much (if you need the extra GPU power, by all means go for it). Because when you REALLY need that extra VRAM, might as well buy the latest and greatest in the 3-5 years when you DO need it. That VRAM will come with a huge GPU boost as well.",
      "Cuberpunk doesnt even max out my 4090 with a bunch of 4k texture mods, crowd density, increased ai events and other visuql mods. All this with path tracing enabled. I can’t imagine 48gb being worth gaming for many years to come.\n\nEdit referring to Vram"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "4080"
    ],
    "title": "[Gamers Nexus] NVIDIA's RTX 4080 Problem: They're Not Selling & MSRP Doesn't Exist",
    "selftext": "",
    "comments": [
      "I think this picture alone speaks volumes.\n\nhttps://i.imgur.com/MBPCI9h.png\n\nHow anyone can defend the pricing of this product is beyond me. Its not value it never was. Its a shameless product in every sense of the way.",
      "The most point is the 3090->4090\n\nAlmost same die size. Only a 100 price increase.\n\nThe 4080 with a much smaller die got a 500 increase.\n\n\n\nThe only reasons its priced liked this is \n\n1) the competition is not a threat. Thank amd on that for making the 4080 seem good value to a 7900xtx.\n\n2) they can upsell the 4090 and who dont will get a 4080 at a larger margin. Win-win for Nvidia\n\n3) to sell out 30 series stock with out lowering. Another win\n\n\nI hate the price, but its an evil genius mastermind move from nvidia. Did 3 things at once.",
      "AMD priced theirs reactionary to Nvidia, people thought AMD would be a savior but they are just taking advantage of nvidias high price to charge a lot for the 7900xtx. Sad.",
      "So here is my theory... The consumer that buys the product (you and I) are directly responsible for this. We bought the graphics cards from scalpers a year or two ago at astronomical prices. \n\nNvidia and AMD was propably thinking... Wait a minute, these suckers are willing to pay alot more than we normally charge. Now the scalpers are making the money we could have made... Let's charge way more on our next generation of cards because these suckers are willing to pay those prices for these cards and then we get to keep the money instead of the scalpers.\n\nThat my theory and I don't think I am too far off either.",
      "Yep 4080 is a scam",
      "This year reddit learns the concept of a price fixing duopoly. Wow!\n\nI was also amazed by the copium being huffed.",
      "Titan pricetag for a gimped card. Hmmm I wonder why it’s not selling. But then again the 30 series cards are still near original msrp or even more so I guess they’re not having trouble selling stuff",
      "IDK I'm one of those who bought a RTX 3080 FE at MSRP because at any other price point, the GPU was no longer \"good value\" to me.",
      "I cringe when I see people buy it or people post their builds with one installed. I’m happy you got new gear… but stop supporting this BS",
      "Amusingly, their 7900 XT may actually be a worse value versus the XTX than the 4080 compared to the 4090.  Just 10% cheaper for 15% less performance.  It’s also readily available on Newegg, AMD.com, and Microcenter, whereas the 7900 XTX has sold out nearly instantly.\n\nI expect the 4080 to get a $100 or so price cut which will make it much more competitive against the 7900 XTX.  Similar rasterization with far superior ray tracing, superior upscaling (DLSS vs FSR), frame generation support, better reference cooling, better efficiency, and better drivers.",
      "Why? RX 6600s were under $200 on Black Friday and are still near $200. The RX 6700 10gb is $320 and can play all games at good settings 1440p.  The RX 6800 XT is around $520 right now and can play 4k without RT or max settings high refresh 1440p. And those are the prices for a NEW card. Used you can get even better value if you are willing to risk it. What exactly are you even waiting for value wise at this point?",
      "if theyre not selling why are they the top selling product on newegg?",
      "> people thought AMD would be a savior but they are just taking advantage of nvidias high price to charge a lot for the 7900xtx.\n\nAnyone who thought this REALLY hasn't been paying attention to AMD's history. I literally have no idea why people think AMD is ever going to be some sort of savior from the high pricing of Intel/Nvidia. It *never* works that way. And look at the Ryzen 5000-series - when it launched, they were significantly better than anything Intel had out, and AMD priced them way over their previous offerings. Additionally, they released no non-X Ryzen 5, and no Ryzen 3 at all. Finally, they also said that Ryzen 5000 on a 300-series chipset board was not possible...until such time as Intel started competing again, and suddenly it was possible.",
      "even 899 is too high LOL, stop dickriding nvidia\n\n1199 msrp is making you over-estimate what normal pricing is",
      "The 1080 ti might legitimately go down as the greatest GPU of all time.",
      "I just don't understand the justification for MSRP (for the 4080) being 1200 USD. I know, they want to sell off the 3000 series, but still, almost double the last xx80.",
      "The justification is that it's the price that NV believes will maximize their profit. I'm not sure what kind of justification you're expecting?",
      "1080 ti and 7970 were better I can assure you of this.\nNow, had it had at least the same vram as the literal flagship two generations prior, and was built on TSMC, then yes - that'd be a great card.\n\nIt being the greatest value card ever sold is very much moving the goalpost in favor of your own bias.",
      "I think the video was made before the 7900xtx launched. The charts didn't have the 7900xtx numbers.\n\nThe newegg top seller happened after the launch of the 7900xtx",
      "I'm going to use my 780ti until it turns to dust at this point."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "4080"
    ],
    "title": "RTX 4080 prices in Finland, €1100 increase from 3080 launch",
    "selftext": "",
    "comments": [
      "WTF? These are 4090 prices...",
      "The 3080 launched for around 100,000 yen here in Japan. The 4080 will launch next month for 220,000 yen. It is basically pushing people to buy the 4090, which was Nvidias plan all along.",
      "3080 FE = £670\n\n4080 FE =  £1270\n\nNothing can justify an almost 2x increase, especially since the 4080 to 4090 perf gap is wider than the 3080 to 3090 perf gap.\n\nThis generation is an absolute joke in terms of pricing.",
      "I paid like €750 for my 3080 2 years ago...\n\nIf I were to spend this much on a GPU, I would just as well grab a 4090 for a bit more",
      "This is fucking crazy, to be honest. I miss the days when for that price, you could build a complete gaming PC.",
      "Only a 400 euro difference between 4080 & 4090? Why do I get the feeling the 4080 is an anchor product to entice you to go for that 4090?\n\n 4080 price feels too inflated, relatively.",
      "I feel like for us non-americans it is even more of a joke. Come on, 1900€ for a 4080 and 2500€ for a 4090, seriously nvidia? 4080 in particular is such a bad joke.",
      "Before these were announced I was like \" €1000 should get me a 4080\"\n\nHow naive I was, It might not even get me a 4060 with these prices",
      "Nvidia ain't getting my money until these clowns cut the price down",
      "Wow these prices are crazy... maybw that is what nvidia wants to get rid of all the 3000 supply which they seemingly have lying around in whole warehouses...",
      "Welcome to Europe. Americans are in for a shock when they see these prices. Granted, these include tax.",
      "i honestly hope nvidia lower prices of 4080 16GB down from 1200usd to 900usd at release. but of course thats not gonna happen since the 3080-3090ti are in that territory so they wont :(..... not for a while.",
      ">If I were to spend this much on a GPU, I would just as well grab a 4090 for a bit more\n\nUpsell working as intended",
      "This strategy makes 3080, ti , 3090 , ti etc look very compelling and I understand that this is the plan … But for pc gamers these prices only serve to discourage them for being pc gamers in the first place. . . When ps5 has HFW , Ratchet and Clank and GoW Ragnarok and these are trully next gen and it costs 550 E then pc gaming with these prices look like it fits only a very small niche group of people . Things look really bad and the only hope is AMD and rx7000 series perf and pricing. .",
      "Not only pricing, with their misleading naming* scheme that lead to the cancellation of a product. Oh and did I touch on the PSU requirements if you don't want to risk a fire. There's fires all over this launch.",
      "You could build a decent pc with $1000 back in 2013, with a 7870xt for example to get max settings in most games.",
      "Even $900 is a $200 increase over the 3080.\n\nWe shouldn't accept that, unless we want to accept that the flagship GPU each generation is going to be $1000+.",
      "Tbh, idk if they’d even release the lower tier 40 series cards in the next year…they still have to sell all the 30 series sitting in warehouses. Performance overlaps make no sense.",
      "It wasn't to long ago you could build a top end gaming PC, with the bells and whistles for the price of one of these cards.",
      "I have a gtx 1070. I want to upgrade so bad but those prices are insane"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "4080"
    ],
    "title": "NVIDIA GeForce RTX 4080 gets tested in Geekbench, 30% to 37% faster than RTX 3080 - VideoCardz.com",
    "selftext": "",
    "comments": [
      "I just paid 80,000 yen (550 USD) for a like-new 3080 12GB. The 4080 is launching for 220,000 yen here in Japan. So that’s 3x the price for 37% better performance. No thanks.",
      "for $1200 thats fucking insulting, guess red team is the better alternative",
      "So for people who can buy used 3080s right now for $550 versus spending $1200+ for a 4080 for a 30% uplift in performance, that's a pretty bad offering lol. Of course this is just one metric and may not reflect other applications as well as not having independent reviews out yet since card itself isn't out yet.",
      "This is pretty much in line with rumors we've had all year with the real goal to continue dragging out sales of the 3000 series at a higher pricetag. This is a $699 card and probably will be later into next year but it's priced high to move 3000 series inventory. They know it likely won't see demand, but if it does then they'll gladly take that huge margin. The 4090 is just straight up a high margin halo card for those that'll pay it but absolutely no doubt that a 4080ti will launch that's effectively the same card as the 4090 but slightly reduced cooler size, lower TDP and most of the performance in a more appropriate price tier when the time is right.",
      "Both 4080 and 4070 (ex \"4080\" 12GB) are overpriced as hell in terms of their raw performance and performance increase vs. the previous generation. And to be honest the former deserves to be called 4070 Ti, and the latter maybe 4060 Ti considering the die sizes and memory buses.\n\nI just hope customers will vote with their wallets and Jensen will finally realize they have to stop gouging so much.\n\n8800 GT was released for something like $250. Now 15 years later we must pay $1200 for the same privilege. OK, inflation, shipping, so on and so forth, let's check something recent. GTX 1080, maybe? $600!",
      "Turns out the real scalpers were the Nvidia employees we met along the way.",
      "If it were like $799 or something this would not be too bad, $100 increase for inflation and a standard generational performance increase. But they're asking for $400 MORE...\n\nSo that makes it about 25% faster than a 3090? When we have the 7900xtx that's said to be 50% faster than a 6950xt? Ohhhh boy the 4080 is gonna get devoured.",
      "\"very decent\"\n\nWhat???? That's an amazing card.",
      "I'm just gonna get an AMD RX 7000 card lol",
      "This is actually a $599 card given the die size, and that's being generous.",
      "I had a guy tell me the 80 series were always underpriced and should have been $1200 before.\n\nPeople like him will happily pay for it",
      "They priced out the scalpers.",
      "They're intentionally overpriced to encourage people to buy up the 3000 stock. Nvidia has been pretty clear about this.\n\nUnfortunately for them, AMD is looming on the horizon with cards that look like solid value.\n\nThe 4090 makes some kind of sense, if you accept that the 3090 was already very over-priced. None of the 4080's are priced to sell, they're priced to make the 3080's look more desirable since they've got so many sitting around in warehouses.",
      "$1200 :), that would be nice, but if we can trust the preliminary AIB pricing it's way worse.\n\n[one](https://i.imgur.com/et7Ag7H.jpg)\n\n[two](https://i.imgur.com/hWxPwCe.png)",
      "I can’t see high demand for this Cards if AMD targets this performance for less money the Pricing for the 4080 is out of touch with reality",
      "Who the fuck is buying a Strix 4080 for 1650 when you can get a Strix 4090 for 350 more, or literally any base model for the same price????\n\nAsus needs a reality check with their ROG Tax.",
      "People acting surprised as if the 2080ti wasn’t just as bad perf/price vs the 1080ti lol",
      "Thats really bad considiring the 7900XTX is like %70 faster than the 3080 for $200 cheaper than the 4080\n\nThis card should have been $800-900",
      "That's the kind of mental manipulation that keeps people buying new cards every year.\n\nIs not good.",
      "See you for 5080. Skipping this."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "4080"
    ],
    "title": "NVIDIA GeForce RTX 4070 Ti could cost $799, at least 10% cheaper than cancelled RTX 4080 12GB - VideoCardz.com",
    "selftext": "",
    "comments": [
      "3080 was 699\n\n4070 ti 799\n\n\ni dont like where this is going lads",
      "Can't wait for the 4090Ti myself. The 4090's served me well, but it's starting to show its age. About time to move on I think.",
      "Cant wait for the 4080 ti $1400 and 4090 ti $2000",
      "Insanely overpriced. This card should be 600$ top.",
      "For anyone buying this card.\n\nPlease measure twice and purchase once… it’s the same size as a 3090…",
      "is nvidia making price to performance a linear graph?",
      "Budget PCs about to start at $2,000 🥲",
      "Heard a 4095 will come out after the 4090ti with 5% improve perfomance and $2,700 price tag. Jumping on that one, 4090 is not giving me 200fps in most games at 4k",
      "I just managed to get a brand new Gigabyte RTX 3070 Ti Gaming for 489€ and it's a beast at 1440p. Since the cheapest RTX 4080 in my country is 1500€, I don't think either the RTX 4070 or RTX 4070 Ti can beat the price to performance ratio of my 3070 Ti.",
      "Still can't believe I managed to get a 3080 FE for MSRP from nvidia's website during launch week. Apparently I should have also played the lottery.",
      "5080 for 1600$\n\n5090 for 2200$\n\n\n5070 for 1200$",
      "The $500 consoles will suddenly look more appealing to anyone still rocking a 1060.",
      "The 1070 was as fast as the 980ti for cheaper. let that sink in.",
      "Not in Europe. 1300€ minimum, guaranteed.",
      "Still expensive cuz it won’t be sold in stores for 800$!!",
      "I heard the 4095 is a six slot card that uses two boards with a factory SLI connection.",
      "5070 — $1200 — 1200W",
      "NV increased price because it could. Not because inflation or TSMC N4 being more expensive.",
      "Likewise, the RTX 3070 was as fast as RTX 2080 Ti and cost half as much.",
      "That is such bullshit..."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "4080"
    ],
    "title": "Nvidia RTX 4080 for sale now for tomorrow delivery in UK.",
    "selftext": "",
    "comments": [
      "Yikes. \nThat’s fucking awful pricing",
      "You can get a PS5, Series X and 4k 50 inch TV for less than this",
      "1690€, that’s a whopping 900€ above the 3080 when it was released (not counting the crazy price explosion that followed).\n\nBut yeah, tell me how “inflation” and “taxes” and the “weak Euro” are to blame…\n\nThen again many commercial sellers are still asking 1300€ and more for a 3090 so it kinda fits in the overall pricing schema of today.\n\nCan’t wait for the budget cards - 4070 at 1200€, 4060 at 1000€ and 4050 at 800€… But maybe we get a 4030 for 600€ down the road. LOL",
      "Keep em",
      "You could get a 3080 and a 4k 144hz monitor for less than this, £200 less in fact.",
      "at this price might as well not buy anything this year",
      "![gif](giphy|10JhviFuU2gWD6)",
      "At this price, you might as well go for the 4090 tbh.",
      "Yeah.... imma skip and go for 7900xtx\nFuck team green",
      "I got a 3090 and 4k144 monitor for far less than this, about 300-400 usd cheaper",
      "Aside for the price.. I'm having a tough time people are willing to buy this with the adapter melting issue still not resolved and not a word from Nvidia. If i'm spending that much money on a electronics that shit better be not defective. \n\nbest of luck to those who can get it.",
      "$1700 LMAO, however i think Nvidia will hammer them pretty hard regardless of the shit price",
      "The main difference is that you can buy a 2nd hand top-tier 3090s in excellent condition, with 1-2 years remaining warranty, for 700 Eur (in my case, an EVGA FTW3). That means the 4090 is 3x more expensive being 65% faster. Similar nonsense for the 4080.\n\nI will game at 4K60 with DLSS2, no problem. Not that I have so much time anyways, still finishing games from several years ago that run at 4K100. Will buy the 4090 for 1000 Eur eventually, when the 5090 buyers eagerly drop 3K Eur for next-gen carrot.",
      "Yup. No longer am I buying nvidia",
      "Hahaha. So they’ll have a lot of 4080s left then.",
      "The cheapest 4080 in Finland: 1800€\n\nThe cheapest 4090: 2250€\n\nWhat a yoke",
      "I remember buying a GTX 780 for 560 Euro. That was around the same time that the internet was invented. I really miss the 80's.",
      "Remember when high end cards went for 500 bucks? \n\nI'm out, not buying any new card until they get the price right, might never buy a gpu again. Who knows huh.",
      "If I didnt/wasnt buying a 4090, Id be buying a 7900XTX",
      "Get this crazy ass prices out of here. I'm an enthusiast, not a money tree."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "4080"
    ],
    "title": "Indiana Jones and the Great Circle | 4K HDR Supreme Settings on an RTX 4080!",
    "selftext": "",
    "comments": [
      "And this is without path tracing. IdTech delivers once again.",
      "I can't even get past the shader pipeline screen. Just freezes up. Newest drivers all files verified. RTX 4080 and 7600x processor W11. Looks pretty damn good in those screens.",
      "This game has plenty of headroom for PT. I am waiting for that update before I start playing.",
      "No way will pathtracing be mandatory.",
      "I mean, you don't *have* to turn path tracing on.",
      "I get up to 130fps in 4K DLAA + FG on Supreme with a 4080s/9800x3d combo. I wish it would stay like that. Be ready for the gaming performance to be cut in half with the upcoming patch which will implement path tracing.",
      "This is exactly what I needed to see. I plan on playing this on my 4080 as well.",
      "Yup. With the day 1 patch, it will be available.",
      "Exact display I’m on and also IS what saved gaming for me. I’m 35 and experienced everything and was experiencing a major burnout until I discovered the world of HDR and OLED. Those two features beat out me even owning a 4080 pc, as I strictly go for the best image quality with acceptable performance versus crazy high fos and shit image quality",
      "idTech fucking delivered.",
      "DLAA was causing noise and shimmer in highlights in the temple at the beginning fit me.  TAA fixed that.  Not having that issue?",
      "I think you are confusing the current raytracing rendering people are playing with in early access, and the path tracing update that will give the more demanding option.",
      "Are they adding an official update for Path tracing?",
      "What shader pipeline screen? Haven't seen that. \n\nRuns great in 3090 + 5800x",
      "Very",
      "Use your brain a little. \n\n\nDoes it make sense to make PT mandatory and have only 4080/4090 users being able to play your game?",
      "This looks like it would absolutely shine on my LG C3. It’s probably my favourite gaming purchase tbh.",
      "Only 4-5 hours in but yes it’s super entertaining so far",
      "There's your issue, you watched Gamermeld",
      "Linear but it has semi open world maps to explore. Kind of like sniper elite"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "4080"
    ],
    "title": "NVIDIA GeForce RTX 4090 & RTX 4080 16GB/12GB max TGP and GPU clocks specs have been leaked - VideoCardz.com",
    "selftext": "",
    "comments": [
      "they dont want a repeat of 3000 series. Jump from base 3080 to a 3090ti is like what 20% stock v stock? it got a lot of people to say fuck that. Now if its 50% faster it gets people thinking.",
      "GPU hot potato:  the previously rumored 4070 Ti, which was then rumored to actually be the 4070, is now rumored to be rebranded as the 4080 12 GB.  Unfortunate, if true.",
      "Why there is such a huge difference between 4090 and 4080 cuda cores count? Its crazy.",
      "4080 12gb only has a 192bit bus width\n\n3080 12gb had a 384bit what the hell",
      "What the hell is this 4080 12GB? That's a 4070 camouflaged as a x80 card. Nvidia wants to screw us again...",
      "It also opens a margin for a 4080ti down the road.",
      "that 12gb 4080 looks like trash, maybe 10% faster than 3090ti. \n\nThis is just the ultimate cash grab, that thing will be 750-800$, when it should be a 70 tier card for less than 600$.",
      "Launching two versions of the 4080 each on a completely different chip would be such bullshit. \n\nStop trying to pull fast ones with product naming and segmentation.",
      "Not even that, RTX 3070 had a 256 bit bus.\n\nnVidia is onto some big greedy bullshit again.",
      "It's the same specs as the 4070/Ti 12 GB from previous leaks, with 11k TSE score it's basically the same perf as the 3090 Ti.  Which would mean the \"4080 12 GB\" is about 20-25% faster than the 3080 10 GB.\n\nIt's so bad, I can't see how Nvidia attempts it.",
      "I think the 4080 is gonna be pretty disappointing",
      "I hope it backfires and the xx80 people buy the xx70 instead of xx90.",
      "Don't forget 4080 super",
      "And the 4080 Super TI",
      "Less cores than 3080 too.\nI hope this rumor is wrong, since I doubt the 12GB will be cheaper than the 3080....",
      "*tips head* People can't complain over a price increase of the 70 series if we just rename it to 80.",
      "If this is truly the 4080 12GB, the 4080 16GB and up are going to be the only cards worth anything in this generation. Literally everything else is within Ampere range and will go even lower within a couple weeks when these start coming out.",
      "It's simple - \"3090 Ti performance for a third of a price\". \n\nIt's that simple, who cares 3080 10GB was almost just as good for 700$ - for Gaming, I mean.",
      "rumors 1 week from release are generally very accurate\n\nand the old xx80ti did have 40-50% more cores than xx80 cards. the 30 series was an exception where everything above the 3080 performed pretty much the same.",
      "Chance that NVIDIA are calling the 4070 a \"4080\" so they can jack up the price: 99.9%"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "4080"
    ],
    "title": "NVIDIA GeForce RTX 4080 rumored to feature 23 Gbps 16GB GDDR6X memory and 340W total board powe",
    "selftext": "",
    "comments": [
      "340w sounds more down to earth.",
      "That's also in line with a rumor from a week ago saying TDP would be around 320W. Then adding an additional 20W for TBP seems realistic.\n\nI knew people were blowing all the insane power reports out of proportion from earlier in the year. I have a good 750W PSU in my build currently and it looks like I'll be able to upgrade to a 4080 without having to swap it out.\n\nThe reports of an 800W TDP was probably Nvidia stress testing the hell out of a 4090Ti but who knows.",
      "40XX rumored to exist at some point with some amount of power draw and performance metrics.",
      "Bold of you to assume a crazy rumor has some basis in fact",
      "The article's 1 hour old, there's probably new rumors out already.\n\nI'm not believing anything until the announcement.",
      "It's pretty efficient then. Same as 3080 board power.\n\nEdit: I wouldn't even have to upgrade my PSU. I think a lot of people will be happy if 4080 comes out with this power limit. Or close enough.",
      "I think $999 for 4080",
      "1080, 2080, 2080S, and 3080 have been $700.  So it probably will be.  Otherwise I expect a minor bump for inflation, ie: $750.\n\nThe $1k+ guesses are stuck in 2021.",
      "Let's hope for $699.",
      "Rumor mill:\n\n5 months from release: \"watch out, guys, it's gonna be a 400W GPU!\"\n\n4 months from release: \"OMG you won't believe, this is a 550W GPU!\"\n\n3 months from release: \"HOW WILL OUR POWER SUPPLIES SURVIVE 700W???\"\n\n2 months from release: \"**AHHHHHHH 900W**\"\n\n1 month from release: \"...340W\"",
      "Its definitely rumored to be a graphics card",
      "Oh man. It had been a while since the last rumor post. Was due.",
      "Get those wallets ready, it ain't going to be pretty.",
      "That's what they claimed about the intel ones, too.",
      "Dunno why you're downvoted. With 340W TDP, transients would be at 700W range",
      "ETH has been transitioning to PoS for like 4 years now.  Do you know if this time any different?",
      "My Asus TUF 3080 is 330w which is already insane, this rumor shows similar power draw but holy shit does it heat up a room fast during gaming",
      "Yep, mid september is when ETH transitions to PoS - which will be the real bloodshed for the gpu market.\n\n\nPretty sure both AMD and nvidia are bracing for that... it will be interesting to see how flooded the used market will be.\n\n\nThis mining wave was arguable a lot bigger than the last one, so there might be hundreds of thousands of used cards hitting the streets around the time.",
      "THANK GOD!  I was really worried about your GPU purchasing plan, Samw_72!",
      "The issue for the last 3 gens is power spikes not constant power.  They never admit them to the masses."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "4080"
    ],
    "title": "GeForce RTX 4080 SUPER reviews rescheduled to January 31st - VideoCardz.com",
    "selftext": "",
    "comments": [
      "4080s is just a discounted 4080. That’s how I’m viewing it. Still a a good thing imo even if the improvements are in the single digits.",
      "I mean the 4080 Super is nothing more than a small bump in cores, faster memory by a tad, and a healthy price reduction. I expect 5% at most but the price reduction makes the 4080 Super a competitive offering.",
      "17% price reduction + 5% base OC = what the 4080 should've been on release.",
      "Should’ve been $799, but I guess leather jacket prices went up so what’re you gonna do?",
      "I just imagine it as an OC'd card.",
      "I mean I don’t really need reviews, I wanted a 4080 but wasn’t willing to pay for it, at this new price I’m willing to pay for it. Had the original model just been discounted instead of a new sku introduced I would have bought that. But this is frustrating regardless.",
      "yep, just like 2080 super was in 2019",
      "Issues with reviewers not getting cards on time? \n\nSo punish consumers? Mislead them and not allow them to get the most informed purchase possible? \n\nBut guys just remember it’s really just going to be like a 5% bump at best. Don’t overthink this card.",
      ">So punish consumers? Mislead them and not allow them to get the most informed purchase possible?\n\nsome people here are really complaining just about anything as long as they can complain about nvidia. Your argument would be valid, if the card was a brand new one. This is literally a refresh of an existing with no major spec change, you know what the perfomance will be within low single digit %.\n\n**Also nobody forces you to buy at launch.**",
      "still waaay to expensive",
      "Having a review embargo the day before release is super scummy. Not shipping the cards enough in advance is harmful for the creators who have to crunch to get a review out. Screwing up shipping to the reviewers is just a huge middle finger to the reviewers and us!",
      "Yeah. If it's 80% of a 4090 for $1000, while the 4090 is being valued at $2000 and gulps 450W, then it's a no-brainer. I can just forget that the 4090 exists.",
      "The benefit of 4070 Super was it's large increase in core count at same price of 4070.\n\nThe benefit of 4070 Ti Super was additional 4GB of VRAM and small performance increase at same price of 4070 Ti.\n\nThe benefit of 4080 Super is just a small performance increase at a $200 price reduction from a 4080.\n\nThere's nothing more or less to what the \"super\" line up is.",
      "melodic theory shelter selective full ten homeless aromatic worthless squeamish\n\n *This post was mass deleted and anonymized with [Redact](https://redact.dev/home)*",
      "To replace the confusing Titan",
      "That still doesn't account for the increase. It's not even half of the price difference.",
      "or more cyncically, to make the notoriously bad value titans seems like less of a vanity card and more like just another item atop the stack.",
      "Yeah this screams “let consumers buy before you put out a review”. Super lame practice",
      "3080 price and 3080 availability....",
      "3080 debuted at $699, but saying it’d be the same availability is a bit pessimistic. 3080 had to contend with a banger price as well as a global pandemic. Had it been a normal year I don’t think it’s insane to think it would’ve been available in wide release a few months after launch."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "4080"
    ],
    "title": "NVIDIA GeForce RTX 4080 SUPER rumored to feature 20GB memory - VideoCardz.com",
    "selftext": "",
    "comments": [
      "In case you can't read the article, TL;DR:\n\n**RTX 4080 SUPER**\n\n- Cut down AD102 die, even more cut down than RTX 4090\n- 20GB which means 320 bit memory bus width\n- Presumably GDDR6X\n\n**RTX 4070 SUPER**\n\n- Cut down AD103 die\n- 16GB which means 256 bit memory bus width\n- Also presumably GDDR6X\n\nNo current release timeline for either. But probably Q1 2024 if I had to guess.\n\nSourced from Benchlife via @harukaze5719, report by Videocardz.com.",
      "I mean the cards have always been appealing,  it's just that all of the prices are atrocious. \n\nNew super cards are nice too, but it won't matter much because they're still too expensive in the end.",
      "And just to add context, when Nvidia did this the last time:\n\n* 2080 Super released 10 months after 2080\n* 2070 Super released 9 months after 2070\n* 2060 Super released 6 months after 2060\n\nSo strictly from a timeline perspective, Q1 of 2024 would be appropriate. That would mean 14 to 16 months for the 4080, 9 to 12 months for the 4070, and 5 to 7 months for the 4060.",
      "+$300 for +10 FPS",
      "Also CES is in January and that would be a suitable event for an announcement.",
      "4070S sounds interesting, might get that TBH. Id like to use DLSS and do at least *some* ray tracing which my current card cant do without dipping into the 20s for FPS",
      "Actually not early, one year almost.",
      "Yep the prices suck still",
      "We don't know the name. \n\nTi or SUPER are just marketing names. All they really represent is that Ti and SUPER are more powerful than the regular baseline card. i.e 2080 Ti is more powerful than the 2080, same goes for 2080 SUPER.\n\n> They still released the ti with the 2000 series and the super also existed.\n\nLook anything is possible because NVIDIA release too many SKUs, I mean you need look no further than last generation with the 3060 8GB, 3060 12GB, 3060 Ti 8GB, 3060 Ti 8GB GDDR6X etc.\n\nThey could release this AD102 chip in the article as the 4080 SUPER or as the 4080 Ti or they could be brazen enough to call it the 4080 20GB. Who knows? People are just calling it the 4080 SUPER because it makes sense or that's what their sources refer to it as. I assume they probably are not going to release an FE card model though.",
      "This is huge, feel bad for the early customers though, missing out on the 4gb VRAM hurts the longevity of the card so much.",
      "Personally I have literally zero concerns about 16 GB not being enough on my 4080 before I upgrade it to a 5080 or whatever",
      "Yes, and then if the leaks are accurate but are not what you want, get the 4070 again at reduced price because of the supers.",
      "> Meanwhile new series is only 3 quarters out so people will feel FOMO again and Nvidia again can stack margins.\n\nNot exactly, rumors are that 50 series is being pushed to 2025, around either Q2 2025 or Q3 2025. Reason being is that NVIDIA probably doesn't feel threatened by AMD's RDNA4 since it's going to be like RDNA1 where they target the mid-range, not high end performance, after AMD's top RDNA4 MCM project supposedly has been abandoned.\n\nNVIDIA is likely going to use whatever TSMC capacity they have for datacenter and AI chips first anyways seeing as thats making them big money right now.",
      "Releasing new architectures on a longer schedule, so neither of the options you gave",
      "Man the 4070 super having more vram than the 4070 ti and probablyonlylosesto it by like 5 fps will  be a f you to the 4079 ti users.",
      "If the 4070 super is the same price as the 4070, I wouldn't say it's a bad price.",
      "Nvidia has slides indicating a slowdown in consumer gpu's, also a slide indicating 2025 for next consumer GPU release. And they are speeding up their datacenter AI gpus \n\nhttps://www.pcworld.com/article/1974281/nvidia-sets-2025-date-for-rtx-50-series-cards.html",
      "They’re probably talking more about the 4070/4070ti having only 12gb of vram.\n\nThe reg 4080 will be fine for a while with 16gb of vram.",
      "Does this mean there is no 4080ti this generation? Or maybe the 4080S is just the ti with another name? They still released the ti with the 2000 series and the super also existed.",
      "My guess was holidays Q4 2023, cuz people after holidays would already spent their money.\n\nBut then I realized releasing after Holidays is genius business strategy, cuz then Nvidia gett to sell their old stock first. Then they can sell new stuff at again margins and people who had FOMO and waited out the upgrade will now upgrade.\n\nMeanwhile new series is only 3 quarters out so people will feel FOMO again and Nvidia again can stack margins.\n\nI will probably go 4090 > 4080 / 4070 Super Q1 > 5080."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "4080"
    ],
    "title": "The narrative of \"RTX 4090 is better value than RTX 4080/4070 Ti\" is false and needs to be fact-checked",
    "selftext": "The 4070 Ti & 4080 are better price/$\nThis isn't even getting into how the 4090 **[has spiked to above $2000.](https://pcpartpicker.com/products/video-card/#c=539&xcx=0&sort=price&page=1)**\n\nGPU | Resolution | Price (US$) | avg FPS | $/FPS\n--|--|--|--|--\n4090 | 4K | 1600 | 159 | 10.06\n4080 | 4K | 1200 | 124 | 9.68\n4070 Ti | 4K | 800 | 99 | **8.08**\n4090 | 1080p | 1600 | 279 | 5.73\n4080 | 1080p | 1200 | 251 | 4.78\n4070 Ti | 1080p | 800 | 221 | **3.62**\n\n\n[source for avg FPS: TechPowerUp review](https://www.techpowerup.com/review/pny-geforce-rtx-4070-ti-oc/33.html) *(25 game average)*\n\nGPU | Resolution | Price (US$) | avg FPS | $/FPS\n--|--|--|--|--\n4090 | 4K | 1600 |  142 | 11.26\n4080 | 4K | 1200 |  109 | 11\n4070 Ti | 4K | 800 |  87 | **9.19**\n4090 | 1080p | 1600 |  235 | 6.81\n4080 | 1080p | 1200 |  215 | 5.58\n4070 Ti | 1080p | 800 |  198 | **4.04**\n\n\n[source for avg FPS: TechSpot review](https://www.techspot.com/review/2601-nvidia-geforce-rtx-4070-ti/) *(16 game average)*\n\n\nGPU | Resolution | Price (US$) | avg FPS | $/FPS\n--|--|--|--|--\n4090 | 4K+RT | 1600 | 79.6 | 20.1\n4080 | 4K+RT | 1200 | 55.07 | 21.8\n4070 Ti | 4K+RT | 800 | 43.1 | **18.56**\n4090 | 4K | 1600 |  253.36 | 6.32\n4080 | 4K | 1200 |  184.28 | 6.51\n4070 Ti | 4K | 800 | 141.74 | **5.64**\n4090 | 1440p| 1600 | 383.67 | 4.17\n4080 | 1440p| 1200 |  326.4 | 3.68\n4070 Ti | 1440p| 800 |   275.4 | **2.9**\n\n[source for avg FPS: GamersNexus review](https://www.youtube.com/watch?v=N-FMPbm5CNM) *(3 games @ 4K+RT, 5 games @ 4K, 3 games @ 1440p)*\n\nYes, the cost of entry is higher than before.  \nYes, you're getting better value from AMD.  \n**No, the 4090 is not better value than the lower class cards.**",
    "comments": [
      "I imagine many that use the term better value really mean better buy. It may not be the better value by purely $/frame but it will/might be the better buy for many other reasons. Your last table showing the 4k +RT performance is an example of this. 4090 averages above 60fps while the 4070ti doesn't even come close and the 4080 is still below 60. Doesn't really matter if the 4070ti has less cost per frame if the framerate isn't even high enough.",
      "why am i even here, im fine with a 3080ti, i don't even play at 4k, im at 1440p 144hz",
      "You should upgrade when your hardware doesn't do what you want it to do, and new hardware will, whether that's the next generation or three generations later.",
      "The 4090 is the fastest card in the world and Nvidia rightly charged a premium. The fact that cards lower in the stack are even comparable in perf/$ to a halo product is the problem.",
      "If you do it by Tflops, it costs $19.35 per tflop for the 4090, $19.95 for the 4070 Ti, and $24.62 for the 4080. Tflops isn't the whole picture, no measurement is. But given the other benefits of the 4090, like vastly higher bandwidth on the VRAM, I think it's the most compelling product. Also if you go by shader cores, the RTX 4090 is .073 per core compared to .104 on the 4070. The 4080 is .123. Not to mention more Tensor, RT cores, etc on the 4090 which scale even better with price.",
      "You shouldn't upgrade every generation anyway.",
      "This is very true, especially for things like VR, where there is never \"enough\" performance. At least for now.",
      "I had a 2070 with 9900k which I had for 4 years, I finally wanted to jump to high fps 4k gaming since I got a C2 and the 4090 could play just about every game at 120+fps, with some aaa games requiring dlss to get there. \n\nThat wasn’t really possible until now, to max out 4k high fps monitors, (I’ve since added a Neo G7 for my actual monitor) in ultra and high settings, so had a new build for under 3100 with ddr5, 13700, 980 pro ssd, and 4090 and I love it, it’ll keep me through until next generation hdmi and display ports come out for several years \n\nThe value isn’t a good argument because it’s literally the only card available to really max out monitors nowadays and have a high fps RTX experience, and for that is worth it.",
      "I prefer refresh over AA, 140fps is soooo much better looking than 100 and below. I was playing portal rtx with dlaa at 90fps, it resets to 1080dlss on restart which goes to 140+ and the difference in feel and movement sharpness is huge.",
      "Most people would notice a bigger visual improvement going from VA/IPS to OLED than from 1440p to 4k. Then there's obviously people with both. My LG OLED TV makes PS5 games look absolutely stunning.",
      "He got if for 1079 and a couple of hoops to jump, so he stretched his story some.",
      "I dont think many people ever said the 4090 is better value than the 4070 Tie. But from your own numbers it's quite clear MSRP to MSRP the 4090 is comparable or better value than a 4080.  Which is crazy. From my point of view , the whole series sucks ass and is bad value",
      ">A lot of users here are on 3070\\3080\\3090 variants.\n\n>In that case, the 4090 is the only realistic upgrade option.\n\nThis was me sitting on a 1080 Ti looking at the 20 series going \"the only card worth upgrading to was a 2080 Ti\" and that cost DOUBLE my Strix 1080 Ti's MSRP *and* it only delivered 35% more performance.\n\nHell even comparing my 1080 Ti to the 30 series, a 3090 got me around 70-100% more performance depending on the game. It took a whopping 5 years, nearly 6, to wait for the 4090 to come out to finally offer a truly worthy upgrade path that delivers a consistent 200 to 250% more performance. GPUs have been so freaking pathetic last 4 years it's not even funny.",
      "Yeah, 1500€.",
      "This is precisely why perf/$ is not a perfect metric. \n\nOn the one hand, yeah, if you get 80-85% performance spending for 10-12% more performance is not linear. But on the other hand, if your personal value is to chase performance or keeping it for 2-3 gens, it is best to maximise what your budget allows, even if the table does not suggest it has the best perf/$. \n\nAlso, we need to stop with \"if you can afford this product at $X you can afford this product B at $Y+200\". No I don't/can't. It does not make me \"stupid\"... It just means I do not want to stretch anything more than $X.",
      "Still, the gap between the 4090 and 4080 in price/performance is quite small, and in one of the benchmarks (3rd table, 4K no-RT), the 4090 did beat the 4080 in price/performance.  \n\n\nI estimated that a better price for the 4080 would be $1,050, then it would sit between the 4090 and 4070Ti in price/performance, but closer to the 4070Ti instead of being closer to the 4090.",
      "Not also considering that you are getting 24GB OF RAM WITH THE 4090",
      "You can definitely tell 4k at 27” and it is much higher quality than 1440p, specifically if you play games with a lot of text, like MMOs or RPGs.",
      "As others have said, 4090 demands a premium because it’s literally the fastest. It’s sold on performance, not value.\n\nSlower cards are sold on value, which is very poor this generation.",
      "OP is right. However, if you want to 4K game with RT, only the 4090 will do it above 60fps consistently.\n\nSo essentially its like this:\n\nWant to 4K +RT above 60fps natively, or 144fps with DLSS: 4090\n\nWant to 4K +RT with DLSS: 4080\n\nWant to 4K +RT with DLSS at lower setting, or 1440 and get best value: 4070Ti\n\n&#x200B;\n\nPS: if dont care about 60fps or above, it probably better to get a console, as the value is insanely good compared to PC GPUs."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "4080"
    ],
    "title": "Upgraded from a 1660 Ti to a 4080...",
    "selftext": "",
    "comments": [
      "You should have said “I’m thinking about upgrading from a 1660 to a 4080. Is it worth it?” \n\nYou would have gotten dudes in here slamming you for asking a dumb question, like they did another person today. I would have loved to see them get mad lol",
      "Got me heat I went from 1060 to 3080 and let me tell you",
      "you vs the guy she tells you not to worry about",
      "I upgraded mine from a 1660 to a 4070 Ti. Worth it.",
      "That is a massive boost. The 3080 is a dream.",
      "I upgraded from a 2070 super to the same PNY XLR8 4080 OC, love this new card, powerful yet cool...",
      "Full specs:\n\n* CPU: 5800X3D ( Undervolted to -30 CO on all cores )\n* CPU COOLER: VETROO U6 PRO\n* GPU: PNY RTX 4080 XLR8 Gaming\n* Motherboard: ASUS Rog Strix B550-I Gaming\n* RAM: G.Skill TridentZ NEO 32gb ( 2 x 16gb ) - 3600Mhz CL16\n* Storage: 2x  Samsumg 970 Evo plus with one 500gb and other 1tb, 2x Sata Ssd with one 250gb and other 1tb ( Crucial and TeamGroup )\n* PSU: Corsair SF600 Platinum\n* Case: NR200P\n\n  \nCyberpunk 2077 RayTracing override maximun settings , DLSS Quality on 1080p ( I know this is a 4K card, but i'll be playing with it on 1440p once i upgrade my screens later )\n\nAround 80fps, gpu temp around 70-75c maximum.   \n\n\nPretty happy with it. The only downside is that frame generation produces a lot of stuttering with the 5800x3d on Cyberpunk 2077",
      "![gif](giphy|Swx36wwSsU49HAnIhC|downsized)",
      "I went from a 1060 to a 3080Ti(wanted a 3080 but during the GPU crysis the Ti came out cheaper somehow)",
      "Don't forget the many \"get a 4090!\"-comments when also forgetting not everyone has 2k lying around to spend for only the GPU. In my view it's also crazy to support these prices.",
      "Im upgrading from a 1080ti to a 4090, cant wait to get it.",
      "I was thinking of a 4080 but it was like 600 more dollars than my 4070 ti, at least it runs almost better than last gen 3090 ti!",
      "4070 ti is amazing, upgraded mine from a 1080 a couple months back",
      "Yeah the 4070 ti is a beast",
      "Very nice upgrade",
      "Enjoy 1050ti to 4080 (same card as you) love it!",
      "The only thing holding me back from.buying 4070 Ti are the 12 GB of vram, I am def. Not gonna upgrade in another 2 years. 5000 Series will prob at least see 16gb vram in the midrange",
      "I mainly play the newest AAA game and every goddamn console port has been an absolute Vram menace. Most easily passing 12gb on ultra. I think developers just don't care to optimize when all consoles are rocking more than 12gb of vram. And I fear it will get even worse with upcoming releases. But if I was only playing older games then yeah it's a great card!",
      "Very nice set of hardware you've got there OP! Seeing builds like this being filled to the brim feels so satisfying. Not to mention, I'm kinda digging the look of your air cooler.  \n\n\nYou should definitely post your build over at r/sffpc once you've got the cable management to your liking.",
      "yeah because 12 gb for 800$ is not a lot, honestly I believe that the 4070 is a much better card compared to the 4070 ti."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "4080"
    ],
    "title": "4 Years, from 1080 to 4080, exactly 4x performance boost. Also 7700k to 13700k, 4x uplifting too.",
    "selftext": "",
    "comments": [
      "1080 and 7700K are from 2016 , it's 6 years, the gap stays huge.",
      "480 MSRP = 499 \n1080 MSRP = 599 \n4080 MSRP = 1199 \n\nWhen accounting for pricing, the jump was bigger back then. If you're paying twice as much, the 4x performance increase is half as impressive.",
      "Jesus Christ can’t people just say congratulations? I know the 4080 is overpriced but god damn man let the man enjoy his purchase.",
      "Wasn’t the 1080 [released in 2016](https://www.pocket-lint.com/games/news/nvidia/137557-nvidia-geforce-gtx-1080-release-date-price-and-why-it-s-the-best-gaming-card-ever)?",
      "Technically it's not huge for a 6 year gap. It's the exact same gap as GTX 480 to GTX 1080 (6 years, about x4 performance)",
      "And still after 6 years you can't get a 1080 for 100€",
      "Correct, and the 7700K was the Jan 2017, nearly 6 years ago (yikes).",
      "Adjust for inflation and that pricing doesn't look terrible until you get to the 4080.\n\nThat price is terrible even accounting for inflation.",
      ">Adjust for inflation and that pricing doesn't look terrible until you get to the 4080.\n\ni dont know , i have a feeling the argument \"adjust for inflation\" only works if wages also adjust for inflation.",
      "I didn't realize the 4080 was popular with religious folk",
      "This chart also kinda shows that there’s a massive performance leap between the 3080 and 4080.\n\nSadly the price leap negates most peoples’ willingness to upgrade :(",
      "i7-6700k to i9-13900k \n\n1660ti to 4090 FE\n\nI know how you feel OP, it’s insane",
      "Also neat that the tdp is unchanged, and in actual use (like gaming etc) the 4080 pulls less power than a 3080, yet performs better than a 3090Ti. It's honestly an incredible card by all metrics as long as we ignore the artificially inflated price Nvidia slapped on it.",
      "Can't do. /s",
      "Same but 6700k to 5800x3d and 1070 to 4080 should last me at least 6 years too . Can't wait .",
      "Except no corporation is content with stable margins and profit.  There must always be growth no matter what, which is how we end up with consumer gouging.",
      "1080 wasn't released 4 years ago, neither was the 7700K.",
      "If we ignore the absurd pricing, this is one powerhouse GPU. Biggest jump in gen on gen performance",
      "It can't be 4x the performance cause 1080x4 is 4320 and that's only a 4080",
      "I’m only 26 but remember the 2500k being basically the only CPU that people bought!!"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "4080"
    ],
    "title": "Went from 2080 super to 4080",
    "selftext": "I still play 1080p just so I can get 240fps on all the games I play. Don’t get me wrong I will play 4k on my tv at 120 but the buttery smooth nessssss is blissfully better!",
    "comments": [
      "Put the GPU in the correct slot.",
      "Put the GPU in the top PCI-E slot, and reverse the bottom fan so it takes in fresh air from the bottom.",
      "While you're correct, it's really sad that OP is getting downvoted for asking what the difference is, thus obfuscating the explanations for inexperienced builders.\n\nCPUs and chipset only have a certain amount of fast PCIe lanes for connecting cards like a GPU. Therefore, motherboard makers need to choose which slot to intend for the GPU, and this is by convention the top slot. In this example, the top slot uses PCIe 5.0 and has 16x electrical lanes (and 16x physical size).\n\nIn comparison, the lower slot OP was using is PCIe 4.0 and only has 4x electrical lanes (despite being also 16x physical size). \nThe lower slot seems to be a 4x PCIe 4.0 slot.\n\nA nice knowledge to keep in mind is that PCIe bandwidth scales linearly with the number of lanes and each lanes bandwidth doubles with every revision. So the 4x PCIe 4.0 lanes of the lower slot is equal 16x PCIe 2.0 lanes.\n\nThe new GPU is a PCIe 4.0 card and has 16 PCIe 4.0 lanes. It will run just fine with fewer lanes or in older PCIe slots, but the limited bandwidth that comes with it can affect performance.\n\nWhat is always surprising to me is how little this matters in practice:  \n\nhttps://www.techpowerup.com/review/nvidia-geforce-rtx-4090-pci-express-scaling/28.html  \n\nSo even on a 4090, the mistake OP made only costs 6-8% in performance.\n\nYou can calculate PCIe bandwidth here: https://3roam.com/pcie-bandwidth-calculator/",
      "Higher bandwidth and better performance on the slot meant for GPUs (top one)",
      "Top slot will have better performance. Easy and quick fix.",
      "How long have you been gaming using a bottom slot GPU?",
      "https://preview.redd.it/1huwsm7zmfgc1.png?width=3024&format=png&auto=webp&s=c653cd26a1e351bf8cc6a0c2203213baf5c9ee38\n\n?",
      "😅 really? What’s the difference",
      "bro won the super bowl",
      "Why the bottom fan pointed into the desk? And gpu is in incorrect slot.",
      "Hol ee fuck that ring",
      "Yeah there’s some douche baggage pulling this boat down",
      "Poor op. You did great for your first build and learned a lot too!  Good job",
      "It's the top most slot, where you already have a slot bracket missing. You didn't share a pic",
      "lol, holy fuck no. Heat rising does not overcome fans.  You're correct here it should be on top but that's because of the obstruction. How fast do you think heat rises, this is hilarious",
      "Did I mention this was my first build ever. I surprised it turned on the first try 😂 glad I posted here to fix my mistakes",
      "I’m fed up of people having to be so hostile to mistakes rather than just helping in a nice manor like what happened to kindness?",
      "ye",
      "Heat rises. That heat will just get recycled back into the case.",
      "Here is what you should say:  thank you i didn’t know this information ☝️"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "4080"
    ],
    "title": "[Digital Foundry] Nvidia GeForce RTX 5080 Review vs RTX 5090/RTX 4090/RTX 4080 Super - Performance Worthy Of The Name?",
    "selftext": "",
    "comments": [
      "Everyone who was saying that the 5080 will outperform the 4090, where are you now? The weird part is that 5080 doesn't even pull ahead in RT.\n\nWhat a joke, lol.",
      "This is the same 5080 die in a \"5090\" laptop with 24GB VRAM and 175watts limit\n\nBut those laptops costs upwards of 4k \n\nNvidia has the capability to give 24GB VRAM to desktop 5080 but nope\n\nSeriously the disrespect to desktop gamers.......lmao!",
      "Too bad they won’t undo all their downvotes on me lol.",
      "As soon as I found out that the review embargo was going to be the day before release for this one, I knew I’d be a dud. \n\n4090 owner here and we’re still second in the stack over 2 years later (and for the next 2 years it seems). Lol",
      "This is what I find the most disappointing by far. I really wasn't expecting much from the 50 series. I would've bought a card that had a 10% improvement and 24GB of VRAM but 16GB again is an absolute joke. Sod off Nvidia",
      "This is a \"passer-by\" generation, it would seem. I know I intend to pass it by.",
      "It's not a new generation is really the simple way of looking at it. \n\nThis is just a refresh of the 40 series, same TSMC 4nm process.",
      "They need the 5090 to look much better...",
      "The 4090 embargo was also one day before release.  That doesn’t mean anything.  We knew the 5080 would be unimpressive when kopite7kimi released its specs, and arguably even earlier when we learned it would be on TSMC 4N, the same as the RTX 4000.  The 5080 has no node advantage, only a 4% core count advantage, and while GDDR7 afforded a significant increase in memory bandwidth, it’s still below that of the 4090.\n\nThe 5090 achieved a 30% raster improvement via a 33% increase in SM count and nearly 80% memory bandwidth increase.  It got a 512-bit memory bus and a massive 750 mm2 die (actually measured a bit larger).  It’s basically double the 5080 in all relevant metrics, including die size, SMs, memory bandwidth, and memory size. It shouldn’t be shocking the 5090 is 50-55% faster than a 5080, or that the 5080 is only 10-15% faster than a 4080S.",
      "Or even 20GiB would suffice.\n\nI guess they want to sell us a 5080ti 24GiB for 1499$ in 10-12 months.",
      "Same 28nm process node didn't stop the 980 Ti being 30% faster than the 780 Ti at the same TDP.\n\nJust sayin'",
      "What a shit card lol",
      "Nah. The 3080 to a 3090 was still an increase.\n\n10gb to 24gb of vram, and around 10-15%. Honestly that was fine, you should pay a premium for a halo tier card.\n\nThe best card available is worth a price hike beyond cost/performance so for that I can't get mad.\n\nWhen I get mad is that the 5080 can't even beat a 4090 and is basically just a 4080 super again so like wtf are we doing here?",
      "You're smoking crack if you think they are there for anything other than the 5090.",
      "Some people need to buy a GPU, and 40 series aren't produced anymore so...",
      "offbeat numerous cows dime ad hoc tie follow fade straight decide\n\n *This post was mass deleted and anonymized with [Redact](https://redact.dev/home)*",
      "Everyday I get more and more relieved I got my 4080super on sale, what a disappointing generation this is",
      "Even with the shit performance increase, if they would have added 24gb of vram. 100% would have upgrade to a 5080.",
      "I’m still rocking a 2080 super FE, I’m going to try and get this card considering it’s been a disappointment to most but I think it will be a nice upgrade for me and easier to grab compared to the 5090 or 5070 cards. I think this card is targeting 20/30 series users that didn’t upgrade to 40 series. I would go for a 5090 but I have a 2020 Corsair 850 gold plus PSU so that won’t work :/",
      "I think the 5080 is a decent upgrade for those on OG 10GB 3080’s. It’s not the generational leap people wanted and Nvidia marketed the card pretty sneaky using Frame Gen and DLSS 4 tech to make it seem faster than it is. General rasterization performance won’t get the huge boosts we used to see from gen to gen unless they make some new breakthrough in chip architecture and die shrinkage. For those stuck with a VRAM limitation when pushing 1440p/4K and RT they’ll see a big lift moving up but for those on a recent 40XX series it just won’t be worth the money. \n\nCompetition at the higher end of the card market is the only thing that will make this situation better for consumers and until Intel or AMD can challenge them on all fronts of a high end card we won’t get the price/performance jump we are looking for."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "4080"
    ],
    "title": "NVIDIA RTX 4080 ($1,459) is the #1 Bestselling GPU on Newegg, RTX 4090 at #3",
    "selftext": "Now after the dust has settled on the 7900XTX, the 4080 is sold in good numbers.\n\n[https://twitter.com/areejs12/status/1602998585443766272](https://twitter.com/areejs12/status/1602998585443766272)",
    "comments": [
      "Meanwhile, the only well-priced GPUs where I live are some 6900XTs and 3080s",
      "mommy",
      "Well we are on the new age of GPU prices. Was hoping to get a 4080 for around $800 before the price reveal (inflation). Only option for upgrading at the moment are a used 3080 or wait for the 5000 series to come out and purchase a used 4080.",
      "Well, apparently it shouldn't be $700 because plenty of people are willing to pay $1,459 for it.... Sucks, but business is business. They'll keep doing this as long as people pay the high prices. I'll be skipping this gen or waiting for big discounts personally.",
      "People waiting for a price drop now will have to be happy with MSRP. AMD didn’t save anyone, all they did was ratify the $1000-$1200 price category.",
      "AMD managed to make the 4080 look like a viable option with it's scuffed launch of the deeply flawed 7900XTX...the GPU market is so fucked right now.",
      "I’m going to enjoy my 3070 for the foreseeable future. I thought I was overpaying for that card because it cost $549 plus tax, when I thought the $499 FE was already expensive \n\nLmao at NVIDIA and AMD knee capping consumers by resetting GPU prices to DOUBLE what they’re worth",
      "Or don’t buy anything at all I guess",
      "I just bought a new 6800XT for ~$620. Seemed like good price performance. Sad!",
      "People are willing to pay their last 1500 to jump into a game and hide themselves from this fucking reality that we have to deal with, that no money can fix",
      "And I guess Zero price drop. The rumor was before AMD reviews. AMD is once again AMD so NVIDIA wins and the consumer loses (because they are so willing to grossly overpay for a GPU) \n\nGuess my 2080TI needs to hold up 3-4 more years.*\n\n*update: which was correctly pointed out to almost be insanely expensive upon launch but given the 30xx pricing/availability and 40XX pricing/availability it turned out to be a decent purchase. Just sucks I can’t upgrade without paying an entire mortgage payment!!",
      "Deeply flawed is a bit of a stretch, but I agree they botched this one. They should have come out with more aggressive pricing. Made the 7900xtx the 7800xt and the 7900xt the 7700xt and then worked on releasing a 7900xt a bit later that could start to compete with the 4090 on rasterization. \n\nAMDs executive leadership was stellar when Ryzen launched. Now they seem completely inept.",
      "I still enjoy following the news, but i consider myself to have been priced out of PC building. I bought a console and a productivity desktop and I'll probably move away from PC gaming unless something changes",
      "The people who pay $1000+ for GPUs now will soon find themselves paying $2000+ for a similar class of GPUs in the future.\n\nOf course they’ll still buy the $2000+ GPUs when that happens, and the rest of us will be priced out of the hobby.",
      "I live in the west and have a good paying job and I have a major f'ing problem with what people are willing to pay for cards. \n\nIn one gen people went from a \"$650\" 3080 to a *checks notes* $1200 4080.\n\nNV's got people Skinner Boxed.",
      "That is a good deal, honestly. Just enjoy your card! :)",
      "Imagine paying $1000+ for GPUs.\n\nEdit: I know I did.",
      "If I were living in the West with a relatively well-paying job, I would neither. But I live in Eastern Europe and even though I make fairly OK money, I cannot justify spending about 70% of my monthly income on a GPU.   \n\n\nBut if the XTX or the 4080 comes down in price at the end of their life cycle like the 6900XT or 3080 did, I'm very open to buying one. Until then, my 3070 is an absolute trooper, still doing very well.",
      "I really have no problem paying $1200 for a new GPU, but the generational p/p improvement just makes me hate the 7900XTX and RTX4080.",
      "Nvidia is the market leader. AMD is just following their lead.\n\nBlame the consumers, not the companies. We in the end set the prices by tolerating them. \n\nDo. Not. Buy."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "4080"
    ],
    "title": "Nvidia GeForce RTX 4080 Founders Edition Review: 4K performance and efficiency champ that deserves sub-US$1,000 pricing",
    "selftext": "",
    "comments": [
      "Anyone remembers 3080 Ti was released on $1200 msrp and stays there for a year. Every single one of reviewers call it overpriced at that time. Yet people still buying it...\n\nRight after it's price lowered to $899 4 months ago, it instantly out of stock almost everywhere.\n\nHopes is good, but reality is more cruel. PC Gaming industry already changed, no matter you want it or not. They **knew** consumer can fork $1200 for a 2nd best card already.\n\nIf you only pursuit fair and square game, just go with consoles. They didn't price gouging and take advantage of shortage and pandemic. They even refrain to release any special editions and focus on produce more units for the market.\n\nAs for PC gaming, except EVGA, none of them even care to implement a preorder for a damn card.",
      "4080's in Canada are around $1799..ridiculous. For $400 more you get a 4090.",
      "No more than $799. *Sub $1000* is too generous.",
      "Next two top comments: “instant buy if below $1000”\n\nLike ya, Nvidia knows. They pay a lot of money to people smarter than Kyle from Reddit to maximize profits.",
      "I will once again sit this generation out.",
      "I think there is one thing we learned from the previous couple years. The market decides what the price of a GPU is.",
      "Canada 🤝 Getting Gouged.",
      "Nah, this is still giving in to Nvidia's ridiculous pricing.  This needs well more than just 'sub $1000'.\n\nI cant emphasize enough that this is the Lovelace equivalent of a 3070 in Ampere's lineup.  AD103 replaces GA104 in the lineup, with similarly reduced specs compared to the top AD/GA102 die, and basically the same die size as GA104 and everything.  BUT, it's also not even a fully enabled AD103 die(ala 680, 980 and 1080).  It's still cut down by about 10%.  So it really is exactly what the 3070 was with Ampere.\n\nAnd look, I'm not even saying this should be $500 just like the 3070.  I get prices are gonna go up, and 5nm is expensive and all that stuff, and so I'd accept $700 as 'reasonable' for this.  If it's $800, I'd say it's not insane, but still back in the firmly 'lousy' territory.\n\nAnybody fooled by Nvidia's inevitable reduction to like $1000 or $900 are only persisting in helping them normalize absurd pricing levels.  And without a clear, overwhelming amount of voices speaking up against this, by us and especially from the tech press, they will succeed.  Seriously, I'm very worried they will, and we'll get what's an effective price raise from $500 to $900-1000 in just two years.  This shouldn't be acceptable to anybody.",
      "It's so exhausting seeing people keep getting fooled into thinking a product name dictates it's pricing.\n\nEdit: die size and bus width too lol. People gauging a card solely by bus width has become such a joke. Great way to show you have absolutely no clue what you're talking about.",
      "The market decides everything, always has. How is this news?",
      "$699, or even $799 is within reason.  $1,199 is just so insane.",
      "The 7900 XTX looks like it will be significantly faster than the 4080 16GB in raster, while being $200 cheaper and coming with 50% more VRAM.\n\nIf RT isn't your main focus, it's worth considering by high-end buyers.\n\nEdit: 24GB of VRAM and the USB-C port are both very handy for VR gaming, so that's another thing to consider.",
      "Yep. AMD figured \"If they can do, then I guess we can too\".",
      "RTX 4000 series cards cost just way too much here in Germany.  \n\n\nI literally paid 700 for my 3080 and the 4080 just cost twice the amount.",
      "Yup, the fucking strix 4080 is $2099!!!!!!!! I can get a 4090 FE for that price! They've actually driven me to the AMD side with these prices, if their 7900XTX competes in performance & price. There is absolutely no way to justify 4080 pricing, so it's either AMD or 4090. Terrible time to be building a brand new comp lol.",
      "Last place to buy a 4090 is on Newegg! those are scalper prices. Check on Canada Computers. I got my Asus 4090 last week for $2,199",
      "I'm still using my 1080 XD, maybe I'll still be using it in 20 years",
      "But not smart enough to realise they were over producing 3000 series chips.\n\nHonestly, they are doing this to plan, although I suspect they thought the 4080 would do better than it has.",
      "You think no one knew about Ethereum moving to Proof of Stake and that it would lead to the death of gpu mining??",
      "Everyone keeps sayin they have a bunch of 3k to get rid of but idk where the fuck they actually are, certainly not at any normal retailors."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "4080"
    ],
    "title": "NVIDIA reportedly stops mass production of RTX 4070Ti/4080 GPUs, now focusing on SUPER variants",
    "selftext": "",
    "comments": [
      "So does the 4070ti get cheaper now because it has a successor ~~predecessor~~ or does it get more expensive because ther are fewer available? \n\nAsking as someone who still couldnt justify a 4070ti for himself",
      "Nah they'll keep them at same prices and sell them extremely slowly to people who don't know better.\n\nJust look at older gpus and cpus that many retailers still have around.\n\nOr older motherboards... :/",
      "Honestly these mid of life refreshes like 2000 supers are in my opinion such a scam. You have to know that in ~1 year or less they'll drop the 5000 series. People with 3000 series, please don't give your money to this super refreshes, save it for 5000 gen. It will be much worth it. Just my 0.2 cents.",
      "I'm not sure where this idea Nvidia needs to drop prices comes from. The PC enthusiast market has proven time and time again they'll spend absurd amounts on the latest and greatest. There's nothing to suggest a better business plan comes from slashing prices on highly demanded products.",
      "Exactly what happened when the 2070 super launched. Old 2070 cards remained at the same launch price on the shelf. There were a number of cases I recall where due to promos the super was actually cheaper. I had a number of friends reach out to ask why that was, assuming there was something better about the older card or that the refresh was in someway inferior based on the pricing alone.",
      "What about RTX 4070? Isn't the 4070 Super also supposed to be released soon?\n\nI hope this doesn't mean the 4070 Super will be so expensive that they'll keep producing the 599€/$ GPU because none of the new cards will be competing at that price....",
      "Enjoy your card man, there’s always something new around the corner",
      "I just bought a 4070ti",
      "I mean the new 3080 are still expensive as fuck even tho the 4070/4080came out like a year ago so dont get your hopes up",
      "I'm old enough to remember this being what PC enthusiasts mocked Apple enthusiasts about. I remember friends buying absurdly overpriced Apple monitors, laptops, desktops and I'd just keep building PC's with my friends for dirt cheap. Kinda wild seeing PC enthusiasts sound exactly like the Apple fans did back then. \"I expect (insert wildly unnecessary attribute) and I pay for that feature\" as if its a brag or something to tout.",
      "I’m holding out. The 3070ti only having 8gb of vram pisses me off and I didn’t have much choice during lockdowns. I also overpaid for it too. I’ll be going for 5080 or 5090 next year depending on reviews.",
      "Same.\n\n![gif](giphy|26ufcVAp3AiJJsrIs)",
      "I mean, a year is a long time. You know how much gaming you can squeeze out in that time?",
      "I’m on 3080 10gb and playing Phantom Liberty pissed me off. Vram gets full, then stutters.",
      "That won't happen, the older models stay expensive or out of stock.",
      "I don't agree because the enthusiasts and top level cards are not the point here. The most common card in the steam hardware survey is the 3060. Your average pc gamer isn't buying the mid tier 4070 because it's priced for enthusiasts. The 4XXX cards are too expensive across the board, not just the high end. The high end sure they can keep charging and the enthusiasts will pay but they are a small demographic. The vast majority never moved off the 3XXX series cards and in fact many gamers are still on the 1XXX series.\n\nNvidia don't want to destroy the PC gaming market and they will if PC gaming continues to be so drastically more expensive than consoles. Enthusiasts alone can't keep the PC graphics card market alive.",
      "It's a trap.\n\nNext gen they are probably going to hardware lock you out of a feature.",
      "And here I really thought the normal variants would get a bit cheaper. Silly me.",
      "Still holding out until the 50 series launches. By then, there will be enough games available to justify an upgrade for people still on Turing and below.",
      "Watch them just slide the price scale even further. 5090 starting at $2000."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "4080"
    ],
    "title": "DLSS 4 Frame Generation Comparison in 5 Games - Runs faster now while using less memory at the same time, tested at 4K on an RTX 4080",
    "selftext": "",
    "comments": [
      "A few important notes:  \n  \n1. In terms of image quality, the Transformer model for Frame Generation is the least impressive upgrade compared to Super Resolution and Ray Reconstruction. Transformer Frame Generation has less blurry image and less ghosting, but it mostly comes from Transformer Super Resolution (because it is used as a base image).  \n  \n2. Instead of image quality, Transformer Frame Generation is focused on other upgrades: increased framerates and less VRAM usage at the same time.  \n  \n3. VRAM usage improvement will depend on a game and your output resolution: at 4K resolution you can expect up to 600MB less VRAM usage, up to 300MB at 1440p and up to 200MB at 1080p.  \n  \n4. The framerate increase will also depend on a game, output resolution and only if you're GPU limited: compared to the old CNN model, Transformer model can generate up to 15% more frames in games like Alan Wake 2 or Stalker 2 at 4K resolution, while in The Witcher 3 it's only around 5% more frames.",
      "On a 3080 and Cyberpunk the new transformer model is way less taxing on your frames if you dont have ray reconstruction. Ray reconstruction kills my frames pretty bad and is probably not worth it unless youre fine playing at 40 to 50fps at 1440p\n\nI havent tries ultra performance mode yet but on 1440p i dont have high hopes of it looking good",
      "Point 4 is not 100% true. Frame gen also gives a little breather to the cpu not needing to address full real frames.",
      "Revisit after driver update is released, people say this isn't exactly optimal right now with two months old drivers.",
      "just got a 4k monitor. I was about to sell my 4080 to get a 4090 used, but I may hold on to the 4080 now with this DLSS",
      "Common knowledge that competitive online games are bad with frame gen and honestly doesn’t need it since these games are heavily optimized. For offline single player games, the added 30ms latency isn’t ruining your game experience.",
      "using 4080 on a 4k monitor myself, and all in all, performance wise it's all about right what you need (DLSS Quality + FG - maxes out p much all games I've touched with decent like 90-100 fps, some titles more, some totes less, - new transformer might make it alright to use balanced or performance mode as well) , and vram is also never an issue.",
      "Nobody uses FG for online shooters, that is not what the technology is for. This is common sense.",
      "Try restarting the game after switching between models? Someone made a similiar claim that seemed to be fixed upon restart.",
      "I personally can't tell any latency issues, I only play games with a controller and don't play multiplayer games, where added latency could be bad. \n\nStalker 2 was the last game I played with it on.  Total system latency without FG was 25ms and with FG it was 35-40 depending on area. Couldn't tell a difference",
      "I tested DLSS4, without Frame Gen (RTX 3060), and I get few FPS less, but better image quality compared to previous DLSS version. Seems like Frame Generation is the one boosting the FPS more.\n\n  \nAnyway, I will keep using Transformer Super Resolution because it gives me better visual quality. This outweigh the few FPS that I lose for Cyberpunk 2077 (not a competitive shooter).",
      "Yes or you can just dll swap",
      "I tested a lot DLSS4 in CP2077 yesterday in my 3080 in a 4k monitor. I will say that I never thought of using RT Ultra with more than 20 frames and basically I am running now a full RT experience with Performance mode at 45 frames and with ultra performance at 70 frames.  Guys Ultra performance in 4k looks very good, very hard to see the difference, you will see it only in more artifacts but Ray reconstruction fixes most of them, it will have a penalty like 10 frames. But Basically you can now play CP with full RT Ray reconstruction at 4k in a 3080 at 60 frames. This DLSS; is game changer. This made me re think about RT, I thought it was not worth using RT and get a penalty in frame for more reflections, I was wrong, the game looks like a movie.",
      "So there was a [list of new DLSS 4 supported games](https://gamerant.com/nvidia-dlss-4-multi-frame-generation-support-games-list/), but with Witcher 3 there you're saying the Transformer model can be used even in the Witcher 3? Can it just be turned on in Nvidia app for any game, or how is this working?",
      "I don't see any improvement in FPS on my 4070 Ti Super switching between CNN and Transformer in CP2077. (Only indirectly since DLSS Perf looks at least as good as old DLSS Balanced). Does this improved frame generation require the new Nvidia driver that's due on the 30th or am I doing something wrong?",
      "The trick is you can lower the quality mode on the transformers model to get better FPS and still have better image quality than the CNN model at it's highest quality.",
      "Fake frames haters in tears as hundreds of games get higher FPS, lower VRAM usage, and better looking images with a single update.",
      "[https://github.com/beeradmoore/dlss-swapper](https://github.com/beeradmoore/dlss-swapper)",
      "don't get baited by fomo. if the 4080 works well - which it does, everything else is tech bros at work.",
      "If I was ever going to play a competitive shooter, it would be a no brainer to never turn it on."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "4080"
    ],
    "title": "Upgrading from 3070 to 4080 Super",
    "selftext": "Welp.  Thought I could just drop it in and G2G.  Didn’t expect I would have to break my entire PC down and hope I can angle it in.  Case is a Frectal Meshify.  I can’t believe how much bigger this is than my 3070.  I guess years from now when I upgrade to the 5000 or 6000 series I’ll need a contractor to build me a tiny home.  Kidding aside… if I can make this work with my current case I guess this will be this cases last build.",
    "comments": [
      "TBF - you picked one of the biggest 4080s’s out there. \n\nThere are much more compact versions if you’re ok with making up a ~50mhz boost clock oc in afterburner after the fact.",
      "Measure twice, buy once... \n\nLike the ole Measure Twice, Cut Once.",
      "I went form a 1080ti to 4090 safe to say it was faster then 4x 1080ti",
      "EVGA being out of the graphics card business is one of my greatest disappointments.  This will be my first non EVGA card in at least 10 years, maybe even 15.  I was so brand loyal and seriously distraught when they got out of GPU business.",
      "The Zotacs, Asus Proart, MSI Slim are all pretty much smaller than this beast",
      "Wow evga looks really pretty",
      "“I can’t believe how much bigger this is” - these cards are absolutely massive for sure, but you could’ve known exactly how much bigger it is (and that it wouldn’t fit) by checking dimensions on the website ;)",
      "It's game-dependant but 4x is about right. Take Dying Light 2 at 21:00 in the below Gamers Nexus video. RTX 4090 scores 203.2FPS, 1080 ti scores 49.5FPS:\n\nhttps://youtu.be/ghT7G_9xyDU",
      "Dude was making a joke about their names lol.\n\n1080 x 4 =/= 4090",
      "Maths disagrees",
      "Unfortunately they won’t. The company is a shell at this point. All of the GPU staff is gone, all of the Motherboard staff was recently let go. Good chance they’re completely gone before too long.",
      "The thing with the FE, is actually getting one. But you are right! Could also check the MSI Expert",
      "I really hope the 5000 series are smaller, the 4000 series gpus look ridiculous imo congrats though brotha big upgrade ✅",
      "Beat me to it. These days i measure my case and look up the dimensions.",
      "Welp.  Buying new case.  Broke the case down as much as possible and it just will not fit unless I use a crowbar.  Idgaf about damaging the case but I’m not about to risk it on the new card trying to force scrape its way in there.  I ordered a Liam Li dynamic o11 Snow White case and it’ll be here Monday.  So I guess I can just sit here and look at everything in pieces until then",
      "I really hope they come back in some way",
      "Even an FE would be good. Very compact and built well.",
      "😶",
      "Founders cards are the best looking ones out there anyways.. those gamer RGB cards just look tacky",
      "I upgraded from a 3070 to a MSI slim 4090 and it just fits into the old case."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "4080"
    ],
    "title": "4080 super for my first ever build.",
    "selftext": "13yo.",
    "comments": [
      "The motherboard without FE cover really irks me, still a nice build for your age, congrats",
      "The plates that cover the rear ports of the motherboard\n\nSeems like you only have one in the back of the case, meanwhile the front of the mb does not have one",
      "Sorry if I sound dumb but what’s an fe cover?",
      "I find it funny that you cheap out on a mobo while running a 4080. I can’t really see which cpu you are running, and yes, most likely you won’t «need» a headsink, until you do. But hey to each their own.",
      "I've bought expensive motherboards that performed like shit, and shitty motherboards that were super reliable. When I was looking at reviews for my AM5 build last year it was a mixed bag, spending an extra $100 - $200 was no guarantee of RAM compatibility or stability.",
      "Nice build! Enjoy it.",
      "Better they spend the extra $100 on the GPU than on the motherboard.",
      "No problem mate, I was just mentioning it, because if I say you did a good job on intel, purchase and finishing your PC, I should also give some credits to your family who supported you financially to get it so far. No ill meaning or intention. I am also greatfull for my family supporting me in your age for the same reason. I did started a bit earlier and was almost always fascinated by electronics and especially computers and that’s what lead to my career as an IT professional.",
      "The thickness of that thing is ridiculous.",
      "Is not having it an issue or just a minor inconvenience? The build has been running fine.",
      "It looks better with it, but also it usually has a heatsink for the vrms as well",
      "Don't listen to those idiots, if the motherboard works with your build it's absolutely fine. Especially with a 7700X there is zero difference between a cheap motherboard and the most expensive one when it comes to performance.\n\nThe pricier motherboards usually have more features, but if you don't need them it's wasted money.",
      "My cpu is a 7700x. This motherboard has everything I need really. The only thing that’s missing is bluetooth but I have a dongle so idc",
      "There’s no need to get defensive. You literally made a post which then obviously will make people respond to that post.\n\nMatter of fact, I would have gotten a different cpu as well. The 5800X3D is better, and probably costs less. The 7800X3D costs more but is even better.",
      "I love this case  alot\nH6 flow not so ridiculously big like h9 and not so basic like other cases good choice",
      "I assuming that you got sponsored, because you said you are 13yo. Or did I interpret something wrong?",
      "So, I got your age right and you used money, which was gifted to you, right?",
      "LTT did a good video testing performance of Boards and how heat affects them. The cheaper boards work fine but the VRMs not having a heatsink can affect performance once they get really hot.\n\nhttps://youtu.be/GvyQXkFUe3E?si=z6wttDc23xS5Nj9h\n\nTbh, I would have done the same thing if it meant I could get a 4080 with the extra budget.",
      "You know what's not ugly? The sweet sweet pixels at high FPS he's getting from that 4080 Super. Do you stare at your motherboard all day?",
      "I actually got my cpu for quite cheap locally. Something around 210 so it was good value"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "4080"
    ],
    "title": "4080 Super in stock now",
    "selftext": "",
    "comments": [
      "Nvidia stock at $1000+ \n\nI'm sure the 5090/5080 will be reasonably priced and not prone to scalpers markups. A couple of lucky ones will secure a card, but it is mostly going to be for China.\n\nAlso, everyone and their mother is selling off their barely used GPU in anticipation. Prepare for the greatest FOMO launch in Nvidia's history, and they are most definitely reading out post.",
      "SKIP ill wait for the 5000 series. \n\n  \ndamn.. then I wont find one to buy and ill have to wait for the 6000 series. ffs..",
      "$300 too much",
      "In the week since rumors for the 5000 series hit the price of used 4090's dropped $200~",
      "300 TOO MUCH",
      "300 TOO MUCH",
      "While I generally endorse the idea of waiting as long as possible, some people need hardware now or relatively soon. The 5070 could be another 12-16 months before release.",
      "https://i.redd.it/9b9fv39k573d1.gif",
      "So you recommend wasting more money while waiting on a used hardware?",
      "im waiting for 5080 at this point.",
      "Man I can't wait for the second great GPU crisis lol, I remember 30 series and 40 series being months and months. Even reading people pulling shenanigans with swapping gpu in prebuilt pcs.",
      "Wish the old cards actually came down in price when the new ones come out but we know Nvidia is way too good at inventory management to let that happen.\n\nI also will be looking for a 5080 and imagine it will be just as much of a nightmare as trying to get a 3090 was at launch. Stock tracker discords including a paid one to get early alerts, auto-refresher chrome extensions, just crazy shit a consumer shouldn't have to go through. But it was either that or wait another 6 months (might do that this time since the 3090 is still fine) or pay a scalper markup (will never do that).",
      "![gif](giphy|3o7TKGMslz2YfhkuwU|downsized)",
      "still in stock",
      "Wait for 5070",
      "4000 series wasn't too bad, i was able to get a 4090 at launch from bestbuy (msrp). Stock got a bit worse (tariff/ban etc..)and i was still able to casually buy a second at msrp around mid cycle.  I don't expect 5090 to be any different, the margin on these items are so high(still nothing compare to enterprise tho) its whatever the market will bear at this point, it has no relation to the underlying cost anymore.",
      "Still only 16gb in a thousand dollar card",
      "At this point, why? Nvidia 5000 series just around corner now.",
      "How did you kill a gpu in 5 and a half years!? I had a rx480 for like 6, sold it still working, and I've had a 5700xt for like 5 years now",
      "Have fun with the mark up plus the 25 percent tariff to deal with. Card is gonna be like 1500 bucks."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "4080"
    ],
    "title": "NVIDIA GeForce RTX 4090 is outselling the RTX 4080 on eBay by a factor of 3.4 - VideoCardz.com",
    "selftext": "",
    "comments": [
      "Because 4080 is stupid. People will only pay over the top for no. 1 card, for everything else performance per dollar matters a lot.",
      "\"The greatest trick the 4080 ever pulled was convincing the world the 4090 was great value\"",
      "This is want Nvidia wants anyway. Why sell a $1200 card when you can sell an $1600 one.",
      "and there's a lot of buzz around the 7900xtx beating out the 4080 for cheaper. I know that's what I'm waiting to see, if I can get 4080 performance for less money, I'm definitely going with AMD this generation after buying nothing but EVGA since the 560ti 448",
      "Nvidia understands and uses the movie theater popcorn \"dilemma\". Do you want a small popcorn for $5, a medium popcorn for $8, or an X-large super bucket with unlimited refills for $8.99?",
      "Because you don't need to go to eBay to get a 4080, but you do need to go to eBay to get a 4090 (or be really lucky).",
      "New headline: \"Journalists don't understand Premium decoy pricing strategy.\"",
      "[The Decoy Effect](https://www.youtube.com/watch?v=33aaQdtD20k) if anyone's interested.",
      "I  am not rich I just don't have kids lol",
      "I have a question that will challenge your intelligence, you ready?\n\nRTX 4080 12GB was $900 MSRP and it got unlaunched, only to be relaunched under a new name - presumably 4070 ti. AIBs already told Gamers Nexus that the MSRP will not be the same - ergo, it will be at least a bit lower.\n\nThe question for you is: if RTX 4070 ti (used to be 4080 12GB) is let's say $800, then how can you believe that BOTH RTX 4070  AND 4060 will be $800 or more?",
      "Because sitting with old cards and saying \"that's cute\" to feel superior on reddit is the name of the game.",
      "Somewhat, I've sold every card I've ever had when I've upgraded to the next one. For instance I  bought my 1080ti for $400 and sold it for $500 because of how crazy the markets got, then bought the 3080 at retail for $800 because my number came up with EVGA. I've basically only spent an $100-$300 on each new graphics cards for the past decade. I only skipped the 2000 generation because it was so overpriced and the performance boost just wasn't there over the 1080ti.\n\nI've had\n\n560ti 448\n\n670\n\n770\n\n970\n\n1080ti\n\n3080 (current card)",
      "If they're able to spend over $1k for a graphics, might as well spend it on the best. $400 gap is not a lot for rich people.",
      "Because the 4080 is in stock and the 4090 isn't.",
      "if it beats the (presumed) 4070 Ti in ray tracing workloads I will consider it",
      "That’s because the 4080 is ridiculously priced. The 4090 is expensive, but it has much better gains than last gen. Moreover, the 4090 is $100 more than the launch price of the 3090. The 4080 is almost double the price of a 3080",
      "basically no chance. nvidia has tripled down on RT and made it even more efficient than ampere. amd has refused to do this and will see equivilent improvements to raster, which should place their highend around a 3080/3090 for RT.",
      "> which should place their highend around a 3080/3090 for RT.\n\nStill pretty respectable imo",
      "Knowing that only 100k were shipped gives the 4090 a much higher value considering how hard it is to get one at msrp.",
      "Extremely. \n\nKnown retailers have drops and it is sold out almost instantly."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "4080"
    ],
    "title": "Nvidia GeForce RTX 4080 starts in Germany at prices from 1,799 euros",
    "selftext": "",
    "comments": [
      "Pass",
      "Its 1000 € too much, change my mind",
      "It’s 1.900€ in Turkey currently. You can get the cheapest 4090 (Palit) starting from 2.290€. \n\nAs an individual who has the opportunity to upgrade every generation, I skipped this one because the attitude is irritating on Nvidia’s end, plus the EU pricing is a straight scam and lunacy.",
      "They've completely lost it.",
      "Should've been like 799.💀",
      ">Maybe the XTX makes the 4080 drop in price.\n\nIt won't unless you start buying it instead of NVIDIA.",
      "Good luck selling it in Europe Nvidia...\n\nAnd some people are waiting for XTX to be good just to force Nvidia  to sell them 4080's for a better price... it's just so sad...\n\nIf you want to make GPU market a better place there's no other way - AMD and Intel both need significant market share - look at the CPU market - competition is the answer, not fanboism.",
      "Yeah, same here in Norway. Not worth it by a long shot. If someone insists on spending money, get the 4090 instead seeing as the prices are so close to each other. That being said, I'd almost argue \"wait\" in general. Maybe the XTX makes the 4080 drop in price.",
      "In Slovenia we have ASUS TUF for 2030 euros 😂😂😂\n\nhttps://preview.redd.it/hggu8tl1gc0a1.jpeg?width=828&format=pjpg&auto=webp&s=f9877f3d53c20bbdad8e1f3ef788ac93a27a813d",
      "Well the 80 series used to cost 800 and below, so no, I won't change it.",
      "A hard one",
      "I'd have bought it if it was 1000€ cheaper.",
      "You could literally add 300 euros and get a better 4090. Hardware prices in eu are ruined. In Germany RTX 4090 and for example Suprim x started at 2100 after tax and is now being sold for 2600",
      "> stupid high taxes\n\nUhm... This is not because of taxes - we only have the VAT which is 19%. \n\n>I guess Germans enjoy paying stupid high prices for their healthcare.\n\n/r/shitamericanssay",
      "Anyone arguing for this price has lost his mind or is very poor with money",
      "No one 'needs' gaming by definition. It's a hobby. People spend fortunes on hobbies regularly.",
      "Will **you** go AMD though? You have a 3080, so not anytime soon I assume, but for a hypothetical 8000 series instead of 5000? Even if the 5000 series is more reasonable priced, would you remember the shitshow we have right now? Or would you forgive and forget and go team green yet again since team red managed to lower its prices?\n\nThat's the question. That's the mindshare NVIDIA has and AMD doesn't.",
      "Considering I got 1080 for \\~500€ new years ago, 4080 would be \\~3.5x the price for an 80 series card.",
      "Literally 1.200€ more expensive than what I've paid for the same model of 3080 on release.\n\nJust WTF",
      "we obviously need better anti trust laws in Europe. This product is literally a scam."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "4080"
    ],
    "title": "RIP 2080, should I get 4080 or 4090?",
    "selftext": "Hi everyone, a few days ago my dear RTX 2080 abandoned me and I am forced to change graphics card. I wanted to wait for the new 5000 series but at this point I can't stay without a graphics card for about a year (considering that they won't be available right away). I currently play with a resolution of 3440x1440 with a ryzen 3900x (I plan to switch to 5700x3d before or during black friday).\n\nHaving said that, is it better for me to get a 4080 super at a price of around 1100-1200 euros or a new 4090 at a price of 1500-1700 euros?\n\nI fear that with the release of the 5000 series, the 4090 is the one that will not lose much compared to the others in terms of performance, but that it could depreciate more than the others given its high current value (even if it will obviously remain a good graphics card).",
    "comments": [
      "I gotta leave this sub lol, everyone always talking about buying 4080s and 4090s, when my gpu dies I’ll have to quit pc gaming",
      "I'd get the 4090 again, because the 5090 prices will make people waiting now, to buy the 4090.  I don't see 4090s getting cheaper when 5090s release.  4090 may be discontinued.",
      "4090 production is being shut down for 5000 series production yes.",
      "This is always a gamble. Just chill, don't give Nvidia $1000, coming from a 2080, 4070 Ti Super is more than fine, if you don't have money to burn.  \n$799 msrp, +109% faster than 2080, 285w vs 215w TDP is enough of a TDP increase.  \nDouble the VRAM.",
      "Or look for a $300ish 3080 10GB to get bye for awhile, you can always sell it when you figure out which 50 series to grab.",
      "AMD is absolutely the alternative. Nvidia’s lineup is terrible for value even though the cards themselves are still solid. But if money is an issue, go AMD. Their cards aren’t stellar in value but they’re certainly MUCH better than Nvidia.\n\nI can see why people forget AMD video cards exist but they’re absolutely the better budget option bar none (though I hope to see Intel getting there eventually too).",
      "4090 prices are extremely high rn. The 4080 makes more sense. It's €1000 for a palit jetstream",
      "This. I think people are putting too much stock in the price and availability of the 5080 and 5090.",
      "4080 super is what I’d get no card is worth 2 grand",
      "If you afford can 4090\n\nAbsolutely 4090 \n\nit is one beast of a card.",
      "My whole dilemma with that is if you can afford a 4090 right now then just wait for the 5090.",
      "Am I crazy to suggest buying a used 2080 for way cheaper than a 4080 or 4090?  Then once the new cards come out see how the 5000 series do and by then a 4000 series would be cheaper if you want.",
      "I’m enjoying my 70tiSuper. It’s my first PC build and I’m quite enjoying the experience. It can run most games at max settings 1440p(sometimes 4K) at 60fps. \n\nComing from console, I’m honestly enjoying path traced cyberpunk w/max settings at DLSS 1440 at like 40fps. That’s a world away from what I had on PS5.",
      "it was 6 years old, and unfortunately it had already been replaced after 3 years with a refurbished one from EVGA",
      "I mean when your GPU dies, you just buy another used one of the same tier for cheap.",
      "300ish? Where? 😂",
      "I have been amazed at how useful it is for me in current games to have 24gb in my 3090. I'm going for the 5090 next mainly to keep the high vram.",
      "The 24GB on XTX is pretty useless right now.  Don't need it for games and professional apps that could use more memory don't run well on it to begin with.",
      "Just remove the fans and shroud and stick a normal pc fan with some zip ties. That will fix it. I also have a 2080 and I'd prefer to wait for the 5000 series before changing it.",
      "4070 now until 5080 comes out"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "4080"
    ],
    "title": "I was not prepared for how big the 4080 actually is.",
    "selftext": "",
    "comments": [
      "4080/4090 make the fractal torrent look like a regular size case",
      "It's interesting that they made the 4080 use the same shroud as the 4090. If nothing else you get great temps.",
      "You Vs the guy she told you not to worry about",
      "gg, you can now put clouds on high at orison.",
      "For real. I put it in my Fractal pop Air XL, which is very very close in size to the torrent. The 4080 definitely makes my XL look like a normal size case.",
      "No one is ever prepared. You think you are after watching a million videos, but then you open the box and CHONKY BOI says hi. Then you are in a race against the clock to get the thing screwed down to the case and the GPU crutch in place before the PCI slot snaps lol.",
      "For real. I never go above 60c no matter how demanding the game is. Maxed out everything. 300+w. No undervolt. Still runs 55-59c",
      "TIL there are people too lazy to unplug a few cables to avoid the risk of damaging hundreds of dollars of computer parts.",
      "https://preview.redd.it/dhtqaapvwula1.jpeg?width=3024&format=pjpg&auto=webp&s=cbc120a3ebc8c35abbaae73ea2f7d4426d031144\n\nI don’t have any bananas, but this is a 3080 Ti next to it to give you a better idea. I might have to get one of the stuffed bananas from Linus hahaha",
      "It’s 13.5 inches long.",
      "Try Playing Control with the HDR/Max texture mod with the increased ray count option ticked. \n\nMy 4090 was drawing nearly 520w",
      "Your display pic is literally a banana and you don’t have any? Get your shit together.",
      "Hurhurhurhur",
      "😂",
      "Still can’t understand how big it is. Need a pic of it next to a banana",
      "Yes, but the 3090 didnt have that much higher tdp than the 3080. While the 4090 pushes a lot higher than 4080. In other words they could have saved money on less cooling. Im just surprised they went this way.",
      "That's what she said.",
      "Wait.. You don't put the case down when installing a GPU?",
      "that's why most people get or want the fe version.",
      "https://preview.redd.it/putywq1ilula1.jpeg?width=3024&format=pjpg&auto=webp&s=79e2a9e756ec0522389760352939e699f943ea4f\n\nLol. Cutting it close! Nice! Here’s mine in the case. There’s about a quarter of an inch between the cable and the glass"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "4080"
    ],
    "title": "Was RMA'ing my 4080 and ended up getting offered a refurb 5080 instead",
    "selftext": "My gigabyte 4080 OC was acting up, so decided to RMA it after hours of troubleshooting. After an initial phone call with Gigabyte, they called me weekly for a few weeks, each time saying they had no 4080s to send me. But this week they called and offered a refurbished 5080 instead. Of course I accepted, but should I expect any issues from a refurbished GPU or are they usually fine? Super excited for it to arrive",
    "comments": [
      "You win. Enjoy!",
      "Refurbished can be many things but in all cases you should have warranty.\n\nRefurbished could be some dead vram that was switched out or a switched out defect cooler/fan. Could also be a defect contact that was repaired. Usually refurbished cards are cards that were bought by someone, had some problem/damage and were switched out bc it was faster. The problematic card is then repaired and resold.\n\nRefurbished often is less of a (rma-)risk than new ones because it is tested usually before being sent out again.",
      "Refurbished could also just mean a return that was inspected.",
      "I'm super lucky for sure, thank you!",
      "This will usually be the case. Returns can't be sold as new so they'll often get used for this.",
      "This is such hyperbole, there are not a \"crazy amount\" of issues, they are isolated and I have had no issues with the latest Nvidia drivers installed thru Nvidia app on my 5090.",
      "I would definitely monitor it for a week or two after getting it and check all the temps and fans etc but enjoy! It's an extremely good card and I really love mine.",
      "Make sure you triple check those ROPS!",
      "I'm honestly not sure what the issue was exactly. I was having crashes in a few games and some fan issues. I tried driver rollbacks, updating mobo, undervolting, you name it. I gave it a few days of troubleshooting before just returning it",
      "They get their news from Reddit! How dare you question their credibility",
      "I wouldn't be shocked if 30-50% of refurbished cards are cards that \n\nA. Didn't overclock the way people wanted so there broke and returned\n\nB. Coil whine OMG its so terrible... Returns.",
      "what was the problem with the 4080 if you don't mind me asking",
      "I think you'll be fine. I had a 650ti ftw black edition or something from EVGA back in the day die, and they sent me a refurbed 770sc, it had a clicking with the fan, they gladly replaced it on their dollar.\n\nSo to say, you'll be fine, it'll have a warranty, anything happens they SHOULD take care of you.",
      "I’ve gotten a lot of refurbishment products (no graphics cards tho) and over half are just open box stuff that has zero indication of repair, damage, or even use. A lot of people for some reason give bullshit answers as to why they are returning something, even if a simple “I decided I didn’t want it” would be fine.",
      "Sounds good, yeah they mentioned they did a lot of tests on it and it performed good. So hoping it turns out fine.",
      "Will do, thanks!",
      "I dunno what the majority of these replies are talking about, because \"refurbished\" always means that the card was returned due to a defect, and the manufacturer repaired and tested it.\n\nRefurbished is also sometimes better than new, as Gigabyte would thoroughly test the card to make sure it's;\n\nA) Got the same performance as a new card.\n\nB) Doesn't suffer from any issues.\n\nEssentially, someone RMA'd your 5080 due to an issue. Gigabyte has replaced their 5080 while they fixed the RMA'd card. They've them given you the refurbished 5080 as compensation for the length of time your 4080 has been gone without a replacement.\n\nChances are, someone who RMAs a 4070 or a 4080 might end up getting your refurbished card, assuming Gigabyte can fix the issue you were experiencing with said card.",
      "If they are missing I doubt op has any recourse, they didn't buy a 5080 so they are only owed equivalent to 4080 and a 5080 with missing ROPs is still faster than a 4080",
      "Tbh i had coil whine so terrible you could hear it 3 rooms away the moment the card had 10% usage. I returned that thing. Sounded like the screaming matchbox insect from Constantine.",
      "returns are resealed not refurbished.\nBut yeah a return could be refurbished if it had some problems and it was inspected."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "4080"
    ],
    "title": "RTX 4080 Gaming Performance",
    "selftext": "",
    "comments": [
      "And yet it's almost double the price, shame on Nvidia.",
      "My 3080ti averages 93 fps at those settings  on Tomb Raider.\n\n**4080 is roughly 38% faster in Tomb Raider**\n\nEdit: I saw in the original post the BL3 settings. Baddass @ 4K, my 3080ti averages 69,5 fps.\n\n**So the 4080 is 31% faster in BL3.**\n\nAlso, in the source, there is a CP77 benchmark run, at 1440p Ultra RT preset. With the 4080 clocking 112,98 and the 3080 ti averaging 84,78 fps.\n\n**So  the 4080 is 33% faster in CP77 at 1440p**\n\nThis is at stock settings.",
      "Well, that's their intent. To clear 3000 series stock first. \"Look how much better the 3080 or 3080ti is for the price\".",
      "That's extremely close and little bit sus",
      "Either:\n\n*  stick with Ampere to save money\n* pick a 7900XTX\n*  ...or a 4090 (once melting issue is clarified)\n\nbecause each one of these options can be justified.   \nMoney saving, best 4K performance per dollar..and the monster 4090 for GPU supremacy for those who can afford.  \n\n\nI'm not going to speak for you but I think if you can afford a 4080, you can afford a 4090 (again, once the melting is clarified)  if you save a little, it will be hugely worth it, the 4080 is too damn expensive, the worst performance per $ \n\n  \nIMO the 4080 is absolutely not justifiable, just look elsewhere, it's the best thing to do",
      "Maybe the intent initially. But do you think they will suddenly lower 4080's price as soon as the stock of 3000 series clears?",
      "Source: https://www.chiphell.com/forum.php?mod=viewthread&tid=2458296&page=1#pid51025622\n\nCPU: Ryzen 5 7600X\n\n3 Games with built-in benchmark.\n\nMore games will be added so follow the forum [thread](https://www.chiphell.com/thread-2458296-1-1.html) if you are interested.",
      "7600x… a bottleneck… at 4k? No it isn’t.",
      "It's not, the cheapest 3080 Ti is [$1100](https://pcpartpicker.com/search/?q=3080+ti&page=1).\n\nOn reddit 10% more is double the price I guess.",
      "They'll probably introduce a 4080ti at the 4080 16 current price point later in the gen, and shift the 4080 down to 1000 or 900.\n\nThey've done that a couple of times befoee with the Super line up, the 3090ti taking the 3090 pricing, and I think when they introduced the 1080 ti the 1080 shifted down in price.",
      "Yeah and I also blame the people who will still buy the 4080 at this price making it the new normal.",
      "Very sus",
      "Yep, 4080 makes zero sense for any purchaser imo. 4090 does if you're going all out.",
      "The game probably doesn't recognise the 4080 yet since it wasn't developed with it.",
      "For people thinking nvidia would reduce the prices I would like to quote a little someone called Jensen: \"Reduced. GPU. Prices. Are. A. Thing. Of. The. Past.\"\n\nMy apologies for the periods, but in my head, I assume he said it in that tone.",
      "More like 42% for Shadow of the Tomb Raider\n\n[https://imgur.com/a/OSEuSh5](https://imgur.com/a/OSEuSh5)\n\nEdit : thanks for the quick maths everyone",
      "How is 4080 double the price of 3080 Ti?",
      "Next to cp77 screenshot it says 4k but on screenshot it’s 1440p?",
      "Awesome! Now I just need 1800€ to buy one! For how much do Kidneys go these days?",
      "RDR2 is showing 99 FPS on the benchmark compared to 93 FPS on the 7900XTX as per the post."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "high",
    "matched_keywords": [
      "4080"
    ],
    "title": "I'm probably a bad person for buying the overpriced 4080, but I'm back on team green after a short run with the 7900 XT",
    "selftext": "",
    "comments": [
      "Well, the 7900xt is also overpriced (as is everything so far this gen) so it's all good. 4090 owner here so it's not like I'm not part of this crap.",
      "Not a bad person.  It's your money. Spend it how you want.  Nice setup!",
      "4080 owner, I agree. All the cards are overpriced and since Nvidia and Amd don't have competition, Nvidia sets the ceiling and Amd just places themselves inside their trail. Don't purchase one if you can do without it, but it seems that its not wise to upgrade every generation now with their business practices.",
      "How you spend your hard-earned money is nobody's business if you are a good or bad person. If the 4080 can fill your needs, then that is all what matters!",
      "You’re not a bad person, you tried something else, and it didn’t work out.",
      "Yeah I agree, I’m also really impressed with frame generation. It seems like there’s some mega cope going on with people who haven’t tried it.",
      "I've never upgraded every gen. Every other gen is the way to go since the gtx 600 or gtx 700 series.",
      "The 7900 XT is great, I wouldn't hesitate to recommend it. For me, I just wanted to jump up a performance tier and a 4080 FE arrived at my local Best Buy so I jumped on it. I may have gotten an AIB XTX if one was available, I really like the Wattman and Adrenaline software, but I also enjoy the nvidia features like DLSS and better RT.",
      "A better rule is, buy when you need it. Or if you have the expendable cash and you're really into hardware, buy whenever you want it, even if it's literally every year.",
      "The truth is I'm happy to pay a lot extra for something that is more reliable. Especially with drivers",
      "This reads so whiny",
      "Me who went from whatever family computer had in early 2000s to 560ti to 2080ti to planning for 6xxx series. Guess I missed the memo.",
      "Too many ultra slow mo tests and not enough watching actual footage of the game like you would play it. Shit is a great feature.",
      "RemindMe! 10 years \"Is PC Gaming Dead Yet?\"",
      "Yeah the pixel peeping is at psychotic levels out there.",
      "If you think 80 class is entry level, you're WILDLY misinformed. It may be worth $700 to you, but to everyone else who has bought it, it was worth $1200+",
      "Cost per frame gives perspective, but when you have a target resolution and framerate that you want, you buy based on that.\n\nCost per frame means nothing if you can't get the performance you want.\n\nYou buy what you can afford, but you should also drive displays that fall within your budget to push.",
      "Haha thanks, I didn't have any issues with AMD drivers luckily, the XT is a great card IMHO",
      "Enough with the virtue signaling, are you suggesting that paying an ex miner an inflated amount of money for a clapped out used card is any better?  Or helping a scalper clear out inventory before prices completely implode on old cards?  Which negative behavior do we reward, or can we just quit focusing on \"what does my video card choice say about me as a person\" bullshit and just enjoy the hobby?\n\nI'd absolutely buy a new 4070ti new with a warranty from a retailer over an overpriced used 3080/3090...   I've seen 4080's tickling $1000 open box with full warranty lately which I'd probably spring for over the 4070ti at full retail.  They aren't bad cards, but they are bad prices.. which will come down in time as A/N clear out their prior gen inventory.  \n\nWe're in Q1 when things usually get shaken out after KPI's tied to executive bonus payouts are settled in Q4 of the prior year, so I expect prices on the new stuff to start coming down by March with the 4060 launch around the corner, which is expected to be $500ish and outperform prior gen 3070ti models.",
      "I sold my 3080 for $650 on FB marketplace the other day so half price 4080 for me! But seriously GPU prices are absolutely insane I mean wtf. Looks great!"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "top",
    "matched_keywords": [
      "rtx 4090",
      "4090",
      "rtx4090"
    ],
    "title": "ASUS wants $3758 to repair a small plastic indent on their $2799 ASUS RTX 4090 WHITE OC",
    "selftext": "Purchased brand new ASUS RTX4090 2 weeks ago. Card works perfectly but safety plastic indent got scratched off. Skeptical of melting stories on 4090 so sent it to ASUS RMA to have it repaired advised by my local store and ASUS support. They quote $3758 to have it repaired?!?! Asked for supervisor/manager to make sure the quotation is correct. Supervisor confirmed and said will give me 30% off for the repair. Last ASUS product ever buying. Beware.\n\n**Edit:** Thank you everyone for your advice. After giving them a mouthful on the phone they said they will get back to me. Few hours later they emailed saying the damage is not covered under warranty and the whole card must be replaced. Their response is even more laughable...\n\nThis is truly outrageous. Now they saying the card is not functionable because of the damage. My local store ( Canada Computers ) previously confirmed the card works perfectly and it's just the clip that's scratched out. This really feels like a scam. I will be updating this post. Below is there email reply.\n\n\"Thank you for reaching out to ASUS Invoice Quotation Support. My name is Amelia M . Thank you for the opportunity to address this matter with you, I have received feedback from the escalation. We do understand your concern However, please note that the damage ultimately effects the functionality of the unit and is not covered under our standard warranty. The GPU is being replaced we can have have a 30% discount offered off the invoice to have the card replaced.\"\n\nhttps://preview.redd.it/bi9zz5n14vyc1.jpg?width=1055&format=pjpg&auto=webp&s=fd9aee92cbd5b1925b9fbc200ba2d34230f1d83d\n\nhttps://preview.redd.it/87zyzvy14vyc1.jpg?width=4096&format=pjpg&auto=webp&s=c2e1cb474f61e4127b1a6487cdfde91ec6978bed\n\nhttps://preview.redd.it/9cdr8f945vyc1.jpg?width=2992&format=pjpg&auto=webp&s=b4f68199024b664116daf3eebe66661ff313b10b",
    "comments": [
      "Write a letter to their support hotline with your receipt and say you want a warranty repair for free because it came damaged\n\nEdit : dude your receipt says defective exchange 30 days. Maybe ask the shop before going to asus",
      "Yeah no kidding! Bring it back to the shop and exchange it asap",
      "Hold on, if it’s under the first year of purchase, aren’t these repairs covered by the manufacturer anyway?",
      "Obviously the part is defective if it snapped off",
      "I’d have just returned it to whatever vendor you purchased it from and say it was like that out the box…",
      "Another person that makes a post about bad warranty handling by Asus while refusing to just go to the store and give it back within 30 days 😂 why do people have no life experience? You go to your store where you bought it say it was like this when you bought it came like this out of the box and ask for a refund. If they decline ask for the manager and so on escalate it 😂",
      "Canada Computers",
      "Why make a post on Reddit for this? Bring it back to the shop you still have 14-15 days left to exchange it. Problem solved.",
      "I am not surprised. Fuck CC",
      "Still doesnt justify asus trying to rip him off. But thanks for your free marketing stunt",
      "Already tried that. Also, it doesn't justify Asus charging 3.7k to repair a plastic piece which is 30% more than retail price for the card. It's been years since I last built a PC and thought service would be better. My mistake.",
      "Send all this info with copies of emails, transcribed phonecalls, receipts, etc. to Gamers Nexus. They dedicate entire stories about manufacturers attempting to renege on their own warranty policies. You may not get an immediate or quick response from Team Steve, but I assure you, as long as you aren't hiding anything, this example of Asus' reliably terrible hardware support is too interesting for them to ignore.",
      "Name the store so they can be shamed into submission.",
      "It’s Canada Computers. Trying to get a refund from them is worse than pulling teeth.",
      "How would someone possibly do that? You'd have to yank the power cable with full force directly away from the card. There's no scenario where that happens unless you did it just to create a Reddit post about it.",
      "My girlfriend bought an open box asrock mobo (along with \\~$1500 in parts) from CC in January, used it for a week without any issue then had to travel for work. Came back two weeks later to a computer that would no longer boot, tested a bunch of stuff and figured the board was dead so she brought it back to CC. The guy put it on his bench, confirmed it was the issue then told her \"yep, it's dead, got to return it. Sucks you didn't get the warranty, can't do anything for you\". She complained to him + the guy that sold it to her and they wouldn't even handle the shipping and belittled her the whole time, claiming \"retail stores never handle warranties anymore, you always need to deal with the manufacturer directly\". I am never spending another dollar there ever again.",
      "I very carefully inserted and removed the power cable because it never \"clicked\" following instructions I pressed the release clip also. Some how the plastic indent got scratched off while doing so. My local store said it was physical damage and they can't help.",
      "Just bring it to another location, say you are seeing artifacting when playing games. Play stupid.",
      "you were already reamed by paying 2799 for a 4090. Maybe they thought if you were foolish enough to buy that, they could rip you off further.",
      "Looks like Canada Computers based on the receipt. Good luck with that."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "top",
    "matched_keywords": [
      "rtx 4090",
      "4090"
    ],
    "title": "If RTX 4090 runs everything you can throw at it, and RTX 5070 is as good with frame gen.. why would anyone buy 5080 or 5090?",
    "selftext": "Yes I know about fake frame gate. But if the generated frames and reflex 2 are really that good and they can get over 120fps in most games.. with relatively small latency.. why get a card that is pricier than that other than to be able to say I have one of the fanciest cards are on the market?  And if frame gen isn't that good.. why upgrade to 50 series instead of picking up cheaper 40 series GPUs?\n\nTLDR: either NVIDIA is telling the truth and AI really is that good and why do we need a more powerful GPU or they aren't and why do we care about 50 series?",
    "comments": [
      "Because that’s marketing bs, you can’t have the same performance as a 4090 with only 12gb of vram, specially if you play at 4K, considering a 4090 user would be playing at 4k so yeah you need a 5080 or 5090.    \n\nCurrently in playing in 4K with a 4080 super and can play everything max at at least 80fps so I don’t need to upgrade this gen but people with older cards might consider it",
      "Ya, the bus width doesn't get the attention it deserves. My min frames are so much more consistent with a 4080s vs even my old 4070ti.\n\nAlso, even if dlss4 is better, framegen and dlss BOTH introduce artifacting. Don't get me wrong they have their place, I even prefer dlss quality vs 4k native on horizon zero dawn, but dlss3.5 has crazy ghosting in cp2077 and frame gen causes terrible stutters and hitches in no man's sky anytime a spinning object is on screen (like refiners).\n\nWorse hardware is worse. Regardless of the software tricks you slap on top to try and mask it.",
      "VR",
      "Frame gen and DLSS have their downsides. Besides latency they also negatively impact visual fidelity. You buy a top tier card to NOT use those AI techniques",
      "Because of this benchmark:\nhttps://store.steampowered.com/app/3309720/GameTechBench/\n\n\nBut seriously, because if you don't/can't want to use upscaling, they are not so powerful. And because you may want to use 4k, or run it at monitors high refresh rates.",
      "It's NOT that good in the first place.\n\n\nI'm actually tired of seeing bullshit over and over again. Thus I'll rather post this.\n\n\nIf the card struggles so much, that you have to use fake image to get some playable experience (with glued gameplay and artifacts) - you need a new card. Which is dumb, since you are already buying a new card.",
      "Same bro cyberpunk tricked out is an experience in its own",
      "Well, they don't make 4090s anymore?  So at some point you have no choice but to buy a 50xx",
      "Can run more stuff without DLSS and frame gen for more fidelity.\n\nAlso, a 4090 cannot run anything and everything in 4k+ at high frame rate. And monitors will go beyond 4k. Games will push more raytracing and other advanced features.\n\nA 4090 cannot run even a current gen game at 4k and high frame rate with ray tracing and all the bells and whistles reliably, nevermind future games.",
      "Because the 5080 and 5090 have more real \"horsepower\". Would I pay a premium for them no but there are people that do and that's fine also.",
      "AI for more images in my RAM. But I wouldn’t. I have a 4090 so I can answer this truthfully haha. So vram requirements for AI is high, like 20 gigs to train high (but can be super low, but more accurate when using more data and higher samples). 12 more gigs of vram is a lot more images I could train at once. Or even video! Video right now is hard to TRAIN on a 4090. I think people use those 18k Au1000 or whatever. But to generate video I’d need at least 40 gigs of vram for some models and the 5090 only (lol) has 36. So no need to rush and buy a new vid card when models and code will probably make it more efficient to run later on. \n\nOn the flip side, if I sell my 4090 I’d get a 5090 only to offset cost. Otherwise I’d never outright buy a new one on top of a 4090. 4090 was a leap of faith when I bought it and was really nervous I’d regret it.",
      "(1) not having to wait (2) future future proofing.",
      "Shhhhhh lol",
      "I would like my GPU to actually \\*render\\*, which is why I bought it. DLSS & other frame-gen technology means nothing to me, and that's even before acknowledging the input lag it generates.",
      "I have RTX4090 and want to upgrade. Is RTX5080 better than RTX4090?",
      "Because I have the money.",
      "There's no real reason to upgrade gen to gen. Some people just enjoy spending the money, same as people who buy the latest phone every year. They're basically paying a gpu subscription at this point lol",
      "Lack of ram",
      "Cause a keen eye notices a difference with native vs ai frames.",
      "consumers of 4090s and 5090s are fools chasing fools gold. leave that shit for ai robots and data centers."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "top",
    "matched_keywords": [
      "rtx 4090",
      "4090"
    ],
    "title": "Should I buy the RTX 4090?",
    "selftext": "Hey all,\n\nI really need some advice. I am going to build a new gaming pc because I still have the RTX 2070 super and an i5 6500k (edit: i5 6700k) cpu. Both are still running very good, and I can run most games, even starfield (30fps) on QHD 144hz.\n\nI wanted to wait for the rtx 5090, but I dont know when it will be released. So I decided to build a good gaming pc now and upgrade the gpu when the 5090 is released.\n\nNow I have build a pc online, I choose the RTX 4080 super, its like 700-800 euros cheaper than the 4090 and it will run games like starfield easy with minimum 60fps.\n\nBut the tought of getting a 4090 instead of the 4080 super is floating in my head because I now have the money for it and wont miss the extra 700 800 euros.\n\nSo should I get the rtx 4080 super of go yolo and buy the 4090? Thanks for reading and thanks for any tips/advice! \n\nEdit: I forgot to mention that I don't need to buy a new monitor, desk, chair mouse keyboard headset etc etc so I can use the 700-800 euros the way I want and both cards are in stock (living in the Netherlands)\n\nEdit 2: I really want to thank you all for all the advice and tips! I will go for the 4080 super (as adviced by many of you) as I dont really need the 4090. I will upgrade to 5090 (if will be possible) and otherwise I will use the card for the 2 3 years. Thx again!",
    "comments": [
      "4080 Super by far. \n\n\nthe 4090 is INSANE for its price tag and you can absolutely use the extra money for other things like a better monitor, or keyboard and mouse combo, or even just further improving your build overall.",
      "with all the AI craze 5090 will be super hard to purchase even after release and could have higher price tag than 4090. They may release in end of this year.\n\nyou should usually get whatever best gpu you can get in your budget\n\nfor this generation this is how it is.\n\n4k high fps - 4090\n\n4k  60fps - 4080/super, 4070tisuper\n\n1440p highfps - 4070ti, 4070super, 4070\n\n1440p 60 fps - 4060ti\n\nanything  4070super and above are significant upgrade to your RTX 2070super",
      "Even if you waited for the 5090 to come out, it's going to be months after release until they're buyable, unless you plan on spending a significant amount of time chasing down restocks. The 4090 came out in September, and I barely managed to get on in December. Realistically, it was more like January until they were buyable. If the 5090 comes out at a similar time period, expect the same or worse due to the AI surge.\n\nIf you aren't going to miss the money, go for it, otherwise you'll be wishing you had gotten it later.",
      "Under full load the 14900 can pull upwards of 250+ watts… that’s on par or even exceeds most mid range GPUs! It’s a beast of a processor, but it takes a massive effort to keep it cool. A case with great airflow and large enough for a 360-420 AIO would be ideal. Otherwise the CPU could throttle itself and you’ll lose out on performance. \n\nFor gaming only, that’s why most people recommend the 7800X3D instead since at max load, you get similar gaming performance to the 14700 / 14900 but it only pulls like 85 watts. Way easier to keep cool and an air cooler is definitely doable with the 7800X3D.",
      "You won't get the 5090 due to crypto and ai. It was hard enough when it was just crypto miners taking all the gpus. Now it's ai on top of crypto and even countries are getting involved. My thoughts are it will be years before the 5090 becomes widely available.",
      "Buy 4080 its good card you will be good and then buy 5090 if money is not the issue",
      "Consider going 7800x3d and upgrading the cpu in 3 years. More cost effective and more performance",
      "If you can afford it, then do whatever you want. I personally wouldn't get the current highest end gpu just to upgrade it again in a year or less. I can't imagine a 4090 becoming obsolete anytime soon, so you wouldn't need to quickly upgrade to a 5090. However, if cost isn't an issue, there's no reason not to do what will make you happy. I'm sure you'll be able to resell your 4090 for a good price to cover a large chunk of the cost of the 5090. \n\nMy personal recommendation would be to do either and not both: Get a 4090 or wait until the 5090 drops. Whichever route you go, you'll notice a freaking enormous jump in performance compared to what you have now.",
      ">I decided to build a good gaming pc now and upgrade the gpu when the 5090 is released.\n\naka\n\n\"I decided to pay $1800 after taxes now, and then another $2000 in a year\"\n\nif you can casually just throw money away at your hobby then go for it. We don't know what your financial situation looks like.\n\nSeems kinda weird to wait from 2070 and then suddenly UBERSPLURGE lol\n\nfinally... expect 4090 to drop to 1k or less the moment the 5090 drops with DLSS 4.",
      ">Both are still running very good, and I can run most games, even starfield (30fps) on QHD 144hz.\n\nConsidering you equate \"running very good\" with gaming at 30fps on a 1440p (144hz) monitor, it's clear that you don't really need either GPUs (4080 nor 4090) atm - especially since you're not upgrading your monitor. \n\nThat said, I'd just get a placeholder GPU, like the **4070 (super)**, and if the 5090 seems worthwhile then sell your placeholder GPU; however, I seriously think you won't miss nor utilize the extra performance as you'll (likely) use frame gen and aren't a high-end/enthusiast gamer.\n\nAs for the extra money saved? Just place it in an alternative bank account or in a physical (safe) location until you have a use for it. \n\n  \ntl;dr: just get the RTX 4070 (super) as you'll unlikely utilize/need the extra horsepower, especially with frame gen. Trade up if things change.",
      "Buy the 4070 TI Super instead",
      "If you got the money. Get the 4090. The performance is insane and nothing else beats it. You won't regret it, as long as what you said about not missing the extra 7-800 is actually true.",
      "Get the RTX4090 bro. Life is short. Enjoy that shit!",
      "I recently editted my post, I dont need a new keyboard, monitor etc. Can I share my build so you can recommend some upgrades?",
      "If only that was true. There’s been so many gpu intensive games that can’t even hit 100fps with 4090 on 1440p like cyberpunk and Alan wake 2. It’s only gonna get worse as more games come out, like the wukong one with path tracing.",
      "If you're deadset on getting the 5090 and you want a 4000 series to hold you over, then the 4080 super would be the most economical choice. If you want to save even more, then look at 4070 ti/super, etc. It will still be a massive improvement, and unless you're running 4k ultra settings, that will hold you over just fine.",
      "I'd go with the 4080S. I went from 2070S to 4080 and the jump was MASSIVE. Certainly satisfactory. I'll prolly wait for the 6080 at this point I'm really happy with the 4080 as a card (price wasn't great) and love how efficient it is. Runs typically around 260~Watts and I play in 4k. The 4080S is plenty for any 1440p you can throw at it and almost overkill already without path tracing",
      "Hi.\n\nyou'll DEFINITELY need a 1000W PSU if you plan on 4090+14900k.\n\nplus get an liquid cooler for that, forget about aircooling. If you plan on gaming mostly, you definitely don't need a 14900k, I'd save a couple of hundreds bucks and go for 14700k or AMD equivalent\n\nI would personnally go for much higher clocked memory ( 6600 at least )",
      "But 7800X3D is much better CPU than 14900 if you are not planning for productivity stuff. You won't have to upgrade for longer than with 14900, and if you want to upgrade AM5 is a much longer lasting platform.",
      "I suggest you look up gaming performance benchmark comparing the 4080 super and 4090 at your gaming resolution of personal preference. See for youself if you need the performance of the 4090."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "top",
    "matched_keywords": [
      "rtx 4090",
      "4090"
    ],
    "title": "RTX 5080 Overclocking vs RTX 4090 Perf - A Bit More Like It?",
    "selftext": "",
    "comments": [
      "\\> it’s pretty much solidified you shouldn’t be upgrading from a 4090 at this point\n\nNot a single person has ever said this btw",
      "in real gaming it's a different story.  Gamer Nexus saw some great synthetic benchmark numbers with 5080 OC'ing, but these translated to only 5-7% better FPS in actual games.\n\nAnd that's without stability testing.",
      "That's pretty much what digital foundry is saying, did you even watch the video? Or do you write comments based on thumbnails?",
      "If you have a 4090, why would you even be considering getting a 5080.",
      "No, not more like it, it should have been +20% performance increase over an RTX4090.\n\n  \nMoving on, bye.",
      "Copium",
      "Why are they comparing Stock 4080super and stock 4090 with 5080overclock? If you want make video about overclocking overclock all cards and not only one..\n\nLooks like they just trying make 5080 looks good? Both 4080super and 4090 oc pretty decent aswell.",
      "?????",
      "What's more interesting to me is setting a PL or undervolt, then adding back core mhz with an OC. I was able to set my 5080 to 70% PL, then set a +300mhz OC and hit 3000mhz on the core with much less wattage and heat. Took CP2077 from ~290-300W to 250W with exactly the same performance. \n\nEspecially with all the cable melting details coming out, I think power limiting is a smart idea vs pushing the card to the max.",
      "Raster, RT and 2x FG.  The 4x MFG is 50-exclusive but most agree is irrelevant to almost everyone as you need minimum 60fps to make it worth it.  So unless you got a 240mhz monitor MFG won't be relevant.",
      "The amount of copium to justify 5080 is insane, it’s pretty much solidified you shouldn’t be upgrading from a 4090 at this point.",
      "Even 10% over 4090 on stock clocks. 15% when overclocked would've been fine",
      "There are basically 2 different ways to undervolt. Both are explained in this video here: \n\nhttps://youtu.be/KPR06CxysMw?si=X3JvOJZuR9EEiPtP\n\nThere are users reporting some weird inconsistencies with 5x series using the VF curve method, so I went with method 2 which is much quicker but not as fine tuned as a true VF curve adjustment.",
      "Not really true and kind of the opposite, the 4080S ships with underclocked memory and pretty much all of them can take a nice +1300MHz increase. Along with a modest core clock boost, you can get 7-10% out of most of them which is good, though not as much as the 5080, but close.",
      "Exactly, it’s just copium at this point.",
      "You're on something else lol. MFG is not the future buddy it's a gimmick that'll get pushed to the back with the 60 series when they make real development. 60 FPS > 30 FPS made into 120 FPS with MFG. That's how it is and how it will always be.",
      "Then we peaked and there’s no point continuing to release graphics cards, as rasterization is no longer the primary focus, whether you like it or not.",
      "DF mention 10-12% improvement which lines up with what Techpowerup got from their 5080, which was 12% in 3DMark. However Techpowerup compared their 5080 OC to their 4080S OC and saw that the 5080 only overclocked 3% better, as in the 4080S oc'd 9%, the 5080 saw 12%\n\nSo the 5080 is still underwhelming",
      "Is that before or after the MFG, which is the whole point of the 5000 gen cards",
      "Is there a good tutorial on doing something like this\n\nI've never OC before and I wanna try undervolting for those reasons you said"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "top",
    "matched_keywords": [
      "rtx 4090",
      "4090",
      "rtx4090"
    ],
    "title": "Sold my RTX3090 Ti FTW3; hello RTX4090…",
    "selftext": "I replaced this with RTX 4090 (see second pic and mind the dust), and was surprised to see this go quickly on the ‘bay. Wanted a quick sale and let this go for about 70% of the average second hand value. \n\nI’ve got 3x more desktops with GTX1080s, two are EVGA FTW3 and another is an Asus OCed version - from which I think I’ll let one more go (EVGA).\n\nI ran a few benchmarks on this RTX4090 card and it wasn’t too shabby. Need to get DCS setup hopefully tomorrow.",
    "comments": [
      "That 4090 in that case looks like if someone had a Ferrari but lived in a tent.",
      "bro had to remove the front case fans xd\nmaybe invest in a bigger case?",
      "This is the most expensive, most jank setup I've seen in a long time",
      "RIP EVGA",
      "Real😭💀",
      "Lived in a tent with a pile of dust that was never cleaned))",
      "“Airflow? What’s air flow?”",
      "Don’t worry, that 4090 will blow all that dust out of the case /s",
      "Im not joking, you need some better case. Maybe something from phanteks",
      "https://preview.redd.it/64byw9bqb6md1.jpeg?width=1600&format=pjpg&auto=webp&s=6fd638e9c1b951c97be89983dff3eabcce9defe2\n\nMy rigs are to the left at the moment. Let me share a snap soon. It’s totally 🤦‍♂️",
      "I hope 5090 comes soon",
      "Haha yes I did. It’s a big Corsair case that’s EATX compatible and I almost couldn’t fit the card in. Its size is just insane.",
      "do you light candles as substitute for rgb?",
      "You have money for engine but not for rest of the car parts and garage",
      "Nice but considering the 5000 series is around the corner I'm gonna be waiting to upgrade my 3090.",
      "juggle sparkle wide command nine handle start bear many sense\n\n *This post was mass deleted and anonymized with [Redact](https://redact.dev/home)*",
      "I mean I see the issue. 💀 You need an X3D processor dog.",
      "i had a friend like this. engineer, couldn't write for shit, house was a fucking mess, but if you were able to take your eyes off the 1950s decor and trash everywhere, you'd see the 10s of thousands of dollars worth of computers and AV equipment hidden in plain sight. dude just didn't care for frivolities, as he put it, only what was practical.",
      "4090 ‘not too shabby’… it’s the fasted GPU you can buy. 🤣",
      "i9-7920X?\n\nMaan, your CPU is the bottleneck here."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "top",
    "matched_keywords": [
      "4090",
      "rtx4090"
    ],
    "title": "Game Suggestions for RTX-4090",
    "selftext": "I am excited to get the new RTX4090 - I tried it with [The Quarry](https://store.steampowered.com/app/1577120/The_Quarry/)  Works amazing :) I was looking for some suggestions on what games should I get to **visually experience** 4090's power.\n\n* I Will highly appreciate 3rd person games only also, please.\n* I was thinking about  [The Callisto Protocol](https://store.steampowered.com/app/1544020/The_Callisto_Protocol/) but the game seems to not score very well Unfortunately\n\nPlease share some of your suggestions :)",
    "comments": [
      "Ratchet & Clank\n\nPortal RTX\n\nWitcher 3 RTX\n\nCrysis Remastered\n\nJedi Survivor looks great but runs like ass on most PCs due to being a shoddy port - there's a DLSS3 mod someone made which helps a lot, though.\n\nResident Evil 4 Remake (get the DLSS mod)",
      "The Witcher 3 with ray tracing max settings looks stunning, also the best RPG ever made, can't go wrong with it",
      "Control is a beautiful game with a really intriguing world/story",
      "Yeah, it's a shame that they don't like Cyberpunk when they have a 4090. It's the best looking game out there right now for ray tracing, imo. I actually hate cyberpunk in the beginning, but once I got to the title screen like 8 hours in, it finally clicked for me. Now I think it's one of my favorite games.",
      "Hogwarts legacy, Red Dad Redeption, Baldurs Gate 3, Sid Meyer's Pirates",
      ">The Witcher 3 ...  the best RPG ever made \n\nI don't want to pick a fight, but The Witcher 3 is a very watered-down RPG, if at all. It's a great game, but I don't consider it strictly an RPG at all. You don't get to create your own character with your own backstory, your choices are all deterministic - you either can convince someone or can't and that's up to the writers, not game systems, and the game heavily leans towards certain decisions, practically disregarding other choices you can make with those paths having very few dialogue options for example, if they are not considered \"canon\". \n\nIt's a great game that I've spent countless hours on, but I'd say it's more of a story-driven action game with RPG elements. Playing the Witcher 3 after Baldur's Gate 3, for example, expecting the same amount of intractability and branching storylines is just going to be a disappointment, even though the Witcher 3 is amazing in its own right.\n\nBut in any case, the next gen update of The Witcher 3 looks very good, although it doesn't run all too well without Frame Generation. The game is great, the gameplay is awesome and the story and characters are top notch.",
      "Better reflections (base game had shitty ones), proper AO, detailed soft shadows, and especially RTGI makes the game an eye candy.\n\nOlder games benefit from RT a lot, because the lighting systems were more limited back then.",
      "Why don't you like Cyberpunk? I could see someone hugely violence or gore opposed not liking it but then you say you're thinking about Callisto Protocol (a game which also runs far worse, bogged down with engine problems).It's an incredible game with an insane level of detail and beautiful environments and with the path tracing update it's absolutely at the cutting edge of graphics engines, the best showcase for the top end card you have.\n\nEdit: Callisto is an ok game, but you will complete it in about 15-20 hours and then there is no point playing again as it's totally linear. Cyberpunk you can run through just the main quest line in something like 30 hours but if you actually play it more as an RPG should be played and try build up your character doing lots of side quests and exploring you can put a lot more time into it if you wish there are people who have hundreds of hours in now, it's fantastic value for money.",
      "Yeah Ratchet & Clank (that'll give you your first heart attack when it crashes it) it looks amazing when it's working!\n\nYou'll be astonished about what it does to games you already own things like AC Origins, Odyssey and Valhalla, Assetto Corsa, Resident Evil games and GTA V.",
      "It got a ray teacing next gen update and new ultra settings for the graphics. It looks really good!",
      "Metro Exodus Extended Edition then :) Or Hogwarts Legacy",
      "That game got **a lot** of updates.",
      "A Plague Tale: Requiem, though you might want to play Innocence first.",
      "Many good suggestions here.   \nI will add Guardians of the Galaxy. Recently played it and it ran and looked great on a 4090 at 4K. It's honestly one of the most fun games I've played in a long time.  \nI also liked Uncharted: Legacy of thieves. The story is good, the visuals are great, the gameplay for me was just OK, but depending on what you like you might love it.",
      "Going to be honest, its hard to justify the 4090 these days purely for visual appeal. Most games are built for mid specs and don't scale that well unless 4k120 is your thing. There used to be a time where these high end cards were really great to own since you'd see a night and day difference between builds, but now even my old 2070s can play most stuff at 4k with dlss, or 1440p for those nasty unoptimized titles, which unironically the 4090 struggles with too, just check remnant 2. So idk, you're not really visually experiencing the 4090's power that way imo. I'd recommend PS titles, they all look good, Last of Us especially. Portal RTX is also great to check out, more a tech demo than anything.\n\n&#x200B;\n\nWhere I can definitely say the 4090 shines and shows is VR. That's a night and day difference even against the 4080 if you have a high end headset or smt really high res (g2, pimax crystal, varjo aero, and I'm placing the quest 3 and pro here as well even tho the pro is lower res)\n\n&#x200B;\n\nThing is since you need high framerates with VR titles, usually you own these headsets but end up lowering resolution, graphics, etc. You compromise a lot to achieve smoothness. The 4090 however maxes everything out but ACC and MFS on the pimax (it can be done with DFR enabled afaik but hard to keep the 120, games fault not the gpu). This means you get crystal clear image with the best fidelity available and I can't remember the last time I had an experience like that, maybe when I got my hd4870 back in the day and played crysis? The rest was pretty incremental, I'd say recently the only game that really wow'ed me on flatscreen was Red dead 2 on pc release.\n\n&#x200B;\n\nIf you end up going the VR route, I'd recommend racing games, Automobilista, ACC are insane in VR (here's hoping forza motorsport has vr support when it releases), Half life Alyx, Lone Echo 1 and 2 (upscale the hell out of them), MS Flight Sim, all resident evils with the vr mods. There's more cool games, but I wouldn't say they are the most good looking, at least nothing impressed me visually outside of those, the others are more about the experience overhaul.",
      ">Ratchet & Clank\n\nwow  [Ratchet & Clank: Rift Apart on Steam (steampowered.com)](https://store.steampowered.com/app/1895880/Ratchet__Clank_Rift_Apart/)  looks stunning too - Do I need DLSS if I am playing on 4090 - I will try 4k and Ultrawide 1440p both",
      "I'm playing at 4k with DLAA + frame gen and all settings maxed, I avg 100-110fps, If I switch to DLSS quality I get around 140fps.",
      "Yes this!",
      "It's an 'older' game by Control looks amazing, specifically the environments.\n\nBut Alan Wake 2 I'm sure is going to stun when it comes out soon",
      "I have red dead 2 but not the others, I will try red dead (Have been thinking to get BG3) - Pirates you mean this?  [Sid Meier's Pirates! on Steam (steampowered.com)](https://store.steampowered.com/app/3920/Sid_Meiers_Pirates/)"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "top",
    "matched_keywords": [
      "4090",
      "rtx4090"
    ],
    "title": "nVidia GeForce RTX 4080 Meta Review",
    "selftext": "- compilation of 10 launch reviews with ~3420 gaming benchmarks at all resolutions\n- only benchmarks at real games compiled, not included any 3DMark & Unigine benchmarks\n- geometric mean in all cases\n- standard rasterizer performance without ray-tracing and/or DLSS/FSR/XeSS\n- extra ray-tracing benchmarks after the standard rasterizer benchmarks\n- stock performance on (usual) reference/FE boards, no overclocking\n- factory overclocked cards _(results marked in italics)_ were normalized to reference clocks/performance, but just for the overall performance average (so the listings show the original result, just the index has been normalized)\n- missing results were interpolated (for a more accurate average) based on the available & former results\n- performance average is (moderate) weighted in favor of reviews with more benchmarks\n- for the full results plus (incl. power draw numbers) and some more explanations check [3DCenter's launch analysis](https://www.3dcenter.org/artikel/launch-analyse-nvidia-geforce-rtx-4080)\n\n&nbsp;\n\n2160p Perf.|6800XT|6900XT|6950XT|3080-10G|3080Ti|3090|3090Ti|4080|4090\n|:--|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|\nGen & Mem|RDNA2 16GB|RDNA2 16GB|RDNA2 16GB|Ampere 10GB|Ampere 12GB|Ampere 24GB|Ampere 24GB|Ada 16GB|Ada 24GB\nComputerB|63.6%|70.2%|-|67.1%|74.8%|_80.3%_|84.4%|100%|134.2%\nEurogamer|64.9%|70.2%|-|68.4%|75.9%|78.3%|86.3%|100%|128.5%\nIgor's|63.8%|67.8%|_75.9%_|63.0%|78.6%|80.4%|88.1%|100%|135.3%\nKitGuru|65.4%|71.2%|_77.0%_|68.6%|75.3%|77.4%|85.4%|100%|132.1%\nLeComptoir|62.6%|68.6%|_75.6%_|66.3%|74.3%|77.1%|84.7%|100%|136.5%\nPaul's|-|68.3%|_71.8%_|-|73.7%|75.2%|_84.9%_|100%|127.7%\nPCGH|65.6%|-|75.1%|67.3%|-|-|84.3%|100%|133.9%\nPurePC|62.7%|67.3%|_72.7%_|66.7%|74.0%|76.0%|83.3%|100%|131.3%\nQuasarZ|64.8%|71.4%|76.6%|68.5%|76.4%|78.0%|84.5%|100%|132.9%\nTweakers|65.1%|-|75.0%|68.6%|-|75.6%|_86.6%_|100%|129.2%\n**average 2160p Perf.**|**64.3%**|**69.9%**|**74.2%**|**67.2%**|**75.3%**|**77.4%**|**84.8%**|**100%**|**132.2%**\nTDP|300W|300W|335W|320W|350W|350W|450W|320W|450W\nreal Consumption|298W|303W|348W|325W|350W|359W|462W|297W|418W\nMSRP|$649|$999|$1099|$699|$1199|$1499|$1999|$1199|$1599\n\n&nbsp;\n\n1440p Perf.|6800XT|6900XT|6950XT|3080-10G|3080Ti|3090|3090Ti|4080|4090\n|:--|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|\nComputerB|65.3%|71.7%|-|67.7%|74.0%|_79.4%_|82.4%|100%|116.6%\nEurogamer|68.6%|73.4%|-|68.4%|75.6%|78.1%|84.1%|100%|114.8%\nIgor's|68.5%|72.6%|_80.4%_|71.1%|78.3%|79.9%|85.3%|100%|120.3%\nKitGuru|68.4%|74.3%|_79.8%_|69.1%|74.8%|77.0%|83.8%|100%|118.6%\nLeComptoir|65.2%|70.9%|_77.2%_|64.9%|72.4%|75.1%|81.2%|100%|121.4%\nPaul's|-|78.1%|_81.5%_|-|78.9%|79.8%|_87.8%_|100%|115.0%\nPCGH|67.9%|-|77.3%|67.2%|-|-|81.4%|100%|123.3%\nPurePC|65.1%|69.8%|_75.2%_|67.1%|73.2%|75.2%|81.9%|100%|125.5%\nQuasarZ|69.8%|76.3%|80.6%|71.9%|78.6%|79.9%|85.0%|100%|120.6%\nTweakers|69.5%|-|79.5%|69.4%|-|77.2%|_84.1%_|100%|121.7%\n**average 1440p Perf.**|**68.3%**|**73.8%**|**77.8%**|**68.9%**|**75.8%**|**77.6%**|**83.4%**|**100%**|**119.3%**\n\n&nbsp;\n\n1080p Perf.|6800XT|6900XT|6950XT|3080-10G|3080Ti|3090|3090Ti|4080|4090\n|:--|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|\nKitGuru|74.6%|79.8%|_81.4%_|74.1%|79.3%|81.4%|86.5%|100%|108.0%\nPaul's|-|89.4%|_93.2%_|-|87.1%|87.3%|_94.0%_|100%|110.1%\nPCGH|71.8%|-|80.4%|69.3%|-|-|81.2%|100%|116.6%\nPurePC|67.8%|71.9%|_77.4%_|68.5%|74.7%|76.7%|82.2%|100%|121.2%\nQuasarZ|75.0%|80.8%|84.6%|77.2%|81.5%|83.4%|86.8%|100%|111.3%\nTweakers|72.3%|-|81.8%|72.0%|-|78.8%|_83.3%_|100%|113.4%\n**average 1080p Perf.**|**75.2%**|**79.8%**|**83.7%**|**74.4%**|**79.9%**|**81.5%**|**85.5%**|**100%**|**112.5%**\n\n&nbsp;\n\nRT@2160p|6800XT|6900XT|6950XT|3080-10G|3080Ti|3090|3090Ti|4080|4090\n|:--|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|\nComputerB|45.9%|50.6%|-|60.1%|73.0%|_78.9%_|83.5%|100%|137.7%\nEurogamer|43.1%|47.5%|-|64.5%|74.1%|76.7%|85.4%|100%|140.7%\nKitGuru|46.5%|50.8%|_54.5%_|61.1%|71.3%|73.3%|82.3%|100%|137.4%\nPurePC|42.6%|45.7%|_49.4%_|61.7%|71.0%|72.8%|82.7%|100%|142.6%\nQuasarZ|49.2%|53.3%|57.2%|64.2%|73.2%|74.5%|81.6%|100%|136.1%\n**average RT@2160p Perf.**|**45.5%**|**49.7%**|**52.9%**|**61.9%**|**72.6%**|**74.8%**|**83.2%**|**100%**|**138.7%**\n\n&nbsp;\n\nRT@1440p|6800XT|6900XT|6950XT|3080-10G|3080Ti|3090|3090Ti|4080|4090\n|:--|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|\nComputerB|50.5%|55.2%|-|68.3%|75.0%|_80.2%_|83.4%|100%|120.6%\nEurogamer|46.5%|50.2%|-|67.6%|74.4%|77.5%|85.0%|100%|130.8%\nKitGuru|48.3%|52.6%|_56.4%_|66.2%|72.6%|74.4%|82.0%|100%|117.8%\nLeComptoir|47.7%|51.5%|_56.3%_|63.2%|70.8%|73.2%|79.7%|100%|128.6%\nPurePC|43.7%|46.2%|_50.0%_|63.3%|70.9%|73.4%|81.0%|100%|136.7%\nQuasarZ|55.3%|59.9%|63.1%|70.7%|77.8%|78.9%|84.9%|100%|124.1%\n**average RT@1440p Perf.**|**48.7%**|**52.7%**|**55.7%**|**66.3%**|**73.4%**|**75.6%**|**82.3%**|**100%**|**125.8%**\n\n&nbsp;\n\nRT@1080p &nbsp; &nbsp; |6800XT|6900XT|6950XT|3080-10G|3080Ti|3090|3090Ti|4080|4090\n|:--|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|\nKitGuru|52.8%|57.9%|_61.4%_|72.3%|77.8%|80.0%|86.0%|100%|109.7%\nPurePC|43.9%|47.1%|_50.3%_|63.7%|72.6%|74.5%|81.5%|100%|136.3%\n\n&nbsp;\n\nGen. Comparison|RTX3080-10G|RTX4080|Difference|RTX3090|RTX4090|Difference\n|:--|:--:|:--:|:--|:--:|:--:|:--|\naverage 2160p Perf.|67.2%|100%|**+48.8%**|77.4%|132.2%|+70.8%\naverage 1440p Perf.|68.9%|100%|+45.1%|77.6%|119.3%|+53.7%\naverage 1080p Perf.|74.4%|100%|+34.4%|81.5%|112.5%|+38.0%\naverage RT@2160p Perf.|61.9%|100%|+61.6%|74.8%|138.7%|+85.4%\naverage RT@1440p Perf.|66.3%|100%|+50.8%|75.6%|125.8%|+66.4%\nTDP|320W|320W|±0|350W|450W|+29%\nreal Consumption|325W|297W|–9%|359W|418W|+16%\nMSRP|$699|$1199|**+72%**|$1499|$1599|+7%\n\n&nbsp;\n\nFE vs AIB Models|Boost Clock|real Clock|Power-Limit /max.|real Consumpt.|Hotspot|Loudness|2160p Perf.\n|:--|:--:|:--:|:--:|:--:|:--:|:--:|:--:|\nnVidia Founders Edition|2505 MHz|2737 MHz|320/355W|304W|73°C|34.3 dBA|100%\nAsus Strix OC|2625 MHz|2859 MHz|360/420W|340W|72°C|32.1 dBA|+3%\nColorful Ultra White OC|2610 MHz|2803 MHz|350/370W|331W|76°C|40.1 dBA|+2%\nGainward Phantom GS|2640 MHz|2855 MHz|340/400W|338W|74°C|31.5 dBA|+2%\nMSI Gaming X Trio|2595 MHz|2824 MHz|320/370W|328W|79°C|26.9 dBA|+2%\nMSI Suprim X|2625 MHz|2861 MHz|320/400W|321W|76°C|26.8 dBA|+2%\nPNY Verto OC|2550 MHz|2779 MHz|320/320W|318W|74°C|26.1 dBA|+1%\nZotac AMP Extreme Airo|2565 MHz|2840 MHz|320/450W|318W|73°C|36.9 dBA|+2%\n\n&nbsp;\n\nNote: This analysis only refers to reviews that used nVidia driver 521.90 (or newer) for RTX30 cards, because older drivers can overestimate the RTX40 performance effect. Since quite a few reviewers used older RTX30 drivers for this launch, there is one task for the upcoming RX7900 launch: **Please update drivers!**\n\n&nbsp;\n\nSources:    \nBenchmarks by [ComputerBase](https://www.computerbase.de/2022-11/nvidia-aus-msi-zotac-geforce-rtx-4080-review-test/), [Eurogamer](https://www.eurogamer.net/digitalfoundry-2022-nvidia-geforce-rtx-4080-review-a-powerful-gpu-with-a-big-pricing-problem), [Igor's Lab](https://www.igorslab.de/nvidia-geforce-rtx-4080-founders-edition-24gb-im-test-schneller-als-gedacht-und-sparsamer-als-befuerchtet/), [KitGuru](https://www.kitguru.net/components/graphic-cards/dominic-moass/nvidia-rtx-4080-founders-edition-review/), [Le Comptoir du Hardware](https://www.comptoir-hardware.com/articles/cartes-graphiques/46900-test-nvidia-geforce-rtx-4080.html), [Paul's Hardware](https://www.youtube.com/watch?v=T8lS4v3-Nyg), [PC Games Hardware](https://www.pcgameshardware.de/Geforce-RTX-4080-16GB-Grafikkarte-279171/Tests/Release-Benchmark-Specs-Kaufen-Preis-1407013/), [PurePC](https://www.purepc.pl/test-kart-graficznych-nvidia-geforce-rtx-4080-vs-geforce-rtx-3090-ti-bylaby-rewelacja-gdyby-nie-zaporowa-cena), [Quasarzone](https://quasarzone.com/bbs/qc_bench/views/82726), [TechPowerUp](https://www.techpowerup.com/review/nvidia-geforce-rtx-4080-founders-edition/), [Tweakers](https://tweakers.net/reviews/10638/nvidia-geforce-rtx-4080-de-enige-echte-4080.html)    \nCompilation by [3DCenter.org](https://www.3dcenter.org/artikel/launch-analyse-nvidia-geforce-rtx-4080)",
    "comments": [
      "Sigh.\n\nYes the 4090 might actually be better FPS per $, but calling a $1600+ GPU a 'better value' and 'bang for buck performance' is disgusting. \n\nI hate this launch, but AMD coming up short with performance means they likely wont be much better. Duopolies suck.",
      "The 4090 is 38.7% faster in raytraced 4K, which means it's a better value at $1600 vs $1200.  Considering most people are buying these cards to play games at 4K with raytracing, you're get more bang for buck performance with the 4090, plus 24 GB VRAM.",
      "The 4000 series really dumped all its stat points into raytracing.",
      "Thanks. 18-20% faster than 3090 Ti, 28% faster than 3090, and 48% faster than 3080 at. Gap grows with RT, 32% faster than 3090 at 1440p, which is DLSS Quality base resolution at 4k. \n\nPeople here are going to hate it, but the 4080 is selling out in the US for online retailers. Best Buy, Amazon, Newegg, all models at MSRP are gone. That doesn't go along with what some dumbass Techtubers say though, and the narrative that we want to believe. Even physical stores the MSRP models are gone, leaving only the heavily overpriced cards. In the coming months, I think AIB 4080 will remain at MSRP or under, and the 4090 will cast away its msrp models.\n\n7900XTX is likely to be 5-10% faster going with these results for $200 less at msrp. If the 4090 wasn't available and I absolutely had to pick one, the 4080 is a very easy choice between the two. DLSS3/DLAA, faster RT, and all the extras when it comes to software.",
      "Its a great 4k card nevermind 1440p.",
      "How is it not bad? This is a new generation. You should be getting lower end cards that beat the high end of last gen for LESS. Otherwise what is the point? Will the 5090 be $3000?\n\nThe 1070 was equal to the 980Ti for $300 less, the 2060 was equal to a 1080 for $300 less...",
      "So twice the cost of the last gen cards and 30 percent more performance.\n\nAND less value for money than the overpriced 4090. \n\nGreat",
      "Mate, where have been the last 5 years? Last time GPU prices made sense was Pascal",
      "So 4070ti will be on par with 3090ti for $899?",
      "There is too much performance gap to label it the Ti",
      "it's pretty close to raster tbh\n\n3080 10GB probably just didn't have enough memory to cut it at 4k RT, but at 1440p RT it seems pretty close in the percentages with raster\n\nand for the 4090, I suspect the raster perf is sometimes still bottlenecked even at 4k, and the card stretches its legs more often with RT on",
      ">30 percent more performance.\n\nMinor nitpick, but that's not now percentages work. You divide by the lower number, not subtract it from 100%.\n\nIf you scroll down it even says the 4080 is **48.8% faster** than the 3080 at 4k and **45.1% faster** than 3080 10GB at 1440p",
      "Came from a 2080ti + waterblock. I'm ashamed to say I'm used to these prices now 😔",
      "If the price goes down on the 4080 it’ll be a great 1440p card. But looking at this.. just get an ampere card or an amd card",
      "Here's a crazy stat for you. Do you wanna know how much more expensive the 3090ti was over the 2080ti? 800$. \n\nYou're literally comparing it to the largest price increase in the history of graphics cards. Ever. And I'm now comparing that with the other largest price increase, ever, in the 2080Ti compared to the 1080ti. Close to 3x in 2 gens, and now you're applauding nvidia for making 1000+ the new mid range. Fantastic.\n\nEven at 1000$ the 4080 is a hard pass.",
      "If you're spending over $1k, it really doesn't make much sense to go with the 4080 to be fair.\n\nI'm not so sure that Nvidia's plan to reset the high end at above $1k will work, as those willing to spend that much will want the best, not the distant 2nd.",
      "$700 3080 in late 2020 (and the first few weeks of 2021) wasn't bad.",
      "It's seems you still don't get it you can't have  the same performance price ratio with last gen cards , so 6090 will cost 10000 is it OK with you  do you finally get it?",
      "To even give further context the 2060 wasn't particularly well received for its hefty price increase (there's a pattern here somewhere) over the 1060. And still superior value compared to Ada.",
      "Here is my review. It's overpriced and not worth it for any situation."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "top",
    "matched_keywords": [
      "rtx 4090",
      "4090",
      "rtx4090"
    ],
    "title": "Which one is better? Gigabyte RTX4090 WINDFORCE OC or GIGABYTE RTX 4090 GAMING OC?",
    "selftext": "I am considering upgrading my GPU to a 4090 and I saw these two models.\n\nThe Gigabyte RTX4090 WINDFORCE OC is 140$ cheaper than the other one.\n\nDoes the GAMING OC version provide better performance that justify being $140 more expensive?\n\nThanks",
    "comments": [
      "This is some shill elitism. Not based in reality.",
      "I have the Gaming OC. It's one of the coolest and quietest graphics cards I've ever used. Even at full load I can barely hear it, no coil whine. Highly recommend.",
      "We probably will.\nThe issue is availability imo. #Fu**Scalpers",
      "They at last made new bios for gaming so I’d say gaming",
      "Gigabyte I've been seeing has been earning a good reputation regarding coil whine",
      "Wait for the 5090 to come out just to wait for it to come in stock for months to a year",
      "Some say the 5090 is just around the corner.\n\nIt might be worth it to wait a bit to either get a new 5090 or an even cheaper 4090.\n\nIt's all speculations as of now, so.",
      "Wind force still has adequately cooling. Even if it is the worst, and what’s your source on that btw, it still gets the job done. All of the 4090s have great temps.",
      "It fixes fan curve",
      "4090 gaming oc owner here, I've had mine since the end of October of 2022 since the launch. I've got to say I haven't had any coil-whine, and if there is it very, very low. It has  great cooling when playing for hours at a time on high and ultra settings on games, I roughly get 62-68°C. \n\nI also have a mid-size case with plenty of airflow, so that may also contribute to the low temperatures. This was my very first Gigabyte card, I had always used EVGA or Nvidia founders editions. So far, I have no regrets on my first Gigabyte purchase.",
      "\"OC\" is just BS and wasted money, you can OC the card yourself and probably higher than the crappy 25 extra mhz they advertise, go for the better cooler",
      "Windforce is the base model, Gaming lineup has better cooling, power phases and components overall.\n\nBoth will do just fine, its down to if u want a better quality product or not.",
      "There is a new bios, first I've heard of it!",
      "Hoping we get the 5090 towards the end of the year",
      "I was thinking that, but I am afraid that it won't be available until the next year, even if it will be announced later this year.",
      "It’ll be scalped for 3K for the first year",
      "Thank you.",
      "I literally have 42 of these cards. Over the past year and a half, only 1 broke and had to be sent back. Another one has broken gigabyte led logo on the side but otherwise functions fine.\n\nThose are the only issues I've had in all this time with the gaming oc cards.",
      "I checked it for a half of a year and it finally here",
      "And priced at $1999"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "top",
    "matched_keywords": [
      "rtx 4090",
      "4090",
      "rtx4090"
    ],
    "title": "Is it worth buying RTX 4090 from Palit if it's $750 cheaper than MSI and ASUS?",
    "selftext": "I'm currently building a new PC for myself (I know almost nothing about PC components) and I'm stuck with GPU.\n\n&#x200B;\n\nIn stock I have:\n\n**$2750** – ASUS PCI-Ex GeForce RTX 4090 TUF Gaming OC Edition 24GB GDDR6X (384bit) (2595/21000) (2 x HDMI, 3 x DisplayPort) (TUF-RTX4090-O24G-GAMING)\n\n&#x200B;\n\n**$2500** – MSI PCI-Ex GeForce RTX 4090 Ventus 3X 24G OC 24GB GDDR6X (384bit) (2550/21000) (HDMI, 3 x DisplayPort) (RTX 4090 Ventus 3X 24G OC)\n\n&#x200B;\n\n**$2000** – Palit PCI-Ex GeForce RTX 4090 GameRock OmniBlack 24GB GDDR6X (384bit) (2520/21000) (1 x HDMI, 3 x DisplayPort) (NED4090019SB-1020Q)\n\n&#x200B;\n\nSo the question is which one to choose? I read a lot of topics saying that ASUS has problems with fans being loud and that Palit has very bad build quality. But does it worth spending $500-750 more in that case? I plan to use this GPU only in games, and I know nothing about boosting and etc so probably won't do anything of that.And yes I read the topics where people say all is ok, but that was like 4-5 months ago, so dunno if the community experience is changed.  \n\n\n**UPD:** Decided to buy the cheapest one (Palit GameRock) thanks to comments",
    "comments": [
      "yes",
      "Someone that has a 4090, I went for the cheapest available at the time of purchasing. They are over engineered, with the same power, essentially\n\n- Did I want the FE Edition? Yes, but it was sold out in Canada on launch day. \n- Would I have liked the Suprim 4090 more than my eventual Gaming Trio from MSI? Sure it looks better, but it was also $150 more for the same power, and was not in stock\n- I would've chosen the Ventus 3X from MSI instead of my Gaming Trio if it was in stock\n\nI went with the Gaming Trio",
      "Yes. All 4090s are overengineered as the chip performs much more efficiently and runs far cooler than initially expected -- even the worst cooling solutions will still keep the card plenty cool, and it's a genuine struggle to get it anywhere close to the highest power limits, even if you push it hard.\n\nWhen buying a 4090, you go for the cheapest option that's available.",
      "Clearly he can afford it so I don’t see a problem when the card is this good lol",
      "My gamerock has been fine. Can't complain. 61c most of the time\n\nhttps://preview.redd.it/fqkjn3g0xkaa1.png?width=1080&format=pjpg&auto=webp&s=e813ecf083f4f6e2cd8ce9e47cd5e2fc18267ecf\n\nI am aware there is no fans on the front it's been fixed since then. Two 140mm maglevs now on the front",
      "JFC None of those GPU's are worth even anywhere close to that much money.  Not even remotely",
      "just because you are not willing to pay a price does not mean that the world also isn’t. the market sets the price for 4090s. just supply and demand.",
      "Palit soldering is super shit low quality. The card will artifact sooner or later.",
      "1599+ tax or bust. All those other prices  for a video card to play video games that will get outclassed in 2 years i wouldn't pay extra for.  And then its up to you if you want to do it all over again in 2025. MSRP or none.  IMO",
      "Yes",
      "People say yes in terms of performance as Nvidia has made the 4000 series cards have limited performance OC. What you want to know is the following:\n1. Is customer service at Palit in your country and is it any good in case you need it.\n2. Do you know what resistors, capacitors, etc are used on the board. Are they high quality, how about the VRM etc.\n\nWithout knowing we have no idea if Palit is really worth the savings if the resistors, vrm, caps give out in a year or 2 and you need to RMA.",
      "None of those cards at that price are worth purchasing.",
      "Yes",
      "10 years ago, I would of done. But its just me, my girlfriend and the cat. I'm beyond caring how it looks. as long as it performs all good.\n\nIn can justify the vertical mount.  its so the connector isn't pushed against the side panel of the case.",
      "the cards will always sell for what the market dictates.. as gaming grows as a hobby, more spenders with deep pockets. the invisible hand will always push the price for any good to where both seller and buyer are willing to meet..\n\nie. the price assigned by nvidia doesnt matter. if there is headroom for scalpers on the 4090 (which obviously there is), then that is indicative of a higher real value to the world than the price that nvidia released it at.\n\nit’s not up to you or nvidia. it’s the effect of global demand meeting supply. nvidia could actually price their cards (sadly) for even higher and make up some of the ground that scalpers are taking from them.",
      "That gamerock looks pretty cool",
      "Is this a rhetorical question? :p",
      "I got the Zotac Amp Extreme Airo for it's list price on Newegg.  It wasn't my first choice (FE & Suprim Liquid X were), but there's very little difference between all the 4090's other than aesthetics.  But the card in stock is better than the card you can't buy.",
      "Sick build. If you wanna add some more style points for cheap, get a full set of Cablemod cables and cable combs. Would definitely improve the look even more",
      "Just in time for the 4090ti!"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "top",
    "matched_keywords": [
      "rtx 4090",
      "4090",
      "rtx4090"
    ],
    "title": "Asus Strix RTX 4090 OC",
    "selftext": " Asus Strix 4090 OC available directly from Asus UK...seems fair price compared to other UK retailers\n\n[Asus Store UK](https://uk.store.asus.com/rog/rog-strix-rtx4090-o24g-gaming8384-90yv0id0-m0na00.html)",
    "comments": [
      "IMO the Strix 4090 isn't worth it by itself. It's an overpriced and overbuilt card. It was sort of nice in some previous gens when better cooling meant less noise, but with the 4090 they all have very overbuilt coolers and the more expensive models are only OCed a bit higher for little performance gain and lots of extra cost on your power bills.\n\nI bought the cheapest card I could find for 1950 EUR and it's dead silent even if OCed. No reason to get something like Strix or Suprim this gen.",
      "I had the Asus Strix 4090 and at the moment have RTX 4090 FE...the FE coil whine is way more louder than the Strix. I think at the end of the day it is luck same as silicon lottery on the chip itself",
      "To add to this - both Asus and Suprim have coil whine … like crazy!",
      "I'm sorry but that's not fair at all. If it would be € sure, but not in gbp",
      "\"Fair price\" 😂😂😂",
      "Coil whine is card dependent, not maker dependent. My Asus card is just fine",
      "I haven't heard any coil whine with my rog strix oc 4090.. hmmm",
      "At least now fan noise is not a problem now. My coil whine is crazy too",
      "I am running my 4090 @ 3Ghz / + 1500mhz mem … clearly I am NOT undervolting and there is no coil whine on it !\n\nPretty sure there is something going on with them during production. Literally this started to happen more and more since 2000 series…but none of the acknowledge it to be a production issue..",
      "Asus Tuf OC and the coil whine was really bad when I first got it, I was really disappointed. After a couple weeks it either went away or diminished so much that I don't hear it anymore.",
      "I think palit and gainwars are the way to go.\n\nDoes anybody have XP with the manli cards the shroud seems to block the fan...such stupid design",
      "That would be the card for me. I need 2 HDMI ports, pretty sure Asus is the only one who makes them with 2.",
      "Makes 0 sense to pay extra for an OC version for a few frames",
      "Oooof... +£400 over my FE is not something I'd call a \"fair\" price... It's not gonna run £400 worth faster.",
      "Thanks mate!!!\n\nI kept the link on my favorite bar and kept checking it every now and then, just placed my order.",
      "Guess I lucked out, my 4090 strix has no audible coil whine (only if I press my ear near the case).",
      "Well, strictly speaking the amount of heat is equal to the power consumption.\n\nSo the only reason the 4090 is releasing less heat is probably because you're under-utilizing it. Because otherwise the 3090 Ti (most models) and 4090 Gaming Trio both have 450 W power limit.\n\nThat being said, you don't really have to fully utilize it to enjoy gaming. Unless you're playing DL2 at 4K with RT like I'm now...",
      "You are lucky then! That doesn’t mean that these brands are not predominant with coil whine…just because it works for you. There are tons of people reporting it",
      "To all of those saying the price is not fair…you should see the prices from other UK retailers for the same model…they are all asking upwards of £2400 so £400 less to me seems a fair price. Afterall this is a 3rd party card not the FE from Nvidia…if you want to pay the price that Nvidia are selling it, then just simply buy it directly from Nvidia",
      "Bestbuy canada has the msi gaming trio in stock here, its 2550 with all taxes, so around £1550. I feel for you guys."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "top",
    "matched_keywords": [
      "rtx 4090",
      "4090",
      "rtx4090"
    ],
    "title": "3070-Ti(Mobile) vs RTX 4070 vs RTX 4090 for Davinci Resolve.",
    "selftext": "Hi Everyone,  \nI used to edit on a laptop with 3070-ti for 2-3 years and recently switched to a PC, but honestly I expected a much bigger difference, especially when we talk about 4090 vs laptop GPU. I didn't feel that my render speed got much quicker. I use Studio version so it should give me all software and hardware features it has.\n\n*I wonder if I do something wrong or I need to activate some setting somewhere. Or that's normal difference?*\n\n**Laptop specs:**\n\nGPU: Nvidia 3070-ti (Mobile)  \nCPU: i7-12700-H  \nRAM: 40Gb DDR5 4800Mhz  \nDavinci Resolve 18.6\n\n**PC-A Specs (4090):**  \nGPU: Nvidia 4090  \nCPU: i7 14700-K  \nRAM: 32Gb DDR5 5200Mhz (will add extra 64 later)  \nDavindi Resolve 19.0\n\n**PC-B Specs (4070):**\n\nGPU: Nvidia 4070  \nCPU: i7 14500K  \nRAM: 40GB DDR 3200Mhz  \nDavinci Resolve 18.6\n\nI've decided to just drop the same video and render out shorter 15 min version from it to compare. No effects just simple render.  \n  \nLaptop had \\~340FPS and rendered in 1m:05s.  \nPC-A(RTX4090) had \\~480FPS and rendered in 0m:45s  \nPC-B(RYX4070) had \\~470 FPS and rendered in 0m:46s\n\nSo my 4090 is 1s better than 4070 in render time. It doesn't make sense to me.  \nAnd it's only 30% faster than mobile GPU 3070-ti. Considering I'm comparing large 4090 brick vs small GPU in a laptop it doesn't sound reasonable enough for me.\n\nIs more VRAM the only bonus I get from 4090, or do I need to configure something properly?  \n\n\nI want to hear from people who migrated to 4090, did you notice a huge increase and what GPU did you compare it to ? Especially if you use Video Editing.\n\nThanks for reading this far.  \n🧙‍♂️ You are legend!",
    "comments": [
      "It looks like the bottleneck is your CPU, or you didn't enable GPU/hardware acceleration.",
      "you are using only NVENC engine (up to 8k video editing and codec converting - H.264 HEVC AV1) which all cards from same generation **Ada Lovelace AD10x** have the same. To experience faster 4090 you would have to use CUDA engine for video AI processing software (like upscaling AI) like TOPAZ video AI or VideoProc AI and this still would not mean that 4090 would be noticeably faster than 4070 because AI SW based on AI models (picture recognition) works differently than games =)\n\nupscaling video 720p to 1080p would give you about 1 FPS converting speed =) You can do benchmark between 3070, 4070, 4090 =)\n\n[https://en.wikipedia.org/wiki/Nvidia\\_NVENC](https://en.wikipedia.org/wiki/Nvidia_NVENC)\n\nusing NVENC engine\n\n[https://www.videoproc.com/video-process/full-gpu-acceleration-benefits-4k-video.htm#how-to-use-gpu-in-videoproc](https://www.videoproc.com/video-process/full-gpu-acceleration-benefits-4k-video.htm#how-to-use-gpu-in-videoproc)\n\nusing CUDA engine\n\n[https://www.videoproc.com/video-converting-software/feature-ai-super-resolution.htm?ttpath=vpcindex-2](https://www.videoproc.com/video-converting-software/feature-ai-super-resolution.htm?ttpath=vpcindex-2)\n\ncheck windows task manager \\\\ performance \\\\ GPU - to see if if you are using 3D game engine or Video Encode engine",
      "I did enable GPU/Hardware acceleration with Studio version.   \n  \nI monitored my GPU and it shows that it works at 60-95% up and down but it's very quiet. Fans work like in Idle which is weird, ocassionaly turn up a bit for 5-10s and go back to very quiet.    \nI expected fans to run like crazy while it uses the most juice of that GPU.  \n\n\nSorry for late reply, I thought nobody has answered me.",
      "Thank you for detailed answer. I feel like a noob reading that but I will check you resources to try to understand it better.\n\nBefore buying this new PC I couldn't decide between 4080 vs 4090 for a long time as there was \\~1000 EUR price difference. I've seen many people say that you need to get the most VRAM for your video editing and in general that 4090 would be so much more powerful. So I thought to invest into that.\n\nBut now I feel like 4080 would provide me the same performance. Why so many people say that 4090 is the best option for video editing considering it's price is way up there.",
      "For your basic video needs like colour space shifting or cutting and editing it would be the same if you would buy 4060 8GB for 300$ because they are HW accelerated on NVENC engine - 470 FPS is very HW accelerated =)\n\n[https://www.videoproc.com/video-editing-software/](https://www.videoproc.com/video-editing-software/)\n\n5090 32GB VRAM only if you using 3D rendering programs with CUDA on 3D GAME HW acceleration pipeline engine - For those building a PC for 3D Modeling or Animation\n\n[https://www.pugetsystems.com/solutions/3d-design-workstations/blender/hardware-recommendations/](https://www.pugetsystems.com/solutions/3d-design-workstations/blender/hardware-recommendations/)\n\nVRAM requirements for active 3D workloads such as Modeling, Animation, Rigging, Texturing\n\n[https://www.cgdirector.com/how-much-vram-do-you-need/](https://www.cgdirector.com/how-much-vram-do-you-need/)\n\n[https://mainleaf.com/blender-system-requirements/](https://mainleaf.com/blender-system-requirements/)"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "top",
    "matched_keywords": [
      "rtx 4090",
      "4090"
    ],
    "title": "B&H Photo RTX 4090 Pre-orders?",
    "selftext": "Anyone else holding out for a B&H Photo RTX 4090 pre-order?  Have no sense of when these might actually ship.\n\nFor reference: [https://www.bhphotovideo.com/c/product/1730937-REG/asus\\_tuf\\_rtx4090\\_24g\\_gaming\\_tuf\\_gmg\\_gefrc\\_rtx.html](https://www.bhphotovideo.com/c/product/1730937-REG/asus_tuf_rtx4090_24g_gaming_tuf_gmg_gefrc_rtx.html)",
    "comments": [
      "I preordered the 3080 TUF exactly like this 4090 TUF at launch from BH. It never shipped. I did it again, but I am not holding my breath.",
      "I tried all day yesterday, and every time I’d add to cart, when I went to checkout I’d get an error saying the item was no longer available. Tried Newegg, Best Buy, and B&H",
      "I literally bought one and my credit card asked for some code and a minute later they were out of stock, so think before you say thins.",
      "Super helpful. Thx Broseph.",
      "so your definition of easy is order in under a minute on release?",
      "They're out of the store until the 18th in observance of Jewish holidays. Nothing will ship until then.",
      "And yet, I did not. Was all gone when I showed up around 2 PM EST.",
      "I started trying about 20 minutes before then. Still don’t have a card. Literally refreshed all day until around Midnight.",
      "True, but when they get back, they will most likely either cancel a lot of orders or you will have to wait a while until you get one.",
      "Probably to some degree, sure. They specifically stated that it was a \"pre-order\", so that shouldn't surprise anyone.",
      "I keep saying, I'd rather wait in a structured line than just hunt around, hoping. I can live with queuing up.",
      "Tried right at 9am on the phone apps. Refreshed like crazy for at least 30 min. All went out of stock even if I managed to get them in the cart",
      "the store opens next week on the 19th. you can try placing an order there, but i think if you did preorder the TUF 4090 you are already in a queue. im holding off for a suprim as my case is a bit small",
      "I have that preordered while trying to snag an FE.",
      "Dubious...  Thx for sharing.",
      "I was charged full even using credit card...will ask them when they are back work.",
      "I do see now that they removed preorders. So it could very well be that the ones that preordered will get it. We’ll see once they reopen.",
      "Pre-orders with a credit card get an authorization charge, while PayPal or digital wallets get charged in full instantly.",
      "Agreed, queues are fine for me. I wasn't expecting the 3080 TUF to ship, given the preorder happened so far before actual launch, but it was nice that it went through.",
      "Hey man, thanks for this post, just pre-ordered one."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "top",
    "matched_keywords": [
      "rtx 4090",
      "4090",
      "rtx4090"
    ],
    "title": "Introducing ASUS Advanced BTF GeForce Graphics Cards – ROG Strix GeForce RTX 4090 BTF Edition and TUF Gaming GeForce RTX 4070 Ti SUPER BTF White Edition",
    "selftext": "https://preview.redd.it/exbm5f2m83cc1.png?width=1920&format=png&auto=webp&s=234cc8f4f38e61e42867d1b968b541f2e699a641\n\nAt Computex 2023, ASUS unveiled a revolutionary hidden-connector solution called BTF, signifying a new era in DIY PC building that prioritizes aesthetics and cleanliness. This innovation aims to transcend traditional PC assembly methods by reducing the number and visibility of internal cables in the front, providing a super-clean DIY experience.\n\nAt CES 2024, the realization of the Advanced BTF ecosystem was on full-display with two separate lines of Advanced BTF products – the ROG Advanced BTF products, featuring the ROG Strix GeForce RTX 4090 BTF Edition, and the TUF Gaming Advanced BTF products, featuring the TUF Gaming GeForce RTX 4070 Ti SUPER White Edition.\n\nhttps://preview.redd.it/ran45spq83cc1.jpg?width=696&format=pjpg&auto=webp&s=89edb6364b924159416d6def2fe80c51144c8288\n\nGraphics cards within the Advanced BTF ecosystem feature a design where no power cables are needed; instead, the cards have a power connector that connects directly to a BTF-compatible motherboard, which can support up to 600W to the graphics card via a graphics card high-power slot. Installing and uninstalling these graphics cards are made simple, thanks to new PCIe Slot Q-Release designs on ASUS Advanced BTF motherboards.\n\nhttps://preview.redd.it/pvm26h4s83cc1.jpg?width=696&format=pjpg&auto=webp&s=7e37690a22543461db0ffb122725f137f6ec2852\n\nKey features:\n\n* PCIe high-power connector for power transmission\n* Improves GPU sag by adding an additional point of contact with the motherboard\n* Eliminates the need for traditional 8-pin or 16-pin external power\n* Eliminates concerns about proper cable installation or where the side panel is pressing against the cable(s)\n\n**ROG Strix GeForce RTX 4090 BTF Edition**\n\nhttps://preview.redd.it/wvo1ebzy83cc1.jpg?width=696&format=pjpg&auto=webp&s=57e71b67a8aa1c138bfa4149c3ea58cbfdf8c393\n\nThe ROG Strix GeForce RTX 4090 BTF Edition graphics card preserves the same ultra-competitive performance of the ROG Strix RTX 4090 while introducing a PCIe high-power connector compatible with the new ROG Maximus Z790 Hero BTF motherboard.  Despite the change in the design, the graphics card still offers the same AI-accelerated features, powerful and quiet cooling solution, and diecast shroud as the original – only without the 16pin power connector hanging off the side.\n\nhttps://preview.redd.it/z3hppzdz83cc1.jpg?width=696&format=pjpg&auto=webp&s=de0e553cc4ab8fc56874d9611e7395895de852ed\n\nLearn more about the ROG Strix GeForce RTX 4090 BTF:  \n[https://rog.asus.com/graphics-cards/graphics-cards/rog-strix/rog-strix-rtx4090-24g-btf-gaming/](https://rog.asus.com/graphics-cards/graphics-cards/rog-strix/rog-strix-rtx4090-24g-btf-gaming/)\n\n**TUF Gaming GeForce RTX™ 4070 Ti SUPER BTF White Edition**\n\nhttps://preview.redd.it/4efffkqx83cc1.jpg?width=696&format=pjpg&auto=webp&s=bedc78e40f8968f5c4630c3e58f9b239c8a8f608\n\nThe TUF Gaming GeForce RTX 4070 Ti SUPER BTF White Edition proves that the Advanced BTF ecosystem will be available at different performance and price points – and does it in stylish fashion. Powered by the brand-new GeForce RTX 4070 Ti SUPER, it’s simply a more powerful version of the TUF Gaming GeForce RTX 4070 Ti.  As with the ROG Strix GeForce RTX 4090 BTF Edition, this card also features the high-power connector used in conjunction with an Advanced BTF ecosystem motherboard, such as the TUF Gaming Z790-BTF WiFi.\n\nhttps://preview.redd.it/8w0huykw83cc1.jpg?width=696&format=pjpg&auto=webp&s=7afea5bd620eda7bd92096af02df84a3195ef6e9\n\nLearn more about the TUF Gaming GeForce RTX 4070 Ti SUPER BTF White Edition:  \n[https://www.asus.com/motherboards-components/graphics-cards/tuf-gaming/tuf-rtx4070tis-16g-btf-white/](https://www.asus.com/motherboards-components/graphics-cards/tuf-gaming/tuf-rtx4070tis-16g-btf-white/)\n\nLearn more about ASUS Advanced BTF design at:  \n[https://www.asus.com/content/btf-hidden-connector-design/](https://www.asus.com/content/btf-hidden-connector-design/)\n\nLearn more about the new Advanced BTF products released at CES:  \n[https://edgeup.asus.com/2024/introducing-btf-an-easy-clean-approach-to-pc-building-that-keeps-the-cables-out-of-sight/](https://edgeup.asus.com/2024/introducing-btf-an-easy-clean-approach-to-pc-building-that-keeps-the-cables-out-of-sight/)[https://edgeup.asus.com/2024/take-a-close-look-at-these-btf-builds-from-rog-and-tuf-ga](https://edgeup.asus.com/2024/take-a-close-look-at-these-btf-builds-from-rog-and-tuf-ga)\n\nStay tuned to ASUS Social Media Channels or the ASUS PCDIY group or weekly PCDIY live stream for more information relative to pricing and availability - [https://www.facebook.com/groups/ASUSPCDIY](https://www.facebook.com/groups/ASUSPCDIY)\n\nThe post will be updated when we have more information.",
    "comments": [
      "What exactly does BTF stand for?",
      "Literally \"Back To the Future\"\n\nGPUs are powered by the MOBO. Let's see how that fares.",
      "I thought it meant \"Behind the Front\" and then I read the actual name which is \"Back to the Future\" and was astounded by how much more dumb it sounded than my stupid thought I made up. The idea however is really cool and I hope ASUS makes it an open standard for other board makers to do because to be honest it makes builds look really clean and it also could avoid that burning card connector situation, assuming they use three or four 8 pins on the back of the board.",
      "I guess that’s one way to get rid of 12VHPWR.",
      "Born to be free. 🤡",
      "and who will make the motherboards???? it's us who will need to front the cost, you can't just drive 600w+ through those nilly willy",
      "> signifying a new era in DIY PC building that prioritizes aesthetics and cleanliness \n\nthey better offer riser cables then as well",
      "Boy to Femboy",
      "Probably won't be a universal thing, every manufacturer will probably see it as an opportunity to sell their own GPU and mobo together.\n\n\"Hey you wanna buy one of our new gpus?  Now you gotta buy one of our mother boards too, more money for us.\"\n\nDon't get me wrong though, I do like the idea and the look, but it might be awhile before it becomes a universal connection type if it catches on.",
      "💀",
      "I was thinking of btf gpu and cpu and lian li o11 dynamic evo. I feel like it would be impossible since i don’t know if the chassis would be compatible.",
      "Looks unnecessarily expensive.",
      "asus does, kinda why they made the gpus to match",
      "Lian Li are partnered with ASUS on BTF so BTF compatible LL cases are in the works.",
      "To use the BTF graphics card, you need to use the BTF-enabled motherboard; this is noted in the post. They are not cross-compatible, and it does not have both sets of connectors. Best of luck with your build, and thanks for being #TeamROG and #TeamSTRIX  \n\n\nWe have been actively communicating and discussing BTF since last year and is target a new builders.\n\nCritically, also keep in mind why it is currently new builder focused is this ecosystem requires chassis support as well. You potentially need all three components ( Chassis, Motherboard and Graphics Card ). Should a new builder get two ( chassis and motherboard ) they can opt to go with a non BTF card and change that in the future as the board supports both but do have to have those pre requistes.",
      "Yeah I know they are powered by the Mobo by that is a terrible name lol. I thought it was going to be something more sophisticated.",
      "that sounds bad, not only do we front the costs, it will have asus tax applied on top of that, sounds like an extremely expensive mobo then...huge skip from me",
      "What a crazy name. I'm waiting for the RTX 4070 Ti SUPER dooper booper BTF ABC XYZ type-r extreme",
      "I wanted to rant about proprietary connectors crap, but I don’t see how else cableless GPUs could be popularized."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "top",
    "matched_keywords": [
      "4090",
      "rtx4090"
    ],
    "title": "RTX 5000 ADA or GTX4090 laptops for OMNIVERSE.",
    "selftext": " I am starting my PhD and am confused regarding these both for my work laptop. I will be working on digital twins and am thing of using nvidia omniverse as the platform. As far as I have researched, both the GTX 4090 and RTX5000 give almost the same performance, but it is getting a bit hard to find an RTX5000 laptop in the UK with up to date processes. In any of your experience, would the RTX4090 laptop be okay for my needs? \n\nThe laptop I am thinking of going with is razerblade 16 (i9), Alienware x16 R2(Ultra 9) or  Asus ROG Zephruys Duo\n\nThanks in advance",
    "comments": [
      "Laptop \"4090\" is not a 4090 chip. It's a power limited 4080 chip, if you look at its specs.",
      "Are you from the future? 5000 isn't out yet.",
      "So what do you suggest for omniverse, would I be able to run simulations with the laptop 4090 ?",
      "Yeah thats true, but the thing is laptops with the ADA generation get a bit too expensive. Would I still be able to run omniverse specially for digital twins on a laptop with GTX 4090?",
      "Get the Razer blade. You need that 24gb vram and a lot of portability",
      "I mean idk tbh but i don’t see why not",
      "As its the same architecture, the vram .",
      "https://docs.omniverse.nvidia.com/materials-and-rendering/latest/common/technical-requirements.html",
      "OP you’re doing academia professional work, get the Qaurdro variant do not get a gaming card. (You can still game fine btw with Quadro cards)",
      "Sorry, no idea, not my area of expertise. I was just sharing that fact about laptop \"4090\" as its name is straight up misleading and some might assume that it's like a real 4090.",
      "*4070 super chip"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "top",
    "matched_keywords": [
      "rtx 4090",
      "4090"
    ],
    "title": "Gigabyte GeForce RTX 4090 Gaming OC Benchmarks",
    "selftext": "Hi folks,\n\nI am trying to buy a second hand Gigabyte 4090 Gaming OC edition. I am however skeptical of the benchmarks results the seller shared with me.\n\nI understand there is a bottleneck with the cpu (i9-10850k) which is why I am looking strictly at the graphics score and not the overall score. For example on the timespy benchmark, based on my research the graphics score should be near 35k however the seller's gpu score was 32k. Another point to mention is that he is running DDR4 3200mhz so not sure how bad this would affect gpu scores.\n\nThoughts? Is it legit?\n\nAny advice would be greatly appreciated.\n\nThank you\n\n[RAM Kit](https://preview.redd.it/yvb90g6y1pmd1.jpg?width=945&format=pjpg&auto=webp&s=ad8ba4807a080df852c669f7ca276d6506ab5cce)\n\n[TimeSpy Charts](https://preview.redd.it/ky0j0j6y1pmd1.jpg?width=2048&format=pjpg&auto=webp&s=743c9da8164be5b9a31b85006c0f5bfdaa38d3bb)\n\n[Time Spy](https://preview.redd.it/dhnplg6y1pmd1.jpg?width=2048&format=pjpg&auto=webp&s=bbd7ec7c7c6c1e0026e7e479688ea2d37d2fb67b)\n\n[SteelNomad](https://preview.redd.it/hyv08g6y1pmd1.jpg?width=2048&format=pjpg&auto=webp&s=1dda2e6580a8a75f8844941d1705e0e84b356064)",
    "comments": []
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "top",
    "matched_keywords": [
      "rtx 4090",
      "4090",
      "rtx4090"
    ],
    "title": "RTX 4090 FE HWinfo voltage check",
    "selftext": "Hello \n\nive used a cable mod adapter cus of the limited space of my lian li case with the rtx4090 fe, back then cablemod was the only quick solution wich doesnt require me to buy a vertical mount and basicly choke one of the fans lol,\n\nafter the recall ive switched to corsairs adapter (dont flame me cus i use adapters pls), i do want to upgrade to a larger case in the future when i have enough to also upgrade my mobo and cpu with it.\n\nNow ive seen some posts where ppl explain that you can check in hwinfo if there is something wrong with the outputs involving adapters but im noob and idk if these readings are good\n\nhttps://preview.redd.it/h79rl23l3zec1.png?width=1920&format=png&auto=webp&s=4ffeb2d9d2362b2eba8dbe84a66616cad58d4c1b",
    "comments": [
      "Unless you know your PSU output voltage, these readings are 100% meaningless.",
      "Agreed. You need to know the voltage at the PSU connector and the voltage at the GPU connector to know the voltage drop and if you have too much contact resistance.",
      "Corsair cable + psu are closer to 12v and as a result the gpu voltages look lower than usual. I’d say it’s normal based on seeing this type of question tons of times. I have an hx1500i + Corsair cable and idle around the same. Tested with like 5 different vhpwr cables and an rm850x and hx1000i. All in the 11.9-12v range at idle and dropping down to 11.7~11.8v under 450w load.\n\nYou’re fine. Just enjoy the card and keep track of what range is normal for you. If that range starts to change then maybe there is something is wrong.",
      "I have hx1500i",
      "Funny that you mention the exact psu i have, well good to know then, and its corsairs 180 degrees adapter not a cable, anyway thx for the clearance i was a bit scared to lose my sweet gpu"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "top",
    "matched_keywords": [
      "rtx 4090",
      "4090",
      "rtx4090"
    ],
    "title": "Is anyone got a RTX 4090(AD102-301 version) with third party vender?",
    "selftext": "I've just bought a Colorful Neptune RTX4090 this month. And I found it does not got a 1.1v on full OC state(unlocked with Afterburner). The limit is 1.07v.\n\nAnd according to the specifications of this graphics card, the TGP is 630W. But I've never seen it consume more than 550W under any situation.\n\nI have a little suspicion that they intentionally limit performance. Does anyone have the same problem as me?\n\n&#x200B;\n\n&#x200B;\n\n[the max core voltage is 1.07 ](https://preview.redd.it/2b3kpn6q4cdb1.png?width=571&format=png&auto=webp&s=2ffb99d7e18f7d01932f01e86e57074924d136e4)\n\n[it's fully unlocked](https://preview.redd.it/bg8q46kt4cdb1.png?width=810&format=png&auto=webp&s=2746e76d52aeeaac3ee6ef712648fffcb925c1c8)",
    "comments": [
      "People are affraid of the truth lol",
      "550w is about the max most see even with a 1.1v card.  4090 is just a lot more efficient than a 3090. \n\nThe new core stepping is filtering in to the AIBs as you found out.  The first of them as you probably know original popped up in the FE.  Nobody knows why they reduced voltage. Well other than people that work at Nvidia of course.",
      "As long as it boosts to advertised boost clock - gotta check it in specs - it is within spec pretty much and I wouldn't call it a problem. There tends to be some variance between GPU batches - say, GPUs produced in November, 2022 can have some differences to May, 2023 - which is ok, as long as it meets the spec. There is also manufacturer-to-manufacturer difference to consider - it is possible for them to alter the boost/voltage table for any reason they see fit.",
      "Hey just curious, when running the card at stock settings, what clock and voltage are you seeing?",
      "4090 strix has entered the chat. I’ve seen my card under gaming on ultra settings 1440p go up to nearly 597 watts at some points.",
      "GB 4090 Gaming OC, if i really wanna torture the card i can get it to 590W.\nBut that‘s in Cyberpunk with Pathtracing 4k without dlss or the 3D Mark interactive Pathtracing Benchmark at 133% Power limit and overclocked.\n\nIm on a 50% + undervolt profile most of the times unless i play a very demanding SP game or render in C4D and Redshift.",
      "Still, a more typical max is 500-550w from what I've seen with my TUF.  With a few exceptions that go higher. Nothing different with the Strix.  Some cards are much more leaky than others too and will pull more power.  Silicon lottery.",
      "Agreed, I was just making a joke lol. No serious inquiries of proving other wise. I just know my strix is a damn power hog. It consumes peaks of up to 597-598 watts. Obviously I don’t think it stays there, it just hits those values at certain times depending what’s going on in the game.",
      "Yup gotta keep in mind the strix 4090 has a higher stock power limit than most cards also which is probly why you see all that",
      "Hello Kalittaa, same here, I bought 4090 Suprim X on the new AD102-301 revision and Voltage is same for this revision as yours. I am on 3060Mhz with +100mV on gpu and 21@23Ghz on memory. For me,its look like I am not limited on overclocking with new revision GPU. Big task here :-D PLS is it possible share your bios for new revision AD102-301 with me (for example export bios by gpu-z and upload to the some share)? Now, I am waiting for EKWB waterblock, so I am curious if your bios can help push the limits for margin steps :-D Becouse in some use case, I am hitting power limit (520w limited on Suprim X....).  I will be very much obliged and can promise some OC tests ;-)",
      "Absolutely, not sure why I keep getting downvoted for throwing that out.. is what it is I suppose",
      "But yes you’re correct. More so higher wattage is all up to silicon lottery. If you have good die that can overclock good, or above average I should say, you’ll pull more power draw. Typically that’s where the more wattage comes into play.",
      "[https://overclock3d.net/news/gpu\\_displays/colorful\\_s\\_rtx\\_4090\\_igame\\_neptune\\_has\\_a\\_max\\_tdp\\_of\\_630w/1](https://overclock3d.net/news/gpu_displays/colorful_s_rtx_4090_igame_neptune_has_a_max_tdp_of_630w/1)\n\nThe tgp of 4090 neptune is 630w. tuf is 550w. Your tuf seems to work as spec, but mine doesn't.\n\nI think this is a result of the AD102-301's 1.07 voltage limit. To be honest, I would like to know the case of users who use the AD102-301 chip like me, not AD102-300."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "top",
    "matched_keywords": [
      "rtx 4090",
      "4090",
      "rtx4090"
    ],
    "title": "Going to buy a RTX 4090 - asking for advice",
    "selftext": "Hi guys, so I'm going to get a 4090 and finally update that part of my setup, which would be the quietest 4090 model? Btw, don't have space for these watercooled integrated models.\n\n&#x200B;\n\nAlso, my current PSU is a Corsair AX850, is it safe?\n\n&#x200B;\n\nI'll not do overclock, mining etc, the card will be only for gaming. Silence is important (option to turn off RGB and light too), mainly in stock when working and not using the PC to game.\n\n&#x200B;\n\n3 options that I've seen in stock nearby I live:\n\n&#x200B;\n\n\\- Palit RTX 4090 GameRock 24GB GDDR6X - NED4090019SB-1020G\n\n\\- RTX 4090 Asus TUF Gaming, 24 GB GDDR6X, ARGB, DLSS, Ray Tracing - TUF-RTX4090-24G-GAMING\n\n\\- INNO3D GEFORCE RTX 4090 X3 OC, 24GB, GDDR6X, 384-BIT, N40903-246XX-18332989\n\n&#x200B;\n\nAre the above cards good and quiet?\n\n&#x200B;\n\nThx in advance!",
    "comments": [
      "850W is fine. And of those 3 I would get the ASUS Tuf because it has an extra HDMI slot. I think the ASUS cards are the only ones that have this.",
      "I’d probably go with the Inno3d. Not sure about Inno3D or Palit, but Asus support is absolutely terrible. Good luck trying to RMA that thing if it malfunctions!",
      "I’d grab the Asus TUF and your PSU is fine.",
      "PSU is fine! I have a AIO Waterforce from Gigabyte and I'm extremely happy with it. It's very silent, never goes above 60°, zero coil wine. But it did cost an extra few hundreds for no other benefits and you do need the extra room for the 360 rad in your case.",
      "I just bought a 4090 Gainward Phantom GS and I regret nothing. It's almost 200-250 EUR less than the ASUS cards at almost the same performance level. Been buying Gainward for the past 15 years and I never had any issues with them.\n\nNo coil-whine whatsoever so far.\n\nShould be the same chip as the Palit one since Gainward and Palit are just two brands within the same company iirc.",
      "Hmm ive had no problems getting rmas from asus. Did my mobo and keyboard so far. Got a new keyboard cus they couldnt get parts or a refurbished one"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "top",
    "matched_keywords": [
      "rtx 4090",
      "4090",
      "rtx4090"
    ],
    "title": "What good brand + relative good warranty for RTX 4090?",
    "selftext": "Hi all,\n\nNo more EVGA cards sad....\n\nI live in Europe btw.\n\nSo if people know GOOD brands that are more popular in Europe please share..\n\nAnyway which of the brands have GOOD build quality and relative good warranties?\n\nWhich brands to AVOID? Ive heard to AVOID Gigabyte is there a reason why?\n\nI just want a RTX 4090 that is reliable ie build quality is good and if something is bad the warranty won't give me lots of stress and hassle SCREW that!\n\nThese cards i can get at a decent non scalper prices:\n\nGainward GeForce RTX 4090 Phantom\n\nZOTAC GeForce RTX 4090 Trinity\n\nInno3D GeForce RTX 4090 ICHILL X3\n\nPalit RTX4090 GameRock 24GB\n\nGIGABYTE GeForce RTX 4090 WINDFORCE\n\nPS i want Asus TUF RTX 4090 BUT no shop in my area has them in stock or sell it at insane prices not gonna join with these stupid scalper prices that some retailers ask.",
    "comments": [
      "MSI warranty doesn’t require the proof of purchase. Only the serial number and is good for 3 years from date of manufacture. Probably your best bet from ebay or the secondary market.",
      "Doing my own research, this is what I found so far:\n\n- Palit - NOPE - 4090 GameRock has a badly designed PCB if this is to be trusted - https://www.youtube.com/watch?v=9I7U4kdc0V4&ab_channel=ActuallyHardcoreOverclocking\n\n- Zotac - if you don't mind the sanitary pad shape, I heard it's ok, though some claim issues with fan noise\n\n- Gigabyte - the Aorus version had some software issues, not sure if these are fixed but other than that I heard nothing negative about it\n\n- Inno3D / Gainward - found 0 opinions on these, apart from random redditors claiming they were fine-ish in the past",
      "Yes but we’re talking about GPUs that are flying off the shelf like hotcakes. It was hard enough to get a 3090 this past March. As soon as they are made and boxed and shipped out they are sold. \n\nSo for MSI…they have a warranty with proof or purchase and a warranty without proof of purchase. But besides EVGA (rip) they have the best warranty of the bunch.",
      "Gigabyte got their act together and their latest GCC works for the most part like a charm here. (4090 Aorus Master)",
      "I have a MSI Gaming Trio 4090 and I love it.  Its been a very solid card.  :)",
      "For anyone who finds this thread that lives in the United States, you should know that \"Warranty void if sticker is broken\" stickers are illegal. It's just a scare tactic used by companies.\n\n&#x200B;\n\n>\" ...Found at [15 U.S.C. § 2302(c): ](https://www.law.cornell.edu/uscode/text/15/2302#c)“No [warrantor ](https://www.law.cornell.edu/definitions/uscode.php?width=840&height=800&iframe=true&def_id=15-USC-1631904320-826470511&term_occur=10&term_src=title:15:chapter:50:section:2302)of a [consumer product ](https://www.law.cornell.edu/definitions/uscode.php?width=840&height=800&iframe=true&def_id=15-USC-1637116219-826470515&term_occur=12&term_src=title:15:chapter:50:section:2302)may condition his written or [implied warranty ](https://www.law.cornell.edu/definitions/uscode.php?width=840&height=800&iframe=true&def_id=15-USC-818519412-826470509&term_occur=4&term_src=title:15:chapter:50:section:2302)of  such product on the consumer’s using, in connection with such product,  any article or service (other than article or service provided without  charge under the terms of the warranty) which is identified by brand,  trade, or corporate name….”  In other words, a company may not say that its warranty will only be honored if the consumer uses a specific product or service. Or put another way, Apple may not tell you (or threaten) that you’ll void the warranty on your iPhone if you replace a  broken screen with non-Apple glass. \"  \n>  \n>  \n>  \n>\\-15 U.S. Code § 2302 - Rules governing contents of warranties \n\n&#x200B;\n\n[https://www.ifixit.com/News/10016/warranty-void-if-removed-stickers](https://www.ifixit.com/News/10016/warranty-void-if-removed-stickers)\n\n[https://www.digitaltrends.com/computing/ftc-warranty-stickers-illegal/](https://www.digitaltrends.com/computing/ftc-warranty-stickers-illegal/)\n\n[https://www.natlawreview.com/article/breaking-sticker-doesn-t-break-your-warranty-how-ftc-taking-aim-manufacturers-game](https://www.natlawreview.com/article/breaking-sticker-doesn-t-break-your-warranty-how-ftc-taking-aim-manufacturers-game)",
      "Thank you so much for all the replies guy's\n\nWhat would you think about MSI RTX 4090's? Good build quality?\n\nAccording to this video MSI is pretty solid choice even warranty.\n\n[https://www.youtube.com/watch?v=Ryd6KZsCvzw](https://www.youtube.com/watch?v=Ryd6KZsCvzw)",
      "What about the Founders Edition? 3 years warranty.",
      "Get a suprim X air or liquid!!!",
      "Well not in Europe anymore so it might be a bit different but MSI in UK doesn't deal with warranty they will send you to the shop you purchased from. Excerpt from email:\nAlso, please note that the basis of the warranty is the original proof of purchase and for any details regarding the warranty length, the device's owner should contact the original purchase shop directly. \nand:\nAll warranty queries for the MSI PC components are being processed by the seller, therefore in order to send the unit for the repair or inquire for more information regarding the warranty length, please contact your shop of purchase directly.\nMSI has 3y warranty AFAIK and I don't think they give you anything extra if you register.\nGiga has 3+1y so a bit better and I think the extra year is with Giga directly if GPU is registered and never had any issues with Giga personally.\nZotac I pretty good with 3+2y with the extra 2 directly with Zotac.\nThe other ones not sure as another thing you have to be careful with is if you want to WC it later on.Some companies void the warranty if water block is installed.MSI,Giga and Zotac are kinda cool with watercooling as long as you put the GPU back together before sending for repair but always double check as I'm not any kind of PR representative.\nPallit, Asus and Inno3D from what I've heard is not cool with WC so I usually not interested in them.\nGainward not sure.\nSo peeps be careful buying of eBay as I know some shops will not transfer warranty and even if you have registered with manufacturer they might not be able to help and you gonna have to deal with eBay seller/shop they purchased from.So I suggest ask the eBay seller which shop they have an invoice from and ask the shop if they can transfer ownership before buying.",
      "I'm terrified of MSI personally - I had dual MSI GTX 780TI, both died within couple of months of warranty running out - one had all its fans stop, the other just crashed and never came back. Then I switched to their 1080, and right about the time the warranty run out it started artifacting like crazy and I have to keep it underclocked or it crashes.\n\nGrand sample of 3, but it's a memorable experience <.<",
      "Is that the case? I thought only EVGA used to do that. I've been holding off buying anything from the secondary market because of it. Do you know of any other GPU brands that do this? Thanks again",
      "Is that the case? I thought only EVGA used to do that. I've been holding off buying anything from the secondary market because of it. Do you know of any other GPU brands that do this? Thanks again",
      "Gainward cards are usually identical quality wise to Palit. But honestly, I don't think their build quality this gen is an issue for anyone that doesn't want to OC the crap out of the card.\n\nPalit and Gainward also offer the smallest (that I know) AIB cards and seem to be also the cheapest. Trade offs I guess.",
      "I cant get one at all in Germany :-(",
      "\"MSI,Giga and Zotac\"\nVoid your warranty if you break their stickers. Or so I heard. I have \"gigabyte quality\" right on the screw. On the website they say \"warranty void if sticker broken\". I heard MSI voids for \"modification\", same for Zotac. If you want to know for sure, you have to ask the manufacturer or seller.\n\nI asked my seller and they void warranty is sticker is broken.\n\nSo don't expect them to respect the warranty if you break that sticker.",
      "Same. No issues and no coil wine",
      "Oh really, I thought they would make more available like in the french website. Could get one shipped to Belgium yesterday.",
      "Have been running them well-ventilated, regularly dusted, in a case with ample breathing room and dust covers and on high quality PSU with external surge protectors. 780TIs had factory OC, while the 1080 had been running stock for 90% of the time (factory OC for some time). For the better part of their life they have been running with sub 70C temps. First one that died was a secondary card in SLI setup, i.e. rarely used. No mining at all, mostly gaming.\n\nThe only \"abusive\" thing I did to them was running them past their warranty period, which is rarer than I thought.\n\nMight have been bad luck."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "top",
    "matched_keywords": [
      "rtx 4090",
      "4090"
    ],
    "title": "ASUS TUF RTX 4090 with CableMod ModMesh 12VHPWR Cable",
    "selftext": "Finally, I managed to install the ASUS TUF RTX 4090 by temporarily re-doing the custom loop to make space for the gigantic card to fit in the O11D Evo case until I get the waterblock from EK that I pre-ordered. I never used the provided nVidia 12VHPWR cable, since I know for a fact that the issue is on the provided cable. I directly used the CableMod 12VHPWR cable that terminates directly into my ASUS Thor 1200P PSU. I purchased the cable back on the October 11th (one day prior to the RTX 4090 launch day).\n\nCouple of things that I have tested:\n\n* Played CoD MW II for 3 hours last night\n* Ran Port Royal test loop for about 1 hour\n* Left the PC ran overnight\n\nI can confirm that everything is still intact and didn't find any melting issue or whatsoever. My advice to RTX 4090 owners is to avoid using the provided cable and get one either from your PSU manufacturer or third party one like CableMod to avoid any risk of getting the melting issue.\n\n&#x200B;\n\nhttps://preview.redd.it/vwubpd9vwkw91.jpg?width=2048&format=pjpg&auto=webp&s=0a5e09af17df65a610364d15437ee6eea612e333",
    "comments": [
      "We usually deliver within 1-2 weeks, but yeah, there have been an insane amount of orders for these 12VHPWR cables, so unfortunately our processing times have been pushed back as such. We are doing what we can to bring this back down to normal though and looking to expand our team accordingly to do so.",
      "I’ve got a CableMod cable on order but I just ordered it like 2 days ago. No idea when it’ll come. I’m stuck with the adapter and chewed down fingernails until then I guess. I can’t find a 3.0 PSU in stock, and even then, they are brands I don’t really trust.",
      "as much as people need your cables,  i hope your people are not crunching and forced to work during weekends n such",
      "Looks good!\n\nMy cablemod 12vhpwr to 4 pcie Corsair cable is on order, as is the ek block for my gigabyte gaming oc 4090.\n\nI’m still using my adapter with the 4090 until cablemod comes in - yolo!!",
      "it's the inverted layout. the O11D Evo case supports both standard and inverted layout. regarding the cable, it still won't fit with the side panel attached. 90 degrees adapter is still needed (I believe this is also the case with most cases) to fit the case with side panel attached.",
      "I do with my Asus Tuff 4090 its not the loudest coil whine, but its there.",
      "The unsleeved wires would be the sense wires actually, those are too small to be sleeved actually, there's just no extra room in the terminal for it, this is why we tuck it away underneath the other cables though to ensure it isn't visible.",
      "For a build like this do you simply put the motherboard upside down or what's the approach?\n\nAlso, official cable or not, you still need to put the side panel. Does it fit well with the huge card?",
      "That is looking absolutely stunning! Thank you for your support! We hope you enjoy the cable to the fullest. :)",
      "do you have coil whine",
      "Been looking around, seems with the demand on CableMod at the moment, from the time you order it'll take around 3 weeks to receive. Their shipping is abnormally slow unfortunately for such a good product, too bad Corsair is out of stock.",
      "Same here on Asus Tuf OC",
      "Yup, a bit of coil whine on my Asus RTX4090 TUF too.",
      "I figured as much. Jesus. I waited for review day before deciding to buy a new card so I didn’t get ahead of the demand craze. And now with AdapterMelt Gate it’s even worse.",
      "Yeah I feel you. I got a 4090 yesterday because my BestBuy stocked 1, CPU coming on the 1st then have everything but now I don't have a CableMod or Corsair so I'm probably not going to even use my new build until then, don't feel like risking it with the provided toilet paper adapters.",
      "Or at least with a paid overtime."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "top",
    "matched_keywords": [
      "rtx 4090",
      "4090",
      "rtx4090"
    ],
    "title": "The resolution and sharpness of RTX 4090 is lower than AMD RX 6900xt. please help!",
    "selftext": " Hello guys.♥  \n\n\n**system specifications:**\n\nMonitor: MSI MAG321QR-QD\n\nMotherboard: Asus TUF GAMING X670E-PLUS WIFI\n\nCPU: Ryzen 7 7700\n\nRAM: 32ddr5  \n\n\nI have a **PowerColor Red Devil RX 6900 XT** and upgraded it to **ASUS TUF Gaming RTX 4090 OC Edition** a few days ago.\n\nBut incredibly, the resolution and image quality of RTX 4090 is lower than the RX 6900!!! This weakness is quite evident in the game and in the movies. 🤦‍♂️\n\nI tried most methods to increase the sharpness and resolution on the RTX 4090, but nothing worked. I must say that the RX6900 was much better in Resolution and Sharp.\n\nIt seems that the rendering resolution of RTX4090 is lower than RX6900. While on 2560x1440 native!\n\nI set the nvidia image sharpening option to the highest setting, but I didn't feel any change! 6900 is much better.  \nI even changed the super resolution, but it didn't help...\n\nI paid a lot for this graphics card, but the 6900 still beats it... 🤦‍♂️\n\nPlease tell me if there is another way to increase resolution and sharpness in Nvidia cards.  \n\n\n[ ](https://preview.redd.it/it84wyoi0jvb1.png?width=1829&format=png&auto=webp&s=9cd43fccd7b6292a329647212d6b81bfe6b93635)\n\nCompare the cards in the game\n\n&#x200B;",
    "comments": [
      "The nvidia drivers are the issue, i\\`ve noticed that the newer ones seem to make the image quality worse, and they also seem to add something like motion blur.",
      "I paid a lot for the RTX 4090, but I still use the RX 6900xt. 🤦‍♂️\r  \nThe color, resolution and sharpness of rx 6900 are much better than RTX 4090!\r  \nEven watching movies in 6900 is better than 4090!\r  \nI hope someone can help me! Maybe it has special settings...\r  \nit is unbelievable! I bought the most expensive gaming graphics card in the world, but I'm not satisfied with it!\r  \nI never imagined that there is such a difference between AMD and Nvidia! 🤦‍♂️",
      "to me it looks like the games run at a lower resolution and then they get upscaled.  \n\n\ntry 1 thing for me, get an older driver where the 4090 is not supported, then use NVCleanstall and check the box \"add hardware support\", add your gpu, install the driver and then run some tests"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "top",
    "matched_keywords": [
      "rtx 4090",
      "4090",
      "rtx4090"
    ],
    "title": "MSI RTX 4090 Gaming X Trio vs GAINWARD RTX4090 PHANTOM (context inside)",
    "selftext": "Hi guys.\n\nI'm located in Japan and i plan on building a SFFPC with DAN C4-SFX (still available here yay!).\n\nRight now I could get one of these cards for the same price (250k jpy - 1762 usd), but there is a catch.\n\nThe MSI would be an import from amazon US, and the price i listed already accounted shipping and taxes). I will still have warranty and whatnot, but I'll need to send it to US if something happens.\n\nThe Gainward would be bought locally, so if need to use warranty it should be a bit easier.\n\nAnother important point is that I might deshroud the card and use it with noctua fans (there are some posts about it here on reddit), the reason would be noise/possibly better thermals. Either way both cards are compatible with the case, with or without the shroud. Source = [https://smallformfactor.net/forum/threads/dan-c4-sfx.12329/](https://smallformfactor.net/forum/threads/dan-c4-sfx.12329/)\n\nI’ve not seen a MSI Gaming X Trio deshrouded though, only the Gainward. However, I’d imagine they are very similar. The gaming performance should be similar as well.\n\nTaking in consideration the context above, which card do you think I should get?\n\nEdit1: I forgot to mention that the ideal card for my needs would be the 4090 founders edition. But as far as I know, it wasn't officially released here and the import prices are insane. Currently I could get it for 345k jpy - 2432 usd.",
    "comments": [
      "I've bought phantom because of the size (meshify 2 compact case) and couldn't be happier with performance and thermals. Max temperature I've seen is 70c with 50% fan speed. Imo you should go for it. Simpler warranty should also give you some peace of mind.",
      "Same with my Gainward 4090 Phantom (non-GS).\nCool, quiet and killer performance as expected. Also has relatively decent looks, compared to other manufacturers this generation. If one cares about that.\n\nI’ve had it since early March and it’s been HARD at work with video editing and 4K 120hz gaming since. No issues whatsoever.\n\nHighly recommended!",
      "I would buy the Gainward its local, if there was issues with coilwhine you can easly return if there is a return windowit(dunno about japan laws thou)",
      "Nice, thank you for your reply.\n\nI've owned most of the \"major\" brands, but never gainward, hence some hesitancy. How long have owned the card? No coil? Any drawbacks?",
      "GS stands for golden sample and has slightly higher clock speeds, like the OC-editions from other brands, I think!\n\nShould have very little difference in real world usage though and could potentially have a higher risk of coil whine? Don’t quote me on this though.\n\nBut if you’re into overclocking and benchmarking, none of the Gainward cards are the best anyway.\nI read that Gainward cheaped out on some electrical component, so you can’t push them as high voltage wise.\n\nSo if you like seeing high numbers and really wanna squeeze out another 2-3% in benchmarks, the MSI is probably better.\n\nFor games and work though, any 4090 is basically equal.",
      "Yeah, I'm leaning a bit more towards the Gainward and this is one of the reasons. If I buy it through Amazon I should get one month to return. Other retailers it varies, but it's at least 7 days.\n\nAmazon US offers up to 90 days for some items.",
      "Thank you for your reply! It does look nice, I agree. Do you know the difference between the gs non-gs? I kinda forgot they had more than one version. Gonna check it anyway"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "top",
    "matched_keywords": [
      "rtx 4090",
      "4090",
      "rtx4090"
    ],
    "title": "Where to buy rtx 4090 in physical store in Munich Germany?",
    "selftext": "Hello,i will visit Munich next week and i wonder are there any physical pc part stores that sells RTX4090 ?",
    "comments": [
      "There aren't any physical stores selling FEs in Germany. You can ONLY get them online from notebooksbilliger when they get new stock in (more or less randomly every few months).\n\nAIB cards are pretty much everywhere but it's usually more expensive in a store, ordering online makes more sense.",
      "maybe you call NBB in Advance, they have a physical store in Munich  \n[https://www.notebooksbilliger.de/inno3d%252bgeforce%252brtx%252b4090%252bx3%252boc%252bgrafikkarte%252b782008?awc=11348\\_1684849449\\_44dfbb84a64fff6d0b6e82ba6b2fbe17&nbb=2177fc&nbbct=1001\\_155280&pid=11348\\_1684849449\\_44dfbb84a64fff6d0b6e82ba6b2fbe17&wt\\_cc8=Hatch](https://www.notebooksbilliger.de/inno3d%252bgeforce%252brtx%252b4090%252bx3%252boc%252bgrafikkarte%252b782008?awc=11348_1684849449_44dfbb84a64fff6d0b6e82ba6b2fbe17&nbb=2177fc&nbbct=1001_155280&pid=11348_1684849449_44dfbb84a64fff6d0b6e82ba6b2fbe17&wt_cc8=Hatch)  \nthis one is availible in the physical shop   \nafaik you could order it to the shop directly",
      "Schwanthaler Computer is located in the city center and has some AIB models in stock:\n\nhttps://www.schwanthaler-computer.de/search?sSearch=rtx+4090\n\nEdit: as someone suggested, calling them upfront might be a good idea",
      "Thank you very much !",
      "Thanks 🙏",
      "See if Proshop. de has any store in München.",
      "It looks like they only have online shopping",
      "Sorry, can't help you.",
      "Thanks a lot for the reply. Unfortunately I have limited time and will stay in a hotel so buying online wont be an option.Can you give me some physical store names if you know any?"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "top",
    "matched_keywords": [
      "rtx 4090",
      "4090",
      "rtx4090"
    ],
    "title": "Help for radiator/fan installation rtx 4090 suprim liquid x",
    "selftext": "Hello community,\n\nI have a little problem installing the fans/radiator of my rtx4090 suprim liquid x to my hyte y60 case. I would like to put them on the side in air intake (pull), but the fans are mounted on the radiator in air explusion mode. Is it possible to disassemble / reassemble them to return them to air pulse mode without creating problems? I know that the best is to put them in top / Push, but I already have my aio processor kit at this level...",
    "comments": [
      "Yes! I have just done that.\n\nJust a notice: the screw included does not works for this setup. You need normal long radiator screws.",
      "Some what off-topic...but I also plan to buy one and I was going to mount it to the front side of my 011 Lian Li case...does it really matter?\n\nFirst time I'm using water cooling so I'm not 100% up with best placement of these. I also will have a AIO on the CPU that I plan on placing on the top. How important is air flow if I have the  GPU and CPU being cooled by water?\n\nI will also have 3 fans on the bottom and one on the rear.",
      "You're going to cook the inside of your PC if you pull through that radiator.",
      "Longer screws? I don't quite understand. I managed to dismantle a fan from the radiator, turn it over and reattach it to the radiator and it works fine. Except that sucking air through the radiator I wondered if it was possible or if I could do it (if it is it is completely prohibited).\n\nIt may be the whole heatsink/fans assembly that needs to be returned to the pc tower, the fans suck in air and push them against the heatsink, then the air goes back into the tower, but the air will be kinda hot i think",
      "Hey, I have one on order now and was wondering how easy would it be to replace the stock fans with different but still no RGB fans?",
      ">finally I think I have found a solution by dismantling the fans and reassembling them on the other side of the radiator. Cold air will be drawn from the fans outside the tower and pushed against the heatsink and then will enter the pc tower...",
      "I put the fan on the other side of my case so it's now fan-> case frame ->radiator.\n\nThe built in screws are not fully threaded and can not be used in this setup as they are too short.\n\nI use normal radiator screw from my old AIO and they works fine.",
      "Its fans suit me well, it's msi silent gale p12, I have them all over my tower :)",
      "What way around do you put the fans?"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "top",
    "matched_keywords": [
      "rtx 4090",
      "4090",
      "rtx4090"
    ],
    "title": "inno3d rtx 4090 - X3 OC vs ICHILL X3",
    "selftext": "So what is the difference between the  INNO3D RTX4090 - ICHILL X3 and the INNO3D RTX4090 - X3 OC?\n\n#",
    "comments": [
      "According to their website comparison tool, \n\n[https://www.inno3d.com/en/product\\_list/index/GRAPHICS%20CARD?p1c4=on](https://www.inno3d.com/en/product_list/index/GRAPHICS%20CARD?p1c4=on)\n\n[https://www.inno3d.com/en/product\\_list/index/GRAPHICS%20CARD?p1c2=on](https://www.inno3d.com/en/product_list/index/GRAPHICS%20CARD?p1c2=on)\n\n[https://www.inno3d.com/en/compare](https://www.inno3d.com/en/compare)\n\n&#x200B;\n\nthe iChill has a 1% higher boost clock, programmable RGB, and is ever so slightly taller and wider, while being a smidgeon less long.\n\nThe product page shows differences with the cooler. The iChill has a longer heatpipe, but lower total surface area. I'm not sure what impact that will have on cooling, but given that 4090's cooling are all overbuilt for the TDP, I suspect it will not impact performance in any measurable fashion one way or another.\n\nThey look different, if that matters. The OC is more understated, the iChill has a more 'gamer' aesthetic, but not terribly overdone by the looks of pictures,\n\nI haven't been able to find anything clear about the gaming OC line vs the iChill line, which is annoying,.",
      "I'm looking to buy one or the other of these. The only thing I'm concerned about is idle power draw - I saw some references suggesting it was high on the Inno3d RTX 4090s, but no specifics. Can anyone give me an accurate figure on this, and whether it's higher for the IChill?\n\nThe card will be idle a lot of the time, so I'd prefer to have <30w draw in that situation.",
      "thank you for your response!",
      "OC X3 basically is much thinner than the iChill, at the cost of higher temperatures ofc.\n\nI have an 3080TI OC X3 in my mini-ITX build since it's an two slot only card, works perfect for that regard. If size is not an issue I would suggest iChill x3 / X4.",
      "I've got an  Inno3D GeForce RTX 4080 iCHILL X3 for about a month ago and I really like the gamer aspect of it,  the RGB strip on the side it's pretty sweet.\n\nAnd from what I've seen, 4090 model has the same cooler design.\n\nAnd for the performance and temps, what can I say ? It performs great, max 63\\*C in full load, VERY silence, I literally can't hear the GPU.  \n\n\nAnd for me, the X3 OC model looks pretty basic, I'll recommend you to go with iCHILL variant.",
      "no worries. I came across this as I happened to be doing the exact same research, so figured I may as well share..."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "top",
    "matched_keywords": [
      "rtx 4090",
      "4090",
      "rtx4090"
    ],
    "title": "RTX 4090 availability",
    "selftext": "Hello fellow Pc'rs, I'm starting to buy parts for a mega-build and am wondering when anyone thinks that the RTX4090 GPU will be available for MSRP?  I don't feel that the crypto craze is weighing things down as much as last year so I'm hoping the wait won't be that long.  Thoughts?",
    "comments": [
      "Same boat as you , have a new build and am waiting to get a 4090, yes you can get 4090's at msrp from major retailers , its just that the drops are limited and you have to compete with scalpers and some peeps with bots.",
      "Nvidia is purposefully restricting stock of the 4090/4080, major tech news companies already detailed that nvidia has been stock piling 40-series since May/June? (whenever 40-series was meant to drop).  I wanted a 4080, but might consider a 7900 xtx if the performance is decent, i currently have a 3080.  Wait, 40-series is going to drop probably after the holidays....",
      "Thanks man.  I'm on a couple of waiting lists and there's no f'ing way I'm paying those ebay scalper prices.  I saw one guy change the status from \"buy now\" to \"best offer\" so that's good I think."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "top",
    "matched_keywords": [
      "rtx 4090",
      "4090"
    ],
    "title": "Ebay buyer stole my RTX 4090s GPU chip",
    "selftext": "TLDR Buyer bought my GPU, returned it, sans GPU chip and ram. I fought it, Ebay paid them, I kept my money I'm whole....with a PCB.\n\nI thought you all might find this interesting. I had heard rumors of this happening, but thought it was rumor/hoax.\n\nI sold an RTX 4090 couple weeks ago. Something about the buyer setoff some alarm bells. It was a huge ebayer. One of those with like 30k feedback and a storefront. Why would they pay retail for my GPU? The address was business in California and the buyer name seemed \"odd\". So I took a ton of pictures, got mega insurance, tracking etc.\n\nSame day they receive it they start a return. \"no video\". This card was pristine, I'm am engineer and I barely used it. So I get the card back and man it had seen some ...\\*\\*\\*\\*. The mounting bracket was bent up. Couple wired were crossed on the RGB.\n\nI called ebay, was nice but 100% this damaged I will go to court. Ebay said keep the card, keep the money, we will give them a one time refund. \"wow ok\". \n\nI figure maybe its salvageable and they are just stupid. I repair the bracket start an RMA. Its really bothering me so tonight before I shipped. I tore it down. Sure enough GPU is gone. \n\nSo here I sit. I'm whole, but I'm not sure what to do. \n\nI already reported them to ebay. Thinking about calling the cops. Whatcha think? I thought it was neat enough to share.\n\n\n\n",
    "comments": [
      "Wonder if the account was hacked, 30k feedback on an account is insane to throw away over whatever you could sell the chip for.",
      "Yeah, it is almost always a hack like that.  They get in, change address, wait a while, then pull several of these at once.",
      "Make a police report in his city",
      "Idk. It gets kind of interesting. I cant provide personal info, but I traced the Buyer back to a business in California thats been reported several times to the BBB for fraud.\n\nThey have some weird overpriced hardware business, Like they sell RTX 4090s for $3-4k scamming locals idk. I agree its odd that they have perfect feedback on ebay, but it doesn't look like a hack just scum. Then again this wholes things  bizarre.\n\n*edit\n\nFolks asking me for the buyers info: Theres rules all over reddit about providing personal info. I'm mostly concerned about getting banned. It explicitly states so on the ebay sub where this started. If I give out the info and they get doxxed Im concerned it could come back to me on reddit or legally.\n\n For what its worth last night I reported them to ebays fraud department and a couple investigative orgs and will likely look into it more today. I also do not want them to prey on anybody else. I definitely understand where you're coming from. \n\nI can't take them to court \"I don't think, because ebay ate the cost. Im fine. I mentioned claims court because that was my next step if ebay hadn't stepped in and helped me. That said even if its useless I will file reports with legal agencies.",
      "Crazy how ebay just let them off like that... No wonder people keep doing it",
      "Honestly, they need to be named and shamed. What if someone here considers buying their products? People need to know what store this is. Otherwise, they get to skate by on their 30,000 reputation feedback score and scam others. \n\nYou're the current line of defence against every honest buyer and seller that may come across this post. \n\nPut them out there.",
      "They aren't going to do anything.",
      "i been though this, as soon as you mention ebay and the internet your local cops are going to tell you its a \"civil matter\" and to contact ebay.",
      "Die is going straight to china for AI farms. Scummy.",
      "True, but PayPal may like the documentation for his dispute.",
      "I lost my 16 year old seller account because a video game store with more negatives than I had total feedback in thr last five years, in California, purchased a sealed xbox series x from me. It had four seal stickers at shipment. I have the serial number sticker photographed in the listing. \n\nThey returned it and left negative feedback. Stating it wasnt sealed. They returned an xbox one in a damaged series x box and the serial numbers matched my listing.\n\nEbay had all of the evidence, I had the USPS sealed the box on video, they let the seller off the hook, charged me and locked my account for investigation.\n\nI filed a police report because ebay told me to. I uploaded it.\nEbay deleted my account. 700+ feedback as a buyer and 400+’feedback as a seller gone.\n\nFuck ebay",
      "I mean almost certainly it's getting shipped off to China though I'm not sure why they need to resort to this",
      "Because us poor folk don’t get the same treatment if this done to a corporation. \n\nWe don’t get protected like CEOs and the Corporations",
      "No real way to police it I guess? They must know it's a problem if they refunded both seller and buyer.",
      "The BBB is not a government entity. It’s a commercial review site like Yelp.",
      "FBI might be interested if so… top level chips black market is a hot national security topic",
      "Sold my 4090 on eBay to someone with 1 feedback (forgot to put a requirement) and I knew there was a high chance it would be a scammer. Buyer paid immediately, I shipped the card after the weekend was over and a few hours later I got an email from eBay that the buyer has been removed from the platform and that I shouldn’t ship the gpu. I called customer service and informed them that it was already shipped (prior to that I called ups to try to have it redirected to my address but they told me that eBay has to initiate this because otherwise I would eat the shipping cost). eBay csr confirmed that the buyer has been banned from the website and that the back office would try to reroute it back to my address or if that didn’t work, I would get a full refund for the price I had it listed. 2 days later I see that the gpu was delivered to that location but I got a full refund from eBay. I googled the address and it was some sort of hub that ships internationally, so it was definitely shipped to China after that. Even with direct signature required, they were able to receive the package by a different person.",
      "Ok, so I know this is about eBay, but honestly, Amazon and Walmart have the same problem. It's everywhere now, and it's getting ridiculous. People returning the wrong item or even removing core chips and sending them back like nothing happened—it’s basically a scam at this point. Shopping online is turning into a total headache.",
      "GPU core is getting installed into another card with more VRAM. Search for 48 GB 4090.",
      "The video wouldn't show the customer extracting the chip from the GPU. Nonsensical solution"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "top",
    "matched_keywords": [
      "4090"
    ],
    "title": "Gigabyte 5090 finally arrived",
    "selftext": "Finally managed to get hold of a 5090 (UK). Used HotStock app and got an Amazon drop on the 26th which just showed up today. All round really happy with it, was a bit dubious about the fake frames but after 2hrs of Cyberpunk I'm sold. Just seems super smooth and letting monitor stretch it legs. \n\nA bit concerned with the melting power cables seeing it pulling in like 575 watts. How's everyone feeling about the issue, this something I should be hugely concerned with ? I see people posting about undercoating. Had 4090 FE and never had a problem. Upgraded to NZXT C1200 PSU for the 5090. ",
    "comments": [
      "Dude, check this post out: https://www.reddit.com/r/nvidia/s/CbRfdPAmBL\n\nThe 5090 runs better than stock at around 450 watts. It’s insane. No need to be nervous at all. I tried this out and tested it myself and it’s legit, just follow the simple undervolting guide. I used it on several benchmarks (3d mark) and Cyberpunk and I’m getting slightly better than stock and it stays so cool. \n\nHonestly, even if you don’t undervolt, youll be fine. I used the card for a while now at full wattage, checking cables and connector with infrared heat sensor (ten bucks you can buy one if you’re worried) and also monitored hvpwr voltage for a week, and everything checks out. The card is a beast and it’ll work fine. The rare cases (maybe only 2 confirmed actual melting incidents) are way overblown. Grats on the sick build!",
      "Cyberpunk just wasn’t running good enough the 4090.",
      "Are you always this confident when you’re wrong?",
      "Bro has beef with ai frames lol",
      "looks matter.",
      "Nice glad your set up is working, it looks great.  I’d be interested to see a picture of your build with the 5090.  Which version of gigabyte did you get?  Im looking to do the same so it’s nice to hear that you are happy with it.  Any coil whine?\n\nRegarding the issues if you are not going to under volt, you could always check each wire of the cable with a digital clamp meter.  You shouldn’t have to do that but you’d have peace of mind.  I’d definitely run it for a while and place your hand on the wires to see if any of them are overheating (I’m sure you’ve probably done this already).\n\nI hope you don’t have this issue.  Sounds like it’s not happening to everyone.",
      "Yeah but I put UK in the post. Maybe if it was America",
      "I've not had any issues with mine (Astral, though). It shows near perfect balancing on the wires with a brand new cable and PSU (Seasonic Prime TX 1300W).",
      "Very nice, new cpu next",
      "i've undervolted and power limited mine.   \n  \npower consumption is now about 420W for about a 2% reduction in frame rate. although interestingly - in one game the undervolting actually gives a huge 30% uplift in frame rate.\n\nthere's not much reason not to undervolt imho, runs cooler, less worry about the power connector burning out and lower electricity bills.",
      "We gotta teach gamers how to take screenshots so they aren't looking crazy out here taking photos of their monitors. Geez.",
      "WoW amazing build",
      "Thanks for the reply. Hopefully it's just overblown. I'll check out the thread you posted. Thanks for the info pal.",
      "Was running pretty great on the 4090 to be fair. I recently got a new monitor that does 240hz and its quite a bit different from 80fps to 200fps. Fair enough they aren't real but still feels much smoother.",
      "I just looked at your other pictures.  Looks like you did include the 5090.  It looks great.",
      "maybe he uploaded this via mobile and it was just easier to do so.",
      "How much did you pay for it? Also after an Aorus in the UK (either that or Suprim).",
      "Meanwhile I’m just trying to upgrade from a 3090 .  Congrats on the upgrade hope it serves you well.",
      "Nice",
      "My Vanguard 5090 never goes above 55c on Cyberpunk with everything maxed.  Why fuck with it?"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "top",
    "matched_keywords": [
      "rtx 4090",
      "4090",
      "rtx4090"
    ],
    "title": "4090 Decision",
    "selftext": "So after 6 years of gaming with my 1080 TI Strix I need to upgrade and decided I want a 4090 and use it for the next couple of years.\n\nNow here is where I have some trouble deciding which one to take as they vary greatly.\n\nI live in Austria therefore the FE is not available under 2.500 €.\n\nI read many comments and often people tell to buy the cheapest because the rest is overpriced.\n\nThe cheapest ones I found are the following:\n\n&#x200B;\n\nPalit GeForce RTX4090 Gamerock 24GB  - 1.799€\n\nPNY GeForce RTX 4090 XLR8 Gaming Verto Epic-X RGB  - 1.799 €\n\nINNO3D GeForce RTX 4090 X3 OC  - 1.799€\n\nZOTAC GAMING GeForce RTX 4090 Trinity   - 1.799€\n\nPalit RTX4090 Gamerock OC 24GB - 1.819 €\n\nKFA2 GeForce RTX 4090 SG 1-Click OC 24GB GDDR6X  - 1.849 €\n\nPNY GeForce RTX® 4090 24GB VERTO Triple Fan - 1.849 €\n\nMSI GeForce RTX 4090 Ventus 3X OC - 1.869 €\n\nZOTAC GAMING GeForce RTX 4090 Trinity OC - 1.869 €\n\nGigaByte GeForce RTX 4090 WINDFORCE 24G - 1.899 €\n\nGigaByte GeForce RTX 4090 GAMING OC 24G - 1.909 €\n\nZOTAC GAMING GeForce RTX 4090 AMP EXTREME AIRO - 1.949 €\n\n ASUS TUF Gaming GeForce RTX 4090 OC - 1.999 €\n\n&#x200B;\n\nI am really not sure which is the best option and if I should just take the cheapest or if some higher priced one of them is actually worth it.\n\nThanks in advance for your help community.",
    "comments": [
      "Have sold 500+ PCs, buy any card but gigabyte. Most of my customer returns were gigabyte.",
      "PNY 4090 XLR8 Epic-X\n\nIt is one of the cheapest in your list and has one of the best/quietest cooling",
      "Heard the gigabyte gaming oc is the best most popular 4090 with no coil wine",
      "It's whisper quiet yet you have to limit fans to 55%, and then go on to talk about how cool it is with an aggressive fan curve?  Confusing.",
      "I’d go with the EVGA…………….. :(",
      "I bought a Zotac 3090 a couple of years ago, simply because they were offering a 5 year warranty with their cards at that time. If the warranty period is important to you then it might be best looking at the decision from that point of view. I wasn't happy with the idea of dropping £1600 on something that only had a 2 year warranty.",
      "I’ve got a Gigabyte Gaming OC and it is the quietest card I’ve ever heard. My friend got the MSI Gaming Trio (which was my first option) and his has such an annoying coil whine. So glad I chose the Gigabyte one.",
      "Ultimately it doesn't matter as they will perform the same, but there are a few things to consider. \n \nIf you are somewhat irrational like me, you may want to avoid the cards with a technically weaker VRM for peace of mind. The Trinity Zotac cards and GameRock cards have a weaker VRM layout/PCB components than the 4090 FE and most other 4090 variants. The techpowerup website is good for checking PCB layouts as their reviews include detailed pictures.\n \nSecondly, cards from more popular brands will likely sell for slightly more in the future. e.g. you may pay 100 EUR more for a Gigabyte card now, but you could get half or more of that back when you sell it. \n \nOut of those yo list, I would probably get the Gigabyte Gaming OC as it has performed well in reviews. The ASUS TUF is another good card, but it is not cheap.",
      "It's so weird. I've had a MSI watercooled 1080 on my brothers pc since 2016 and it's still running, but my Aorus water-cooled 2080ti (bought a few months after release) was at 85°C when running warzone at medium-low.\n\nA few days ago bought a 4090 MSI Suprim Watercooled, it's very quiet and doesn't go over 60°C, as of now.",
      "I am using Zotac 3090 myself. Upgraded from an ASUS 3080 TUF 10GB because I kept running out of VRAM trying to play VR.\n\nGonna upgrade to a 4090 once 7800X3D comes available. My current rig with a 5800X3D is going to my partner who is trying to game on my old 980Ti but it's starting to crash every time she tries a graphically intensive game.\n\nMy 980Ti is a Palit, lasted a good 8 years now.",
      "I went from strix 1080 Ti to 4090 Galax KFA2, its really a great card",
      "Asus TUF has bad coilwhine on many cards so be prepared. I returned my strix and went for K2FA",
      "Just GPUs, love their motherboards.",
      "Gigabyte Cards are great till they stop working without a reason. I might be unlucky but never had similar track record with even so called b brands. Once the shop i bought told your card has issues but gigabyte won’t accept their return so they gave me a new kfa. So I don’t like that kind of shit when they say no to their official partners",
      "I would personally get the Zotac. That card looks stunning in person, and their quality control got extremely good with the 3000 series. PNY designs professional cards for NVIDIA, so they are high up there in terms of quality as well.\n\nYou have many options man, pick the one you like the best honestly! Hard to go wrong.",
      "From your list I would (and did) choose the KFA2 / Galax SG.\n\nWhy?\n\nIts a Reference PCB, which fits the Alphacool enterprise waterblock (the smallest block), however its a 600w card (not 450) with more power phases than the Inno3D/PNY reference cards.",
      "ASUS TUF",
      "Gigabyte OC 4090 GAMING would be my choice. Enjoy!",
      "I have pny 4090 and no issues. Quiet and minimal to no coil whine.",
      "Have the 4080 version and love it."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "top",
    "matched_keywords": [
      "rtx 4090",
      "4090",
      "rtx4090"
    ],
    "title": "Can you help me with the difference between these two 4090 video cards?",
    "selftext": "Please help me to understand the difference what they ask me to pay for? Do I actually need the more expensive video card?🙏\n\nIt is meant to be for video editing, streaming, and playing video games.\n\nI have found 2 video cards from Asus:\n\n1. [https://www.asus.com/motherboards-components/graphics-cards/tuf-gaming/tuf-rtx4090-o24g-og-gaming/techspec/](https://www.asus.com/motherboards-components/graphics-cards/tuf-gaming/tuf-rtx4090-o24g-og-gaming/techspec/) - ASUS TUF Gaming GeForce RTX™ 4090 OG OC Edition Gaming Graphics Card (PCIe 4.0, 24GB GDDR6X, DLSS 3, HDMI 2.1, DisplayPort 1.4a) - costs $1,759 on Amazon.\n\n  \n2. [https://rog.asus.com/graphics-cards/graphics-cards/rog-strix/rog-strix-rtx4090-o24g-white-model/spec/](https://rog.asus.com/graphics-cards/graphics-cards/rog-strix/rog-strix-rtx4090-o24g-white-model/spec/) - ASUS ROG Strix GeForce RTX 4090 OC Edition Gaming Graphics Card White (PCIe 4.0, 24GB GDDR6X, HDMI 2.1a, DisplayPort 1.4a) - costs $2,472 on Amazon.\n\nThe price difference is huge - $713 or 40.5% to be exact.\n\nThe difference as far as I understood from specs are:\n\n|Metric|TUF|ROG|Difference|\n|:-|:-|:-|:-|\n|Recommended PSU|850W|1000W|+17.65% (WHY?)|\n|OC mode|2595 MHz (Boost clock)|2640 MHz|+1.74%|\n|Default mode|2565 MHz (Boost clock)|2610 MHz (Boost Clock)|+1.75%|\n|Slot|3.2 Slot|3.5 Slot|What does it even mean?|\n\nAny comments on this would be very helpful! Thank you so much for your time! 🙏\n\n",
    "comments": [
      "The Strix is not worth 700 additional Dollars. Especially not some few months before the 5090 launch.\nNo tough choice: take the TUF",
      "You will not see a 40% performance difference but like a 2% performance difference.  \n\n How much that is worth it to you depends on you.  And it’s a very nice card, but very pointless for a typical consumer. \n\nUnless you are making the majority of your money with your computer and the bottleneck for additional profits is your graphics card, you could probably still be fine with a significantly cheaper 30 series. \n\nBut if it makes you feel good, go for it.",
      "* Recommended PSU - because the ROG card uses more power, clocks can go higher\n\n* OC, default mode - overclocking from factory\n\n* slot - thickness of the card",
      "just a reminder what 2% is = playing 4k maxed out newest game 110 FPS or 112 FPS",
      "Sounds like you already know your answer then!\n\nAnd yes, it's significantly more performance for significantly more price, but the performance tends to be very overkill for the average consumer. \n\nBut nothing wrong with wanting the best of the best either if you're into that sort of thing.\n\n(I have one too)\n\nIt might still be worth waiting to see what the 50 series will be like performance/pricing wise if it's not urgent though.",
      "Any 4090 is the best card money can buy.  I bought an MSI Trio at launch for $1600 and it's remains stupidly unbeatably awesome.  Get the TUF.",
      "The power delivery is much better, higher quality VRMs and other components, and better cooling. It's more than just a better bin of the GPU die.\n\n\nAll of that adds up to a relatively small improvement though.",
      "i mean 5090 will get scalped to hell. going for 3500-4000 USD. then you'd have to wait another 6 months for non-Nvidia versions to come out + drivers. I'm in the same boat. I have a macbook but wanted to get back into PC gaming and can afford 4090 now. People say wait but that's 6 months of my life not playing anything.\n\nI was thinking that I could still sell barely used 4090 for at least 800 and then cover at least some of the difference for 5090. Besides, you (and I) could still buy 5090 in 2-3 years because 6090 won't come for a long long time.",
      "Everyone in this thread is fucking blind. It's not normal TUF, it's \"OG\" version, it reuses old 3090 PCB and cooler. \n\n\nAnyway, the differences in practice are basically zero, so just get the cheapest version you can. Stick with Asus, since it's the only oem with 2x hdmi 2.1. Every other card is imo a piece of crap due to this specific reason.",
      "The ROG is basically the same thing as the TUF but it's binned higher (technically higher quality silicon, thus higher clocks, meant for more overclocking). I have a MSI 4090 Suprim X which is effectively the ASUS ROG, you will notice zero performance difference between the two Asus 4090 models you listed, or really any similarly priced 4090 from any vendor, in a real world scenario. Buy the cheapest name brand you trust from a reputable dealer (don't fall for the scams on Amazon and Newegg showing GPUs that are $200-400 under their MSRP; I usually filter out 3rd parties on Newegg/Amazon because of this).\n\nAs already noted, the slot size is the width of the card. The 4090 is a big boi and will basically require 4 PCI slots. This matters if you're trying to do something...special like a Mini-ITX or a vertical mount (those come to mind but there are others). Generally if you have no other PCI devices (capture card, sound card (lol), etc.) you'll be fine with any mid-size ATX case; the bigger concern is the length of the card (typically around 315mm+, or over 12+ inches) which may not fit all mid-size ATX cases.\n\nIf you want a more in depth review, check out TechPowerUp. They have comparison verses the other models on some graphs and the FE model. It's not worth the huge markup for the ROG for the everyday gamer. [https://www.techpowerup.com/review/asus-geforce-rtx-4090-strix-oc/31.html](https://www.techpowerup.com/review/asus-geforce-rtx-4090-strix-oc/31.html)",
      "Any other series besides the 4090 I say get the strix but but seen the tuf match the strix in the 4090. So I say yet the cheapest of rhe two. It isn't like the 4080 super strix that can be 420watts while the tuf is 355watts with only a 10% availability in oc power with the strix a 33%  so yeah get whichever you like more or go with the cheaper one. The tuf and strix are way to similiar in the 4090 I can't imagine spending the extra on the strix. Unless you truely do love the looks that much more\nAlso those boost clocks are random. You can get the oc or none OC. I've seen some OC be higher on both and some none OC higher. It's all silicon lottery and the OC bios only adds to the clocks but even then let's say you get a none OC without the bios it can still have higher clocks then the OC out of the box. The OC just makes sure it's adding a certain amount over its base clocks that's it. \n\nA tuf can have the same clocks out of the box as a strix vice versa.",
      "Higher out of the box clock speeds on the Strix but you're only paying for that alongside maybe a bit better binning for higher OC, but you won't exactly see a hug improvement unless you're custom water cooling with an industrial chiller. Get the tuf and OC it to strix speeds is really the best option",
      "Coming from an 3080 tuf, 3080ti strix and now 4090strix can say they are beautiful but the coil whine is just stupid, it doesn’t make any sense something that expensive can make that noise, take it from me that I live in argentina and paid 2600 dollars for a 4090 strix, and the coil whine is pretty intense, I’ve been told gigabyte have less but it’s a lottery but apparently asus have the most",
      "Yeah, high quality components are important, but I am not sure it worth so much. In the end if it will fail in 3-4 years it'll be easier to buy a new one than try to fix the old one, especially considering I don't have any knowledge on how to fix it myself.",
      "Yeah sounds good, luckily the tuf 4090s are the best tuf cards asus has ever made. I find it funny the year they get called out for customer service from past is the year there cards having been working so well lol. Like legit so so good always at the top of every list even the tuf. The tuf and the strix imo are identical people even figured out how to raise the power limit just like on the strix. So all good man enjoy.",
      "Man, I am on MacMini M2 Pro right now, with literally no adequate heat dissipation, interfaces and so on.  😂 I want to run from it.\n\nAnd if I would want to upgrade, I think there will be a huge market for used 4090, considering receipt with quite new date on it.",
      "the price of a used 4090 will go down considerably once the 5090 is out, because you and everyone else will jack up the supply as they sell to upgrade. so you'll lose a lot of the money you spent.",
      "just get a 4090 bro",
      "Go for it then. You will be happy with the performance.",
      "Don't buy Asus stuff"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "top",
    "matched_keywords": [
      "rtx 4090",
      "4090",
      "rtx4090"
    ],
    "title": "Need help confirming a build RTX4090 + 7800x3d",
    "selftext": "Hi guys, I'm planning to make this build to run MSFS, CyberPunk and GTA V (hopefully also GTA VI)\n\nI'm stuck on choosing a case, the motherboard (X670E vs. B650), a sufficient power supply (1000W or 1200W), and the optimal CPU cooler.\n\nCould you please check my build and let me know your recommendations?\n\nFor the motherboard, I'm picking between MSI B650 GAMING PLUS WIFI or Gigabyte B650 Gaming X AX Or MSI X670E GAMING PLUS WIFI AM5 – but am open to suggestions.\n\n\\[PCPartPicker Part List\\](https://pcpartpicker.com/list/twXpYN)\n\n\n\nType|Item|Price\n\n:----|:----|:----\n\n\\*\\*CPU\\*\\* | \\[AMD Ryzen 7 7800X3D 4.2 GHz 8-Core Processor\\](https://pcpartpicker.com/product/3hyH99/amd-ryzen-7-7800x3d-42-ghz-8-core-processor-100-100000910wof) | $384.00 @ Newegg\n\n\\*\\*CPU Cooler\\*\\* | \\[Thermalright Peerless Assassin 120 SE 66.17 CFM CPU Cooler\\](https://pcpartpicker.com/product/hYxRsY/thermalright-peerless-assassin-120-se-6617-cfm-cpu-cooler-pa120-se-d3) | $33.90 @ Amazon\n\n\\*\\*Motherboard\\*\\* | \\[MSI X670E GAMING PLUS WIFI ATX AM5 Motherboard\\](https://pcpartpicker.com/product/4jKscf/msi-x670e-gaming-plus-wifi-atx-am5-motherboard-x670e-gaming-plus-wifi) | $229.00 @ MSI\n\n\\*\\*Memory\\*\\* | \\[G.Skill Trident Z5 RGB 64 GB (2 x 32 GB) DDR5-6400 CL32 Memory\\](https://pcpartpicker.com/product/636p99/gskill-trident-z5-rgb-64-gb-2-x-32-gb-ddr5-6400-cl32-memory-f5-6400j3239g32gx2-tz5rk) | $217.99 @ Amazon\n\n\\*\\*Storage\\*\\* | \\[Western Digital Black SN850X 2 TB M.2-2280 PCIe 4.0 X4 NVME Solid State Drive\\](https://pcpartpicker.com/product/crKKHx/western-digital-black-sn850x-2-tb-m2-2280-pcie-40-x4-nvme-solid-state-drive-wds200t2x0e) | $154.99 @ Walmart\n\n\\*\\*Video Card\\*\\* | \\[Gigabyte GAMING OC GeForce RTX 4090 24 GB Video Card\\](https://pcpartpicker.com/product/TgkWGX/gigabyte-gaming-oc-geforce-rtx-4090-24-gb-video-card-gv-n4090gaming-oc-24gd) | $1799.99 @ B&H\n\n\\*\\*Case\\*\\* | \\[Corsair 4000D Airflow ATX Mid Tower Case\\](https://pcpartpicker.com/product/bCYQzy/corsair-4000d-airflow-atx-mid-tower-case-cc-9011200-ww) | $104.99 @ Amazon\n\n\\*\\*Power Supply\\*\\* | \\[be quiet! Straight Power 12 1000 W 80+ Platinum Certified Fully Modular ATX Power Supply\\](https://pcpartpicker.com/product/NyxxFT/be-quiet-straight-power-12-1000-w-80-platinum-certified-fully-modular-atx-power-supply-bn338) | $189.90 @ Amazon\n\n| \\*Prices include shipping, taxes, rebates, and discounts\\* |\n\n| \\*\\*Total\\*\\* | \\*\\*$3114.76\\*\\*\n\n| Generated by \\[PCPartPicker\\](https://pcpartpicker.com) 2024-04-10 15:31 EDT-0400 |",
    "comments": [
      "If you are looking for a pure gaming build, you could save over $100 on RAM if you chose a 32GB kit of DDR5 6000mhz CL30. AMD's X3D CPUs are not as memory sensitive as others and the extra speed won't benefit you much for gaming.\n\nAlso there are other great options for motherboards to save money as well. Check out the YouTube channel \"Hardware\nUnboxed\" motherboard roundup for great motherboard recommendations.\n\nThe money you save could always be reinvested into other components like NVME SSD's or a monitor.",
      "I'm glad it's working for you, bud. I did do some other digging (sources below) and it looks like the performance gain is on average less than 3% at 1080p for gaming and the price is double. I think I'm going to stick by my original statement for now though. Save the cash on 6000mhz CL30 and use that  saved money for other upgrades.\n\nSources\nhttps://youtu.be/-Wkr3FV50xI?si=s7zOooxYZ6MEXCM_\n\nhttps://youtu.be/p21bsVYAgvA?si=BZA1qCh4jRBJp54G",
      "Yes you can do the peerless assassin. They are basically the same, but the phantom spirit is one extra heat pipe. Both will work just fine as the 7800x3d doesn’t pull much wattage.\n\nFractal torrent is a great case. The main things to check with case clearance is cpu cooler height, max GPU length, and max PSU length. You can look at the manufacturer website for the case specs. Newegg also has a quick reference section for stuff like that if you see the product on Newegg.\n\nFor the PSU, I picked an A tier PSU. 1000w gold is more than enough for your setup. The one you picked is good too, just more expensive. Both have Japanese transistors and 10-year warranties so I would pick whichever one is cheaper.\n\nFor the GPU, I would personally just get the cheapest 4090 you can. Coil whine tends to be a luck of the draw type of deal. Also, gigabyte 4090’s had (don’t know if this issue has been resolved) thinner pcbs so if you don’t properly support the card, the pcb could bend or crack.\n\nAs for the RAM, two things here. First, you need low profile ram to fit under the PA cooler and ther is no point of getting rgb ram because it will be covered by the cooler. Second, the sweet spot for ram speeds on AMD is 6000mhz and 30 CAS latency.\n\nHope that helps.",
      "Thanks!\n\nWould you recommend the B650’s or the X670E for the motherboards?",
      "Doing this, great advice. \n\nThank you!",
      "What? Rockstar has always done this to PC gamers. They release the game on console first, then a year or so later, release it on PC.  There's been no official confirmation from Rockstar that there won't be a PC version unless you can prove me wrong.",
      "go peerless assassin or Spirit, they are best coolers atm, conquering 100$+ coolers",
      "Thanks man! Realised this would be a smart move.",
      "1) get one of the B650s\n2) change the ram used as already noted\n3) 1000W is fine",
      "Funny build since it is so much like what I use. I have the MSI Gaming Trio X 4090, 32 gig of that same memory (non rgb for me), and I am using my previous Corsair HX850W psu. My case is also the 4000's big brother, the 7000D, since I like a lot of space and missed it from my previous mid tower type case. Other stuff you list is the exact same as what I use.\n\nI can say that all your main stuff there will work well based on my experience of using it for the last 7-8 months. Well, assuming there's nothing funky about the Gigabyte 4090.",
      "Made some changes, let me know if you have questions.\n\n[PCPartPicker Part List](https://pcpartpicker.com/list/ZBh834)\n\nType|Item|Price\n:----|:----|:----\n**CPU** | [AMD Ryzen 7 7800X3D 4.2 GHz 8-Core Processor](https://pcpartpicker.com/product/3hyH99/amd-ryzen-7-7800x3d-42-ghz-8-core-processor-100-100000910wof) | $384.00 @ Newegg \n**CPU Cooler** | [Thermalright Phantom Spirit 120 SE 66.17 CFM CPU Cooler](https://pcpartpicker.com/product/GpbRsY/thermalright-phantom-spirit-120-se-6617-cfm-cpu-cooler-ps120se) | $35.90 @ Amazon \n**Motherboard** | [MSI B650 GAMING PLUS WIFI ATX AM5 Motherboard](https://pcpartpicker.com/product/szfxFT/msi-b650-gaming-plus-wifi-atx-am5-motherboard-b650-gaming-plus-wifi) | $169.00 @ MSI \n**Memory** | [TEAMGROUP T-Force Vulcan 32 GB (2 x 16 GB) DDR5-6000 CL30 Memory](https://pcpartpicker.com/product/HNZXsY/teamgroup-t-force-vulcan-32-gb-2-x-16-gb-ddr5-6000-cl30-memory-flbd532g6000hc30dc01) | $102.99 @ Amazon \n**Storage** | [Inland TN450 2 TB M.2-2280 PCIe 4.0 X4 NVME Solid State Drive](https://pcpartpicker.com/product/BqWJ7P/inland-tn450-2-tb-m2-2280-pcie-40-x4-nvme-solid-state-drive-2tb-tn450) | $116.99 @ Amazon \n**Video Card** | [MSI RTX 4090 GAMING SLIM 24G GeForce RTX 4090 24 GB Video Card](https://pcpartpicker.com/product/7srqqs/msi-rtx-4090-gaming-slim-24g-geforce-rtx-4090-24-gb-video-card-rtx-4090-gaming-slim-24g) | $1599.00 @ MSI \n**Case** | [Lian Li LANCOOL 216 ATX Mid Tower Case](https://pcpartpicker.com/product/qP2WGX/lian-li-lancool-216-atx-mid-tower-case-lancool-216x) | $94.99 @ Newegg Sellers \n**Power Supply** | [Montech TITAN GOLD 1000W 1000 W 80+ Gold Certified Fully Modular ATX Power Supply](https://pcpartpicker.com/product/nWM48d/montech-titan-gold-1000w-1000-w-80-gold-certified-fully-modular-atx-power-supply-titan-gold-1000w) | $137.99 @ Amazon \n | *Prices include shipping, taxes, rebates, and discounts* |\n | **Total** | **$2640.86**\n | Generated by [PCPartPicker](https://pcpartpicker.com) 2024-04-10 18:23 EDT-0400 |",
      "What is your monitor, is it 4k?",
      "I basically built this build late last year and put it in a Fractal Torrent. Went with newer phantom spirit 120 cooler. ASRock Taichi Lite B650 for mobo. Hell of a board.",
      "https://pcpartpicker.com/list/zxKLXk\n\nImo get this and upgrade the GPU to the 5090 on launch. Getting a 4090 just 4-5 months before the brand new big boi is gonna hurt. Imagine how 3090ti buyers felt 4-5 months after they bought theirs and the 4090 dropped.\n\nIf you still really want a 4090 go for it. But right now it's overpriced and 1.5 yrs old",
      "Okay wait a minute…\n\nGet a 4070 super or 4070 TI Super now.\n\nThen later get a 5080 when GTA 6 is released for PC.",
      "Get a B650E/X670E board, either doesn't matter because the E stands for PCIe 5.0 x16 compatibility which means future GPUs beyond the 4090 will also work without any limitations. \n\nGet a Corsair/Seasonic PSU for the best realiability and peace of mind. 1000w is plenty enough.\n\nAnd that brings us to the question, what is the purpose of 64GB RAM in the system?",
      "I’m thinking of going for this one \nMSI X670E GAMING PLUS WIFI ATX AM5 Motherboard\n\nCan’t recommend it? Could you give me a B650 you recommend if not?",
      "You’ve got the same motherboard? If so, you think I should go for it or opt for a B650? Really stuck on that…",
      "The case I’m looking at is the Fractal Torrent, looks quite sick.",
      "The cooler you chose is out of stock where I am, can I get the [Thermalright Peerless Assassin 120 WHITE ARGB CPU Air Cooler,6 Heat Pipes]() instead?\n\nThe case I prefer is the Fractal Torrent, will it fit everything?\n\nPower supply, any specific reason you changed it? I like the be quiet! one, Japanese quality\n\nVideo card I heard that the Gigabyte OC Gaming is the card that's had less coin whine issues, so went for that one\n\nMemory also, why the change?"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "top",
    "matched_keywords": [
      "rtx 4090",
      "4090",
      "rtx4090"
    ],
    "title": "Gigabyte (Benelux) absolutely unhappy of behavior of webshops after RTX4090 launch",
    "selftext": ">Gigabyte has responded with a statement on social media to what it calls the 'price explosion' after the introduction of the GeForce RTX 4090. The Benelux delegation of the video card manufacturer says it is 'absolutely unhappy' about the price increases.  \n>  \n>Data from the Tweakers Pricewatch shows that the cheapest RTX 4090 video cards were on sale last week on the introduction day for just under 2000 euros. That is reasonably in line with the official suggested retail price of 1959 euros. The cheapest model now costs at least 2349 euros.  According to Gigabyte, it has done everything possible to bring the RTX 4090 'for a decent price and (with) sufficient stock' on the market. After questions from Tweakers, the manufacturer explains that it had hundreds of cards available for the sale. Specifically, the WindForce variant was intended to actually be for sale for the recommended retail price, whereby a 'healthy margin' was already possible for web stores. The price increases that can now be seen therefore only increase profits in the last link of the chain.\n\n[https://tweakers.net/nieuws/202378/gigabyte-absoluut-niet-te-spreken-over-gedrag-webshops-na-rtx-4090-release.html](https://tweakers.net/nieuws/202378/gigabyte-absoluut-niet-te-spreken-over-gedrag-webshops-na-rtx-4090-release.html)\n\n[https://www.instagram.com/p/Cjz-FvPqpzZ/](https://www.instagram.com/p/Cjz-FvPqpzZ/)",
    "comments": [
      "Gigabyte could and should set maximum pricing requirements on resellers. Actually these manufacturers should be doing what EVGA started doing long ago letting people join waitlists to buy so they didn't have to resort to botting, F5ing, or buying from scalpers",
      "Name drop them",
      "[cyberport's prices are also insanely high](https://www.cyberport.de/pc-und-zubehoer/komponenten/grafikkarten/nvidia-fuer-gaming.html?productsPerPage=15&sort=price_desc&2E_Grafikchip=GeForce%20RTX%204090&page=1)",
      "Same is happening in NL,  2650 euros for stock Asus 4090 TUF ..",
      "Same here in the UK, COUGH, Overclockers UK. Disgusting prices on the Gigabyte cards, which are not exactly high-end, yet they want crazy money.",
      "amazon.it cheapest i've seen is PNY at 2.5k euros, i haven't seen anything close to msrp. some of them even over 3k. other sites are the same.\n\nhttps://www.trovaprezzi.it/prezzo_schede-grafiche_4090.aspx\n\nthis is not a result of our sales tax, just fucking sellers being greedy as usual. long are gone the days of paying maybe 50€ over msrp and feeling bad about it.\n\nonly sites where prices aren't scalped as fuck: directly from nvidia (soldout since d1) and 3 other nvidia partners also sold out since day 1, the only partner website where you can get a 4090 right now sells it inside a prebuilt that goes from 5.5k to 6.3k. its so fucking dumb",
      "Tech in the Benelux is a wallet vacuum",
      "They should take a look at Best Buy. They are still charging over 2K for an Aorus 3090",
      "Nvidia and AIBs are being short-sighted not to let people waitlist to buy, and not clamping down on overpricing/scalping. When faced with overpricing or scalper prices a lot of people will just resort to other products or hold onto their current. And if people do end up paying too much to retailers overpricing or scalpers, many won't be able to upgrade as often or at a higher tier than if they were able to buy at normal prices.",
      "Manufacturers usually keep track of where products go by serial numbers. If they see an unauthorized seller (anyone who hasn't agreed to manufacturer pricing requirements) selling large quantities, they can buy one or a few units to see where it came from.\n\nI work in wholesale and have seen retailers get penalized and even removed for violating manufacturer pricing. Trying to hide it by selling through an unauthorized seller would be even worse.",
      "Worth noting caseking is the EU sister branch of the uks overclockers they doing the same shit.",
      "Damn we don't even have a single reseller so far in Ireland lol.",
      "It's the entire scummy Europe. Not just Germany. Even 3090's still sell for €1500. Scalpers aka retailers, probably figured out if they bump up the price of 40 series, then they can easily ask same old scalp price for 30 series.",
      "I’ve also noticed a huge price bump on Amazon as well. I’ve seen the Asus Rog strix go from $2,000 to $4,000. It’s disgusting and awful.",
      "Almost every UK outlet is scalping now... pretty disgusting.",
      "You'd have to be an absolute *idiot* to try to open up a computer shop/electronics store in 2023.  There's a reason why almost all of them around the world failed nearly two decades ago.",
      "That happens because people keep buying at those prices.\n\nJust check this and other subreddits to see what i mean. It´s a sausage contest and who buys it now has the greatest sausage to show their friends :)",
      "Dit gaat o.a. ook over Megekko.. (NL)",
      "2899 voor de suprim 😂",
      "Fcking sick, there are no 4090 in pc stores in México yet and scalpers buying at scalper prices are selling 4090s for 4-5k USD, disgusting."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "top",
    "matched_keywords": [
      "rtx 4090",
      "4090",
      "rtx4090"
    ],
    "title": "From 7900XTX to 4090, opinions on which model?",
    "selftext": "Edit: i decided on the PNY one, thanks folks :)\n\nHi guys,\n\nI bought a new PC a few weeks ago and decided to go with the 7900XTX. It's a great GPU in itself, but I'm playing at 4k and want to get as close to 144FPS as possible (not always possible, I know, but as often and as close as I can). Now I'm wondering if I should return the 7900XTX and get a 4090 instead. The 4090s start at €1650 in my country (Germany), the Founders Edition is hardly available and from €2000 upwards, that's too much for me. I therefore have these 6 in mind, I would like to stay under €1800. Which one can you rather recommend?\n\nAlso, important is my case (Fractal Design North), there are maximum 355 mm (almost 14 inch) length for the GPU in it.\n\n[https://www.galaxus.de/de/s1/product/msi-geforce-rtx-4090-gaming-x-trio-24g-24-gb-grafikkarte-22534974?supplier=2705624](https://www.galaxus.de/de/s1/product/msi-geforce-rtx-4090-gaming-x-trio-24g-24-gb-grafikkarte-22534974?supplier=2705624)\n\n[https://www.galaxus.de/de/s1/product/palit-geforce-rtx-4090-gamerock-oc-24-gb-grafikkarte-23188710?supplier=2705624](https://www.galaxus.de/de/s1/product/palit-geforce-rtx-4090-gamerock-oc-24-gb-grafikkarte-23188710?supplier=2705624)\n\n[https://www.galaxus.de/de/s1/product/gainward-rtx-4090-phantom-gs-24-gb-grafikkarte-22671040?supplier=2705624](https://www.galaxus.de/de/s1/product/gainward-rtx-4090-phantom-gs-24-gb-grafikkarte-22671040?supplier=2705624)\n\n[https://www.galaxus.de/de/s1/product/kfa2-geforce-rtx4090-24-gb-grafikkarte-23599748?supplier=2705624](https://www.galaxus.de/de/s1/product/kfa2-geforce-rtx4090-24-gb-grafikkarte-23599748?supplier=2705624)\n\n[MSI GeForce RTX 4090 Ventus 3X OC (24 GB) - kaufen bei Galaxus](https://www.galaxus.de/de/s1/product/msi-geforce-rtx-4090-ventus-3x-oc-24-gb-grafikkarte-22983714)\n\n[PNY GeForce RTX 4090 Gaming Verto (24 GB) - kaufen bei Galaxus](https://www.galaxus.de/de/s1/product/pny-geforce-rtx-4090-gaming-verto-24-gb-grafikkarte-22610459)\n\nThank you!\n\nPS: My remaining hardware, if relevant:\n\nRyzen 7800X3D32GB DDR5 6000Mhz CL 30 RAMMSI MEG X670E Tomahawkbe quiet! Straight Power 12 Platinum 1000 W PSUMy 4k monitor has Freesync Premium Pro, so it's not a problem with an nvidia GPU, right? It's the Gigabyte M28U.",
    "comments": [
      "As always: go for the cheapest one you can find in stock.",
      "You really can't go wrong with 4090, as they all have beefy coolers. However, AFAIK, gaming x trio is the best among the gpus you've listed.",
      "I have a gigabyte gaming oc. No coil whine, I guess if you get one with whine just send it back",
      "Honestly go for the cheapest that will fit. There’s so little difference between them",
      "MSI has very good build quality normally, but the gaming x trio is one of the few 4090s that has no vapor chamber, so if you are really looking at optimal cooling, this might not be the one for you",
      "I am afraid of Coil whine :(   \nMy old MSI 1070 had it, it was awful.",
      "Hey there, out of the mentioned GPU‘s, I would choose the KFA2 Version (600w Power limit just like FE and good cooler) - however I went with the Gamerock OC and I‘m very happy with it. No coil whine, and overall quiet even under heavy load. MSI cheaped out on the cooling and only offer a Vapor chamber with their supreme cards.\n\nBtw. If you are concerned about the dimensions go with the palit card as it is one of the smallest 4090‘s out there.",
      "Go with the PNY, has a vapor chamber and good cooler. \n\nThe MSI models do not have a vapor chamber and run warmer because of that. \n\nCan’t speak to the other brands.",
      "Hmm, I def wouldn’t change video cards intra-gen like that but I get feeling like you made a misstep. For 4k you absolutely need upscaling and fsr just ain’t it so I get the feeling that you’d want DLSS instead",
      "Zotac is fine.",
      "PNY 4090 XLR8 should give you the best chance at low coil whine",
      "I bought the zotac trinity oc because it was white and the only other white option was a strix for £350 more and that wasn’t happening.\nApparently the zotac is the worst of the lot but mines hitting a +250 oc and doing it without making any real noise. Haven’t really obsessed over the temps but they’re low, high 50’s whenever I’ve looked and I’m maxing it at 4k. I’m not going to bother watercooling it like I have with my previous cards.",
      "If 4k144 with max settings is your goal, you're gonna have to return that XTX. That's definitely 4090 territory. As far as which model, that's the easy part. Theres only 3 things that are meaningful in that equation. Price, quality of warranty coverage, and whether its power locked. Go with the cheapest model that has a good history of warranty service, and if overclocking and squeezing every last drop of performance is important to you, make sure it's not a power locked model. By that, I mean you can't increase the power limit beyond 100%. Stock limit is 450w, overclocked models can go well beyond that.\n\nI guess a 4th thing could be fan noise, but the coolers are all overbuilt this gen so I'd be surprised if it went above 65°C in normal use. You're probably never going to hear the GPU fans above the ambient noise of everything else, but some people are particular about it.",
      "Thanks.\n\nAs far as i know, the GameRock and Gainward are identical, they also have the exact dimensions and price. I hardly consider the Gainward (i don't like the shiny GameRock). The KFA2 could be a bit hard to fit in",
      "Galaxus states that the OC (Kaleideskop Edition) needs 1200W PSU, the non OC version 1000W, do you think it's really like that? I don't plan to send my PSU back and get one with 1200+. Or should i play it safe and just get the non OC edition?",
      "SUPRIM X triple fan is literally silent I love mine",
      "Don't worry, 1000W is far enough. When my GameRock OC was here it just drew about 430W mostly. If you do not OC your GPU/CPU heavily then it really is no concern.   \nAlso I would suggest undervolting your card when it arrives, or at least Powerlimit it. It nearly costs no FPS and saves you about 100W easily. I made an undervolt and reduced my FPS by about 6-8 FPS for \"just\" a regular power-consumption of 200-280Watts.",
      "My Gigabyte gaming oc 4090 is fantastic. So quiet, even under load, no coil whine, barely gets hot. Great card.",
      "Can confirm. I've never heard a peep from my gaming oc. Been playing cp2077 on just about max settings for the past two weeks as well. Card usually sits around 65c. Just amazing.",
      "This"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "top",
    "matched_keywords": [
      "4090",
      "rtx4090"
    ],
    "title": "Looking for proper specs for a Workstation to train AI models at high processing speeds",
    "selftext": "Hi,\n    At our AI startup we are looking to offload our AI training and computing tasks from AWS to a local machine. \nHere are some of the tasks we need to process\n1. Run Whisper Large offline for Speech to Text\n2. Run algorithms for healthcare applications like prediction models\n3. Run an backend application to send data continuously to multiple frontend devices\n\nSo based on this requirement, we have shortlisted the following configuration:\n\n1. RTX3090(value for money) or 4090\n2. ⁠NVLink Bridge with either 2 or 3 slot depending on the card\n3. ⁠Motherboard that supports PCle 8 lane split\n4. ⁠ATLEAST 24GB VRAM\n5. ⁠The latest 5090 with 32GB would be preferred\n\nNow, we are confused on whether the ADA5000 or ADA6000 series would be more appropriate than RTX4090 or RTX5090 since we have been seeing that ADA series are more preferred than RTX for specifically AI workloads, but the benchmarking of RTX series seems to be way better.\n\nPlease weigh in your thoughts on this, whether the configuration above seems sufficient for our workload and any suitable links for buying and building our workstation. Thank you!",
    "comments": [
      "You would think the literal AI company would know about this lol",
      "Asking this on Reddit is something only an AI in its infancy would do. Newborn babies know better and in fact make up half this sub.",
      "I would suggest giving up on your dream to help everyone else lose their jobs and work at McDonalds instead",
      "This isn’t the sub for this question. You need to post in one of the ai subs. \nIn any case, any serious AI should be done on cloud. You need to setup different servers for systems like these, not to mention redundancy, privacy and disaster recovery concerns. You put all this stuff in a single local machine, with little to no protections and you’re in for a world of hurt.\n\nIf you insist, RTX xx90 would be best but that’s because it’s a consumer card designed to be used in standalone cases. Your use case should not even consider standalone stuff."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "top",
    "matched_keywords": [
      "rtx 4090",
      "4090",
      "rtx4090"
    ],
    "title": "What are realistic price drop expectations for rtx4090?",
    "selftext": "The rtx 50 series have just been announced for release at the end of january, what price drop expectations can we expect from the predecessor rtx 4090?",
    "comments": [
      "New? Prices won't probably change. Used on marketplace? They will follow the market, so. It depends on rarity. Might still be very pricey.",
      "Not much. I expect the 5090 prices to be inflated by vendors, and not make a significant impact on the 4090 prices as a result.",
      "probably makes more sense to buy the new rtx 50 series since it'll be cheaper and faster. i'm trying to find out how to buy them before they're sold out",
      "4080s sellin for $900 on ebay already",
      "New? 0.\nUsed? Maybe less than a 5080.",
      "Yea is there actually a way to get your hands on one, considering everythings swarmed with bots nowadays?",
      "some stores are first come first serve like microcenter, check their social media and email blasts. \n\nsome people are buying rtx 4090 on facebook to resell when this the 50 series are out of stock. Maybe put out that you're looking to buy and your friends/family know someone.\n\nand to answer you, nvidia doesn't drop prices often, and when they do, it's equivalent in price/performance with the new item (which is better)",
      "Oh I don't think I have a microcenter, your from US I assume, I'm from EU"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "top",
    "matched_keywords": [
      "rtx 4090",
      "4090"
    ],
    "title": "RTX 4090 dies under warranty, won't replace it, what now?",
    "selftext": "[Resolved]\n\nSo, I bought an MSI RTX 4090 Gaming X Trio about 2 years ago, brand new, from MSI's Official Amazon pgae. My GPU has been working and being used correctly, (high quality PSU, no overclocking, ect.) Then about 2 months ago I had a serious problem and my GPU would spin up my fans to the max while my monitors lost connection but I'd hear sound.\n\n Long story short, after spending hours of my time diagnosing the issue and trying to resolve it, it was for sure the GPU at fault, so I paid $120 to have it shipped all the way to Sacramento to get it fixed, including the power cable. I got it back about a month later and put it in my pc and had the same problem within hours after they sent it back to me, put it in my Wife's computer and same issue. \n\nI called customer service back and told them of the issue, got it sent out about 2 weeks ago, and just got an email stating that it was unrepairable and not replaceable. They offered me some money back,  but not much, and said it wasn't going to be the $1,750 I paid for it because their \"3 Year warranty\" isn't actually a warranty, it's only prorated.\n\nSo, now I'm completely lost on what to do. I don't have the money I did two years ago when I was able to buy this card, and I figured it would last at least until the warranty was up (I've have Nvida and AMD cards for numerous years, and never once had a hardware issue with any of them). So what should I do? I can't get another 4090 as they are over $2,000 on the used market right now, and can't get the only card in the world that's better than it (5090) for obvious reasons. Even the 5080 is far worse than the 4090 and I'd still have to pay extra just to get that downgrade If I was even able to find one. I'm sitting here numb, at a loss. Is there any wisdom or help you guys could provide? Thank you very much.\n\n[Edit] \n\n- I just filed a compaint aginst MSI on BBB and FTC (heard back from only the BBB)\n- I also contacted the MSI spokesperson and emailed them requiring a replacement or upgrade (see resolution)\n- I also emailed Gamers Nexus like you all said. (no reply)\n\n[Resolution]\n\nSo, after a good couple of days after I made this post, MSI finally resolved my issue (as much as you can expect them too). About a day after I filed multiple of those compaints, they responded with: \"The RMA is unable to repair your card which is why we are asking if you are okay with the refund.\nPlease kindly share me a copy of your initial component purchase and I will check with RMA Dept if able to process item price refund. Thanks.\" \n\nAfter that, I sent them my recipt they asked for and I specified that I'd much rather a replacement 4090, but if that was not able to be done (it has been out of production for a few months) then I'd accept a 5080 or 5090. They then waited some more time before responding. The next time they responded was in response to the BBB contacting them and asking for a resolution, in the resolution they stated they already offered a full refund that I did not accept (They offered me hundreds of dollars less than a \"Full Refund\"). I then see in an email from the MSI spokesperson that they are going to: \"We will refund you $1748.99 as we do not have an equivalent replacements to offer\". \n\nSo, with that being said, I'll take that offer of a full refund, as that is what I paid 2 years ago. I spoke to multiple people at different times who told me that they had ZERO 5080s or 5090s in stock. Since, this resolution is more expensive than sending me a 5080, I'm inclined to think they are at least out of 5080s. This isn't the resolution I wanted, but it's good enough, as I'm tired of this fighting which isn't face-to-face, just screen-to-screen. I'd rather just have a 4090 back, but it looks like I'll be buying something different now. Likely getting an RTX 5080 with that money, or an RX 7900 XTX. They have somewhat similar FPS in most games and the prices are less than what I paid for my RTX 4090. Thank you all for the help and wisdom!",
    "comments": [
      "\"isn't actually a warranty\" is an outrageous statement given they explicitly list it as a warranty and the warranty length on their own store.\n\nYou live in the United States, they are legally required to make you whole. \n\nIn this case that means either a refund for the original purchase price or a functioning product of equal value.  It's common for MSI to play these games where they'll offer you a lower end product or less money that what you are entitled to.  If you accept those offers, you agree to taking less than you could have gotten.\n\nLet them know you are entitled to be made whole and may else wise be forced to take legal action.  Post this on other social media to put pressure on them to make it right.\n\nAll else fails, if your account of the story is correct, this is an extremely easily win in small claims court.  You will likely win by default given the cost to pay someone to travel and lodge in your state likely exceeds the value of the replacement.\n\nThe other comments in this thread telling you to just move on and buy a different card are capitulary.  All the big AIBs do this nonsense and just giving up encourages them to do this more.  Taking them to task will make them reconsider screwing their customers monetarily.",
      "Gamers Nexus has an inbox. And they are already on the MSI hate list, so there's no love lost in case it turns out that MSI should have responded more favourable here.\n\nThey might at least have some arguments to consider and/or write to MSI. Or maybe some local consumer advocate groups are in their list.",
      "Please listen to this poster. Tell them you will not settle for whatever garbage they are offering. Assuming your story is correct and there was nothing you did to prematurely shorten the life of the card.. MAKE THEM make it right. If they still refuse, file it in small claims court. If they don't have any 4090's to replace it with, tell them to send you a shiny new 5090 instead. I would not settle for less than a 5080.",
      "Gamers Nexus is crucial in dealing with these issues. Intel went non verbal after confirming that: 1. My cpu was defective (14900kf) and 2. That I had selected fast swap. After a month of no response, two days after emailing Gamers Nexus a manager replied to my ticket offering 100% refund via cheque.",
      "Why would you even settle for a 5080? It's objectively worse than a 4090 at stock.\n\nGet a direct replacement or an upgrade only.",
      "Tech Jesus literally saving gamers 🙏",
      "It's times like this that we miss EVGA....",
      "this comment should be moved to the top",
      "Yea luckily with a 4090 you can make the VRAM argument, which is just about rock solid as it comes. “I need at least 24gb of vram”… that’s another 4090 or a 5090.",
      "https://consumer.ftc.gov/articles/warranties",
      "GN would have a field day of them saying their warranty is not actually a warranty.",
      "Manguson Moss warranty act covers you under implied warranty by law, regardless of what they say.\n\nWhen I've ran into any warranty issues in the past, I've dropped that on them and they've capitulated. \n\n>**Sellers of consumer products who make service contracts on their products are prohibited under the act from disclaiming or limiting implied warranties**. Sellers who extend written warranties on consumer products cannot disclaim implied warranties, regardless of whether they make service contracts on their products.\n\n>",
      "https://preview.redd.it/logm41go5gwe1.jpeg?width=1897&format=pjpg&auto=webp&s=884958a5834c6ef2c39b52222aae848fb115f816\n\nHe healed Kingpin once",
      "They replaced my 1080ti a couple months out of warranty, they saw this coming a mile away.",
      "Agreed, I'm not seeing anything that indicates it's prorated on their website: [https://us.msi.com/page/warranty](https://us.msi.com/page/warranty)\n\nThe first part of that page is crazy though:\n\n\"The warranty term differs from one region to another. If you would like to verify the warranty term of the product bought, please kindly contact our local offices.\"\n\nThey don't disclose said extra terms and they don't even provide a number to call (easy to implement a region selector that provides the correct number) or link to where the person could even further inquire about them.\n\nThe thing is, under the Magnuson-Moss Warranty Act, companies are required to clearly and reasonably disclose these terms to customers.  They are impeding customers from learning about these said full terms in three ways:\n\n1. They don't disclose them online or at the place of sale.\n2. They require you to call in to learn full terms.\n3. They don't even provide the number for said full terms (at least not where one would reasonable expect it).\n\nIt's beyond shady that they are hiding warranty terms to such a degree.\n\nI will note though that Gigabyte's warrant IS prorated (but at least they provide the full terms FFS):  \"If a Product is near the end of a given warranty period and a repair/replacement is not possible, GIGABYTE reserves the right to offer an alternative of equal or greater value or a partial refund proportional to the remaining warranty life of the Product.\"\n\nI'm not sure when this trend started or if other companies are doing it but consumers should push back against it.  Prorated warranties make no sense for GPUs.  GPUs are not consumable products that quickly burn through their life in the mere 3 year warranty period.  Most of my GPUs last 10+ years.  GPUs are far too expensive and this is clearly a move to push customers to buy more often.  God i miss EVGA, screw these big corpa AIBs.",
      "Are you always using the same power cable with it? I was having that exact same problem with my Suprim 4090 and it turned out to be the cablemod 12VPWR. I put the squid adapter on the pcie cables for my PSU and the problem was gone.",
      "The more this guy, the more you save. ❤️",
      "A \"pro-rated\" warranty?!?\n\nSo, you buy a product with a 3 year warranty, and it fails on the last day WITHIN the warranty period, and you're only due ~0.1% of the purchase price in refund?\n\nThat's not a 3 year warranty. At all.",
      "By all measurable metric the 5080 is slower and less capable than the 4090.",
      "Ask the rep to point you to where it says that their warranty is prorated in any of their TOS. I'd first, absolutely demand to see that in writing, and not as of today, as of the day you bought it (lord knows Nvidia LOVES to change their TOS). If they can produce that, you're pretty much SOL and need to just accept what they give you, but if they can't, I'd threaten BBB and small claims court. Also, make sure you're speaking with a supervisor"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "top",
    "matched_keywords": [
      "rtx 4090",
      "4090"
    ],
    "title": "RTX 4090 Adapter burned",
    "selftext": "",
    "comments": [
      "Maybe you plugged in/out 31 times :⁠^⁠)",
      "Gamers Nexus would like to know your location",
      "Hope NVIDIA and its AIB are ready to honor their warranty for stuff like this for next 3-5 years ;s",
      "I dont know why it happened. I think my adapter cable is faulty. Welp i guess RMA it is\nEDIT\nCard was attached vertically. Bend was not that aggressive. Sure there was bend still this should not happen on a 2k Euro gpu PSU Corsair rmx 1000",
      "Hey u/reggie_gakil  I just sent you a direct message. Please take a look, thank you.",
      "You aren't the only one. This happened to me today as well, not as badly burned as your though. I was having a gaming session few hours ago, playing Black Desert with my dungeon party. All the sudden the screen went black and all the fans started spinning at 100%. Powered off the machine and after some inspection noticed that the power adapter was damaged. \n\nMy card is Asus RTX 4090 TUF Gaming - OC Edition\n\n&#x200B;\n\n[https://cdn.discordapp.com/attachments/1023507386805256192/1034182353741938788/rtx4090\\_poweradapter.jpeg](https://cdn.discordapp.com/attachments/1023507386805256192/1034182353741938788/rtx4090_poweradapter.jpeg)",
      "once you got your replacement card, reach out to us and we will send you a free PCIE cable to help you out a little bit!",
      "\"Back to you Steve\"",
      "Plenty of cable relief on that, possibly a defect",
      "[https://cdn.discordapp.com/attachments/513140358729957378/1032633584877576192/unknown.png](https://cdn.discordapp.com/attachments/513140358729957378/1032633584877576192/unknown.png)",
      "\"thanks Steve\"",
      "There’s gonna be a lot of melted connectors",
      "I bet they will just say it is user error.",
      "that was the setup",
      "Don't bend vertically nor horizontally. If that's the case don't give us a flexible cable to begin with.",
      "You think 5000 series is going to be cheaper? Nope.",
      "There are no fucking excuses. For a card that costs €2,000, the connector should be deep space mining grade. Of any other material except crappy plastic.\n\nPlease guys, stop justifying crappy business practices that only hurt the consumer, and encourage future graphics cards to be even more expensive with worse materials.\n\nI wish you good luck with the RMA process.\n\nEdit: changed military grade.",
      "Didn't Jayz2Centz warn about this?",
      "The problem could be the direction of the bend, see https://cablemod.com/12vhpwr/",
      "\"On this week's episode of Gamers Nexus.\""
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "top",
    "matched_keywords": [
      "4090",
      "rtx4090"
    ],
    "title": "Asus Strix and Strix OC clock speeds are listed now",
    "selftext": "TLDR - +$400 gets you +140mhz boost clock\n\nStrix - 2550Mhz\nhttps://rog.asus.com/graphics-cards/graphics-cards/rog-strix/rog-strix-rtx4090-24g-gaming-model/spec/\n\nStrix OC - 2640Mhz\nhttps://rog.asus.com/graphics-cards/graphics-cards/rog-strix/rog-strix-rtx4090-o24g-gaming-model/spec/\n\n4090 FE - 2500Mhz\nhttps://www.techpowerup.com/gpu-specs/geforce-rtx-4090.c3889",
    "comments": [
      "Boost clockspeeds dont really matter anyway because the cards will automatically overboost via GPU Boost if they have enough temperature headroom. \n\nThe appeal of higher end AIBs is more the potential power delivery (and those 70A Power Stages are very overkill anyway) and the cooling to have more overclock headroom.",
      "Lol Asus can smd",
      "I would pay 100-150 dollar more for a better cooler.\n\nNever 400 dollar.",
      "Pretty much. 400+ dollars for essentially minuscule difference in performance. The rest is just features like the BIOS switch and the cooler. Which is so damn huge this time around that the card won’t even fit inside a larger mid tower case. \n\nThe Founders Edition looks better and better every time I read up on these new cards.",
      "Still a joke of a price premium.",
      "Wtf just get the suprim liquid.",
      "Absolutely no cooler is worth that much over MSRP unless it comes with a water block.",
      "Ugh... the strix tax doesn't even apply to how your treated for any warranty issued with strix products. Either nit in stock or 3+ weeks for an advanced RMA.",
      ">TLDR - +$400 gets you +140mhz boost clock\r  \n\r\n\nAnd a much better cooler with less noise.",
      "do you have a link to that tweet?",
      "If you've ever bought a modern graphics card, you'd know rated clockspeeds on Nvidia cards mean nothing.\n\nActual clock potential will depend on silicon quality and how robust the graphics card and cooling setup is.\n\nBut really, a lot of the point in buying a higher end model is reduced noise and obviously just running cool, rather than any large increase in performance.\n\nI'm not saying it's a good deal, it's not, but these are never good value in terms of what kind of actual performance uplifts you get from them.  That's been the case for a long time.",
      "Easiest choice. It’ll perform better and cheaper.",
      "I found it, it was in the wccftech comment section but got deleted\n\nhttps://www.computerbase.de/forum/attachments/screenshot-20221004-135130-jpg.1266965/",
      "The guy from WCCFTECH go he's to 3.1ghz on air (didn't mentioned the fan speed tought) so they boost quite high He said on Twitter 3.1ghz, 509W peak, 61C",
      "Any word on TUF ones?Likely the TUF non-OC edition will be same as FE. Not sure about OC edition. If the difference is only 50 mhz, then probably not worth it. Of course, overclocking potential is another thing but I don't expect too much perf difference even with overclocking.Edit:\n\nASUS tuf OC edition (1799):\n\nOC mode: 2595 MHz\n\nGaming mode: 2565 MHz (Boost Clock)\n\nAsus TUF non-OC edition(1599):\n\nOC mode: 2550 MHz\n\nGaming mode: 2520 MHz (Boost Clock)",
      "I really want that one, but being an AIO makes it less tempting.  I haven't really heard of any horror stories with AIO GPUs, but they aren't as popular as CPU coolers.",
      "MSI 4090 Suprim X (air cooler)",
      "I’ve owned a couple. Never any issues and they are very quiet and cool. Not sure about msi since I’ve only ever had evga though.",
      "So $2K for slightly over 100mhz on the core? That's some bullshit.",
      "If you want an OptimusPC waterblock, you've already decided to get the Strix/TUF cards\n\nPersonally, I pay the Strix tax for looks, better power delivery, and better cooling. I've never had a bad experience with a Strix card and they're over engineered to the point that you'd have to really do something stupid to kill one.\n\nPerformance wise, though, the Strix hasn't been worth it since 10xx series.\n\nThis year, I'll probably still get Strix, if I can, from habit if nothing else, but the TUF is looking tempting.\n\nIf you don't care about OptimusPC, I think most people should get the FE"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "top",
    "matched_keywords": [
      "rtx 4090",
      "4090",
      "rtx4090"
    ],
    "title": "12VHPWR cables, new Seasonic power supplies and RTX4090s",
    "selftext": "If anyone else got or ordered a new Seasonic power supply recently, you might've noticed they are shipping (or you can order one for free) new 12VHPWR cables.\n\nThese, unlike the ones that comes in the RTX4090 boxes (that have 3-4) have only two PCI-E plugs at the end. I was somewhat concerned, whether the 2 plugs would be enough so I e-mailed their support about it, and this is what they told me:\n\n> Our 12VHPWR is intended to power to be used without any problem with a RTX 4090. It's made of 16AWG wires and High Current Terminal in order to handle the load. So, you won't need the NVIDIA adapter provided.\n\nso TL;DR; 12VHPWR cables in new Seasonic PSUs are good, use them",
    "comments": [
      "Almost every PCIE cable(single) in the market can carry 300+W\n\nSo two cables can manage 600W without any issue",
      "Lol no. Your comment is completely false. \n\nThat \"PCIE 150W limit\" is for the hardware that draws power from the cable. PCIE standard says that a single PCIE port of a device can draw 150W at max. This is nothing to do with power supply nor power cables. \n\n\nAlmost every power cable in the market is 16 AWG, which can carry 468 watts at 12 volts. So 2 PCIE power cables can carry up to 936 watts in total. 600W is nothing compared to this capacity. Every PSU brand(afaik) ships their PCIE cables with 2 heads, this is why. There isn't any problem nor risk to do that. \n\n\nIn addition to that, if you didn't notice new 12VHPWR cables for modular ATX 2.0 PSUs from brands(Corsair, Seasonic etc.) are all using 2 PCIE ports to feed a single 12VHPWR port. \n\n\nBy the way, ATX 3.0 sense pins(additional little 4 pins on 12VHPWR port) is nothing to do with \"drawing more power\" from the PSU that you've mentioned. It is a totally different thing.",
      "I was about to grab the EVGA cable for my power supply but hesitated when I saw it only has two eight pin connectors as well. This makes me a little less concerned.",
      "For those that may be reading this and thinking \"Oh no my connector will not work...\"\n\nI just received an email from Seasonic:\n\n>Thank you for contacting Seasonic.  \n>  \n>The 12VHPWR cable provided with our PRIME PX and TX is a 600W version.  \n>  \n>Any other question, please let us know.  \n>  \n>Thank you.\n\n&#x200B;\n\nYou can see further video evidence here on JayzTwoCents\n\n[https://www.youtube.com/watch?v=dbT84gxKnMA](https://www.youtube.com/watch?v=dbT84gxKnMA)",
      "I am personally using the SilverStone HELA 850R with my RTX 4090 and can confirm it comes with a 12VHPWR cable.",
      "I just bought one, haven't installed it yet since I still gotta buy a 4090 hopefully tomorrow at 8:00AM CT",
      "if it's PCIE-5 certified, then yeah - that should be good.",
      "2 regular + 1 split should not be a problem",
      "What are you confused by exactly? Happy to help clear up any confusion. :)",
      "How do you order one for free? I got my seasonic about a year ago. So it didn't come with that cable.",
      "I filled out the form for a cable but I’m wondering if I should order from cable mod also I’m concerned about only 2 8 pin",
      "Its safe to use seasonic 12VHPWR instead of nvidias adapter? It will not burn or melting?",
      "Has anyone received one of the free ones from Seasonic yet? I am dying to put this 4090 to good use",
      "I have a Phanteks Amp 1000 (which afaik is a essentially just a rebranded Seasonic). \n\nI don't mind having to pay for the Cable, but could i use that Seasonic adapter as well? I'm hoping this way it's only using up 2 of my 8pin conections rather than 3.  It appears in the other comments that those 8pin ports can supply upwards of 600w so it should be safe? \n\n[https://phanteks.com/Amp-Series.html](https://phanteks.com/Amp-Series.html) is the PSU in question. \n\nlet me know wha ya'll think",
      "Looking at [https://seasonic.com/12vhpwr-cable](https://seasonic.com/12vhpwr-cable)  \nWhy is this cable only compatible with 850w and above PSU? with a low wattage CPU I have a 4090 on a TX750 quite happily, but I'd like to get away from the 4 plug dongle adaptor.",
      "Can i use this with any brands?",
      "Can i use with Focus PX 850w or need GX 1000 or Prime?",
      "Right here!  :)\n\nhttps://seasonic.com/cable-request/",
      "I mean, it hasn't for me so far :D",
      "How are you connected to the PSU on a 750W PSU? As far as I know only 850W PSUs and up have 4 open 8-pin slots plus 1 8-pin for the CPU."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "top",
    "matched_keywords": [
      "rtx 4090",
      "4090"
    ],
    "title": "NVIDIA GeForce RTX 5090 reportedly targets 600W, RTX 5080 aims for 400W with 10% performance increase over RTX 4090 - VideoCardz.com",
    "selftext": "",
    "comments": [
      "Oh these prices are about to HURT hurt huh. inb4 $1399 5080, $1999 5090.",
      "<Pets 1080ti> Hang in there, old friend.",
      "They learned. They learned that their greedy ass can get away with overpriced GPUs, because they know people will still buy. If only AMD were competing in this bracket they would carefully price their cards.",
      "Seeing how they significantly dropped the price of the 4080S vs the 4080 shows they knew they over priced the 4080. I hope they learned from this, they have found the ceiling for an 80 tier gpu.",
      "Are people forgetting that the 70 class always matched the previous gen’s flagship? What happened to the 1070=980ti or the 3070 being the 2080ti. It’s not like it was a long time ago. Just recently nvidia decided to be extra freakin greedy and people are forgetting this.",
      "![gif](giphy|fXnRObM8Q0RkOmR5nf)\n\nNvidia",
      "We had identical power usage rumors before last gen that were completely false.",
      "If the 5080 comes in 10% above the 4090 that would make it a ~100% upgrade over my 3080 (4090 is 87% per techpowerup), which is my personal threshold for considering an upgrade worthwhile. So that's good. \n\nIf it comes in at that performance and costs <=$1000 I'll probably get one, particularly if Nvidia announces new tech limited to the 50-series like framegen was on the 40s. Not happy about the 400w, though.",
      "Here's hoping my 1000w platinum PSU will be enough for the 5090.",
      "The people willing to spend over a thousand bucks on a graphics card but not the top of the line model is pretty limited.  \n\nIf you’re in for a $2500 build, why not spend $3000 for the very best?  \n\nIf you’re trying to get price/performance, why not spend 1500 or less with one gen old parts? \n\nThat’s the problem of the 4080. Minimal target market.  \n\nDon’t forget that the 4070ti was intended to be the entry level 4080, they just rebranded it before release when everyone cried about two very different 4080 versions.",
      "Well their actions strongly suggest the 4080 didn’t sell in the numbers they had hoped",
      "I'm so starved for info on the 50 series lol. i just click on anything about it even if it's a rumour.",
      "If it costs less than $1200 at launch I’ll genuinely be shocked. If I can actually find one for less than $1500 I’ll be even moreso.",
      "Please be affordable, please be available..",
      "To be fair the flagships are fairly inconsistent from generation to generation.\nAccording to techpowerup the 980 Ti was 31% faster compared to the 970 while the 4090 is 99% faster than the 4070. \n\nSo in one case the 1070 case the 70->70 improvement was roughly 31% (it actually was 47) but to bear the 4090 you would need literally more than twice the performance.",
      "At that point it’s earned the right to be there.",
      "I’m still rocking a 1070.  At this point I’m just gonna use it until it dies.",
      "Checkin in as guy who bought 980, 1080, 2080, and was eyeing the 4080s before deciding to wait… \n\nI’m someone who likes high-end performance, but I also keep price:performance ratio in mind.  I didn’t want to pay an extra 50% cost for 20% gains when the 80 is already getting me very high FPS, mixed with issues from higher-tier cards (3080ti failure rate, 4090 melting, etc.).  So that’s the mindset of someone in that market.",
      "THE MORE YOU BUY THE MORE YOU SAVE",
      "If this card comes at less that 1000 availability will be null for the next year lol.\nBut most likely it will not, it will probably cost 1300 or something like that (so it will be not available for 6 months)"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "top",
    "matched_keywords": [
      "rtx 4090",
      "4090"
    ],
    "title": "[Megathread] GeForce at CES 2025 - GeForce RTX 50 Series GPUs & Laptops, DLSS 4, Reflex 2, Project G-Assist, NVIDIA ACE, and more",
    "selftext": "https://preview.redd.it/5sb22vtbyhbe1.jpg?width=1600&format=pjpg&auto=webp&s=3b411b7b446ac5e8163c0416f1372b03e218936c\n\nHello everyone! Below, you’ll find all of the NVIDIA GeForce announcements from CES 2025. We hope you enjoyed the keynote. You can [watch a recap of the keynote here](https://www.youtube.com/watch?v=k82RwXqZHY8), or get the tl;dr for GeForce below. For detailed information, be sure to read through the articles, and watch the explainer videos.\n\n# GeForce RTX 50 Series\n\nMultiply performance by up to 8X using DLSS 4 with Multi Frame Generation, reduce PC latency by up to 75% with Reflex 2, and experience next-generation RTX Neural Rendering.\n\n|Specs|GeForce RTX 5090|GeForce RTX 5080|GeForce RTX 5070 Ti|GeForce RTX 5070|\n|:-|:-|:-|:-|:-|\n|**GPU**|GB202|GB203|GB203|GB205|\n|**Transistor Count**|92.2 Billion|45.6 Billion|45.6 Billion|31.1 Billion|\n|**Die Size**|750 mm^(2)|378 mm^(2)|378 mm^(2)|263 mm^(2)|\n|**GPC**|11|7|7|5|\n|**TPC**|85|42|35|24|\n|**CUDA Cores**|21760 Cores (170 SM)|10752 Cores (84 SM)|8960 Cores (70 SM)|6144 Cores (48 SM)|\n|**Tensor Cores (AI)**|680 5th Generation 3352 AI TOPS|336 5th Generation 1801 AI TOPS|280 5th Generation 1406 AI TOPS|192 5th Generation 988 AI TOPS|\n|**Ray Tracing Cores**|170 4th Generation 318 TFLOPS|84 4th Generation 171 TFLOPS|70 4th Generation 133 TFLOPS|48 4th Generation 94 TFLOPS|\n|**ROPs**|176|112|96|80|\n|**Texture Units**|680|336|280|192|\n|**L2 Cache**|96 MB|64 MB|48 MB|48 MB|\n|**Boost Clock**|2.41 Ghz|2.62 Ghz|2.45 Ghz|2.51 Ghz|\n|**Base Clock**|2.01 Ghz|2.3 Ghz|2.3 Ghz|2.16 Ghz|\n|**Standard Memory Config**|32 GB GDDR7|16 GB GDDR7|16 GB GDDR7|12 GB GDDR7|\n|**Memory Interface Width**|512-bit|256-bit|256-bit|192-bit|\n|**VRAM Speed**|28 Gbps|30 Gbps|28 Gbps|28 Gbps|\n|**Memory Bandwidth**|1792 GB/s|960 GB/s|896 GB/s|672 GB/s|\n|**Displayport**|DisplayPort 2.1b with UHBR20: up to 4K 480Hz or 8K 165Hz with DSC|DisplayPort 2.1b with UHBR20: up to 4K 480Hz or 8K 165Hz with DSC|DisplayPort 2.1b with UHBR20: up to 4K 480Hz or 8K 165Hz with DSC|DisplayPort 2.1b with UHBR20: up to 4K 480Hz or 8K 165Hz with DSC|\n|**HDMI**|HDMI 2.1b: up to 4K 480Hz or 8K 120Hz with DSC, Gaming VRR, HDR|HDMI 2.1b: up to 4K 480Hz or 8K 120Hz with DSC, Gaming VRR, HDR|HDMI 2.1b: up to 4K 480Hz or 8K 120Hz with DSC, Gaming VRR, HDR|HDMI 2.1b: up to 4K 480Hz or 8K 120Hz with DSC, Gaming VRR, HDR|\n|**Video Engine**|3x NVENC (9th Gen) / 2x NVDEC (6th Gen)|2x NVENC (9th Gen) / 2x NVDEC (6th Gen)|2x NVENC (9th Gen) / 1x NVDEC (6th Gen)|1x NVENC (9th Gen) / 1x NVDEC (6th Gen)|\n|**Total Graphics Power**|575 W|360 W|300 W|250 W|\n|**Required System Power**|1000 W|850 W|750 W|650 W|\n|**Required Power Connectors**|4x PCIe 8-pin cables (adapter in box) OR 1x 600 W PCIe Gen 5 cable|3x PCIe 8-pin cables (adapter in box) OR 1x 450 W or greater PCIe Gen 5 cable|2x PCIe 8-pin cables (adapter in box) OR 300 W or greater PCIe Gen 5 cable|2x PCIe 8-pin cables (adapter in box) OR 300 W or greater PCIe Gen 5 cable|\n|**Founders Edition**|Yes|Yes|No|Yes|\n|**Price**|Starting at $1,999|Starting at $999|Starting at $749|Starting at $549|\n|**Availability**|January 30th|January 30th|February|February|\n\n***Stated Performance Claim***:\n\n**RTX 5090:**\n\n* Thanks to the Blackwell architecture’s innovations and DLSS 4, the GeForce RTX 5090 outperforms the GeForce RTX 4090 by 2X.\n* NVIDIA GeForce RTX 5090 Founders Edition is a 2-slot, 304mm long x 137mm high x 2-slot wide, SFF-Ready Enthusiast GeForce Card.\n\nhttps://preview.redd.it/7s6n96qvg6de1.jpg?width=2580&format=pjpg&auto=webp&s=b391f241fb1cc0d25985b76ab3fdf0955589f30a\n\n**RTX 5080:**\n\n* Up to twice the speed of the GeForce RTX 4080 in games, thanks to the Blackwell architecture and DLSS 4 with Multi Frame Generation.\n\nhttps://preview.redd.it/yz68h9mxg6de1.jpg?width=2580&format=pjpg&auto=webp&s=02b2f4637b5b27e632ad97559294ece5b0120c9d\n\n**RTX 5070 Ti:**\n\n* Using the full capabilities of the Blackwell architecture, and the power of DLSS 4 with Multi Frame Generation, game frame rates are 2X faster than the GeForce RTX 4070 Ti’s.\n\nhttps://preview.redd.it/1v05b7nyg6de1.jpg?width=2580&format=pjpg&auto=webp&s=8890de414ab322bfd4db28d11ad18ad24a07ce50\n\n**RTX 5070:**\n\n* At 2560x1440, with full ray tracing and other settings maxed, and DLSS Multi Frame Generation enabled, GeForce RTX 5070 owners can play Black Myth: Wukong, Alan Wake 2, and Cyberpunk 2077 at high frame rates, with performance that is twice as fast on average compared to the GeForce RTX 4070.\n\nhttps://preview.redd.it/m4wya0a0h6de1.jpg?width=2580&format=pjpg&auto=webp&s=00fe354dd86f43a1aed9b4d240dddc95fd7351c4\n\n# RTX 50 Series Laptops\n\n* Starting in March, GeForce RTX 50 Series comes to laptops. As thin as 14.9mm, GeForce RTX 50 Series laptops boast up to 40% better battery life thanks to new Blackwell Max-Q innovations, and double the performance of previous-generation models.\n* Game with double the FPS. Create content and complete workflows in half the time. And finish generative AI tasks 2.5X faster.\n* GeForce RTX 5090, GeForce RTX 5080, and GeForce RTX 5070 Ti laptops will be available starting in March, followed by GeForce RTX 5070 Laptops in April. There will be designs from the world’s top manufacturers, including Acer, ASUS, Dell, GIGABYTE, HP, Lenovo, MECHREVO, MSI, and Razer. Stay tuned to their websites for further details about the GeForce RTX 50 Series Laptops they’re creating\n\nhttps://preview.redd.it/nrl2bz5o1ibe1.jpg?width=1600&format=pjpg&auto=webp&s=fa9ce5c1daaf4e3309a8fbda3f7beccd796adf0a\n\n# RTX Neural Shaders\n\n* Alongside GeForce RTX 50 Series GPUs, NVIDIA is introducing [RTX Neural Shaders](https://developer.nvidia.com/blog/nvidia-rtx-neural-rendering-introduces-next-era-of-ai-powered-graphics-innovation/), which brings small AI networks into programmable shaders, unlocking film-quality materials, lighting and more in real-time games. \n* Rendering game characters is one of the most challenging tasks in real-time graphics, as people are prone to notice the smallest errors or artifacts in digital humans. [RTX Neural Faces](https://developer.nvidia.com/blog/nvidia-rtx-neural-rendering-introduces-next-era-of-ai-powered-graphics-innovation/) takes a simple rasterized face and 3D pose data as input, and uses generative AI to render a temporally stable, high-quality digital face in real time.  \n* RTX Neural Faces is complemented by new RTX technologies for [ray-traced hair and skin](https://developer.nvidia.com/blog/nvidia-rtx-neural-rendering-introduces-next-era-of-ai-powered-graphics-innovation/). Along with the new [RTX Mega Geometry](https://developer.nvidia.com/blog/nvidia-rtx-neural-rendering-introduces-next-era-of-ai-powered-graphics-innovation/), which enables up to 100x more ray-traced triangles in a scene, these advancements are poised to deliver a massive leap in realism for game characters and environments.  \n* The power of neural rendering, DLSS 4 and the new DLSS transformer model is showcased on GeForce RTX 50 Series GPUs with Zorah, a groundbreaking new technology demo from NVIDIA. \n\n# DLSS 4\n\n**Article Link**: [NVIDIA DLSS 4 Introduces Multi Frame Generation & Enhancements For All DLSS Technologies](https://www.nvidia.com/en-us/geforce/news/dlss4-multi-frame-generation-ai-innovations/)\n\n**Video Link**: [Watch NVIDIA’s Bryan Catanzaro and Edward Liu walk through DLSS 4](https://youtu.be/qQn3bsPNTyI)\n\nDLSS 4 FAQ: [Link Here](https://www.nvidia.com/en-us/geforce/forums/geforce-graphics-cards/5/555374/dlss-4-faq/)\n\n* [75 games and apps will have support](https://www.nvidia.com/en-us/geforce/news/dlss4-multi-frame-generation-ray-tracing-rtx-games) for Multi Frame Generation when they’re released.\n* DLSS 4 also introduces the biggest upgrade to its AI models since the release of DLSS 2.0 in 2020.\n\nhttps://preview.redd.it/0lhwv6q72ibe1.jpg?width=1600&format=pjpg&auto=webp&s=5db40477bd3025099ca17cb278c27064483fc634\n\n* **DLSS Multi Frame Generation** generates up to three additional frames per traditionally rendered frame, working in unison with the complete suite of DLSS technologies to multiply frame rates by up to 8X over traditional brute-force rendering. This massive performance improvement on GeForce RTX 5090 graphics cards unlocks stunning 4K 240 FPS fully ray-traced gaming.\n   * **Video Link**: [*On the GeForce RTX 5090, DLSS 4 with Multi Frame Generation multiplies performance by over 8X versus traditional brute force rendering in this Cyberpunk 2077 scene, PC latency is halved for more responsive gameplay, and image quality is further enhanced*](https://www.youtube.com/watch?v=yWYbqOFyB5Q)\n\nhttps://preview.redd.it/uzdkhzxc2ibe1.jpg?width=1600&format=pjpg&auto=webp&s=a7122bff7530378daf0f4ba84b22e813223178ab\n\n* **Frame Generation** gets an upgrade for GeForce RTX 50 Series and GeForce 40 Series GPUs, boosting performance while reducing VRAM usage.\n* **DLSS Ray Reconstruction, DLSS Super Resolution, and DLAA will now be powered by the graphics industry’s first real-time application of ‘transformers’**, the same advanced architecture powering frontier AI models like ChatGPT, Flux, and Gemini. DLSS transformer models improve image quality with improved temporal stability, less ghosting, and higher detail in motion\n* Alongside the availability of GeForce RTX 50 Series, NVIDIA app users will be able to upgrade games and apps to use these enhancements.\n* And on all GeForce RTX GPUs, DLSS games with Ray Reconstruction, Super Resolution, and DLAA can be upgraded to the new DLSS transformer model.\n* For many games that haven’t updated yet to the latest DLSS models and features, [NVIDIA app](https://www.nvidia.com/en-us/software/nvidia-app/) will enable support through a new DLSS Override feature. Alongside the launch of our GeForce RTX 50 Series GPUs, after installation of a new GeForce Game Ready Driver and the latest NVIDIA app update, the following DLSS override options will be available in the Graphics > Program Settings screen, under “Driver Settings” for each supported title.\n   * **DLSS Override for Frame Generation** \\- Enables Multi Frame Generation for GeForce RTX 50 Series users when Frame Generation is ON in-game.\n   * **DLSS Override for Model Presets** \\- Enables the latest Frame Generation model for GeForce RTX 50 Series and GeForce RTX 40 Series users, and the transformer model for Super Resolution and Ray Reconstruction for all GeForce RTX users, when DLSS is ON in-game.\n   * **DLSS Override for Super Resolution** \\- Sets the internal rendering resolution for DLSS Super Resolution, enabling DLAA or Ultra Performance mode when Super Resolution is ON in-game.\n   * Upgrading and enhancing games takes just a few clicks in NVIDIA app\n\nhttps://preview.redd.it/isew0jx86ibe1.png?width=1840&format=png&auto=webp&s=639462bdc55c8ee578d3051c4f71cbfce0e83ecd\n\n# [DLSS Multi Frame Generation & New RTX Technologies Coming To Black State, DOOM: The Dark Ages, Dune: Awakening, and More. 75 Games and Apps At Launch & More On The Way](https://www.nvidia.com/en-us/geforce/news/dlss4-multi-frame-generation-ray-tracing-rtx-games)\n\n* Multiply performance by up to 8X and experience new cutting-edge NVIDIA RTX ray tracing and AI technologies in Alan Wake 2, Black Myth: Wukong, Indiana Jones and the Great Circle, Marvel Rivals, NARAKA: BLADEPOINT, and many other titles.\n* Alan Wake 2 is also adding RTX Mega Geometry, and an Ultra quality full ray tracing mode.\n* Indiana Jones and the Great Circle is also adding DLSS Ray Reconstruction and RTX Hair.\n* The Witcher IV will feature the latest RTX technologies when released.\n* Even more games and apps are adding [RTX Neural Shader technologies](https://developer.nvidia.com/rtx-kit). Stay tuned for details.\n* **Video Link**: [RTX. It’s On. The Ultimate in Ray Tracing and AI with DLSS 4](https://www.youtube.com/watch?v=M3fglmDxD2U)\n\n# NVIDIA Reflex 2\n\n**Article Link**: [**NVIDIA Reflex 2 With New Frame Warp Technology Reduces Latency In Games By Up To 75%**](https://www.nvidia.com/en-us/geforce/news/reflex-2-even-lower-latency-gameplay-with-frame-warp)\n\n**Video Link:** [Click Here](https://www.youtube.com/watch?v=zpDxo2m6Sko)\n\n* Reflex 2 combines Reflex Low Latency mode with a new Frame Warp technology, further reducing latency by updating the rendered game frame based on the latest mouse input right before it is sent to the display.\n\n# Project G-Assist\n\nArticle Link: [**Project G-Assist: An AI Assistant For GeForce RTX AI PCs, Comes to NVIDIA App In February**](https://www.nvidia.com/en-us/geforce/news/g-assist-ai-companion-for-rtx-ai-pcs)\n\n* Optimize performance, configure PC settings, and more with a voice-powered AI Assistant, all run locally on GeForce RTX GPUs.\n\n# NVIDIA ACE\n\nArticle Link: [**NVIDIA Redefines Game AI With ACE Autonomous Game Characters**](https://www.nvidia.com/en-us/geforce/news/nvidia-ace-autonomous-ai-companions-pubg-naraka-bladepoint)\n\nVideo Link: [Click Here](https://www.youtube.com/watch?v=wEKUSMqrbzQ)\n\n* PUBG: BATTLEGROUNDS, inZOI, MIR5 & NARAKA: BLADEPOINT MOBILE PC VERSION are the first games to incorporate autonomous companions, enemies, and game systems powered by NVIDIA ACE.\n* In 2025, *PUBG* IP Franchise is introducing Co-Playable Character (CPC) with *PUBG* Ally. Built with NVIDIA ACE, Ally utilizes the Mistral-Nemo-Minitron-8B-128k-instruct small language model that enables AI teammates to communicate using game-specific lingo, provide real-time strategic recommendations, find and share loot, drive vehicles, and fight other human players using the game’s extensive arsenal of weapons.\n* In March 2025, NetEase will release a local inference AI Teammate feature built with NVIDIA ACE for[ *NARAKA: BLADEPOINT* *MOBILE PC VERSION*](https://www.narakamobile.com/en/#/), with[ *NARAKA: BLADEPOINT*](https://store.steampowered.com/app/1203220/NARAKA_BLADEPOINT/)on PC also adding the feature later in 2025. *NARAKA: BLADEPOINT* is one of the top 10 most played games on Steam each week, and *NARAKA: BLADEPOINT MOBILE* boasts millions of weekly players on phones, tablets, and PCs. AI Teammates powered by NVIDIA ACE can join your party, battling alongside you, finding you specific items that you need, swapping gear, offering suggestions on skills to unlock, and making plays that’ll help you achieve victory.\n* Several other games are also incorporating NVIDIA ACE technologies: full details in the article.\n\n# Creator\n\n* The GeForce RTX 50 Series revolutionizes creative workflows [thanks to new NVIDIA Studio tools and features for creators, and even faster hardware](https://blogs.nvidia.com/blog/generative-ai-studio-ces-geforce-rtx-50-series).\n* Added hardware support for encoding and decoding the 4:2:2 pro-grade color format yields a staggering 11X encoding speed increase compared to software encoders.\n* 9th Gen NVENC video encoders include a 5% improvement to HEVC and AV1 encoding quality, and a new AV1 Ultra Quality mode that offers an additional 5% improvement to encoding efficiency. And the 6th Gen NVIDIA decoder is capable of decoding and playing back up to eight 4K60 4:2:2 video streams simultaneously.\n\n# Giveaway\n\nRespond on the pinned comment below to enter giveaway for 3x $20 Steam giftcards.",
    "comments": [
      "$549 was certainly a surprise",
      "I'm going to be very interested to see 5000 series benchmarks without dlss/ai/upscaling features.  They seemed to be really talking AI enabled with the new cards, but I'm excited to see what benchmarks brings",
      "I'm ready to be so disappointed by linus tech tips or gamersnexus, watch it be an 18% uplift without the new magical fake frames feature",
      "It feels like this generation is the first true generation of AI prioritized GPUs.  Rasterization is essentially dead. \n\n\nGPUs from here on out will nearly completely rely on AI advancements instead of raw horsepower. This is what a GPU is now.",
      "Literally just murdered AMD’s 9070 before they even announce it lol.\n\nPeople over there were so fucking adamant that no way NVDA would sell the 5070 less than $650 and that the 9070 would undercut it by $50.",
      "Can’t wait for the 5090 and fighting all the bots again ugh",
      "Were any benchmarks shown without frame generation? Also it looks like DLSS4 features are coming to all RTX cards, just not multi-frame gen, which is the least exciting feature imo.",
      "Where are all the doomers saying that the 5080 was going to be at minimum 1500 dollars? Never believe rumored \"leak\" prices everyone. There's no such thing as a confirmed price until jensen walks on stage and says one",
      "Instead of fighting bots. You will be fighting 30+ year old men that smell like New York rats to get your 5090 at Microcenter.",
      "Very happy with the 5070 price point. Was expecting 650-700. Really excited to see reviews and upgrade out of my 2070 super. Pretty much only upgrading because of MH Wilds.",
      "From this imprecise bar graph, Nvidia seems to be saying that a 5090 gets framerates ~30 fps for native 4k path tracing in Cyberpunk, and ~150 fps with performance DLSS + DLSS3 frame generation.\n\nFor comparison, a 4090 gets ~20 fps with native 4k path tracing in Cyberpunk.\n\nhttps://www.nvidia.com/content/dam/en-zz/Solutions/geforce/news/dlss4-multi-frame-generation-ai-innovations/nvidia-dlss-4-multi-frame-generation-up-to-8x-faster-performance.jpg\n\nEDIT: Typo.",
      "I'm fine with it as long as it looks good. \n\nInsert bell curve meme\n\ndoes it look good? \n\nnooooo the raster performance is only 15% higher and blah blah blah\n\ndoes it look good?",
      "What the actual fuck are these AI benchmarks?  \n  \nFP8 on 40 series but FP4 on 50 series? That's not even remotely a fair comparison. It's not even a comparison at all.",
      "Can anyone explain to me if the new DLSS 4 multi frame generation thing still gives you input lag? Has it been improved?",
      "With a 27% increase in power draw... 20% isn't all that great.",
      "RTX 5090 *starting at* $4039 AUD… get fuuuuuucked.",
      "My sincere apologies for the delay on the Megathread. There were tons of stuff announced. \n\nIf you want to enter the giveaway for a chance to win 3x $20 Steam Giftcard, please respond to this pinned comment for the following questions:\n\n   * Which platform technology or GPU feature are you most excited about from today’s announcement?\n   * Which RTX game are you most looking forward to playing and why?\n\nGiveaway will open until Sunday January 25th at Noon Eastern.",
      "Lmao obviously not \nOnly with DLSS4 on",
      "Gotta wait until review samples go out before any real information about raw performance is shown. Jensen really likes playing up the disingenuous CES graphs.",
      "The 5090 still has 93 billion transistors over the 76 bil of the 4090 and also has GDDR7 so shouldn’t rely totally on ai for performance improvements"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "top",
    "matched_keywords": [
      "rtx 4090",
      "4090"
    ],
    "title": "I know I'm late to the party, how I did with a RTX 4090 3 months old GPU? $800 from a friend!",
    "selftext": "",
    "comments": [
      "When’s the wedding?",
      "What did you threaten your friend with to get that price?",
      "Not that much money apparently... Your friend essentially gifted you 600-800 dollars",
      "Lol, naahhh he just need the money!",
      "5070 is 4090 performance, sell fast\n\nEdit: btw, that was sarcasm, i still have my 4090 and would never sell that boy",
      "Now pass it on to me your new friend for 300$",
      "Thats a great deal! Congrats on that card and a decent friend 👏",
      "At the moment? He gifted him 800-1000€. At least if you take the european used market as a reference. GZ op.",
      "You know you did well that's why you're posting it.\nEnjoy the card the 4090 is the new 1080ti",
      "Lol no it doesn't.  U need to learn the difference between raw performance nd ai generated frames with dlss nd frame gen. If u play alan wake, I get 60fps ultra contant, maxed out no dlss or frame gen. U with a 5070 native no dlss would get 20 to 30 frames. Ull need dlss nd frame gen which causes alot of artifacts and glitches. Depending on which u set like quality balance performance etc. Dlss4 nd frame gen will give performance \"like\" 4090, meaning the only way ull get high frames is thro dlss. Doesn't mean it will out performance a 4090. Nvidia admitted 5070 is no where near the performance of a 4090. So yea its not the same shit.",
      "nice. i got my bids in on 1400 bucks so you did better than me",
      "No 5070 no where near performance of a 4090 bro\nOnly with dlss 4 nd frame gen do u get performance like 4090 , keyword like.",
      "4090 is selling for 1700 at the very least on used market",
      "pretty damn good",
      "He could have easily gotten money elsewhere, and a lot more. He’s a good friend.",
      "Your ‘friend’ is a Homeless man you paid $800 to boost you a 4090 dont lie",
      "There’s a reason the 4090 is selling for $2.2k and the 5070 will be less than half that. Maybe one day you’ll get it",
      "god damn that look's beautiful",
      "It seems you bought yourself RTX5080 Ti. Good job! You're ahead of your time, not late at all 😂 It's both funny and tragic, but - great for you. Much better choice than anything at this moment. RTX 5090 will be good within a year, I never understand those people buying it on premiere. Burning cables with 4090, now PCI, drivers and games issues with 5090. When 5080Ti releases and there will be stable mods for frame gen on 4000 series, or just better lossless scaling or even the official multi FG support for 4000 from DLSS4, it may turn out that we'll still have better GPUs than a whole new generation. 5080Ti will become just 4090 + multi FG and if that's also taken away by a better lossless scaling or the official multi FG support, then well... It will be even more funny. So - good job, again.",
      "Man I need a friend who needs money like this lol.. 800 for a 4090 is a steal"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "top",
    "matched_keywords": [
      "rtx 4090",
      "4090",
      "rtx4090"
    ],
    "title": "Really dumb 4090 question",
    "selftext": "I am trying to see what is compatible with the corsair Hydro X Series XG7 RGB 40-SERIES GPU Water Block (4090 FE) and I have gotten utterly confused and can't find the answer. Is the Vipera Nvidia Geforce RTX 4090 FE the nvidia Geforce RTX4090 FE and thus is compatible ? or is it a different brand than just the nvidia Geforce 4090 RTX FE (i.e. strix, tuf etc)?",
    "comments": [
      "RTX 4090 FE. FE means founders edition. They are from nvidia the founder, no brand other than nvidia. If its asus msi gigabyte not FE"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "top",
    "matched_keywords": [
      "4090",
      "rtx4090"
    ],
    "title": "Is the MSI RTX4090 Ventus 3X a decent card?",
    "selftext": "Hi guys. I have a chance to get a MSI RTX4090 Ventus 3X for a good price vs other 4090\\^s and I notice it's quite a bit smaller than other cards. [https://www.msi.com/Graphics-Card/GeForce-RTX-4090-VENTUS-3X-24G-OC](https://www.msi.com/Graphics-Card/GeForce-RTX-4090-VENTUS-3X-24G-OC)\n\nCan anyone who owns this please give me some feedback on temps, fan noise, coil whine and general thoughts? Many thanks. :)",
    "comments": [
      "600w cards make almost no difference to performance it's just marketing and a waste of more power. Stock RTX4090 performance is plenty.",
      "I think you are not very smart if you don't understand the question. It's about the AIB card quality, not the raw performance.",
      "Temps and fan noise are like any other 4090. 58 - 62 degrees at max load in 4k Rt games at 1400 - 1800 rpm. I must’ve got lucky with my silicon or the ventus is a beast Because I’m stable in games with 175/200+ on the core + 1500 on mem. As far as I can see from others max ocs  thats quite high. Gpu doesn’t sag at all the build quality is quite sturdy as usual from the ventus series. Coil whine is non existent. If u got any other q’s lmk.",
      "Dude you can do what you want but you don't need to try and convince others who have been in the PC hardware game for many years. I KNOW that 600w makes very little practical difference over 450w and nowadays I care more about efficiency than 1-3% extra performance..",
      "How much difference can you please be more specific?",
      "inaudible at max load (50-60% fan speed), at least compared to my already silent case fans even at idle, dont really know how else to test them lol. i was really surprised by it so im sure you wont be let down",
      "I would love to get it but it doesn't seem available in North America?",
      "What is fan noise like under load?\n\nAnyway thanks for the feedback, I went ahead and ordered one as it was a couple of hundred cheaper than other models in my EU region and I would rather put that money towards other things. :)",
      "stock - [http://www.3dmark.com/spy/34308777](http://www.3dmark.com/spy/34308777)\n\nMost stable in game Oc (175 core, 1500 mem) - [http://www.3dmark.com/spy/34308998](http://www.3dmark.com/spy/34308998)\n\nMax Bench Oc - [http://www.3dmark.com/spy/34172890](http://www.3dmark.com/spy/34172890)\n\nobvs didnt mess with cpu and case is a lian 215 and 240mm AIO as exhaust on top, exhaust at back and 2 200m front fans as intake. not too shabby for what's supposed to be the \"worst AIB model\" imo",
      "Thanks my dude I will report back when I hopefully receive mine (if the store doesn't screw me around)! :)",
      "Highly doubtful that you got a 50% increase  in performance because of a small OC. Sure you didn't change CPU recently? :p",
      "Highly unlikely that difference is because of OC.",
      "The 1% lows are 50% better than they were, no?",
      "It's a 4090 what do you think.",
      "Any “4090” is pretty “decent” lol",
      "How many phases and quality internal components are?\n\n[https://www.reddit.com/r/nvidia/comments/y5x5pg/buildzoids\\_gpu\\_pcb\\_breakdown\\_of\\_the\\_palit\\_rtx/](https://www.reddit.com/r/nvidia/comments/y5x5pg/buildzoids_gpu_pcb_breakdown_of_the_palit_rtx/)",
      "Just purchased this card coming from a 3080 and it’s quiet as fans only run at 45% while playing the last of us in ultra native 4k it’s dreamy. My 3080 used to run at like 2000rpm plus so noise difference is huge with big performance.\n\nI run it at 70% power due to a 750sfx psu.",
      "Hey, can I have your timespy extreme result link?",
      "dang... thats bad",
      "Any coil whine issues? I've been reading about some very mixed results between brands.\n\nHow has the 70% power limit been working out? I'm considering this GPU since I want to cram it into a SFF case (SSUPD Meshlicious), and have the same type of 750W SFX power supply."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "top",
    "matched_keywords": [
      "rtx 4090",
      "4090"
    ],
    "title": "RTX 5090 & 5080 Launchday Thread - Surprise Inside",
    "selftext": "**What**: GeForce RTX 5090 & 5080 Launch Day\n\n**When**: Thursday, January 30, 2025 at 9am Eastern Time (expected time)\n\n* The subreddit will be locked for submission starting **7am Eastern Time**. This restriction should be lifted by **5pm Eastern Time**.\n\n* This Launch Day Megathread will serve as the hub for discussion regarding various launchday bonanza.\n\n* [You can also join our Discord server for discussion!](https://discord.gg/nvidia)\n\n* Topics that should be in Megathread include:\n\n     * Sharing your successful order\n\n     * Sharing your non successful order\n\n     * Sharing your Brick & Mortar store experience\n\n     * Discussion regarding stock\n\n     * Any questions regarding orders and availability\n\n     * Any discussion regarding what you plan to use your new GPU for\n\n     * Any discussion about how you're happy because you get one\n\n     * Any discussion about how you're mad because you didn't get one\n\n* **Any standalone launch day related posts will be removed.**\n\n**Reference Info:**\n\n[RTX 5090 Review Megathread](https://www.reddit.com/r/nvidia/comments/1i85jwg/geforce_rtx_5090_review_megathread/)\n\n[RTX 5080 Review Megathread](https://www.reddit.com/r/nvidia/comments/1icwhds/geforce_rtx_5080_review_megathread/)\n\n[GeForce RTX 5090 & GeForce RTX 5080 Out Now, Featuring Game-Changing AI and Neural Rendering Capabilities, and DLSS 4 With Multi Frame Generation](https://www.nvidia.com/en-us/geforce/news/rtx-5090-5080-out-now)\n\n\\------------------------------\n\n# The Surprise...\n\nWe've collaborated with the NVIDIA community team in the last 4 years spanning two GPU generations. We had Q&A sessions for RTX 30 and 40 series launches and for the RTX 40 series, we also had the NVIDIA community team handing out a bunch of game codes during in the RTX 4090 launchday thread such as this one.\n\nThis year, we are collaborating with the team yet again to help celebrate the launch of GeForce RTX 50 series. In addition to posting your launch day experience as listed above, also read the information below to win Steam Gift Cards!\n\nWithout further ado, here's the details from: u/NV_Tim:\n\n\\------------------------\n\nThe availability day for the [GeForce RTX 5090 and GeForce RTX 5080](https://www.nvidia.com/en-us/geforce/graphics-cards/50-series/) has arrived!\n\nTo help celebrate, we’ve given the mods STEAM Gift Cards to distribute.\n\nFrom 1/30-2/4, just comment on this thread with any of the following and you could find yourself with a DM from the mods delivering a code.\n\n* Reply with which new RTX technology you’re looking forward to, or which game you’re looking forward to playing on the RTX 50 Series!\n* If you purchased a GeForce RTX 5090 or RTX 5080, feel free to share, or share your awesome hands-on experience with DLSS 4!\n\nWe hope you have a great weekend!",
    "comments": [
      "Friendly reminder that there is zero reason these companies couldn't just take an order and put it in a queue for fulfillment.",
      "Simulated frames, simulated inventory.",
      "fuck best buy, fuck nvidia, this shit is not a real product, managed to get \"in line\" in first few seconds and now out of stock.",
      "> Got onto Best Buy.\n\n> Clicked \"Add to Cart\", got a \"You're waiting in line\" pop up.\n\n> Got error message \"Something went wrong with adding this item to your cart\"\n\n> Tried three more times\n\n> Sold out\n\nSigh.",
      "https://preview.redd.it/kq1ax3jh25ge1.png?width=3160&format=png&auto=webp&s=b4b9ef5e3c5d42198149e78d5d38f1a1faf30ca1\n\naaaaand it feels like the 30 series launch again",
      "That's what I'm saying, mate.    I did this when I bought a Vive almost 9 years ago.  I did this when I bought a Steam Deck.  \n\nI literally don't care if my spot in queue is 3 months out or whatever...Just let me have the peace of mind to buy the thing and be done with it, without jumping through hoops refreshing to a Sold Out page.",
      "Biggest scam out there\n\nhttps://preview.redd.it/5u6xiawg65ge1.jpeg?width=1206&format=pjpg&auto=webp&s=0629e74cc95bf05fe3e5266bcb0de4a514496b74",
      "grey hard-to-find march six screw mighty elderly chief history work\n\n *This post was mass deleted and anonymized with [Redact](https://redact.dev/home)*",
      "Paper launch, get fucked nVidia",
      "Hey  u/NV_Tim where the fuck are the cards? Bring back the Verified Gamer program so we can just sign up and be notified to purchase the card we want when it comes in stock without having to play hot potato with a billion bots.",
      "Does Nvidia know these cards are dropping today?",
      "Why can't the purchase experience be like an iPhone?  Just put your order in and have them ship it to you.  This purchase experience is just awful, can't even place an order to begin with.  Like how is the Nvidia team even celebrating this launch knowing full well that they shipped way less than what the demand was going to be.   There's a lot of disappointed gamers and tons of happy scalpers.  Do Better Nvidia",
      "2020: bots snag all the GPUs\n\n2025: bots snag all the GPUs and comment how good DLSS 4 on reddit",
      "\\> lock sub down\n\n\\> have a single launchday thread\n\n\\> also make it a giveaway thread sponsored by \"the NVIDIA community team\", whatever that is (only giving away Steam gift cards, lol)\n\n\\> successfully suppress the conversation about peoples' frustration with how bad the launch is by flooding the single thread with giveaway comments",
      "Wasnt even possible for a human to buy",
      "At 9:00 sharp I refreshed the BB 5090 page and it still said \"Coming Soon\". I kept refreshing and finally after 45 seconds it said \"Add to Cart\". I clicked \"Add to Cart\" and got into the queue, then got kicked out because 'Something went wrong'. This happened thrice and now it's sold out. Fucking hell",
      "- Nvidia website never even acknowledged the existence of the 50 series until a few minutes after the embargo time, and that was only as a product filter/lefthand nav showing 2 SKUs.   No actual products ever displayed.\n\n- B&H showed there would be a waiting list and the embargo time and instantly flipped to 'out of stock 'on everything\n\n- Newegg, like Nvidia, didn't even add navigation for the 50 series until a few minutes after the embargo time, and were also instantly all marked sold out\n\n- Best Buy only ever availability on the FE.   All other models out of stock the entire time.   Got in line multiple times for the FE with the website throwing errors aborting that wait until Sold Out.\n\n\nWhat a joke.",
      "Best Buy looks to be sold out instantly. \n\nThis is not a serious product launch",
      "Why didn't Nvidia just do a geforce presale for existing customers like they did with the 4 series. Screw this insta-botted crap lol.",
      "I miss EVGA when we could just sign up for a waitlist and be in line than play the F5 game all over."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "top",
    "matched_keywords": [
      "rtx 4090",
      "4090"
    ],
    "title": "RTX 4090 Tustin California Micro Center Launch. 9 hours left!",
    "selftext": "",
    "comments": [
      "Nvidia looking at this: \"where is all the dumb c**** that said no one gonna be buying 4090 at 1600 dollars?\"",
      "Brace yourselves. GPU on car seat posts incoming",
      "It turns out redditors are out of touch with reality once again. Imagine actually thinking this card wasn’t gonna sell like hot cakes.",
      "Well that's depressing but not unexpected. Nvidia could've charged $2,400 for this thing and people would still be lining up like this.",
      "first batch always sells\n\navailability week after launch will show us true demand on this card",
      "as a former micro center tustin employee, i sincerely wish that every single one of you would go home",
      "Woah.. And I thought showing up 30min before opening was excessive....",
      "NVIDIA's AI already informed Jensen that the card will sell well with that price.",
      "Guy at the front has been here since yesterday",
      "This is what I was thinking, don’t forget, they will have it buckled too",
      "Here we go again",
      "These people be camping outside all night. Meanwhile, Jensen is sleeping soundly wearing his comfy leather jacket.",
      "Don't worry, that's coming next gen. This was their plan to test the waters. If day 1 this card had poor sales and nobody lined up for it, then maybe there was chance of Nvidia realizing, oh shit maybe that was a tad bit too high.  \n  \nBut clearly its going to sell out day 1, and now Nvidia's going to look at this and go, awesome we're definitely raising prices again.",
      "What recession?",
      "That's what I am most interested in seeing as well. Every major GPU launch sells out. Also a good amount are probably scalpers I imagine.",
      "I'm both amazed and terrified, about equal parts.",
      "I get it, like its a fast GPU, demolishes 4K. But this basically just gives Nvidia the green light.",
      "Let's hope them scalpers are left holding the bag",
      "They'd need to be, since the seatbelt sensor will keep beeping at them if they don't.",
      "They are just buying the card to keep their homeless car or tent heated in the winter."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "top",
    "matched_keywords": [
      "rtx 4090",
      "4090",
      "rtx4090"
    ],
    "title": "4090 and power cables",
    "selftext": "I recently built a new pc with tuf gaming 4090 oc edition and I cant close the case with that 1 to 4 pin psu connector. I'm looking to buy Corsair Premium 600W PCIe 5.0 / Gen 5 12VHPWR PSU Cable - Fits Type-4 PSUs via Dual 8-pin PCIe - 12+4pin to go into a evga supernova 1000w g+ psu. With only two connectors to the psu will this be fine?\n\nPsu- EVGA SuperNOVA 1000 G+, 80 Plus Gold 1000W, Fully Modular, FDB Fan, 10 Year Warranty, Includes Power ON Self Tester, Power Supply 120-GP-1000-X1,Black https://a.co/d/7oed0TS\n\nCable- Corsair Premium 600W PCIe 5.0 /... https://www.amazon.com/dp/B0BLXWHW2N?ref=ppx_pop_mob_ap_share\n\nGpu-  ASUS TUF Gaming GeForce RTX 4090 OC Edition Gaming Graphics Card (PCIe 4.0, 24GB GDDR6X, HDMI 2.1a, DisplayPort 1.4a) TUF-RTX4090-O24G-GAMING https://www.newegg.com/asus-geforce-rtx-4090-tuf-rtx4090-o24g-gaming/p/N82E16814126594?Item=N82E16814126594&Source=socialshare&cm_mmc=snc-social-_-sr-_-14-126-594-_-04142024",
    "comments": [
      "Don’t do this. Different psu manufacturers use different pinouts for their products and mixing and matching can kill your hardware. You’ll need to search for a compatible evga cable.",
      "Buy the power cable for your PSU, DO NOT use corsair power cable on EVGA PSU or vice versa, NEVER do this.\n\nBuy the correct cable. Please for the love of god.\n\nThat being said, I had the corsair cable on my corsair psu, and yes 2 x 8 pin on the PSU side and 1 x 12vhpwr on the gpu side is fine. You will get all the power you need.",
      "I have a 4090 TUF OC, same card you do, bought it in october 2022, like a week or 2 after launch. I use the stock adaptor they gave with it ever since, 4K gaming, demanding games, I didn't power limit, downclock or anything. 0 issues so far. It's kind of luck of the draw if you ask me. You either get a faulty card or you don't. Just make sure you push the adapter all the way in, don't bend the cable too much and that's it. That's all you can do.",
      "Thank you",
      "Thank you",
      "Yes I bought the same cable for the exact same reason."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "top",
    "matched_keywords": [
      "rtx 4090",
      "4090"
    ],
    "title": "NVIDIA GeForce RTX 4090 & 4090D To Be Discontinued Next Month In Preparation For Next-Gen RTX 5090 & 5090D GPUs",
    "selftext": "https://wccftech.com/nvidia-geforce-rtx-4090-4090d-discontinued-next-month-in-preparation-for-next-gen-rtx-5090-5090d-gpus/",
    "comments": [
      "I might be interested in a 5080 but I'm sure its going to be over $1000.",
      "If production ends as early as October, then when can we expect the 5090?",
      "production has likely already stopped that is when they expect the stock to run out.",
      "I just hope there’s one that can fit in my case",
      "Oh shit, it’s happening!",
      "Let's play a game. Who's going to fk us this time? Scalpers? Crypto-miners? Chinese AI firms? Jensen himself?",
      "remember how quickly stock of the (desirable) new 30 series cards disappeared?  \n  \nwasn't even a window for their prices to drop really",
      "It wont",
      "This. Some people are delusional and thought they will get a cheap 3000 series once the 4000 comes out. We saw how quick the stock was drained and the 3000 cards never really lost that much value. It will be no different with the 4000 series. And its a good thing for both Nvidia and 4000 series owners who want to upgrade to the 5000 series and can sell their current cards without a massive loss.",
      "3000 series came out in the middle of covid, supply shortages as well as scalpers made this the worst launch possible. Hopefully it doesn't happen again.",
      "What case do you have? Most recent PC cases have pretty generous margins for GPUs with how large the cards are getting.",
      "The 5090 will be even more crazy since amd isn’t competing and tsmc increased their prices by 15%. There is absolutely no way NVIDIA isn’t taking advantage out of this situation.",
      "I mean, sorta. Not a ton of people want to a buy a 3 year old GPU that has no warranty and literally zero idea about what it's been through. Maybe I'm wrong but I'd rather have a market where things eventually drop below MSRP, I'm not saying 50% below but getting an old card off ebay without a warranty is a coin flip.",
      "Yeah. No reason not too if it’s supposed to replace the 4090 and there is literally 0 competition at all. Could be $2000 just because why not. Hell $3000. No competition. I expect no stock and higher prices at least.",
      "Crazy isn’t it ?  We’re staring at the crossroad right now!",
      "As always, RIP EVGA and their transferable warranty",
      "Lol, I'll be using my 4090 for a long time. How much more powerful will th 5090 be? And will you be able to even get your hands on one?",
      "\"Nerfed\" or less powerful cards for the Chinese market.",
      "Get ready to own a 5090 in 4 years after the scalpers dry up",
      "I think that *might* have been NVIDIA’s thought process up until the AMD news. Now they don’t even need to worry about their precious market share (if they even needed to in the first place) in the high end tiers\n\n5080 -$1200\n\n5090 -$1800\n\nThat’s my prediction based on absolutely nothing other than cynicism"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "top",
    "matched_keywords": [
      "rtx 4090",
      "4090"
    ],
    "title": "[Gamers Nexus] The Truth About NVIDIA’s RTX 4090 Adapters: Testing, X-Ray, & 12VHPWR Failures",
    "selftext": "",
    "comments": [
      "Finally some clarity. GN once again doing the work.\n\nEstimation of failures is 0.05% to 0.1%.\nBasically it's mostly user error with connectors that aren't fully seated (design oversight on the adapters that should have a clear audible click). Fringe cases of connectors with internal debris causing contacts where there shouldn't be.",
      "Tl;dw all cables are susceptible, even the cablemod ones\n\nAnd the cause seems to be mostly user error, with some poor design and manufacturing error thrown in\n\nIt could also be argued the user error is caused by poor design",
      "Information with actual reasearch, testing and evidence. I tip my hat to GN.",
      "Lmao, Cablemod making bank on user errors.",
      "This is why I love GN, their work is on par with what I'd expect from a vendor doing a quality control related root cause analysis.\n\nGood stuff, great analysis and testing.\n\nThe end result doesn't surprise me either.",
      "JohnnyGURU basically said the same thing and was attacked by most people on this forum.",
      "So the top likely failure cause is from incorrect insertion.\n\nAnother failure cause but less likely is from foreign object debris from manufacturing.",
      "So that msi graphic that people flamed was right.",
      "TLDW - PLUG THE DAMN CABLE IN ALL THE WAY NOT JUST MOST OR ALMOST!",
      "You already know jay is going to make a 30 minutes video copy pasting what gamer nexus says with some lame ass jokes.",
      "Funny that, how a manufacturer who actually built the fuckin things might know better than a forum full of idiots hammering at their keyboards",
      "Tbh I would’ve bought a CableMod cable regardless, the stock adapter looks terrible.",
      "Thanks I was waiting for someone to post this as I couldn't",
      "That was a sad event that occurred... Johnny was even confused with the toxicity of Reddit since he doesn't post here often. That says a lot about the Reddit community.",
      "I know one conclusion I support. Igor's lab is not a good source for these \"fear gate\" news. The guy jumps the gun and is wrong often. \n\nCapacitor gate, cable gate. What next Igor?\n\nThank god we have Steve GN, Johnny Guru, etc.",
      "So “you’re holding it wrong” with a few added steps will be the tact NVIDIA takes but benevolently offer new cables.\n\nThese should be easy to insert, give good solid feedback (CLICK) that the cable is seated, and should survive dozens of connections.  I worked in durable customer goods manufacturing and in almost all cases we treated products failing to perform as expected as a manufacturing or design defect.",
      "I was sort of shocked when i first plugged it in, there was no audible or tactile click of any kind, but pulling and repushing confirmed it was attached. Not the best design choice considering pretty much every single other plug involved in a PC's wiring clicks.",
      "When I get home from work; I’m gonna shove in that connector with all my might.",
      "The knock against JayzTwoCents at the end was just classic.",
      "That's not manufacturing error, that is poor design. Works as intended if used correctly, but goes very wrong very quickly if it meets a certain failure mode."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "top",
    "matched_keywords": [
      "4090"
    ],
    "title": "Does anyone know the 3rd-party manufacturer for this 4090?",
    "selftext": "Or is it some additional outer shell on top of the GPU? Never seen a GPU like this.",
    "comments": [
      "It looks like Zotac OEM 4090. I could be wrong, but thats the only gpu that kinda looks like this, where the letters “GEFORCE RTX” are in the middle. The rbg thing is I guess the gpu holder.",
      "I checked, it is. Thank you! :)",
      "https://preview.redd.it/338yml7cojic1.jpeg?width=708&format=pjpg&auto=webp&s=ea0b35dea0a912a6a8ce758e31b300005da0a8da\n\nYou are right. And GPU holder looks like model UpHere G276 ARGB but with other brand symbol (white label product maybe?)",
      "Yes this looks like that holder, but some variant."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "top",
    "matched_keywords": [
      "rtx 4090",
      "4090",
      "rtx4090"
    ],
    "title": "Will the Gigabyte gaming rtx4090 fit in Cooler Master H500 ?",
    "selftext": "Hello there .\nI ordered a Gigabyte Gaming OC RTX 4090 and I have a h500 cooler master case \nDoes the card fit ?\nI mean the site says the cpu clearance is 16.1 cm and and card 15 is cm\n\nI got also the be quite psu that has his own pci5 cable inside so I will not use the adapter \n\nDo you thing it can work ?",
    "comments": [
      "Barely. I had the same H500+4090 Gaming OC, and the cable is pushed right up on the glass, and you have to pre-bend the cable. It felt a bit sketchy, but I triple checked everything was plugged before and after closing up the side panel and ran it for a month like that. A 90-degree adapter would probably be a good idea if you keep the case. It's seriously tight enough of a fit that I eased the glass side panel screws up for +1mm of space.\n\nI ended up upgrading most of my PC and got a Lian Li Lancool III, which now has plenty of room for the GPU. The build quality, 360/420mm AIO support, sliding cable cutouts, and general ease of access to everything has been amazing compared to the H500. The only downside is that the velcro tie down points don't pull back on themselves, so cables are loosely held in place, which makes closing the rear side glass with the giant 24-pin mobo cable in the way a bit tricky but still doable. I do miss the carry handle for moving my PC around for VR.",
      "Do you have any link of that adapter ? Also I am sry for asking but do you believe I will really have a problem I mean I could leave it like that and checking of course if it's connected properly ? I hope the cable that comes up with the be quite is durable and okay and not melt",
      "Cablemod is pretty much the only option. The Be Quiet cable will be high quality. The problem is that harsh bend. You can also just leave the side panel open for as long as you need with just a little bit of extra dust buildup. \n\n\n\nPersonally, I just went with a new case because I always hated getting stuff in/out of the H500 with a big Noctua HN-D15 cooler in the way. To add a m.2 SSD, I would have to remove the fans or the full cooler, then remove the GPU, then add the SSD. All with like 2 inches of clearance for my hand, so unplugging the top fan headers or removing the fan clips always cut my knuckles up on the fins of the Noctua.",
      "https://store.cablemod.com/12vhpwr-angled-adapter/\n\nMeasure clearance once installed in your case. A 12vhpwr cable needs 35-40mm of room for a \"safe\" bend. \n\n180 degree (cable over the backplate) cuts that down to 15.4mm.\n\n90 degree (cable down under GPU cooler) cuts that down to 21mm.",
      "I very noticed that adapter is 2cm also between the card and the glass so it will not fit again. I need to see it with my own eyes with my technician. I think 2 cm will be OK i think . Dunno what else to say",
      "The 180 degree I think it will fit and it's the only one I can find in stores in my country . I will try to see with out it how bad it is if it's OK I will leave it like that or I will leave the panel open for a few days until the adapter arrive",
      "It's a big card, and either the FE ($1600) or the MSI Suprim Liquid X ($1750) would cut 10-13mm off the width and fit better. The 240mm AIO may be hard to fit in there depending on what your current CPU cooler is.",
      "Is that bend generally bad for all cards or just for the 4090 in general because of the melts ?",
      "It's bad on the cable because it can potentially unseat a wire. It also puts downward tension on the connector, which may be enough to loosen it or have poor contact with the pins. That bad contact causes large resistance, and since the 4-sense pins are still touching, it doesn't cut power and the cable burns.\n\nThe 4090 has the most issues burning up because they are the biggest cards, and they push right up on the glass, which causes the issue. You don't see any RTX 4070 burning posts even though the cable, connector, and risk of burning are the same.",
      "I have one question if you can help me ATM I have an rtx 2080 gaming gigabyte. On the official site it says that the width it's 114.5 mm. But I am measuring it 111.. ! IA there a chance that it's the same way with the 4090?",
      "Yes, it may include the width of the PCIe slot that hangs off the side. That's probably why I got my 4090 to barely fit and why the -13mm width 4090 FE should fit fine without needing to worry about adapters and the side panel.\n\nAgain, if you decide to stick with the 4090 Gaming OC, you can just keep the side open till you either decide on buying an adapter or a new case.\n\n\nhttps://www.coolermaster.com/catalog/legacy-products/cases/mastercase-h500/\n\nAnd just to double check, this is the case, right? Don't want to give you bad info if we have slightly different models.",
      "Yeah that's the case . II already bought the gigsbyte I cannot give it back . I saw one other post on reddit that the guy had the tuf version the card had the same width with the gigabyte 150mm and he had the same case and it had room to bed correctly . I can show you the images  if you want.i need to see it by my self to judge it seems"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "top",
    "matched_keywords": [
      "rtx 4090",
      "4090",
      "rtx4090"
    ],
    "title": "Fitting the RTX4090 FE on Corsair x680?",
    "selftext": "I am considering buying the RTX 4090 FE but I am getting concerned if it actually fits on the Corsair 680x. \n\nAnyone who tried that or knows of it would work?",
    "comments": [
      "Well, it says on the home page;  Maximum GPU Length330.\n\n[https://www.corsair.com/us/en/p/pc-cases/cc-9011169-ww/crystal-series-680x-rgb-atx-high-airflow-tempered-glass-smart-case-white-cc-9011169-ww#tab-techspecs](https://www.corsair.com/us/en/p/pc-cases/cc-9011169-ww/crystal-series-680x-rgb-atx-high-airflow-tempered-glass-smart-case-white-cc-9011169-ww#tab-techspecs)",
      "Yeah I have seen that, but I also read about ppl having issues with this card and with fitting it in that case."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "top",
    "matched_keywords": [
      "rtx 4090",
      "4090"
    ],
    "title": "Here’s what’s happened to the 12VHPWR power cable of our NVIDIA RTX 4090 after two years of continuous work",
    "selftext": "Nvidias own cable adapter ",
    "comments": [
      "This is making me wonder how many cables with a 4090 are melted and users dont know. For most people there is no reason to remove a cable to check for anything",
      "I'm telling you, someone's room or house is going to burn down as a result of all this for that exact reason.\n\nIt's just not a normal thing to constantly check on your GPU cables like that.",
      "Oh it will don't worry",
      "What's worse, is the same people blame users for reusing these cables( as if this was ever a concern with 8 pin ), and blame users for somehow creating a \"loose\" connection. \n\n\nThere's no winning with this shitty connector",
      "Nvidia trying to stay quiet and avoid lawsuits.",
      "Car stereo and amplifier companies figured it out.  When you are talking about pulling 50+ amps at 12v, you better start thinking about single gauge cable.  These things need 8 gauge copper and clamp down connectors.",
      "\"You probably used the cable more than once, you're stupid.\"\n\n\"You used 3rd party cables, you're stupid.\"\n\n\"You didn't plug it in all the way (ignore the pictures showing it plugged in properly)\n\nI hate all the people blaming the users as if it's they're fault. Even if it is the \"users fault\", a cable *should not* be easy to fuck up to use. I never heard of the old 6/8 pin connectors burning (**Not** saying it never has happened) but god damn, the amount of people with burnt cards/cables is insane.",
      "I hope the 60XX series doesn't have that dumbass connector",
      "Yep, user error was very tiring to hear. It isn't happening to everyone, but it has absolutely happened to *enough* people to show that the 12VHPWR is very, VERY flawed.\n\n  \nWhich is why it was almost immediately revised...and still flawed.",
      "After recent revelations from Der8auer and Buildzoid, those lawsuits are absolutely coming. This is a serious, demonstrable problem: the connector is badly engineered and, in the case of the 4090 and 5090, it is defective in implementation due to the lack of lead/pin specific protections.",
      "They need their individual cables to be load balanced properly. That’s the only issue that actually exists. It can be done relatively easy on the card itself. It can be done trivially easy on the cables themselves. Someone just needs to do it.",
      "What Nvidia should be doing is figuring out how to increase performance without these crazy power draws, forcing the creation of a new power connector that sucks! Give me my 8pin connectors back.",
      "Probably have 2 of them the way things are going 😂",
      "its funny how this has never been an issue with the old 6/8 connectors but somehow its \"user error\" with the 12VHPWR: its like saying magically people have become stupid all of a sudden when handling 12VHPWR... typical brain dead shill response blaming the users even after countless evidences.\n\nIts either 12VHPWR has a serious design flaw, or 12VHPWR is magically making users stupid on touch. Either way its the 12VHPWR's fault by natural or supernatural means.",
      "Honestly 50 is an alarmingly low number considering the risk of fire once you hit the limit.",
      "What concerns me is, if I check and see and there is nothing wrong with it, will removing and replugging the cable potentially rise the risk of it happening? It’s a double edged sword.",
      "Nvidia should go for the chaotic option and do 12pin + 8 pin + 6 pin",
      "How big of an issue is this cable on cards that have lower power draw, such as the 4070 Super? I'm kinda worried after reading all these reports of failure. I am using the 12VHPWR cable straight to my PSU, not the dual 8-pin adapter. Been checking it a couple times a week and it seems OK.",
      "50 mating cycles is what they're rated for too. And just because something is rated for a number doesn't mean the number is absolute either. It could go fewer cycles, it could go more cycles.\n\nTherefore, every time you unplug to \"check\", you are incrementing that number upward. Just like if you transplant your PC to a new case, or have to test a friend's GPU to see if their GPU is dying or if it's just their PSU, or if you need to deep clean your case. And at least before 3.0 PSUs, you could get good PSUs for a fairly reasonable price. \n\n  \nNow you need a more expensive PSU (3.x) as well as a higher wattage PSU (higher GPU/CPU consumption, especially if Intel.) All of these things drive the price up. Those 50 mating cycles matter a lot more now, especially as if you do it too much apparently your home can liquefy.",
      "Imagine the amount of people checking now and realizing that the cable has melted and nvidia still won’t do anything about it"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "top",
    "matched_keywords": [
      "4090",
      "rtx4090"
    ],
    "title": "Pls help me to configure a PC for deep learning",
    "selftext": "Hello guys. Im trying to build a PC, and the main purpose of this PC is for deep learning works. So my initial choice is : \nCPU: i5 13400F (10core)\nMotherboard: Asus Tuf gaming z790-plus DDR5\nRAM: 64gb ddr5\nGPU: RTX 4080 16gb\nStorage: 5TB in total\nCPU cooler: Be quiet! Silent loop2 240mm\nPSU: 850W\n\nQ.\nI’d like to get RTX4090, but my budget is £2,600. \nDo u guys reckon it is worth to get 4090 instead of 4080? \nAnd if I get 4090, should I change the cooler and PSU? + is there any other components that I should change?\nObviously, I would get 4090 if I have a higher budget, but that amount of money is too much for me. But if it is really worth the money, Im gonna make some more money and get it next month probably.\n\nPls pls help me guys. Your experience and advice will help me a lot!\nThanks👍",
    "comments": [
      "> Obviously, I would get 4090 if I have a higher budget\n\nAnd you would be going the cost-ineffective route. Are you able to get 3090? Even used? I'm a DL researcher, and the main thing to target is memory. If you're putting all your money into a single GPU with 24gb, you're missing out on potential, better performance. Two used 3090s cost about the same as a single 4090 while providing you with double the memory, more CUDA cores, and more Tensor cores.",
      "The biggest issue to consider is the memory. So A 90 series card is imo worth it",
      "I power two 3090s and a 7950x with RM850x Shift. The two GPUs max out at about 340W at stock, no undervolt. I have plenty of headroom with 850W, so 1kW should be more than enough. 64gb memory should be enough if you don't have to do a lot of memory-heavy preprocessing. Depending on your work, 64gb might not be enough, especially if you plan on doing large model training on CPU. When I'm in the lab, our computers have at minimum 128gb memory, and there are times where I'm close to filling that up completely, but that's usually when doing things inefficiently lol. My home deep learning computer has 96gb memory and that feels nice to me. So it really depends on what you'd need the memory for.",
      "Lovely. Thanks a lot mate. Bless",
      "Thanks for your advice! Is there anything that I should check when I buy a used 3090? \nAnd do u reckon is 64gb ram and 1000W PSU still enough to handle the two 3090s? \nThanks! 👍",
      "Thanks a lot!! I’ll go for dual 3090s or a 4090 :)"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "top",
    "matched_keywords": [
      "rtx 4090",
      "4090"
    ],
    "title": "Here's all the RTX 4090 prices from Overclockers",
    "selftext": "",
    "comments": [
      "Definitely rooting for AMD.  NVIDIA corporate greed is on a whole other level now.",
      "Who can buy such expensive cards, nvidia really wants to kill their customer base, I don't want to know the price in euro something like 2300 Euro.",
      "If AMD is smart they would price their counterparts each 599$, 799$ and 999$. This move alone would net them so many Nvidia costumers.\n\nBut let's be honest they will price their cards a 100 bucks less and then act as if they have done the PC community a favour.\n\nNvidia is high on the crypto boom which doesn't exist anymore. They will probably slash prices once 30 series stock starts going down.",
      "Cheapest card in the picture is £1679,99 . Remove 20% VAT => £1399,99. \n\nIs this close to the MSRP?",
      "Its not only that too, high energy prices are becoming a factor here, and at idle it wont really be an issue, but you you are full blast pulling 200w from your cpu and 400w from your gpu, with maybe another 50-100w overhead for the rest of the computer+monitor/VR headset, and you put in some long sessions like 6 hours a day for a solid week its about 25kw, i think that works out about £5-10 of electricity a week with our sky high prices.\n\nIts not insignificant, a heavy gamer could easily be adding £25 a month on bills, i suppose if you can afford a 4090 you can afford an extra £25 a month on electric, but what if unit costs double, it could be a real problem.",
      "Yesterday it would have been $1582. Yeah our economies fucked.",
      "100% sitting this gen out.  I hope AMD pulls a rabbit out of a hat",
      "Why people think AMD care about consumers is beyond me, since AMD has proven that just like any other corporation, all they care about is profit, and they will take the piss if they can and whenever they're able to.",
      "Here in Australia the FE is around $2,959, I can only imagine the AIB prices",
      "thats $1519 USD",
      "Not looking atractive to keep buying GPUs from now on. Move on to something else. Good that I have music Instruments and skates/skateboard.\n\nSee you outside guys :)",
      "AMD aren't going to price competitively either, these people are in for a rude awakening. They'll just price slightly lower than NVIDIA's batshit pricing to reflect the lack of features and demand.",
      "Nope. These prices are out of control and it's just going to lead to a crash of the GPU market. People are going to look at consoles as a far more affordable choice for gaming and PC owners will just stick to the current cards they have now.",
      "What the fuck? This is nuts. I'm done for a few years lol. This just burns my eyes.",
      "It's unlikely they may slightly under cut. But amd is a business also and is driven by profits. It would be great if they came out and made a 4080 12gb aka 4070 competitor at 499 or 599 or something similar ,and under cut nvidia. but it's likely they will try to price as close as they can get away with",
      "4090 FE is quoted at 1959€ on nVidia's page. Can expect AIBs to cost 100-400€ more depending on the model. It's silly.",
      "Man I remember when $2000 was more than enough to build a high tier PC. Now that's just a video card.",
      "no GPU should be over $1000 USD change my mind",
      "With PlayStations and XBox readily available now, PC gaming is looking less and less attractive.  I could buy myself and 3 friends or family a console for how much it cost for one fugly Aorus Master.",
      "Lol £2000 pounds for just a GPU for playing games.\n\nMaybe if u are a streamer or creator or have lots of money."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "top",
    "matched_keywords": [
      "4090"
    ],
    "title": "RTX 5080 rumoured  performance ",
    "selftext": "3DCenter forum did some manual frame counting using the digital foundry 5080 video and found that it is around 18% faster than the 4080 under the same rendering load. \n\nDetails here - [https://www.forum-3dcenter.org/vbulletin/showthread.php?t=620427](https://www.forum-3dcenter.org/vbulletin/showthread.php?t=620427)\n\n\n\nWhat do we think about this - this seems underwhelming to me if true (huge if) , would also mean the 5080 is around 15% slower than the 4090.",
    "comments": [
      "Interesting analysis. Even without this, the 5070 Ti looks like a better deal.",
      "I’m shocked at the MASSIVE gap in the stack. There HAS to be a 5080ti at like 14-16k cores because half the cores in the 5080 is insane.",
      "There will be in about 12 months' time. I imagine that they will use 5090 GPUs that didn't meet the requirements to be used in 5090s. Once they have a big enough pile of those they can use them for the 5080ti",
      "You do not have to buy a new card every generation.\n\n5080 is a fine upgrade from a 3080.\n\nIf you really really want to upgrade 4080, get a 5090. As a bonus, all your problems with too much money in your bank account are solved.",
      "Not really enough of a gap with the 40 series, despite the large core difference between the 4080 and the 4090 of 68% more, [the 4090 was only 20-25% faster or so in raster](https://tpucdn.com/review/nvidia-geforce-rtx-4080-founders-edition/images/relative-performance_3840-2160.png). The only time you saw a bigger gap was with [RT enabled where it was more like 30-35% depending on the game for the 4090 in terms of a performance lead.](https://tpucdn.com/review/nvidia-geforce-rtx-4080-super-founders-edition/images/relative-performance-rt-3840-2160.png)\n\nMuch of the prolem with the 4090 was that it was memory bottlenecked and the cores couldn't all be effectively used, I suspect this is also the case with the 5090 despite using GDDR7. Thats just a lot of cores and they need to be fed data quickly to be useful. Don't forget too, despite the memory bus being smaller on the 4080, it was probably more balanced or reached the sweet spot of memory efficiency, as in it had little bottlenecks in the computation pipeline. The 4080 and particularly the 4080 SUPER had faster G6X memory than the 4090 too. Had that faster G6X been given to the 4090 instead of the 4080, the gap would've been larger in favor of the 4090 since the cores could feed data in and out way faster.\n\nI think people are underestimating just how good the 5080 will be. Assuming the 5090 really is only about 25-30% faster than the 4090 considering the core count difference is around a 33% increase for the 5090 over the 4090 (of which architectures rarely scale linearly in terms of core count increase too) and the chart [NVIDIA has given us shows about a 27% performance increase in RT Far Cry 6](https://www.reddit.com/media?url=https%3A%2F%2Fpreview.redd.it%2Fwq919yvsolbe1.png%3Fwidth%3D960%26crop%3Dsmart%26auto%3Dwebp%26s%3Ddbe652fc2d1e02ee2c74eff37251ab4b5bbad2f4). That means the 5090 is only about 50-55% faster than the 4080. That's not incredibly faster really, at least it's not like the jump in performance the 4090 gave over the 3090 and that was flagship vs last gen flagship, this is new gen flagship versus a whole tier lower from last gen. Kind of disappointing. Maybe the RT is holding the 5090's performance increase back and it's actually faster in pure raster, but I doubt it really, NVIDIA is probably showing best case scenarios of performance increase to really try and sell the GPU and as I said earlier the architectures rarely scale with core count increases, they tend to underperform.\n\nBut if we extrapolate the 5080 data, [we get 33% faster in Far Cry 6 RT for the 5080 over the 4080](https://www.reddit.com/media?url=https%3A%2F%2Fpreview.redd.it%2Fd5thkxvsolbe1.png%3Fwidth%3D2644%26format%3Dpng%26auto%3Dwebp%26s%3D79519f30f6366c139258a72feb316e32c98a9f01), assuming that maybe it's more like 20-30% because we should assume RT is a little faster than raster as probably thats where NVIDIA is getting big perf increases architecturally. So let's say it's 25% faster in raster, that puts us a little faster than the 4090, +/- 5-10%, probably more like 5%.\n\nThat leaves about a 20-25% performance gap between the 5090 and the 5080. Honestly, the 5080 is a no brainer at that point, half the price for around 80% the performance. There might not be room for a 5080 Ti in terms of performance, but there might be for VRAM.\n\nI mean just think about it, if they do make a 5080 Ti it would have to bring something to the table to justify the higher pricing, the gap in performance is kind of pointless for the price increase. With 40 series there really wasn't anything NVIDIA could give you to justify moving up, if you wanted more VRAM, paying $1599 for the 4090 versus the $1199 of the 4080 was kind of justified but only because the 4080 was priced so high to begin with. The pricing gap with 40 series just wasn't there to do a bigger VRAM card like a 4080 Ti and slot it in the product stack. If they did, what would it be? $1399? So they really couldn't do a 4080 Ti in the 40 series, not unless they bumped down the 4080 to $999 (which they did eventually with the 4080 SUPER but it took 14 months to do that) and tried to make a 4080 Ti at $1299 with 24GB of VRAM. But don't forget NVIDIA's original plan was to have a 4080 12GB and a 4080 16GB. The 4080 12GB was really a different die completely, which later became the rebranded 4070 Ti, neither of which were GB203. NVIDIA eventually also took all the \"bad\" AD102 dies and used them in China as the 4090D or as the RTX 5880 Ada, RTX 5000 Ada or L20's, some even ended up as 4070 Ti SUPERs (probably the absolute worst dies).\n\nSo the only justifiable reason for a 5080 Ti this gen is a VRAM increase and they could slot it in at $1499 with 24GB of VRAM becase to move a tier up in VRAM you have to spend double and buy a 5090. So I think that's what NVIDIA has done, they have priced the 5090 with a large enough gap to give themselves some room to slot in a 5080 Ti because last gen they really couldn't.",
      "Except with no FE, it will be priced too close to the 5080 FE not to just up a tier?",
      "Wait like two weeks and then find out. Nothing isn't going anywhere and no need to waste the time wondering. Pretty easy to make a close calculations based by the released full specs.",
      "Manual frame counting on yt video capped at 60?..",
      "I really don't think these cards are gonna be so unobtainable at MSRP that spending an extra $250 to get the next card up suddenly seems like the best option.",
      "lol this is what I don't understand, it's like upgrading to the new iphone everytime they announce one. You don't need to upgrade every time new tech exists especially when they are incremental. Jesus christ. \n\n5xxx generation is not mean't for 4xxxx owners",
      "This has seemed very likely to me the whole time.  If it were as strong as the 4090 it would trigger the Chinese import ban.  And nvidia is no longer in the business of selling +50% performance for the same price gen-over-gen. Incremental performance improvements that mostly track with price increases are way more typical.",
      "I know in the grand scheme the difference is minimal. But just on principle, the 5080 not matching the 4090 would be so annoying. Are gen on gen increases really that dead? The gap between the 4080 and 4090 is not that much, it just seemed a given that the next 80 class would overtake this. I'm going to cope and hold onto the FC6 benchmark.",
      "DF slowed it down for exactly this reason",
      "Price scaling linearly with performance to me is fucking insane, you'll end up at a price point in the future where nobody can even buy the cheapest stuff.",
      "arrest vase marry fall imagine political strong paint fade abounding\n\n *This post was mass deleted and anonymized with [Redact](https://redact.dev/home)*",
      "These people do not care. Reality doesnt matter to them. So they think that nVidia can just increase performance by 50% on the same node. Just with magic and unicorns.",
      "It was the 4080 super with 3-5% advantage ^^",
      "How is the number of models a source for the availability of the cards?\n\nFor all we know, they will only make 10 of each model?",
      "We already have a few in this thread.\n\n***18% improvement is incredible!***",
      "Nope, fanboys will convince you that the stack is fine, you should compare it to the non-super versions and 90 class card should be 2x the 80 card’s specs."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "top",
    "matched_keywords": [
      "rtx 4090",
      "4090",
      "rtx4090"
    ],
    "title": "Bios update for 4090?",
    "selftext": "Hello,\n\nI just installed a brand new 4090. I have the  ASUS TUF Gaming GeForce RTX 4090 OC Edition. I went to Asus website and i noticed that they have a bios update tool on there for my GPU. Do i need to use this to update the bios on the card?\n\nI feel reluctant to install that. I have downloaded the Nvidia driver and installed it. Everything works fine. \n\nI have never had to use any bios updater tool on previous GPU i have installed so i feel a little confused about what this is about.\n\nHere is the direct link to the bios updater tool. [Asus bios installer tool](https://www.asus.com/us/motherboards-components/graphics-cards/tuf-gaming/tuf-rtx4090-o24g-gaming/helpdesk_bios/?model2Name=TUF-RTX4090-O24G-GAMING) if you need more information. \n\nThanks.",
    "comments": [
      "Don’t need it for gaming. If you have a 4090 for MI/compute then you probably already know if you need ECC.",
      "It says it is to fix an issue where ECC can't be enabled. If you don't use ECC or don't have problems enabling it, then you can ignore the update.\n\nECC = memory correction, in case you don't know.",
      "Don't want to void your warranty if you update (asus joke). Jokes aside i updated my tuf 4090 no issue. But like everyone said, no need unless using ECC.",
      "Then it’s safe (and probably best) to leave it be.",
      "Thanks guys, I don’t use ecc, this is for gaming only.",
      "Lol Asus is not in good spot now….but all joking aside they make great video cards.",
      "it is usually to enable resizable bar.",
      "Just pray you don't need to RMA anything.",
      "Yeah I will not mess with it, Thank you.",
      "Yup. Wouldn't even tell me an approximate cost to fix a bent pin on a brand new mobo with a single bent pin, which I think was a manufacturer's defect. Last asus product I buy, which considering my last mobo and gpu plus my current one will end up costing them."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "top",
    "matched_keywords": [
      "4090",
      "rtx4090"
    ],
    "title": "No white LED on my RTX4090 when using cablemod instead of nvidia adaptor?",
    "selftext": "Computer boots fine, but there's no white led? Im using the ASUS TUF OC 4090 RTX. What does the white LED mean?",
    "comments": [
      "If you are referring to the diode next to the power port. On the original cable, with a working graphics card, it's not illuminated either. And it rarely lights up, I honestly don't even know why.  Card 4090 Aorus Master",
      "What do you mean about white led? There is a RED led on my TUF when computer power is off but no leds at all when it's started.",
      "To clarify, I had a white led indicator on my GPU when the computer was off but power on from the wall, with the stock NVIDIA adaptor.\n\nBut when I swapped to cablemod no LED",
      "The small white LED next to the power cable is a power  indicator, it only lights up if there is a problem with your power supply and the GPU is not receiving proper power. \n\nI believe in the TUF model its red? and lights up during boot similar to the indicator lights on most motherboards.",
      "To my knowledge, I believe the cards light up red if there is an issue. If you don't see the LED I believe that means everything is correct, but you should confirm this with ASUS support directly to be on the safe side. Also, double check the connector and ensure it is fully seated as per our image here: https://cablemod.com/12vhpwr/",
      "Same here I have a red led on my asus strix 4090 when pc is power off and turns off when I turn it on",
      "Unless they changed it from the 1080 Ti STRIX days, my card would have white LEDs on each port to state \"all power is good here.\"",
      "I'm  referring  to this small diode light [https://ibb.co/mz38KTd](https://ibb.co/mz38KTd)",
      "As others have stated the white led lights up when not supplied with sufficient power. I usually only see them during start for a sec as the psu turns on. If you don't see them it's good if you do just for a second during a power cycle it's also not an issue. If you are up and running and it is lit up it's a problem.",
      "My 4090 Strix's leds are red when not supplied with power.",
      "Thank you !",
      "when I read  \"If you don't see them it's good if you do just for a second during a power cycle it's also not an issue.\" this gave me peace from this anxiety. Mine does light up for 1 sec then goes away.",
      "Very welcome. :)"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "top",
    "matched_keywords": [
      "4090"
    ],
    "title": "RTX 5080 - OC on all cards to match 4090 performance/fps",
    "selftext": "After reviewing multiple videos and articles about the 5080, it seems like every 5080 card is able to overclock to gain an additional 10-15% performance increase bringing it within striking distance of the 4090. If this was Nvidia’s intention to allow the community to get this performance on all cards, why not just do it from the factory??\n\nInterested in your thoughts!\n\nhttps://www.techpowerup.com/review/?p=1\n\nhttps://youtu.be/fRxcaBszigw\n\n\nEdit: I am including a list of other sources I’ve found\n\nhttps://www.youtube.com/watch?v=IERjPCjnVnI\n\nhttps://youtu.be/D_sVNuOg74c\n\nhttps://youtu.be/x6pEZJT1uyI?t=1252\n\nhttps://youtu.be/Lqi_BbFgcMo?t=1055\n\nhttps://youtu.be/wnO-VxSWrl0?t=279",
    "comments": [
      "Shhh, that’s the 5080 Super coming soon",
      "How funny would it be if they sent reviewers binned gpus",
      "Because Overclocking to get 10%-15% gains isn't going to be guaranteed to be possible on all the cards. Hopefully most can, but some people will get unlucky.",
      "I expect 5080 Ti 20 GB with 15% uplift. I can see all reviews and comments already that say \"this card should be RTX 5080 in the first place!!!!!\"",
      "Then you also need to OC the 4090. You won’t get 15% out of it but you’ll get something and you need to take that into account",
      "\"It seems like every -\" bro I heard that bull with 9800X3D and had to return my first unit because it would not budge from stock clocks.\n\nIt seems stupid but they have to ensure even bottom 1% of chips are stable on stock.",
      "IF THIS IS TRUE, WE TOTALLY THOUGHT OF THIS IDEA FIRST!!!",
      "Yeah I do think we'll see a 24GB 5080S next year with boosted clocks. It's still weird though that they are leaving basically 10% free performance on the table for the card. Especially because they had to have known that 5080 reception would be poor with it's mediocre uplift in performance.\n\nIf 5080 had a boost clock to 3GHz out of the box and came within 5% of a 4090 it would be much better received at launch.",
      "This reddit has a habit of casually advising $1000 product jumps.",
      "Yep. Luck of the draw when it comes to processors.\n\nMy I7-8700k isn't stable at 5 GHz even though most others are. Same with Graphics cards.",
      "**tl;dr - Not all 5080s are created equal, there are going to be some that can't handle** ***any*** **overclocking so nVidia just sets them all to that minimum spec where** ***all*** **of them are stable, not just most of them.**\n\nGPUs and CPUs are binned. What that means is they're the same chips, just some are crippled and those become the lower tier offerings. Chip manufacturing is hard, these things are extraordinarily complex, delicate machines and you have to get everything literally perfect. It's just a fact of the business that a lot, if not most, chips you make come out defective. Maybe some cores don't work, maybe it's unstable at full frequency or wattage. Good news is, if you just disable the defective parts or don't run them as hard then it works and is stable.\n\nSo GPU markers don't throw out their defective chips if they can salvage them. Instead they sort them into bins of performance. So you have your flagship tier, the fully functional chip. Then below that you come up with a performance level that slightly defective chips can still meet. So if a chip isn't good enough to be a 5090 you call it a 5080. But some 5080s are more broken than others, so you just disable more cores, downclock, etc. to bring the more functional ones down to the same level as the weakest 5080. Then for chips too defective to be 5080s you have the 5070, and so on.\n\nWhat this means is that you can often eek out more performance with most chips. You can push the frequency back up to what the chip can actually handle, sometimes you can even do things like re-enable disabled cores though that's only ever been the case on a handful of GPUs. But this all depends on how defective your chip was. If you're lucky, it's near the top of the bin and was just artificially crippled. If you're unlucky, everything was disabled and toned down for a valid reason.",
      "Careful, you'll get downvoted by high IQ redditers who think ever 5080 is going to be some golden goose overclocking GPU.",
      "maybe not every 4090 which will be true of the 5080 too, but I think I get about 12-13% uplift with my 4090 when overclocked. 101-103fps in speedway to 114-115 fps.",
      "Guess I'll be overclocking my 4090 to try and match the power of a 5090.",
      "The more you buy the more you save",
      "Nonsense. Your GPU may be allocating that much but it's definitely not utilising that much.",
      "What games do you play? The X3D cpus are a whole different beast, I went from a 10900k which is obviously quite a bit faster than yours and even that made a ridiculous difference in almost every game. \n\nObviously if you mainly play Stardew Valley and Runescape, then you're right.",
      "rtx 4000 series ocs much worse compared to 5000 from what we have seen so far",
      "I agree, this would have drastically help with the initial acceptance of the card by reviewers",
      "I’m guessing nvidia lowered the clocks to keep power consumption down? Wondering if there will be some headroom with the 5070ti."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "top",
    "matched_keywords": [
      "rtx 4090",
      "4090"
    ],
    "title": "GeForce RTX 5090 Review Megathread",
    "selftext": "# GeForce RTX 5090 Founders Edition reviews are up.\n\nhttps://preview.redd.it/3568lwrnwqee1.jpg?width=3840&format=pjpg&auto=webp&s=30ca4f255f94899838a70ab1168949437d3e03fd\n\n# Below is the compilation of all the reviews that have been posted so far. I will be updating this continuously throughout the day with the conclusion of each publications and any new review links. This will be sorted alphabetically.\n\n# Written Articles\n\n# [Babeltechreviews](https://babeltechreviews.com/nvidia-geforce-rtx-5090-founders-edition-review/)\n\n>For the Blackwell RTX 50 series launch, NVIDIA strategically chose to introduce their flagship model first, launching the GeForce RTX 5090 ahead of other models to set a high benchmark in performance. Following this release, other models like the RTX 5080 and RTX 5070 are set to be launched, all of which we assume will also be impressive with DLSS 4 and their new design. The RTX 5090 remains the pinnacle in terms of raw power and capabilities and is in a class of its own, alongside its high price tag.\n\n>The NVIDIA GeForce RTX 5090 Founders Edition’s powerful performance make it an essential upgrade for enthusiasts and professionals aiming to push the limits of what’s possible in their digital environments. Purists will not enjoy DLSS 4 and will want a much larger raw performance jump, but for those that do the performance uplift will make you drop your jaw just like it did to ours. We remember titles like Hogwarts Legacy having performance issues at launch and with DLSS 4 enabled we saw incredibly high gains of 301.6 AI generated FPS performance difference over its raw power. Nothing can replace proper optimization but expanding the capabilities of a game to perform in such large amounts is amazing.\n\n# [Digital Foundry Article](https://www.eurogamer.net/digitalfoundry-2025-nvidia-geforce-rtx-5090-review)\n\n# [Digital Foundry Video](https://www.youtube.com/watch?v=Dk3fECI-fmw)\n\n>Going into this review, it was clear that there was some trepidation that the RTX 5090 wouldn't offer enough of a performance advantage over its predecessor when it comes to raw frame-rates, ie without the multi frame generation tech that Nvidia leaned heavily on in its pre-release marketing. These are justifiable concerns - after all, there's no die shrink to accompany this generation of processors, and pushing more power can only get you so far.\n\n>Thankfully - for those that want to justify upgrading to a $2000+ graphics card - the beefier design and faster GDDR7 memory do deliver sizeable gains over the outgoing 4090 flagship, measured at around 31 percent on average at 4K. The differentials are understandably smaller when you look at lower resolutions - just 17 percent at 1080p, though anyone considering the 5090 is probably unlikely to be rocking a 1080p display. Nvidia, Intel, AMD and Sony have all spoken about the slowing progress in terms of silicon price to performance, and we can see why all four companies are now [looking to machine learning](https://www.eurogamer.net/digitalfoundry-2024-sony-ps5-pro-tech-interview-with-mark-cerny-and-mike-fitzgerald) technologies to shore up generational advancements.\n\n>Speaking of which, DLSS 4's multi frame generation is an effective tool for pushing frame-rates - though arguably not *performance* to higher levels. On the RTX 5090, it's best used along similarly high-end 4K 144Hz+ monitors, so it's no surprise that Nvidia and its partners ensured that reviewers had access to 4K 240Hz screens for their testing. If you're lucky enough to be in that situation, you can use MFG to essentially max out your monitor's refresh rate, with a choice of 1x, 2x or 3x frame generation.\n\n>There's of course a trade-off in terms of latency, but it's smaller than you might think - and once you've already enabled frame generation, knocking it up an extra level has only a small impact on thos latency figures. For example, in [Cyberpunk 2077](https://www.eurogamer.net/games/cyberpunk-2077) with RT Overdrive (path tracing), we saw frame-rates go with 94.5fps with DLSS upscaling to 286fps when adding 4x multi frame generation, a \\~3x multiplier at the cost of \\~9ms of added latency (26ms vs 35ms). If you have a 4K 240Hz monitor, that might be a trade worth taking - and of course, you're more than free to ignore frame generation and knock back other settings instead to get performance to a level you're happy with.\n\n# [Guru3D](https://www.guru3d.com/review/review-nvidia-geforce-rtx-5090-reference-edition/)\n\n>The RTX 5090 features an advanced rendering engine that pushes past previous limits with the help of its  21,760 CUDA cores. This means smoother and faster gameplay with more realistic environments, creating an immersive experience. The RTX 50 series introduced a new generation of Ray tracing and Tensor cores. These aren’t just numbers on a spec sheet – they represent a leap in efficiency and power. Located close to the shader engine, these cores work tirelessly to deliver distinctive outputs. Even though Tensor cores can be tricky to measure, their impact is unmistakable, especially when paired with DLSS3.5 and new DLSS4 with MFG  technology that delivers impressive results. The GeForce RTX 5090 is not just an enthusiast-class card; it's a versatile powerhouse. Whether playing games at 2K (2560x1440) or better yet, game at 4K (3840x2160), it offers superlative performance at every resolution. This makes it an outstanding choice for gamers who seek both quality and speed, transporting them into new realms of interactive entertainment\n\n>Depending on the game title this value can greatly differ! However, on average you're looking at 25% maybe 30% more traditional rendering performance. The thing is though, NVIDIA has invested a lot of the transistor budget into AI, Deeplearning and Neural shading. We've presented the numbers with DLSS4 and when you enable frame generation mode at 4x, the performance is astounding. The reality is that we are reaching physical limits where traditional methods of increasing performance are becoming harder than ever. Chips would have to grow even larger, power consumption would skyrocket, and costs would soar. Imagine a future where every attempt to push technology further leads to larger, more power-hungry chips that become increasingly expensive. As we encounter these boundaries, think creatively and seek new solutions. Instead of following a path that leads to dead ends, this challenge invites us to innovate and discover groundbreaking ideas such as DLSS4 and MFG.\n\n>If you factor out pricing and energy consumption, it's gonna be hard to not be impressed with the GeForce RTX 5090. The card drips and oozes performance and it all packs into a two-slot form factor. On the traditional shader rasterizer part, it's still a good notch faster than RTX 4090, however, if you are savvy with technologies like DLSS4 offers, the sky is the limit. We do hope to see more backwards compatibility with DLSS 4 so that older games will get this new tech included as well. DLSS4 is not perfect though, yes butter smooth, but in Alan Wake 2 for example the scene rendered was fantastic but we; see birds flying over in the sky leaving a weird hale trail. The scene was otherwise very nice though.  The Blackwell GPU architecture of the 5090 demonstrates proficient performance. It boasts about 1.25 to sometimes 1.50 times the raw shader performance compared to its predecessor, along with enhanced Raytracing and Tensor core capabilities.\n\n# [Hot Hardware](https://hothardware.com/reviews/nvidia-geforce-rtx-5090-review)\n\n>NVIDIA's GeForce RTX 5090 is the fastest, most powerful, and feature-rich consumer GPU in the world as of today, period. There’s no other way to put it. The NVIDIA GeForce RTX 5090 Founders Edition card itself is also a refined piece of hardware. To design a card that offers significantly more performance than an RTX 4090, at much higher power levels, in a roughly 33% smaller form factor is no small feat of engineering. The card also looks great in our opinion. On its own, the GeForce RTX 5090 is currently unmatched in the consumer GPU market – nothing can touch it in terms of performance, with virtually any workload – AI, content creation, gaming, you name it.\n\n>It's not all sunshine and rainbows, though. In many cases, the GeForce RTX 5090 offered nearly double the performance of its predecessor (RTX 3090) when it debuted, at lower power, while using the exact same settings and workloads. If you compare the GeForce RTX 5090 to the RTX 4090 at like settings, however, the RTX 5090 is “only” about 25% - 40% faster and consumes more power. The RTX 5090’s $1,999 MSRP is also significantly higher than the 4090’s $1,599 price tag. Considering the Ada and [Blackwell GPUs](https://hothardware.com/reviews/nvidia-rtx-blackwell-architecture-overview) at play here are manufactured on the same TSMC process node, NVIDIA was still able to move the needle considerably, but the GeForce RTX 5090 doesn’t represent the same kind of monumental leap the RTX 4090 did when it launched, if you disregard its new rendering technologies at least.\n\n>You can’t disregard those new capabilities, though. Neural Rendering, DLSS 4 with multi-frame generation, the updated media engine, and all that additional memory and memory bandwidth all have to be taken into consideration. When playing a game that can leverage Blackwell’s new features, the GeForce RTX 5090 can indeed be more than twice as fast as [the RTX 4090](https://hothardware.com/reviews/nvidia-geforce-rtx-4090-gpu-review).\n\n>The use of frame generation has spurred much discussion since its introduction, and we understand the concerns regarding input latency and potential visual artifacts that come from using frame-gen. But the fact remains, using AI and machine learning to boost game and graphics performance in the most effective and efficient way forward at this time. Moving to more advanced manufacturing process nodes doesn’t offer the kind of power, performance and area benefits it once did, so boosting performance must ultimately come mostly from architectural and feature updates. And everyone in the PC graphics game is turning to AI. We specifically asked about the importance of traditional rasterization moving forward and were told development is still happening, and it will remain necessary for “ground truth” rendering to train the models, but ultimately AI will be generating more and more frames in the future.\n\n# [Igor's Lab](https://www.igorslab.de/en/nvidia-geforce-rtx-5090-founders-edition-review-the-600-watt-powerhouse-in-gaming-and-lab-tests/)\n\n>The GeForce RTX 5090 delivered impressive results in practical tests. The card achieved significantly higher frame rates in Full HD, WQHD and Ultra HD compared to the RTX 4090, especially with DLSS and ray tracing support enabled. The multi-frame generation enables consistent frame pacing and reduces noticeable latency, which is particularly beneficial in fast and dynamic gaming scenarios. The improvements in patch tracing and ray tracing ensure a more realistic representation of complex scenes. Games such as Cyberpunk 2077 and Alan Wake 2 visibly benefit from the technological advances and show that the Blackwell architecture has the potential to smoothly display the most demanding graphic effects.\n\n>The image quality achieved by the Transformer models in DLSS 4 is another important aspect. Where previously a clear trade-off had to be made between performance and quality, DLSS 4 combines both in an impressive way. Most notably, the new Performance setting offers almost the same visual quality as previous Quality modes. This is achieved through advanced AI-powered models that capture both local details and global relationships to produce a near-native image representation. The smooth and detailed rendering at significantly higher frame rates shows that DLSS 4 is an essential part of the RTX 5090, further underlining its performance. There will be a detailed practical test on this from our monitor professional Fritz Hunter.\n\n>In my opinion, the GeForce RTX 5090 is an impressive graphics card that shows just how far GPU technology has come. The new features in particular, such as DLSS 4 and Transformer-supported image optimization, set new standards. The performance of this card is simply breathtaking, be it in games in Ultra HD with active patch tracing or in demanding AI-supported applications. It is remarkable how NVIDIA has managed to find the balance between graphical excellence and innovative technologies. Another outstanding aspect is the ability of DLSS 4 to achieve an image quality that is almost indistinguishable from native resolutions, while at the same time increasing performance. The change from “Quality” to “Performance” as a standard option is like a revolution in the way we perceive image enhancement. The smooth display, combined with an incredible level of detail, takes the gaming experience to a new level.\n\n# [KitGuru Article](https://www.kitguru.net/components/graphic-cards/dominic-moass/nvidia-rtx-5090-review-ray-tracing-dlss-4-and-raw-power-explored/)\n\n# [KitGuru Video](https://www.youtube.com/watch?v=8wEXrZSnsRM)\n\n>Much was made of the performance ahead of launch, people were breaking out rulers and [pixel counting Nvidia's bar charts](https://www.reddit.com/r/nvidia/comments/1hvvrqj/50_vs_40_series_nvidia_benchmark_exact_numbers/), but after thorough testing today we can confirm native rendering performance has increased in the ballpark of 30% over the RTX 4090 when testing at 4K. That makes the RTX 5090 64% faster on average compared to AMD's current consumer flagship, the RX 7900 XTX, while it's also a 71% uplift over the RTX 4080 Super. Ray tracing also scales similarly, given we saw the exact same 29% margin over the RTX 4090 in the eight RT titles we tested.\n\n>Those are the sort of performance increases you can expect at 4K, but the uplift does get progressively smaller as resolution decreases. Versus the RTX 4090, for instance, we saw smaller gains of 22% at 1440p and 18% at 1080p. Now, I don't expect many people will be gaming at native 1080p on an RTX 5090, but it's worth bearing that in mind if you'd typically game with DLSS Super Resolution. After all, using its performance mode at 4K utilises a 1080p internal render resolution. Clearly this is a card designed for 4K – and perhaps even above – but that performance scaling at lower resolutions could be something to bear in mind.\n\n>Of course, whether or not you are impressed by those generational gains depends entirely on your perspective – an extra 30% over the 4090 could sound great, or it could be a disappointment. The main thing from my perspective as a reviewer is to give you, the reader, as much information as possible to allow you to make an informed decision, and I think I have done that today.\n\n>Gamers do get the extra value add of DLSS 4, specifically Multi Frame Generation (MFG), which is a new feature exclusive to the RTX 50-series. I spent a fair bit of time testing MFG as part of this review and I think if you already got on with Frame Generation on the RX 40-series, you'll probably find a lot to like with MFG. It's been particularly useful in enabling 4K/240Hz gaming experiences that wouldn't otherwise be possible – such as high frame rate path tracing in Cyberpunk 2077 – and with the growing [4K OLED monitor segment](https://www.kitguru.net/components/matthew-wilson/ces-2025-leo-gets-a-closer-look-at-new-msi-oled-monitors-dual-system-case-and-more/), that's certainly good news.\n\n>However, it's definitely not a perfect technology as the discerning gamer will still notice some fizzling or shimmering that isn't otherwise there, while latency scaling is still backwards compared to what we've come to expect – in the sense that latency actually *increases* as frame rate increases with MFG, rather than latency decreasing. That means some will find it problematic as the *feel* doesn't always match up to the visual fluidity of the increased frame rate.\n\n>It is great to see Nvidia is improving other aspects of DLSS, though, with its new Transformer-based models of Super Resolution and Ray Reconstruction. Not only do these improve things like ghosting and overall level of detail compared to the previous Convolutional Neural Network (CNN) model, but this upgrade actually applies to *all* RTX GPUs, right the way back to the 20-series. There's even a possibility that Multi Frame Gen [might come to older cards](https://www.kitguru.net/gaming/joao-silva/nvidia-multi-frame-generation-could-come-to-rtx-30-series-gpus/) given that Nvidia hasn't explicitly ruled it out, but personally I'd be surprised to see that happen given it currently acts as an incentive to upgrade to the latest and greatest.\n\n>We can't end this review without a discussion of Nvidia's Founders Edition design, either. This is a *highly* impressive feat of engineering, considering it's a mere dual-slot thickness yet it is able to comfortably tame 575W of power. We saw the GPU settling at 72C during a thirty-minute 4K stress test, while the VRAM hit 88C, which is slightly warmer but still well within safe limits. I love to see the innovation in this department, as when pretty much every AIB partner is slapping quad-slot coolers onto their 5090s, this is a refreshing step back to a time when GPUs didn't cover the entire bottom-half of your motherboard.\n\n# [LanOC](https://lanoc.org/review/video-cards/9132-nvidia-rtx-5090-founders-edition)\n\n>Performance for the new generation of cards in my testing had the RTX 5090 outperforming the RTX 4090 by around 32% which is right in line with the increase in CUDA cores for the card. There were some tests which saw an even bigger increase and the RTX 5090 was at the top of the chart across the board in every applicable test. What was even more impressive to me was the improvements with DLSS 4, the performance difference that it can make is sometimes shocking, but on top of that Nvidia has improved the smoothness and picture quality. At the end of the day, there wasn’t anything that I threw at the RTX 5090 that slowed it down, but if you do run into something that it can’t handle DLSS 4 is going to fix you right up. I did see some bugs in my DLSS testing, mostly when trying down resolutions, but I suspect some of those will be smoothed out once the updates are released. The biggest issue I ran into performance-wise was that a few of our benchmarks just wouldn’t run at all and they were all OpenCL. Nvidia is aware and is working to get support for those tests.\n\n>The big increase in performance without any change in manufacturing size does have the RTX 5090 having a significantly higher power consumption. I saw it pulling up to 648 watts at peak, combine that with today's highest-end CPUs and we are swinging back to needing high-wattage power supplies. Speaking of power, the power connection has been improved in a whole list of ways including moving from the original 12VHPWR connection to the changed design that is called 12V-2-6. It looks the same and all of the power supplies will still connect. But they have changed the pin heights to get a better connection and the sense pins are shorter and are more likely to catch when the plug isn’t connected all the way. On top of that Nvidia’s card design has recessed the connection down into the card and angled it to reduce any strain on the connection. They have also included a much nicer power adapter as well. All of that power does mean there is more heat but the double blow-through design handled it surprisingly well running similarly in temperatures to the RTX 4090 Founders Edition even with a thinner card design and a lot more wattage going through.\n\n# [OC3D Article](https://overclock3d.net/reviews/gpu_displays/nvidia-rtx-5090-founders-edition-review/)\n\n# [OC3D Video](https://www.youtube.com/watch?v=4oDxME5APa8)\n\n>Speaking of DLSS 4, that comes with the big ticket item in the Blackwell release, Multi Frame Generation. By refining the algorithm, and giving the card newer generations of hardware, the RTX 5090 can now generate three extra frames from a single frame rendered. As you could see from our results in Alan Wake II, Cyberpunk 2077 and Star Wars Outlaws, the effect is considerable. Cyberpunk 2077, with an open world, neon soaked, usually wet and thus reflective environment is about as good as games can look. Turn on path-tracing and it’s nearly real life. That path-tracing has a massive performance cost though. On the RTX 4090 you get 133 FPS @ 4K without it, 40 FPS with it.\n\n>Even turning DLSS and Frame Gen on doesn’t recoup all that, maxing out at 104. Click through the Multi Frame Gen settings on the RTX 5090 though and that number hits 241 FPS. With, and we cannot state this enough, NO loss in visual fidelity. That’s Cyberpunk at 4K with pathed ray-tracing turned on and a frame rate you’d require a very expensive monitor (4K@240Hz!) to appreciate fully. When CD Projekt Red’s Magnum Opus first appeared you could get smoother frame rates from a flipbook.\n\n>All of which returns us to the way we’ve tested how we have. Because in regular mode, with DLSS turned on and, at most, a single frame generated as is currently the way, the RTX 5090 is another big step forwards on the best of the current cards. Anything which can stomp on a RTX 4090 is crazy good. That the RTX 5090 Founders Edition can do that, and then has much further to go with the benefits of MFG, makes any claims about it being a purely software-based improvement look as ill-informed as they do.\n\n>Already that’s more than enough to make the Nvidia RTX 5090 Founders Edition a Day One recommendation to anyone serious about their gaming. We haven’t even mentioned the crazy low latencies – and thus higher KD ratio – of the upgraded Reflex 2 technology. Or RTX Neural Faces that can convert a 2D picture into a 3D character. We’ve not discussed, because it’s embryonic, the potential of the AI powered NPCs with the Nvidia Ace technology. Or the extra broadcast features, faster encoding and decoding, and all the AI calculation benefits having this much power at your disposal can bring.\n\n>Simply put, the Nvidia RTX 5090 has coalesced all the current thinking on AI, performance, sharpness, and generative content into a single card that blows the doors off anything on the market. It’s the future, today.\n\n# [PC Perspective](https://pcper.com/2025/01/nvidia-geforce-rtx-5090-founders-edition-review/)\n\n>Well, NVIDIA has topped NVIDIA. Once again, and with zero competition at the high end, GeForce reigns supreme. And while raster performance has risen, DLSS 4 is the star of the show with the RTX 50 Series, now supporting up to ***four*** generated frames per rendered frame (!) if you dare. Yes, the price for NVIDIA’s flagship has risen again, from $1599 to $1999 this generation, but those who want the fastest graphics card in the world will surely buy it anyway.\n\n# [PC World Article](https://www.pcworld.com/article/2585806/nvidia-geforce-rtx-5090-review.html)\n\n# [PC World Video](https://www.youtube.com/watch?v=_J5wDq2ba2E)\n\n>The GeForce RTX 4090 stood unopposed as the ultimate gaming GPU since the moment it launched. No longer. The new Blackwell generation uses the same underlying TSMC 4N process technology as the RTX 40-series, so Nvidia couldn’t squeeze easy improvements there. Instead, the company overhauled the RTX 5090’s instruction pipeline, endowed it with 33 percent more CUDA cores, and pushed it to a staggering 575W TGP, up from the 4090’s 450W. Blackwell also introduced a new generation of RT and AI cores.\n\n>Add it all up and the RTX 5090 is an unparalleled gaming beast — though the effects hit different depending on whether or not you’re using RTX features like ray tracing and DLSS.\n\n>In games that *don’t* use ray tracing or DLSS, simply brute force graphics rendering, the RTX 5090 isn’t much more than a mild generational performance upgrade. It runs an average of 27 percent faster in those games — but the splits swing wildly depending on the game: *Cyberpunk 2077* is 50 percent faster, *Shadow of the Tomb Raider* is 32 percent faster, and *Rainbox Six Siege* is 28 percent faster, but *Assassin’s Creed Valhalla* and *Call of Duty: Black Ops 6* only pick up 15 and 12 percent more performance, respectively.\n\n>Much like DLSS, DLSS 2, and DLSS 3 before it, the [new DLSS 4 generation](https://go.skimresources.com/?id=111346X1569483&xs=1&url=https://www.nvidia.com/en-us/geforce/news/dlss4-multi-frame-generation-ai-innovations/&xcust=2-1-2585806-1-0-0-0-0&sref=https://www.pcworld.com/article/2585806/nvidia-geforce-rtx-5090-review.html) is an absolute game-changer. Nvidia’s boundary-pushing AI tech continues to look better, run faster, and now *feel* smoother. It’s insane.\n\n>Nvidia made two monumental changes to DLSS to coincide with the RTX 50-series release. First, all DLSS games will be switching to a new “Transformer” model from the older “Convolutional Neural Network” behind the scenes, on all RTX GPUs going back to the 20-series.\n\n>More crucially for the RTX 5090 (and future 50-series offerings), DLSS 4 adds a new Multi Frame Generation technology, building upon the success of [DLSS 3 Frame Gen](https://www.pcworld.com/article/1662185/what-is-dlss-3-nvidia-geforce-rtx-ai-feature-explained.html). While DLSS 3 uses tensor cores to insert a single AI-generated frame between GPU-rendered frames, supercharging performance, MFG inserts *three* AI frames between each GPU-rendered frame (which itself may only be rendering an image at quarter resolution, then using DLSS Super Resolution to upscale that to fit your screen).\n\n>Bottom line: DLSS 4 is a stunning upgrade you *must* play around with to fully appreciate its benefits. It’s literally a game-changer, once again — though we’ll have to see if it feels *this* sublime on lower-end Nvidia cards like the more affordable RTX 5070.\n\n>In a vacuum, the RTX 5090 delivers around a 30 percent average boost in gaming performance over the RTX 4090. That’s a solid generational improvement, but one we’ve seen throughout history delivered at the same price point as the older, slower outgoing hardware. Nvidia asking for an extra $500 on top seems garish and overblown from that perspective.\n\n>While I wouldn’t recommend upgrading to this over the RTX 4090 for gaming (unless you’re giddy to try DLSS 4), it’s a definite upgrade option for the RTX 3090 and anything older. The 4090 was 55 to 83 percent faster than the 3090 in games, and the 5090 is about 30 percent faster than *that*, with gobs more memory.\n\n>At the end of the day, nobody needs a $2,000 graphics card to play games. But if you *want* one and don’t mind the sticker price, this is easily the most powerful, capable graphics card ever released. The GeForce RTX 5090 is a performance monster supercharged by DLSS 4’s see-it-to-believe it magic.\n\n# [Puget Systems (Content Creation Review)](https://www.pugetsystems.com/labs/articles/nvidia-geforce-rtx-5090-content-creation-review/)\n\n>Overall, the RTX 5090 is a beast of a card. Drawing 575 W, with 32 GB VRAM and a $2000 price tag (at least), it is overkill for many use cases. However, it excels at GPU-heavy workloads like rendering and provides solid performance improvements over the last-gen 4090 in many applications. There are some issues with software compatibility that need to be worked out, but historically, NVIDIA has been great about ensuring its products are properly supported throughout the software ecosystem.\n\n>For **video editing and motion graphics**, the RTX 5090 performs well, with 10-20% improvements across the board. In particular sub-tests, where the workload is primarily GPU bound, we see up to 35% performance advantages over the previous-generation 4090. However, the area we are most excited about is actually the enhanced codec support for the NVENC/NVDEC engines. In DaVinci Resolve, the H.265 4:2:2 10-bit processing was more than twice as fast as software decoding and exceeded even what we see from Intel Quick Sync. Even if the 5090 is more than a workload requires, we are excited to see what this means for upcoming 50-series cards.\n\n>In **rendering applications**, real-time and offline, the 5090 pushes its lead over previous-generation cards even further. It is 17% faster than the 4090 in our Unreal Engine benchmark while also offering more VRAM for heavy scenes. Offline renderers, such as V-Ray and Blender, score 38% and 35% higher than 4090, respectively. This more than justifies the $2,000 MSRP, especially factoring in the added VRAM. The lack of support for some of our normally-tested rendering engines is non-ideal, but we are hopeful NVIDIA will address that issue shortly.\n\n>NVIDIA’s new GeForce RTX 5090 is a monster of a GPU, delivering best-in-class performance alongside a rich feature set. However, it comes along with a huge price tag of $2,000 MSRP; ad likely higher for most buyers, as AIB cards will be a good bit more expensive than that. It also requires that your computer can support that much power draw and heat. If you need the most powerful consumer GPU ever made, this is it. Otherwise, we are excited by what this promises for the rest of the 50-series of GPUs and look forward to testing those in the near future.\n\n# [Techpowerup](https://www.techpowerup.com/review/nvidia-geforce-rtx-5090-founders-edition/)\n\n>At 4K resolution, with pure rasterization, without ray tracing or DLSS, we measured a 35% performance uplift over the RTX 4090. While this is certainly impressive, it is considerably less than what we got from RTX 3090 Ti to RTX 4090 (+51%). NVIDIA still achieves their \"twice the performance every second generation\" rule: the RTX 5090 is twice as fast as the RTX 3090 Ti. There really isn't much on the market that RTX 5090 can be compared to, it's 75% faster than AMD's flagship the RX 7900 XTX. AMD has confirmed that they are not going for high-end with RDNA 4, and it's expected that the RX 9070 Series will end up somewhere between RX 7900 XT and RX 7900 GRE. This means that RTX 5090 is at least twice as fast as AMD's fastest next-generation card. Compared to the second-fastest Ada card, the RTX 4080 Super, the performance increase is 72%--wow!\n\n>There really is no question, RTX 5090 is the card you want for 4K gaming at maximum settings with all RT eye candy enabled. I guess you could run the card at 1440p at insanely high FPS, but considering that DLSS 4 will give you those FPS even at 4K, the only reason why you would want to do that is if you really want the lowest latency with the highest FPS.\n\n>Want lower latency? Then turn on DLSS 4 Upscaling, which lowers the render resolution and scales up the native frame. In the past there were a lot of debates where DLSS upscaling image quality is good enough, some people even claimed \"better than native\"--I strongly disagree with that--I'm one of the people who are allergic to DLSS 3 upscaling, even at \"quality.\" With Blackwell, NVIDIA is introducing a \"Transformers\" upscaling model for DLSS, which is a major improvement over the previous \"CNN\" model. I tested Transformers and I'm in love. The image quality is so good, \"Quality\" looks like native, sometimes better. There is no more flickering or low-res smeared out textures on the horizon. Thin wires are crystal clear, even at sub-4K resolution! You really have to see it for yourself to appreciate it, it's almost like magic. The best thing? DLSS Transformers is available not only on GeForce 50, but on all GeForce RTX cards with Tensor Cores! While it comes with a roughly 10% performance hit compared to CNN, I would never go back to CNN. While our press driver was limited to a handful of games with DLSS 4 support, NVIDIA will have around 75 games supporting it on launch, most through NVIDIA App overrides, and many more are individually tested, to ensure best results. NVIDIA is putting extra focus on ensuring that there will be no anti-cheat drama when using the overrides.\n\n# [The FPS Review](https://www.thefpsreview.com/2025/01/23/nvidia-geforce-rtx-5090-founders-edition-video-card-review/)\n\n>There is a lot to unpack in regards to the NVIDIA GeForce RTX 5090, and GeForce RTX 50 series from NVIDIA. A lot of technologies have been debuted, and there are a lot of features to test that we simply cannot do in one single review. In today’s review, we focused on the gameplay performance aspect of the GeForce RTX 5090.\n\n>We focused on the GeForce RTX 5090 performance, so subsequent reviews will focus on the rest of the family, and we’ll have to see how they fit into the overall opinion of the RTX 50 series family this generation. For now, we can look at the GeForce RTX 5090 as the flagship of the RTX 50 series, and what it offers for the gameplay experience at a steep price of $1,999, a 25% price bump over the previous generation GeForce RTX 4090.\n\n>If we look back at the average performance gains we saw in just regular raster performance, we experienced performance that ranged from 19%-48%, but there were a lot of common performance gains in the 30-33% range. We did have some outliers that were lower, and some higher, depending on the game and settings. We generally saw gains in the 30% region with Ray Tracing enabled, where scenarios were more GPU-bound.\n\n>We think one problem that is being encountered is that the NVIDIA GeForce RTX 5090 is becoming CPU-bound in a lot of games. The data tells us that perhaps even our AMD Ryzen 7 9800X3D is holding back the potential of the GeForce RTX 5090. Therefore, as newer, faster CPU generations are released, the GeForce RTX 5090’s performance advantage may increase over time. The GeForce RTX 5090 has powerful specifications, but the performance advantage we are currently seeing seems shy of what should be expected with those specifications. It may very well be the case that it is being held back, and it has more potential with better-optimized games or faster CPUs. Time will tell on that one.\n\n>As it stands right now, you should always buy based on the current level of performance, not what might happen. Therefore, at this time you are seeing about a 33% gameplay performance advantage average, but with a 25% price increase, making the price-to-performance value very narrow. The facts are, that the GeForce RTX 5090 has no competition, it does offer the best gameplay performance you can get on the desktop.\n\n# [Tomshardware](https://www.tomshardware.com/pc-components/gpus/nvidia-geforce-rtx-5090-review)\n\n>The RTX 5090 is a lot like this initial review: It's a bit of a messy situation — a work in progress. We're not done testing, and Nvidia isn't done either. Certain games and apps need updates and/or driver work. Nvidia usually does pretty good with drivers, but new architectures can change requirements in somewhat unexpected ways, and Nvidia needs to continue to work on tuning and optimizing its drivers. We're also sure Nvidia doesn't need us to tell it that.\n\n>Gaming performance is very much about running 4K and maxed out settings. If you only have a 1440p or 1080p display, you're better off saving your pennies and upgrading you monitor — and probably the rest of your PC as well! — before spending a couple grand on a gaming GPU.\n\n>Unless you're also interested in non-gaming applications and tasks, particularly AI workloads. If that's what you're after, the RTX 5090 could be a perfect fit.\n\n>The RTX 5090 is the sort of GPU that every gamer would love to have, but few can actually afford. If we're right and the AI industry starts picking up 5090 cards, prices could end up being even higher. Even if you have the spare change and can find one in stock (next week), it still feels like drivers and software could use a bit more time baking before they're fully ready.\n\n>Due to time constraints, we haven't been able to fully test everything we want to look at with the RTX 5090. We'll be investigating the other areas in the coming days, and we'll update the text, charts, and the score as appropriate. For now, the score stands as it is until our tests are complete.\n\n# [Computerbase - German](https://www.computerbase.de/artikel/grafikkarten/nvidia-geforce-rtx-5090-test.91081/)\n\n# [HardwareLuxx - German](https://www.hardwareluxx.de/index.php/artikel/hardware/grafikkarten/65361-die-geforce-rtx-5090-founders-edition-im-test.html)\n\n# [PCGH - German](https://www.pcgameshardware.de/Geforce-RTX-5090-Grafikkarte-281029/Tests/Reviews-Benchmarks-Vergleich-RTX-4090-1463971/)\n\n# [Elchapuzasinformatico - Spanish](https://elchapuzasinformatico.com/2025/01/nvidia-geforce-rtx-5090-founders-edition-review/)\n\n\\--------------------------------------------\n\n# Video Review\n\n# [Der8auer](https://www.youtube.com/watch?v=La4EdRPT_Mg)\n\n# [Digital Foundry Video](https://www.youtube.com/watch?v=Dk3fECI-fmw)\n\n# [Gamers Nexus Video](https://www.youtube.com/watch?v=VWSlOC_jiLQ)\n\n# [Hardware Canucks](https://www.youtube.com/watch?v=5TJk_P2A0Iw)\n\n# [Hardware Unboxed](https://www.youtube.com/watch?v=eA5lFiP3mrs)\n\n# [JayzTwoCents](https://www.youtube.com/watch?v=ulUZ7bf_MXI)\n\n# [KitGuru Video](https://www.youtube.com/watch?v=8wEXrZSnsRM)\n\n# [Level1Techs](https://www.youtube.com/watch?v=nryZwnVYpns)\n\n# [Linus Tech Tips](https://www.youtube.com/watch?v=Q82tQJyJwgk)\n\n# [OC3D Video](https://www.youtube.com/watch?v=4oDxME5APa8)\n\n# [Optimum Tech](https://www.youtube.com/watch?v=5YJNFREQHiw)\n\n# [PC World Video](https://www.youtube.com/watch?v=_J5wDq2ba2E)\n\n# [Techtesters](https://www.youtube.com/watch?v=srQHBeWnQzw)\n\n# [Tech Notice (Creators Benchmark)](https://www.youtube.com/watch?v=Ah0JxguHdp4)\n\n# [Tech Yes City](https://www.youtube.com/watch?v=Lv-lMrKiwyk=)",
    "comments": [
      "I am whelmed.",
      "As someone with a 30 series gpu that never expected to upgrade after only 1 gen and left potential 40 series buyers alone in 2022 and didn't judge their potential upgrades, id like to express that 4090 owners that ponder upgrading after 1 gen and then when they realize it's not worth it for them BUT their ego can't handle that there's a better gpu available, start make posts saying they're glad they won't be upgrading are annoying as fuck. We get it, you want the best at all times but now that you don't want to dish out the money for a smaller relative upgrade you want to shit on a product that would be a much bigger upgrade for everyone else that doesn't look to upgrade every generation.",
      "https://preview.redd.it/uk4qaluuiree1.png?width=845&format=png&auto=webp&s=7139c38c5162a46e822fac34e9298fa6b4a4d8ec\n\nFeels accurate",
      "RTX 4090 Ti indeed",
      "+25% cost for +25% the performance and +50% the pooooowwwweeerrrrrr",
      "In summary, 30% average uplift in 4K. Old games or UE5 games don't get any significant uplift so there is only a couple of examples in the gray zone like TLoU or Cyberpunk that experience a worthwhile \\~50% uplift.\n\nFor anyone on the 4090 there isn't any point to upgrading right now, besides a few exceptions there aren't enough games demanding enough to utilize the card's full potential so you'll only waste money trying to get it for scalped/paper launch prices.",
      "I like how everyone here is wondering if they should upgrade their 3090 or 4090. I am just trying to decide if I should upgrade my 1080.",
      "https://preview.redd.it/0s0q58ntzsee1.png?width=1018&format=png&auto=webp&s=4cd9ce969154258d47b6f511c7b3e28d9ee695d8\n\nYou're going to have to go water or you need a gargantuan case with half a dozen fans if you want to pair the 5090 with big air.",
      "Terrible coil whine. My number one takeaway",
      "We need real world testing!  wtf uses 1600 PSUs and open cases?\n\nPut the damn thing in a case (fractal north, lancool 7, etc) and then tell me noise, temps, wattage.",
      "It's a 4090TI good if moving from 3090, lower spec 40 series or older cards, pointless for 4090 owners.",
      "Yes, very sorry you will have to “keep your 4080”",
      "So 100%+ increase over a 3090 at 4K. I’m in.",
      "Damn, the FE is loud and hot according Techpowerup, might need to look at AIBs for this ! Always felt like two slots was pushing it with 600W GPU.",
      "Well it was near, the 1080Ti was 27% faster than the 1080\n\nThough the 5090 is faster than that vs the 4090",
      "the amount of 4000 series owners stroking each other to validate their purchases is wild lol",
      "One of the things that always bothered me about some sites is when they say “we are using the medium preset with medium ray tracing”. wtf…with a $2000 card you are testing medium? Turn everything on and let’s see.\n\nAlso I only perused the various articles but I want to see this compared to the 4090 with and without framegen. A lot of sites don’t seem to offer thorough results. They may do a CP2077 test but it’s one single chart. That game alone should be at least 3 charts at every resolution. Raster,  DLSS, frame gen.",
      "Are there any reviews for VR for the 5090 out there yet?  I haven't been able to find any.",
      "Own a 4080/4090 (not worth it) - as expected tbh, who upgrades every generation of iPhone? (but I'm old)\n\nOwn a 3090 or older - you will see a performance bump for the price. And hopefully after 4+ years since your last purchase, your finances have recoverd enough to be in a possition to asses if you want to spend to upgrade. \\[Hopefully for another 4 years to allow one's finances to recover\\]",
      "Everywhere else is saying around 75c and quiet fans, be curious to see why Techpowerup is getting different results. For a dual-slot cooler dissipating up to 600w that's insanely good. Obviously the coil whine is bad though..."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "top",
    "matched_keywords": [
      "rtx 4090",
      "4090",
      "rtx4090"
    ],
    "title": "Running an RTX4090 on a 13 year old PSU?",
    "selftext": "Many moons ago, Corsair released the [HX1000W PSU](https://www.corsair.com/us/en/Categories/Products/Power-Supply-Units/Professional-Series%E2%84%A2-HX1000%C2%A0%E2%80%93-80%C2%A0PLUS%C2%AE-Certified-Modular-Power-Supply/p/CMPSU-1000HX). I bought mine in 2009, and it has been running since through many, many builds (single card, SLI's, etc). It has been rock solid and never gave me any problems.\n\nI'm in the process of building a new PC right now, but am waiting for the newer ATX3.0 PSU's to come out. I already acquired an RTX 4090 and want to test it out.\n\nWould it be a terrible idea to plug an RTX 4090 into a 13-year-old 1000watt PSU? 🤔",
    "comments": [
      "I'd think it should be fine. It's no different from most people running it with an adapter cable.",
      "HX1000 gang. [2011](https://i.imgur.com/rgGpSg3.jpeg), [2015](https://i.imgur.com/nphgFne.jpg), [2017](https://i.imgur.com/8Kzawuq.jpg) [2021](https://i.imgur.com/cSWLf0R.jpg)\n\nUsing it pretty much 24/7 since 2010, I'm never turning my pc off unless I'm leaving town for more than a day. It powered a GTX 295, 2xGTX 580, GTX 690, 2xGTX 970 and A GTX 1080 Ti and I plan to use it for a RTX 4090 as soon as I can get my hands on any ASUS model. I've cleaned it from the inside a couple of times and all the capacitors looked good but I had to replace a noisy fan a few years ago. I feel like this thing will outlive me.",
      "No problem, as long as you've still got clean, stable output from it. I'm using an equally [well rated](https://overclock3d.net/reviews/power_supply/corsair_hx850w_850w_atx_psu/4) HX850W from 2009 in my system (not the flair rig), which is stuffed to the gills. No issues even at 100% load during bench sessions, although I have found myself looking at a potential replacement at some point due to improved efficiency on modern units and for full cable modularity.",
      "The newer ATX3.0 PSU are already out since couple of months",
      "Damn I bought the HX620W from the same series in 2008, the fan on mine died in 2019 but the unit still works fine.",
      "That’s what I’m talking about! :)\n\nI’ve had a similar setup of rigs as you throughout the years. My current GPU is a FTW3 1080ti. I nabbed a gigabyte 24gb-OC 4090. You have no concerns running a 4090 with your HX1000w?",
      "Not SFX/SFX-L. :/ waiting on the Asus Loki 1000w",
      "Nah, not really. I plan to undervolt it and I doubt it will actually consume more than 350W, not a big step up from a 250-300W 1080 Ti.",
      "Not like your HX is SFF either way",
      "I’m doing a new build in  smaller case that doesn’t fit ATX PSUs. It doesn’t make sense to buy an ATX PSU when I’ll have to get rid of it in 2 months.",
      "SFF build? I hope you are aware how fucking ginormous RTX 4090 is, it makes already huge RTX 3090 look cute.",
      "It’s a MFF case technically (>20L) but I need the additional clearance a SFF provides. Not my first rodeo :)"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "top",
    "matched_keywords": [
      "rtx 4090",
      "4090"
    ],
    "title": "ITX motherboard installed on a RTX 4090",
    "selftext": "",
    "comments": [
      "You probably could fit a whole ITX system on the 6090",
      "You got some motherboard on your GPU",
      "Joke's on you, the 6090 is going to be an integrated PSU/Motherboard unit that you slot your other components into.",
      "I'm personally waiting for the 5090 which will also function as a gaming desk.",
      "That doesn't sound like a bad idea tbh",
      "\"Look at me\n\nI am the motherboard now\"",
      "ITX format makes no more sense to me with these cards.",
      "https://twitter.com/9550pro/status/1572272657760153600?t=9ITqDyc3g_LzajkZf6F8Ow&s=19",
      "It does with a waterblock.",
      "I wouldn't be surprised if it's the future of PC's tbf, whole computer units built onto a big GPU.",
      "That will also keep your hands warm in a cold winter. Brilliant.",
      "Is Nvidia planning to build a gpu case for 5090 that will come with an air conditioner.",
      "Sure, but then be ~~really~~ ready to shell out 5 grand for GPU+barebone systems. More proprietary tech, closed down ecosystems and solely controlled supply chains. I'd rather hope for a polyopoly.",
      "> sounds reasonable\n\nUntil you see the price tag they'd probably slap on these things.",
      "They have their own linus now.",
      "Is there a spec limitation for how tall a GPU can be? Considering many will have something like a big ass Noctua tower cooler on their CPU, why not have something just as tall for the GPU? You could put 140mm fans on it while having the heatsink be tall but slimmer rather than just taking up more PCIe slot space and ever more length.",
      "They are all just circuit boards.",
      "are you kidding? it'll keep half the house warm at idle",
      "You're a circuit board",
      "ATX case standards set some limits, Intel and AMD boards have their own \"safe areas\" for CPU coolers also defined. Also when things go large, there are limits how many kilos of copper you can bolt on.\n\nIn general there is a point where adding more just doesn't work well and it is better to go with a waterpump and a separate radiator.\n\nFrankly personally starting to look at MO-RA3 as more and more sane option these days. Can get away with a lot smaller case with tiny waterblocks and ther just routing the problem out of the case completely. Only thing I worry about a bit is the whole mess of wiring the pump and the fans for it.. seems like bit of an arts-and-crafts project to get the extensions and make the cabling work out nicely in addition to the waterloop tubes."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "top",
    "matched_keywords": [
      "rtx 4090",
      "4090"
    ],
    "title": "The RTX 4090 is quite a beast",
    "selftext": "I had a GTX 970 which had served me well, although I was struggling to get decent frame rates in recent games, even on low settings. It died a few days ago, and I had enough, so I finally decided to upgrade my whole system.  Got the RTX 4090, Ryzen 7950x3D, Trident z-neo 64gb (2x32gb) 6000mhz CL30 etc. \n\nBut what impressed me most is the sheer brute force of the 4090. Sure, I had to pay 4 times more than my previous card, but I'm also getting more than 4 times the frame rates on resolution that I couldn't even dare to play on my previous card.  This thing is a beast. Couldn't even get stable 40 fps on the GTX 970 at 1080p in RDR2. And now getting over 80-110 fps on the 4090 at 4K. Impressive stuff. \n\n[https://i.imgur.com/ya11UOn.jpg](https://i.imgur.com/ya11UOn.jpg)",
    "comments": [
      "You went from a 970 to a 4090, that is a RIDICULOUSLY huge upgrade.",
      "Dude legit went from taking a bus to driving a ferrari.",
      "Fuck the bus dude went from camel to chiron",
      "We have the same setup. \n7950X3D and 4090 is the best hardware i ever bought, 4090 is superb.",
      "Hope RTX 5090 keeps the same expectations. Not that I'm gonna buy it, but I just love watching new GPU benchmarks lol.",
      "Just for reference a regular 980 is the base measurement that equals 100 OctaneBench score. The 4090 benches 1500 OB.",
      "Yes 4090 is truly a game changer. No need to tweak settings, just play. If something, you often need to frame limit your games lol.",
      "Bro went from a gtx970 to a rtx4090",
      "5090 will probably be about 50% faster than the 4090 based on the latest rumors and estimates. Pretty nice, although there's no such thing as too much GPU performance. :)",
      "Almost 16 times the details, there.",
      "He went from BMX to Falcon 9.",
      "The real question is will it be 100% more expensive than 4090 for 50% performance 😭",
      "Guy went through a GPU wormhole lol congrats!",
      "OP hang that 970 on the wall. that shit is hall of fame.",
      "i went from a 3090 to a 4090 and was impressed by the upgrade. I cant imagine how you felt! congrats",
      "Still it's extremely overpriced imo",
      "You still need to tweak settings for demanding games especially at 4k",
      "*todd howard wants to know your location*",
      "5800x3d is mostly keeping up with 4090 at 4k. I also don't see a reason to go over 144hz that my screen can support.",
      "That’s easily done globally from nvcp."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "top",
    "matched_keywords": [
      "4090"
    ],
    "title": "[Digital Foundry Article] Nvidia GeForce RTX 5070 review: DLSS 4 doesn't deliver 4090 performance",
    "selftext": "",
    "comments": [
      "https://preview.redd.it/recn3a5ioome1.jpeg?width=720&format=pjpg&auto=webp&s=c23dd66669736f95a8ba9d580509a96704d12bf1\n\nI really am not surprised but man Nvidia really missed the mark with this",
      "The fact regression is even possible relative to the 4070s is unbelievable imo. Feels especially bad for those that waited for this GPU, since the 40-series has become more expensive since. \n\nJust a raw deal, really",
      "They didnt miss the mark, the writing was on the wall since the 4000 series and the 5000 releases have been further evidence. They purposely released this crap and crafted this whole situation knowing people will still buy it.",
      "We'll look at it like this. The 50 series might end up faster and cheaper than the 60 series at this point. My 3070 about to be faster than a $2000 6080!",
      "![gif](giphy|10uct1aSFT7QiY)",
      "It's funny I went with a 4080 super for my new build last year and I was telling a friend and he was like why not wait for the 50 series cards I'm like bro after how shitty the pricing for the 40 cards went why risk it. Needless to say paying 2300 for a 4080 build feels pretty nice right now",
      "Whomp whomp.",
      "Literally in that boat right now, was waiting for a good 5080 to replace my 3070 and wow man... ruined my dreams of getting a 4k setup and now that i look for a good 4090 its somehow increased in price.",
      "With the exception of the 5090 the rest of the 5000 series is really just a 4000.01 series reboot",
      "This is the future proofing we did NOT ask for!",
      "Wait for AMD, it's likely better for cheaper",
      "LMAO, even the lie is another lie",
      "Oh wow. Who would have guessed.",
      "Not long after I bought my 4070S last January someone told me I should have waited for the 5070 \"In the Autumn\".  \n\nI still resent the shorter lifespan its 12gb FB will give it, but at least I've enjoyed a full year's use out of it already.",
      "Would this be a case for false advertising?",
      "Good call. After the 3000 and 4000 series, it pretty much guaranteed that releases are going to be the worst time to get a gpu, waiting till stock stagnated and drops in price.\n\nThe stupid fucking 5000 series hype meter was just too damn foreshadowing of how nvidia was going to launch this series... lol",
      ">> now that I look for a good 4090 its somehow increased in price. \n\n\nYeah the same 4090 i paid $2400 CAD taxes inc. is now at average list price of $2500 CAD before taxes. \n\nI had always hoped ^((coped)^) my purchase would age well, But I never could have imagined it would age this well this quickly.",
      "4070S owners represent!\n\nBought one myself last February in 2024 for MSRP, best purchase ever so far given how the 50 series is turning out.\n\nI'm also pretty sure 549 USD 5070s will also be unavailable for quite sometime to come, the ASP of these cards will be 600+ easily until stock stabilizes, and for those of us who got the 4070 Super last year for that amount of money, we've enjoyed pretty much the same performance 1 year in advance lmao.\n\nHeck, i've noticed the 5070 doesn't always match the 4070S either, losing out in certain games which is an absolute disgrace lol.",
      "Ah yes, the o'l over hype then under deliver",
      "Should be"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "top",
    "matched_keywords": [
      "rtx 4090",
      "4090"
    ],
    "title": "RTX 4090 started burning",
    "selftext": "My new graphic card started burning, what do i do now?\nI unplugged it straight away when it started burning.\n\nWhy have nvidia not officially annouced this yet?\n\nI actually ordered a new cable before it started burning, guess i gonna need to cancel my order.\nimage: [cable burned](https://ibb.co/qDZzHzC)\n\nUPDATE: Got a replacement or refund, gonna mount the new card vertical until new adapters are send out.\n\nAnyone that can confirm if this is i stallet correctly until i get my cablemod one.\nIt is 3 PCIe cables from PSU where one is being splitted into 2\nImages:\nhttps://ibb.co/DDWBBXC\nhttps://ibb.co/5M4YvGT\nhttps://ibb.co/PN6CZJd",
    "comments": [
      "I still can't believe Nvidia is silent on this",
      "Jensen is too busy joining random girls livestreams.",
      "[https://www.reddit.com/r/pcmasterrace/comments/ynobf8/jensen\\_shows\\_up\\_on\\_a\\_random\\_livestream\\_and\\_picks/](https://www.reddit.com/r/pcmasterrace/comments/ynobf8/jensen_shows_up_on_a_random_livestream_and_picks/)",
      "For those in the comment section blaming users for not plugging it in all the way/correctly, if this adapter is this sensitive to this error why hasn't it been solved/detected during Nvidia's/AIBs quality control. This is like buying a flagship phone only to find out it explodes with the slightest tug in the charging cable. I think it's a stupid question to ask what the user was playing/doing with their pc when the plug burned. It's a freaking graphics card. It's made to play games and/or for intensive 3D rendering it shouldn't matter what you are doing when it burned up. If you can't play games with your gpu without it burning then what's point.",
      "Holy shit this is one of the worse ones. The plastic housing is all melted and only the metal core is left.\n\nWow..",
      "I sense either a recall or class action lawsuit coming.",
      "I dont know what to say but as an advice for everyone is to hold off on buying the card until Nvidia comes out with a statement, dont convince yourself that you will not be affected and wont be next, the idea of being paranoid all the time is just awful.\n\nNobody knows the real issue here, even a native MSI PSU cable got melted, there is no guarantee that 3rd party cables will not melt either as its too early to tell, some people got away with 600W while others are having it melting at 450W, its a risk that no one should take especially when Nvidia is just avoiding to even comment on this and charging $1600+ premium for it.",
      "Wait, what?",
      "In 3 years time you'll get a check for $20.",
      "amazing you can spend 2,000 for a card and they cant even make a statement",
      "Why not both?",
      "People just keeps spending no matter how Nvidia fucks it up so it is what it is",
      "That was way less creepy than I expected",
      "https://preview.redd.it/hf6n9czwxmy91.jpeg?width=1634&format=pjpg&auto=webp&s=d677ffe0f1c1f053ccd24b8d6069aff26d343d3d\n\nplugged it back in for the image, just to be clear.",
      "What model aib",
      "https://preview.redd.it/u808q11pxmy91.jpeg?width=1634&format=pjpg&auto=webp&s=ccdab304ecd88e3c58df3055a35fc8a32a50b4cc\n\nplugged it in half way for a image. Does not fit anymore all the way",
      "this is actually kinda wholesome lol\n\nhe's even tearing up a bit when they start singing  AWW",
      "Good thing EVGA pulled out of this mess.",
      "I see nothing wrong with that vídeo. quite the opposite",
      "We need to burn Jensens Leather Jacket to show him how it feels"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "top",
    "matched_keywords": [
      "rtx 4090",
      "4090"
    ],
    "title": "[Gamers Nexus] NVIDIA GeForce RTX 4090 Founders Edition Review & Benchmarks: Gaming, Power, & Thermals",
    "selftext": "",
    "comments": [
      "It's breaking all the charts in the review. Crazy seeing 0.1% lows higher than other cards' averages.",
      "Double the performance of my 3080 10gb in rasterisation and RTX (no DLSS).\n\nThat's bloody insane. If it wasn't also double the price. Extremely exciting to see such a major uplift though.\n\nEdit 262% the price of the original 3080 MSRP in UK. Ludicrous pricing.",
      "The most shocking part of this whole review to me is that Tech Jesus actually liked the FE cooler.\n\nGood job Nvidia",
      "He had a recent video where a Nvidia engineer talked about the engineering of the cooler, would recommend watching.\n\nWhile the video is pretty cool and informative, you can get a sense of why EVGA threw in the towel: the Nvidia team is well funded with airflow models, have access to the specs and actual chip way before their partners.  Stuff like detailed hotspot data is something I doubt Nvidia's partners have access to at all.\n\nYou end up entering a race where the owner is in their finishing lap when you are on the starting line.",
      "Here we go. People will forget the insulting prices and this shit will sell out.\n\nRemember when people thought the 2080ti was crazy expensive?",
      "This card is insane in every aspect. From performance to pricing",
      "Even as someone who is very anti-Nvidia as of late, very impressive product. \n\nCan't say the engineers didn't nail this card, especially with the FE cooler. \n\nI hope AMD can compete with this come November as we *really* need the competition to stay alive in this space or there will be no pricing pressure here.",
      "Oh my god it has 0.1% lows that surpass the peak of the 3090 ti in some games",
      "That the _Stuttering_ from the 4090 is as good as the 3090ti in top situations",
      "So the rumored jump turned out to be true. Nice.",
      "> If they make all the data they need available to vendors\n\nYeah, I think Nvidia's long-term game plan doesn't really involve any of those.",
      "Even in size. That thing is stupid big.",
      "This damn thing is actually fast unlike the 2080ti",
      "Can't argue with the results, pretty impressive.",
      "Let's see Paul Allen's video card",
      "the lows and highs almost the same = CPU bottleneck. damn the 4090 so fast it needed faster cpus to truly flex",
      "Nvidias been increasing prices steadily for years now. We've went from the best cards costing 700usd in the pascal era to now costing 1600. How are you all ok with these insane prices?",
      "Generally, you have your average FPS and the lows or dips. What he means is that in some games, the lowest FPS the 4090 is getting is still higher than the average of the 3090 Ti which is insane.",
      "A part of me wishes AMD makes a graphics card twice the size of a 4090 where you need 2 PSUs to run it just for lols",
      ">You end up entering a race where the owner is in their finishing lap when you are on the starting line. \n\nYeah, but I'm betting in the future it's not really good for consumers. If they make all the data they need available to vendors, we might actually get creative and innovative cooling solutions."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "top",
    "matched_keywords": [
      "4090"
    ],
    "title": "4090 Suprim X (air cooled) benchmark in gaming vs silent mode - better results in silent mode, higher than suspected score. Thoughts?",
    "selftext": "",
    "comments": [
      "Looks like the 4090 score is actually pretty average for a Suprim X and the 5800x3d above average some, though I'm still very surprised the Suprim X performs better in silent than gaming."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "top",
    "matched_keywords": [
      "rtx 4090",
      "4090"
    ],
    "title": "GeForce 9500 GT in a Zotac RTX 4090 box. Oh how far we've come.",
    "selftext": "",
    "comments": [
      "POV: you just bought a 4090 from Newegg",
      "Back when XFX sold Nvidia cards.",
      "And there was a time when tech was getting smaller not bigger",
      "I laughed way too hard at this. Thank you.",
      "Back when the name \"video card\" made sense",
      "That is correct.",
      "I've had all kinds of issues. I don't buy from them anymore.\n\nEdit: For example, they had a bundle on ryzen cpu, mobo and ram. I got everything assembled and it turned out the mobo did not have a bios that supported the bundled cpu. It couldn't be updated without an older cpu. I contacted customer support and they said I was shit out of luck and they do not guarantee compatibility in their bundles.",
      "now it should be \"graphics engine\"",
      "I don’t get it, is Newegg not trustworthy, or something?",
      "Never had any problem with Newegg. Customer for 5+ years.",
      "Probably a noticeable upgrade. ; )",
      "My first XFX card caught fire.\n\nLiterally caught fire, not 'started smoking' I mean there was a solid pilot light's worth of flame.\n\nXFX's response? They didn't just overnight me a new card, they upgraded me two generations and then when they realized that 1x 7750 was worse than my previous 2x 5770s, he tossed another 7750 in for me to crossfire as well so I would lose out on nothing.\n\nAlso the guys' reaction when he saw the pictures was hilarious.\n\n\"Hol^ly shit it ACTUALLY _DID CATCH ON_ ^_FIRE_?!\"",
      "You vs the guy she told you not to worry about.",
      "One of my first cards was xfx, I loved it",
      "or \"rendering obelisk\"",
      "That’s one of the dumbest takes I’ve ever seen",
      ">the overall power consumption of GPUs isn't that different (save for models like the 6950XT or 4090) than older cards with much smaller coolers. \n\nNah, it's a lot higher in general. An entire high end system with an 8800GTX would pull around 300w in game, while my 3090 alone can pull more than 100W more than that.",
      "[newegg.ca](https://newegg.ca) bundled a 5600x with a 450W Corsair PSU during the height of the COVID related PC parts frenzy. Nobody is building a 5600x system with 450W lol. Yet it sold out.",
      "It's funny you think it was ryzen 5000. It was actually a 2700x, so they've clearly been fucking people over in the same way for a long time.",
      "You build a case around the GPU."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "top",
    "matched_keywords": [
      "rtx4090"
    ],
    "title": "will the rtx4090 have a connector for display port 2.0?",
    "selftext": "",
    "comments": [
      "According to this, no https://www.techpowerup.com/gpu-specs/geforce-rtx-4090.c3889",
      "Too bad. I guess we likely won't pass 48 gbps bandwidth gaming for 2 years and it'll likely be 4 + years until we have 80 gbps bandwidth gaming."
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "top",
    "matched_keywords": [
      "rtx 4090",
      "4090"
    ],
    "title": "RTX 4090's in stock on Central Computers shelves",
    "selftext": "",
    "comments": [
      "And they’re on NewEgg right now for retail. :) Fuck Scalpers.",
      "*4090s ARE ROTTING ON SHELVES!!!*",
      "Went to the grocery store and saw food on shelves. TERRIBLE VALUE",
      "$550 MSRP over the founders is bonkers \n\n\nCould literally buy a founders 4090 + a PS5 for the price of that card",
      "Wow…the white ROG in the flesh. Too bad about the price ($150 for white…sigh).",
      "Weird. I’m not seeing any “direct from Newegg” but the same third party sellers that were scalping before.",
      "I saw behind the door of the stock room at their Sunnyvale location two days ago and there were two or three stacks of ASUS 4090s literally from floor to almost the ceiling.",
      "Time to make a video about how no one wants the 4090 and they aren't selling. Also switching to AMD!",
      "OVER $2K lmaoooo",
      "Asus basically took a 4090 FE and said, we will add one fan and paint it white and charge you the price of a i9-13900k for it 🥴",
      "👀",
      "Yep. 4090s are a thing you can buy now.  Show me some 5090s on shelves.  Now that would be news.",
      "I wore a green polo to NVIDIA HQ and they took me to the back and let me pet the creature that lays the 4090s.",
      "At least Newegg has replacement-only policy now iirc.\n\nInterestingly both anti-consumer and  anti-scalper.",
      "Yeeah where are you? Not in the US they aren’t. Closest was a pny for 200 over. Most everything is like 2-2.5k",
      "This is funny because right now nvidia and food is a terrible vlaue",
      "Where I got my Suprim X on launch day. Online Order. Highly recommend Central Computers!",
      "Best computer store!\n\n![gif](giphy|fT3PPZwB2lZMk)",
      "2nd shipment arrived. Cards about to reach normal stock",
      "Lol \n\n“Confirmed! 5090 will be the official title!”\n\n“Leak performance numbers! 5 is better than 4!” \n\n“Dirty secret discover at NV’s office! One door is push instead of pull!”"
    ]
  },
  {
    "brand": "nvidia",
    "generation": "40",
    "tier": "top",
    "matched_keywords": [
      "rtx 4090",
      "4090"
    ],
    "title": "GeForce RTX 5080 Review Megathread",
    "selftext": "# GeForce RTX 5080 Founders Edition reviews are up.\n\nhttps://preview.redd.it/0b57tcm6vxfe1.jpg?width=3840&format=pjpg&auto=webp&s=ad230615d607bf9dd8a84e9abf0861c159b5cc42\n\n# Below is the compilation of all the reviews that have been posted so far. I will be updating this continuously throughout the day with the conclusion of each publications and any new review links. This will be sorted alphabetically.\n\n# Written Articles\n\n# [Babeltechreviews](https://babeltechreviews.com/rtx-5080-founders-edition-review/)\n\n>Upgrading to the new RTX 5080 from a 30 series GPU—or for those who simply demand peak performance—presents a clear decision. The price-to-performance ratio of the RTX 5080 is impressive, especially when viewed against the backdrop of NVIDIA’s previous generations or its current competitors. There is a uplift gen-over-gen of around 7-15% on average in raw power, when you consider DLSS 4 and its incredible uplift for max settings its really exciting. DLSS 4 is not perfect, however, and it cannot replace raw power for enthusiasts. The RTX 5080 also carries a higher price tag, albeit lower than the RTX 4080’s MSRP at $200 less. This is much better and the value it offers in enhanced performance, especially with advancements in ray tracing and AI-driven capabilities like DLSS 4, justifies the investment in our opinion.\n\n>We understand the inclination to wait for the more budget-friendly 70 and 80 class GPUs from the Blackwell generation, as these models often strike a balance between cost and performance, catering to the needs of the average gamer. However, for those seeking the pinnacle of current gaming technology, the RTX 5080 is unparalleled in its price range and class. It’s designed to deliver top-tier performance for years to come, making it an investment in future-proofing your gaming or creative setup. Ultimately, the decision to invest in such a high-end GPU depends on your specific needs and budget, but for those who prioritize leading-edge technology, the RTX 5080 is a wonderful new addition to the market.\n\n# [Digital Foundry Article](https://www.eurogamer.net/digitalfoundry-2025-nvidia-geforce-rtx-5080-review)\n\n# [Digital Foundry Video](https://www.youtube.com/watch?v=k7hDtGh0wIo)\n\n>See Stickied Comment\n\n# [eTeknix Article](https://www.eteknix.com/nvidia-geforce-rtx-5080-founders-edition-review/)\n\n# [eTeknix Video](https://www.youtube.com/watch?v=CKhoBBX2h00)\n\n>See Stickied Comment\n\n# [Guru3D](https://www.guru3d.com/review/review-nvidia-geforce-rtx-5080-founders-edition-reference/)\n\n>Depending on the game, performance improvements can vary widely. On average, you can expect a 10 to 25 percent boost in traditional rendering performance coming from a 4080S. The more effective part is NVIDIA's heavy investment in AI, deep learning, and neural shading. When we tested DLSS4 with frame generation enabled at 4x, the performance is simply incredible. However, the pressing question arises: will consumers be ready to invest in AI-assisted rendering? The answer isn’t clear yet, but time will tell. One thing is certain—DLSS4 works wonders. The performance metrics shown are a testament to its power. This GPU is quintessential for gamers using Ultra-Wide HD, Quad HD, or Ultra HD monitors, delivering a great visual experience with framerates to match. But yes, overall from the shading rasterization performance, the card is somewhat lacklustre\n\n>The GeForce RTX 5080 will speak to a lot more people compared to the $1999 costing RTX 5090. However, you'll get far less performance. Compared to the RTX 4080/4080 Super the overall rasterizer performance is a notch faster, but not heaps, and that is today's most disappointing news. NVIDIA invested heavily in the transistor budget for AI, the new generation of products places a strong focus on Raytracing, Neural Shading and of course DLSS4 with MFG (Multi Frame Generation). The combination of these together can easily bring in a fact x3 or x4 (and sometimes faster) result. Whether or not the end user is ready for artificially created frames in this degree we doubt, but as far as NVIDIA is concerned, it's the future. We do hope to see more backwards compatibility with DLSS 4 so that older games will get this new tech included as well. We stated this in the RTX 5090 review already, we wonder if the balance hasn't shifted towards AI assistance a bit too much. For the end-user change and thus a move away from the traditional render engine it will be a tough pill to swallow. The potential is huge though. For example, games like Microsoft Flight Simulator 2024, when combined with 4.0, could achieve over 150+ FPS at Ultra HD. Similarly, Cyberpunk in UHD did \\~180 FPS, that's with raytracing enabled. The recent move towards Ray reconstruction also moved NVIDIA into a new sweet spot. All features and performance combined with new technology like DLSS4 really make the Series 5000 from NVIDIA compelling. Other downsides for today's tested product have to be the high energy consumption and price level. In the end whatever we write, or how we feel about the AI-driven content doesn't matter. It's you guys that make the decisive purchase or not which makes this product series a success. The product is a notch faster than the previous generation if you look at that traditional render engine, however looking just that alone is not enough. With a whole lot of extra AI driver functionality that comes along with it, boosting your game FPS towards very high levels in the highest resolutions is possible with the likes of DLSS4 and MFG. Realistically though an RTX 4000 card with DLSS3.5 and Frame Generation will get you plenty of AI-driven performance as well. The founder card itself is lovely in design, it looks nice and it is reasonably silent. The power usage is somewhat icky. If you're coming from the RTX 3000 series or lower products, then this might be an attractive enough buy, but I think many of you expected to see RTX 4090 performance, or even slightly better. For that, you'll need a premium AIC OC version with a premium price. \n\n# [Hot Hardware](https://hothardware.com/reviews/nvidia-geforce-rtx-5080-blackwell-review)\n\n>Last week’s launch of the [GeForce RTX 5090](https://hothardware.com/reviews/nvidia-geforce-rtx-5090-review), crowned a new king in the gaming GPU market. It’s pricier and consumes more power than its predecessor, but the RTX 5090 was performance leader across the board. The GeForce RTX 5080 is also technically an upgrade over the RTX 4080 in virtually every way, but its power consumption is in the same ball park and its introductory $999 MSRP is actually somewhat lower. That should be a great story, but the GeForce RTX 5080 is only a mild upgrade over its previous-gen namesake for gaming, unless you can turn on all DLSS features with multi-frame generation. It does, however, offer more of a boost with AI and content creation workloads.\n\n>When the GeForce RTX 4080 launched, it [crushed the GeForce RTX 3090](https://hothardware.com/reviews/nvidia-geforce-rtx-4080-gpu-review) with many workloads. That’s not the case with the GeForce RTX 5080, but that was obviously not NVIDIA’s intention. The GB203 GPU powering the card is actually smaller than the AD103 on the RTX 4080, and it is manufactured on the same process node.\n\n>NVIDIA’s focus here was obviously on architectural advancements and AI-powered rendering. When you factor in the capabilities of RTX Neural Rendering and DLSS 4 with multi-frame generation, the RTX 5080 separates itself from previous-gen offerings and offers clearly superior performance and technology. And therein lies the rub. Traditional raster will likely be less of a focus for the industry moving forward. NVIDIA is looking to the [future with Blackwell](https://hothardware.com/reviews/nvidia-rtx-blackwell-architecture-overview), and they're not alone, as both AMD and Intel are on this path as well . As game developers incorporate more of the technologies available in the RTX 50 series, its performance profile relative to previous-gen GPUs will change. Though 75 titles will offer support for DLSS as of tomorrow (if you factor in the DLSS override controls in the NVIDIA app), we suspect revisiting the performance of these cards in a few months may tell a different story. AMD and Intel may also have some fresh competitors in the mix too by then.\n\n>That said, most consumers buy products for what they offer today, and not what they may potentially offer in the future. If you’re considering a card in the GeForce RTX 5080 FE’s price range, it is the current best option on the market. It’s faster and has more advanced features than a GeForce RTX 4080 and also AMD’s current flagship offering. It is not a significant upgrade over the GeForce RTX 40 series for gamers though. For owners of GeForce RTX 30 series cards (or older), however, the GeForce RTX 5080 will offer a massive boost.\n\n# [Igor's Lab](https://www.igorslab.de/en/nvidia-geforce-rtx-5080-founders-edition-im-test-geforce-rtx-4080-ti-mit-blackwell-genen/)\n\n>The RTX 5080 is particularly impressive in Ultra-HD resolutions (3840 x 2160 pixels) with activated ray tracing and patch tracing effects. Thanks to the 10,752 CUDA cores, 336 fifth-generation Tensor cores and support for DLSS 4, the card achieves exceptional frame rates in graphically demanding scenarios. While the RTX 4080 Super lags behind the RTX 5080 in most benchmarks, the new card manages to deliver a smoother frame rate and better stability through the integration of multi-frame generation (MFG). This is certainly advantageous for those who believe they need something like this.\n\n>The improved ray tracing performance, made possible by 84 fourth-generation RT cores, is particularly evident in games such as *Cyberpunk 2077* and *Alan Wake 2*. With ray tracing enabled, the RTX 5080 also benefits from advanced ray reconstruction functionality, ensuring outstanding image quality in even the most demanding scenarios. Despite this impressive performance, some limitations can be recognized: In native 4K with maximum settings, the card may still remain at its performance limit, especially at high frame rates and intensive lighting simulations. Apart from these new features, however, the GeForce RTX 5080 remains a classic sidegrade and can hardly score with significant additional performance. Everyone has to decide for themselves whether they are disappointed by this. For my part, I had actually hoped for 20 percent.\n\n>The thermal design of the RTX 5080 is based on a double-sided flow-through cooling system that directs cool air through the card and efficiently dissipates heated air. During operation, the GPU temperature remains stable even in intensive gaming scenarios, with the card reaching a maximum temperature of just under 76 °C. The memory temperatures benefit from the optimized power supply via separate power rails, which ensure an even power supply. This minimizes thermal fluctuations and ensures that the memory area remains stable even under high loads. Thermal analysis using the Optris PI 640 shows homogeneous heat distribution, with hotspots such as the GPU and voltage converters being effectively cooled.\n\n>The noise development of the RTX 5080 is heavily dependent on the fan speed. When idling and at moderate speeds, the card remains pleasantly quiet, which is due to the low-vibration fan mounting and the aerodynamic optimization of the fan blades. Under load, however, the noise increases noticeably and reaches values of up to 38 dB(A). A characteristic humming at around 200 Hz was detected in the tests, which is caused by resonances of the fans or the voltage converters. This noise is particularly noticeable at certain fan speeds, but is not consistently audible.\n\n# [KitGuru Article](https://www.kitguru.net/components/graphic-cards/dominic-moass/nvidia-rtx-5080-review-efficiency-gains-but-a-performance-letdown/)\n\n# [KitGuru Video](https://www.youtube.com/watch?v=uKIwmW5j6oc)\n\n>Only consider the RTX 5080 if you buy into Nvidia’s AI-fueled vision of the future\n\n>DLSS 4’s Multi Frame Generation feature must be seen (and felt) to be believed. On PCWorld’s Full Nerd podcast, we compared the leap from Single Frame to Multi Frame Generation to the leap from DLSS 1 to DLSS 2. When both technologies first came out, they showed promise but had plenty of rough edges. With DLSS 2, gamers agreed that Nvidia *nailed it*. And while it’s not quite perfect, Multi Frame Generation *nails it*. Once more gamers get their Dorito-stained paws on RTX 50-series cards, and are able to tool around with MFG in 75+ games and apps, I wouldn’t be surprised if all the furor over “fake frames” online dies down quite a bit. It’s a literal game changer.\n\n>But Nvidia is in trouble this generation if the masses *don’t* embrace Multi Frame Generation. Because when it comes to traditional gaming performance, the RTX 5080 is no game changer.\n\n>It’s a pretty damned terrible generational upgrade, actually. Eking out a mere 11 to 15 more render performance than the RTX 4080 Super, at the same price, at a higher power draw, isn’t compelling whatsoever. It can’t come anywhere close to last gen’s 4090. If you don’t like AI-generated frames — maybe you’re sensitive to latency, or you focus on competitive games, or you loathe the idea of AI frames potentially introducing visual glitches — I’d even go so far as to suggest picking up a 4080 Super to get roughly comparable performance for less cash.\n\n>Remember: The [RTX 3080 beat the RTX 2080 by *60 to 80 percent*](https://www.pcworld.com/article/393472/nvidia-geforce-rtx-3080-founders-edition-review.html) when it launched earlier this decade, and it did so for just $700. Then [Nvidia jacked the price of the vanilla RTX 4080](https://www.pcworld.com/article/1379747/nvidia-geforce-rtx-4080-tested-5-things.html) by *$500 dollars* for a 30 percent performance increase, leading to poor sales rectified only by the launch of the 4080 Super at $999. With the RTX 5080 barely outpacing that, the RTX 5080 would have been immensely more compelling at a couple hundred dollars cheaper. Two generations after the RTX 3080, Nvidia has truly devastated the xx80 tier’s value in recent memory. Upgrading from the 3080 to a 5080 will only get you about 40 to 45 percent more performance, for a price tag that’s 42 percent higher. That’s not progress.\n\n>If Nvidia didn’t have MFG in tow, this would’ve been a *scathing* review for the RTX 5080 itself. But boyyyyy does DLSS 4’s new tricks feel great. Multi Frame Generation makes *Star Wars Outlaws*, a notoriously janky game, feel just as good as *Doom 2016*. *Cyberpunk*’s neon Night City feels so much more *alive* when you’re racing around at a buttery-smooth 240Hz+, or over 150fps even with the game’s nuclear RT Overdrive Mode active.\n\n>And that’s the promise Nvidia needs gamers to buy into for the GeForce RTX 5080 — heck, perhaps this entire RTX 50-series generation. Are you willing to embrace “fake frames” and dip your toes into experiences that aren’t currently possible with traditional rendering alone? If so, this GPU provides enough grunt to fuel those adventures in 4K and 1440p alike.\n\n>If not, the RTX 5080 is one of the most disappointing GPU releases in a long time. It’s probably best to save your cash.\n\n>Me? I’m into the vision. But I wish Nvidia imbued the RTX 5080 with more raw rendering firepower, so it could be a decent upgrade even for “fake frame” haters. Nvidia didn’t, alas — so now the RTX 5080’s future hangs in the balance of those 75 DLSS 4 games working correctly at launch.\n\n>If DLSS 4 and Multi Frame Generation perform like a champ when that wider availability hits, it could usher in a new era of smooth, AI-supercharged performance. But if DLSS 4 winds up plagued by visual artifacts or other issues once the floodgates open, it could instead set off an explosion of “fake frames” memes and sign a death warrant for the otherwise ho-hum RTX 5080 — perhaps even the rest of Nvidia’s 50-series lineup.\n\n>The GeForce RTX 5090 can stand alone on its own merits, but the RTX 5080 is all-in on DLSS 4. All that’s left us to see is where the chips fall.\n\n# [LanOC](https://lanoc.org/review/video-cards/9135-nvidia-rtx-5080-founders-edition)\n\n>For performance, it will depend a lot on what your goal is for the card on whether you would say it did well in testing or not. Nvidia markets the card as a 2k or 1440p card and at that resolution and at 1080p it did extremely well, outperforming last generation's flagship RTX 4090. At 4k I would still say it did very well, but on average the RTX 4090 does edge back in ahead of it in our tests. The RTX 5080 has 16GB of memory and a smaller memory interface than the RTX 4090. It does have faster memory which makes up the difference a lot, but that does make a difference at 4k in some tests. That said, if you haven’t experienced DLSS 4 with the improved transformer models making significant improvements in the visual quality and frame generation x4 giving mind blowing performance, I would take that over the 8 extra FPS at 4k. Not only do you see a lot of those improvements even in CPU-limited situations, but you can see 300-500% performance improvements over not using DLSS at all. I didn’t run into as many of the bugs as I saw when testing the RTX 5090, but OpenCL-based workloads were still a problem but Nvidia is aware and working on it.\n\n>At the end of the day though, it always comes down to pricing. The RTX 5080 Founders Edition has an MSRP of $999. That is $200 less than the RTX 4080 launched at but is $300 more than what the RTX 3080 launched at. It’s also half of the price of the new RTX 5090. More importantly, how does it compare to other cards with current pricing? For that, I put the graph above together that takes every card I’ve tested’s Time Spy Extreme GPU Score and divides it by its current price as well as its launch MSRP. For current pricing, it is the lowest available price on PCPartPicker and it is interesting to see how much pricing and card availability has changed from last week when the performance of the RTX 5090 was shown. The RTX 5080 Founders Edition is sitting in the middle of the pack for value right now but there aren’t any cards faster or even near it in performance on the chart. With all of the talk on how it compares with the RTX 4090 for example, the only 4090’s you can currently get are $2598 or more. I wouldn’t call it a value, but if you are looking for high-end 1400p or 4k performance and the RTX 5090 isn’t in your budget this is the clear choice, that is assuming you can find these anywhere near the launch price once they hit stores.\n\n# [OC3D Article](https://overclock3d.net/reviews/gpu_displays/nvidia-rtx-5080-founders-edition-review/)\n\n# [OC3D Video](https://www.youtube.com/watch?v=k-6Dw4qsGhA)\n\n>As we said in our introduction, the Nvidia RTX 5080 Founders Edition is almost famous before it’s appeared. Such is the incredible reputation of its similarly numbered forebears, the expectation is massive. The GTX 280 was launched 17 years ago, and apart from a couple of notable missteps – the red hot GTX 480 for example – they’ve all been stellar. It’s not a coincidence that when Nvidia introduced the RTX series of cards the top model was a RTX 2080 Ti. The name has cachet.\n\n>Clearly the RTX 5090 follows the recent trend where the 90 card is the flagship, money-no-object option. The x080 cards are for those with deep pockets, but not unlimited ones. Or perhaps those for whom gaming is your primary thing and so spending a little more is worthwhile. That’s where the Nvidia RTX 5080 Founders Edition comes in. We’ve yet to see performance figures for the guaranteed massive selling RTX 5070 and RTX 5070Ti models. That leaves us with either seeing how close the Nvidia RTX 5080 can get to the big RTX 5090, or how much better than the Ada Lovelace cards it is.\n\n>If the RTX 5090 was jaw-dropping, the RTX 5080 continues that good work. The next generation of cores which festoon the tiny PCB really put the work in to give you smooth performance. We know that the big ticket item is multi-frame generation, but even in pure rasterised benchmarks the Nvidia RTX 5080 Founders Edition proves a big upgrade on the previous model. If you’re just after the latest and greatest at an enthusiast price point, you can almost stop reading here.\n\n# [PC World Article](https://www.pcworld.com/article/2591060/nvidia-geforce-rtx-5080-review.html)\n\n# [PC World Video](https://www.youtube.com/watch?v=YaZT5OuW6v0)\n\n>DLSS 4’s Multi Frame Generation feature must be seen (and felt) to be believed. On PCWorld’s Full Nerd podcast, we compared the leap from Single Frame to Multi Frame Generation to the leap from DLSS 1 to DLSS 2. When both technologies first came out, they showed promise but had plenty of rough edges. With DLSS 2, gamers agreed that Nvidia *nailed it*. And while it’s not quite perfect, Multi Frame Generation *nails it*. Once more gamers get their Dorito-stained paws on RTX 50-series cards, and are able to tool around with MFG in 75+ games and apps, I wouldn’t be surprised if all the furor over “fake frames” online dies down quite a bit. It’s a literal game changer.\n\n>But Nvidia is in trouble this generation if the masses *don’t* embrace Multi Frame Generation. Because when it comes to traditional gaming performance, the RTX 5080 is no game changer. \n\n>It’s a pretty damned terrible generational upgrade, actually. Eking out a mere 11 to 15 more render performance than the RTX 4080 Super, at the same price, at a higher power draw, isn’t compelling whatsoever. It can’t come anywhere close to last gen’s 4090. If you don’t like AI-generated frames — maybe you’re sensitive to latency, or you focus on competitive games, or you loathe the idea of AI frames potentially introducing visual glitches — I’d even go so far as to suggest picking up a 4080 Super to get roughly comparable performance for less cash.\n\n>If Nvidia didn’t have MFG in tow, this would’ve been a *scathing* review for the RTX 5080 itself. But boyyyyy does DLSS 4’s new tricks feel great. Multi Frame Generation makes *Star Wars Outlaws*, a notoriously janky game, feel just as good as *Doom 2016*. *Cyberpunk*’s neon Night City feels so much more *alive* when you’re racing around at a buttery-smooth 240Hz+, or over 150fps even with the game’s nuclear RT Overdrive Mode active.\n\n>If not, the RTX 5080 is one of the most disappointing GPU releases in a long time despite its prowess. It’s probably best to save your cash unless you’re on a card several generations old and don’t mind spending big for a big performance upgrade.\n\n>If DLSS 4 and Multi Frame Generation perform like a champ when that wider availability hits, it could usher in a new era of smooth, AI-supercharged performance. But if DLSS 4 winds up plagued by visual artifacts or other issues once the floodgates open, it could instead set off an explosion of “fake frames” memes and sign a death warrant for the otherwise ho-hum RTX 5080 — perhaps even the rest of Nvidia’s 50-series lineup.\n\n>The GeForce RTX 5090 can stand alone on its own merits, but the RTX 5080 is all-in on DLSS 4. All that’s left us to see is where the chips fall.\n\n# [Puget Systems (Content Creation Review)](https://www.pugetsystems.com/labs/articles/nvidia-geforce-rtx-5080-content-creation-review/)\n\n>Overall, the RTX 5080 is a solid GPU that provides good performance nearly across the board. However, following [our 5090 review](https://www.pugetsystems.com/labs/articles/nvidia-geforce-rtx-5090-content-creation-review/), we are somewhat disappointed by the relatively small performance uplifts over the RTX 4080 SUPER. In some places, the 5090 seemed to justify the price increase over the 4090 with staggering performance increases. For the 5080, the same price seems to get you basically just the same performance in many workloads.\n\n>In **video editing and motion graphics**, the RTX 5080 is about 5-10% faster than the RTX 4080 SUPER and 20-30% faster than the 3080 Ti. There were some standout areas, such as 3D performance in After Effects, with gains double those. We’re still waiting on finalized DaVinci Resolve results, but we are doubtful the 5080 will be a huge upgrade over a 4080 or 4080 SUPER, except perhaps with LongGOP media. Still, for new-to-PC users or those on even older cards, it offers a solid upgrade.\n\n>In **rendering applications**, the 5080 manages better, with a 10-20% lead over the 4080 SUPER and a 55% to 188% lead over the 3080 Ti. This is definitely a performance jump that may be worth upgrading for even from the 40-series card, and it offers a great value for those using older generation cards. However, there is still the lingering issue of compatibility and performance quirks, so we would recommend buying with caution or holding off for a bit before committing to a 5080 for a rendering system. We are currently [maintaining a list of known issues](https://www.pugetsystems.com/blog/2025/01/27/nvidia-geforce-rtx-50-series-known-software-issues/) in content creation applications that you can check in on to see when these are resolved.\n\n>NVIDIA’s new GeForce RTX 5080 is a great workhorse GPU that provides solid performance across the board and can handle most of the tasks you throw at it. In many workflows, it is only slightly slower than the RTX 5090, so it may end up being one of the better price-to-performance cards of this generation. If you are on a 30-series card or older, it offers a great upgrade, but less so for users on a 40-series card. Especially given the dwindling supply of those previous-generation cards, we expect the RTX 5080 to be an incredibly popular GPU.\n\n# [Techpowerup](https://www.techpowerup.com/review/nvidia-geforce-rtx-5080-founders-edition/)\n\n>At 4K resolution, with pure rasterization, without ray tracing or DLSS, we measured a 14% performance uplift over the RTX 4080 Super, 15% over the RTX 4080 non-Super. This is definitely MUCH less than expected and not nearly as much as what we saw last week from RTX 5090, which beat the RTX 4090 by 35%. Compared to the GeForce RTX 3080, the performance increase is 75%, which means NVIDIA missed the \"twice the performance every second generation\" rule. Last-generation's flagship, the RTX 4090 is 13% faster than the RTX 5080 and the new RTX 5090 flagship is 52% faster, but twice as expensive.\n\n>GeForce RTX 5080 is still faster than AMD Radeon RX 7900 XTX, Team Red's best GPU, by 15% in a pure raster scenario, much more in RT. AMD has confirmed that they are not going for high-end with RDNA 4, and it's expected that the RX 9070 Series will end up somewhere between RX 7900 XT and RX 7900 GRE. This means that AMD's new cards don't pose a threat to the RTX 5080, which might explain why we're not getting bigger performance improvements.\n\n>RTX 5080 is a good card for 4K gaming. With RT or Path Tracing enabled, some titles require that you use DLSS Upscaling / Frame Generation. The card is also great for 1440p gaming, to feed those high-refresh-rate gaming monitors.\n\n>NVIDIA is betting on ray tracing and Blackwell comes with several hardware improvements here. Interestingly, the RTX 5080 runs only 11% faster at RT than RTX 4080 Super—remember, we got +14% in without RT. It looks like this is partly due to the game selection. The games that show the biggest gains in our non-RT test suite do not support RT. Still, compared to AMD's Radeon RX 7900 XTX, the difference is massive—the RTX 5080 is 61% (!) faster than the RX 7900 XTX. On top of that, NVIDIA is introducing several new optimization techniques that game developers can adopt. The most interesting one is Neural Rendering, which is exposed through a Microsoft DirectX API (Cooperative Vectors). This ensures that the feature is universally available for all GPU vendors to implement, so game developers should be highly motivated to pick it up. AMD has confirmed that for RDNA 4 they have put in some extra love for the RT cores, so hopefully they can catch up a bit.\n\n>NVIDIA made a big marketing push to tell everyone how awesome DLSS 4 is, and they are not wrong. First of all, DLSS 4 Multi-Frame-Generation. While DLSS 3 doubled the framerates by generating a single new frame, DLSS 4 can now triple or quadruple the frame count. In our testing this worked very well and delivered the expected FPS rates. Using FG, gaming latency does NOT scale linearly with FPS, but given a base FPS of like 40 or 50, DLSS x4 works great to achieve the smoothness of over 150 FPS, with similar latency than you started out with. Image quality is good, if you know what to look for you can see some halos around the player, but that's nothing you'd notice in actual gameplay.\n\n>Want lower latency? Then turn on DLSS 4 Upscaling, which lowers the render resolution and scales up the native frame. In the past there were a lot of debates whether DLSS upscaling image quality is good enough, some people even claimed \"better than native\"—I strongly disagree with that—I'm one of the people who are allergic to DLSS 3 upscaling, even at \"quality.\" With Blackwell, NVIDIA is introducing a \"Transformer\" upscaling model for DLSS, which is a major improvement over the previous \"CNN\" model. I tested Transformer and I'm in love. The image quality is so good, \"Quality\" looks like native, sometimes better. There is no more flickering or low-res smeared out textures on the horizon. Thin wires are crystal clear, even at sub-4K resolution! You really have to see it for yourself to appreciate it, it's almost like magic. The best thing? DLSS Transformer is available not only on GeForce 50 series, but on all GeForce RTX cards with Tensor Cores! While it comes with a roughly 10% performance hit compared to CNN, I would never go back to CNN. While our press driver was limited to a handful of games with DLSS 4 support, NVIDIA will have around 75 games supporting it on launch, most through NVIDIA App overrides, and many more are individually tested, to ensure best results. NVIDIA is putting extra focus on ensuring that there will be no anti-cheat drama when using the overrides.\n\n>For $1000, there is no reason you should buy RTX 4080 or RTX 4080 Super now. AMD's Radeon RX 7900 XTX is $820, or 18% cheaper, but it's also 15% slower in raster, and 38% slower in RT. NVIDIA is also very strong in software features, the new DLSS Transformer model is a game-changer and DLSS 4 multi-frame-generation is a notable selling point, too. No way I would buy RX 7900 XTX at that price instead of RTX 5080—maybe if AMD drops the price considerably. Also, the way AMD is handling Radeon lately makes me wonder if their discrete GPU brand will still be around in two or three years. The upcoming RDNA 4 lineup will not target the top end of the market, so unless a miracle happens, RX 9070 XT won't be able to compete with RTX 5080, maybe RTX 5070 Ti, which is coming out soon.\n\n>If you already have a high-end GeForce RTX 40 Series card, then there is no reason to upgrade. You're just missing out on multi-frame-generation, the DLSS Transformer model is supported on all older RTX cards, too. On the other hand, if you're coming from GeForce 30, then suddenly you'll get to experience frame generation, which will make a huge difference for your gaming experience.\n\n# [The FPS Review](https://www.thefpsreview.com/2025/01/29/nvidia-geforce-rtx-5080-founders-edition-video-card-review/)\n\n>GeForce RTX 5080 performance makes us go hmmm. That’s an interesting way for us to start this paragraph, but the performance of the GeForce RTX 5080 is indeed all over the place. There are some games where the generational uplift looks exciting, and then there are others that make us scratch our head. It generally gives us a feeling of “hmmm.”\n\n>There are some good cases where the GeForce RTX 5080 is a nice uplift from the previous generation. We did see some 23%+ performance improvements, but those seemed to be outliers, more than the norm. Overall, it has somewhere between a 10%-20% performance uplift depending on the game and settings, Ray Tracing wasn’t that big. This isn’t enough to reach or match the GeForce RTX 4090 in performance. The GeForce RTX 4090 remains the performance leader in this regard. If you thought the GeForce RTX 5080 would be as fast as the GeForce RTX 4090, it isn’t.\n\n>Some of the results we have experienced make sense, after all, the raw specifications of the GeForce RTX 5080 are not that much upgraded from the GeForce RTX 4080 Super. The GeForce RTX 5080 is a GPU that is essentially a GeForce RTX 5090 cut in half, and the price reflects that as well. The GeForce RTX 5080 seems to consume about 17% more power than the GeForce RTX 4080 Super, and we get a performance increase that is close to that, some cases better, some cases worse.\n\n>Overall this means that the GeForce RTX 5080 at times follows a little too closely to the previous generation it is supposed to be supplanting. Often times we are left with a sense of a less-than-desirable gameplay experience improvement that one would expect from a new generation.\n\n>One could even call the GeForce RTX 5080 more akin to a theoretical ‘GeForce RTX 4080 Super Ti” or “GeForce RTX 4080 Super Super”, at least that is what it feels like. Keep in mind that the MSRP is $999, and that IS the same MSRP that the GeForce RTX 4080 Super was as well. Therefore, technically, it is a price for performance improvement, if pricing is at $999. It’s just that… it isn’t that exciting really.\n\n>As the GeForce RTX 4080 Super’s dry up in the market and the GeForce RTX 5080’s replace it, you will be getting a better gameplay experience with the GeForce RTX 5080. At the $999 MSRP, the NVIDIA GeForce RTX 5080 Founders Edition would be a solid upgrade from *prior generations*, such as GeForce RTX 3080 or GeForce RTX 2080 or even earlier.\n\n>If you are moving from an older generation prior to the RTX 40 series, the GeForce RTX 5080 will offer a good substantial upgrade path to modern features and gameplay performance at the $999 MSRP, but if you currently own a GeForce RTX 40 Series, unless you are moving from low-end to high-end, it is not going to be worth the upgrade.\n\n# [Tomshardware](https://www.tomshardware.com/pc-components/gpus/nvidia-geforce-rtx-5080-review)\n\n>Nvidia's RTX 5080 Founders Edition delivers what we were expecting, mostly. We can't help but feel that, like the RTX 5090, these first drivers made available to reviewers aren't fully tuned for the Blackwell architecture yet. In some games, performance looks quite good with reasonable generational improvements. In others, the gains don't materialize — particularly at lower resolutions.\n\n>What is obvious is that the RTX 5080 isn't a massive leap in performance compared to its predecessor — whether that's the 4080 Super we tested or the slightly slower RTX 4080. Nvidia's performance claims depend almost entirely on Multi Frame Generation (MFG), and that's disingenuous at best. Nvidia knows as well as anyone that a game running at 200 FPS with 4X MFG doesn't feel the same as a game rendering at 200 FPS without any form of framegen. Pretending that the resulting \"framerates\" are comparable requires serious mental gymnastics.\n\n>However, it's equally disingenuous to suggest that framegen/MFG are useless or \"fake frames.\" If you play a game running at 30–35 FPS without framegen and then try the same game running at 55–60 FPS with framegen, the latter feels better in my book. It's not anywhere close to twice as fast, but perhaps 20% faster. And if you use 4X MFG running at 105–115 FPS, that might feel another 10–20 percent faster than the 2X framegen result.\n\n>It's really just frame smoothing, but that smoothness interacts with your brain to make the game generally feel better, even if the base input sampling rate decreases slightly.\n\n>As a potential GPU purchase, if they're both priced the same, the RTX 5080 will be better than an RTX 4080 Super. That much is a given. Right now, it doesn't always win, but driver tuning should address any shortcomings. But if you already have a decent GPU, the benefits of the 5080 over the 4080 Super are pretty thin at present. If you didn't see enough in the RTX 4080 Super to entice you to upgrade in early 2024, the extra 10% performance plus new features that the 5080 offers isn't likely to change things.\n\n>If you're in the market for a $1,000 graphics card, and assuming there's enough supply to keep prices down, the RTX 5080 now sits on the podium as the second fastest GPU overall. It's half the price of the 5090, less likely to be continually sold out, and has all the other Blackwell architecture features. It's just nowhere near the potential 30% higher baseline performance we like to see with generational upgrades.\n\n>And if you're able to justify spending a grand on the RTX 5080, it's probably not that much of a stretch to double that for the clearly superior RTX 5090 that's over 50% faster on average — at 4K. The RTX 3090 was only 15% faster than an RTX 3080 four years ago, for double the price. For the well-funded gamer / streamer / AI researcher / etc., the 5090 is the clearly superior option. Which is one more reason we expect it will be hard to come by for quite some time.\n\n# [Computerbase - German](https://www.computerbase.de/artikel/grafikkarten/nvidia-geforce-rtx-5080-test.91176/)\n\n# [HardwareLuxx - German](https://www.hardwareluxx.de/index.php/artikel/hardware/grafikkarten/65395-leistungsplus-nur-ueber-mfg-die-geforce-rtx-5080-founders-edition-im-test.html)\n\n# [PCGH - German](https://www.pcgameshardware.de/Geforce-RTX-5080-Grafikkarte-281030/Tests/Release-Preis-kaufen-Benchmark-Review-vs-4080-Super-1464610/)\n\n# [Elchapuzasinformatico - Spanish](https://elchapuzasinformatico.com/2025/01/nvidia-geforce-rtx-5080-founders-edition-review/)\n\n\\--------------------------------------------\n\n# Video Review\n\n# [Der8auer](https://www.youtube.com/watch?v=IvQwlN1sE0U)\n\n# [Digital Foundry Video](https://www.youtube.com/watch?v=k7hDtGh0wIo)\n\n# [eTeknix Video](https://www.youtube.com/watch?v=CKhoBBX2h00)\n\n# [Gamers Nexus Video](https://www.youtube.com/watch?v=nShh_j4s2YE)\n\n# [Hardware Canucks](https://www.youtube.com/watch?v=JFF7lMvpV-s)\n\n# [Hardware Unboxed](https://www.youtube.com/watch?v=sEu6k-MdZgc)\n\n# [JayzTwoCents](https://www.youtube.com/watch?v=meekBr-ZB1E)\n\n# [KitGuru Video](https://www.youtube.com/watch?v=uKIwmW5j6oc)\n\n# [Level1Techs](https://www.youtube.com/watch?v=ZoE8GQnDwQQ)\n\n# [Linus Tech Tips](https://www.youtube.com/watch?v=Fbg7ChsjmEA)\n\n# [OC3D Video](https://www.youtube.com/watch?v=k-6Dw4qsGhA)\n\n# [Optimum Tech](https://www.youtube.com/watch?v=d7k4XWg-TcA)\n\n# [PC World Video](https://www.youtube.com/watch?v=YaZT5OuW6v0)\n\n# [Techtesters](https://www.youtube.com/watch?v=azD56D4_bFM)\n\n# [Tech Yes City](https://www.youtube.com/watch?v=6NwO1qrkEds)",
    "comments": [
      "> And if you’re able to justify spending a grand on the RTX 5080, it’s probably not that much of a stretch to double that for the clearly superior RTX 5090 that’s over 50% faster on average — at 4K\n\nWhat a stupid take (as expected) from Tomshardware.",
      "Literally the worst generation of GPUs Nvidia has ever released.",
      "RTX 50 8.0%",
      "TLDR; Skip the 5080 if you have a 40 series.",
      "I hope this doomer posting from this sub continues so I can get a 5080 tomorrow. \n\nNot everyone is upgrading from a 4000 series, and this seems like a great upgrade from my 3070ti.",
      "I may as well double it again and run dual 5090s at that point because clearly if im just throwing thousands around like that it's not an issue",
      "RIP my dreams of cheaper used 4090s.",
      "Fairly disappointing coming from a 3080 Ti looking to upgrade.",
      "My takeaway.\n\n\nIf you are on 4000 series, skip. Unless you really want multi frame gen.\n\n\nFor 3000 series, it is up to you. It's up to 50% more frames, some improvements in frame time, and access to frame Gen.\n\nUnder the 3000 series? Much better performance, much better frame times, more features. If you were previously considering the 4000 series, this is a no brainer. Better performance at the same price.\n\nThe 5000 series is being compared to Turing. A lot of the new architecture is focused on neural rendering, but no games use it yet. Like Turing, these cards might age well in 2 years time.\n\nThe small Gen on Gen uplift is why everyone is upset. Neural rendering doesn't exist in games right now. Silver lining is that the 5000 series is the same price as last Gen.\n\n\n\nThere is so much room for a 5080 Ti or Super. The 5090 is getting something like up to 50% more frames over the 5080. Also room for more ram on a 5080 Super/Ti.",
      "See the bright side: There will be less posts about 5080 not beeing in stock.",
      "This \" launch \" could've been an email",
      "CPU manufs should retaliate by blowing hot air towards the GPU.",
      "NVIDIA has been trying to make people think this way for years, but this gen doesn’t sell it at all. $1200 -> $1600 made a lot more sense last gen, even if that was also BS",
      "Going from a 1070 to a 5080 is a massive upgrade, why would it not be worth it?",
      "Gonna keep my 3080 for a while longer, lets see what the next generation has in store.",
      "The 16gb vram aside (which already made it a no-buy for me), the pitiful perf increase and price tag make this a slap in the face from nvidia.\n\nI'll definitely be holding on to my 3080 for another gen it seems.",
      "basically a 4080 Ti Super with multi frame gen \n\nnot a bad card if you're going from 30 series GPUs and below or a 4060, but still a bad card generation to generation wise",
      "I wasn't expecting much and was still disappointment",
      "I thought my 4090 purchase was insane at launch. It might actually turn out one of the best in a few more years.\n\n5xxx series is the least impressive launch since GTX 700 series!",
      "I feel even better than I already did buying a 4080 early last year."
    ]
  }
]